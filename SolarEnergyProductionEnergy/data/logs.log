2023-10-20 23:15:29,306:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-20 23:15:29,306:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-20 23:15:29,306:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-20 23:15:29,306:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-20 23:20:46,999:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-20 23:20:46,999:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-20 23:20:46,999:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-20 23:20:46,999:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-20 23:20:47,186:INFO:PyCaret RegressionExperiment
2023-10-20 23:20:47,186:INFO:Logging name: exp_A
2023-10-20 23:20:47,186:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-20 23:20:47,186:INFO:version 3.1.0
2023-10-20 23:20:47,186:INFO:Initializing setup()
2023-10-20 23:20:47,186:INFO:self.USI: 2be0
2023-10-20 23:20:47,186:INFO:self._variable_keys: {'transform_target_param', 'exp_name_log', 'y_train', 'logging_param', 'n_jobs_param', 'X_train', 'target_param', 'USI', 'gpu_n_jobs_param', 'fold_groups_param', '_ml_usecase', 'seed', 'fold_generator', 'idx', 'html_param', 'log_plots_param', 'y', 'gpu_param', 'X_test', 'memory', 'y_test', 'data', 'X', 'exp_id', '_available_plots', 'fold_shuffle_param', 'pipeline'}
2023-10-20 23:20:47,186:INFO:Checking environment
2023-10-20 23:20:47,186:INFO:python_version: 3.8.18
2023-10-20 23:20:47,186:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-20 23:20:47,186:INFO:machine: AMD64
2023-10-20 23:20:47,186:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-20 23:20:47,186:INFO:Memory: svmem(total=16505954304, available=3563368448, percent=78.4, used=12942585856, free=3563368448)
2023-10-20 23:20:47,186:INFO:Physical Core: 8
2023-10-20 23:20:47,186:INFO:Logical Core: 16
2023-10-20 23:20:47,186:INFO:Checking libraries
2023-10-20 23:20:47,186:INFO:System:
2023-10-20 23:20:47,186:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-20 23:20:47,186:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-20 23:20:47,186:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-20 23:20:47,186:INFO:PyCaret required dependencies:
2023-10-20 23:20:47,253:INFO:                 pip: 23.3
2023-10-20 23:20:47,254:INFO:          setuptools: 68.0.0
2023-10-20 23:20:47,254:INFO:             pycaret: 3.1.0
2023-10-20 23:20:47,254:INFO:             IPython: 8.12.0
2023-10-20 23:20:47,254:INFO:          ipywidgets: 8.1.1
2023-10-20 23:20:47,254:INFO:                tqdm: 4.66.1
2023-10-20 23:20:47,254:INFO:               numpy: 1.23.5
2023-10-20 23:20:47,254:INFO:              pandas: 1.5.3
2023-10-20 23:20:47,254:INFO:              jinja2: 3.1.2
2023-10-20 23:20:47,254:INFO:               scipy: 1.10.1
2023-10-20 23:20:47,254:INFO:              joblib: 1.3.2
2023-10-20 23:20:47,254:INFO:             sklearn: 1.2.2
2023-10-20 23:20:47,254:INFO:                pyod: 1.1.0
2023-10-20 23:20:47,254:INFO:            imblearn: 0.11.0
2023-10-20 23:20:47,254:INFO:   category_encoders: 2.6.2
2023-10-20 23:20:47,254:INFO:            lightgbm: 4.1.0
2023-10-20 23:20:47,254:INFO:               numba: 0.58.1
2023-10-20 23:20:47,254:INFO:            requests: 2.31.0
2023-10-20 23:20:47,254:INFO:          matplotlib: 3.7.3
2023-10-20 23:20:47,254:INFO:          scikitplot: 0.3.7
2023-10-20 23:20:47,254:INFO:         yellowbrick: 1.5
2023-10-20 23:20:47,255:INFO:              plotly: 5.17.0
2023-10-20 23:20:47,255:INFO:    plotly-resampler: Not installed
2023-10-20 23:20:47,255:INFO:             kaleido: 0.2.1
2023-10-20 23:20:47,255:INFO:           schemdraw: 0.15
2023-10-20 23:20:47,255:INFO:         statsmodels: 0.14.0
2023-10-20 23:20:47,255:INFO:              sktime: 0.21.1
2023-10-20 23:20:47,255:INFO:               tbats: 1.1.3
2023-10-20 23:20:47,255:INFO:            pmdarima: 2.0.3
2023-10-20 23:20:47,255:INFO:              psutil: 5.9.0
2023-10-20 23:20:47,255:INFO:          markupsafe: 2.1.3
2023-10-20 23:20:47,255:INFO:             pickle5: Not installed
2023-10-20 23:20:47,255:INFO:         cloudpickle: 2.2.1
2023-10-20 23:20:47,255:INFO:         deprecation: 2.1.0
2023-10-20 23:20:47,255:INFO:              xxhash: 3.4.1
2023-10-20 23:20:47,255:INFO:           wurlitzer: Not installed
2023-10-20 23:20:47,255:INFO:PyCaret optional dependencies:
2023-10-20 23:20:47,270:INFO:                shap: Not installed
2023-10-20 23:20:47,270:INFO:           interpret: Not installed
2023-10-20 23:20:47,270:INFO:                umap: Not installed
2023-10-20 23:20:47,271:INFO:     ydata_profiling: Not installed
2023-10-20 23:20:47,271:INFO:  explainerdashboard: Not installed
2023-10-20 23:20:47,271:INFO:             autoviz: Not installed
2023-10-20 23:20:47,271:INFO:           fairlearn: Not installed
2023-10-20 23:20:47,271:INFO:          deepchecks: Not installed
2023-10-20 23:20:47,271:INFO:             xgboost: Not installed
2023-10-20 23:20:47,271:INFO:            catboost: 1.2.2
2023-10-20 23:20:47,271:INFO:              kmodes: Not installed
2023-10-20 23:20:47,271:INFO:             mlxtend: Not installed
2023-10-20 23:20:47,271:INFO:       statsforecast: Not installed
2023-10-20 23:20:47,271:INFO:        tune_sklearn: Not installed
2023-10-20 23:20:47,271:INFO:                 ray: Not installed
2023-10-20 23:20:47,271:INFO:            hyperopt: Not installed
2023-10-20 23:20:47,271:INFO:              optuna: Not installed
2023-10-20 23:20:47,271:INFO:               skopt: Not installed
2023-10-20 23:20:47,271:INFO:              mlflow: 2.7.1
2023-10-20 23:20:47,271:INFO:              gradio: Not installed
2023-10-20 23:20:47,271:INFO:             fastapi: Not installed
2023-10-20 23:20:47,271:INFO:             uvicorn: Not installed
2023-10-20 23:20:47,271:INFO:              m2cgen: Not installed
2023-10-20 23:20:47,271:INFO:           evidently: Not installed
2023-10-20 23:20:47,272:INFO:               fugue: Not installed
2023-10-20 23:20:47,272:INFO:           streamlit: Not installed
2023-10-20 23:20:47,272:INFO:             prophet: Not installed
2023-10-20 23:20:47,272:INFO:None
2023-10-20 23:20:47,272:INFO:Set up data.
2023-10-20 23:20:47,303:INFO:Set up folding strategy.
2023-10-20 23:20:47,303:INFO:Set up train/test split.
2023-10-20 23:20:47,324:INFO:Set up index.
2023-10-20 23:20:47,324:INFO:Assigning column types.
2023-10-20 23:20:47,355:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-20 23:20:47,355:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,357:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,369:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,461:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,515:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,517:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:20:47,517:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:20:47,518:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,520:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,520:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,605:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,653:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,653:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:20:47,653:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:20:47,653:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-20 23:20:47,668:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,668:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,759:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,818:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,819:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:20:47,819:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:20:47,819:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,833:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,921:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,970:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,970:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:20:47,970:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:20:47,970:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-20 23:20:47,990:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-20 23:20:48,067:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:20:48,133:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:20:48,133:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:20:48,134:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:20:48,145:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-20 23:20:48,217:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:20:48,267:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:20:48,267:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:20:48,267:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:20:48,267:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-20 23:20:48,371:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:20:48,422:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:20:48,422:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:20:48,422:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:20:48,525:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:20:48,585:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:20:48,586:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:20:48,586:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:20:48,587:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-20 23:20:48,688:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:20:48,744:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:20:48,744:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:20:48,841:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:20:48,900:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:20:48,900:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:20:48,901:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-20 23:20:49,053:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:20:49,053:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:20:49,203:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:20:49,203:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:20:49,219:INFO:Preparing preprocessing pipeline...
2023-10-20 23:20:49,219:INFO:Set up simple imputation.
2023-10-20 23:20:49,219:INFO:Set up column name cleaning.
2023-10-20 23:20:49,286:INFO:Finished creating preprocessing pipeline.
2023-10-20 23:20:49,286:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-20 23:20:49,286:INFO:Creating final display dataframe.
2023-10-20 23:20:49,501:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (34061, 39)
4        Transformed data shape   (34061, 39)
5   Transformed train set shape   (23842, 39)
6    Transformed test set shape   (10219, 39)
7              Numeric features            38
8      Rows with missing values         23.1%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_A
19                          USI          2be0
2023-10-20 23:20:49,668:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:20:49,669:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:20:49,824:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:20:49,824:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:20:49,824:INFO:Logging experiment in loggers
2023-10-20 23:20:50,167:INFO:SubProcess save_model() called ==================================
2023-10-20 23:20:50,167:INFO:Initializing save_model()
2023-10-20 23:20:50,167:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmp4rp_n54e\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-20 23:20:50,167:INFO:Adding model into prep_pipe
2023-10-20 23:20:50,167:WARNING:Only Model saved as it was a pipeline.
2023-10-20 23:20:50,183:INFO:C:\Users\thoma\AppData\Local\Temp\tmp4rp_n54e\Transformation Pipeline.pkl saved in current working directory
2023-10-20 23:20:50,183:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-20 23:20:50,183:INFO:save_model() successfully completed......................................
2023-10-20 23:20:50,283:INFO:SubProcess save_model() end ==================================
2023-10-20 23:20:50,381:INFO:setup() successfully completed in 2.64s...............
2023-10-20 23:20:50,381:INFO:Initializing compare_models()
2023-10-20 23:20:50,381:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, 'include': None, 'exclude': ['ransac'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=['ransac'])
2023-10-20 23:20:50,381:INFO:Checking exceptions
2023-10-20 23:20:50,397:INFO:Preparing display monitor
2023-10-20 23:20:50,397:INFO:Initializing Linear Regression
2023-10-20 23:20:50,397:INFO:Total runtime is 0.0 minutes
2023-10-20 23:20:50,397:INFO:SubProcess create_model() called ==================================
2023-10-20 23:20:50,397:INFO:Initializing create_model()
2023-10-20 23:20:50,397:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:20:50,397:INFO:Checking exceptions
2023-10-20 23:20:50,397:INFO:Importing libraries
2023-10-20 23:20:50,397:INFO:Copying training dataset
2023-10-20 23:20:50,431:INFO:Defining folds
2023-10-20 23:20:50,433:INFO:Declaring metric variables
2023-10-20 23:20:50,433:INFO:Importing untrained model
2023-10-20 23:20:50,433:INFO:Linear Regression Imported successfully
2023-10-20 23:20:50,434:INFO:Starting cross validation
2023-10-20 23:20:50,437:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:20:57,263:INFO:Calculating mean and std
2023-10-20 23:20:57,266:INFO:Creating metrics dataframe
2023-10-20 23:20:57,266:INFO:Uploading results into container
2023-10-20 23:20:57,266:INFO:Uploading model into container now
2023-10-20 23:20:57,266:INFO:_master_model_container: 1
2023-10-20 23:20:57,266:INFO:_display_container: 2
2023-10-20 23:20:57,266:INFO:LinearRegression(n_jobs=-1)
2023-10-20 23:20:57,266:INFO:create_model() successfully completed......................................
2023-10-20 23:20:57,391:INFO:SubProcess create_model() end ==================================
2023-10-20 23:20:57,391:INFO:Creating metrics dataframe
2023-10-20 23:20:57,391:INFO:Initializing Lasso Regression
2023-10-20 23:20:57,391:INFO:Total runtime is 0.11657266219456991 minutes
2023-10-20 23:20:57,391:INFO:SubProcess create_model() called ==================================
2023-10-20 23:20:57,391:INFO:Initializing create_model()
2023-10-20 23:20:57,391:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:20:57,391:INFO:Checking exceptions
2023-10-20 23:20:57,407:INFO:Importing libraries
2023-10-20 23:20:57,407:INFO:Copying training dataset
2023-10-20 23:20:57,430:INFO:Defining folds
2023-10-20 23:20:57,430:INFO:Declaring metric variables
2023-10-20 23:20:57,430:INFO:Importing untrained model
2023-10-20 23:20:57,430:INFO:Lasso Regression Imported successfully
2023-10-20 23:20:57,430:INFO:Starting cross validation
2023-10-20 23:20:57,430:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:20:58,289:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.464e+09, tolerance: 2.904e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:20:58,304:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.457e+09, tolerance: 2.881e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:20:58,336:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.410e+09, tolerance: 2.856e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:20:58,352:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.470e+09, tolerance: 2.933e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:02,475:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.448e+09, tolerance: 2.871e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:02,551:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.427e+09, tolerance: 2.896e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:02,558:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.463e+09, tolerance: 2.927e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:02,573:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.450e+09, tolerance: 2.898e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:02,573:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.456e+09, tolerance: 2.898e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:02,656:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.460e+09, tolerance: 2.900e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:02,804:INFO:Calculating mean and std
2023-10-20 23:21:02,805:INFO:Creating metrics dataframe
2023-10-20 23:21:02,805:INFO:Uploading results into container
2023-10-20 23:21:02,805:INFO:Uploading model into container now
2023-10-20 23:21:02,805:INFO:_master_model_container: 2
2023-10-20 23:21:02,805:INFO:_display_container: 2
2023-10-20 23:21:02,805:INFO:Lasso(random_state=123)
2023-10-20 23:21:02,805:INFO:create_model() successfully completed......................................
2023-10-20 23:21:02,922:INFO:SubProcess create_model() end ==================================
2023-10-20 23:21:02,922:INFO:Creating metrics dataframe
2023-10-20 23:21:02,922:INFO:Initializing Ridge Regression
2023-10-20 23:21:02,922:INFO:Total runtime is 0.20875295797983806 minutes
2023-10-20 23:21:02,922:INFO:SubProcess create_model() called ==================================
2023-10-20 23:21:02,922:INFO:Initializing create_model()
2023-10-20 23:21:02,922:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:21:02,922:INFO:Checking exceptions
2023-10-20 23:21:02,922:INFO:Importing libraries
2023-10-20 23:21:02,922:INFO:Copying training dataset
2023-10-20 23:21:02,955:INFO:Defining folds
2023-10-20 23:21:02,955:INFO:Declaring metric variables
2023-10-20 23:21:02,958:INFO:Importing untrained model
2023-10-20 23:21:02,958:INFO:Ridge Regression Imported successfully
2023-10-20 23:21:02,958:INFO:Starting cross validation
2023-10-20 23:21:02,958:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:21:03,095:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.09042e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:21:03,095:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.08204e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:21:03,096:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.07861e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:21:03,103:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.06296e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:21:03,106:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.05293e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:21:03,122:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.07372e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:21:03,122:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.06625e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:21:03,139:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.06293e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:21:03,156:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.1254e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:21:03,162:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.05971e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:21:03,294:INFO:Calculating mean and std
2023-10-20 23:21:03,296:INFO:Creating metrics dataframe
2023-10-20 23:21:03,300:INFO:Uploading results into container
2023-10-20 23:21:03,301:INFO:Uploading model into container now
2023-10-20 23:21:03,301:INFO:_master_model_container: 3
2023-10-20 23:21:03,302:INFO:_display_container: 2
2023-10-20 23:21:03,302:INFO:Ridge(random_state=123)
2023-10-20 23:21:03,302:INFO:create_model() successfully completed......................................
2023-10-20 23:21:03,402:INFO:SubProcess create_model() end ==================================
2023-10-20 23:21:03,402:INFO:Creating metrics dataframe
2023-10-20 23:21:03,405:INFO:Initializing Elastic Net
2023-10-20 23:21:03,405:INFO:Total runtime is 0.21679709752400717 minutes
2023-10-20 23:21:03,405:INFO:SubProcess create_model() called ==================================
2023-10-20 23:21:03,405:INFO:Initializing create_model()
2023-10-20 23:21:03,405:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:21:03,405:INFO:Checking exceptions
2023-10-20 23:21:03,405:INFO:Importing libraries
2023-10-20 23:21:03,405:INFO:Copying training dataset
2023-10-20 23:21:03,426:INFO:Defining folds
2023-10-20 23:21:03,426:INFO:Declaring metric variables
2023-10-20 23:21:03,426:INFO:Importing untrained model
2023-10-20 23:21:03,426:INFO:Elastic Net Imported successfully
2023-10-20 23:21:03,426:INFO:Starting cross validation
2023-10-20 23:21:03,426:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:21:04,795:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.468e+09, tolerance: 2.871e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:04,795:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.476e+09, tolerance: 2.898e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:04,810:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.448e+09, tolerance: 2.896e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:04,827:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.481e+09, tolerance: 2.900e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:04,880:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.482e+09, tolerance: 2.927e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:04,891:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.470e+09, tolerance: 2.898e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:04,891:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.484e+09, tolerance: 2.904e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:04,907:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.477e+09, tolerance: 2.881e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:04,907:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.431e+09, tolerance: 2.856e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:04,922:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.490e+09, tolerance: 2.933e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:05,068:INFO:Calculating mean and std
2023-10-20 23:21:05,070:INFO:Creating metrics dataframe
2023-10-20 23:21:05,074:INFO:Uploading results into container
2023-10-20 23:21:05,074:INFO:Uploading model into container now
2023-10-20 23:21:05,074:INFO:_master_model_container: 4
2023-10-20 23:21:05,074:INFO:_display_container: 2
2023-10-20 23:21:05,074:INFO:ElasticNet(random_state=123)
2023-10-20 23:21:05,074:INFO:create_model() successfully completed......................................
2023-10-20 23:21:05,168:INFO:SubProcess create_model() end ==================================
2023-10-20 23:21:05,168:INFO:Creating metrics dataframe
2023-10-20 23:21:05,168:INFO:Initializing Least Angle Regression
2023-10-20 23:21:05,168:INFO:Total runtime is 0.24618028004964193 minutes
2023-10-20 23:21:05,168:INFO:SubProcess create_model() called ==================================
2023-10-20 23:21:05,168:INFO:Initializing create_model()
2023-10-20 23:21:05,168:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:21:05,168:INFO:Checking exceptions
2023-10-20 23:21:05,168:INFO:Importing libraries
2023-10-20 23:21:05,168:INFO:Copying training dataset
2023-10-20 23:21:05,192:INFO:Defining folds
2023-10-20 23:21:05,192:INFO:Declaring metric variables
2023-10-20 23:21:05,192:INFO:Importing untrained model
2023-10-20 23:21:05,192:INFO:Least Angle Regression Imported successfully
2023-10-20 23:21:05,192:INFO:Starting cross validation
2023-10-20 23:21:05,207:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:21:05,538:INFO:Calculating mean and std
2023-10-20 23:21:05,538:INFO:Creating metrics dataframe
2023-10-20 23:21:05,538:INFO:Uploading results into container
2023-10-20 23:21:05,538:INFO:Uploading model into container now
2023-10-20 23:21:05,538:INFO:_master_model_container: 5
2023-10-20 23:21:05,538:INFO:_display_container: 2
2023-10-20 23:21:05,538:INFO:Lars(random_state=123)
2023-10-20 23:21:05,538:INFO:create_model() successfully completed......................................
2023-10-20 23:21:05,655:INFO:SubProcess create_model() end ==================================
2023-10-20 23:21:05,661:INFO:Creating metrics dataframe
2023-10-20 23:21:05,661:INFO:Initializing Lasso Least Angle Regression
2023-10-20 23:21:05,661:INFO:Total runtime is 0.25440373420715334 minutes
2023-10-20 23:21:05,661:INFO:SubProcess create_model() called ==================================
2023-10-20 23:21:05,661:INFO:Initializing create_model()
2023-10-20 23:21:05,661:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:21:05,661:INFO:Checking exceptions
2023-10-20 23:21:05,661:INFO:Importing libraries
2023-10-20 23:21:05,661:INFO:Copying training dataset
2023-10-20 23:21:05,690:INFO:Defining folds
2023-10-20 23:21:05,690:INFO:Declaring metric variables
2023-10-20 23:21:05,690:INFO:Importing untrained model
2023-10-20 23:21:05,690:INFO:Lasso Least Angle Regression Imported successfully
2023-10-20 23:21:05,690:INFO:Starting cross validation
2023-10-20 23:21:05,690:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:21:05,833:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=1.588e+02, previous alpha=1.437e+02, with an active set of 14 regressors.
  warnings.warn(

2023-10-20 23:21:05,833:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 26 iterations, alpha=3.480e+01, previous alpha=3.271e+01, with an active set of 17 regressors.
  warnings.warn(

2023-10-20 23:21:05,848:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 26 iterations, alpha=3.393e+01, previous alpha=3.161e+01, with an active set of 17 regressors.
  warnings.warn(

2023-10-20 23:21:05,864:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 35 iterations, alpha=8.305e+00, previous alpha=6.087e+00, with an active set of 26 regressors.
  warnings.warn(

2023-10-20 23:21:05,880:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 29 iterations, alpha=1.570e+01, previous alpha=1.483e+01, with an active set of 20 regressors.
  warnings.warn(

2023-10-20 23:21:05,880:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 31 iterations, alpha=2.233e+01, previous alpha=2.086e+01, with an active set of 18 regressors.
  warnings.warn(

2023-10-20 23:21:05,895:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 26 iterations, alpha=3.158e+01, previous alpha=2.937e+01, with an active set of 17 regressors.
  warnings.warn(

2023-10-20 23:21:05,895:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 32 iterations, alpha=1.675e+01, previous alpha=1.367e+01, with an active set of 23 regressors.
  warnings.warn(

2023-10-20 23:21:05,911:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 31 iterations, alpha=7.665e+00, previous alpha=7.128e+00, with an active set of 22 regressors.
  warnings.warn(

2023-10-20 23:21:06,041:INFO:Calculating mean and std
2023-10-20 23:21:06,041:INFO:Creating metrics dataframe
2023-10-20 23:21:06,041:INFO:Uploading results into container
2023-10-20 23:21:06,041:INFO:Uploading model into container now
2023-10-20 23:21:06,041:INFO:_master_model_container: 6
2023-10-20 23:21:06,041:INFO:_display_container: 2
2023-10-20 23:21:06,041:INFO:LassoLars(random_state=123)
2023-10-20 23:21:06,041:INFO:create_model() successfully completed......................................
2023-10-20 23:21:06,139:INFO:SubProcess create_model() end ==================================
2023-10-20 23:21:06,139:INFO:Creating metrics dataframe
2023-10-20 23:21:06,139:INFO:Initializing Orthogonal Matching Pursuit
2023-10-20 23:21:06,139:INFO:Total runtime is 0.26237805287043253 minutes
2023-10-20 23:21:06,139:INFO:SubProcess create_model() called ==================================
2023-10-20 23:21:06,139:INFO:Initializing create_model()
2023-10-20 23:21:06,139:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:21:06,139:INFO:Checking exceptions
2023-10-20 23:21:06,139:INFO:Importing libraries
2023-10-20 23:21:06,139:INFO:Copying training dataset
2023-10-20 23:21:06,171:INFO:Defining folds
2023-10-20 23:21:06,171:INFO:Declaring metric variables
2023-10-20 23:21:06,171:INFO:Importing untrained model
2023-10-20 23:21:06,171:INFO:Orthogonal Matching Pursuit Imported successfully
2023-10-20 23:21:06,171:INFO:Starting cross validation
2023-10-20 23:21:06,171:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:21:06,467:INFO:Calculating mean and std
2023-10-20 23:21:06,469:INFO:Creating metrics dataframe
2023-10-20 23:21:06,473:INFO:Uploading results into container
2023-10-20 23:21:06,473:INFO:Uploading model into container now
2023-10-20 23:21:06,473:INFO:_master_model_container: 7
2023-10-20 23:21:06,473:INFO:_display_container: 2
2023-10-20 23:21:06,473:INFO:OrthogonalMatchingPursuit()
2023-10-20 23:21:06,473:INFO:create_model() successfully completed......................................
2023-10-20 23:21:06,566:INFO:SubProcess create_model() end ==================================
2023-10-20 23:21:06,566:INFO:Creating metrics dataframe
2023-10-20 23:21:06,573:INFO:Initializing Bayesian Ridge
2023-10-20 23:21:06,573:INFO:Total runtime is 0.26961002747217816 minutes
2023-10-20 23:21:06,573:INFO:SubProcess create_model() called ==================================
2023-10-20 23:21:06,573:INFO:Initializing create_model()
2023-10-20 23:21:06,573:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:21:06,573:INFO:Checking exceptions
2023-10-20 23:21:06,573:INFO:Importing libraries
2023-10-20 23:21:06,573:INFO:Copying training dataset
2023-10-20 23:21:06,589:INFO:Defining folds
2023-10-20 23:21:06,589:INFO:Declaring metric variables
2023-10-20 23:21:06,589:INFO:Importing untrained model
2023-10-20 23:21:06,589:INFO:Bayesian Ridge Imported successfully
2023-10-20 23:21:06,589:INFO:Starting cross validation
2023-10-20 23:21:06,589:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:21:07,152:INFO:Calculating mean and std
2023-10-20 23:21:07,152:INFO:Creating metrics dataframe
2023-10-20 23:21:07,152:INFO:Uploading results into container
2023-10-20 23:21:07,152:INFO:Uploading model into container now
2023-10-20 23:21:07,152:INFO:_master_model_container: 8
2023-10-20 23:21:07,152:INFO:_display_container: 2
2023-10-20 23:21:07,152:INFO:BayesianRidge()
2023-10-20 23:21:07,152:INFO:create_model() successfully completed......................................
2023-10-20 23:21:07,250:INFO:SubProcess create_model() end ==================================
2023-10-20 23:21:07,250:INFO:Creating metrics dataframe
2023-10-20 23:21:07,265:INFO:Initializing Passive Aggressive Regressor
2023-10-20 23:21:07,265:INFO:Total runtime is 0.28113539616266886 minutes
2023-10-20 23:21:07,265:INFO:SubProcess create_model() called ==================================
2023-10-20 23:21:07,265:INFO:Initializing create_model()
2023-10-20 23:21:07,266:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:21:07,266:INFO:Checking exceptions
2023-10-20 23:21:07,266:INFO:Importing libraries
2023-10-20 23:21:07,266:INFO:Copying training dataset
2023-10-20 23:21:07,282:INFO:Defining folds
2023-10-20 23:21:07,282:INFO:Declaring metric variables
2023-10-20 23:21:07,282:INFO:Importing untrained model
2023-10-20 23:21:07,282:INFO:Passive Aggressive Regressor Imported successfully
2023-10-20 23:21:07,282:INFO:Starting cross validation
2023-10-20 23:21:07,282:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:21:07,717:INFO:Calculating mean and std
2023-10-20 23:21:07,717:INFO:Creating metrics dataframe
2023-10-20 23:21:07,717:INFO:Uploading results into container
2023-10-20 23:21:07,717:INFO:Uploading model into container now
2023-10-20 23:21:07,717:INFO:_master_model_container: 9
2023-10-20 23:21:07,717:INFO:_display_container: 2
2023-10-20 23:21:07,717:INFO:PassiveAggressiveRegressor(random_state=123)
2023-10-20 23:21:07,717:INFO:create_model() successfully completed......................................
2023-10-20 23:21:07,816:INFO:SubProcess create_model() end ==================================
2023-10-20 23:21:07,816:INFO:Creating metrics dataframe
2023-10-20 23:21:07,816:INFO:Initializing Huber Regressor
2023-10-20 23:21:07,816:INFO:Total runtime is 0.2903209328651428 minutes
2023-10-20 23:21:07,816:INFO:SubProcess create_model() called ==================================
2023-10-20 23:21:07,816:INFO:Initializing create_model()
2023-10-20 23:21:07,816:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:21:07,816:INFO:Checking exceptions
2023-10-20 23:21:07,816:INFO:Importing libraries
2023-10-20 23:21:07,816:INFO:Copying training dataset
2023-10-20 23:21:07,839:INFO:Defining folds
2023-10-20 23:21:07,839:INFO:Declaring metric variables
2023-10-20 23:21:07,839:INFO:Importing untrained model
2023-10-20 23:21:07,839:INFO:Huber Regressor Imported successfully
2023-10-20 23:21:07,839:INFO:Starting cross validation
2023-10-20 23:21:07,839:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:21:12,211:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:21:12,232:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:21:12,270:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:21:12,270:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:21:12,331:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:21:12,331:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:21:12,358:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:21:12,370:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:21:12,381:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:21:12,448:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:21:12,581:INFO:Calculating mean and std
2023-10-20 23:21:12,581:INFO:Creating metrics dataframe
2023-10-20 23:21:12,581:INFO:Uploading results into container
2023-10-20 23:21:12,581:INFO:Uploading model into container now
2023-10-20 23:21:12,581:INFO:_master_model_container: 10
2023-10-20 23:21:12,581:INFO:_display_container: 2
2023-10-20 23:21:12,581:INFO:HuberRegressor()
2023-10-20 23:21:12,581:INFO:create_model() successfully completed......................................
2023-10-20 23:21:12,681:INFO:SubProcess create_model() end ==================================
2023-10-20 23:21:12,681:INFO:Creating metrics dataframe
2023-10-20 23:21:12,681:INFO:Initializing K Neighbors Regressor
2023-10-20 23:21:12,681:INFO:Total runtime is 0.371399708588918 minutes
2023-10-20 23:21:12,681:INFO:SubProcess create_model() called ==================================
2023-10-20 23:21:12,681:INFO:Initializing create_model()
2023-10-20 23:21:12,681:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:21:12,681:INFO:Checking exceptions
2023-10-20 23:21:12,681:INFO:Importing libraries
2023-10-20 23:21:12,681:INFO:Copying training dataset
2023-10-20 23:21:12,714:INFO:Defining folds
2023-10-20 23:21:12,714:INFO:Declaring metric variables
2023-10-20 23:21:12,714:INFO:Importing untrained model
2023-10-20 23:21:12,714:INFO:K Neighbors Regressor Imported successfully
2023-10-20 23:21:12,714:INFO:Starting cross validation
2023-10-20 23:21:12,714:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:21:13,880:INFO:Calculating mean and std
2023-10-20 23:21:13,880:INFO:Creating metrics dataframe
2023-10-20 23:21:13,880:INFO:Uploading results into container
2023-10-20 23:21:13,880:INFO:Uploading model into container now
2023-10-20 23:21:13,880:INFO:_master_model_container: 11
2023-10-20 23:21:13,880:INFO:_display_container: 2
2023-10-20 23:21:13,880:INFO:KNeighborsRegressor(n_jobs=-1)
2023-10-20 23:21:13,880:INFO:create_model() successfully completed......................................
2023-10-20 23:21:13,996:INFO:SubProcess create_model() end ==================================
2023-10-20 23:21:13,996:INFO:Creating metrics dataframe
2023-10-20 23:21:13,996:INFO:Initializing Decision Tree Regressor
2023-10-20 23:21:14,012:INFO:Total runtime is 0.3933236400286356 minutes
2023-10-20 23:21:14,012:INFO:SubProcess create_model() called ==================================
2023-10-20 23:21:14,012:INFO:Initializing create_model()
2023-10-20 23:21:14,012:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:21:14,012:INFO:Checking exceptions
2023-10-20 23:21:14,012:INFO:Importing libraries
2023-10-20 23:21:14,012:INFO:Copying training dataset
2023-10-20 23:21:14,030:INFO:Defining folds
2023-10-20 23:21:14,030:INFO:Declaring metric variables
2023-10-20 23:21:14,030:INFO:Importing untrained model
2023-10-20 23:21:14,030:INFO:Decision Tree Regressor Imported successfully
2023-10-20 23:21:14,030:INFO:Starting cross validation
2023-10-20 23:21:14,030:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:21:15,273:INFO:Calculating mean and std
2023-10-20 23:21:15,273:INFO:Creating metrics dataframe
2023-10-20 23:21:15,279:INFO:Uploading results into container
2023-10-20 23:21:15,280:INFO:Uploading model into container now
2023-10-20 23:21:15,280:INFO:_master_model_container: 12
2023-10-20 23:21:15,280:INFO:_display_container: 2
2023-10-20 23:21:15,281:INFO:DecisionTreeRegressor(random_state=123)
2023-10-20 23:21:15,281:INFO:create_model() successfully completed......................................
2023-10-20 23:21:15,394:INFO:SubProcess create_model() end ==================================
2023-10-20 23:21:15,394:INFO:Creating metrics dataframe
2023-10-20 23:21:15,400:INFO:Initializing Random Forest Regressor
2023-10-20 23:21:15,400:INFO:Total runtime is 0.416713277498881 minutes
2023-10-20 23:21:15,400:INFO:SubProcess create_model() called ==================================
2023-10-20 23:21:15,400:INFO:Initializing create_model()
2023-10-20 23:21:15,400:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:21:15,400:INFO:Checking exceptions
2023-10-20 23:21:15,400:INFO:Importing libraries
2023-10-20 23:21:15,400:INFO:Copying training dataset
2023-10-20 23:21:15,412:INFO:Defining folds
2023-10-20 23:21:15,412:INFO:Declaring metric variables
2023-10-20 23:21:15,412:INFO:Importing untrained model
2023-10-20 23:21:15,412:INFO:Random Forest Regressor Imported successfully
2023-10-20 23:21:15,412:INFO:Starting cross validation
2023-10-20 23:21:15,428:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:22:07,988:INFO:Calculating mean and std
2023-10-20 23:22:07,988:INFO:Creating metrics dataframe
2023-10-20 23:22:07,988:INFO:Uploading results into container
2023-10-20 23:22:07,988:INFO:Uploading model into container now
2023-10-20 23:22:07,988:INFO:_master_model_container: 13
2023-10-20 23:22:07,988:INFO:_display_container: 2
2023-10-20 23:22:07,988:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-10-20 23:22:07,988:INFO:create_model() successfully completed......................................
2023-10-20 23:22:08,099:INFO:SubProcess create_model() end ==================================
2023-10-20 23:22:08,099:INFO:Creating metrics dataframe
2023-10-20 23:22:08,117:INFO:Initializing Extra Trees Regressor
2023-10-20 23:22:08,117:INFO:Total runtime is 1.295339612166087 minutes
2023-10-20 23:22:08,118:INFO:SubProcess create_model() called ==================================
2023-10-20 23:22:08,118:INFO:Initializing create_model()
2023-10-20 23:22:08,118:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:22:08,118:INFO:Checking exceptions
2023-10-20 23:22:08,118:INFO:Importing libraries
2023-10-20 23:22:08,118:INFO:Copying training dataset
2023-10-20 23:22:08,138:INFO:Defining folds
2023-10-20 23:22:08,138:INFO:Declaring metric variables
2023-10-20 23:22:08,138:INFO:Importing untrained model
2023-10-20 23:22:08,138:INFO:Extra Trees Regressor Imported successfully
2023-10-20 23:22:08,138:INFO:Starting cross validation
2023-10-20 23:22:08,138:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:22:24,238:INFO:Calculating mean and std
2023-10-20 23:22:24,238:INFO:Creating metrics dataframe
2023-10-20 23:22:24,238:INFO:Uploading results into container
2023-10-20 23:22:24,238:INFO:Uploading model into container now
2023-10-20 23:22:24,238:INFO:_master_model_container: 14
2023-10-20 23:22:24,238:INFO:_display_container: 2
2023-10-20 23:22:24,238:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-10-20 23:22:24,238:INFO:create_model() successfully completed......................................
2023-10-20 23:22:24,410:INFO:SubProcess create_model() end ==================================
2023-10-20 23:22:24,410:INFO:Creating metrics dataframe
2023-10-20 23:22:24,421:INFO:Initializing AdaBoost Regressor
2023-10-20 23:22:24,421:INFO:Total runtime is 1.5670756936073305 minutes
2023-10-20 23:22:24,421:INFO:SubProcess create_model() called ==================================
2023-10-20 23:22:24,421:INFO:Initializing create_model()
2023-10-20 23:22:24,421:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:22:24,421:INFO:Checking exceptions
2023-10-20 23:22:24,421:INFO:Importing libraries
2023-10-20 23:22:24,421:INFO:Copying training dataset
2023-10-20 23:22:24,438:INFO:Defining folds
2023-10-20 23:22:24,438:INFO:Declaring metric variables
2023-10-20 23:22:24,438:INFO:Importing untrained model
2023-10-20 23:22:24,438:INFO:AdaBoost Regressor Imported successfully
2023-10-20 23:22:24,438:INFO:Starting cross validation
2023-10-20 23:22:24,453:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:22:31,199:INFO:Calculating mean and std
2023-10-20 23:22:31,199:INFO:Creating metrics dataframe
2023-10-20 23:22:31,199:INFO:Uploading results into container
2023-10-20 23:22:31,199:INFO:Uploading model into container now
2023-10-20 23:22:31,199:INFO:_master_model_container: 15
2023-10-20 23:22:31,199:INFO:_display_container: 2
2023-10-20 23:22:31,199:INFO:AdaBoostRegressor(random_state=123)
2023-10-20 23:22:31,199:INFO:create_model() successfully completed......................................
2023-10-20 23:22:31,299:INFO:SubProcess create_model() end ==================================
2023-10-20 23:22:31,299:INFO:Creating metrics dataframe
2023-10-20 23:22:31,299:INFO:Initializing Gradient Boosting Regressor
2023-10-20 23:22:31,299:INFO:Total runtime is 1.6817017118136088 minutes
2023-10-20 23:22:31,299:INFO:SubProcess create_model() called ==================================
2023-10-20 23:22:31,299:INFO:Initializing create_model()
2023-10-20 23:22:31,299:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:22:31,299:INFO:Checking exceptions
2023-10-20 23:22:31,299:INFO:Importing libraries
2023-10-20 23:22:31,299:INFO:Copying training dataset
2023-10-20 23:22:31,333:INFO:Defining folds
2023-10-20 23:22:31,333:INFO:Declaring metric variables
2023-10-20 23:22:31,333:INFO:Importing untrained model
2023-10-20 23:22:31,333:INFO:Gradient Boosting Regressor Imported successfully
2023-10-20 23:22:31,333:INFO:Starting cross validation
2023-10-20 23:22:31,333:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:22:52,132:INFO:Calculating mean and std
2023-10-20 23:22:52,133:INFO:Creating metrics dataframe
2023-10-20 23:22:52,133:INFO:Uploading results into container
2023-10-20 23:22:52,133:INFO:Uploading model into container now
2023-10-20 23:22:52,133:INFO:_master_model_container: 16
2023-10-20 23:22:52,133:INFO:_display_container: 2
2023-10-20 23:22:52,133:INFO:GradientBoostingRegressor(random_state=123)
2023-10-20 23:22:52,133:INFO:create_model() successfully completed......................................
2023-10-20 23:22:52,232:INFO:SubProcess create_model() end ==================================
2023-10-20 23:22:52,232:INFO:Creating metrics dataframe
2023-10-20 23:22:52,232:INFO:Initializing Light Gradient Boosting Machine
2023-10-20 23:22:52,232:INFO:Total runtime is 2.0305909077326456 minutes
2023-10-20 23:22:52,232:INFO:SubProcess create_model() called ==================================
2023-10-20 23:22:52,232:INFO:Initializing create_model()
2023-10-20 23:22:52,232:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:22:52,232:INFO:Checking exceptions
2023-10-20 23:22:52,232:INFO:Importing libraries
2023-10-20 23:22:52,232:INFO:Copying training dataset
2023-10-20 23:22:52,253:INFO:Defining folds
2023-10-20 23:22:52,253:INFO:Declaring metric variables
2023-10-20 23:22:52,253:INFO:Importing untrained model
2023-10-20 23:22:52,253:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-20 23:22:52,253:INFO:Starting cross validation
2023-10-20 23:22:52,253:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:22:54,847:INFO:Calculating mean and std
2023-10-20 23:22:54,850:INFO:Creating metrics dataframe
2023-10-20 23:22:54,851:INFO:Uploading results into container
2023-10-20 23:22:54,851:INFO:Uploading model into container now
2023-10-20 23:22:54,851:INFO:_master_model_container: 17
2023-10-20 23:22:54,851:INFO:_display_container: 2
2023-10-20 23:22:54,851:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-20 23:22:54,851:INFO:create_model() successfully completed......................................
2023-10-20 23:22:54,953:INFO:SubProcess create_model() end ==================================
2023-10-20 23:22:54,953:INFO:Creating metrics dataframe
2023-10-20 23:22:54,962:INFO:Initializing CatBoost Regressor
2023-10-20 23:22:54,962:INFO:Total runtime is 2.076080063978831 minutes
2023-10-20 23:22:54,962:INFO:SubProcess create_model() called ==================================
2023-10-20 23:22:54,963:INFO:Initializing create_model()
2023-10-20 23:22:54,963:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:22:54,963:INFO:Checking exceptions
2023-10-20 23:22:54,963:INFO:Importing libraries
2023-10-20 23:22:54,963:INFO:Copying training dataset
2023-10-20 23:22:54,979:INFO:Defining folds
2023-10-20 23:22:54,979:INFO:Declaring metric variables
2023-10-20 23:22:54,979:INFO:Importing untrained model
2023-10-20 23:22:54,979:INFO:CatBoost Regressor Imported successfully
2023-10-20 23:22:54,979:INFO:Starting cross validation
2023-10-20 23:22:54,979:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:23:28,367:INFO:Calculating mean and std
2023-10-20 23:23:28,368:INFO:Creating metrics dataframe
2023-10-20 23:23:28,368:INFO:Uploading results into container
2023-10-20 23:23:28,368:INFO:Uploading model into container now
2023-10-20 23:23:28,368:INFO:_master_model_container: 18
2023-10-20 23:23:28,368:INFO:_display_container: 2
2023-10-20 23:23:28,368:INFO:<catboost.core.CatBoostRegressor object at 0x00000209E3906F40>
2023-10-20 23:23:28,368:INFO:create_model() successfully completed......................................
2023-10-20 23:23:28,485:INFO:SubProcess create_model() end ==================================
2023-10-20 23:23:28,485:INFO:Creating metrics dataframe
2023-10-20 23:23:28,502:INFO:Initializing Dummy Regressor
2023-10-20 23:23:28,502:INFO:Total runtime is 2.6350830396016436 minutes
2023-10-20 23:23:28,502:INFO:SubProcess create_model() called ==================================
2023-10-20 23:23:28,502:INFO:Initializing create_model()
2023-10-20 23:23:28,502:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:23:28,502:INFO:Checking exceptions
2023-10-20 23:23:28,502:INFO:Importing libraries
2023-10-20 23:23:28,502:INFO:Copying training dataset
2023-10-20 23:23:28,519:INFO:Defining folds
2023-10-20 23:23:28,519:INFO:Declaring metric variables
2023-10-20 23:23:28,519:INFO:Importing untrained model
2023-10-20 23:23:28,534:INFO:Dummy Regressor Imported successfully
2023-10-20 23:23:28,535:INFO:Starting cross validation
2023-10-20 23:23:28,535:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:23:28,834:INFO:Calculating mean and std
2023-10-20 23:23:28,834:INFO:Creating metrics dataframe
2023-10-20 23:23:28,834:INFO:Uploading results into container
2023-10-20 23:23:28,834:INFO:Uploading model into container now
2023-10-20 23:23:28,834:INFO:_master_model_container: 19
2023-10-20 23:23:28,834:INFO:_display_container: 2
2023-10-20 23:23:28,834:INFO:DummyRegressor()
2023-10-20 23:23:28,834:INFO:create_model() successfully completed......................................
2023-10-20 23:23:28,951:INFO:SubProcess create_model() end ==================================
2023-10-20 23:23:28,951:INFO:Creating metrics dataframe
2023-10-20 23:23:28,951:INFO:Initializing create_model()
2023-10-20 23:23:28,951:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=<catboost.core.CatBoostRegressor object at 0x00000209E3906F40>, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:23:28,951:INFO:Checking exceptions
2023-10-20 23:23:28,968:INFO:Importing libraries
2023-10-20 23:23:28,968:INFO:Copying training dataset
2023-10-20 23:23:28,985:INFO:Defining folds
2023-10-20 23:23:28,985:INFO:Declaring metric variables
2023-10-20 23:23:28,985:INFO:Importing untrained model
2023-10-20 23:23:28,985:INFO:Declaring custom model
2023-10-20 23:23:28,985:INFO:CatBoost Regressor Imported successfully
2023-10-20 23:23:28,985:INFO:Cross validation set to False
2023-10-20 23:23:28,985:INFO:Fitting Model
2023-10-20 23:23:35,896:INFO:<catboost.core.CatBoostRegressor object at 0x00000209E3BDBC70>
2023-10-20 23:23:35,896:INFO:create_model() successfully completed......................................
2023-10-20 23:23:35,996:INFO:Creating Dashboard logs
2023-10-20 23:23:35,996:INFO:Model: CatBoost Regressor
2023-10-20 23:23:36,062:INFO:Logged params: {'nan_mode': 'Min', 'eval_metric': 'RMSE', 'iterations': 1000, 'sampling_frequency': 'PerTree', 'leaf_estimation_method': 'Newton', 'random_score_type': 'NormalWithModelSizeDecrease', 'grow_policy': 'SymmetricTree', 'penalties_coefficient': 1, 'boosting_type': 'Plain', 'model_shrink_mode': 'Constant', 'feature_border_type': 'GreedyLogSum', 'bayesian_matrix_reg': 0.10000000149011612, 'eval_fraction': 0, 'force_unit_auto_pair_weights': False, 'l2_leaf_reg': 3, 'random_strength': 1, 'rsm': 1, 'boost_from_average': True, 'model_size_reg': 0.5, 'pool_metainfo_options': {'tags': {}}, 'subsample': 0.800000011920929, 'use_best_model': False, 'random_seed': 123, 'depth': 6, 'posterior_sampling': False, 'border_count': 254, 'classes_count': 0, 'auto_class_weights': 'None', 'sparse_features_conflict_fraction': 0, 'leaf_estimation_backtracking': 'AnyImprovement', 'best_model_min_trees': 1, 'model_shrink_rate': 0, 'min_data_in_leaf': 1, 'loss_function': 'RMSE', 'learning_rate': 0.06757699698209763, 'score_function': 'Cosine', 'task_type': 'CPU', 'leaf_estimation_iterations': 1, 'bootstrap_type': 'MVS', 'max_leaves': 64}
2023-10-20 23:23:36,362:INFO:Initializing predict_model()
2023-10-20 23:23:36,362:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=<catboost.core.CatBoostRegressor object at 0x00000209E3BDBC70>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209E3CC7820>)
2023-10-20 23:23:36,362:INFO:Checking exceptions
2023-10-20 23:23:36,362:INFO:Preloading libraries
2023-10-20 23:23:36,595:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\_distutils_hack\__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2023-10-20 23:23:36,779:INFO:Creating Dashboard logs
2023-10-20 23:23:36,779:INFO:Model: Light Gradient Boosting Machine
2023-10-20 23:23:36,851:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-20 23:23:37,194:INFO:Creating Dashboard logs
2023-10-20 23:23:37,194:INFO:Model: Extra Trees Regressor
2023-10-20 23:23:37,244:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-20 23:23:37,582:INFO:Creating Dashboard logs
2023-10-20 23:23:37,582:INFO:Model: Random Forest Regressor
2023-10-20 23:23:37,645:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-20 23:23:37,960:INFO:Creating Dashboard logs
2023-10-20 23:23:37,960:INFO:Model: Gradient Boosting Regressor
2023-10-20 23:23:38,027:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 123, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-10-20 23:23:38,377:INFO:Creating Dashboard logs
2023-10-20 23:23:38,377:INFO:Model: Ridge Regression
2023-10-20 23:23:38,448:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 123, 'solver': 'auto', 'tol': 0.0001}
2023-10-20 23:23:38,727:INFO:Creating Dashboard logs
2023-10-20 23:23:38,727:INFO:Model: Lasso Regression
2023-10-20 23:23:38,793:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 123, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-10-20 23:23:39,084:INFO:Creating Dashboard logs
2023-10-20 23:23:39,084:INFO:Model: Elastic Net
2023-10-20 23:23:39,143:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 123, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-10-20 23:23:39,426:INFO:Creating Dashboard logs
2023-10-20 23:23:39,426:INFO:Model: Lasso Least Angle Regression
2023-10-20 23:23:39,477:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'max_iter': 500, 'normalize': 'deprecated', 'positive': False, 'precompute': 'auto', 'random_state': 123, 'verbose': False}
2023-10-20 23:23:39,776:INFO:Creating Dashboard logs
2023-10-20 23:23:39,776:INFO:Model: Linear Regression
2023-10-20 23:23:39,842:INFO:Logged params: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'positive': False}
2023-10-20 23:23:40,125:INFO:Creating Dashboard logs
2023-10-20 23:23:40,125:INFO:Model: AdaBoost Regressor
2023-10-20 23:23:40,192:INFO:Logged params: {'base_estimator': 'deprecated', 'estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': 123}
2023-10-20 23:23:40,492:INFO:Creating Dashboard logs
2023-10-20 23:23:40,492:INFO:Model: Orthogonal Matching Pursuit
2023-10-20 23:23:40,542:INFO:Logged params: {'fit_intercept': True, 'n_nonzero_coefs': None, 'normalize': 'deprecated', 'precompute': 'auto', 'tol': None}
2023-10-20 23:23:40,809:INFO:Creating Dashboard logs
2023-10-20 23:23:40,809:INFO:Model: Huber Regressor
2023-10-20 23:23:40,875:INFO:Logged params: {'alpha': 0.0001, 'epsilon': 1.35, 'fit_intercept': True, 'max_iter': 100, 'tol': 1e-05, 'warm_start': False}
2023-10-20 23:23:41,158:INFO:Creating Dashboard logs
2023-10-20 23:23:41,158:INFO:Model: Decision Tree Regressor
2023-10-20 23:23:41,226:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 123, 'splitter': 'best'}
2023-10-20 23:23:41,507:INFO:Creating Dashboard logs
2023-10-20 23:23:41,507:INFO:Model: K Neighbors Regressor
2023-10-20 23:23:41,574:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2023-10-20 23:23:41,858:INFO:Creating Dashboard logs
2023-10-20 23:23:41,858:INFO:Model: Dummy Regressor
2023-10-20 23:23:41,924:INFO:Logged params: {'constant': None, 'quantile': None, 'strategy': 'mean'}
2023-10-20 23:23:42,224:INFO:Creating Dashboard logs
2023-10-20 23:23:42,224:INFO:Model: Passive Aggressive Regressor
2023-10-20 23:23:42,274:INFO:Logged params: {'C': 1.0, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'fit_intercept': True, 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 5, 'random_state': 123, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-10-20 23:23:42,557:INFO:Creating Dashboard logs
2023-10-20 23:23:42,557:INFO:Model: Bayesian Ridge
2023-10-20 23:23:42,623:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'tol': 0.001, 'verbose': False}
2023-10-20 23:23:42,906:INFO:Creating Dashboard logs
2023-10-20 23:23:42,906:INFO:Model: Least Angle Regression
2023-10-20 23:23:42,973:INFO:Logged params: {'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'n_nonzero_coefs': 500, 'normalize': 'deprecated', 'precompute': 'auto', 'random_state': 123, 'verbose': False}
2023-10-20 23:23:43,272:INFO:_master_model_container: 19
2023-10-20 23:23:43,272:INFO:_display_container: 2
2023-10-20 23:23:43,273:INFO:<catboost.core.CatBoostRegressor object at 0x00000209E3BDBC70>
2023-10-20 23:23:43,273:INFO:compare_models() successfully completed......................................
2023-10-20 23:29:24,017:INFO:PyCaret RegressionExperiment
2023-10-20 23:29:24,019:INFO:Logging name: exp_A
2023-10-20 23:29:24,019:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-20 23:29:24,020:INFO:version 3.1.0
2023-10-20 23:29:24,020:INFO:Initializing setup()
2023-10-20 23:29:24,020:INFO:self.USI: f486
2023-10-20 23:29:24,020:INFO:self._variable_keys: {'transform_target_param', 'exp_name_log', 'y_train', 'logging_param', 'n_jobs_param', 'X_train', 'target_param', 'USI', 'gpu_n_jobs_param', 'fold_groups_param', '_ml_usecase', 'seed', 'fold_generator', 'idx', 'html_param', 'log_plots_param', 'y', 'gpu_param', 'X_test', 'memory', 'y_test', 'data', 'X', 'exp_id', '_available_plots', 'fold_shuffle_param', 'pipeline'}
2023-10-20 23:29:24,020:INFO:Checking environment
2023-10-20 23:29:24,021:INFO:python_version: 3.8.18
2023-10-20 23:29:24,021:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-20 23:29:24,021:INFO:machine: AMD64
2023-10-20 23:29:24,022:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-20 23:29:24,022:INFO:Memory: svmem(total=16505954304, available=2596114432, percent=84.3, used=13909839872, free=2596114432)
2023-10-20 23:29:24,022:INFO:Physical Core: 8
2023-10-20 23:29:24,022:INFO:Logical Core: 16
2023-10-20 23:29:24,023:INFO:Checking libraries
2023-10-20 23:29:24,023:INFO:System:
2023-10-20 23:29:24,023:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-20 23:29:24,023:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-20 23:29:24,023:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-20 23:29:24,023:INFO:PyCaret required dependencies:
2023-10-20 23:29:24,023:INFO:                 pip: 23.3
2023-10-20 23:29:24,023:INFO:          setuptools: 68.0.0
2023-10-20 23:29:24,023:INFO:             pycaret: 3.1.0
2023-10-20 23:29:24,023:INFO:             IPython: 8.12.0
2023-10-20 23:29:24,023:INFO:          ipywidgets: 8.1.1
2023-10-20 23:29:24,023:INFO:                tqdm: 4.66.1
2023-10-20 23:29:24,024:INFO:               numpy: 1.23.5
2023-10-20 23:29:24,024:INFO:              pandas: 1.5.3
2023-10-20 23:29:24,024:INFO:              jinja2: 3.1.2
2023-10-20 23:29:24,024:INFO:               scipy: 1.10.1
2023-10-20 23:29:24,024:INFO:              joblib: 1.3.2
2023-10-20 23:29:24,024:INFO:             sklearn: 1.2.2
2023-10-20 23:29:24,024:INFO:                pyod: 1.1.0
2023-10-20 23:29:24,024:INFO:            imblearn: 0.11.0
2023-10-20 23:29:24,024:INFO:   category_encoders: 2.6.2
2023-10-20 23:29:24,024:INFO:            lightgbm: 4.1.0
2023-10-20 23:29:24,024:INFO:               numba: 0.58.1
2023-10-20 23:29:24,024:INFO:            requests: 2.31.0
2023-10-20 23:29:24,024:INFO:          matplotlib: 3.7.3
2023-10-20 23:29:24,024:INFO:          scikitplot: 0.3.7
2023-10-20 23:29:24,024:INFO:         yellowbrick: 1.5
2023-10-20 23:29:24,024:INFO:              plotly: 5.17.0
2023-10-20 23:29:24,024:INFO:    plotly-resampler: Not installed
2023-10-20 23:29:24,025:INFO:             kaleido: 0.2.1
2023-10-20 23:29:24,025:INFO:           schemdraw: 0.15
2023-10-20 23:29:24,025:INFO:         statsmodels: 0.14.0
2023-10-20 23:29:24,025:INFO:              sktime: 0.21.1
2023-10-20 23:29:24,025:INFO:               tbats: 1.1.3
2023-10-20 23:29:24,025:INFO:            pmdarima: 2.0.3
2023-10-20 23:29:24,025:INFO:              psutil: 5.9.0
2023-10-20 23:29:24,025:INFO:          markupsafe: 2.1.3
2023-10-20 23:29:24,025:INFO:             pickle5: Not installed
2023-10-20 23:29:24,025:INFO:         cloudpickle: 2.2.1
2023-10-20 23:29:24,025:INFO:         deprecation: 2.1.0
2023-10-20 23:29:24,025:INFO:              xxhash: 3.4.1
2023-10-20 23:29:24,025:INFO:           wurlitzer: Not installed
2023-10-20 23:29:24,025:INFO:PyCaret optional dependencies:
2023-10-20 23:29:24,025:INFO:                shap: Not installed
2023-10-20 23:29:24,026:INFO:           interpret: Not installed
2023-10-20 23:29:24,026:INFO:                umap: Not installed
2023-10-20 23:29:24,026:INFO:     ydata_profiling: Not installed
2023-10-20 23:29:24,026:INFO:  explainerdashboard: Not installed
2023-10-20 23:29:24,026:INFO:             autoviz: Not installed
2023-10-20 23:29:24,026:INFO:           fairlearn: Not installed
2023-10-20 23:29:24,026:INFO:          deepchecks: Not installed
2023-10-20 23:29:24,026:INFO:             xgboost: Not installed
2023-10-20 23:29:24,026:INFO:            catboost: 1.2.2
2023-10-20 23:29:24,026:INFO:              kmodes: Not installed
2023-10-20 23:29:24,026:INFO:             mlxtend: Not installed
2023-10-20 23:29:24,026:INFO:       statsforecast: Not installed
2023-10-20 23:29:24,026:INFO:        tune_sklearn: Not installed
2023-10-20 23:29:24,026:INFO:                 ray: Not installed
2023-10-20 23:29:24,026:INFO:            hyperopt: Not installed
2023-10-20 23:29:24,026:INFO:              optuna: Not installed
2023-10-20 23:29:24,027:INFO:               skopt: Not installed
2023-10-20 23:29:24,027:INFO:              mlflow: 2.7.1
2023-10-20 23:29:24,027:INFO:              gradio: Not installed
2023-10-20 23:29:24,027:INFO:             fastapi: Not installed
2023-10-20 23:29:24,027:INFO:             uvicorn: Not installed
2023-10-20 23:29:24,027:INFO:              m2cgen: Not installed
2023-10-20 23:29:24,027:INFO:           evidently: Not installed
2023-10-20 23:29:24,027:INFO:               fugue: Not installed
2023-10-20 23:29:24,027:INFO:           streamlit: Not installed
2023-10-20 23:29:24,027:INFO:             prophet: Not installed
2023-10-20 23:29:24,027:INFO:None
2023-10-20 23:29:24,027:INFO:Set up data.
2023-10-20 23:29:24,057:INFO:Set up folding strategy.
2023-10-20 23:29:24,057:INFO:Set up train/test split.
2023-10-20 23:29:24,081:INFO:Set up index.
2023-10-20 23:29:24,082:INFO:Assigning column types.
2023-10-20 23:29:24,100:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-20 23:29:24,100:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,107:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,107:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,190:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,241:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,242:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:29:24,242:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:29:24,243:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,248:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,253:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,325:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,383:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,385:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:29:24,385:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:29:24,385:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-20 23:29:24,391:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,396:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,475:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,529:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,529:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:29:24,529:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:29:24,535:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,541:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,626:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,676:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,677:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:29:24,677:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:29:24,678:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-20 23:29:24,680:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,772:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,824:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,824:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:29:24,824:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:29:24,824:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,919:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,962:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,962:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:29:24,962:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:29:24,962:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-20 23:29:25,079:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:29:25,126:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:29:25,126:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:29:25,126:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:29:25,213:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:29:25,257:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:29:25,257:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:29:25,257:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:29:25,257:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-20 23:29:25,341:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:29:25,400:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:29:25,400:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:29:25,474:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:29:25,527:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:29:25,527:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:29:25,527:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-20 23:29:25,656:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:29:25,656:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:29:25,806:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:29:25,806:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:29:25,806:INFO:Preparing preprocessing pipeline...
2023-10-20 23:29:25,806:INFO:Set up simple imputation.
2023-10-20 23:29:25,806:INFO:Set up column name cleaning.
2023-10-20 23:29:25,859:INFO:Finished creating preprocessing pipeline.
2023-10-20 23:29:25,875:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-20 23:29:25,875:INFO:Creating final display dataframe.
2023-10-20 23:29:26,062:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (34061, 39)
4        Transformed data shape   (34061, 39)
5   Transformed train set shape   (23842, 39)
6    Transformed test set shape   (10219, 39)
7              Numeric features            38
8      Rows with missing values         23.1%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_A
19                          USI          f486
2023-10-20 23:29:26,191:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:29:26,191:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:29:26,340:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:29:26,340:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:29:26,341:INFO:Logging experiment in loggers
2023-10-20 23:29:26,442:INFO:SubProcess save_model() called ==================================
2023-10-20 23:29:26,445:INFO:Initializing save_model()
2023-10-20 23:29:26,445:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmplzngiykf\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-20 23:29:26,445:INFO:Adding model into prep_pipe
2023-10-20 23:29:26,445:WARNING:Only Model saved as it was a pipeline.
2023-10-20 23:29:26,445:INFO:C:\Users\thoma\AppData\Local\Temp\tmplzngiykf\Transformation Pipeline.pkl saved in current working directory
2023-10-20 23:29:26,460:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-20 23:29:26,460:INFO:save_model() successfully completed......................................
2023-10-20 23:29:26,572:INFO:SubProcess save_model() end ==================================
2023-10-20 23:29:26,612:INFO:setup() successfully completed in 2.33s...............
2023-10-20 23:29:26,612:INFO:Initializing compare_models()
2023-10-20 23:29:26,612:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, 'include': None, 'exclude': ['ransac'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=['ransac'])
2023-10-20 23:29:26,612:INFO:Checking exceptions
2023-10-20 23:29:26,630:INFO:Preparing display monitor
2023-10-20 23:29:26,634:INFO:Initializing Linear Regression
2023-10-20 23:29:26,634:INFO:Total runtime is 0.0 minutes
2023-10-20 23:29:26,635:INFO:SubProcess create_model() called ==================================
2023-10-20 23:29:26,635:INFO:Initializing create_model()
2023-10-20 23:29:26,635:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:29:26,635:INFO:Checking exceptions
2023-10-20 23:29:26,635:INFO:Importing libraries
2023-10-20 23:29:26,635:INFO:Copying training dataset
2023-10-20 23:29:26,657:INFO:Defining folds
2023-10-20 23:29:26,657:INFO:Declaring metric variables
2023-10-20 23:29:26,657:INFO:Importing untrained model
2023-10-20 23:29:26,658:INFO:Linear Regression Imported successfully
2023-10-20 23:29:26,658:INFO:Starting cross validation
2023-10-20 23:29:26,659:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:29:28,951:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\joblib\externals\loky\process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(

2023-10-20 23:29:31,883:INFO:Calculating mean and std
2023-10-20 23:29:31,883:INFO:Creating metrics dataframe
2023-10-20 23:29:31,883:INFO:Uploading results into container
2023-10-20 23:29:31,883:INFO:Uploading model into container now
2023-10-20 23:29:31,883:INFO:_master_model_container: 1
2023-10-20 23:29:31,883:INFO:_display_container: 2
2023-10-20 23:29:31,883:INFO:LinearRegression(n_jobs=-1)
2023-10-20 23:29:31,883:INFO:create_model() successfully completed......................................
2023-10-20 23:29:31,985:INFO:SubProcess create_model() end ==================================
2023-10-20 23:29:31,985:INFO:Creating metrics dataframe
2023-10-20 23:29:31,985:INFO:Initializing Lasso Regression
2023-10-20 23:29:31,985:INFO:Total runtime is 0.08918093045552572 minutes
2023-10-20 23:29:32,000:INFO:SubProcess create_model() called ==================================
2023-10-20 23:29:32,000:INFO:Initializing create_model()
2023-10-20 23:29:32,000:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:29:32,000:INFO:Checking exceptions
2023-10-20 23:29:32,000:INFO:Importing libraries
2023-10-20 23:29:32,000:INFO:Copying training dataset
2023-10-20 23:29:32,022:INFO:Defining folds
2023-10-20 23:29:32,022:INFO:Declaring metric variables
2023-10-20 23:29:32,022:INFO:Importing untrained model
2023-10-20 23:29:32,022:INFO:Lasso Regression Imported successfully
2023-10-20 23:29:32,022:INFO:Starting cross validation
2023-10-20 23:29:32,022:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:29:32,688:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.427e+09, tolerance: 2.896e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:37,881:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.463e+09, tolerance: 2.927e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:37,894:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.464e+09, tolerance: 2.904e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:37,997:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.457e+09, tolerance: 2.881e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:38,014:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.460e+09, tolerance: 2.900e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:38,014:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.450e+09, tolerance: 2.898e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:38,030:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.448e+09, tolerance: 2.871e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:38,030:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.410e+09, tolerance: 2.856e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:38,046:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.470e+09, tolerance: 2.933e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:38,046:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.456e+09, tolerance: 2.898e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:38,180:INFO:Calculating mean and std
2023-10-20 23:29:38,181:INFO:Creating metrics dataframe
2023-10-20 23:29:38,183:INFO:Uploading results into container
2023-10-20 23:29:38,183:INFO:Uploading model into container now
2023-10-20 23:29:38,183:INFO:_master_model_container: 2
2023-10-20 23:29:38,183:INFO:_display_container: 2
2023-10-20 23:29:38,183:INFO:Lasso(random_state=123)
2023-10-20 23:29:38,183:INFO:create_model() successfully completed......................................
2023-10-20 23:29:38,284:INFO:SubProcess create_model() end ==================================
2023-10-20 23:29:38,284:INFO:Creating metrics dataframe
2023-10-20 23:29:38,296:INFO:Initializing Ridge Regression
2023-10-20 23:29:38,296:INFO:Total runtime is 0.19436156749725342 minutes
2023-10-20 23:29:38,296:INFO:SubProcess create_model() called ==================================
2023-10-20 23:29:38,297:INFO:Initializing create_model()
2023-10-20 23:29:38,297:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:29:38,297:INFO:Checking exceptions
2023-10-20 23:29:38,297:INFO:Importing libraries
2023-10-20 23:29:38,297:INFO:Copying training dataset
2023-10-20 23:29:38,315:INFO:Defining folds
2023-10-20 23:29:38,315:INFO:Declaring metric variables
2023-10-20 23:29:38,315:INFO:Importing untrained model
2023-10-20 23:29:38,315:INFO:Ridge Regression Imported successfully
2023-10-20 23:29:38,315:INFO:Starting cross validation
2023-10-20 23:29:38,315:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:29:38,454:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.06625e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:29:38,470:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.06293e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:29:38,470:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.1254e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:29:38,470:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.05971e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:29:41,802:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.06296e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:29:41,821:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.07861e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:29:41,826:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.09042e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:29:41,827:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.05293e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:29:41,831:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.07372e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:29:41,834:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.08204e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:29:41,977:INFO:Calculating mean and std
2023-10-20 23:29:41,977:INFO:Creating metrics dataframe
2023-10-20 23:29:41,977:INFO:Uploading results into container
2023-10-20 23:29:41,977:INFO:Uploading model into container now
2023-10-20 23:29:41,977:INFO:_master_model_container: 3
2023-10-20 23:29:41,977:INFO:_display_container: 2
2023-10-20 23:29:41,977:INFO:Ridge(random_state=123)
2023-10-20 23:29:41,977:INFO:create_model() successfully completed......................................
2023-10-20 23:29:42,093:INFO:SubProcess create_model() end ==================================
2023-10-20 23:29:42,093:INFO:Creating metrics dataframe
2023-10-20 23:29:42,096:INFO:Initializing Elastic Net
2023-10-20 23:29:42,096:INFO:Total runtime is 0.257698396841685 minutes
2023-10-20 23:29:42,096:INFO:SubProcess create_model() called ==================================
2023-10-20 23:29:42,096:INFO:Initializing create_model()
2023-10-20 23:29:42,096:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:29:42,096:INFO:Checking exceptions
2023-10-20 23:29:42,096:INFO:Importing libraries
2023-10-20 23:29:42,096:INFO:Copying training dataset
2023-10-20 23:29:42,117:INFO:Defining folds
2023-10-20 23:29:42,117:INFO:Declaring metric variables
2023-10-20 23:29:42,117:INFO:Importing untrained model
2023-10-20 23:29:42,117:INFO:Elastic Net Imported successfully
2023-10-20 23:29:42,117:INFO:Starting cross validation
2023-10-20 23:29:42,117:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:29:43,444:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.468e+09, tolerance: 2.871e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:43,544:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.484e+09, tolerance: 2.904e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:43,560:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.448e+09, tolerance: 2.896e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:43,560:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.477e+09, tolerance: 2.881e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:43,585:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.470e+09, tolerance: 2.898e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:43,593:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.482e+09, tolerance: 2.927e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:43,593:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.476e+09, tolerance: 2.898e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:43,593:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.481e+09, tolerance: 2.900e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:43,613:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.490e+09, tolerance: 2.933e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:43,631:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.431e+09, tolerance: 2.856e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:43,758:INFO:Calculating mean and std
2023-10-20 23:29:43,758:INFO:Creating metrics dataframe
2023-10-20 23:29:43,758:INFO:Uploading results into container
2023-10-20 23:29:43,758:INFO:Uploading model into container now
2023-10-20 23:29:43,758:INFO:_master_model_container: 4
2023-10-20 23:29:43,758:INFO:_display_container: 2
2023-10-20 23:29:43,758:INFO:ElasticNet(random_state=123)
2023-10-20 23:29:43,758:INFO:create_model() successfully completed......................................
2023-10-20 23:29:43,858:INFO:SubProcess create_model() end ==================================
2023-10-20 23:29:43,858:INFO:Creating metrics dataframe
2023-10-20 23:29:43,875:INFO:Initializing Least Angle Regression
2023-10-20 23:29:43,875:INFO:Total runtime is 0.2873404979705811 minutes
2023-10-20 23:29:43,875:INFO:SubProcess create_model() called ==================================
2023-10-20 23:29:43,875:INFO:Initializing create_model()
2023-10-20 23:29:43,875:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:29:43,875:INFO:Checking exceptions
2023-10-20 23:29:43,875:INFO:Importing libraries
2023-10-20 23:29:43,875:INFO:Copying training dataset
2023-10-20 23:29:43,891:INFO:Defining folds
2023-10-20 23:29:43,891:INFO:Declaring metric variables
2023-10-20 23:29:43,891:INFO:Importing untrained model
2023-10-20 23:29:43,891:INFO:Least Angle Regression Imported successfully
2023-10-20 23:29:43,891:INFO:Starting cross validation
2023-10-20 23:29:43,891:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:29:44,227:INFO:Calculating mean and std
2023-10-20 23:29:44,227:INFO:Creating metrics dataframe
2023-10-20 23:29:44,227:INFO:Uploading results into container
2023-10-20 23:29:44,227:INFO:Uploading model into container now
2023-10-20 23:29:44,227:INFO:_master_model_container: 5
2023-10-20 23:29:44,227:INFO:_display_container: 2
2023-10-20 23:29:44,227:INFO:Lars(random_state=123)
2023-10-20 23:29:44,227:INFO:create_model() successfully completed......................................
2023-10-20 23:29:44,341:INFO:SubProcess create_model() end ==================================
2023-10-20 23:29:44,341:INFO:Creating metrics dataframe
2023-10-20 23:29:44,341:INFO:Initializing Lasso Least Angle Regression
2023-10-20 23:29:44,341:INFO:Total runtime is 0.2951181729634603 minutes
2023-10-20 23:29:44,341:INFO:SubProcess create_model() called ==================================
2023-10-20 23:29:44,341:INFO:Initializing create_model()
2023-10-20 23:29:44,341:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:29:44,341:INFO:Checking exceptions
2023-10-20 23:29:44,341:INFO:Importing libraries
2023-10-20 23:29:44,341:INFO:Copying training dataset
2023-10-20 23:29:44,358:INFO:Defining folds
2023-10-20 23:29:44,358:INFO:Declaring metric variables
2023-10-20 23:29:44,358:INFO:Importing untrained model
2023-10-20 23:29:44,358:INFO:Lasso Least Angle Regression Imported successfully
2023-10-20 23:29:44,358:INFO:Starting cross validation
2023-10-20 23:29:44,374:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:29:44,491:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=1.588e+02, previous alpha=1.437e+02, with an active set of 14 regressors.
  warnings.warn(

2023-10-20 23:29:44,491:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 26 iterations, alpha=3.480e+01, previous alpha=3.271e+01, with an active set of 17 regressors.
  warnings.warn(

2023-10-20 23:29:44,507:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 35 iterations, alpha=8.305e+00, previous alpha=6.087e+00, with an active set of 26 regressors.
  warnings.warn(

2023-10-20 23:29:44,508:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 26 iterations, alpha=3.393e+01, previous alpha=3.161e+01, with an active set of 17 regressors.
  warnings.warn(

2023-10-20 23:29:44,508:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 29 iterations, alpha=1.570e+01, previous alpha=1.483e+01, with an active set of 20 regressors.
  warnings.warn(

2023-10-20 23:29:44,525:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 31 iterations, alpha=2.233e+01, previous alpha=2.086e+01, with an active set of 18 regressors.
  warnings.warn(

2023-10-20 23:29:44,541:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 26 iterations, alpha=3.158e+01, previous alpha=2.937e+01, with an active set of 17 regressors.
  warnings.warn(

2023-10-20 23:29:44,547:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 32 iterations, alpha=1.675e+01, previous alpha=1.367e+01, with an active set of 23 regressors.
  warnings.warn(

2023-10-20 23:29:44,557:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 31 iterations, alpha=7.665e+00, previous alpha=7.128e+00, with an active set of 22 regressors.
  warnings.warn(

2023-10-20 23:29:44,690:INFO:Calculating mean and std
2023-10-20 23:29:44,690:INFO:Creating metrics dataframe
2023-10-20 23:29:44,690:INFO:Uploading results into container
2023-10-20 23:29:44,690:INFO:Uploading model into container now
2023-10-20 23:29:44,690:INFO:_master_model_container: 6
2023-10-20 23:29:44,690:INFO:_display_container: 2
2023-10-20 23:29:44,690:INFO:LassoLars(random_state=123)
2023-10-20 23:29:44,690:INFO:create_model() successfully completed......................................
2023-10-20 23:29:44,807:INFO:SubProcess create_model() end ==================================
2023-10-20 23:29:44,807:INFO:Creating metrics dataframe
2023-10-20 23:29:44,807:INFO:Initializing Orthogonal Matching Pursuit
2023-10-20 23:29:44,807:INFO:Total runtime is 0.3028773665428162 minutes
2023-10-20 23:29:44,807:INFO:SubProcess create_model() called ==================================
2023-10-20 23:29:44,807:INFO:Initializing create_model()
2023-10-20 23:29:44,807:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:29:44,807:INFO:Checking exceptions
2023-10-20 23:29:44,807:INFO:Importing libraries
2023-10-20 23:29:44,807:INFO:Copying training dataset
2023-10-20 23:29:44,824:INFO:Defining folds
2023-10-20 23:29:44,824:INFO:Declaring metric variables
2023-10-20 23:29:44,824:INFO:Importing untrained model
2023-10-20 23:29:44,824:INFO:Orthogonal Matching Pursuit Imported successfully
2023-10-20 23:29:44,839:INFO:Starting cross validation
2023-10-20 23:29:44,840:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:29:45,157:INFO:Calculating mean and std
2023-10-20 23:29:45,157:INFO:Creating metrics dataframe
2023-10-20 23:29:45,157:INFO:Uploading results into container
2023-10-20 23:29:45,157:INFO:Uploading model into container now
2023-10-20 23:29:45,157:INFO:_master_model_container: 7
2023-10-20 23:29:45,157:INFO:_display_container: 2
2023-10-20 23:29:45,157:INFO:OrthogonalMatchingPursuit()
2023-10-20 23:29:45,157:INFO:create_model() successfully completed......................................
2023-10-20 23:29:45,258:INFO:SubProcess create_model() end ==================================
2023-10-20 23:29:45,258:INFO:Creating metrics dataframe
2023-10-20 23:29:45,258:INFO:Initializing Bayesian Ridge
2023-10-20 23:29:45,258:INFO:Total runtime is 0.3103906472524008 minutes
2023-10-20 23:29:45,258:INFO:SubProcess create_model() called ==================================
2023-10-20 23:29:45,258:INFO:Initializing create_model()
2023-10-20 23:29:45,258:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:29:45,258:INFO:Checking exceptions
2023-10-20 23:29:45,258:INFO:Importing libraries
2023-10-20 23:29:45,258:INFO:Copying training dataset
2023-10-20 23:29:45,288:INFO:Defining folds
2023-10-20 23:29:45,288:INFO:Declaring metric variables
2023-10-20 23:29:45,288:INFO:Importing untrained model
2023-10-20 23:29:45,290:INFO:Bayesian Ridge Imported successfully
2023-10-20 23:29:45,290:INFO:Starting cross validation
2023-10-20 23:29:45,290:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:29:45,840:INFO:Calculating mean and std
2023-10-20 23:29:45,840:INFO:Creating metrics dataframe
2023-10-20 23:29:45,840:INFO:Uploading results into container
2023-10-20 23:29:45,840:INFO:Uploading model into container now
2023-10-20 23:29:45,840:INFO:_master_model_container: 8
2023-10-20 23:29:45,840:INFO:_display_container: 2
2023-10-20 23:29:45,840:INFO:BayesianRidge()
2023-10-20 23:29:45,840:INFO:create_model() successfully completed......................................
2023-10-20 23:29:45,943:INFO:SubProcess create_model() end ==================================
2023-10-20 23:29:45,943:INFO:Creating metrics dataframe
2023-10-20 23:29:45,943:INFO:Initializing Passive Aggressive Regressor
2023-10-20 23:29:45,943:INFO:Total runtime is 0.32181796630223597 minutes
2023-10-20 23:29:45,943:INFO:SubProcess create_model() called ==================================
2023-10-20 23:29:45,943:INFO:Initializing create_model()
2023-10-20 23:29:45,943:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:29:45,943:INFO:Checking exceptions
2023-10-20 23:29:45,943:INFO:Importing libraries
2023-10-20 23:29:45,943:INFO:Copying training dataset
2023-10-20 23:29:45,974:INFO:Defining folds
2023-10-20 23:29:45,974:INFO:Declaring metric variables
2023-10-20 23:29:45,974:INFO:Importing untrained model
2023-10-20 23:29:45,974:INFO:Passive Aggressive Regressor Imported successfully
2023-10-20 23:29:45,974:INFO:Starting cross validation
2023-10-20 23:29:45,974:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:29:46,406:INFO:Calculating mean and std
2023-10-20 23:29:46,407:INFO:Creating metrics dataframe
2023-10-20 23:29:46,407:INFO:Uploading results into container
2023-10-20 23:29:46,407:INFO:Uploading model into container now
2023-10-20 23:29:46,407:INFO:_master_model_container: 9
2023-10-20 23:29:46,407:INFO:_display_container: 2
2023-10-20 23:29:46,407:INFO:PassiveAggressiveRegressor(random_state=123)
2023-10-20 23:29:46,407:INFO:create_model() successfully completed......................................
2023-10-20 23:29:46,517:INFO:SubProcess create_model() end ==================================
2023-10-20 23:29:46,517:INFO:Creating metrics dataframe
2023-10-20 23:29:46,523:INFO:Initializing Huber Regressor
2023-10-20 23:29:46,523:INFO:Total runtime is 0.33148535887400316 minutes
2023-10-20 23:29:46,523:INFO:SubProcess create_model() called ==================================
2023-10-20 23:29:46,523:INFO:Initializing create_model()
2023-10-20 23:29:46,523:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:29:46,523:INFO:Checking exceptions
2023-10-20 23:29:46,523:INFO:Importing libraries
2023-10-20 23:29:46,524:INFO:Copying training dataset
2023-10-20 23:29:46,539:INFO:Defining folds
2023-10-20 23:29:46,539:INFO:Declaring metric variables
2023-10-20 23:29:46,539:INFO:Importing untrained model
2023-10-20 23:29:46,539:INFO:Huber Regressor Imported successfully
2023-10-20 23:29:46,539:INFO:Starting cross validation
2023-10-20 23:29:46,539:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:29:50,652:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:29:50,706:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:29:50,706:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:29:50,729:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:29:50,736:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:29:50,754:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:29:50,803:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:29:50,819:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:29:50,836:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:29:50,929:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:29:51,053:INFO:Calculating mean and std
2023-10-20 23:29:51,053:INFO:Creating metrics dataframe
2023-10-20 23:29:51,053:INFO:Uploading results into container
2023-10-20 23:29:51,053:INFO:Uploading model into container now
2023-10-20 23:29:51,053:INFO:_master_model_container: 10
2023-10-20 23:29:51,053:INFO:_display_container: 2
2023-10-20 23:29:51,053:INFO:HuberRegressor()
2023-10-20 23:29:51,053:INFO:create_model() successfully completed......................................
2023-10-20 23:29:51,168:INFO:SubProcess create_model() end ==================================
2023-10-20 23:29:51,168:INFO:Creating metrics dataframe
2023-10-20 23:29:51,168:INFO:Initializing K Neighbors Regressor
2023-10-20 23:29:51,168:INFO:Total runtime is 0.4089048584302267 minutes
2023-10-20 23:29:51,168:INFO:SubProcess create_model() called ==================================
2023-10-20 23:29:51,168:INFO:Initializing create_model()
2023-10-20 23:29:51,168:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:29:51,168:INFO:Checking exceptions
2023-10-20 23:29:51,168:INFO:Importing libraries
2023-10-20 23:29:51,168:INFO:Copying training dataset
2023-10-20 23:29:51,186:INFO:Defining folds
2023-10-20 23:29:51,186:INFO:Declaring metric variables
2023-10-20 23:29:51,186:INFO:Importing untrained model
2023-10-20 23:29:51,186:INFO:K Neighbors Regressor Imported successfully
2023-10-20 23:29:51,186:INFO:Starting cross validation
2023-10-20 23:29:51,186:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:29:52,272:INFO:Calculating mean and std
2023-10-20 23:29:52,272:INFO:Creating metrics dataframe
2023-10-20 23:29:52,272:INFO:Uploading results into container
2023-10-20 23:29:52,272:INFO:Uploading model into container now
2023-10-20 23:29:52,283:INFO:_master_model_container: 11
2023-10-20 23:29:52,284:INFO:_display_container: 2
2023-10-20 23:29:52,284:INFO:KNeighborsRegressor(n_jobs=-1)
2023-10-20 23:29:52,284:INFO:create_model() successfully completed......................................
2023-10-20 23:29:52,400:INFO:SubProcess create_model() end ==================================
2023-10-20 23:29:52,400:INFO:Creating metrics dataframe
2023-10-20 23:29:52,417:INFO:Initializing Decision Tree Regressor
2023-10-20 23:29:52,417:INFO:Total runtime is 0.4297126571337383 minutes
2023-10-20 23:29:52,417:INFO:SubProcess create_model() called ==================================
2023-10-20 23:29:52,417:INFO:Initializing create_model()
2023-10-20 23:29:52,417:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:29:52,417:INFO:Checking exceptions
2023-10-20 23:29:52,417:INFO:Importing libraries
2023-10-20 23:29:52,417:INFO:Copying training dataset
2023-10-20 23:29:52,437:INFO:Defining folds
2023-10-20 23:29:52,437:INFO:Declaring metric variables
2023-10-20 23:29:52,437:INFO:Importing untrained model
2023-10-20 23:29:52,437:INFO:Decision Tree Regressor Imported successfully
2023-10-20 23:29:52,437:INFO:Starting cross validation
2023-10-20 23:29:52,437:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:29:53,583:INFO:Calculating mean and std
2023-10-20 23:29:53,583:INFO:Creating metrics dataframe
2023-10-20 23:29:53,583:INFO:Uploading results into container
2023-10-20 23:29:53,583:INFO:Uploading model into container now
2023-10-20 23:29:53,583:INFO:_master_model_container: 12
2023-10-20 23:29:53,583:INFO:_display_container: 2
2023-10-20 23:29:53,583:INFO:DecisionTreeRegressor(random_state=123)
2023-10-20 23:29:53,583:INFO:create_model() successfully completed......................................
2023-10-20 23:29:53,700:INFO:SubProcess create_model() end ==================================
2023-10-20 23:29:53,700:INFO:Creating metrics dataframe
2023-10-20 23:29:53,700:INFO:Initializing Random Forest Regressor
2023-10-20 23:29:53,700:INFO:Total runtime is 0.45109365781148286 minutes
2023-10-20 23:29:53,700:INFO:SubProcess create_model() called ==================================
2023-10-20 23:29:53,700:INFO:Initializing create_model()
2023-10-20 23:29:53,700:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:29:53,700:INFO:Checking exceptions
2023-10-20 23:29:53,700:INFO:Importing libraries
2023-10-20 23:29:53,700:INFO:Copying training dataset
2023-10-20 23:29:53,716:INFO:Defining folds
2023-10-20 23:29:53,716:INFO:Declaring metric variables
2023-10-20 23:29:53,716:INFO:Importing untrained model
2023-10-20 23:29:53,731:INFO:Random Forest Regressor Imported successfully
2023-10-20 23:29:53,732:INFO:Starting cross validation
2023-10-20 23:29:53,733:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:30:46,477:INFO:Calculating mean and std
2023-10-20 23:30:46,477:INFO:Creating metrics dataframe
2023-10-20 23:30:46,477:INFO:Uploading results into container
2023-10-20 23:30:46,477:INFO:Uploading model into container now
2023-10-20 23:30:46,477:INFO:_master_model_container: 13
2023-10-20 23:30:46,477:INFO:_display_container: 2
2023-10-20 23:30:46,477:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-10-20 23:30:46,477:INFO:create_model() successfully completed......................................
2023-10-20 23:30:46,606:INFO:SubProcess create_model() end ==================================
2023-10-20 23:30:46,606:INFO:Creating metrics dataframe
2023-10-20 23:30:46,621:INFO:Initializing Extra Trees Regressor
2023-10-20 23:30:46,621:INFO:Total runtime is 1.333108727137248 minutes
2023-10-20 23:30:46,621:INFO:SubProcess create_model() called ==================================
2023-10-20 23:30:46,621:INFO:Initializing create_model()
2023-10-20 23:30:46,621:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:30:46,621:INFO:Checking exceptions
2023-10-20 23:30:46,621:INFO:Importing libraries
2023-10-20 23:30:46,621:INFO:Copying training dataset
2023-10-20 23:30:46,639:INFO:Defining folds
2023-10-20 23:30:46,639:INFO:Declaring metric variables
2023-10-20 23:30:46,639:INFO:Importing untrained model
2023-10-20 23:30:46,639:INFO:Extra Trees Regressor Imported successfully
2023-10-20 23:30:46,639:INFO:Starting cross validation
2023-10-20 23:30:46,639:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:31:02,598:INFO:Calculating mean and std
2023-10-20 23:31:02,598:INFO:Creating metrics dataframe
2023-10-20 23:31:02,613:INFO:Uploading results into container
2023-10-20 23:31:02,613:INFO:Uploading model into container now
2023-10-20 23:31:02,613:INFO:_master_model_container: 14
2023-10-20 23:31:02,613:INFO:_display_container: 2
2023-10-20 23:31:02,618:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-10-20 23:31:02,619:INFO:create_model() successfully completed......................................
2023-10-20 23:31:02,852:INFO:SubProcess create_model() end ==================================
2023-10-20 23:31:02,852:INFO:Creating metrics dataframe
2023-10-20 23:31:02,868:INFO:Initializing AdaBoost Regressor
2023-10-20 23:31:02,868:INFO:Total runtime is 1.603890113035838 minutes
2023-10-20 23:31:02,868:INFO:SubProcess create_model() called ==================================
2023-10-20 23:31:02,868:INFO:Initializing create_model()
2023-10-20 23:31:02,868:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:31:02,868:INFO:Checking exceptions
2023-10-20 23:31:02,868:INFO:Importing libraries
2023-10-20 23:31:02,868:INFO:Copying training dataset
2023-10-20 23:31:02,914:INFO:Defining folds
2023-10-20 23:31:02,914:INFO:Declaring metric variables
2023-10-20 23:31:02,914:INFO:Importing untrained model
2023-10-20 23:31:02,914:INFO:AdaBoost Regressor Imported successfully
2023-10-20 23:31:02,914:INFO:Starting cross validation
2023-10-20 23:31:02,930:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:31:10,552:INFO:Calculating mean and std
2023-10-20 23:31:10,553:INFO:Creating metrics dataframe
2023-10-20 23:31:10,553:INFO:Uploading results into container
2023-10-20 23:31:10,553:INFO:Uploading model into container now
2023-10-20 23:31:10,553:INFO:_master_model_container: 15
2023-10-20 23:31:10,553:INFO:_display_container: 2
2023-10-20 23:31:10,553:INFO:AdaBoostRegressor(random_state=123)
2023-10-20 23:31:10,553:INFO:create_model() successfully completed......................................
2023-10-20 23:31:10,653:INFO:SubProcess create_model() end ==================================
2023-10-20 23:31:10,653:INFO:Creating metrics dataframe
2023-10-20 23:31:10,669:INFO:Initializing Gradient Boosting Regressor
2023-10-20 23:31:10,669:INFO:Total runtime is 1.7339226762453717 minutes
2023-10-20 23:31:10,669:INFO:SubProcess create_model() called ==================================
2023-10-20 23:31:10,669:INFO:Initializing create_model()
2023-10-20 23:31:10,669:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:31:10,669:INFO:Checking exceptions
2023-10-20 23:31:10,669:INFO:Importing libraries
2023-10-20 23:31:10,669:INFO:Copying training dataset
2023-10-20 23:31:10,691:INFO:Defining folds
2023-10-20 23:31:10,691:INFO:Declaring metric variables
2023-10-20 23:31:10,691:INFO:Importing untrained model
2023-10-20 23:31:10,691:INFO:Gradient Boosting Regressor Imported successfully
2023-10-20 23:31:10,691:INFO:Starting cross validation
2023-10-20 23:31:10,691:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:31:31,253:INFO:Calculating mean and std
2023-10-20 23:31:31,253:INFO:Creating metrics dataframe
2023-10-20 23:31:31,253:INFO:Uploading results into container
2023-10-20 23:31:31,253:INFO:Uploading model into container now
2023-10-20 23:31:31,253:INFO:_master_model_container: 16
2023-10-20 23:31:31,253:INFO:_display_container: 2
2023-10-20 23:31:31,253:INFO:GradientBoostingRegressor(random_state=123)
2023-10-20 23:31:31,253:INFO:create_model() successfully completed......................................
2023-10-20 23:31:31,352:INFO:SubProcess create_model() end ==================================
2023-10-20 23:31:31,352:INFO:Creating metrics dataframe
2023-10-20 23:31:31,352:INFO:Initializing Light Gradient Boosting Machine
2023-10-20 23:31:31,352:INFO:Total runtime is 2.0786349614461264 minutes
2023-10-20 23:31:31,352:INFO:SubProcess create_model() called ==================================
2023-10-20 23:31:31,352:INFO:Initializing create_model()
2023-10-20 23:31:31,352:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:31:31,352:INFO:Checking exceptions
2023-10-20 23:31:31,352:INFO:Importing libraries
2023-10-20 23:31:31,352:INFO:Copying training dataset
2023-10-20 23:31:31,386:INFO:Defining folds
2023-10-20 23:31:31,386:INFO:Declaring metric variables
2023-10-20 23:31:31,386:INFO:Importing untrained model
2023-10-20 23:31:31,386:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-20 23:31:31,386:INFO:Starting cross validation
2023-10-20 23:31:31,386:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:31:34,148:INFO:Calculating mean and std
2023-10-20 23:31:34,150:INFO:Creating metrics dataframe
2023-10-20 23:31:34,150:INFO:Uploading results into container
2023-10-20 23:31:34,150:INFO:Uploading model into container now
2023-10-20 23:31:34,150:INFO:_master_model_container: 17
2023-10-20 23:31:34,150:INFO:_display_container: 2
2023-10-20 23:31:34,150:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-20 23:31:34,150:INFO:create_model() successfully completed......................................
2023-10-20 23:31:34,266:INFO:SubProcess create_model() end ==================================
2023-10-20 23:31:34,266:INFO:Creating metrics dataframe
2023-10-20 23:31:34,283:INFO:Initializing CatBoost Regressor
2023-10-20 23:31:34,283:INFO:Total runtime is 2.127480455239614 minutes
2023-10-20 23:31:34,283:INFO:SubProcess create_model() called ==================================
2023-10-20 23:31:34,283:INFO:Initializing create_model()
2023-10-20 23:31:34,283:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:31:34,283:INFO:Checking exceptions
2023-10-20 23:31:34,283:INFO:Importing libraries
2023-10-20 23:31:34,283:INFO:Copying training dataset
2023-10-20 23:31:34,311:INFO:Defining folds
2023-10-20 23:31:34,312:INFO:Declaring metric variables
2023-10-20 23:31:34,313:INFO:Importing untrained model
2023-10-20 23:31:34,313:INFO:CatBoost Regressor Imported successfully
2023-10-20 23:31:34,313:INFO:Starting cross validation
2023-10-20 23:31:34,316:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:32:07,875:INFO:Calculating mean and std
2023-10-20 23:32:07,875:INFO:Creating metrics dataframe
2023-10-20 23:32:07,875:INFO:Uploading results into container
2023-10-20 23:32:07,875:INFO:Uploading model into container now
2023-10-20 23:32:07,875:INFO:_master_model_container: 18
2023-10-20 23:32:07,875:INFO:_display_container: 2
2023-10-20 23:32:07,875:INFO:<catboost.core.CatBoostRegressor object at 0x00000209D5A82340>
2023-10-20 23:32:07,875:INFO:create_model() successfully completed......................................
2023-10-20 23:32:08,002:INFO:SubProcess create_model() end ==================================
2023-10-20 23:32:08,002:INFO:Creating metrics dataframe
2023-10-20 23:32:08,002:INFO:Initializing Dummy Regressor
2023-10-20 23:32:08,002:INFO:Total runtime is 2.689457360903422 minutes
2023-10-20 23:32:08,002:INFO:SubProcess create_model() called ==================================
2023-10-20 23:32:08,002:INFO:Initializing create_model()
2023-10-20 23:32:08,002:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:32:08,002:INFO:Checking exceptions
2023-10-20 23:32:08,002:INFO:Importing libraries
2023-10-20 23:32:08,002:INFO:Copying training dataset
2023-10-20 23:32:08,040:INFO:Defining folds
2023-10-20 23:32:08,040:INFO:Declaring metric variables
2023-10-20 23:32:08,040:INFO:Importing untrained model
2023-10-20 23:32:08,041:INFO:Dummy Regressor Imported successfully
2023-10-20 23:32:08,041:INFO:Starting cross validation
2023-10-20 23:32:08,043:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:32:08,354:INFO:Calculating mean and std
2023-10-20 23:32:08,354:INFO:Creating metrics dataframe
2023-10-20 23:32:08,354:INFO:Uploading results into container
2023-10-20 23:32:08,354:INFO:Uploading model into container now
2023-10-20 23:32:08,354:INFO:_master_model_container: 19
2023-10-20 23:32:08,354:INFO:_display_container: 2
2023-10-20 23:32:08,354:INFO:DummyRegressor()
2023-10-20 23:32:08,354:INFO:create_model() successfully completed......................................
2023-10-20 23:32:08,476:INFO:SubProcess create_model() end ==================================
2023-10-20 23:32:08,476:INFO:Creating metrics dataframe
2023-10-20 23:32:08,476:INFO:Initializing create_model()
2023-10-20 23:32:08,476:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=<catboost.core.CatBoostRegressor object at 0x00000209D5A82340>, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:32:08,476:INFO:Checking exceptions
2023-10-20 23:32:08,476:INFO:Importing libraries
2023-10-20 23:32:08,476:INFO:Copying training dataset
2023-10-20 23:32:08,507:INFO:Defining folds
2023-10-20 23:32:08,507:INFO:Declaring metric variables
2023-10-20 23:32:08,507:INFO:Importing untrained model
2023-10-20 23:32:08,507:INFO:Declaring custom model
2023-10-20 23:32:08,507:INFO:CatBoost Regressor Imported successfully
2023-10-20 23:32:08,507:INFO:Cross validation set to False
2023-10-20 23:32:08,507:INFO:Fitting Model
2023-10-20 23:32:15,516:INFO:<catboost.core.CatBoostRegressor object at 0x00000209E4212880>
2023-10-20 23:32:15,516:INFO:create_model() successfully completed......................................
2023-10-20 23:32:15,616:INFO:Creating Dashboard logs
2023-10-20 23:32:15,616:INFO:Model: CatBoost Regressor
2023-10-20 23:32:15,685:INFO:Logged params: {'nan_mode': 'Min', 'eval_metric': 'RMSE', 'iterations': 1000, 'sampling_frequency': 'PerTree', 'leaf_estimation_method': 'Newton', 'random_score_type': 'NormalWithModelSizeDecrease', 'grow_policy': 'SymmetricTree', 'penalties_coefficient': 1, 'boosting_type': 'Plain', 'model_shrink_mode': 'Constant', 'feature_border_type': 'GreedyLogSum', 'bayesian_matrix_reg': 0.10000000149011612, 'eval_fraction': 0, 'force_unit_auto_pair_weights': False, 'l2_leaf_reg': 3, 'random_strength': 1, 'rsm': 1, 'boost_from_average': True, 'model_size_reg': 0.5, 'pool_metainfo_options': {'tags': {}}, 'subsample': 0.800000011920929, 'use_best_model': False, 'random_seed': 123, 'depth': 6, 'posterior_sampling': False, 'border_count': 254, 'classes_count': 0, 'auto_class_weights': 'None', 'sparse_features_conflict_fraction': 0, 'leaf_estimation_backtracking': 'AnyImprovement', 'best_model_min_trees': 1, 'model_shrink_rate': 0, 'min_data_in_leaf': 1, 'loss_function': 'RMSE', 'learning_rate': 0.06757699698209763, 'score_function': 'Cosine', 'task_type': 'CPU', 'leaf_estimation_iterations': 1, 'bootstrap_type': 'MVS', 'max_leaves': 64}
2023-10-20 23:32:15,939:INFO:Initializing predict_model()
2023-10-20 23:32:15,947:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=<catboost.core.CatBoostRegressor object at 0x00000209E4212880>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DA9FBF70>)
2023-10-20 23:32:15,947:INFO:Checking exceptions
2023-10-20 23:32:15,947:INFO:Preloading libraries
2023-10-20 23:32:16,353:INFO:Creating Dashboard logs
2023-10-20 23:32:16,354:INFO:Model: Light Gradient Boosting Machine
2023-10-20 23:32:16,416:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-20 23:32:16,740:INFO:Creating Dashboard logs
2023-10-20 23:32:16,740:INFO:Model: Extra Trees Regressor
2023-10-20 23:32:16,802:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-20 23:32:17,117:INFO:Creating Dashboard logs
2023-10-20 23:32:17,117:INFO:Model: Random Forest Regressor
2023-10-20 23:32:17,180:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-20 23:32:17,520:INFO:Creating Dashboard logs
2023-10-20 23:32:17,520:INFO:Model: Gradient Boosting Regressor
2023-10-20 23:32:17,585:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 123, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-10-20 23:32:17,904:INFO:Creating Dashboard logs
2023-10-20 23:32:17,904:INFO:Model: Ridge Regression
2023-10-20 23:32:17,951:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 123, 'solver': 'auto', 'tol': 0.0001}
2023-10-20 23:32:18,231:INFO:Creating Dashboard logs
2023-10-20 23:32:18,242:INFO:Model: Lasso Regression
2023-10-20 23:32:18,303:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 123, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-10-20 23:32:18,634:INFO:Creating Dashboard logs
2023-10-20 23:32:18,634:INFO:Model: Elastic Net
2023-10-20 23:32:18,688:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 123, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-10-20 23:32:18,992:INFO:Creating Dashboard logs
2023-10-20 23:32:18,992:INFO:Model: Lasso Least Angle Regression
2023-10-20 23:32:19,048:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'max_iter': 500, 'normalize': 'deprecated', 'positive': False, 'precompute': 'auto', 'random_state': 123, 'verbose': False}
2023-10-20 23:32:19,360:INFO:Creating Dashboard logs
2023-10-20 23:32:19,360:INFO:Model: Linear Regression
2023-10-20 23:32:19,419:INFO:Logged params: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'positive': False}
2023-10-20 23:32:19,712:INFO:Creating Dashboard logs
2023-10-20 23:32:19,712:INFO:Model: AdaBoost Regressor
2023-10-20 23:32:19,768:INFO:Logged params: {'base_estimator': 'deprecated', 'estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': 123}
2023-10-20 23:32:20,078:INFO:Creating Dashboard logs
2023-10-20 23:32:20,080:INFO:Model: Orthogonal Matching Pursuit
2023-10-20 23:32:20,130:INFO:Logged params: {'fit_intercept': True, 'n_nonzero_coefs': None, 'normalize': 'deprecated', 'precompute': 'auto', 'tol': None}
2023-10-20 23:32:20,416:INFO:Creating Dashboard logs
2023-10-20 23:32:20,416:INFO:Model: Huber Regressor
2023-10-20 23:32:20,485:INFO:Logged params: {'alpha': 0.0001, 'epsilon': 1.35, 'fit_intercept': True, 'max_iter': 100, 'tol': 1e-05, 'warm_start': False}
2023-10-20 23:32:20,762:INFO:Creating Dashboard logs
2023-10-20 23:32:20,762:INFO:Model: Decision Tree Regressor
2023-10-20 23:32:20,817:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 123, 'splitter': 'best'}
2023-10-20 23:32:21,106:INFO:Creating Dashboard logs
2023-10-20 23:32:21,106:INFO:Model: K Neighbors Regressor
2023-10-20 23:32:21,164:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2023-10-20 23:32:21,462:INFO:Creating Dashboard logs
2023-10-20 23:32:21,462:INFO:Model: Dummy Regressor
2023-10-20 23:32:21,509:INFO:Logged params: {'constant': None, 'quantile': None, 'strategy': 'mean'}
2023-10-20 23:32:21,795:INFO:Creating Dashboard logs
2023-10-20 23:32:21,795:INFO:Model: Passive Aggressive Regressor
2023-10-20 23:32:21,848:INFO:Logged params: {'C': 1.0, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'fit_intercept': True, 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 5, 'random_state': 123, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-10-20 23:32:22,165:INFO:Creating Dashboard logs
2023-10-20 23:32:22,165:INFO:Model: Bayesian Ridge
2023-10-20 23:32:22,227:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'tol': 0.001, 'verbose': False}
2023-10-20 23:32:22,546:INFO:Creating Dashboard logs
2023-10-20 23:32:22,546:INFO:Model: Least Angle Regression
2023-10-20 23:32:22,613:INFO:Logged params: {'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'n_nonzero_coefs': 500, 'normalize': 'deprecated', 'precompute': 'auto', 'random_state': 123, 'verbose': False}
2023-10-20 23:32:22,909:INFO:_master_model_container: 19
2023-10-20 23:32:22,909:INFO:_display_container: 2
2023-10-20 23:32:22,909:INFO:<catboost.core.CatBoostRegressor object at 0x00000209E4212880>
2023-10-20 23:32:22,911:INFO:compare_models() successfully completed......................................
2023-10-20 23:32:22,911:INFO:Initializing ensemble_model()
2023-10-20 23:32:22,911:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=<catboost.core.CatBoostRegressor object at 0x00000209E4212880>, method=Boosting, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-20 23:32:22,911:INFO:Checking exceptions
2023-10-20 23:33:31,120:INFO:Importing libraries
2023-10-20 23:33:31,120:INFO:Copying training dataset
2023-10-20 23:33:31,120:INFO:Checking base model
2023-10-20 23:33:31,120:INFO:Base model : CatBoost Regressor
2023-10-20 23:33:31,120:INFO:Importing untrained ensembler
2023-10-20 23:33:31,120:INFO:Ensemble method set to Boosting
2023-10-20 23:33:31,120:INFO:SubProcess create_model() called ==================================
2023-10-20 23:33:31,135:INFO:Initializing create_model()
2023-10-20 23:33:31,135:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=AdaBoostRegressor(estimator=<catboost.core.CatBoostRegressor object at 0x00000209E4212880>,
                  n_estimators=10, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3CA4430>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:33:31,135:INFO:Checking exceptions
2023-10-20 23:33:31,135:INFO:Importing libraries
2023-10-20 23:33:31,135:INFO:Copying training dataset
2023-10-20 23:33:31,156:INFO:Defining folds
2023-10-20 23:33:31,157:INFO:Declaring metric variables
2023-10-20 23:33:31,157:INFO:Importing untrained model
2023-10-20 23:33:31,157:INFO:Declaring custom model
2023-10-20 23:33:31,159:INFO:AdaBoost Regressor Imported successfully
2023-10-20 23:33:31,159:INFO:Starting cross validation
2023-10-20 23:33:31,159:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:39:41,850:INFO:Calculating mean and std
2023-10-20 23:39:41,851:INFO:Creating metrics dataframe
2023-10-20 23:39:41,851:INFO:Finalizing model
2023-10-20 23:40:50,507:INFO:Uploading results into container
2023-10-20 23:40:50,507:INFO:Uploading model into container now
2023-10-20 23:40:50,507:INFO:_master_model_container: 20
2023-10-20 23:40:50,507:INFO:_display_container: 3
2023-10-20 23:40:50,507:INFO:AdaBoostRegressor(estimator=<catboost.core.CatBoostRegressor object at 0x00000209E421A670>,
                  n_estimators=10, random_state=123)
2023-10-20 23:40:50,507:INFO:create_model() successfully completed......................................
2023-10-20 23:40:50,607:INFO:SubProcess create_model() end ==================================
2023-10-20 23:40:50,623:INFO:Creating Dashboard logs
2023-10-20 23:40:50,624:INFO:Model: AdaBoost Regressor
2023-10-20 23:40:50,681:INFO:Logged params: {'base_estimator': 'deprecated', 'estimator__loss_function': 'RMSE', 'estimator__border_count': 254, 'estimator__verbose': False, 'estimator__task_type': 'CPU', 'estimator__random_state': 123, 'estimator': <catboost.core.CatBoostRegressor object at 0x00000209E421A670>, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 10, 'random_state': 123}
2023-10-20 23:40:50,840:INFO:Initializing predict_model()
2023-10-20 23:40:50,840:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=AdaBoostRegressor(estimator=<catboost.core.CatBoostRegressor object at 0x00000209E421A670>,
                  n_estimators=10, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DC9DE1F0>)
2023-10-20 23:40:50,840:INFO:Checking exceptions
2023-10-20 23:40:50,840:INFO:Preloading libraries
2023-10-20 23:40:51,323:INFO:_master_model_container: 20
2023-10-20 23:40:51,323:INFO:_display_container: 3
2023-10-20 23:40:51,323:INFO:AdaBoostRegressor(estimator=<catboost.core.CatBoostRegressor object at 0x00000209E421A670>,
                  n_estimators=10, random_state=123)
2023-10-20 23:40:51,323:INFO:ensemble_model() successfully completed......................................
2023-10-20 23:40:51,425:INFO:Initializing tune_model()
2023-10-20 23:40:51,425:INFO:tune_model(estimator=AdaBoostRegressor(estimator=<catboost.core.CatBoostRegressor object at 0x00000209E421A670>,
                  n_estimators=10, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>)
2023-10-20 23:40:51,425:INFO:Checking exceptions
2023-10-20 23:40:51,441:INFO:Copying training dataset
2023-10-20 23:40:51,457:INFO:Checking base model
2023-10-20 23:40:51,457:INFO:Base model : AdaBoost Regressor
2023-10-20 23:40:51,457:INFO:Declaring metric variables
2023-10-20 23:40:51,457:INFO:Defining Hyperparameters
2023-10-20 23:40:51,574:INFO:Tuning with n_jobs=-1
2023-10-20 23:40:51,574:INFO:Initializing RandomizedSearchCV
2023-10-21 08:53:05,939:INFO:PyCaret RegressionExperiment
2023-10-21 08:53:05,940:INFO:Logging name: exp_A
2023-10-21 08:53:05,940:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-21 08:53:05,941:INFO:version 3.1.0
2023-10-21 08:53:05,941:INFO:Initializing setup()
2023-10-21 08:53:05,941:INFO:self.USI: 0c8f
2023-10-21 08:53:05,941:INFO:self._variable_keys: {'transform_target_param', 'exp_name_log', 'y_train', 'logging_param', 'n_jobs_param', 'X_train', 'target_param', 'USI', 'gpu_n_jobs_param', 'fold_groups_param', '_ml_usecase', 'seed', 'fold_generator', 'idx', 'html_param', 'log_plots_param', 'y', 'gpu_param', 'X_test', 'memory', 'y_test', 'data', 'X', 'exp_id', '_available_plots', 'fold_shuffle_param', 'pipeline'}
2023-10-21 08:53:05,942:INFO:Checking environment
2023-10-21 08:53:05,942:INFO:python_version: 3.8.18
2023-10-21 08:53:05,942:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-21 08:53:05,942:INFO:machine: AMD64
2023-10-21 08:53:05,943:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-21 08:53:05,943:INFO:Memory: svmem(total=16505954304, available=5360242688, percent=67.5, used=11145711616, free=5360242688)
2023-10-21 08:53:05,943:INFO:Physical Core: 8
2023-10-21 08:53:05,943:INFO:Logical Core: 16
2023-10-21 08:53:05,943:INFO:Checking libraries
2023-10-21 08:53:05,944:INFO:System:
2023-10-21 08:53:05,944:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-21 08:53:05,944:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-21 08:53:05,944:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-21 08:53:05,944:INFO:PyCaret required dependencies:
2023-10-21 08:53:05,944:INFO:                 pip: 23.3
2023-10-21 08:53:05,944:INFO:          setuptools: 68.0.0
2023-10-21 08:53:05,944:INFO:             pycaret: 3.1.0
2023-10-21 08:53:05,944:INFO:             IPython: 8.12.0
2023-10-21 08:53:05,944:INFO:          ipywidgets: 8.1.1
2023-10-21 08:53:05,945:INFO:                tqdm: 4.66.1
2023-10-21 08:53:05,945:INFO:               numpy: 1.23.5
2023-10-21 08:53:05,945:INFO:              pandas: 1.5.3
2023-10-21 08:53:05,945:INFO:              jinja2: 3.1.2
2023-10-21 08:53:05,945:INFO:               scipy: 1.10.1
2023-10-21 08:53:05,945:INFO:              joblib: 1.3.2
2023-10-21 08:53:05,945:INFO:             sklearn: 1.2.2
2023-10-21 08:53:05,945:INFO:                pyod: 1.1.0
2023-10-21 08:53:05,945:INFO:            imblearn: 0.11.0
2023-10-21 08:53:05,945:INFO:   category_encoders: 2.6.2
2023-10-21 08:53:05,945:INFO:            lightgbm: 4.1.0
2023-10-21 08:53:05,945:INFO:               numba: 0.58.1
2023-10-21 08:53:05,945:INFO:            requests: 2.31.0
2023-10-21 08:53:05,945:INFO:          matplotlib: 3.7.3
2023-10-21 08:53:05,945:INFO:          scikitplot: 0.3.7
2023-10-21 08:53:05,946:INFO:         yellowbrick: 1.5
2023-10-21 08:53:05,946:INFO:              plotly: 5.17.0
2023-10-21 08:53:05,946:INFO:    plotly-resampler: Not installed
2023-10-21 08:53:05,946:INFO:             kaleido: 0.2.1
2023-10-21 08:53:05,946:INFO:           schemdraw: 0.15
2023-10-21 08:53:05,946:INFO:         statsmodels: 0.14.0
2023-10-21 08:53:05,946:INFO:              sktime: 0.21.1
2023-10-21 08:53:05,946:INFO:               tbats: 1.1.3
2023-10-21 08:53:05,946:INFO:            pmdarima: 2.0.3
2023-10-21 08:53:05,946:INFO:              psutil: 5.9.0
2023-10-21 08:53:05,946:INFO:          markupsafe: 2.1.3
2023-10-21 08:53:05,946:INFO:             pickle5: Not installed
2023-10-21 08:53:05,946:INFO:         cloudpickle: 2.2.1
2023-10-21 08:53:05,946:INFO:         deprecation: 2.1.0
2023-10-21 08:53:05,946:INFO:              xxhash: 3.4.1
2023-10-21 08:53:05,946:INFO:           wurlitzer: Not installed
2023-10-21 08:53:05,946:INFO:PyCaret optional dependencies:
2023-10-21 08:53:05,946:INFO:                shap: Not installed
2023-10-21 08:53:05,947:INFO:           interpret: Not installed
2023-10-21 08:53:05,947:INFO:                umap: Not installed
2023-10-21 08:53:05,947:INFO:     ydata_profiling: Not installed
2023-10-21 08:53:05,947:INFO:  explainerdashboard: Not installed
2023-10-21 08:53:05,947:INFO:             autoviz: Not installed
2023-10-21 08:53:05,947:INFO:           fairlearn: Not installed
2023-10-21 08:53:05,947:INFO:          deepchecks: Not installed
2023-10-21 08:53:05,947:INFO:             xgboost: Not installed
2023-10-21 08:53:05,947:INFO:            catboost: 1.2.2
2023-10-21 08:53:05,947:INFO:              kmodes: Not installed
2023-10-21 08:53:05,947:INFO:             mlxtend: Not installed
2023-10-21 08:53:05,947:INFO:       statsforecast: Not installed
2023-10-21 08:53:05,947:INFO:        tune_sklearn: Not installed
2023-10-21 08:53:05,947:INFO:                 ray: Not installed
2023-10-21 08:53:05,947:INFO:            hyperopt: Not installed
2023-10-21 08:53:05,947:INFO:              optuna: Not installed
2023-10-21 08:53:05,947:INFO:               skopt: Not installed
2023-10-21 08:53:05,947:INFO:              mlflow: 2.7.1
2023-10-21 08:53:05,947:INFO:              gradio: Not installed
2023-10-21 08:53:05,948:INFO:             fastapi: Not installed
2023-10-21 08:53:05,948:INFO:             uvicorn: Not installed
2023-10-21 08:53:05,948:INFO:              m2cgen: Not installed
2023-10-21 08:53:05,948:INFO:           evidently: Not installed
2023-10-21 08:53:05,948:INFO:               fugue: Not installed
2023-10-21 08:53:05,948:INFO:           streamlit: Not installed
2023-10-21 08:53:05,948:INFO:             prophet: Not installed
2023-10-21 08:53:05,948:INFO:None
2023-10-21 08:53:05,948:INFO:Set up data.
2023-10-21 08:53:05,970:INFO:Set up folding strategy.
2023-10-21 08:53:05,970:INFO:Set up train/test split.
2023-10-21 08:53:06,004:INFO:Set up index.
2023-10-21 08:53:06,005:INFO:Assigning column types.
2023-10-21 08:53:06,027:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-21 08:53:06,028:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,034:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,039:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,124:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,179:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,180:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:53:06,180:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:53:06,181:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,184:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,192:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,278:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,334:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,334:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:53:06,335:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:53:06,336:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-21 08:53:06,341:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,347:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,430:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,487:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,488:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:53:06,488:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:53:06,494:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,500:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,586:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,651:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,651:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:53:06,651:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:53:06,660:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-21 08:53:06,671:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,738:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,792:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,792:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:53:06,792:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:53:06,808:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,871:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,923:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,923:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:53:06,923:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:53:06,923:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-21 08:53:07,008:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:53:07,060:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:53:07,060:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:53:07,060:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:53:07,140:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:53:07,203:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:53:07,204:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:53:07,204:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:53:07,205:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-21 08:53:07,291:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:53:07,341:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:53:07,341:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:53:07,426:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:53:07,472:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:53:07,472:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:53:07,472:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-21 08:53:07,612:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:53:07,612:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:53:07,739:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:53:07,739:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:53:07,739:INFO:Preparing preprocessing pipeline...
2023-10-21 08:53:07,739:INFO:Set up simple imputation.
2023-10-21 08:53:07,739:INFO:Set up column name cleaning.
2023-10-21 08:53:07,802:INFO:Finished creating preprocessing pipeline.
2023-10-21 08:53:07,802:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 08:53:07,802:INFO:Creating final display dataframe.
2023-10-21 08:53:07,973:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (34061, 39)
4        Transformed data shape   (34061, 39)
5   Transformed train set shape   (23842, 39)
6    Transformed test set shape   (10219, 39)
7              Numeric features            38
8      Rows with missing values         23.1%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_A
19                          USI          0c8f
2023-10-21 08:53:08,108:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:53:08,108:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:53:08,235:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:53:08,235:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:53:08,252:INFO:Logging experiment in loggers
2023-10-21 08:53:08,357:INFO:SubProcess save_model() called ==================================
2023-10-21 08:53:08,372:INFO:Initializing save_model()
2023-10-21 08:53:08,372:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmpid5n4mr7\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 08:53:08,372:INFO:Adding model into prep_pipe
2023-10-21 08:53:08,372:WARNING:Only Model saved as it was a pipeline.
2023-10-21 08:53:08,372:INFO:C:\Users\thoma\AppData\Local\Temp\tmpid5n4mr7\Transformation Pipeline.pkl saved in current working directory
2023-10-21 08:53:08,372:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 08:53:08,372:INFO:save_model() successfully completed......................................
2023-10-21 08:53:08,507:INFO:SubProcess save_model() end ==================================
2023-10-21 08:53:08,564:INFO:setup() successfully completed in 2.31s...............
2023-10-21 08:53:08,564:INFO:Initializing create_model()
2023-10-21 08:53:08,564:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6BB93A0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 08:53:08,564:INFO:Checking exceptions
2023-10-21 08:53:08,570:INFO:Importing libraries
2023-10-21 08:53:08,570:INFO:Copying training dataset
2023-10-21 08:53:08,590:INFO:Defining folds
2023-10-21 08:53:08,590:INFO:Declaring metric variables
2023-10-21 08:53:08,590:INFO:Importing untrained model
2023-10-21 08:53:08,590:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 08:53:08,590:INFO:Starting cross validation
2023-10-21 08:53:08,590:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 08:53:18,947:INFO:Calculating mean and std
2023-10-21 08:53:18,950:INFO:Creating metrics dataframe
2023-10-21 08:53:18,950:INFO:Finalizing model
2023-10-21 08:53:19,081:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005763 seconds.
2023-10-21 08:53:19,081:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 08:53:19,082:INFO:[LightGBM] [Info] Total Bins 6173
2023-10-21 08:53:19,082:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 37
2023-10-21 08:53:19,084:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-21 08:53:19,327:INFO:Creating Dashboard logs
2023-10-21 08:53:19,327:INFO:Model: Light Gradient Boosting Machine
2023-10-21 08:53:19,410:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 08:53:19,610:INFO:Initializing predict_model()
2023-10-21 08:53:19,610:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6BB93A0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DCC6AA60>)
2023-10-21 08:53:19,610:INFO:Checking exceptions
2023-10-21 08:53:19,610:INFO:Preloading libraries
2023-10-21 08:53:20,160:INFO:Uploading results into container
2023-10-21 08:53:20,172:INFO:Uploading model into container now
2023-10-21 08:53:20,176:INFO:_master_model_container: 1
2023-10-21 08:53:20,176:INFO:_display_container: 2
2023-10-21 08:53:20,176:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 08:53:20,176:INFO:create_model() successfully completed......................................
2023-10-21 08:53:20,310:INFO:Initializing tune_model()
2023-10-21 08:53:20,310:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6BB93A0>)
2023-10-21 08:53:20,310:INFO:Checking exceptions
2023-10-21 08:53:20,327:INFO:Copying training dataset
2023-10-21 08:53:20,350:INFO:Checking base model
2023-10-21 08:53:20,350:INFO:Base model : Light Gradient Boosting Machine
2023-10-21 08:53:20,350:INFO:Declaring metric variables
2023-10-21 08:53:20,350:INFO:Defining Hyperparameters
2023-10-21 08:53:20,509:INFO:Tuning with n_jobs=-1
2023-10-21 08:53:20,509:INFO:Initializing RandomizedSearchCV
2023-10-21 08:54:14,998:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-21 08:54:14,998:INFO:Hyperparameter search completed
2023-10-21 08:54:14,998:INFO:SubProcess create_model() called ==================================
2023-10-21 08:54:14,998:INFO:Initializing create_model()
2023-10-21 08:54:14,998:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6BB93A0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209DAADED30>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-21 08:54:14,998:INFO:Checking exceptions
2023-10-21 08:54:14,998:INFO:Importing libraries
2023-10-21 08:54:14,998:INFO:Copying training dataset
2023-10-21 08:54:15,032:INFO:Defining folds
2023-10-21 08:54:15,032:INFO:Declaring metric variables
2023-10-21 08:54:15,032:INFO:Importing untrained model
2023-10-21 08:54:15,032:INFO:Declaring custom model
2023-10-21 08:54:15,032:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 08:54:15,032:INFO:Starting cross validation
2023-10-21 08:54:15,032:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 08:54:24,628:INFO:Calculating mean and std
2023-10-21 08:54:24,628:INFO:Creating metrics dataframe
2023-10-21 08:54:24,628:INFO:Finalizing model
2023-10-21 08:54:24,693:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 08:54:24,693:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 08:54:24,694:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 08:54:24,729:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 08:54:24,729:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 08:54:24,729:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 08:54:24,729:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005286 seconds.
2023-10-21 08:54:24,729:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 08:54:24,739:INFO:[LightGBM] [Info] Total Bins 6173
2023-10-21 08:54:24,739:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 37
2023-10-21 08:54:24,741:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-21 08:54:25,845:INFO:Uploading results into container
2023-10-21 08:54:25,845:INFO:Uploading model into container now
2023-10-21 08:54:25,845:INFO:_master_model_container: 2
2023-10-21 08:54:25,845:INFO:_display_container: 3
2023-10-21 08:54:25,845:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-21 08:54:25,845:INFO:create_model() successfully completed......................................
2023-10-21 08:54:26,009:INFO:SubProcess create_model() end ==================================
2023-10-21 08:54:26,009:INFO:choose_better activated
2023-10-21 08:54:26,009:INFO:SubProcess create_model() called ==================================
2023-10-21 08:54:26,009:INFO:Initializing create_model()
2023-10-21 08:54:26,009:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6BB93A0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 08:54:26,009:INFO:Checking exceptions
2023-10-21 08:54:26,009:INFO:Importing libraries
2023-10-21 08:54:26,009:INFO:Copying training dataset
2023-10-21 08:54:26,024:INFO:Defining folds
2023-10-21 08:54:26,024:INFO:Declaring metric variables
2023-10-21 08:54:26,024:INFO:Importing untrained model
2023-10-21 08:54:26,024:INFO:Declaring custom model
2023-10-21 08:54:26,024:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 08:54:26,024:INFO:Starting cross validation
2023-10-21 08:54:26,024:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 08:54:28,843:INFO:Calculating mean and std
2023-10-21 08:54:28,843:INFO:Creating metrics dataframe
2023-10-21 08:54:28,843:INFO:Finalizing model
2023-10-21 08:54:28,903:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004530 seconds.
2023-10-21 08:54:28,903:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 08:54:28,903:INFO:[LightGBM] [Info] Total Bins 6173
2023-10-21 08:54:28,903:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 37
2023-10-21 08:54:28,903:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-21 08:54:29,140:INFO:Uploading results into container
2023-10-21 08:54:29,140:INFO:Uploading model into container now
2023-10-21 08:54:29,140:INFO:_master_model_container: 3
2023-10-21 08:54:29,140:INFO:_display_container: 4
2023-10-21 08:54:29,140:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 08:54:29,140:INFO:create_model() successfully completed......................................
2023-10-21 08:54:29,302:INFO:SubProcess create_model() end ==================================
2023-10-21 08:54:29,302:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8702
2023-10-21 08:54:29,302:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.867
2023-10-21 08:54:29,302:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-21 08:54:29,302:INFO:choose_better completed
2023-10-21 08:54:29,302:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-21 08:54:29,302:INFO:Creating Dashboard logs
2023-10-21 08:54:29,302:INFO:Model: Light Gradient Boosting Machine
2023-10-21 08:54:29,365:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 08:54:29,535:INFO:Initializing predict_model()
2023-10-21 08:54:29,535:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6BB93A0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DCC6A670>)
2023-10-21 08:54:29,535:INFO:Checking exceptions
2023-10-21 08:54:29,535:INFO:Preloading libraries
2023-10-21 08:54:30,089:INFO:_master_model_container: 3
2023-10-21 08:54:30,089:INFO:_display_container: 3
2023-10-21 08:54:30,090:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 08:54:30,090:INFO:tune_model() successfully completed......................................
2023-10-21 08:54:30,220:INFO:Initializing finalize_model()
2023-10-21 08:54:30,220:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6BB93A0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-21 08:54:30,220:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 08:54:30,236:INFO:Initializing create_model()
2023-10-21 08:54:30,236:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6BB93A0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-21 08:54:30,236:INFO:Checking exceptions
2023-10-21 08:54:30,236:INFO:Importing libraries
2023-10-21 08:54:30,236:INFO:Copying training dataset
2023-10-21 08:54:30,236:INFO:Defining folds
2023-10-21 08:54:30,236:INFO:Declaring metric variables
2023-10-21 08:54:30,236:INFO:Importing untrained model
2023-10-21 08:54:30,236:INFO:Declaring custom model
2023-10-21 08:54:30,236:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 08:54:30,236:INFO:Cross validation set to False
2023-10-21 08:54:30,236:INFO:Fitting Model
2023-10-21 08:54:30,341:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010197 seconds.
2023-10-21 08:54:30,341:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 08:54:30,341:INFO:[LightGBM] [Info] Total Bins 6208
2023-10-21 08:54:30,356:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 37
2023-10-21 08:54:30,356:INFO:[LightGBM] [Info] Start training from score 631.011165
2023-10-21 08:54:30,654:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-21 08:54:30,654:INFO:create_model() successfully completed......................................
2023-10-21 08:54:30,799:INFO:Creating Dashboard logs
2023-10-21 08:54:30,799:INFO:Model: Light Gradient Boosting Machine
2023-10-21 08:54:30,869:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 08:54:31,217:INFO:_master_model_container: 3
2023-10-21 08:54:31,217:INFO:_display_container: 3
2023-10-21 08:54:31,221:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-21 08:54:31,221:INFO:finalize_model() successfully completed......................................
2023-10-21 08:54:31,375:INFO:Initializing save_model()
2023-10-21 08:54:31,375:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_A, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 08:54:31,375:INFO:Adding model into prep_pipe
2023-10-21 08:54:31,375:WARNING:Only Model saved as it was a pipeline.
2023-10-21 08:54:31,386:INFO:final_model_for_location_A.pkl saved in current working directory
2023-10-21 08:54:31,386:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-21 08:54:31,386:INFO:save_model() successfully completed......................................
2023-10-21 08:54:31,555:INFO:PyCaret RegressionExperiment
2023-10-21 08:54:31,555:INFO:Logging name: exp_B
2023-10-21 08:54:31,555:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-21 08:54:31,555:INFO:version 3.1.0
2023-10-21 08:54:31,555:INFO:Initializing setup()
2023-10-21 08:54:31,555:INFO:self.USI: 024c
2023-10-21 08:54:31,555:INFO:self._variable_keys: {'transform_target_param', 'exp_name_log', 'y_train', 'logging_param', 'n_jobs_param', 'X_train', 'target_param', 'USI', 'gpu_n_jobs_param', 'fold_groups_param', '_ml_usecase', 'seed', 'fold_generator', 'idx', 'html_param', 'log_plots_param', 'y', 'gpu_param', 'X_test', 'memory', 'y_test', 'data', 'X', 'exp_id', '_available_plots', 'fold_shuffle_param', 'pipeline'}
2023-10-21 08:54:31,555:INFO:Checking environment
2023-10-21 08:54:31,555:INFO:python_version: 3.8.18
2023-10-21 08:54:31,555:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-21 08:54:31,555:INFO:machine: AMD64
2023-10-21 08:54:31,555:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-21 08:54:31,555:INFO:Memory: svmem(total=16505954304, available=3512782848, percent=78.7, used=12993171456, free=3512782848)
2023-10-21 08:54:31,555:INFO:Physical Core: 8
2023-10-21 08:54:31,555:INFO:Logical Core: 16
2023-10-21 08:54:31,555:INFO:Checking libraries
2023-10-21 08:54:31,555:INFO:System:
2023-10-21 08:54:31,555:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-21 08:54:31,555:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-21 08:54:31,555:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-21 08:54:31,555:INFO:PyCaret required dependencies:
2023-10-21 08:54:31,555:INFO:                 pip: 23.3
2023-10-21 08:54:31,555:INFO:          setuptools: 68.0.0
2023-10-21 08:54:31,555:INFO:             pycaret: 3.1.0
2023-10-21 08:54:31,555:INFO:             IPython: 8.12.0
2023-10-21 08:54:31,555:INFO:          ipywidgets: 8.1.1
2023-10-21 08:54:31,555:INFO:                tqdm: 4.66.1
2023-10-21 08:54:31,555:INFO:               numpy: 1.23.5
2023-10-21 08:54:31,555:INFO:              pandas: 1.5.3
2023-10-21 08:54:31,555:INFO:              jinja2: 3.1.2
2023-10-21 08:54:31,555:INFO:               scipy: 1.10.1
2023-10-21 08:54:31,555:INFO:              joblib: 1.3.2
2023-10-21 08:54:31,555:INFO:             sklearn: 1.2.2
2023-10-21 08:54:31,555:INFO:                pyod: 1.1.0
2023-10-21 08:54:31,555:INFO:            imblearn: 0.11.0
2023-10-21 08:54:31,555:INFO:   category_encoders: 2.6.2
2023-10-21 08:54:31,555:INFO:            lightgbm: 4.1.0
2023-10-21 08:54:31,555:INFO:               numba: 0.58.1
2023-10-21 08:54:31,555:INFO:            requests: 2.31.0
2023-10-21 08:54:31,555:INFO:          matplotlib: 3.7.3
2023-10-21 08:54:31,555:INFO:          scikitplot: 0.3.7
2023-10-21 08:54:31,555:INFO:         yellowbrick: 1.5
2023-10-21 08:54:31,555:INFO:              plotly: 5.17.0
2023-10-21 08:54:31,555:INFO:    plotly-resampler: Not installed
2023-10-21 08:54:31,555:INFO:             kaleido: 0.2.1
2023-10-21 08:54:31,555:INFO:           schemdraw: 0.15
2023-10-21 08:54:31,555:INFO:         statsmodels: 0.14.0
2023-10-21 08:54:31,555:INFO:              sktime: 0.21.1
2023-10-21 08:54:31,555:INFO:               tbats: 1.1.3
2023-10-21 08:54:31,555:INFO:            pmdarima: 2.0.3
2023-10-21 08:54:31,555:INFO:              psutil: 5.9.0
2023-10-21 08:54:31,555:INFO:          markupsafe: 2.1.3
2023-10-21 08:54:31,555:INFO:             pickle5: Not installed
2023-10-21 08:54:31,555:INFO:         cloudpickle: 2.2.1
2023-10-21 08:54:31,555:INFO:         deprecation: 2.1.0
2023-10-21 08:54:31,555:INFO:              xxhash: 3.4.1
2023-10-21 08:54:31,555:INFO:           wurlitzer: Not installed
2023-10-21 08:54:31,555:INFO:PyCaret optional dependencies:
2023-10-21 08:54:31,555:INFO:                shap: Not installed
2023-10-21 08:54:31,555:INFO:           interpret: Not installed
2023-10-21 08:54:31,555:INFO:                umap: Not installed
2023-10-21 08:54:31,555:INFO:     ydata_profiling: Not installed
2023-10-21 08:54:31,555:INFO:  explainerdashboard: Not installed
2023-10-21 08:54:31,555:INFO:             autoviz: Not installed
2023-10-21 08:54:31,555:INFO:           fairlearn: Not installed
2023-10-21 08:54:31,555:INFO:          deepchecks: Not installed
2023-10-21 08:54:31,555:INFO:             xgboost: Not installed
2023-10-21 08:54:31,555:INFO:            catboost: 1.2.2
2023-10-21 08:54:31,555:INFO:              kmodes: Not installed
2023-10-21 08:54:31,555:INFO:             mlxtend: Not installed
2023-10-21 08:54:31,555:INFO:       statsforecast: Not installed
2023-10-21 08:54:31,555:INFO:        tune_sklearn: Not installed
2023-10-21 08:54:31,555:INFO:                 ray: Not installed
2023-10-21 08:54:31,571:INFO:            hyperopt: Not installed
2023-10-21 08:54:31,571:INFO:              optuna: Not installed
2023-10-21 08:54:31,571:INFO:               skopt: Not installed
2023-10-21 08:54:31,571:INFO:              mlflow: 2.7.1
2023-10-21 08:54:31,571:INFO:              gradio: Not installed
2023-10-21 08:54:31,571:INFO:             fastapi: Not installed
2023-10-21 08:54:31,571:INFO:             uvicorn: Not installed
2023-10-21 08:54:31,571:INFO:              m2cgen: Not installed
2023-10-21 08:54:31,571:INFO:           evidently: Not installed
2023-10-21 08:54:31,571:INFO:               fugue: Not installed
2023-10-21 08:54:31,571:INFO:           streamlit: Not installed
2023-10-21 08:54:31,571:INFO:             prophet: Not installed
2023-10-21 08:54:31,571:INFO:None
2023-10-21 08:54:31,571:INFO:Set up data.
2023-10-21 08:54:31,589:INFO:Set up folding strategy.
2023-10-21 08:54:31,589:INFO:Set up train/test split.
2023-10-21 08:54:31,621:INFO:Set up index.
2023-10-21 08:54:31,621:INFO:Assigning column types.
2023-10-21 08:54:31,637:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-21 08:54:31,637:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 08:54:31,637:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 08:54:31,653:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:54:31,721:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:54:31,787:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:54:31,787:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:54:31,787:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:54:31,787:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 08:54:31,787:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 08:54:31,787:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:54:31,884:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:54:31,924:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:54:31,924:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:54:31,924:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:54:31,924:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-21 08:54:31,939:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 08:54:31,939:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,021:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,087:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,087:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:54:32,088:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:54:32,093:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,100:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,186:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,235:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,235:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:54:32,235:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:54:32,235:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-21 08:54:32,251:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,336:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,383:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,383:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:54:32,383:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:54:32,399:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,483:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,537:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,537:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:54:32,537:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:54:32,537:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-21 08:54:32,637:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,722:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,731:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:54:32,731:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:54:32,822:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,883:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,884:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:54:32,884:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:54:32,885:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-21 08:54:32,969:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:54:33,022:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:54:33,022:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:54:33,122:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:54:33,170:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:54:33,170:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:54:33,170:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-21 08:54:33,323:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:54:33,323:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:54:33,469:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:54:33,469:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:54:33,469:INFO:Preparing preprocessing pipeline...
2023-10-21 08:54:33,469:INFO:Set up simple imputation.
2023-10-21 08:54:33,485:INFO:Set up column name cleaning.
2023-10-21 08:54:33,532:INFO:Finished creating preprocessing pipeline.
2023-10-21 08:54:33,532:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 08:54:33,532:INFO:Creating final display dataframe.
2023-10-21 08:54:33,702:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (32819, 39)
4        Transformed data shape   (32819, 39)
5   Transformed train set shape   (22973, 39)
6    Transformed test set shape    (9846, 39)
7              Numeric features            38
8      Rows with missing values         19.9%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_B
19                          USI          024c
2023-10-21 08:54:33,901:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:54:33,901:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:54:34,103:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:54:34,103:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:54:34,103:INFO:Logging experiment in loggers
2023-10-21 08:54:34,225:INFO:SubProcess save_model() called ==================================
2023-10-21 08:54:34,234:INFO:Initializing save_model()
2023-10-21 08:54:34,234:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmpov9bwx63\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 08:54:34,234:INFO:Adding model into prep_pipe
2023-10-21 08:54:34,234:WARNING:Only Model saved as it was a pipeline.
2023-10-21 08:54:34,234:INFO:C:\Users\thoma\AppData\Local\Temp\tmpov9bwx63\Transformation Pipeline.pkl saved in current working directory
2023-10-21 08:54:34,249:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 08:54:34,249:INFO:save_model() successfully completed......................................
2023-10-21 08:54:34,370:INFO:SubProcess save_model() end ==================================
2023-10-21 08:54:34,433:INFO:setup() successfully completed in 2.55s...............
2023-10-21 08:54:34,433:INFO:Initializing create_model()
2023-10-21 08:54:34,433:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E3690730>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 08:54:34,433:INFO:Checking exceptions
2023-10-21 08:54:34,433:INFO:Importing libraries
2023-10-21 08:54:34,433:INFO:Copying training dataset
2023-10-21 08:54:34,448:INFO:Defining folds
2023-10-21 08:54:34,448:INFO:Declaring metric variables
2023-10-21 08:54:34,448:INFO:Importing untrained model
2023-10-21 08:54:34,448:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 08:54:34,448:INFO:Starting cross validation
2023-10-21 08:54:34,448:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 08:54:37,332:INFO:Calculating mean and std
2023-10-21 08:54:37,332:INFO:Creating metrics dataframe
2023-10-21 08:54:37,332:INFO:Finalizing model
2023-10-21 08:54:37,398:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003893 seconds.
2023-10-21 08:54:37,398:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 08:54:37,398:INFO:[LightGBM] [Info] Total Bins 6163
2023-10-21 08:54:37,398:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 37
2023-10-21 08:54:37,398:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-21 08:54:37,602:INFO:Creating Dashboard logs
2023-10-21 08:54:37,618:INFO:Model: Light Gradient Boosting Machine
2023-10-21 08:54:37,702:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 08:54:37,879:INFO:Initializing predict_model()
2023-10-21 08:54:37,879:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E3690730>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209D70B8160>)
2023-10-21 08:54:37,879:INFO:Checking exceptions
2023-10-21 08:54:37,879:INFO:Preloading libraries
2023-10-21 08:54:38,375:INFO:Uploading results into container
2023-10-21 08:54:38,376:INFO:Uploading model into container now
2023-10-21 08:54:38,378:INFO:_master_model_container: 1
2023-10-21 08:54:38,378:INFO:_display_container: 2
2023-10-21 08:54:38,378:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 08:54:38,378:INFO:create_model() successfully completed......................................
2023-10-21 08:54:38,511:INFO:Initializing tune_model()
2023-10-21 08:54:38,511:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E3690730>)
2023-10-21 08:54:38,511:INFO:Checking exceptions
2023-10-21 08:54:38,526:INFO:Copying training dataset
2023-10-21 08:54:38,536:INFO:Checking base model
2023-10-21 08:54:38,536:INFO:Base model : Light Gradient Boosting Machine
2023-10-21 08:54:38,536:INFO:Declaring metric variables
2023-10-21 08:54:38,536:INFO:Defining Hyperparameters
2023-10-21 08:54:38,677:INFO:Tuning with n_jobs=-1
2023-10-21 08:54:38,677:INFO:Initializing RandomizedSearchCV
2023-10-21 08:55:25,730:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-21 08:55:25,730:INFO:Hyperparameter search completed
2023-10-21 08:55:25,730:INFO:SubProcess create_model() called ==================================
2023-10-21 08:55:25,730:INFO:Initializing create_model()
2023-10-21 08:55:25,730:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E3690730>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E373BC10>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-21 08:55:25,730:INFO:Checking exceptions
2023-10-21 08:55:25,730:INFO:Importing libraries
2023-10-21 08:55:25,730:INFO:Copying training dataset
2023-10-21 08:55:25,761:INFO:Defining folds
2023-10-21 08:55:25,761:INFO:Declaring metric variables
2023-10-21 08:55:25,761:INFO:Importing untrained model
2023-10-21 08:55:25,761:INFO:Declaring custom model
2023-10-21 08:55:25,761:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 08:55:25,761:INFO:Starting cross validation
2023-10-21 08:55:25,761:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 08:55:35,480:INFO:Calculating mean and std
2023-10-21 08:55:35,484:INFO:Creating metrics dataframe
2023-10-21 08:55:35,486:INFO:Finalizing model
2023-10-21 08:55:35,519:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 08:55:35,519:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 08:55:35,519:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 08:55:35,553:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 08:55:35,553:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 08:55:35,553:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 08:55:35,553:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001322 seconds.
2023-10-21 08:55:35,553:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-21 08:55:35,553:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-21 08:55:35,553:INFO:[LightGBM] [Info] Total Bins 6163
2023-10-21 08:55:35,553:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 37
2023-10-21 08:55:35,565:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-21 08:55:36,930:INFO:Uploading results into container
2023-10-21 08:55:36,930:INFO:Uploading model into container now
2023-10-21 08:55:36,930:INFO:_master_model_container: 2
2023-10-21 08:55:36,930:INFO:_display_container: 3
2023-10-21 08:55:36,930:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-21 08:55:36,930:INFO:create_model() successfully completed......................................
2023-10-21 08:55:37,084:INFO:SubProcess create_model() end ==================================
2023-10-21 08:55:37,084:INFO:choose_better activated
2023-10-21 08:55:37,084:INFO:SubProcess create_model() called ==================================
2023-10-21 08:55:37,084:INFO:Initializing create_model()
2023-10-21 08:55:37,084:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E3690730>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 08:55:37,084:INFO:Checking exceptions
2023-10-21 08:55:37,096:INFO:Importing libraries
2023-10-21 08:55:37,097:INFO:Copying training dataset
2023-10-21 08:55:37,114:INFO:Defining folds
2023-10-21 08:55:37,114:INFO:Declaring metric variables
2023-10-21 08:55:37,114:INFO:Importing untrained model
2023-10-21 08:55:37,114:INFO:Declaring custom model
2023-10-21 08:55:37,114:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 08:55:37,114:INFO:Starting cross validation
2023-10-21 08:55:37,114:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 08:55:40,094:INFO:Calculating mean and std
2023-10-21 08:55:40,094:INFO:Creating metrics dataframe
2023-10-21 08:55:40,094:INFO:Finalizing model
2023-10-21 08:55:40,173:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005807 seconds.
2023-10-21 08:55:40,174:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 08:55:40,174:INFO:[LightGBM] [Info] Total Bins 6163
2023-10-21 08:55:40,175:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 37
2023-10-21 08:55:40,175:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-21 08:55:40,418:INFO:Uploading results into container
2023-10-21 08:55:40,418:INFO:Uploading model into container now
2023-10-21 08:55:40,418:INFO:_master_model_container: 3
2023-10-21 08:55:40,418:INFO:_display_container: 4
2023-10-21 08:55:40,418:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 08:55:40,418:INFO:create_model() successfully completed......................................
2023-10-21 08:55:40,577:INFO:SubProcess create_model() end ==================================
2023-10-21 08:55:40,578:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.836
2023-10-21 08:55:40,579:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8394
2023-10-21 08:55:40,579:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) is best model
2023-10-21 08:55:40,579:INFO:choose_better completed
2023-10-21 08:55:40,580:INFO:Creating Dashboard logs
2023-10-21 08:55:40,580:INFO:Model: Light Gradient Boosting Machine
2023-10-21 08:55:40,631:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 41, 'min_child_weight': 0.001, 'min_split_gain': 0.9, 'n_estimators': 260, 'n_jobs': -1, 'num_leaves': 70, 'objective': None, 'random_state': 123, 'reg_alpha': 2, 'reg_lambda': 3, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6}
2023-10-21 08:55:40,810:INFO:Initializing predict_model()
2023-10-21 08:55:40,810:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E3690730>, estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DCE7EAF0>)
2023-10-21 08:55:40,810:INFO:Checking exceptions
2023-10-21 08:55:40,810:INFO:Preloading libraries
2023-10-21 08:55:41,393:INFO:_master_model_container: 3
2023-10-21 08:55:41,393:INFO:_display_container: 3
2023-10-21 08:55:41,393:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-21 08:55:41,393:INFO:tune_model() successfully completed......................................
2023-10-21 08:55:41,515:INFO:Initializing finalize_model()
2023-10-21 08:55:41,515:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E3690730>, estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-21 08:55:41,515:INFO:Finalizing LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-21 08:55:41,527:INFO:Initializing create_model()
2023-10-21 08:55:41,527:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E3690730>, estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-21 08:55:41,527:INFO:Checking exceptions
2023-10-21 08:55:41,527:INFO:Importing libraries
2023-10-21 08:55:41,527:INFO:Copying training dataset
2023-10-21 08:55:41,527:INFO:Defining folds
2023-10-21 08:55:41,527:INFO:Declaring metric variables
2023-10-21 08:55:41,527:INFO:Importing untrained model
2023-10-21 08:55:41,527:INFO:Declaring custom model
2023-10-21 08:55:41,527:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 08:55:41,527:INFO:Cross validation set to False
2023-10-21 08:55:41,527:INFO:Fitting Model
2023-10-21 08:55:41,576:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 08:55:41,576:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 08:55:41,576:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 08:55:41,609:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 08:55:41,609:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 08:55:41,609:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 08:55:41,629:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006571 seconds.
2023-10-21 08:55:41,629:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 08:55:41,629:INFO:[LightGBM] [Info] Total Bins 6208
2023-10-21 08:55:41,631:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 37
2023-10-21 08:55:41,632:INFO:[LightGBM] [Info] Start training from score 96.893335
2023-10-21 08:55:42,825:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                               feature_fraction=0.4, min_child_samples=41,
                               min_split_gain=0.9, n_estimators=260, n_jobs=-1,
                               num_leaves=70, random_state=123, reg_alpha=2,
                               reg_lambda=3))])
2023-10-21 08:55:42,825:INFO:create_model() successfully completed......................................
2023-10-21 08:55:42,978:INFO:Creating Dashboard logs
2023-10-21 08:55:42,978:INFO:Model: Light Gradient Boosting Machine
2023-10-21 08:55:43,042:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 41, 'min_child_weight': 0.001, 'min_split_gain': 0.9, 'n_estimators': 260, 'n_jobs': -1, 'num_leaves': 70, 'objective': None, 'random_state': 123, 'reg_alpha': 2, 'reg_lambda': 3, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6}
2023-10-21 08:55:43,426:INFO:_master_model_container: 3
2023-10-21 08:55:43,426:INFO:_display_container: 3
2023-10-21 08:55:43,430:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                               feature_fraction=0.4, min_child_samples=41,
                               min_split_gain=0.9, n_estimators=260, n_jobs=-1,
                               num_leaves=70, random_state=123, reg_alpha=2,
                               reg_lambda=3))])
2023-10-21 08:55:43,430:INFO:finalize_model() successfully completed......................................
2023-10-21 08:55:43,560:INFO:Initializing save_model()
2023-10-21 08:55:43,560:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                               feature_fraction=0.4, min_child_samples=41,
                               min_split_gain=0.9, n_estimators=260, n_jobs=-1,
                               num_leaves=70, random_state=123, reg_alpha=2,
                               reg_lambda=3))]), model_name=final_model_for_location_B, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 08:55:43,560:INFO:Adding model into prep_pipe
2023-10-21 08:55:43,560:WARNING:Only Model saved as it was a pipeline.
2023-10-21 08:55:43,608:INFO:final_model_for_location_B.pkl saved in current working directory
2023-10-21 08:55:43,627:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                               feature_fraction=0.4, min_child_samples=41,
                               min_split_gain=0.9, n_estimators=260, n_jobs=-1,
                               num_leaves=70, random_state=123, reg_alpha=2,
                               reg_lambda=3))])
2023-10-21 08:55:43,627:INFO:save_model() successfully completed......................................
2023-10-21 08:55:43,791:INFO:PyCaret RegressionExperiment
2023-10-21 08:55:43,791:INFO:Logging name: exp_C
2023-10-21 08:55:43,791:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-21 08:55:43,791:INFO:version 3.1.0
2023-10-21 08:55:43,791:INFO:Initializing setup()
2023-10-21 08:55:43,791:INFO:self.USI: f8e8
2023-10-21 08:55:43,792:INFO:self._variable_keys: {'transform_target_param', 'exp_name_log', 'y_train', 'logging_param', 'n_jobs_param', 'X_train', 'target_param', 'USI', 'gpu_n_jobs_param', 'fold_groups_param', '_ml_usecase', 'seed', 'fold_generator', 'idx', 'html_param', 'log_plots_param', 'y', 'gpu_param', 'X_test', 'memory', 'y_test', 'data', 'X', 'exp_id', '_available_plots', 'fold_shuffle_param', 'pipeline'}
2023-10-21 08:55:43,792:INFO:Checking environment
2023-10-21 08:55:43,792:INFO:python_version: 3.8.18
2023-10-21 08:55:43,792:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-21 08:55:43,792:INFO:machine: AMD64
2023-10-21 08:55:43,792:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-21 08:55:43,792:INFO:Memory: svmem(total=16505954304, available=3406655488, percent=79.4, used=13099298816, free=3406655488)
2023-10-21 08:55:43,792:INFO:Physical Core: 8
2023-10-21 08:55:43,792:INFO:Logical Core: 16
2023-10-21 08:55:43,792:INFO:Checking libraries
2023-10-21 08:55:43,792:INFO:System:
2023-10-21 08:55:43,792:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-21 08:55:43,792:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-21 08:55:43,792:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-21 08:55:43,792:INFO:PyCaret required dependencies:
2023-10-21 08:55:43,792:INFO:                 pip: 23.3
2023-10-21 08:55:43,792:INFO:          setuptools: 68.0.0
2023-10-21 08:55:43,792:INFO:             pycaret: 3.1.0
2023-10-21 08:55:43,792:INFO:             IPython: 8.12.0
2023-10-21 08:55:43,792:INFO:          ipywidgets: 8.1.1
2023-10-21 08:55:43,792:INFO:                tqdm: 4.66.1
2023-10-21 08:55:43,792:INFO:               numpy: 1.23.5
2023-10-21 08:55:43,792:INFO:              pandas: 1.5.3
2023-10-21 08:55:43,792:INFO:              jinja2: 3.1.2
2023-10-21 08:55:43,792:INFO:               scipy: 1.10.1
2023-10-21 08:55:43,792:INFO:              joblib: 1.3.2
2023-10-21 08:55:43,792:INFO:             sklearn: 1.2.2
2023-10-21 08:55:43,792:INFO:                pyod: 1.1.0
2023-10-21 08:55:43,792:INFO:            imblearn: 0.11.0
2023-10-21 08:55:43,792:INFO:   category_encoders: 2.6.2
2023-10-21 08:55:43,792:INFO:            lightgbm: 4.1.0
2023-10-21 08:55:43,792:INFO:               numba: 0.58.1
2023-10-21 08:55:43,792:INFO:            requests: 2.31.0
2023-10-21 08:55:43,792:INFO:          matplotlib: 3.7.3
2023-10-21 08:55:43,792:INFO:          scikitplot: 0.3.7
2023-10-21 08:55:43,792:INFO:         yellowbrick: 1.5
2023-10-21 08:55:43,792:INFO:              plotly: 5.17.0
2023-10-21 08:55:43,792:INFO:    plotly-resampler: Not installed
2023-10-21 08:55:43,792:INFO:             kaleido: 0.2.1
2023-10-21 08:55:43,792:INFO:           schemdraw: 0.15
2023-10-21 08:55:43,792:INFO:         statsmodels: 0.14.0
2023-10-21 08:55:43,792:INFO:              sktime: 0.21.1
2023-10-21 08:55:43,792:INFO:               tbats: 1.1.3
2023-10-21 08:55:43,792:INFO:            pmdarima: 2.0.3
2023-10-21 08:55:43,792:INFO:              psutil: 5.9.0
2023-10-21 08:55:43,792:INFO:          markupsafe: 2.1.3
2023-10-21 08:55:43,792:INFO:             pickle5: Not installed
2023-10-21 08:55:43,792:INFO:         cloudpickle: 2.2.1
2023-10-21 08:55:43,792:INFO:         deprecation: 2.1.0
2023-10-21 08:55:43,792:INFO:              xxhash: 3.4.1
2023-10-21 08:55:43,792:INFO:           wurlitzer: Not installed
2023-10-21 08:55:43,792:INFO:PyCaret optional dependencies:
2023-10-21 08:55:43,792:INFO:                shap: Not installed
2023-10-21 08:55:43,792:INFO:           interpret: Not installed
2023-10-21 08:55:43,792:INFO:                umap: Not installed
2023-10-21 08:55:43,792:INFO:     ydata_profiling: Not installed
2023-10-21 08:55:43,792:INFO:  explainerdashboard: Not installed
2023-10-21 08:55:43,792:INFO:             autoviz: Not installed
2023-10-21 08:55:43,792:INFO:           fairlearn: Not installed
2023-10-21 08:55:43,792:INFO:          deepchecks: Not installed
2023-10-21 08:55:43,792:INFO:             xgboost: Not installed
2023-10-21 08:55:43,792:INFO:            catboost: 1.2.2
2023-10-21 08:55:43,792:INFO:              kmodes: Not installed
2023-10-21 08:55:43,792:INFO:             mlxtend: Not installed
2023-10-21 08:55:43,792:INFO:       statsforecast: Not installed
2023-10-21 08:55:43,792:INFO:        tune_sklearn: Not installed
2023-10-21 08:55:43,792:INFO:                 ray: Not installed
2023-10-21 08:55:43,792:INFO:            hyperopt: Not installed
2023-10-21 08:55:43,792:INFO:              optuna: Not installed
2023-10-21 08:55:43,792:INFO:               skopt: Not installed
2023-10-21 08:55:43,792:INFO:              mlflow: 2.7.1
2023-10-21 08:55:43,792:INFO:              gradio: Not installed
2023-10-21 08:55:43,792:INFO:             fastapi: Not installed
2023-10-21 08:55:43,792:INFO:             uvicorn: Not installed
2023-10-21 08:55:43,792:INFO:              m2cgen: Not installed
2023-10-21 08:55:43,792:INFO:           evidently: Not installed
2023-10-21 08:55:43,792:INFO:               fugue: Not installed
2023-10-21 08:55:43,792:INFO:           streamlit: Not installed
2023-10-21 08:55:43,792:INFO:             prophet: Not installed
2023-10-21 08:55:43,792:INFO:None
2023-10-21 08:55:43,792:INFO:Set up data.
2023-10-21 08:55:43,825:INFO:Set up folding strategy.
2023-10-21 08:55:43,825:INFO:Set up train/test split.
2023-10-21 08:55:43,847:INFO:Set up index.
2023-10-21 08:55:43,847:INFO:Assigning column types.
2023-10-21 08:55:43,860:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-21 08:55:43,860:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 08:55:43,873:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 08:55:43,875:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:55:43,945:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:55:43,991:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,007:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:55:44,007:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:55:44,008:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,008:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,008:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,091:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,140:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,141:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:55:44,142:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:55:44,142:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-21 08:55:44,142:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,142:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,224:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,274:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,274:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:55:44,274:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:55:44,274:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,290:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,363:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,425:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,426:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:55:44,426:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:55:44,427:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-21 08:55:44,428:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,508:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,560:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,560:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:55:44,560:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:55:44,576:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,641:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,694:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,694:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:55:44,694:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:55:44,694:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-21 08:55:44,797:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,856:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,857:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:55:44,857:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:55:44,947:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:55:45,007:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:55:45,008:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:55:45,009:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:55:45,009:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-21 08:55:45,095:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:55:45,149:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:55:45,149:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:55:45,235:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:55:45,273:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:55:45,273:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:55:45,273:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-21 08:55:45,430:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:55:45,431:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:55:45,581:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:55:45,581:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:55:45,581:INFO:Preparing preprocessing pipeline...
2023-10-21 08:55:45,581:INFO:Set up simple imputation.
2023-10-21 08:55:45,590:INFO:Set up column name cleaning.
2023-10-21 08:55:45,644:INFO:Finished creating preprocessing pipeline.
2023-10-21 08:55:45,649:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 08:55:45,649:INFO:Creating final display dataframe.
2023-10-21 08:55:45,828:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (26071, 39)
4        Transformed data shape   (26071, 39)
5   Transformed train set shape   (18249, 39)
6    Transformed test set shape    (7822, 39)
7              Numeric features            38
8      Rows with missing values         25.0%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_C
19                          USI          f8e8
2023-10-21 08:55:45,974:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:55:45,974:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:55:46,106:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:55:46,106:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:55:46,106:INFO:Logging experiment in loggers
2023-10-21 08:55:46,263:INFO:SubProcess save_model() called ==================================
2023-10-21 08:55:46,278:INFO:Initializing save_model()
2023-10-21 08:55:46,278:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmp20uec8o6\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 08:55:46,278:INFO:Adding model into prep_pipe
2023-10-21 08:55:46,278:WARNING:Only Model saved as it was a pipeline.
2023-10-21 08:55:46,280:INFO:C:\Users\thoma\AppData\Local\Temp\tmp20uec8o6\Transformation Pipeline.pkl saved in current working directory
2023-10-21 08:55:46,291:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 08:55:46,291:INFO:save_model() successfully completed......................................
2023-10-21 08:55:46,439:INFO:SubProcess save_model() end ==================================
2023-10-21 08:55:46,520:INFO:setup() successfully completed in 2.33s...............
2023-10-21 08:55:46,520:INFO:Initializing create_model()
2023-10-21 08:55:46,520:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 08:55:46,520:INFO:Checking exceptions
2023-10-21 08:55:46,526:INFO:Importing libraries
2023-10-21 08:55:46,526:INFO:Copying training dataset
2023-10-21 08:55:46,545:INFO:Defining folds
2023-10-21 08:55:46,546:INFO:Declaring metric variables
2023-10-21 08:55:46,546:INFO:Importing untrained model
2023-10-21 08:55:46,546:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 08:55:46,547:INFO:Starting cross validation
2023-10-21 08:55:46,548:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 08:55:49,622:INFO:Calculating mean and std
2023-10-21 08:55:49,622:INFO:Creating metrics dataframe
2023-10-21 08:55:49,622:INFO:Finalizing model
2023-10-21 08:55:49,728:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004660 seconds.
2023-10-21 08:55:49,728:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 08:55:49,728:INFO:[LightGBM] [Info] Total Bins 6153
2023-10-21 08:55:49,728:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 37
2023-10-21 08:55:49,728:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-21 08:55:50,025:INFO:Creating Dashboard logs
2023-10-21 08:55:50,027:INFO:Model: Light Gradient Boosting Machine
2023-10-21 08:55:50,137:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 08:55:50,336:INFO:Initializing predict_model()
2023-10-21 08:55:50,336:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209D6F36CA0>)
2023-10-21 08:55:50,337:INFO:Checking exceptions
2023-10-21 08:55:50,337:INFO:Preloading libraries
2023-10-21 08:55:50,887:INFO:Uploading results into container
2023-10-21 08:55:50,887:INFO:Uploading model into container now
2023-10-21 08:55:50,887:INFO:_master_model_container: 1
2023-10-21 08:55:50,903:INFO:_display_container: 2
2023-10-21 08:55:50,903:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 08:55:50,903:INFO:create_model() successfully completed......................................
2023-10-21 08:55:51,043:INFO:Initializing tune_model()
2023-10-21 08:55:51,043:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>)
2023-10-21 08:55:51,043:INFO:Checking exceptions
2023-10-21 08:55:51,055:INFO:Copying training dataset
2023-10-21 08:55:51,068:INFO:Checking base model
2023-10-21 08:55:51,068:INFO:Base model : Light Gradient Boosting Machine
2023-10-21 08:55:51,069:INFO:Declaring metric variables
2023-10-21 08:55:51,070:INFO:Defining Hyperparameters
2023-10-21 08:55:51,224:INFO:Tuning with n_jobs=-1
2023-10-21 08:55:51,225:INFO:Initializing RandomizedSearchCV
2023-10-21 08:56:36,065:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-21 08:56:36,068:INFO:Hyperparameter search completed
2023-10-21 08:56:36,068:INFO:SubProcess create_model() called ==================================
2023-10-21 08:56:36,069:INFO:Initializing create_model()
2023-10-21 08:56:36,069:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E421AF10>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-21 08:56:36,069:INFO:Checking exceptions
2023-10-21 08:56:36,070:INFO:Importing libraries
2023-10-21 08:56:36,070:INFO:Copying training dataset
2023-10-21 08:56:36,094:INFO:Defining folds
2023-10-21 08:56:36,094:INFO:Declaring metric variables
2023-10-21 08:56:36,094:INFO:Importing untrained model
2023-10-21 08:56:36,094:INFO:Declaring custom model
2023-10-21 08:56:36,094:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 08:56:36,097:INFO:Starting cross validation
2023-10-21 08:56:36,099:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 08:56:45,640:INFO:Calculating mean and std
2023-10-21 08:56:45,640:INFO:Creating metrics dataframe
2023-10-21 08:56:45,640:INFO:Finalizing model
2023-10-21 08:56:45,679:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 08:56:45,679:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 08:56:45,679:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 08:56:45,696:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 08:56:45,696:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 08:56:45,696:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 08:56:45,696:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002809 seconds.
2023-10-21 08:56:45,696:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 08:56:45,696:INFO:[LightGBM] [Info] Total Bins 6153
2023-10-21 08:56:45,706:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 37
2023-10-21 08:56:45,707:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-21 08:56:45,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 08:56:45,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 08:56:45,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 08:56:45,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 08:56:46,706:INFO:Uploading results into container
2023-10-21 08:56:46,706:INFO:Uploading model into container now
2023-10-21 08:56:46,706:INFO:_master_model_container: 2
2023-10-21 08:56:46,706:INFO:_display_container: 3
2023-10-21 08:56:46,706:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-21 08:56:46,706:INFO:create_model() successfully completed......................................
2023-10-21 08:56:46,873:INFO:SubProcess create_model() end ==================================
2023-10-21 08:56:46,873:INFO:choose_better activated
2023-10-21 08:56:46,873:INFO:SubProcess create_model() called ==================================
2023-10-21 08:56:46,873:INFO:Initializing create_model()
2023-10-21 08:56:46,873:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 08:56:46,873:INFO:Checking exceptions
2023-10-21 08:56:46,873:INFO:Importing libraries
2023-10-21 08:56:46,873:INFO:Copying training dataset
2023-10-21 08:56:46,896:INFO:Defining folds
2023-10-21 08:56:46,896:INFO:Declaring metric variables
2023-10-21 08:56:46,896:INFO:Importing untrained model
2023-10-21 08:56:46,896:INFO:Declaring custom model
2023-10-21 08:56:46,896:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 08:56:46,896:INFO:Starting cross validation
2023-10-21 08:56:46,896:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 08:56:49,187:INFO:Calculating mean and std
2023-10-21 08:56:49,187:INFO:Creating metrics dataframe
2023-10-21 08:56:49,187:INFO:Finalizing model
2023-10-21 08:56:49,254:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003392 seconds.
2023-10-21 08:56:49,254:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 08:56:49,254:INFO:[LightGBM] [Info] Total Bins 6153
2023-10-21 08:56:49,254:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 37
2023-10-21 08:56:49,254:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-21 08:56:49,487:INFO:Uploading results into container
2023-10-21 08:56:49,487:INFO:Uploading model into container now
2023-10-21 08:56:49,487:INFO:_master_model_container: 3
2023-10-21 08:56:49,487:INFO:_display_container: 4
2023-10-21 08:56:49,487:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 08:56:49,487:INFO:create_model() successfully completed......................................
2023-10-21 08:56:49,635:INFO:SubProcess create_model() end ==================================
2023-10-21 08:56:49,636:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.9008
2023-10-21 08:56:49,637:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8936
2023-10-21 08:56:49,637:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-21 08:56:49,637:INFO:choose_better completed
2023-10-21 08:56:49,637:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-21 08:56:49,637:INFO:Creating Dashboard logs
2023-10-21 08:56:49,637:INFO:Model: Light Gradient Boosting Machine
2023-10-21 08:56:49,698:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 08:56:49,871:INFO:Initializing predict_model()
2023-10-21 08:56:49,871:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209D6F36310>)
2023-10-21 08:56:49,871:INFO:Checking exceptions
2023-10-21 08:56:49,871:INFO:Preloading libraries
2023-10-21 08:56:50,355:INFO:_master_model_container: 3
2023-10-21 08:56:50,369:INFO:_display_container: 3
2023-10-21 08:56:50,369:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 08:56:50,369:INFO:tune_model() successfully completed......................................
2023-10-21 08:56:50,490:INFO:Initializing finalize_model()
2023-10-21 08:56:50,490:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-21 08:56:50,490:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 08:56:50,500:INFO:Initializing create_model()
2023-10-21 08:56:50,506:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-21 08:56:50,506:INFO:Checking exceptions
2023-10-21 08:56:50,506:INFO:Importing libraries
2023-10-21 08:56:50,506:INFO:Copying training dataset
2023-10-21 08:56:50,506:INFO:Defining folds
2023-10-21 08:56:50,506:INFO:Declaring metric variables
2023-10-21 08:56:50,506:INFO:Importing untrained model
2023-10-21 08:56:50,506:INFO:Declaring custom model
2023-10-21 08:56:50,506:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 08:56:50,506:INFO:Cross validation set to False
2023-10-21 08:56:50,506:INFO:Fitting Model
2023-10-21 08:56:50,579:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004880 seconds.
2023-10-21 08:56:50,579:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 08:56:50,579:INFO:[LightGBM] [Info] Total Bins 6199
2023-10-21 08:56:50,579:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 37
2023-10-21 08:56:50,579:INFO:[LightGBM] [Info] Start training from score 77.700043
2023-10-21 08:56:50,820:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-21 08:56:50,820:INFO:create_model() successfully completed......................................
2023-10-21 08:56:50,973:INFO:Creating Dashboard logs
2023-10-21 08:56:50,973:INFO:Model: Light Gradient Boosting Machine
2023-10-21 08:56:51,035:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 08:56:51,351:INFO:_master_model_container: 3
2023-10-21 08:56:51,351:INFO:_display_container: 3
2023-10-21 08:56:51,351:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-21 08:56:51,351:INFO:finalize_model() successfully completed......................................
2023-10-21 08:56:51,489:INFO:Initializing save_model()
2023-10-21 08:56:51,489:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_C, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 08:56:51,489:INFO:Adding model into prep_pipe
2023-10-21 08:56:51,489:WARNING:Only Model saved as it was a pipeline.
2023-10-21 08:56:51,504:INFO:final_model_for_location_C.pkl saved in current working directory
2023-10-21 08:56:51,520:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-21 08:56:51,520:INFO:save_model() successfully completed......................................
2023-10-21 08:56:52,850:INFO:Initializing load_model()
2023-10-21 08:56:52,851:INFO:load_model(model_name=final_model_for_location_A, platform=None, authentication=None, verbose=True)
2023-10-21 08:56:52,866:INFO:Initializing load_model()
2023-10-21 08:56:52,866:INFO:load_model(model_name=final_model_for_location_B, platform=None, authentication=None, verbose=True)
2023-10-21 08:56:52,897:INFO:Initializing load_model()
2023-10-21 08:56:52,898:INFO:load_model(model_name=final_model_for_location_C, platform=None, authentication=None, verbose=True)
2023-10-21 08:56:52,933:INFO:Initializing predict_model()
2023-10-21 08:56:52,934:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DCC6AF70>)
2023-10-21 08:56:52,934:INFO:Checking exceptions
2023-10-21 08:56:52,934:INFO:Preloading libraries
2023-10-21 08:56:52,935:INFO:Set up data.
2023-10-21 08:56:52,959:INFO:Set up index.
2023-10-21 08:56:53,157:INFO:Initializing predict_model()
2023-10-21 08:56:53,157:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                               feature_fraction=0.4, min_child_samples=41,
                               min_split_gain=0.9, n_estimators=260, n_jobs=-1,
                               num_leaves=70, random_state=123, reg_alpha=2,
                               reg_lambda=3))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209D98B08B0>)
2023-10-21 08:56:53,157:INFO:Checking exceptions
2023-10-21 08:56:53,157:INFO:Preloading libraries
2023-10-21 08:56:53,157:INFO:Set up data.
2023-10-21 08:56:53,170:INFO:Set up index.
2023-10-21 08:56:53,398:INFO:Initializing predict_model()
2023-10-21 08:56:53,398:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209D98B08B0>)
2023-10-21 08:56:53,398:INFO:Checking exceptions
2023-10-21 08:56:53,398:INFO:Preloading libraries
2023-10-21 08:56:53,399:INFO:Set up data.
2023-10-21 08:56:53,412:INFO:Set up index.
2023-10-21 08:59:42,011:INFO:Initializing load_model()
2023-10-21 08:59:42,012:INFO:load_model(model_name=final_model_for_location_A, platform=None, authentication=None, verbose=True)
2023-10-21 08:59:42,013:INFO:Initializing load_model()
2023-10-21 08:59:42,013:INFO:load_model(model_name=final_model_for_location_B, platform=None, authentication=None, verbose=True)
2023-10-21 08:59:42,040:INFO:Initializing load_model()
2023-10-21 08:59:42,041:INFO:load_model(model_name=final_model_for_location_C, platform=None, authentication=None, verbose=True)
2023-10-21 08:59:42,063:INFO:Initializing predict_model()
2023-10-21 08:59:42,063:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209D5905EE0>)
2023-10-21 08:59:42,064:INFO:Checking exceptions
2023-10-21 08:59:42,064:INFO:Preloading libraries
2023-10-21 08:59:42,064:INFO:Set up data.
2023-10-21 08:59:42,078:INFO:Set up index.
2023-10-21 08:59:42,293:INFO:Initializing predict_model()
2023-10-21 08:59:42,293:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                               feature_fraction=0.4, min_child_samples=41,
                               min_split_gain=0.9, n_estimators=260, n_jobs=-1,
                               num_leaves=70, random_state=123, reg_alpha=2,
                               reg_lambda=3))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209D5905EE0>)
2023-10-21 08:59:42,293:INFO:Checking exceptions
2023-10-21 08:59:42,293:INFO:Preloading libraries
2023-10-21 08:59:42,294:INFO:Set up data.
2023-10-21 08:59:42,297:INFO:Set up index.
2023-10-21 08:59:42,516:INFO:Initializing predict_model()
2023-10-21 08:59:42,516:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209D5905EE0>)
2023-10-21 08:59:42,516:INFO:Checking exceptions
2023-10-21 08:59:42,516:INFO:Preloading libraries
2023-10-21 08:59:42,516:INFO:Set up data.
2023-10-21 08:59:42,533:INFO:Set up index.
2023-10-21 09:00:42,577:INFO:Initializing load_model()
2023-10-21 09:00:42,577:INFO:load_model(model_name=final_model_for_location_A, platform=None, authentication=None, verbose=True)
2023-10-21 09:00:42,589:INFO:Initializing load_model()
2023-10-21 09:00:42,589:INFO:load_model(model_name=final_model_for_location_B, platform=None, authentication=None, verbose=True)
2023-10-21 09:00:42,611:INFO:Initializing load_model()
2023-10-21 09:00:42,611:INFO:load_model(model_name=final_model_for_location_C, platform=None, authentication=None, verbose=True)
2023-10-21 09:00:42,635:INFO:Initializing predict_model()
2023-10-21 09:00:42,635:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DACFEA60>)
2023-10-21 09:00:42,635:INFO:Checking exceptions
2023-10-21 09:00:42,635:INFO:Preloading libraries
2023-10-21 09:00:42,636:INFO:Set up data.
2023-10-21 09:00:42,653:INFO:Set up index.
2023-10-21 09:00:42,860:INFO:Initializing predict_model()
2023-10-21 09:00:42,861:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                               feature_fraction=0.4, min_child_samples=41,
                               min_split_gain=0.9, n_estimators=260, n_jobs=-1,
                               num_leaves=70, random_state=123, reg_alpha=2,
                               reg_lambda=3))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209E36DEE50>)
2023-10-21 09:00:42,862:INFO:Checking exceptions
2023-10-21 09:00:42,862:INFO:Preloading libraries
2023-10-21 09:00:42,862:INFO:Set up data.
2023-10-21 09:00:42,862:INFO:Set up index.
2023-10-21 09:00:43,079:INFO:Initializing predict_model()
2023-10-21 09:00:43,079:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209E36DEE50>)
2023-10-21 09:00:43,079:INFO:Checking exceptions
2023-10-21 09:00:43,079:INFO:Preloading libraries
2023-10-21 09:00:43,079:INFO:Set up data.
2023-10-21 09:00:43,096:INFO:Set up index.
2023-10-21 13:11:47,221:INFO:PyCaret RegressionExperiment
2023-10-21 13:11:47,221:INFO:Logging name: exp_A
2023-10-21 13:11:47,221:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-21 13:11:47,221:INFO:version 3.1.0
2023-10-21 13:11:47,221:INFO:Initializing setup()
2023-10-21 13:11:47,221:INFO:self.USI: 1fbb
2023-10-21 13:11:47,221:INFO:self._variable_keys: {'transform_target_param', 'exp_name_log', 'y_train', 'logging_param', 'n_jobs_param', 'X_train', 'target_param', 'USI', 'gpu_n_jobs_param', 'fold_groups_param', '_ml_usecase', 'seed', 'fold_generator', 'idx', 'html_param', 'log_plots_param', 'y', 'gpu_param', 'X_test', 'memory', 'y_test', 'data', 'X', 'exp_id', '_available_plots', 'fold_shuffle_param', 'pipeline'}
2023-10-21 13:11:47,221:INFO:Checking environment
2023-10-21 13:11:47,221:INFO:python_version: 3.8.18
2023-10-21 13:11:47,221:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-21 13:11:47,221:INFO:machine: AMD64
2023-10-21 13:11:47,221:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-21 13:11:47,221:INFO:Memory: svmem(total=16505954304, available=4054556672, percent=75.4, used=12451397632, free=4054556672)
2023-10-21 13:11:47,221:INFO:Physical Core: 8
2023-10-21 13:11:47,221:INFO:Logical Core: 16
2023-10-21 13:11:47,221:INFO:Checking libraries
2023-10-21 13:11:47,221:INFO:System:
2023-10-21 13:11:47,221:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-21 13:11:47,221:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-21 13:11:47,221:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-21 13:11:47,221:INFO:PyCaret required dependencies:
2023-10-21 13:11:47,221:INFO:                 pip: 23.3
2023-10-21 13:11:47,221:INFO:          setuptools: 68.0.0
2023-10-21 13:11:47,221:INFO:             pycaret: 3.1.0
2023-10-21 13:11:47,221:INFO:             IPython: 8.12.0
2023-10-21 13:11:47,221:INFO:          ipywidgets: 8.1.1
2023-10-21 13:11:47,221:INFO:                tqdm: 4.66.1
2023-10-21 13:11:47,221:INFO:               numpy: 1.23.5
2023-10-21 13:11:47,221:INFO:              pandas: 1.5.3
2023-10-21 13:11:47,221:INFO:              jinja2: 3.1.2
2023-10-21 13:11:47,221:INFO:               scipy: 1.10.1
2023-10-21 13:11:47,221:INFO:              joblib: 1.3.2
2023-10-21 13:11:47,221:INFO:             sklearn: 1.2.2
2023-10-21 13:11:47,221:INFO:                pyod: 1.1.0
2023-10-21 13:11:47,221:INFO:            imblearn: 0.11.0
2023-10-21 13:11:47,221:INFO:   category_encoders: 2.6.2
2023-10-21 13:11:47,221:INFO:            lightgbm: 4.1.0
2023-10-21 13:11:47,221:INFO:               numba: 0.58.1
2023-10-21 13:11:47,221:INFO:            requests: 2.31.0
2023-10-21 13:11:47,221:INFO:          matplotlib: 3.7.3
2023-10-21 13:11:47,221:INFO:          scikitplot: 0.3.7
2023-10-21 13:11:47,221:INFO:         yellowbrick: 1.5
2023-10-21 13:11:47,221:INFO:              plotly: 5.17.0
2023-10-21 13:11:47,221:INFO:    plotly-resampler: Not installed
2023-10-21 13:11:47,221:INFO:             kaleido: 0.2.1
2023-10-21 13:11:47,221:INFO:           schemdraw: 0.15
2023-10-21 13:11:47,221:INFO:         statsmodels: 0.14.0
2023-10-21 13:11:47,221:INFO:              sktime: 0.21.1
2023-10-21 13:11:47,221:INFO:               tbats: 1.1.3
2023-10-21 13:11:47,221:INFO:            pmdarima: 2.0.3
2023-10-21 13:11:47,221:INFO:              psutil: 5.9.0
2023-10-21 13:11:47,221:INFO:          markupsafe: 2.1.3
2023-10-21 13:11:47,221:INFO:             pickle5: Not installed
2023-10-21 13:11:47,221:INFO:         cloudpickle: 2.2.1
2023-10-21 13:11:47,221:INFO:         deprecation: 2.1.0
2023-10-21 13:11:47,221:INFO:              xxhash: 3.4.1
2023-10-21 13:11:47,221:INFO:           wurlitzer: Not installed
2023-10-21 13:11:47,221:INFO:PyCaret optional dependencies:
2023-10-21 13:11:47,221:INFO:                shap: Not installed
2023-10-21 13:11:47,221:INFO:           interpret: Not installed
2023-10-21 13:11:47,221:INFO:                umap: Not installed
2023-10-21 13:11:47,221:INFO:     ydata_profiling: Not installed
2023-10-21 13:11:47,221:INFO:  explainerdashboard: Not installed
2023-10-21 13:11:47,221:INFO:             autoviz: Not installed
2023-10-21 13:11:47,221:INFO:           fairlearn: Not installed
2023-10-21 13:11:47,221:INFO:          deepchecks: Not installed
2023-10-21 13:11:47,221:INFO:             xgboost: Not installed
2023-10-21 13:11:47,221:INFO:            catboost: 1.2.2
2023-10-21 13:11:47,221:INFO:              kmodes: Not installed
2023-10-21 13:11:47,221:INFO:             mlxtend: Not installed
2023-10-21 13:11:47,221:INFO:       statsforecast: Not installed
2023-10-21 13:11:47,221:INFO:        tune_sklearn: Not installed
2023-10-21 13:11:47,221:INFO:                 ray: Not installed
2023-10-21 13:11:47,221:INFO:            hyperopt: Not installed
2023-10-21 13:11:47,221:INFO:              optuna: Not installed
2023-10-21 13:11:47,221:INFO:               skopt: Not installed
2023-10-21 13:11:47,221:INFO:              mlflow: 2.7.1
2023-10-21 13:11:47,221:INFO:              gradio: Not installed
2023-10-21 13:11:47,221:INFO:             fastapi: Not installed
2023-10-21 13:11:47,221:INFO:             uvicorn: Not installed
2023-10-21 13:11:47,221:INFO:              m2cgen: Not installed
2023-10-21 13:11:47,221:INFO:           evidently: Not installed
2023-10-21 13:11:47,221:INFO:               fugue: Not installed
2023-10-21 13:11:47,221:INFO:           streamlit: Not installed
2023-10-21 13:11:47,221:INFO:             prophet: Not installed
2023-10-21 13:11:47,221:INFO:None
2023-10-21 13:11:47,221:INFO:Set up data.
2023-10-21 13:11:47,268:INFO:Set up folding strategy.
2023-10-21 13:11:47,268:INFO:Set up train/test split.
2023-10-21 13:11:47,312:INFO:Set up index.
2023-10-21 13:11:47,315:INFO:Assigning column types.
2023-10-21 13:11:47,347:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-21 13:11:47,347:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,347:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,347:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,442:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,512:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,512:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:11:47,512:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:11:47,512:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,521:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,521:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,616:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,679:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,679:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:11:47,679:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:11:47,679:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-21 13:11:47,695:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,695:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,790:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,838:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,838:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:11:47,838:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:11:47,854:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,854:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,949:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:11:48,013:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:11:48,028:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:11:48,028:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:11:48,028:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-21 13:11:48,044:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:11:48,145:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:11:48,194:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:11:48,195:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:11:48,195:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:11:48,206:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:11:48,279:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:11:48,329:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:11:48,329:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:11:48,329:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:11:48,329:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-21 13:11:48,428:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:11:48,487:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:11:48,487:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:11:48,488:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:11:48,578:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:11:48,629:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:11:48,629:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:11:48,629:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:11:48,629:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-21 13:11:48,730:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:11:48,787:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:11:48,787:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:11:48,884:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:11:48,942:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:11:48,942:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:11:48,943:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-21 13:11:49,113:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:11:49,114:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:11:49,283:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:11:49,283:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:11:49,283:INFO:Preparing preprocessing pipeline...
2023-10-21 13:11:49,283:INFO:Set up simple imputation.
2023-10-21 13:11:49,298:INFO:Set up column name cleaning.
2023-10-21 13:11:49,377:INFO:Finished creating preprocessing pipeline.
2023-10-21 13:11:49,393:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 13:11:49,393:INFO:Creating final display dataframe.
2023-10-21 13:11:49,720:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (34061, 50)
4        Transformed data shape   (34061, 50)
5   Transformed train set shape   (23842, 50)
6    Transformed test set shape   (10219, 50)
7              Numeric features            49
8      Rows with missing values         97.6%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_A
19                          USI          1fbb
2023-10-21 13:11:49,914:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:11:49,914:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:11:50,077:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:11:50,077:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:11:50,077:INFO:Logging experiment in loggers
2023-10-21 13:11:50,244:INFO:SubProcess save_model() called ==================================
2023-10-21 13:11:50,249:INFO:Initializing save_model()
2023-10-21 13:11:50,249:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmphuo33fa3\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 13:11:50,249:INFO:Adding model into prep_pipe
2023-10-21 13:11:50,249:WARNING:Only Model saved as it was a pipeline.
2023-10-21 13:11:50,262:INFO:C:\Users\thoma\AppData\Local\Temp\tmphuo33fa3\Transformation Pipeline.pkl saved in current working directory
2023-10-21 13:11:50,265:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 13:11:50,265:INFO:save_model() successfully completed......................................
2023-10-21 13:11:50,469:INFO:SubProcess save_model() end ==================================
2023-10-21 13:11:50,562:INFO:setup() successfully completed in 2.87s...............
2023-10-21 13:11:50,562:INFO:Initializing create_model()
2023-10-21 13:11:50,562:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6CC2520>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 13:11:50,562:INFO:Checking exceptions
2023-10-21 13:11:50,562:INFO:Importing libraries
2023-10-21 13:11:50,562:INFO:Copying training dataset
2023-10-21 13:11:50,593:INFO:Defining folds
2023-10-21 13:11:50,593:INFO:Declaring metric variables
2023-10-21 13:11:50,593:INFO:Importing untrained model
2023-10-21 13:11:50,595:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 13:11:50,595:INFO:Starting cross validation
2023-10-21 13:11:50,595:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 13:12:00,954:INFO:Calculating mean and std
2023-10-21 13:12:00,954:INFO:Creating metrics dataframe
2023-10-21 13:12:00,954:INFO:Finalizing model
2023-10-21 13:12:01,052:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006269 seconds.
2023-10-21 13:12:01,052:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 13:12:01,052:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 13:12:01,052:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 13:12:01,052:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-21 13:12:01,286:INFO:Creating Dashboard logs
2023-10-21 13:12:01,286:INFO:Model: Light Gradient Boosting Machine
2023-10-21 13:12:01,386:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 13:12:01,586:INFO:Initializing predict_model()
2023-10-21 13:12:01,586:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6CC2520>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DA6C63A0>)
2023-10-21 13:12:01,586:INFO:Checking exceptions
2023-10-21 13:12:01,586:INFO:Preloading libraries
2023-10-21 13:12:02,250:INFO:Uploading results into container
2023-10-21 13:12:02,250:INFO:Uploading model into container now
2023-10-21 13:12:02,250:INFO:_master_model_container: 1
2023-10-21 13:12:02,250:INFO:_display_container: 2
2023-10-21 13:12:02,250:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 13:12:02,250:INFO:create_model() successfully completed......................................
2023-10-21 13:12:02,433:INFO:Initializing tune_model()
2023-10-21 13:12:02,433:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6CC2520>)
2023-10-21 13:12:02,433:INFO:Checking exceptions
2023-10-21 13:12:02,434:INFO:Copying training dataset
2023-10-21 13:12:02,460:INFO:Checking base model
2023-10-21 13:12:02,461:INFO:Base model : Light Gradient Boosting Machine
2023-10-21 13:12:02,461:INFO:Declaring metric variables
2023-10-21 13:12:02,461:INFO:Defining Hyperparameters
2023-10-21 13:12:02,666:INFO:Tuning with n_jobs=-1
2023-10-21 13:12:02,667:INFO:Initializing RandomizedSearchCV
2023-10-21 13:13:00,964:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-21 13:13:00,964:INFO:Hyperparameter search completed
2023-10-21 13:13:00,964:INFO:SubProcess create_model() called ==================================
2023-10-21 13:13:00,967:INFO:Initializing create_model()
2023-10-21 13:13:00,968:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6CC2520>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209DAB65AF0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-21 13:13:00,968:INFO:Checking exceptions
2023-10-21 13:13:00,968:INFO:Importing libraries
2023-10-21 13:13:00,968:INFO:Copying training dataset
2023-10-21 13:13:01,003:INFO:Defining folds
2023-10-21 13:13:01,004:INFO:Declaring metric variables
2023-10-21 13:13:01,004:INFO:Importing untrained model
2023-10-21 13:13:01,004:INFO:Declaring custom model
2023-10-21 13:13:01,006:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 13:13:01,006:INFO:Starting cross validation
2023-10-21 13:13:01,008:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 13:13:10,401:INFO:Calculating mean and std
2023-10-21 13:13:10,401:INFO:Creating metrics dataframe
2023-10-21 13:13:10,401:INFO:Finalizing model
2023-10-21 13:13:10,476:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 13:13:10,476:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 13:13:10,476:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 13:13:10,514:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 13:13:10,514:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 13:13:10,514:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 13:13:10,529:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007281 seconds.
2023-10-21 13:13:10,529:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 13:13:10,529:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 13:13:10,529:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 13:13:10,529:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-21 13:13:11,809:INFO:Uploading results into container
2023-10-21 13:13:11,809:INFO:Uploading model into container now
2023-10-21 13:13:11,809:INFO:_master_model_container: 2
2023-10-21 13:13:11,809:INFO:_display_container: 3
2023-10-21 13:13:11,809:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-21 13:13:11,809:INFO:create_model() successfully completed......................................
2023-10-21 13:13:12,024:INFO:SubProcess create_model() end ==================================
2023-10-21 13:13:12,024:INFO:choose_better activated
2023-10-21 13:13:12,025:INFO:SubProcess create_model() called ==================================
2023-10-21 13:13:12,026:INFO:Initializing create_model()
2023-10-21 13:13:12,026:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6CC2520>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 13:13:12,026:INFO:Checking exceptions
2023-10-21 13:13:12,026:INFO:Importing libraries
2023-10-21 13:13:12,026:INFO:Copying training dataset
2023-10-21 13:13:12,046:INFO:Defining folds
2023-10-21 13:13:12,046:INFO:Declaring metric variables
2023-10-21 13:13:12,046:INFO:Importing untrained model
2023-10-21 13:13:12,046:INFO:Declaring custom model
2023-10-21 13:13:12,046:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 13:13:12,046:INFO:Starting cross validation
2023-10-21 13:13:12,046:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 13:13:15,290:INFO:Calculating mean and std
2023-10-21 13:13:15,290:INFO:Creating metrics dataframe
2023-10-21 13:13:15,290:INFO:Finalizing model
2023-10-21 13:13:15,389:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006151 seconds.
2023-10-21 13:13:15,389:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 13:13:15,389:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 13:13:15,389:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 13:13:15,389:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-21 13:13:15,641:INFO:Uploading results into container
2023-10-21 13:13:15,642:INFO:Uploading model into container now
2023-10-21 13:13:15,643:INFO:_master_model_container: 3
2023-10-21 13:13:15,643:INFO:_display_container: 4
2023-10-21 13:13:15,644:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 13:13:15,644:INFO:create_model() successfully completed......................................
2023-10-21 13:13:15,847:INFO:SubProcess create_model() end ==================================
2023-10-21 13:13:15,848:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8716
2023-10-21 13:13:15,848:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8712
2023-10-21 13:13:15,849:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-21 13:13:15,849:INFO:choose_better completed
2023-10-21 13:13:15,849:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-21 13:13:15,849:INFO:Creating Dashboard logs
2023-10-21 13:13:15,850:INFO:Model: Light Gradient Boosting Machine
2023-10-21 13:13:15,909:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 13:13:16,081:INFO:Initializing predict_model()
2023-10-21 13:13:16,081:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6CC2520>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DA6C6550>)
2023-10-21 13:13:16,081:INFO:Checking exceptions
2023-10-21 13:13:16,081:INFO:Preloading libraries
2023-10-21 13:13:16,704:INFO:_master_model_container: 3
2023-10-21 13:13:16,704:INFO:_display_container: 3
2023-10-21 13:13:16,704:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 13:13:16,704:INFO:tune_model() successfully completed......................................
2023-10-21 13:13:16,888:INFO:Initializing finalize_model()
2023-10-21 13:13:16,888:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6CC2520>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-21 13:13:16,888:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 13:13:16,888:INFO:Initializing create_model()
2023-10-21 13:13:16,888:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6CC2520>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-21 13:13:16,888:INFO:Checking exceptions
2023-10-21 13:13:16,904:INFO:Importing libraries
2023-10-21 13:13:16,904:INFO:Copying training dataset
2023-10-21 13:13:16,904:INFO:Defining folds
2023-10-21 13:13:16,904:INFO:Declaring metric variables
2023-10-21 13:13:16,904:INFO:Importing untrained model
2023-10-21 13:13:16,904:INFO:Declaring custom model
2023-10-21 13:13:16,904:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 13:13:16,904:INFO:Cross validation set to False
2023-10-21 13:13:16,904:INFO:Fitting Model
2023-10-21 13:13:17,020:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007974 seconds.
2023-10-21 13:13:17,020:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 13:13:17,020:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-21 13:13:17,020:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-21 13:13:17,020:INFO:[LightGBM] [Info] Start training from score 631.011165
2023-10-21 13:13:17,376:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-21 13:13:17,376:INFO:create_model() successfully completed......................................
2023-10-21 13:13:17,574:INFO:Creating Dashboard logs
2023-10-21 13:13:17,574:INFO:Model: Light Gradient Boosting Machine
2023-10-21 13:13:17,622:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 13:13:17,990:INFO:_master_model_container: 3
2023-10-21 13:13:17,990:INFO:_display_container: 3
2023-10-21 13:13:18,006:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-21 13:13:18,006:INFO:finalize_model() successfully completed......................................
2023-10-21 13:13:18,186:INFO:Initializing save_model()
2023-10-21 13:13:18,186:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_A, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 13:13:18,186:INFO:Adding model into prep_pipe
2023-10-21 13:13:18,186:WARNING:Only Model saved as it was a pipeline.
2023-10-21 13:13:18,210:INFO:final_model_for_location_A.pkl saved in current working directory
2023-10-21 13:13:18,225:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-21 13:13:18,225:INFO:save_model() successfully completed......................................
2023-10-21 13:13:18,439:INFO:PyCaret RegressionExperiment
2023-10-21 13:13:18,439:INFO:Logging name: exp_B
2023-10-21 13:13:18,439:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-21 13:13:18,439:INFO:version 3.1.0
2023-10-21 13:13:18,439:INFO:Initializing setup()
2023-10-21 13:13:18,439:INFO:self.USI: 9f74
2023-10-21 13:13:18,439:INFO:self._variable_keys: {'transform_target_param', 'exp_name_log', 'y_train', 'logging_param', 'n_jobs_param', 'X_train', 'target_param', 'USI', 'gpu_n_jobs_param', 'fold_groups_param', '_ml_usecase', 'seed', 'fold_generator', 'idx', 'html_param', 'log_plots_param', 'y', 'gpu_param', 'X_test', 'memory', 'y_test', 'data', 'X', 'exp_id', '_available_plots', 'fold_shuffle_param', 'pipeline'}
2023-10-21 13:13:18,439:INFO:Checking environment
2023-10-21 13:13:18,439:INFO:python_version: 3.8.18
2023-10-21 13:13:18,439:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-21 13:13:18,439:INFO:machine: AMD64
2023-10-21 13:13:18,439:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-21 13:13:18,439:INFO:Memory: svmem(total=16505954304, available=3044720640, percent=81.6, used=13461233664, free=3044720640)
2023-10-21 13:13:18,439:INFO:Physical Core: 8
2023-10-21 13:13:18,439:INFO:Logical Core: 16
2023-10-21 13:13:18,439:INFO:Checking libraries
2023-10-21 13:13:18,439:INFO:System:
2023-10-21 13:13:18,439:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-21 13:13:18,439:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-21 13:13:18,439:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-21 13:13:18,439:INFO:PyCaret required dependencies:
2023-10-21 13:13:18,439:INFO:                 pip: 23.3
2023-10-21 13:13:18,439:INFO:          setuptools: 68.0.0
2023-10-21 13:13:18,439:INFO:             pycaret: 3.1.0
2023-10-21 13:13:18,439:INFO:             IPython: 8.12.0
2023-10-21 13:13:18,439:INFO:          ipywidgets: 8.1.1
2023-10-21 13:13:18,439:INFO:                tqdm: 4.66.1
2023-10-21 13:13:18,439:INFO:               numpy: 1.23.5
2023-10-21 13:13:18,439:INFO:              pandas: 1.5.3
2023-10-21 13:13:18,439:INFO:              jinja2: 3.1.2
2023-10-21 13:13:18,439:INFO:               scipy: 1.10.1
2023-10-21 13:13:18,439:INFO:              joblib: 1.3.2
2023-10-21 13:13:18,439:INFO:             sklearn: 1.2.2
2023-10-21 13:13:18,439:INFO:                pyod: 1.1.0
2023-10-21 13:13:18,439:INFO:            imblearn: 0.11.0
2023-10-21 13:13:18,439:INFO:   category_encoders: 2.6.2
2023-10-21 13:13:18,439:INFO:            lightgbm: 4.1.0
2023-10-21 13:13:18,439:INFO:               numba: 0.58.1
2023-10-21 13:13:18,439:INFO:            requests: 2.31.0
2023-10-21 13:13:18,439:INFO:          matplotlib: 3.7.3
2023-10-21 13:13:18,439:INFO:          scikitplot: 0.3.7
2023-10-21 13:13:18,439:INFO:         yellowbrick: 1.5
2023-10-21 13:13:18,439:INFO:              plotly: 5.17.0
2023-10-21 13:13:18,439:INFO:    plotly-resampler: Not installed
2023-10-21 13:13:18,439:INFO:             kaleido: 0.2.1
2023-10-21 13:13:18,439:INFO:           schemdraw: 0.15
2023-10-21 13:13:18,439:INFO:         statsmodels: 0.14.0
2023-10-21 13:13:18,439:INFO:              sktime: 0.21.1
2023-10-21 13:13:18,439:INFO:               tbats: 1.1.3
2023-10-21 13:13:18,439:INFO:            pmdarima: 2.0.3
2023-10-21 13:13:18,439:INFO:              psutil: 5.9.0
2023-10-21 13:13:18,439:INFO:          markupsafe: 2.1.3
2023-10-21 13:13:18,439:INFO:             pickle5: Not installed
2023-10-21 13:13:18,439:INFO:         cloudpickle: 2.2.1
2023-10-21 13:13:18,439:INFO:         deprecation: 2.1.0
2023-10-21 13:13:18,439:INFO:              xxhash: 3.4.1
2023-10-21 13:13:18,439:INFO:           wurlitzer: Not installed
2023-10-21 13:13:18,439:INFO:PyCaret optional dependencies:
2023-10-21 13:13:18,439:INFO:                shap: Not installed
2023-10-21 13:13:18,439:INFO:           interpret: Not installed
2023-10-21 13:13:18,439:INFO:                umap: Not installed
2023-10-21 13:13:18,439:INFO:     ydata_profiling: Not installed
2023-10-21 13:13:18,439:INFO:  explainerdashboard: Not installed
2023-10-21 13:13:18,439:INFO:             autoviz: Not installed
2023-10-21 13:13:18,439:INFO:           fairlearn: Not installed
2023-10-21 13:13:18,439:INFO:          deepchecks: Not installed
2023-10-21 13:13:18,439:INFO:             xgboost: Not installed
2023-10-21 13:13:18,439:INFO:            catboost: 1.2.2
2023-10-21 13:13:18,439:INFO:              kmodes: Not installed
2023-10-21 13:13:18,439:INFO:             mlxtend: Not installed
2023-10-21 13:13:18,439:INFO:       statsforecast: Not installed
2023-10-21 13:13:18,439:INFO:        tune_sklearn: Not installed
2023-10-21 13:13:18,439:INFO:                 ray: Not installed
2023-10-21 13:13:18,439:INFO:            hyperopt: Not installed
2023-10-21 13:13:18,439:INFO:              optuna: Not installed
2023-10-21 13:13:18,439:INFO:               skopt: Not installed
2023-10-21 13:13:18,439:INFO:              mlflow: 2.7.1
2023-10-21 13:13:18,439:INFO:              gradio: Not installed
2023-10-21 13:13:18,439:INFO:             fastapi: Not installed
2023-10-21 13:13:18,439:INFO:             uvicorn: Not installed
2023-10-21 13:13:18,439:INFO:              m2cgen: Not installed
2023-10-21 13:13:18,439:INFO:           evidently: Not installed
2023-10-21 13:13:18,439:INFO:               fugue: Not installed
2023-10-21 13:13:18,439:INFO:           streamlit: Not installed
2023-10-21 13:13:18,439:INFO:             prophet: Not installed
2023-10-21 13:13:18,439:INFO:None
2023-10-21 13:13:18,439:INFO:Set up data.
2023-10-21 13:13:18,479:INFO:Set up folding strategy.
2023-10-21 13:13:18,479:INFO:Set up train/test split.
2023-10-21 13:13:18,507:INFO:Set up index.
2023-10-21 13:13:18,509:INFO:Assigning column types.
2023-10-21 13:13:18,533:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-21 13:13:18,533:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 13:13:18,539:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 13:13:18,545:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:13:18,627:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:13:18,679:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:13:18,680:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:13:18,680:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:13:18,681:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 13:13:18,686:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 13:13:18,692:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:13:18,772:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:13:18,819:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:13:18,819:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:13:18,819:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:13:18,819:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-21 13:13:18,819:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 13:13:18,835:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:13:18,902:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:13:18,955:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:13:18,955:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:13:18,955:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:13:18,955:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 13:13:18,971:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:13:19,053:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:13:19,106:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:13:19,107:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:13:19,107:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:13:19,108:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-21 13:13:19,119:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:13:19,191:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:13:19,256:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:13:19,257:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:13:19,257:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:13:19,269:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:13:19,350:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:13:19,392:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:13:19,392:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:13:19,392:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:13:19,392:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-21 13:13:19,495:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:13:19,561:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:13:19,562:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:13:19,562:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:13:19,666:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:13:19,719:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:13:19,719:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:13:19,720:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:13:19,720:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-21 13:13:19,804:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:13:19,870:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:13:19,870:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:13:19,975:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:13:20,035:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:13:20,036:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:13:20,036:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-21 13:13:20,190:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:13:20,190:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:13:20,336:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:13:20,336:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:13:20,350:INFO:Preparing preprocessing pipeline...
2023-10-21 13:13:20,351:INFO:Set up simple imputation.
2023-10-21 13:13:20,355:INFO:Set up column name cleaning.
2023-10-21 13:13:20,419:INFO:Finished creating preprocessing pipeline.
2023-10-21 13:13:20,423:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 13:13:20,423:INFO:Creating final display dataframe.
2023-10-21 13:13:20,619:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (32819, 50)
4        Transformed data shape   (32819, 50)
5   Transformed train set shape   (22973, 50)
6    Transformed test set shape    (9846, 50)
7              Numeric features            49
8      Rows with missing values         95.9%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_B
19                          USI          9f74
2023-10-21 13:13:20,771:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:13:20,771:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:13:20,917:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:13:20,917:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:13:20,917:INFO:Logging experiment in loggers
2023-10-21 13:13:21,032:INFO:SubProcess save_model() called ==================================
2023-10-21 13:13:21,032:INFO:Initializing save_model()
2023-10-21 13:13:21,032:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmpiturykv6\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 13:13:21,032:INFO:Adding model into prep_pipe
2023-10-21 13:13:21,032:WARNING:Only Model saved as it was a pipeline.
2023-10-21 13:13:21,047:INFO:C:\Users\thoma\AppData\Local\Temp\tmpiturykv6\Transformation Pipeline.pkl saved in current working directory
2023-10-21 13:13:21,047:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 13:13:21,047:INFO:save_model() successfully completed......................................
2023-10-21 13:13:21,235:INFO:SubProcess save_model() end ==================================
2023-10-21 13:13:21,287:INFO:setup() successfully completed in 2.48s...............
2023-10-21 13:13:21,287:INFO:Initializing create_model()
2023-10-21 13:13:21,287:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAB65940>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 13:13:21,287:INFO:Checking exceptions
2023-10-21 13:13:21,303:INFO:Importing libraries
2023-10-21 13:13:21,303:INFO:Copying training dataset
2023-10-21 13:13:21,327:INFO:Defining folds
2023-10-21 13:13:21,327:INFO:Declaring metric variables
2023-10-21 13:13:21,327:INFO:Importing untrained model
2023-10-21 13:13:21,327:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 13:13:21,327:INFO:Starting cross validation
2023-10-21 13:13:21,327:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 13:13:24,373:INFO:Calculating mean and std
2023-10-21 13:13:24,373:INFO:Creating metrics dataframe
2023-10-21 13:13:24,373:INFO:Finalizing model
2023-10-21 13:13:24,472:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005085 seconds.
2023-10-21 13:13:24,472:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 13:13:24,473:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 13:13:24,473:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 13:13:24,474:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-21 13:13:24,733:INFO:Creating Dashboard logs
2023-10-21 13:13:24,733:INFO:Model: Light Gradient Boosting Machine
2023-10-21 13:13:24,831:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 13:13:25,049:INFO:Initializing predict_model()
2023-10-21 13:13:25,049:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAB65940>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209D98B01F0>)
2023-10-21 13:13:25,049:INFO:Checking exceptions
2023-10-21 13:13:25,049:INFO:Preloading libraries
2023-10-21 13:13:25,816:INFO:Uploading results into container
2023-10-21 13:13:25,816:INFO:Uploading model into container now
2023-10-21 13:13:25,816:INFO:_master_model_container: 1
2023-10-21 13:13:25,816:INFO:_display_container: 2
2023-10-21 13:13:25,816:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 13:13:25,816:INFO:create_model() successfully completed......................................
2023-10-21 13:13:26,033:INFO:Initializing tune_model()
2023-10-21 13:13:26,033:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAB65940>)
2023-10-21 13:13:26,033:INFO:Checking exceptions
2023-10-21 13:13:26,048:INFO:Copying training dataset
2023-10-21 13:13:26,065:INFO:Checking base model
2023-10-21 13:13:26,065:INFO:Base model : Light Gradient Boosting Machine
2023-10-21 13:13:26,065:INFO:Declaring metric variables
2023-10-21 13:13:26,065:INFO:Defining Hyperparameters
2023-10-21 13:13:26,271:INFO:Tuning with n_jobs=-1
2023-10-21 13:13:26,271:INFO:Initializing RandomizedSearchCV
2023-10-21 13:14:17,771:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-21 13:14:17,771:INFO:Hyperparameter search completed
2023-10-21 13:14:17,771:INFO:SubProcess create_model() called ==================================
2023-10-21 13:14:17,771:INFO:Initializing create_model()
2023-10-21 13:14:17,771:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAB65940>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209DCBE0D90>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-21 13:14:17,771:INFO:Checking exceptions
2023-10-21 13:14:17,771:INFO:Importing libraries
2023-10-21 13:14:17,771:INFO:Copying training dataset
2023-10-21 13:14:17,788:INFO:Defining folds
2023-10-21 13:14:17,788:INFO:Declaring metric variables
2023-10-21 13:14:17,788:INFO:Importing untrained model
2023-10-21 13:14:17,788:INFO:Declaring custom model
2023-10-21 13:14:17,803:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 13:14:17,803:INFO:Starting cross validation
2023-10-21 13:14:17,804:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 13:14:27,280:INFO:Calculating mean and std
2023-10-21 13:14:27,280:INFO:Creating metrics dataframe
2023-10-21 13:14:27,280:INFO:Finalizing model
2023-10-21 13:14:27,346:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 13:14:27,346:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 13:14:27,346:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 13:14:27,380:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 13:14:27,380:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 13:14:27,380:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 13:14:27,397:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005985 seconds.
2023-10-21 13:14:27,397:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 13:14:27,397:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 13:14:27,397:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 13:14:27,397:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-21 13:14:28,840:INFO:Uploading results into container
2023-10-21 13:14:28,840:INFO:Uploading model into container now
2023-10-21 13:14:28,840:INFO:_master_model_container: 2
2023-10-21 13:14:28,840:INFO:_display_container: 3
2023-10-21 13:14:28,840:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-21 13:14:28,840:INFO:create_model() successfully completed......................................
2023-10-21 13:14:29,060:INFO:SubProcess create_model() end ==================================
2023-10-21 13:14:29,060:INFO:choose_better activated
2023-10-21 13:14:29,060:INFO:SubProcess create_model() called ==================================
2023-10-21 13:14:29,060:INFO:Initializing create_model()
2023-10-21 13:14:29,060:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAB65940>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 13:14:29,060:INFO:Checking exceptions
2023-10-21 13:14:29,060:INFO:Importing libraries
2023-10-21 13:14:29,060:INFO:Copying training dataset
2023-10-21 13:14:29,091:INFO:Defining folds
2023-10-21 13:14:29,091:INFO:Declaring metric variables
2023-10-21 13:14:29,091:INFO:Importing untrained model
2023-10-21 13:14:29,091:INFO:Declaring custom model
2023-10-21 13:14:29,091:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 13:14:29,091:INFO:Starting cross validation
2023-10-21 13:14:29,091:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 13:14:31,610:INFO:Calculating mean and std
2023-10-21 13:14:31,610:INFO:Creating metrics dataframe
2023-10-21 13:14:31,610:INFO:Finalizing model
2023-10-21 13:14:31,693:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004877 seconds.
2023-10-21 13:14:31,693:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 13:14:31,693:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 13:14:31,693:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 13:14:31,693:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-21 13:14:31,926:INFO:Uploading results into container
2023-10-21 13:14:31,926:INFO:Uploading model into container now
2023-10-21 13:14:31,936:INFO:_master_model_container: 3
2023-10-21 13:14:31,936:INFO:_display_container: 4
2023-10-21 13:14:31,936:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 13:14:31,936:INFO:create_model() successfully completed......................................
2023-10-21 13:14:32,126:INFO:SubProcess create_model() end ==================================
2023-10-21 13:14:32,137:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8523
2023-10-21 13:14:32,137:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8523
2023-10-21 13:14:32,137:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-21 13:14:32,137:INFO:choose_better completed
2023-10-21 13:14:32,137:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-21 13:14:32,137:INFO:Creating Dashboard logs
2023-10-21 13:14:32,137:INFO:Model: Light Gradient Boosting Machine
2023-10-21 13:14:32,195:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 13:14:32,392:INFO:Initializing predict_model()
2023-10-21 13:14:32,392:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAB65940>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209D98B0AF0>)
2023-10-21 13:14:32,392:INFO:Checking exceptions
2023-10-21 13:14:32,392:INFO:Preloading libraries
2023-10-21 13:14:33,041:INFO:_master_model_container: 3
2023-10-21 13:14:33,041:INFO:_display_container: 3
2023-10-21 13:14:33,041:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 13:14:33,041:INFO:tune_model() successfully completed......................................
2023-10-21 13:14:33,208:INFO:Initializing finalize_model()
2023-10-21 13:14:33,208:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAB65940>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-21 13:14:33,208:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 13:14:33,225:INFO:Initializing create_model()
2023-10-21 13:14:33,225:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAB65940>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-21 13:14:33,225:INFO:Checking exceptions
2023-10-21 13:14:33,225:INFO:Importing libraries
2023-10-21 13:14:33,225:INFO:Copying training dataset
2023-10-21 13:14:33,238:INFO:Defining folds
2023-10-21 13:14:33,238:INFO:Declaring metric variables
2023-10-21 13:14:33,238:INFO:Importing untrained model
2023-10-21 13:14:33,238:INFO:Declaring custom model
2023-10-21 13:14:33,238:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 13:14:33,240:INFO:Cross validation set to False
2023-10-21 13:14:33,240:INFO:Fitting Model
2023-10-21 13:14:33,366:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009484 seconds.
2023-10-21 13:14:33,366:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 13:14:33,367:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-21 13:14:33,368:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-21 13:14:33,369:INFO:[LightGBM] [Info] Start training from score 96.893335
2023-10-21 13:14:33,658:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-21 13:14:33,658:INFO:create_model() successfully completed......................................
2023-10-21 13:14:33,874:INFO:Creating Dashboard logs
2023-10-21 13:14:33,874:INFO:Model: Light Gradient Boosting Machine
2023-10-21 13:14:33,942:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 13:14:34,358:INFO:_master_model_container: 3
2023-10-21 13:14:34,358:INFO:_display_container: 3
2023-10-21 13:14:34,373:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-21 13:14:34,373:INFO:finalize_model() successfully completed......................................
2023-10-21 13:14:34,557:INFO:Initializing save_model()
2023-10-21 13:14:34,557:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_B, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 13:14:34,557:INFO:Adding model into prep_pipe
2023-10-21 13:14:34,557:WARNING:Only Model saved as it was a pipeline.
2023-10-21 13:14:34,557:INFO:final_model_for_location_B.pkl saved in current working directory
2023-10-21 13:14:34,574:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-21 13:14:34,574:INFO:save_model() successfully completed......................................
2023-10-21 13:14:34,790:INFO:PyCaret RegressionExperiment
2023-10-21 13:14:34,790:INFO:Logging name: exp_C
2023-10-21 13:14:34,790:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-21 13:14:34,790:INFO:version 3.1.0
2023-10-21 13:14:34,790:INFO:Initializing setup()
2023-10-21 13:14:34,790:INFO:self.USI: f13b
2023-10-21 13:14:34,790:INFO:self._variable_keys: {'transform_target_param', 'exp_name_log', 'y_train', 'logging_param', 'n_jobs_param', 'X_train', 'target_param', 'USI', 'gpu_n_jobs_param', 'fold_groups_param', '_ml_usecase', 'seed', 'fold_generator', 'idx', 'html_param', 'log_plots_param', 'y', 'gpu_param', 'X_test', 'memory', 'y_test', 'data', 'X', 'exp_id', '_available_plots', 'fold_shuffle_param', 'pipeline'}
2023-10-21 13:14:34,790:INFO:Checking environment
2023-10-21 13:14:34,790:INFO:python_version: 3.8.18
2023-10-21 13:14:34,790:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-21 13:14:34,790:INFO:machine: AMD64
2023-10-21 13:14:34,790:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-21 13:14:34,790:INFO:Memory: svmem(total=16505954304, available=3200471040, percent=80.6, used=13305483264, free=3200471040)
2023-10-21 13:14:34,790:INFO:Physical Core: 8
2023-10-21 13:14:34,790:INFO:Logical Core: 16
2023-10-21 13:14:34,790:INFO:Checking libraries
2023-10-21 13:14:34,790:INFO:System:
2023-10-21 13:14:34,790:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-21 13:14:34,790:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-21 13:14:34,790:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-21 13:14:34,790:INFO:PyCaret required dependencies:
2023-10-21 13:14:34,790:INFO:                 pip: 23.3
2023-10-21 13:14:34,790:INFO:          setuptools: 68.0.0
2023-10-21 13:14:34,790:INFO:             pycaret: 3.1.0
2023-10-21 13:14:34,790:INFO:             IPython: 8.12.0
2023-10-21 13:14:34,790:INFO:          ipywidgets: 8.1.1
2023-10-21 13:14:34,790:INFO:                tqdm: 4.66.1
2023-10-21 13:14:34,790:INFO:               numpy: 1.23.5
2023-10-21 13:14:34,790:INFO:              pandas: 1.5.3
2023-10-21 13:14:34,790:INFO:              jinja2: 3.1.2
2023-10-21 13:14:34,790:INFO:               scipy: 1.10.1
2023-10-21 13:14:34,790:INFO:              joblib: 1.3.2
2023-10-21 13:14:34,790:INFO:             sklearn: 1.2.2
2023-10-21 13:14:34,790:INFO:                pyod: 1.1.0
2023-10-21 13:14:34,790:INFO:            imblearn: 0.11.0
2023-10-21 13:14:34,790:INFO:   category_encoders: 2.6.2
2023-10-21 13:14:34,790:INFO:            lightgbm: 4.1.0
2023-10-21 13:14:34,790:INFO:               numba: 0.58.1
2023-10-21 13:14:34,790:INFO:            requests: 2.31.0
2023-10-21 13:14:34,790:INFO:          matplotlib: 3.7.3
2023-10-21 13:14:34,790:INFO:          scikitplot: 0.3.7
2023-10-21 13:14:34,790:INFO:         yellowbrick: 1.5
2023-10-21 13:14:34,790:INFO:              plotly: 5.17.0
2023-10-21 13:14:34,790:INFO:    plotly-resampler: Not installed
2023-10-21 13:14:34,790:INFO:             kaleido: 0.2.1
2023-10-21 13:14:34,790:INFO:           schemdraw: 0.15
2023-10-21 13:14:34,790:INFO:         statsmodels: 0.14.0
2023-10-21 13:14:34,790:INFO:              sktime: 0.21.1
2023-10-21 13:14:34,790:INFO:               tbats: 1.1.3
2023-10-21 13:14:34,790:INFO:            pmdarima: 2.0.3
2023-10-21 13:14:34,790:INFO:              psutil: 5.9.0
2023-10-21 13:14:34,790:INFO:          markupsafe: 2.1.3
2023-10-21 13:14:34,790:INFO:             pickle5: Not installed
2023-10-21 13:14:34,790:INFO:         cloudpickle: 2.2.1
2023-10-21 13:14:34,790:INFO:         deprecation: 2.1.0
2023-10-21 13:14:34,790:INFO:              xxhash: 3.4.1
2023-10-21 13:14:34,790:INFO:           wurlitzer: Not installed
2023-10-21 13:14:34,790:INFO:PyCaret optional dependencies:
2023-10-21 13:14:34,790:INFO:                shap: Not installed
2023-10-21 13:14:34,790:INFO:           interpret: Not installed
2023-10-21 13:14:34,790:INFO:                umap: Not installed
2023-10-21 13:14:34,790:INFO:     ydata_profiling: Not installed
2023-10-21 13:14:34,790:INFO:  explainerdashboard: Not installed
2023-10-21 13:14:34,790:INFO:             autoviz: Not installed
2023-10-21 13:14:34,790:INFO:           fairlearn: Not installed
2023-10-21 13:14:34,790:INFO:          deepchecks: Not installed
2023-10-21 13:14:34,790:INFO:             xgboost: Not installed
2023-10-21 13:14:34,790:INFO:            catboost: 1.2.2
2023-10-21 13:14:34,790:INFO:              kmodes: Not installed
2023-10-21 13:14:34,790:INFO:             mlxtend: Not installed
2023-10-21 13:14:34,790:INFO:       statsforecast: Not installed
2023-10-21 13:14:34,790:INFO:        tune_sklearn: Not installed
2023-10-21 13:14:34,790:INFO:                 ray: Not installed
2023-10-21 13:14:34,790:INFO:            hyperopt: Not installed
2023-10-21 13:14:34,790:INFO:              optuna: Not installed
2023-10-21 13:14:34,790:INFO:               skopt: Not installed
2023-10-21 13:14:34,790:INFO:              mlflow: 2.7.1
2023-10-21 13:14:34,790:INFO:              gradio: Not installed
2023-10-21 13:14:34,790:INFO:             fastapi: Not installed
2023-10-21 13:14:34,790:INFO:             uvicorn: Not installed
2023-10-21 13:14:34,790:INFO:              m2cgen: Not installed
2023-10-21 13:14:34,790:INFO:           evidently: Not installed
2023-10-21 13:14:34,790:INFO:               fugue: Not installed
2023-10-21 13:14:34,790:INFO:           streamlit: Not installed
2023-10-21 13:14:34,790:INFO:             prophet: Not installed
2023-10-21 13:14:34,790:INFO:None
2023-10-21 13:14:34,790:INFO:Set up data.
2023-10-21 13:14:34,824:INFO:Set up folding strategy.
2023-10-21 13:14:34,824:INFO:Set up train/test split.
2023-10-21 13:14:34,852:INFO:Set up index.
2023-10-21 13:14:34,853:INFO:Assigning column types.
2023-10-21 13:14:34,857:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-21 13:14:34,857:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 13:14:34,873:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 13:14:34,873:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:14:34,956:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,007:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,007:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:14:35,007:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:14:35,007:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,007:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,007:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,090:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,147:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,148:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:14:35,148:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:14:35,148:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-21 13:14:35,154:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,156:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,223:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,273:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,287:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:14:35,287:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:14:35,290:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,290:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,373:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,423:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,423:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:14:35,423:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:14:35,423:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-21 13:14:35,445:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,506:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,556:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,572:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:14:35,573:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:14:35,573:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,656:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,706:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,706:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:14:35,706:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:14:35,706:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-21 13:14:35,790:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,847:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,848:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:14:35,848:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:14:35,923:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,988:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,988:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:14:35,989:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:14:35,989:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-21 13:14:36,072:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:14:36,123:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:14:36,123:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:14:36,206:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:14:36,255:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:14:36,255:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:14:36,255:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-21 13:14:36,406:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:14:36,406:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:14:36,551:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:14:36,552:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:14:36,553:INFO:Preparing preprocessing pipeline...
2023-10-21 13:14:36,553:INFO:Set up simple imputation.
2023-10-21 13:14:36,556:INFO:Set up column name cleaning.
2023-10-21 13:14:36,606:INFO:Finished creating preprocessing pipeline.
2023-10-21 13:14:36,606:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 13:14:36,606:INFO:Creating final display dataframe.
2023-10-21 13:14:36,789:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (26071, 50)
4        Transformed data shape   (26071, 50)
5   Transformed train set shape   (18249, 50)
6    Transformed test set shape    (7822, 50)
7              Numeric features            49
8      Rows with missing values         95.9%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_C
19                          USI          f13b
2023-10-21 13:14:36,941:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:14:36,941:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:14:37,088:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:14:37,088:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:14:37,088:INFO:Logging experiment in loggers
2023-10-21 13:14:37,205:INFO:SubProcess save_model() called ==================================
2023-10-21 13:14:37,205:INFO:Initializing save_model()
2023-10-21 13:14:37,205:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmpokoacz1e\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 13:14:37,205:INFO:Adding model into prep_pipe
2023-10-21 13:14:37,205:WARNING:Only Model saved as it was a pipeline.
2023-10-21 13:14:37,221:INFO:C:\Users\thoma\AppData\Local\Temp\tmpokoacz1e\Transformation Pipeline.pkl saved in current working directory
2023-10-21 13:14:37,221:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 13:14:37,221:INFO:save_model() successfully completed......................................
2023-10-21 13:14:37,404:INFO:SubProcess save_model() end ==================================
2023-10-21 13:14:37,455:INFO:setup() successfully completed in 2.3s...............
2023-10-21 13:14:37,455:INFO:Initializing create_model()
2023-10-21 13:14:37,455:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCD99880>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 13:14:37,455:INFO:Checking exceptions
2023-10-21 13:14:37,455:INFO:Importing libraries
2023-10-21 13:14:37,455:INFO:Copying training dataset
2023-10-21 13:14:37,471:INFO:Defining folds
2023-10-21 13:14:37,471:INFO:Declaring metric variables
2023-10-21 13:14:37,471:INFO:Importing untrained model
2023-10-21 13:14:37,471:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 13:14:37,471:INFO:Starting cross validation
2023-10-21 13:14:37,471:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 13:14:40,103:INFO:Calculating mean and std
2023-10-21 13:14:40,103:INFO:Creating metrics dataframe
2023-10-21 13:14:40,103:INFO:Finalizing model
2023-10-21 13:14:40,186:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004403 seconds.
2023-10-21 13:14:40,186:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 13:14:40,186:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-21 13:14:40,186:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-21 13:14:40,186:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-21 13:14:40,436:INFO:Creating Dashboard logs
2023-10-21 13:14:40,436:INFO:Model: Light Gradient Boosting Machine
2023-10-21 13:14:40,534:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 13:14:40,702:INFO:Initializing predict_model()
2023-10-21 13:14:40,702:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCD99880>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DB43D670>)
2023-10-21 13:14:40,702:INFO:Checking exceptions
2023-10-21 13:14:40,702:INFO:Preloading libraries
2023-10-21 13:14:41,285:INFO:Uploading results into container
2023-10-21 13:14:41,285:INFO:Uploading model into container now
2023-10-21 13:14:41,285:INFO:_master_model_container: 1
2023-10-21 13:14:41,285:INFO:_display_container: 2
2023-10-21 13:14:41,285:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 13:14:41,285:INFO:create_model() successfully completed......................................
2023-10-21 13:14:41,469:INFO:Initializing tune_model()
2023-10-21 13:14:41,469:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCD99880>)
2023-10-21 13:14:41,469:INFO:Checking exceptions
2023-10-21 13:14:41,485:INFO:Copying training dataset
2023-10-21 13:14:41,502:INFO:Checking base model
2023-10-21 13:14:41,502:INFO:Base model : Light Gradient Boosting Machine
2023-10-21 13:14:41,502:INFO:Declaring metric variables
2023-10-21 13:14:41,502:INFO:Defining Hyperparameters
2023-10-21 13:14:41,668:INFO:Tuning with n_jobs=-1
2023-10-21 13:14:41,668:INFO:Initializing RandomizedSearchCV
2023-10-21 13:15:23,268:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-21 13:15:23,268:INFO:Hyperparameter search completed
2023-10-21 13:15:23,268:INFO:SubProcess create_model() called ==================================
2023-10-21 13:15:23,268:INFO:Initializing create_model()
2023-10-21 13:15:23,268:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCD99880>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3955D00>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-21 13:15:23,268:INFO:Checking exceptions
2023-10-21 13:15:23,268:INFO:Importing libraries
2023-10-21 13:15:23,268:INFO:Copying training dataset
2023-10-21 13:15:23,306:INFO:Defining folds
2023-10-21 13:15:23,306:INFO:Declaring metric variables
2023-10-21 13:15:23,307:INFO:Importing untrained model
2023-10-21 13:15:23,307:INFO:Declaring custom model
2023-10-21 13:15:23,308:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 13:15:23,309:INFO:Starting cross validation
2023-10-21 13:15:23,310:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 13:15:32,027:INFO:Calculating mean and std
2023-10-21 13:15:32,027:INFO:Creating metrics dataframe
2023-10-21 13:15:32,027:INFO:Finalizing model
2023-10-21 13:15:32,074:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 13:15:32,074:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 13:15:32,074:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 13:15:32,093:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 13:15:32,093:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 13:15:32,093:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 13:15:32,110:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004872 seconds.
2023-10-21 13:15:32,110:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 13:15:32,110:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-21 13:15:32,110:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-21 13:15:32,110:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-21 13:15:32,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 13:15:32,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 13:15:32,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 13:15:32,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 13:15:32,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 13:15:32,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 13:15:32,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 13:15:32,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 13:15:33,242:INFO:Uploading results into container
2023-10-21 13:15:33,242:INFO:Uploading model into container now
2023-10-21 13:15:33,242:INFO:_master_model_container: 2
2023-10-21 13:15:33,242:INFO:_display_container: 3
2023-10-21 13:15:33,242:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-21 13:15:33,242:INFO:create_model() successfully completed......................................
2023-10-21 13:15:33,474:INFO:SubProcess create_model() end ==================================
2023-10-21 13:15:33,475:INFO:choose_better activated
2023-10-21 13:15:33,475:INFO:SubProcess create_model() called ==================================
2023-10-21 13:15:33,475:INFO:Initializing create_model()
2023-10-21 13:15:33,475:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCD99880>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 13:15:33,475:INFO:Checking exceptions
2023-10-21 13:15:33,475:INFO:Importing libraries
2023-10-21 13:15:33,475:INFO:Copying training dataset
2023-10-21 13:15:33,492:INFO:Defining folds
2023-10-21 13:15:33,492:INFO:Declaring metric variables
2023-10-21 13:15:33,492:INFO:Importing untrained model
2023-10-21 13:15:33,492:INFO:Declaring custom model
2023-10-21 13:15:33,492:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 13:15:33,492:INFO:Starting cross validation
2023-10-21 13:15:33,492:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 13:15:36,256:INFO:Calculating mean and std
2023-10-21 13:15:36,256:INFO:Creating metrics dataframe
2023-10-21 13:15:36,256:INFO:Finalizing model
2023-10-21 13:15:36,338:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005240 seconds.
2023-10-21 13:15:36,338:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 13:15:36,339:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-21 13:15:36,339:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-21 13:15:36,340:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-21 13:15:36,648:INFO:Uploading results into container
2023-10-21 13:15:36,649:INFO:Uploading model into container now
2023-10-21 13:15:36,650:INFO:_master_model_container: 3
2023-10-21 13:15:36,650:INFO:_display_container: 4
2023-10-21 13:15:36,651:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 13:15:36,651:INFO:create_model() successfully completed......................................
2023-10-21 13:15:36,856:INFO:SubProcess create_model() end ==================================
2023-10-21 13:15:36,856:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.905
2023-10-21 13:15:36,856:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8993
2023-10-21 13:15:36,856:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-21 13:15:36,856:INFO:choose_better completed
2023-10-21 13:15:36,856:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-21 13:15:36,856:INFO:Creating Dashboard logs
2023-10-21 13:15:36,856:INFO:Model: Light Gradient Boosting Machine
2023-10-21 13:15:36,922:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 13:15:37,122:INFO:Initializing predict_model()
2023-10-21 13:15:37,122:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCD99880>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DB43D040>)
2023-10-21 13:15:37,122:INFO:Checking exceptions
2023-10-21 13:15:37,122:INFO:Preloading libraries
2023-10-21 13:15:37,752:INFO:_master_model_container: 3
2023-10-21 13:15:37,753:INFO:_display_container: 3
2023-10-21 13:15:37,754:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 13:15:37,754:INFO:tune_model() successfully completed......................................
2023-10-21 13:15:37,943:INFO:Initializing finalize_model()
2023-10-21 13:15:37,943:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCD99880>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-21 13:15:37,943:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 13:15:37,955:INFO:Initializing create_model()
2023-10-21 13:15:37,955:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCD99880>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-21 13:15:37,955:INFO:Checking exceptions
2023-10-21 13:15:37,955:INFO:Importing libraries
2023-10-21 13:15:37,955:INFO:Copying training dataset
2023-10-21 13:15:37,955:INFO:Defining folds
2023-10-21 13:15:37,955:INFO:Declaring metric variables
2023-10-21 13:15:37,955:INFO:Importing untrained model
2023-10-21 13:15:37,955:INFO:Declaring custom model
2023-10-21 13:15:37,955:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 13:15:37,955:INFO:Cross validation set to False
2023-10-21 13:15:37,955:INFO:Fitting Model
2023-10-21 13:15:38,055:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005569 seconds.
2023-10-21 13:15:38,055:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 13:15:38,055:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-21 13:15:38,055:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-21 13:15:38,055:INFO:[LightGBM] [Info] Start training from score 77.700043
2023-10-21 13:15:38,336:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-21 13:15:38,336:INFO:create_model() successfully completed......................................
2023-10-21 13:15:38,522:INFO:Creating Dashboard logs
2023-10-21 13:15:38,522:INFO:Model: Light Gradient Boosting Machine
2023-10-21 13:15:38,587:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 13:15:38,955:INFO:_master_model_container: 3
2023-10-21 13:15:38,955:INFO:_display_container: 3
2023-10-21 13:15:38,972:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-21 13:15:38,972:INFO:finalize_model() successfully completed......................................
2023-10-21 13:15:39,172:INFO:Initializing save_model()
2023-10-21 13:15:39,172:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_C, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 13:15:39,172:INFO:Adding model into prep_pipe
2023-10-21 13:15:39,172:WARNING:Only Model saved as it was a pipeline.
2023-10-21 13:15:39,187:INFO:final_model_for_location_C.pkl saved in current working directory
2023-10-21 13:15:39,187:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-21 13:15:39,187:INFO:save_model() successfully completed......................................
2023-10-21 13:47:22,068:INFO:Initializing predict_model()
2023-10-21 13:47:22,068:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCD99880>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209D9514EE0>)
2023-10-21 13:47:22,068:INFO:Checking exceptions
2023-10-21 13:47:22,068:INFO:Preloading libraries
2023-10-21 13:47:22,068:INFO:Set up data.
2023-10-21 13:47:22,102:INFO:Set up index.
2023-10-21 14:11:14,187:INFO:Initializing predict_model()
2023-10-21 14:11:14,187:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCD99880>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209D95198B0>)
2023-10-21 14:11:14,187:INFO:Checking exceptions
2023-10-21 14:11:14,187:INFO:Preloading libraries
2023-10-21 14:11:14,196:INFO:Set up data.
2023-10-21 14:11:14,225:INFO:Set up index.
2023-10-21 14:24:13,932:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\base\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals
  warnings.warn("Maximum Likelihood optimization failed to "

2023-10-21 14:27:19,293:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.
  self._init_dates(dates, freq)

2023-10-21 14:27:19,294:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.
  self._init_dates(dates, freq)

2023-10-21 14:27:19,295:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.
  self._init_dates(dates, freq)

2023-10-21 14:31:24,554:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.
  self._init_dates(dates, freq)

2023-10-21 14:31:24,554:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.
  self._init_dates(dates, freq)

2023-10-21 14:31:24,554:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.
  self._init_dates(dates, freq)

2023-10-21 15:42:01,872:INFO:Initializing predict_model()
2023-10-21 15:42:01,872:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCD99880>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209D9519310>)
2023-10-21 15:42:01,872:INFO:Checking exceptions
2023-10-21 15:42:01,874:INFO:Preloading libraries
2023-10-21 15:42:01,877:INFO:Set up data.
2023-10-21 15:42:01,912:INFO:Set up index.
2023-10-21 15:42:45,886:INFO:PyCaret RegressionExperiment
2023-10-21 15:42:45,886:INFO:Logging name: exp_A
2023-10-21 15:42:45,886:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-21 15:42:45,886:INFO:version 3.1.0
2023-10-21 15:42:45,886:INFO:Initializing setup()
2023-10-21 15:42:45,886:INFO:self.USI: af10
2023-10-21 15:42:45,887:INFO:self._variable_keys: {'transform_target_param', 'exp_name_log', 'y_train', 'logging_param', 'n_jobs_param', 'X_train', 'target_param', 'USI', 'gpu_n_jobs_param', 'fold_groups_param', '_ml_usecase', 'seed', 'fold_generator', 'idx', 'html_param', 'log_plots_param', 'y', 'gpu_param', 'X_test', 'memory', 'y_test', 'data', 'X', 'exp_id', '_available_plots', 'fold_shuffle_param', 'pipeline'}
2023-10-21 15:42:45,887:INFO:Checking environment
2023-10-21 15:42:45,887:INFO:python_version: 3.8.18
2023-10-21 15:42:45,887:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-21 15:42:45,887:INFO:machine: AMD64
2023-10-21 15:42:45,887:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-21 15:42:45,887:INFO:Memory: svmem(total=16505954304, available=4074913792, percent=75.3, used=12431040512, free=4074913792)
2023-10-21 15:42:45,887:INFO:Physical Core: 8
2023-10-21 15:42:45,887:INFO:Logical Core: 16
2023-10-21 15:42:45,887:INFO:Checking libraries
2023-10-21 15:42:45,888:INFO:System:
2023-10-21 15:42:45,888:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-21 15:42:45,888:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-21 15:42:45,888:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-21 15:42:45,888:INFO:PyCaret required dependencies:
2023-10-21 15:42:45,888:INFO:                 pip: 23.3
2023-10-21 15:42:45,888:INFO:          setuptools: 68.0.0
2023-10-21 15:42:45,888:INFO:             pycaret: 3.1.0
2023-10-21 15:42:45,888:INFO:             IPython: 8.12.0
2023-10-21 15:42:45,888:INFO:          ipywidgets: 8.1.1
2023-10-21 15:42:45,888:INFO:                tqdm: 4.66.1
2023-10-21 15:42:45,888:INFO:               numpy: 1.23.5
2023-10-21 15:42:45,888:INFO:              pandas: 1.5.3
2023-10-21 15:42:45,888:INFO:              jinja2: 3.1.2
2023-10-21 15:42:45,888:INFO:               scipy: 1.10.1
2023-10-21 15:42:45,889:INFO:              joblib: 1.3.2
2023-10-21 15:42:45,889:INFO:             sklearn: 1.2.2
2023-10-21 15:42:45,889:INFO:                pyod: 1.1.0
2023-10-21 15:42:45,889:INFO:            imblearn: 0.11.0
2023-10-21 15:42:45,889:INFO:   category_encoders: 2.6.2
2023-10-21 15:42:45,889:INFO:            lightgbm: 4.1.0
2023-10-21 15:42:45,889:INFO:               numba: 0.58.1
2023-10-21 15:42:45,889:INFO:            requests: 2.31.0
2023-10-21 15:42:45,889:INFO:          matplotlib: 3.7.3
2023-10-21 15:42:45,889:INFO:          scikitplot: 0.3.7
2023-10-21 15:42:45,889:INFO:         yellowbrick: 1.5
2023-10-21 15:42:45,889:INFO:              plotly: 5.17.0
2023-10-21 15:42:45,889:INFO:    plotly-resampler: Not installed
2023-10-21 15:42:45,889:INFO:             kaleido: 0.2.1
2023-10-21 15:42:45,889:INFO:           schemdraw: 0.15
2023-10-21 15:42:45,890:INFO:         statsmodels: 0.14.0
2023-10-21 15:42:45,890:INFO:              sktime: 0.21.1
2023-10-21 15:42:45,890:INFO:               tbats: 1.1.3
2023-10-21 15:42:45,890:INFO:            pmdarima: 2.0.3
2023-10-21 15:42:45,890:INFO:              psutil: 5.9.0
2023-10-21 15:42:45,890:INFO:          markupsafe: 2.1.3
2023-10-21 15:42:45,890:INFO:             pickle5: Not installed
2023-10-21 15:42:45,890:INFO:         cloudpickle: 2.2.1
2023-10-21 15:42:45,890:INFO:         deprecation: 2.1.0
2023-10-21 15:42:45,890:INFO:              xxhash: 3.4.1
2023-10-21 15:42:45,890:INFO:           wurlitzer: Not installed
2023-10-21 15:42:45,890:INFO:PyCaret optional dependencies:
2023-10-21 15:42:45,890:INFO:                shap: Not installed
2023-10-21 15:42:45,890:INFO:           interpret: Not installed
2023-10-21 15:42:45,890:INFO:                umap: Not installed
2023-10-21 15:42:45,890:INFO:     ydata_profiling: Not installed
2023-10-21 15:42:45,890:INFO:  explainerdashboard: Not installed
2023-10-21 15:42:45,890:INFO:             autoviz: Not installed
2023-10-21 15:42:45,890:INFO:           fairlearn: Not installed
2023-10-21 15:42:45,892:INFO:          deepchecks: Not installed
2023-10-21 15:42:45,892:INFO:             xgboost: Not installed
2023-10-21 15:42:45,892:INFO:            catboost: 1.2.2
2023-10-21 15:42:45,892:INFO:              kmodes: Not installed
2023-10-21 15:42:45,892:INFO:             mlxtend: Not installed
2023-10-21 15:42:45,892:INFO:       statsforecast: Not installed
2023-10-21 15:42:45,892:INFO:        tune_sklearn: Not installed
2023-10-21 15:42:45,892:INFO:                 ray: Not installed
2023-10-21 15:42:45,892:INFO:            hyperopt: Not installed
2023-10-21 15:42:45,892:INFO:              optuna: Not installed
2023-10-21 15:42:45,892:INFO:               skopt: Not installed
2023-10-21 15:42:45,892:INFO:              mlflow: 2.7.1
2023-10-21 15:42:45,892:INFO:              gradio: Not installed
2023-10-21 15:42:45,892:INFO:             fastapi: Not installed
2023-10-21 15:42:45,892:INFO:             uvicorn: Not installed
2023-10-21 15:42:45,892:INFO:              m2cgen: Not installed
2023-10-21 15:42:45,892:INFO:           evidently: Not installed
2023-10-21 15:42:45,892:INFO:               fugue: Not installed
2023-10-21 15:42:45,893:INFO:           streamlit: Not installed
2023-10-21 15:42:45,893:INFO:             prophet: Not installed
2023-10-21 15:42:45,893:INFO:None
2023-10-21 15:42:45,893:INFO:Set up data.
2023-10-21 15:42:45,932:INFO:Set up folding strategy.
2023-10-21 15:42:45,932:INFO:Set up train/test split.
2023-10-21 15:42:45,960:INFO:Set up index.
2023-10-21 15:42:45,963:INFO:Assigning column types.
2023-10-21 15:42:45,989:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-21 15:42:45,990:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 15:42:45,995:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,001:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,100:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,148:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,149:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:42:46,150:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:42:46,150:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,156:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,161:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,240:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,288:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,288:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:42:46,288:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:42:46,289:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-21 15:42:46,295:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,300:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,378:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,426:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,426:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:42:46,427:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:42:46,433:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,438:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,527:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,579:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,579:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:42:46,580:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:42:46,580:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-21 15:42:46,584:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,662:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,710:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,710:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:42:46,710:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:42:46,725:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,804:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,852:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,852:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:42:46,852:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:42:46,852:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-21 15:42:46,936:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,987:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,988:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:42:46,988:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:42:47,067:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:42:47,115:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:42:47,115:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:42:47,115:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:42:47,115:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-21 15:42:47,210:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:42:47,257:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:42:47,257:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:42:47,337:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:42:47,402:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:42:47,402:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:42:47,402:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-21 15:42:47,531:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:42:47,531:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:42:47,670:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:42:47,670:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:42:47,670:INFO:Preparing preprocessing pipeline...
2023-10-21 15:42:47,670:INFO:Set up simple imputation.
2023-10-21 15:42:47,670:INFO:Set up column name cleaning.
2023-10-21 15:42:47,732:INFO:Finished creating preprocessing pipeline.
2023-10-21 15:42:47,732:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 15:42:47,732:INFO:Creating final display dataframe.
2023-10-21 15:42:47,952:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (34061, 50)
4        Transformed data shape   (34061, 50)
5   Transformed train set shape   (23842, 50)
6    Transformed test set shape   (10219, 50)
7              Numeric features            49
8      Rows with missing values         97.6%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_A
19                          USI          af10
2023-10-21 15:42:48,101:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:42:48,101:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:42:48,231:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:42:48,231:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:42:48,231:INFO:Logging experiment in loggers
2023-10-21 15:42:48,346:INFO:SubProcess save_model() called ==================================
2023-10-21 15:42:48,346:INFO:Initializing save_model()
2023-10-21 15:42:48,346:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmp1lfcq50a\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 15:42:48,346:INFO:Adding model into prep_pipe
2023-10-21 15:42:48,346:WARNING:Only Model saved as it was a pipeline.
2023-10-21 15:42:48,362:INFO:C:\Users\thoma\AppData\Local\Temp\tmp1lfcq50a\Transformation Pipeline.pkl saved in current working directory
2023-10-21 15:42:48,368:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 15:42:48,369:INFO:save_model() successfully completed......................................
2023-10-21 15:42:48,618:INFO:SubProcess save_model() end ==================================
2023-10-21 15:42:48,702:INFO:setup() successfully completed in 2.35s...............
2023-10-21 15:42:48,702:INFO:Initializing create_model()
2023-10-21 15:42:48,702:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D936C850>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 15:42:48,702:INFO:Checking exceptions
2023-10-21 15:42:48,702:INFO:Importing libraries
2023-10-21 15:42:48,702:INFO:Copying training dataset
2023-10-21 15:42:48,734:INFO:Defining folds
2023-10-21 15:42:48,734:INFO:Declaring metric variables
2023-10-21 15:42:48,734:INFO:Importing untrained model
2023-10-21 15:42:48,736:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 15:42:48,736:INFO:Starting cross validation
2023-10-21 15:42:48,736:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 15:42:58,941:INFO:Calculating mean and std
2023-10-21 15:42:58,941:INFO:Creating metrics dataframe
2023-10-21 15:42:58,941:INFO:Finalizing model
2023-10-21 15:42:59,042:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005359 seconds.
2023-10-21 15:42:59,042:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:42:59,042:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 15:42:59,042:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 15:42:59,042:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-21 15:42:59,307:INFO:Creating Dashboard logs
2023-10-21 15:42:59,307:INFO:Model: Light Gradient Boosting Machine
2023-10-21 15:42:59,390:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 15:42:59,575:INFO:Initializing predict_model()
2023-10-21 15:42:59,575:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D936C850>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DB02D9D0>)
2023-10-21 15:42:59,575:INFO:Checking exceptions
2023-10-21 15:42:59,575:INFO:Preloading libraries
2023-10-21 15:43:00,271:INFO:Uploading results into container
2023-10-21 15:43:00,273:INFO:Uploading model into container now
2023-10-21 15:43:00,273:INFO:_master_model_container: 1
2023-10-21 15:43:00,273:INFO:_display_container: 2
2023-10-21 15:43:00,273:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 15:43:00,273:INFO:create_model() successfully completed......................................
2023-10-21 15:43:00,538:INFO:Initializing tune_model()
2023-10-21 15:43:00,538:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D936C850>)
2023-10-21 15:43:00,539:INFO:Checking exceptions
2023-10-21 15:43:00,540:INFO:Copying training dataset
2023-10-21 15:43:00,569:INFO:Checking base model
2023-10-21 15:43:00,569:INFO:Base model : Light Gradient Boosting Machine
2023-10-21 15:43:00,569:INFO:Declaring metric variables
2023-10-21 15:43:00,570:INFO:Defining Hyperparameters
2023-10-21 15:43:00,790:INFO:Tuning with n_jobs=-1
2023-10-21 15:43:00,790:INFO:Initializing RandomizedSearchCV
2023-10-21 15:43:50,349:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-21 15:43:50,349:INFO:Hyperparameter search completed
2023-10-21 15:43:50,349:INFO:SubProcess create_model() called ==================================
2023-10-21 15:43:50,349:INFO:Initializing create_model()
2023-10-21 15:43:50,349:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D936C850>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209DB287A60>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-21 15:43:50,349:INFO:Checking exceptions
2023-10-21 15:43:50,349:INFO:Importing libraries
2023-10-21 15:43:50,349:INFO:Copying training dataset
2023-10-21 15:43:50,382:INFO:Defining folds
2023-10-21 15:43:50,383:INFO:Declaring metric variables
2023-10-21 15:43:50,383:INFO:Importing untrained model
2023-10-21 15:43:50,383:INFO:Declaring custom model
2023-10-21 15:43:50,384:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 15:43:50,385:INFO:Starting cross validation
2023-10-21 15:43:50,386:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 15:43:58,073:INFO:Calculating mean and std
2023-10-21 15:43:58,075:INFO:Creating metrics dataframe
2023-10-21 15:43:58,075:INFO:Finalizing model
2023-10-21 15:43:58,137:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 15:43:58,137:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 15:43:58,137:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 15:43:58,175:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 15:43:58,175:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 15:43:58,175:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 15:43:58,175:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005496 seconds.
2023-10-21 15:43:58,175:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:43:58,175:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 15:43:58,175:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 15:43:58,191:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-21 15:43:59,341:INFO:Uploading results into container
2023-10-21 15:43:59,341:INFO:Uploading model into container now
2023-10-21 15:43:59,356:INFO:_master_model_container: 2
2023-10-21 15:43:59,357:INFO:_display_container: 3
2023-10-21 15:43:59,358:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-21 15:43:59,359:INFO:create_model() successfully completed......................................
2023-10-21 15:43:59,624:INFO:SubProcess create_model() end ==================================
2023-10-21 15:43:59,624:INFO:choose_better activated
2023-10-21 15:43:59,624:INFO:SubProcess create_model() called ==================================
2023-10-21 15:43:59,624:INFO:Initializing create_model()
2023-10-21 15:43:59,624:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D936C850>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 15:43:59,624:INFO:Checking exceptions
2023-10-21 15:43:59,624:INFO:Importing libraries
2023-10-21 15:43:59,624:INFO:Copying training dataset
2023-10-21 15:43:59,660:INFO:Defining folds
2023-10-21 15:43:59,660:INFO:Declaring metric variables
2023-10-21 15:43:59,660:INFO:Importing untrained model
2023-10-21 15:43:59,660:INFO:Declaring custom model
2023-10-21 15:43:59,661:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 15:43:59,662:INFO:Starting cross validation
2023-10-21 15:43:59,663:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 15:44:02,905:INFO:Calculating mean and std
2023-10-21 15:44:02,905:INFO:Creating metrics dataframe
2023-10-21 15:44:02,905:INFO:Finalizing model
2023-10-21 15:44:03,005:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006647 seconds.
2023-10-21 15:44:03,005:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:03,005:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 15:44:03,005:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 15:44:03,005:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-21 15:44:03,288:INFO:Uploading results into container
2023-10-21 15:44:03,304:INFO:Uploading model into container now
2023-10-21 15:44:03,304:INFO:_master_model_container: 3
2023-10-21 15:44:03,304:INFO:_display_container: 4
2023-10-21 15:44:03,304:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 15:44:03,304:INFO:create_model() successfully completed......................................
2023-10-21 15:44:03,588:INFO:SubProcess create_model() end ==================================
2023-10-21 15:44:03,588:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8716
2023-10-21 15:44:03,588:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8712
2023-10-21 15:44:03,588:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-21 15:44:03,588:INFO:choose_better completed
2023-10-21 15:44:03,588:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-21 15:44:03,588:INFO:Creating Dashboard logs
2023-10-21 15:44:03,588:INFO:Model: Light Gradient Boosting Machine
2023-10-21 15:44:03,654:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 15:44:03,842:INFO:Initializing predict_model()
2023-10-21 15:44:03,842:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D936C850>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DB02D310>)
2023-10-21 15:44:03,842:INFO:Checking exceptions
2023-10-21 15:44:03,842:INFO:Preloading libraries
2023-10-21 15:44:04,503:INFO:_master_model_container: 3
2023-10-21 15:44:04,503:INFO:_display_container: 3
2023-10-21 15:44:04,503:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 15:44:04,503:INFO:tune_model() successfully completed......................................
2023-10-21 15:44:04,720:INFO:Initializing ensemble_model()
2023-10-21 15:44:04,720:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D936C850>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-21 15:44:04,720:INFO:Checking exceptions
2023-10-21 15:44:04,744:INFO:Importing libraries
2023-10-21 15:44:04,744:INFO:Copying training dataset
2023-10-21 15:44:04,744:INFO:Checking base model
2023-10-21 15:44:04,744:INFO:Base model : Light Gradient Boosting Machine
2023-10-21 15:44:04,744:INFO:Importing untrained ensembler
2023-10-21 15:44:04,744:INFO:Ensemble method set to Bagging
2023-10-21 15:44:04,744:INFO:SubProcess create_model() called ==================================
2023-10-21 15:44:04,744:INFO:Initializing create_model()
2023-10-21 15:44:04,744:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D936C850>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209DB287A60>, model_only=True, return_train_score=False, kwargs={})
2023-10-21 15:44:04,744:INFO:Checking exceptions
2023-10-21 15:44:04,744:INFO:Importing libraries
2023-10-21 15:44:04,744:INFO:Copying training dataset
2023-10-21 15:44:04,771:INFO:Defining folds
2023-10-21 15:44:04,771:INFO:Declaring metric variables
2023-10-21 15:44:04,771:INFO:Importing untrained model
2023-10-21 15:44:04,771:INFO:Declaring custom model
2023-10-21 15:44:04,771:INFO:Bagging Regressor Imported successfully
2023-10-21 15:44:04,771:INFO:Starting cross validation
2023-10-21 15:44:04,775:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 15:44:28,750:INFO:Calculating mean and std
2023-10-21 15:44:28,750:INFO:Creating metrics dataframe
2023-10-21 15:44:28,750:INFO:Finalizing model
2023-10-21 15:44:28,833:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004075 seconds.
2023-10-21 15:44:28,833:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:28,833:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 15:44:28,833:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 15:44:28,833:INFO:[LightGBM] [Info] Start training from score 626.831517
2023-10-21 15:44:29,083:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005246 seconds.
2023-10-21 15:44:29,083:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:29,083:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 15:44:29,083:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 15:44:29,083:INFO:[LightGBM] [Info] Start training from score 640.013980
2023-10-21 15:44:29,333:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005388 seconds.
2023-10-21 15:44:29,333:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:29,333:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 15:44:29,333:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 15:44:29,333:INFO:[LightGBM] [Info] Start training from score 623.946930
2023-10-21 15:44:29,583:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005223 seconds.
2023-10-21 15:44:29,583:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:29,583:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 15:44:29,583:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 15:44:29,583:INFO:[LightGBM] [Info] Start training from score 632.335152
2023-10-21 15:44:29,832:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004364 seconds.
2023-10-21 15:44:29,832:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:29,832:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 15:44:29,832:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 15:44:29,848:INFO:[LightGBM] [Info] Start training from score 620.070240
2023-10-21 15:44:30,165:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005504 seconds.
2023-10-21 15:44:30,165:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:30,165:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 15:44:30,165:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 15:44:30,165:INFO:[LightGBM] [Info] Start training from score 635.137343
2023-10-21 15:44:30,465:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006071 seconds.
2023-10-21 15:44:30,465:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:30,465:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 15:44:30,465:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 15:44:30,465:INFO:[LightGBM] [Info] Start training from score 620.066941
2023-10-21 15:44:30,765:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006645 seconds.
2023-10-21 15:44:30,765:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:30,765:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 15:44:30,765:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 15:44:30,765:INFO:[LightGBM] [Info] Start training from score 623.069874
2023-10-21 15:44:31,031:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004510 seconds.
2023-10-21 15:44:31,031:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:31,047:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 15:44:31,047:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 15:44:31,048:INFO:[LightGBM] [Info] Start training from score 633.817057
2023-10-21 15:44:31,315:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005548 seconds.
2023-10-21 15:44:31,315:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:31,315:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 15:44:31,315:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 15:44:31,315:INFO:[LightGBM] [Info] Start training from score 641.113408
2023-10-21 15:44:31,564:INFO:Uploading results into container
2023-10-21 15:44:31,564:INFO:Uploading model into container now
2023-10-21 15:44:31,564:INFO:_master_model_container: 4
2023-10-21 15:44:31,564:INFO:_display_container: 4
2023-10-21 15:44:31,564:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-21 15:44:31,564:INFO:create_model() successfully completed......................................
2023-10-21 15:44:31,815:INFO:SubProcess create_model() end ==================================
2023-10-21 15:44:31,815:INFO:Creating Dashboard logs
2023-10-21 15:44:31,815:INFO:Model: Bagging Regressor
2023-10-21 15:44:31,897:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-21 15:44:32,114:INFO:Initializing predict_model()
2023-10-21 15:44:32,114:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D936C850>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020986AFBCA0>)
2023-10-21 15:44:32,114:INFO:Checking exceptions
2023-10-21 15:44:32,114:INFO:Preloading libraries
2023-10-21 15:44:32,963:INFO:_master_model_container: 4
2023-10-21 15:44:32,963:INFO:_display_container: 4
2023-10-21 15:44:32,963:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-21 15:44:32,963:INFO:ensemble_model() successfully completed......................................
2023-10-21 15:44:33,180:INFO:Initializing finalize_model()
2023-10-21 15:44:33,180:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D936C850>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-21 15:44:33,180:INFO:Finalizing BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-21 15:44:33,196:INFO:Initializing create_model()
2023-10-21 15:44:33,196:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D936C850>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-21 15:44:33,196:INFO:Checking exceptions
2023-10-21 15:44:33,196:INFO:Importing libraries
2023-10-21 15:44:33,196:INFO:Copying training dataset
2023-10-21 15:44:33,196:INFO:Defining folds
2023-10-21 15:44:33,196:INFO:Declaring metric variables
2023-10-21 15:44:33,196:INFO:Importing untrained model
2023-10-21 15:44:33,196:INFO:Declaring custom model
2023-10-21 15:44:33,196:INFO:Bagging Regressor Imported successfully
2023-10-21 15:44:33,196:INFO:Cross validation set to False
2023-10-21 15:44:33,196:INFO:Fitting Model
2023-10-21 15:44:33,313:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008017 seconds.
2023-10-21 15:44:33,313:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:33,313:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-21 15:44:33,313:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-21 15:44:33,313:INFO:[LightGBM] [Info] Start training from score 634.491655
2023-10-21 15:44:33,713:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006599 seconds.
2023-10-21 15:44:33,713:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:33,713:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-21 15:44:33,713:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-21 15:44:33,728:INFO:[LightGBM] [Info] Start training from score 635.470959
2023-10-21 15:44:34,096:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007300 seconds.
2023-10-21 15:44:34,096:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:34,096:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-21 15:44:34,096:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-21 15:44:34,096:INFO:[LightGBM] [Info] Start training from score 634.053589
2023-10-21 15:44:34,528:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008366 seconds.
2023-10-21 15:44:34,528:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:34,528:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-21 15:44:34,528:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-21 15:44:34,528:INFO:[LightGBM] [Info] Start training from score 635.251785
2023-10-21 15:44:34,962:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006308 seconds.
2023-10-21 15:44:34,962:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:34,962:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-21 15:44:34,962:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-21 15:44:34,962:INFO:[LightGBM] [Info] Start training from score 627.555784
2023-10-21 15:44:35,261:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008473 seconds.
2023-10-21 15:44:35,261:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:35,262:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-21 15:44:35,262:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-21 15:44:35,262:INFO:[LightGBM] [Info] Start training from score 638.162596
2023-10-21 15:44:35,578:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008136 seconds.
2023-10-21 15:44:35,578:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:35,578:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-21 15:44:35,578:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-21 15:44:35,578:INFO:[LightGBM] [Info] Start training from score 633.181363
2023-10-21 15:44:35,861:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006286 seconds.
2023-10-21 15:44:35,861:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:35,861:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-21 15:44:35,861:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-21 15:44:35,861:INFO:[LightGBM] [Info] Start training from score 611.992287
2023-10-21 15:44:36,161:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008329 seconds.
2023-10-21 15:44:36,161:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:36,161:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-21 15:44:36,161:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-21 15:44:36,161:INFO:[LightGBM] [Info] Start training from score 638.181417
2023-10-21 15:44:36,477:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008043 seconds.
2023-10-21 15:44:36,477:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:36,477:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-21 15:44:36,477:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-21 15:44:36,477:INFO:[LightGBM] [Info] Start training from score 639.502137
2023-10-21 15:44:36,710:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-21 15:44:36,710:INFO:create_model() successfully completed......................................
2023-10-21 15:44:36,944:INFO:Creating Dashboard logs
2023-10-21 15:44:36,944:INFO:Model: Bagging Regressor
2023-10-21 15:44:37,010:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-21 15:44:37,477:INFO:_master_model_container: 4
2023-10-21 15:44:37,477:INFO:_display_container: 4
2023-10-21 15:44:37,477:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-21 15:44:37,477:INFO:finalize_model() successfully completed......................................
2023-10-21 15:44:37,693:INFO:Initializing save_model()
2023-10-21 15:44:37,693:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), model_name=final_model_for_location_A, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 15:44:37,693:INFO:Adding model into prep_pipe
2023-10-21 15:44:37,693:WARNING:Only Model saved as it was a pipeline.
2023-10-21 15:44:37,776:INFO:final_model_for_location_A.pkl saved in current working directory
2023-10-21 15:44:37,791:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-21 15:44:37,791:INFO:save_model() successfully completed......................................
2023-10-21 15:44:38,026:INFO:PyCaret RegressionExperiment
2023-10-21 15:44:38,026:INFO:Logging name: exp_B
2023-10-21 15:44:38,026:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-21 15:44:38,026:INFO:version 3.1.0
2023-10-21 15:44:38,026:INFO:Initializing setup()
2023-10-21 15:44:38,026:INFO:self.USI: e04f
2023-10-21 15:44:38,026:INFO:self._variable_keys: {'transform_target_param', 'exp_name_log', 'y_train', 'logging_param', 'n_jobs_param', 'X_train', 'target_param', 'USI', 'gpu_n_jobs_param', 'fold_groups_param', '_ml_usecase', 'seed', 'fold_generator', 'idx', 'html_param', 'log_plots_param', 'y', 'gpu_param', 'X_test', 'memory', 'y_test', 'data', 'X', 'exp_id', '_available_plots', 'fold_shuffle_param', 'pipeline'}
2023-10-21 15:44:38,026:INFO:Checking environment
2023-10-21 15:44:38,026:INFO:python_version: 3.8.18
2023-10-21 15:44:38,026:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-21 15:44:38,026:INFO:machine: AMD64
2023-10-21 15:44:38,026:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-21 15:44:38,026:INFO:Memory: svmem(total=16505954304, available=2976317440, percent=82.0, used=13529636864, free=2976317440)
2023-10-21 15:44:38,026:INFO:Physical Core: 8
2023-10-21 15:44:38,026:INFO:Logical Core: 16
2023-10-21 15:44:38,026:INFO:Checking libraries
2023-10-21 15:44:38,026:INFO:System:
2023-10-21 15:44:38,026:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-21 15:44:38,026:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-21 15:44:38,026:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-21 15:44:38,026:INFO:PyCaret required dependencies:
2023-10-21 15:44:38,026:INFO:                 pip: 23.3
2023-10-21 15:44:38,026:INFO:          setuptools: 68.0.0
2023-10-21 15:44:38,026:INFO:             pycaret: 3.1.0
2023-10-21 15:44:38,026:INFO:             IPython: 8.12.0
2023-10-21 15:44:38,026:INFO:          ipywidgets: 8.1.1
2023-10-21 15:44:38,026:INFO:                tqdm: 4.66.1
2023-10-21 15:44:38,026:INFO:               numpy: 1.23.5
2023-10-21 15:44:38,026:INFO:              pandas: 1.5.3
2023-10-21 15:44:38,026:INFO:              jinja2: 3.1.2
2023-10-21 15:44:38,026:INFO:               scipy: 1.10.1
2023-10-21 15:44:38,026:INFO:              joblib: 1.3.2
2023-10-21 15:44:38,026:INFO:             sklearn: 1.2.2
2023-10-21 15:44:38,026:INFO:                pyod: 1.1.0
2023-10-21 15:44:38,026:INFO:            imblearn: 0.11.0
2023-10-21 15:44:38,026:INFO:   category_encoders: 2.6.2
2023-10-21 15:44:38,026:INFO:            lightgbm: 4.1.0
2023-10-21 15:44:38,026:INFO:               numba: 0.58.1
2023-10-21 15:44:38,026:INFO:            requests: 2.31.0
2023-10-21 15:44:38,026:INFO:          matplotlib: 3.7.3
2023-10-21 15:44:38,026:INFO:          scikitplot: 0.3.7
2023-10-21 15:44:38,026:INFO:         yellowbrick: 1.5
2023-10-21 15:44:38,026:INFO:              plotly: 5.17.0
2023-10-21 15:44:38,026:INFO:    plotly-resampler: Not installed
2023-10-21 15:44:38,026:INFO:             kaleido: 0.2.1
2023-10-21 15:44:38,026:INFO:           schemdraw: 0.15
2023-10-21 15:44:38,026:INFO:         statsmodels: 0.14.0
2023-10-21 15:44:38,041:INFO:              sktime: 0.21.1
2023-10-21 15:44:38,041:INFO:               tbats: 1.1.3
2023-10-21 15:44:38,041:INFO:            pmdarima: 2.0.3
2023-10-21 15:44:38,041:INFO:              psutil: 5.9.0
2023-10-21 15:44:38,041:INFO:          markupsafe: 2.1.3
2023-10-21 15:44:38,041:INFO:             pickle5: Not installed
2023-10-21 15:44:38,041:INFO:         cloudpickle: 2.2.1
2023-10-21 15:44:38,041:INFO:         deprecation: 2.1.0
2023-10-21 15:44:38,041:INFO:              xxhash: 3.4.1
2023-10-21 15:44:38,041:INFO:           wurlitzer: Not installed
2023-10-21 15:44:38,041:INFO:PyCaret optional dependencies:
2023-10-21 15:44:38,041:INFO:                shap: Not installed
2023-10-21 15:44:38,041:INFO:           interpret: Not installed
2023-10-21 15:44:38,042:INFO:                umap: Not installed
2023-10-21 15:44:38,042:INFO:     ydata_profiling: Not installed
2023-10-21 15:44:38,042:INFO:  explainerdashboard: Not installed
2023-10-21 15:44:38,042:INFO:             autoviz: Not installed
2023-10-21 15:44:38,042:INFO:           fairlearn: Not installed
2023-10-21 15:44:38,042:INFO:          deepchecks: Not installed
2023-10-21 15:44:38,042:INFO:             xgboost: Not installed
2023-10-21 15:44:38,042:INFO:            catboost: 1.2.2
2023-10-21 15:44:38,042:INFO:              kmodes: Not installed
2023-10-21 15:44:38,042:INFO:             mlxtend: Not installed
2023-10-21 15:44:38,042:INFO:       statsforecast: Not installed
2023-10-21 15:44:38,042:INFO:        tune_sklearn: Not installed
2023-10-21 15:44:38,042:INFO:                 ray: Not installed
2023-10-21 15:44:38,042:INFO:            hyperopt: Not installed
2023-10-21 15:44:38,042:INFO:              optuna: Not installed
2023-10-21 15:44:38,042:INFO:               skopt: Not installed
2023-10-21 15:44:38,042:INFO:              mlflow: 2.7.1
2023-10-21 15:44:38,042:INFO:              gradio: Not installed
2023-10-21 15:44:38,042:INFO:             fastapi: Not installed
2023-10-21 15:44:38,042:INFO:             uvicorn: Not installed
2023-10-21 15:44:38,042:INFO:              m2cgen: Not installed
2023-10-21 15:44:38,042:INFO:           evidently: Not installed
2023-10-21 15:44:38,042:INFO:               fugue: Not installed
2023-10-21 15:44:38,042:INFO:           streamlit: Not installed
2023-10-21 15:44:38,042:INFO:             prophet: Not installed
2023-10-21 15:44:38,042:INFO:None
2023-10-21 15:44:38,042:INFO:Set up data.
2023-10-21 15:44:38,060:INFO:Set up folding strategy.
2023-10-21 15:44:38,060:INFO:Set up train/test split.
2023-10-21 15:44:38,093:INFO:Set up index.
2023-10-21 15:44:38,093:INFO:Assigning column types.
2023-10-21 15:44:38,110:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-21 15:44:38,110:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,124:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,126:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,209:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,260:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,260:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:44:38,260:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:44:38,260:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,274:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,276:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,358:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,409:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,409:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:44:38,409:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:44:38,409:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-21 15:44:38,409:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,409:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,492:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,558:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,559:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:44:38,559:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:44:38,561:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,561:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,642:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,693:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,693:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:44:38,707:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:44:38,707:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-21 15:44:38,708:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,792:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,842:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,857:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:44:38,857:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:44:38,869:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,942:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,991:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,991:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:44:38,991:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:44:38,991:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-21 15:44:39,092:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:44:39,142:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:44:39,142:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:44:39,142:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:44:39,241:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:44:39,291:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:44:39,291:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:44:39,291:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:44:39,291:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-21 15:44:39,378:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:44:39,425:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:44:39,425:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:44:39,525:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:44:39,574:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:44:39,574:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:44:39,574:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-21 15:44:39,724:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:44:39,724:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:44:39,881:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:44:39,881:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:44:39,883:INFO:Preparing preprocessing pipeline...
2023-10-21 15:44:39,883:INFO:Set up simple imputation.
2023-10-21 15:44:39,883:INFO:Set up column name cleaning.
2023-10-21 15:44:39,941:INFO:Finished creating preprocessing pipeline.
2023-10-21 15:44:39,956:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 15:44:39,956:INFO:Creating final display dataframe.
2023-10-21 15:44:40,166:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (32819, 50)
4        Transformed data shape   (32819, 50)
5   Transformed train set shape   (22973, 50)
6    Transformed test set shape    (9846, 50)
7              Numeric features            49
8      Rows with missing values         95.9%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_B
19                          USI          e04f
2023-10-21 15:44:40,307:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:44:40,307:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:44:40,440:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:44:40,440:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:44:40,440:INFO:Logging experiment in loggers
2023-10-21 15:44:40,567:INFO:SubProcess save_model() called ==================================
2023-10-21 15:44:40,573:INFO:Initializing save_model()
2023-10-21 15:44:40,573:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmpc91y37zv\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 15:44:40,573:INFO:Adding model into prep_pipe
2023-10-21 15:44:40,573:WARNING:Only Model saved as it was a pipeline.
2023-10-21 15:44:40,573:INFO:C:\Users\thoma\AppData\Local\Temp\tmpc91y37zv\Transformation Pipeline.pkl saved in current working directory
2023-10-21 15:44:40,590:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 15:44:40,590:INFO:save_model() successfully completed......................................
2023-10-21 15:44:40,790:INFO:SubProcess save_model() end ==================================
2023-10-21 15:44:40,841:INFO:setup() successfully completed in 2.41s...............
2023-10-21 15:44:40,841:INFO:Initializing create_model()
2023-10-21 15:44:40,841:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCAFE9D0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 15:44:40,841:INFO:Checking exceptions
2023-10-21 15:44:40,841:INFO:Importing libraries
2023-10-21 15:44:40,841:INFO:Copying training dataset
2023-10-21 15:44:40,868:INFO:Defining folds
2023-10-21 15:44:40,868:INFO:Declaring metric variables
2023-10-21 15:44:40,868:INFO:Importing untrained model
2023-10-21 15:44:40,869:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 15:44:40,869:INFO:Starting cross validation
2023-10-21 15:44:40,870:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 15:44:43,655:INFO:Calculating mean and std
2023-10-21 15:44:43,655:INFO:Creating metrics dataframe
2023-10-21 15:44:43,655:INFO:Finalizing model
2023-10-21 15:44:43,738:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004451 seconds.
2023-10-21 15:44:43,738:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:43,738:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 15:44:43,738:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 15:44:43,753:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-21 15:44:43,989:INFO:Creating Dashboard logs
2023-10-21 15:44:43,989:INFO:Model: Light Gradient Boosting Machine
2023-10-21 15:44:44,087:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 15:44:44,271:INFO:Initializing predict_model()
2023-10-21 15:44:44,271:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCAFE9D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002098123F550>)
2023-10-21 15:44:44,271:INFO:Checking exceptions
2023-10-21 15:44:44,271:INFO:Preloading libraries
2023-10-21 15:44:44,966:INFO:Uploading results into container
2023-10-21 15:44:44,966:INFO:Uploading model into container now
2023-10-21 15:44:44,970:INFO:_master_model_container: 1
2023-10-21 15:44:44,970:INFO:_display_container: 2
2023-10-21 15:44:44,970:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 15:44:44,970:INFO:create_model() successfully completed......................................
2023-10-21 15:44:45,170:INFO:Initializing tune_model()
2023-10-21 15:44:45,170:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCAFE9D0>)
2023-10-21 15:44:45,170:INFO:Checking exceptions
2023-10-21 15:44:45,187:INFO:Copying training dataset
2023-10-21 15:44:45,205:INFO:Checking base model
2023-10-21 15:44:45,205:INFO:Base model : Light Gradient Boosting Machine
2023-10-21 15:44:45,205:INFO:Declaring metric variables
2023-10-21 15:44:45,205:INFO:Defining Hyperparameters
2023-10-21 15:44:45,404:INFO:Tuning with n_jobs=-1
2023-10-21 15:44:45,404:INFO:Initializing RandomizedSearchCV
2023-10-21 15:45:31,981:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-21 15:45:31,981:INFO:Hyperparameter search completed
2023-10-21 15:45:31,981:INFO:SubProcess create_model() called ==================================
2023-10-21 15:45:31,981:INFO:Initializing create_model()
2023-10-21 15:45:31,981:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCAFE9D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209DAC11A60>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-21 15:45:31,981:INFO:Checking exceptions
2023-10-21 15:45:31,981:INFO:Importing libraries
2023-10-21 15:45:31,981:INFO:Copying training dataset
2023-10-21 15:45:32,017:INFO:Defining folds
2023-10-21 15:45:32,017:INFO:Declaring metric variables
2023-10-21 15:45:32,017:INFO:Importing untrained model
2023-10-21 15:45:32,017:INFO:Declaring custom model
2023-10-21 15:45:32,017:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 15:45:32,017:INFO:Starting cross validation
2023-10-21 15:45:32,017:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 15:45:43,372:INFO:Calculating mean and std
2023-10-21 15:45:43,372:INFO:Creating metrics dataframe
2023-10-21 15:45:43,372:INFO:Finalizing model
2023-10-21 15:45:43,422:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 15:45:43,422:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 15:45:43,422:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 15:45:43,455:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 15:45:43,455:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 15:45:43,455:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 15:45:43,472:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005311 seconds.
2023-10-21 15:45:43,472:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:45:43,472:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 15:45:43,472:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 15:45:43,472:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-21 15:45:44,654:INFO:Uploading results into container
2023-10-21 15:45:44,654:INFO:Uploading model into container now
2023-10-21 15:45:44,654:INFO:_master_model_container: 2
2023-10-21 15:45:44,654:INFO:_display_container: 3
2023-10-21 15:45:44,654:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-21 15:45:44,654:INFO:create_model() successfully completed......................................
2023-10-21 15:45:44,904:INFO:SubProcess create_model() end ==================================
2023-10-21 15:45:44,904:INFO:choose_better activated
2023-10-21 15:45:44,904:INFO:SubProcess create_model() called ==================================
2023-10-21 15:45:44,904:INFO:Initializing create_model()
2023-10-21 15:45:44,904:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCAFE9D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 15:45:44,904:INFO:Checking exceptions
2023-10-21 15:45:44,904:INFO:Importing libraries
2023-10-21 15:45:44,904:INFO:Copying training dataset
2023-10-21 15:45:44,921:INFO:Defining folds
2023-10-21 15:45:44,921:INFO:Declaring metric variables
2023-10-21 15:45:44,921:INFO:Importing untrained model
2023-10-21 15:45:44,921:INFO:Declaring custom model
2023-10-21 15:45:44,921:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 15:45:44,921:INFO:Starting cross validation
2023-10-21 15:45:44,921:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 15:45:47,485:INFO:Calculating mean and std
2023-10-21 15:45:47,485:INFO:Creating metrics dataframe
2023-10-21 15:45:47,485:INFO:Finalizing model
2023-10-21 15:45:47,568:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005051 seconds.
2023-10-21 15:45:47,568:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:45:47,568:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 15:45:47,584:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 15:45:47,585:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-21 15:45:47,852:INFO:Uploading results into container
2023-10-21 15:45:47,852:INFO:Uploading model into container now
2023-10-21 15:45:47,852:INFO:_master_model_container: 3
2023-10-21 15:45:47,852:INFO:_display_container: 4
2023-10-21 15:45:47,852:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 15:45:47,852:INFO:create_model() successfully completed......................................
2023-10-21 15:45:48,085:INFO:SubProcess create_model() end ==================================
2023-10-21 15:45:48,085:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8523
2023-10-21 15:45:48,085:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8523
2023-10-21 15:45:48,085:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-21 15:45:48,085:INFO:choose_better completed
2023-10-21 15:45:48,085:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-21 15:45:48,085:INFO:Creating Dashboard logs
2023-10-21 15:45:48,085:INFO:Model: Light Gradient Boosting Machine
2023-10-21 15:45:48,151:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 15:45:48,335:INFO:Initializing predict_model()
2023-10-21 15:45:48,335:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCAFE9D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209D83A4F70>)
2023-10-21 15:45:48,335:INFO:Checking exceptions
2023-10-21 15:45:48,335:INFO:Preloading libraries
2023-10-21 15:45:49,018:INFO:_master_model_container: 3
2023-10-21 15:45:49,018:INFO:_display_container: 3
2023-10-21 15:45:49,018:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 15:45:49,018:INFO:tune_model() successfully completed......................................
2023-10-21 15:45:49,227:INFO:Initializing ensemble_model()
2023-10-21 15:45:49,228:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCAFE9D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-21 15:45:49,228:INFO:Checking exceptions
2023-10-21 15:45:49,234:INFO:Importing libraries
2023-10-21 15:45:49,234:INFO:Copying training dataset
2023-10-21 15:45:49,234:INFO:Checking base model
2023-10-21 15:45:49,234:INFO:Base model : Light Gradient Boosting Machine
2023-10-21 15:45:49,234:INFO:Importing untrained ensembler
2023-10-21 15:45:49,234:INFO:Ensemble method set to Bagging
2023-10-21 15:45:49,234:INFO:SubProcess create_model() called ==================================
2023-10-21 15:45:49,234:INFO:Initializing create_model()
2023-10-21 15:45:49,234:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCAFE9D0>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209DCD99490>, model_only=True, return_train_score=False, kwargs={})
2023-10-21 15:45:49,234:INFO:Checking exceptions
2023-10-21 15:45:49,234:INFO:Importing libraries
2023-10-21 15:45:49,234:INFO:Copying training dataset
2023-10-21 15:45:49,250:INFO:Defining folds
2023-10-21 15:45:49,250:INFO:Declaring metric variables
2023-10-21 15:45:49,250:INFO:Importing untrained model
2023-10-21 15:45:49,250:INFO:Declaring custom model
2023-10-21 15:45:49,266:INFO:Bagging Regressor Imported successfully
2023-10-21 15:45:49,266:INFO:Starting cross validation
2023-10-21 15:45:49,267:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 15:46:17,913:INFO:Calculating mean and std
2023-10-21 15:46:17,913:INFO:Creating metrics dataframe
2023-10-21 15:46:17,913:INFO:Finalizing model
2023-10-21 15:46:18,008:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005190 seconds.
2023-10-21 15:46:18,008:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:18,008:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 15:46:18,008:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 15:46:18,008:INFO:[LightGBM] [Info] Start training from score 99.624795
2023-10-21 15:46:18,307:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005292 seconds.
2023-10-21 15:46:18,307:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:18,307:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 15:46:18,307:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 15:46:18,307:INFO:[LightGBM] [Info] Start training from score 96.229614
2023-10-21 15:46:18,587:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004625 seconds.
2023-10-21 15:46:18,587:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:18,587:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 15:46:18,587:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 15:46:18,587:INFO:[LightGBM] [Info] Start training from score 95.360987
2023-10-21 15:46:18,860:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005025 seconds.
2023-10-21 15:46:18,860:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:18,860:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 15:46:18,860:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 15:46:18,860:INFO:[LightGBM] [Info] Start training from score 94.348528
2023-10-21 15:46:19,148:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005167 seconds.
2023-10-21 15:46:19,148:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:19,148:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 15:46:19,148:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 15:46:19,148:INFO:[LightGBM] [Info] Start training from score 95.509684
2023-10-21 15:46:19,475:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005509 seconds.
2023-10-21 15:46:19,475:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:19,475:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 15:46:19,475:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 15:46:19,491:INFO:[LightGBM] [Info] Start training from score 96.036959
2023-10-21 15:46:19,775:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006716 seconds.
2023-10-21 15:46:19,775:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:19,775:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 15:46:19,775:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 15:46:19,775:INFO:[LightGBM] [Info] Start training from score 97.844637
2023-10-21 15:46:20,059:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004742 seconds.
2023-10-21 15:46:20,059:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:20,059:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 15:46:20,059:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 15:46:20,060:INFO:[LightGBM] [Info] Start training from score 96.245614
2023-10-21 15:46:20,325:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005188 seconds.
2023-10-21 15:46:20,325:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:20,325:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 15:46:20,325:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 15:46:20,325:INFO:[LightGBM] [Info] Start training from score 97.594984
2023-10-21 15:46:20,591:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006478 seconds.
2023-10-21 15:46:20,591:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:20,606:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 15:46:20,606:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 15:46:20,607:INFO:[LightGBM] [Info] Start training from score 96.370407
2023-10-21 15:46:20,841:INFO:Uploading results into container
2023-10-21 15:46:20,841:INFO:Uploading model into container now
2023-10-21 15:46:20,841:INFO:_master_model_container: 4
2023-10-21 15:46:20,841:INFO:_display_container: 4
2023-10-21 15:46:20,841:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-21 15:46:20,841:INFO:create_model() successfully completed......................................
2023-10-21 15:46:21,089:INFO:SubProcess create_model() end ==================================
2023-10-21 15:46:21,090:INFO:Creating Dashboard logs
2023-10-21 15:46:21,090:INFO:Model: Bagging Regressor
2023-10-21 15:46:21,140:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-21 15:46:21,363:INFO:Initializing predict_model()
2023-10-21 15:46:21,363:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCAFE9D0>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DCE93550>)
2023-10-21 15:46:21,363:INFO:Checking exceptions
2023-10-21 15:46:21,363:INFO:Preloading libraries
2023-10-21 15:46:22,189:INFO:_master_model_container: 4
2023-10-21 15:46:22,189:INFO:_display_container: 4
2023-10-21 15:46:22,189:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-21 15:46:22,189:INFO:ensemble_model() successfully completed......................................
2023-10-21 15:46:22,406:INFO:Initializing finalize_model()
2023-10-21 15:46:22,406:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCAFE9D0>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-21 15:46:22,406:INFO:Finalizing BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-21 15:46:22,423:INFO:Initializing create_model()
2023-10-21 15:46:22,423:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCAFE9D0>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-21 15:46:22,423:INFO:Checking exceptions
2023-10-21 15:46:22,423:INFO:Importing libraries
2023-10-21 15:46:22,423:INFO:Copying training dataset
2023-10-21 15:46:22,423:INFO:Defining folds
2023-10-21 15:46:22,423:INFO:Declaring metric variables
2023-10-21 15:46:22,423:INFO:Importing untrained model
2023-10-21 15:46:22,423:INFO:Declaring custom model
2023-10-21 15:46:22,423:INFO:Bagging Regressor Imported successfully
2023-10-21 15:46:22,423:INFO:Cross validation set to False
2023-10-21 15:46:22,423:INFO:Fitting Model
2023-10-21 15:46:22,570:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007404 seconds.
2023-10-21 15:46:22,571:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:22,571:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-21 15:46:22,572:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-21 15:46:22,573:INFO:[LightGBM] [Info] Start training from score 96.465021
2023-10-21 15:46:22,955:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007477 seconds.
2023-10-21 15:46:22,955:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:22,956:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-21 15:46:22,956:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-21 15:46:22,958:INFO:[LightGBM] [Info] Start training from score 97.264361
2023-10-21 15:46:23,356:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007300 seconds.
2023-10-21 15:46:23,356:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:23,356:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-21 15:46:23,356:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-21 15:46:23,356:INFO:[LightGBM] [Info] Start training from score 95.842370
2023-10-21 15:46:23,772:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007613 seconds.
2023-10-21 15:46:23,772:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:23,772:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-21 15:46:23,772:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-21 15:46:23,772:INFO:[LightGBM] [Info] Start training from score 95.431515
2023-10-21 15:46:24,213:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006845 seconds.
2023-10-21 15:46:24,213:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:24,213:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-21 15:46:24,213:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-21 15:46:24,213:INFO:[LightGBM] [Info] Start training from score 97.222213
2023-10-21 15:46:24,571:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008044 seconds.
2023-10-21 15:46:24,571:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:24,571:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-21 15:46:24,571:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-21 15:46:24,571:INFO:[LightGBM] [Info] Start training from score 97.332701
2023-10-21 15:46:25,004:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007975 seconds.
2023-10-21 15:46:25,004:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:25,004:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-21 15:46:25,004:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-21 15:46:25,004:INFO:[LightGBM] [Info] Start training from score 96.452612
2023-10-21 15:46:25,377:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007679 seconds.
2023-10-21 15:46:25,377:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:25,377:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-21 15:46:25,377:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-21 15:46:25,377:INFO:[LightGBM] [Info] Start training from score 97.322509
2023-10-21 15:46:25,737:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007850 seconds.
2023-10-21 15:46:25,737:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:25,737:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-21 15:46:25,737:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-21 15:46:25,737:INFO:[LightGBM] [Info] Start training from score 96.419103
2023-10-21 15:46:26,103:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007504 seconds.
2023-10-21 15:46:26,103:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:26,103:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-21 15:46:26,103:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-21 15:46:26,103:INFO:[LightGBM] [Info] Start training from score 95.095963
2023-10-21 15:46:26,403:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-21 15:46:26,403:INFO:create_model() successfully completed......................................
2023-10-21 15:46:26,670:INFO:Creating Dashboard logs
2023-10-21 15:46:26,670:INFO:Model: Bagging Regressor
2023-10-21 15:46:26,736:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-21 15:46:27,253:INFO:_master_model_container: 4
2023-10-21 15:46:27,268:INFO:_display_container: 4
2023-10-21 15:46:27,269:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-21 15:46:27,269:INFO:finalize_model() successfully completed......................................
2023-10-21 15:46:27,485:INFO:Initializing save_model()
2023-10-21 15:46:27,485:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), model_name=final_model_for_location_B, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 15:46:27,485:INFO:Adding model into prep_pipe
2023-10-21 15:46:27,485:WARNING:Only Model saved as it was a pipeline.
2023-10-21 15:46:27,552:INFO:final_model_for_location_B.pkl saved in current working directory
2023-10-21 15:46:27,569:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-21 15:46:27,569:INFO:save_model() successfully completed......................................
2023-10-21 15:46:27,819:INFO:PyCaret RegressionExperiment
2023-10-21 15:46:27,819:INFO:Logging name: exp_C
2023-10-21 15:46:27,819:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-21 15:46:27,819:INFO:version 3.1.0
2023-10-21 15:46:27,819:INFO:Initializing setup()
2023-10-21 15:46:27,819:INFO:self.USI: 54c7
2023-10-21 15:46:27,819:INFO:self._variable_keys: {'transform_target_param', 'exp_name_log', 'y_train', 'logging_param', 'n_jobs_param', 'X_train', 'target_param', 'USI', 'gpu_n_jobs_param', 'fold_groups_param', '_ml_usecase', 'seed', 'fold_generator', 'idx', 'html_param', 'log_plots_param', 'y', 'gpu_param', 'X_test', 'memory', 'y_test', 'data', 'X', 'exp_id', '_available_plots', 'fold_shuffle_param', 'pipeline'}
2023-10-21 15:46:27,819:INFO:Checking environment
2023-10-21 15:46:27,819:INFO:python_version: 3.8.18
2023-10-21 15:46:27,819:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-21 15:46:27,819:INFO:machine: AMD64
2023-10-21 15:46:27,819:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-21 15:46:27,819:INFO:Memory: svmem(total=16505954304, available=2961993728, percent=82.1, used=13543960576, free=2961993728)
2023-10-21 15:46:27,819:INFO:Physical Core: 8
2023-10-21 15:46:27,819:INFO:Logical Core: 16
2023-10-21 15:46:27,819:INFO:Checking libraries
2023-10-21 15:46:27,819:INFO:System:
2023-10-21 15:46:27,819:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-21 15:46:27,819:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-21 15:46:27,819:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-21 15:46:27,819:INFO:PyCaret required dependencies:
2023-10-21 15:46:27,819:INFO:                 pip: 23.3
2023-10-21 15:46:27,819:INFO:          setuptools: 68.0.0
2023-10-21 15:46:27,819:INFO:             pycaret: 3.1.0
2023-10-21 15:46:27,819:INFO:             IPython: 8.12.0
2023-10-21 15:46:27,819:INFO:          ipywidgets: 8.1.1
2023-10-21 15:46:27,819:INFO:                tqdm: 4.66.1
2023-10-21 15:46:27,819:INFO:               numpy: 1.23.5
2023-10-21 15:46:27,819:INFO:              pandas: 1.5.3
2023-10-21 15:46:27,819:INFO:              jinja2: 3.1.2
2023-10-21 15:46:27,819:INFO:               scipy: 1.10.1
2023-10-21 15:46:27,819:INFO:              joblib: 1.3.2
2023-10-21 15:46:27,819:INFO:             sklearn: 1.2.2
2023-10-21 15:46:27,819:INFO:                pyod: 1.1.0
2023-10-21 15:46:27,819:INFO:            imblearn: 0.11.0
2023-10-21 15:46:27,819:INFO:   category_encoders: 2.6.2
2023-10-21 15:46:27,819:INFO:            lightgbm: 4.1.0
2023-10-21 15:46:27,819:INFO:               numba: 0.58.1
2023-10-21 15:46:27,819:INFO:            requests: 2.31.0
2023-10-21 15:46:27,819:INFO:          matplotlib: 3.7.3
2023-10-21 15:46:27,819:INFO:          scikitplot: 0.3.7
2023-10-21 15:46:27,819:INFO:         yellowbrick: 1.5
2023-10-21 15:46:27,819:INFO:              plotly: 5.17.0
2023-10-21 15:46:27,819:INFO:    plotly-resampler: Not installed
2023-10-21 15:46:27,819:INFO:             kaleido: 0.2.1
2023-10-21 15:46:27,819:INFO:           schemdraw: 0.15
2023-10-21 15:46:27,819:INFO:         statsmodels: 0.14.0
2023-10-21 15:46:27,819:INFO:              sktime: 0.21.1
2023-10-21 15:46:27,819:INFO:               tbats: 1.1.3
2023-10-21 15:46:27,819:INFO:            pmdarima: 2.0.3
2023-10-21 15:46:27,819:INFO:              psutil: 5.9.0
2023-10-21 15:46:27,819:INFO:          markupsafe: 2.1.3
2023-10-21 15:46:27,819:INFO:             pickle5: Not installed
2023-10-21 15:46:27,819:INFO:         cloudpickle: 2.2.1
2023-10-21 15:46:27,819:INFO:         deprecation: 2.1.0
2023-10-21 15:46:27,819:INFO:              xxhash: 3.4.1
2023-10-21 15:46:27,819:INFO:           wurlitzer: Not installed
2023-10-21 15:46:27,819:INFO:PyCaret optional dependencies:
2023-10-21 15:46:27,819:INFO:                shap: Not installed
2023-10-21 15:46:27,819:INFO:           interpret: Not installed
2023-10-21 15:46:27,819:INFO:                umap: Not installed
2023-10-21 15:46:27,819:INFO:     ydata_profiling: Not installed
2023-10-21 15:46:27,819:INFO:  explainerdashboard: Not installed
2023-10-21 15:46:27,819:INFO:             autoviz: Not installed
2023-10-21 15:46:27,819:INFO:           fairlearn: Not installed
2023-10-21 15:46:27,819:INFO:          deepchecks: Not installed
2023-10-21 15:46:27,819:INFO:             xgboost: Not installed
2023-10-21 15:46:27,819:INFO:            catboost: 1.2.2
2023-10-21 15:46:27,819:INFO:              kmodes: Not installed
2023-10-21 15:46:27,819:INFO:             mlxtend: Not installed
2023-10-21 15:46:27,819:INFO:       statsforecast: Not installed
2023-10-21 15:46:27,819:INFO:        tune_sklearn: Not installed
2023-10-21 15:46:27,819:INFO:                 ray: Not installed
2023-10-21 15:46:27,819:INFO:            hyperopt: Not installed
2023-10-21 15:46:27,819:INFO:              optuna: Not installed
2023-10-21 15:46:27,819:INFO:               skopt: Not installed
2023-10-21 15:46:27,819:INFO:              mlflow: 2.7.1
2023-10-21 15:46:27,819:INFO:              gradio: Not installed
2023-10-21 15:46:27,819:INFO:             fastapi: Not installed
2023-10-21 15:46:27,819:INFO:             uvicorn: Not installed
2023-10-21 15:46:27,819:INFO:              m2cgen: Not installed
2023-10-21 15:46:27,819:INFO:           evidently: Not installed
2023-10-21 15:46:27,834:INFO:               fugue: Not installed
2023-10-21 15:46:27,834:INFO:           streamlit: Not installed
2023-10-21 15:46:27,834:INFO:             prophet: Not installed
2023-10-21 15:46:27,834:INFO:None
2023-10-21 15:46:27,834:INFO:Set up data.
2023-10-21 15:46:27,852:INFO:Set up folding strategy.
2023-10-21 15:46:27,852:INFO:Set up train/test split.
2023-10-21 15:46:27,873:INFO:Set up index.
2023-10-21 15:46:27,873:INFO:Assigning column types.
2023-10-21 15:46:27,885:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-21 15:46:27,885:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 15:46:27,902:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 15:46:27,902:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:46:27,985:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,035:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,035:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:46:28,035:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:46:28,035:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,035:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,050:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,119:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,169:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,169:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:46:28,169:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:46:28,169:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-21 15:46:28,185:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,185:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,268:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,318:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,318:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:46:28,318:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:46:28,318:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,318:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,402:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,451:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,451:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:46:28,451:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:46:28,451:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-21 15:46:28,467:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,536:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,585:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,585:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:46:28,585:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:46:28,602:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,668:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,736:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,736:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:46:28,736:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:46:28,736:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-21 15:46:28,818:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,872:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,872:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:46:28,872:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:46:28,966:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:46:29,018:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:46:29,018:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:46:29,018:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:46:29,018:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-21 15:46:29,101:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:46:29,151:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:46:29,151:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:46:29,236:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:46:29,284:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:46:29,284:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:46:29,299:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-21 15:46:29,436:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:46:29,436:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:46:29,584:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:46:29,584:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:46:29,584:INFO:Preparing preprocessing pipeline...
2023-10-21 15:46:29,584:INFO:Set up simple imputation.
2023-10-21 15:46:29,584:INFO:Set up column name cleaning.
2023-10-21 15:46:29,637:INFO:Finished creating preprocessing pipeline.
2023-10-21 15:46:29,650:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 15:46:29,650:INFO:Creating final display dataframe.
2023-10-21 15:46:29,837:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (26071, 50)
4        Transformed data shape   (26071, 50)
5   Transformed train set shape   (18249, 50)
6    Transformed test set shape    (7822, 50)
7              Numeric features            49
8      Rows with missing values         95.9%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_C
19                          USI          54c7
2023-10-21 15:46:30,000:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:46:30,000:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:46:30,137:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:46:30,148:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:46:30,150:INFO:Logging experiment in loggers
2023-10-21 15:46:30,250:INFO:SubProcess save_model() called ==================================
2023-10-21 15:46:30,267:INFO:Initializing save_model()
2023-10-21 15:46:30,267:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmpdslaeafk\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 15:46:30,267:INFO:Adding model into prep_pipe
2023-10-21 15:46:30,267:WARNING:Only Model saved as it was a pipeline.
2023-10-21 15:46:30,267:INFO:C:\Users\thoma\AppData\Local\Temp\tmpdslaeafk\Transformation Pipeline.pkl saved in current working directory
2023-10-21 15:46:30,267:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 15:46:30,267:INFO:save_model() successfully completed......................................
2023-10-21 15:46:30,483:INFO:SubProcess save_model() end ==================================
2023-10-21 15:46:30,517:INFO:setup() successfully completed in 2.33s...............
2023-10-21 15:46:30,517:INFO:Initializing create_model()
2023-10-21 15:46:30,517:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCBE0D90>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 15:46:30,517:INFO:Checking exceptions
2023-10-21 15:46:30,517:INFO:Importing libraries
2023-10-21 15:46:30,517:INFO:Copying training dataset
2023-10-21 15:46:30,538:INFO:Defining folds
2023-10-21 15:46:30,538:INFO:Declaring metric variables
2023-10-21 15:46:30,538:INFO:Importing untrained model
2023-10-21 15:46:30,538:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 15:46:30,538:INFO:Starting cross validation
2023-10-21 15:46:30,538:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 15:46:33,141:INFO:Calculating mean and std
2023-10-21 15:46:33,141:INFO:Creating metrics dataframe
2023-10-21 15:46:33,147:INFO:Finalizing model
2023-10-21 15:46:33,251:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005335 seconds.
2023-10-21 15:46:33,251:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:33,252:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-21 15:46:33,252:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-21 15:46:33,253:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-21 15:46:33,464:INFO:Creating Dashboard logs
2023-10-21 15:46:33,464:INFO:Model: Light Gradient Boosting Machine
2023-10-21 15:46:33,564:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 15:46:33,747:INFO:Initializing predict_model()
2023-10-21 15:46:33,747:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCBE0D90>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002098DAA5790>)
2023-10-21 15:46:33,747:INFO:Checking exceptions
2023-10-21 15:46:33,747:INFO:Preloading libraries
2023-10-21 15:46:34,430:INFO:Uploading results into container
2023-10-21 15:46:34,430:INFO:Uploading model into container now
2023-10-21 15:46:34,443:INFO:_master_model_container: 1
2023-10-21 15:46:34,445:INFO:_display_container: 2
2023-10-21 15:46:34,446:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 15:46:34,446:INFO:create_model() successfully completed......................................
2023-10-21 15:46:34,646:INFO:Initializing tune_model()
2023-10-21 15:46:34,646:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCBE0D90>)
2023-10-21 15:46:34,646:INFO:Checking exceptions
2023-10-21 15:46:34,663:INFO:Copying training dataset
2023-10-21 15:46:34,682:INFO:Checking base model
2023-10-21 15:46:34,682:INFO:Base model : Light Gradient Boosting Machine
2023-10-21 15:46:34,682:INFO:Declaring metric variables
2023-10-21 15:46:34,682:INFO:Defining Hyperparameters
2023-10-21 15:46:34,896:INFO:Tuning with n_jobs=-1
2023-10-21 15:46:34,896:INFO:Initializing RandomizedSearchCV
2023-10-21 15:47:21,125:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-21 15:47:21,125:INFO:Hyperparameter search completed
2023-10-21 15:47:21,125:INFO:SubProcess create_model() called ==================================
2023-10-21 15:47:21,125:INFO:Initializing create_model()
2023-10-21 15:47:21,125:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCBE0D90>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002098DA01E80>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-21 15:47:21,125:INFO:Checking exceptions
2023-10-21 15:47:21,125:INFO:Importing libraries
2023-10-21 15:47:21,125:INFO:Copying training dataset
2023-10-21 15:47:21,169:INFO:Defining folds
2023-10-21 15:47:21,169:INFO:Declaring metric variables
2023-10-21 15:47:21,171:INFO:Importing untrained model
2023-10-21 15:47:21,171:INFO:Declaring custom model
2023-10-21 15:47:21,172:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 15:47:21,173:INFO:Starting cross validation
2023-10-21 15:47:21,174:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 15:47:30,367:INFO:Calculating mean and std
2023-10-21 15:47:30,367:INFO:Creating metrics dataframe
2023-10-21 15:47:30,367:INFO:Finalizing model
2023-10-21 15:47:30,426:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 15:47:30,427:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 15:47:30,427:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 15:47:30,450:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 15:47:30,450:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 15:47:30,450:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 15:47:30,467:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005335 seconds.
2023-10-21 15:47:30,467:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:47:30,467:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-21 15:47:30,467:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-21 15:47:30,467:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-21 15:47:30,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 15:47:30,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 15:47:30,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 15:47:30,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 15:47:30,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 15:47:30,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 15:47:30,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 15:47:30,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 15:47:31,617:INFO:Uploading results into container
2023-10-21 15:47:31,619:INFO:Uploading model into container now
2023-10-21 15:47:31,621:INFO:_master_model_container: 2
2023-10-21 15:47:31,621:INFO:_display_container: 3
2023-10-21 15:47:31,623:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-21 15:47:31,623:INFO:create_model() successfully completed......................................
2023-10-21 15:47:31,870:INFO:SubProcess create_model() end ==================================
2023-10-21 15:47:31,870:INFO:choose_better activated
2023-10-21 15:47:31,870:INFO:SubProcess create_model() called ==================================
2023-10-21 15:47:31,876:INFO:Initializing create_model()
2023-10-21 15:47:31,876:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCBE0D90>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 15:47:31,876:INFO:Checking exceptions
2023-10-21 15:47:31,876:INFO:Importing libraries
2023-10-21 15:47:31,876:INFO:Copying training dataset
2023-10-21 15:47:31,899:INFO:Defining folds
2023-10-21 15:47:31,899:INFO:Declaring metric variables
2023-10-21 15:47:31,899:INFO:Importing untrained model
2023-10-21 15:47:31,899:INFO:Declaring custom model
2023-10-21 15:47:31,899:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 15:47:31,899:INFO:Starting cross validation
2023-10-21 15:47:31,899:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 15:47:34,496:INFO:Calculating mean and std
2023-10-21 15:47:34,497:INFO:Creating metrics dataframe
2023-10-21 15:47:34,497:INFO:Finalizing model
2023-10-21 15:47:34,563:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004016 seconds.
2023-10-21 15:47:34,563:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:47:34,563:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-21 15:47:34,563:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-21 15:47:34,563:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-21 15:47:34,797:INFO:Uploading results into container
2023-10-21 15:47:34,797:INFO:Uploading model into container now
2023-10-21 15:47:34,797:INFO:_master_model_container: 3
2023-10-21 15:47:34,797:INFO:_display_container: 4
2023-10-21 15:47:34,797:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 15:47:34,797:INFO:create_model() successfully completed......................................
2023-10-21 15:47:35,013:INFO:SubProcess create_model() end ==================================
2023-10-21 15:47:35,013:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.905
2023-10-21 15:47:35,028:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8993
2023-10-21 15:47:35,028:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-21 15:47:35,028:INFO:choose_better completed
2023-10-21 15:47:35,028:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-21 15:47:35,030:INFO:Creating Dashboard logs
2023-10-21 15:47:35,030:INFO:Model: Light Gradient Boosting Machine
2023-10-21 15:47:35,080:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 15:47:35,246:INFO:Initializing predict_model()
2023-10-21 15:47:35,246:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCBE0D90>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DBA03670>)
2023-10-21 15:47:35,246:INFO:Checking exceptions
2023-10-21 15:47:35,246:INFO:Preloading libraries
2023-10-21 15:47:35,929:INFO:_master_model_container: 3
2023-10-21 15:47:35,929:INFO:_display_container: 3
2023-10-21 15:47:35,929:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 15:47:35,929:INFO:tune_model() successfully completed......................................
2023-10-21 15:47:36,129:INFO:Initializing ensemble_model()
2023-10-21 15:47:36,129:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCBE0D90>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-21 15:47:36,129:INFO:Checking exceptions
2023-10-21 15:47:36,145:INFO:Importing libraries
2023-10-21 15:47:36,145:INFO:Copying training dataset
2023-10-21 15:47:36,145:INFO:Checking base model
2023-10-21 15:47:36,145:INFO:Base model : Light Gradient Boosting Machine
2023-10-21 15:47:36,145:INFO:Importing untrained ensembler
2023-10-21 15:47:36,145:INFO:Ensemble method set to Bagging
2023-10-21 15:47:36,145:INFO:SubProcess create_model() called ==================================
2023-10-21 15:47:36,145:INFO:Initializing create_model()
2023-10-21 15:47:36,145:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCBE0D90>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209D9BE5BB0>, model_only=True, return_train_score=False, kwargs={})
2023-10-21 15:47:36,145:INFO:Checking exceptions
2023-10-21 15:47:36,145:INFO:Importing libraries
2023-10-21 15:47:36,145:INFO:Copying training dataset
2023-10-21 15:47:36,162:INFO:Defining folds
2023-10-21 15:47:36,162:INFO:Declaring metric variables
2023-10-21 15:47:36,162:INFO:Importing untrained model
2023-10-21 15:47:36,162:INFO:Declaring custom model
2023-10-21 15:47:36,162:INFO:Bagging Regressor Imported successfully
2023-10-21 15:47:36,162:INFO:Starting cross validation
2023-10-21 15:47:36,162:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 06:00:12,211:INFO:Calculating mean and std
2023-10-22 06:00:12,213:INFO:Creating metrics dataframe
2023-10-22 06:00:12,213:INFO:Finalizing model
2023-10-22 06:00:12,427:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018408 seconds.
2023-10-22 06:00:12,427:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:12,429:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-22 06:00:12,429:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-22 06:00:12,429:INFO:[LightGBM] [Info] Start training from score 77.044367
2023-10-22 06:00:13,641:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013711 seconds.
2023-10-22 06:00:13,641:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:13,641:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-22 06:00:13,643:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-22 06:00:13,646:INFO:[LightGBM] [Info] Start training from score 76.520588
2023-10-22 06:00:14,362:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008493 seconds.
2023-10-22 06:00:14,362:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:14,362:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-22 06:00:14,362:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-22 06:00:14,362:INFO:[LightGBM] [Info] Start training from score 76.462170
2023-10-22 06:00:15,064:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005862 seconds.
2023-10-22 06:00:15,064:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:15,064:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-22 06:00:15,075:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-22 06:00:15,078:INFO:[LightGBM] [Info] Start training from score 77.386428
2023-10-22 06:00:15,693:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003786 seconds.
2023-10-22 06:00:15,693:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-22 06:00:15,693:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-22 06:00:15,693:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-22 06:00:15,693:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-22 06:00:15,700:INFO:[LightGBM] [Info] Start training from score 73.916304
2023-10-22 06:00:16,460:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009418 seconds.
2023-10-22 06:00:16,460:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:16,460:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-22 06:00:16,460:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-22 06:00:16,460:INFO:[LightGBM] [Info] Start training from score 75.879633
2023-10-22 06:00:17,177:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005668 seconds.
2023-10-22 06:00:17,177:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:17,177:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-22 06:00:17,177:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-22 06:00:17,177:INFO:[LightGBM] [Info] Start training from score 75.615395
2023-10-22 06:00:17,745:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005515 seconds.
2023-10-22 06:00:17,745:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:17,745:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-22 06:00:17,745:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-22 06:00:17,745:INFO:[LightGBM] [Info] Start training from score 79.544595
2023-10-22 06:00:18,259:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005585 seconds.
2023-10-22 06:00:18,259:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:18,259:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-22 06:00:18,273:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-22 06:00:18,274:INFO:[LightGBM] [Info] Start training from score 76.012052
2023-10-22 06:00:18,776:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004686 seconds.
2023-10-22 06:00:18,776:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:18,776:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-22 06:00:18,776:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-22 06:00:18,776:INFO:[LightGBM] [Info] Start training from score 78.124037
2023-10-22 06:00:19,141:INFO:Uploading results into container
2023-10-22 06:00:19,141:INFO:Uploading model into container now
2023-10-22 06:00:19,141:INFO:_master_model_container: 4
2023-10-22 06:00:19,141:INFO:_display_container: 4
2023-10-22 06:00:19,155:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-22 06:00:19,156:INFO:create_model() successfully completed......................................
2023-10-22 06:00:19,479:INFO:SubProcess create_model() end ==================================
2023-10-22 06:00:19,479:INFO:Creating Dashboard logs
2023-10-22 06:00:19,479:INFO:Model: Bagging Regressor
2023-10-22 06:00:19,641:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-22 06:00:20,026:INFO:Initializing predict_model()
2023-10-22 06:00:20,026:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCBE0D90>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209831F0DC0>)
2023-10-22 06:00:20,026:INFO:Checking exceptions
2023-10-22 06:00:20,026:INFO:Preloading libraries
2023-10-22 06:00:21,305:INFO:_master_model_container: 4
2023-10-22 06:00:21,305:INFO:_display_container: 4
2023-10-22 06:00:21,305:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-22 06:00:21,305:INFO:ensemble_model() successfully completed......................................
2023-10-22 06:00:21,688:INFO:Initializing finalize_model()
2023-10-22 06:00:21,688:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCBE0D90>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-22 06:00:21,688:INFO:Finalizing BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-22 06:00:21,710:INFO:Initializing create_model()
2023-10-22 06:00:21,710:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCBE0D90>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-22 06:00:21,710:INFO:Checking exceptions
2023-10-22 06:00:21,710:INFO:Importing libraries
2023-10-22 06:00:21,710:INFO:Copying training dataset
2023-10-22 06:00:21,710:INFO:Defining folds
2023-10-22 06:00:21,710:INFO:Declaring metric variables
2023-10-22 06:00:21,710:INFO:Importing untrained model
2023-10-22 06:00:21,710:INFO:Declaring custom model
2023-10-22 06:00:21,720:INFO:Bagging Regressor Imported successfully
2023-10-22 06:00:21,721:INFO:Cross validation set to False
2023-10-22 06:00:21,721:INFO:Fitting Model
2023-10-22 06:00:21,871:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007416 seconds.
2023-10-22 06:00:21,871:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:21,871:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-22 06:00:21,871:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-22 06:00:21,871:INFO:[LightGBM] [Info] Start training from score 77.360615
2023-10-22 06:00:22,287:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005908 seconds.
2023-10-22 06:00:22,287:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:22,287:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-22 06:00:22,296:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-22 06:00:22,296:INFO:[LightGBM] [Info] Start training from score 78.162759
2023-10-22 06:00:22,920:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007327 seconds.
2023-10-22 06:00:22,920:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:22,920:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-22 06:00:22,920:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-22 06:00:22,926:INFO:[LightGBM] [Info] Start training from score 77.185434
2023-10-22 06:00:23,379:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007738 seconds.
2023-10-22 06:00:23,379:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:23,379:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-22 06:00:23,379:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-22 06:00:23,379:INFO:[LightGBM] [Info] Start training from score 78.293126
2023-10-22 06:00:23,886:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008236 seconds.
2023-10-22 06:00:23,886:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:23,886:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-22 06:00:23,886:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-22 06:00:23,891:INFO:[LightGBM] [Info] Start training from score 75.493649
2023-10-22 06:00:24,329:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006544 seconds.
2023-10-22 06:00:24,329:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:24,329:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-22 06:00:24,329:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-22 06:00:24,334:INFO:[LightGBM] [Info] Start training from score 77.467219
2023-10-22 06:00:24,777:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006316 seconds.
2023-10-22 06:00:24,777:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:24,777:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-22 06:00:24,777:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-22 06:00:24,782:INFO:[LightGBM] [Info] Start training from score 77.083598
2023-10-22 06:00:25,278:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006562 seconds.
2023-10-22 06:00:25,278:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:25,278:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-22 06:00:25,278:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-22 06:00:25,278:INFO:[LightGBM] [Info] Start training from score 79.854607
2023-10-22 06:00:25,779:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007476 seconds.
2023-10-22 06:00:25,779:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:25,779:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-22 06:00:25,779:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-22 06:00:25,779:INFO:[LightGBM] [Info] Start training from score 76.153078
2023-10-22 06:00:26,203:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006755 seconds.
2023-10-22 06:00:26,203:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:26,211:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-22 06:00:26,211:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-22 06:00:26,211:INFO:[LightGBM] [Info] Start training from score 78.843978
2023-10-22 06:00:26,596:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-22 06:00:26,599:INFO:create_model() successfully completed......................................
2023-10-22 06:00:27,178:INFO:Creating Dashboard logs
2023-10-22 06:00:27,180:INFO:Model: Bagging Regressor
2023-10-22 06:00:27,309:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-22 06:00:28,283:INFO:_master_model_container: 4
2023-10-22 06:00:28,283:INFO:_display_container: 4
2023-10-22 06:00:28,304:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-22 06:00:28,304:INFO:finalize_model() successfully completed......................................
2023-10-22 06:00:28,746:INFO:Initializing save_model()
2023-10-22 06:00:28,746:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), model_name=final_model_for_location_C, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-22 06:00:28,746:INFO:Adding model into prep_pipe
2023-10-22 06:00:28,746:WARNING:Only Model saved as it was a pipeline.
2023-10-22 06:00:28,827:INFO:final_model_for_location_C.pkl saved in current working directory
2023-10-22 06:00:28,851:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-22 06:00:28,851:INFO:save_model() successfully completed......................................
2023-10-22 20:28:39,809:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\base\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals
  warnings.warn("Maximum Likelihood optimization failed to "

2023-10-23 09:36:55,148:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.
  self._init_dates(dates, freq)

2023-10-23 09:36:55,150:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.
  self._init_dates(dates, freq)

2023-10-23 09:36:55,152:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.
  self._init_dates(dates, freq)

2023-10-23 09:41:36,374:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.
  self._init_dates(dates, freq)

2023-10-23 09:41:36,374:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.
  self._init_dates(dates, freq)

2023-10-23 09:41:36,374:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.
  self._init_dates(dates, freq)

2023-10-23 09:41:45,324:INFO:Initializing predict_model()
2023-10-23 09:41:45,340:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCBE0D90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002098DAA5A60>)
2023-10-23 09:41:45,340:INFO:Checking exceptions
2023-10-23 09:41:45,340:INFO:Preloading libraries
2023-10-23 09:41:45,340:INFO:Set up data.
2023-10-23 09:41:45,402:INFO:Set up index.
2023-10-23 09:42:01,711:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\base\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals
  warnings.warn("Maximum Likelihood optimization failed to "

2023-10-23 09:42:03,101:INFO:Initializing predict_model()
2023-10-23 09:42:03,101:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCBE0D90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DA6BEA60>)
2023-10-23 09:42:03,101:INFO:Checking exceptions
2023-10-23 09:42:03,101:INFO:Preloading libraries
2023-10-23 09:42:03,102:INFO:Set up data.
2023-10-23 09:42:03,137:INFO:Set up index.
2023-10-23 09:42:03,786:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.
  self._init_dates(dates, freq)

2023-10-23 09:42:03,786:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.
  self._init_dates(dates, freq)

2023-10-23 09:42:03,787:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.
  self._init_dates(dates, freq)

2023-10-23 10:27:50,104:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-23 10:27:50,104:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-23 10:27:50,104:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-23 10:27:50,104:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-23 10:27:50,458:INFO:PyCaret RegressionExperiment
2023-10-23 10:27:50,458:INFO:Logging name: exp_A
2023-10-23 10:27:50,458:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 10:27:50,458:INFO:version 3.1.0
2023-10-23 10:27:50,458:INFO:Initializing setup()
2023-10-23 10:27:50,458:INFO:self.USI: eaad
2023-10-23 10:27:50,458:INFO:self._variable_keys: {'data', 'X_test', 'html_param', 'exp_id', 'exp_name_log', 'log_plots_param', '_available_plots', 'idx', 'pipeline', 'fold_generator', 'y', 'X', 'gpu_n_jobs_param', 'logging_param', 'memory', 'n_jobs_param', 'target_param', 'X_train', 'gpu_param', 'seed', 'USI', 'y_test', 'transform_target_param', 'y_train', 'fold_shuffle_param', 'fold_groups_param', '_ml_usecase'}
2023-10-23 10:27:50,458:INFO:Checking environment
2023-10-23 10:27:50,458:INFO:python_version: 3.8.18
2023-10-23 10:27:50,458:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 10:27:50,458:INFO:machine: AMD64
2023-10-23 10:27:50,472:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 10:27:50,472:INFO:Memory: svmem(total=16505954304, available=4717416448, percent=71.4, used=11788537856, free=4717416448)
2023-10-23 10:27:50,472:INFO:Physical Core: 8
2023-10-23 10:27:50,472:INFO:Logical Core: 16
2023-10-23 10:27:50,472:INFO:Checking libraries
2023-10-23 10:27:50,472:INFO:System:
2023-10-23 10:27:50,472:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 10:27:50,472:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 10:27:50,472:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 10:27:50,472:INFO:PyCaret required dependencies:
2023-10-23 10:27:50,596:INFO:                 pip: 23.3
2023-10-23 10:27:50,596:INFO:          setuptools: 68.0.0
2023-10-23 10:27:50,596:INFO:             pycaret: 3.1.0
2023-10-23 10:27:50,596:INFO:             IPython: 8.12.0
2023-10-23 10:27:50,596:INFO:          ipywidgets: 8.1.1
2023-10-23 10:27:50,596:INFO:                tqdm: 4.66.1
2023-10-23 10:27:50,596:INFO:               numpy: 1.23.5
2023-10-23 10:27:50,596:INFO:              pandas: 1.5.3
2023-10-23 10:27:50,596:INFO:              jinja2: 3.1.2
2023-10-23 10:27:50,596:INFO:               scipy: 1.10.1
2023-10-23 10:27:50,596:INFO:              joblib: 1.3.2
2023-10-23 10:27:50,596:INFO:             sklearn: 1.2.2
2023-10-23 10:27:50,596:INFO:                pyod: 1.1.0
2023-10-23 10:27:50,596:INFO:            imblearn: 0.11.0
2023-10-23 10:27:50,596:INFO:   category_encoders: 2.6.2
2023-10-23 10:27:50,596:INFO:            lightgbm: 4.1.0
2023-10-23 10:27:50,596:INFO:               numba: 0.58.1
2023-10-23 10:27:50,596:INFO:            requests: 2.31.0
2023-10-23 10:27:50,596:INFO:          matplotlib: 3.7.3
2023-10-23 10:27:50,596:INFO:          scikitplot: 0.3.7
2023-10-23 10:27:50,596:INFO:         yellowbrick: 1.5
2023-10-23 10:27:50,596:INFO:              plotly: 5.17.0
2023-10-23 10:27:50,596:INFO:    plotly-resampler: Not installed
2023-10-23 10:27:50,596:INFO:             kaleido: 0.2.1
2023-10-23 10:27:50,596:INFO:           schemdraw: 0.15
2023-10-23 10:27:50,596:INFO:         statsmodels: 0.14.0
2023-10-23 10:27:50,596:INFO:              sktime: 0.21.1
2023-10-23 10:27:50,596:INFO:               tbats: 1.1.3
2023-10-23 10:27:50,596:INFO:            pmdarima: 2.0.3
2023-10-23 10:27:50,596:INFO:              psutil: 5.9.0
2023-10-23 10:27:50,596:INFO:          markupsafe: 2.1.3
2023-10-23 10:27:50,596:INFO:             pickle5: Not installed
2023-10-23 10:27:50,596:INFO:         cloudpickle: 2.2.1
2023-10-23 10:27:50,596:INFO:         deprecation: 2.1.0
2023-10-23 10:27:50,596:INFO:              xxhash: 3.4.1
2023-10-23 10:27:50,596:INFO:           wurlitzer: Not installed
2023-10-23 10:27:50,596:INFO:PyCaret optional dependencies:
2023-10-23 10:27:50,638:INFO:                shap: Not installed
2023-10-23 10:27:50,638:INFO:           interpret: Not installed
2023-10-23 10:27:50,638:INFO:                umap: Not installed
2023-10-23 10:27:50,638:INFO:     ydata_profiling: Not installed
2023-10-23 10:27:50,638:INFO:  explainerdashboard: Not installed
2023-10-23 10:27:50,638:INFO:             autoviz: Not installed
2023-10-23 10:27:50,638:INFO:           fairlearn: Not installed
2023-10-23 10:27:50,638:INFO:          deepchecks: Not installed
2023-10-23 10:27:50,638:INFO:             xgboost: Not installed
2023-10-23 10:27:50,638:INFO:            catboost: 1.2.2
2023-10-23 10:27:50,638:INFO:              kmodes: Not installed
2023-10-23 10:27:50,638:INFO:             mlxtend: Not installed
2023-10-23 10:27:50,638:INFO:       statsforecast: Not installed
2023-10-23 10:27:50,638:INFO:        tune_sklearn: Not installed
2023-10-23 10:27:50,638:INFO:                 ray: Not installed
2023-10-23 10:27:50,638:INFO:            hyperopt: Not installed
2023-10-23 10:27:50,638:INFO:              optuna: Not installed
2023-10-23 10:27:50,638:INFO:               skopt: Not installed
2023-10-23 10:27:50,638:INFO:              mlflow: 2.7.1
2023-10-23 10:27:50,638:INFO:              gradio: Not installed
2023-10-23 10:27:50,638:INFO:             fastapi: Not installed
2023-10-23 10:27:50,638:INFO:             uvicorn: Not installed
2023-10-23 10:27:50,638:INFO:              m2cgen: Not installed
2023-10-23 10:27:50,638:INFO:           evidently: Not installed
2023-10-23 10:27:50,638:INFO:               fugue: Not installed
2023-10-23 10:27:50,638:INFO:           streamlit: Not installed
2023-10-23 10:27:50,638:INFO:             prophet: Not installed
2023-10-23 10:27:50,638:INFO:None
2023-10-23 10:27:50,638:INFO:Set up data.
2023-10-23 10:27:50,689:INFO:Set up folding strategy.
2023-10-23 10:27:50,689:INFO:Set up train/test split.
2023-10-23 10:27:50,728:INFO:Set up index.
2023-10-23 10:27:50,728:INFO:Assigning column types.
2023-10-23 10:27:50,768:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 10:27:50,768:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 10:27:50,774:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 10:27:50,789:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 10:27:50,916:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 10:27:50,990:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 10:27:50,990:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 10:27:50,990:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 10:27:50,990:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,002:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,002:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,136:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,214:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,214:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 10:27:51,214:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 10:27:51,214:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 10:27:51,230:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,230:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,348:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,434:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,434:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 10:27:51,434:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 10:27:51,450:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,450:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,568:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,653:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,653:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 10:27:51,653:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 10:27:51,653:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 10:27:51,669:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,800:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,878:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,878:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 10:27:51,878:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 10:27:51,894:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 10:27:52,022:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 10:27:52,115:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 10:27:52,115:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 10:27:52,115:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 10:27:52,115:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 10:27:52,270:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 10:27:52,353:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 10:27:52,356:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 10:27:52,356:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 10:27:52,513:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 10:27:52,596:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 10:27:52,596:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 10:27:52,596:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 10:27:52,596:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 10:27:52,747:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 10:27:52,831:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 10:27:52,831:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 10:27:52,994:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 10:27:53,079:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 10:27:53,079:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 10:27:53,081:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 10:27:53,338:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 10:27:53,338:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 10:27:53,612:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 10:27:53,612:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 10:27:53,612:INFO:Preparing preprocessing pipeline...
2023-10-23 10:27:53,612:INFO:Set up simple imputation.
2023-10-23 10:27:53,619:INFO:Set up column name cleaning.
2023-10-23 10:27:53,738:INFO:Finished creating preprocessing pipeline.
2023-10-23 10:27:53,754:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 10:27:53,754:INFO:Creating final display dataframe.
2023-10-23 10:27:54,124:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (34061, 50)
4        Transformed data shape   (34061, 50)
5   Transformed train set shape   (23842, 50)
6    Transformed test set shape   (10219, 50)
7              Numeric features            49
8      Rows with missing values         97.6%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_A
19                          USI          eaad
2023-10-23 10:27:54,316:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 10:27:54,316:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 10:27:54,521:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 10:27:54,521:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 10:27:54,521:INFO:Logging experiment in loggers
2023-10-23 10:27:55,047:INFO:SubProcess save_model() called ==================================
2023-10-23 10:27:55,060:INFO:Initializing save_model()
2023-10-23 10:27:55,060:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmps3mkt90d\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 10:27:55,060:INFO:Adding model into prep_pipe
2023-10-23 10:27:55,060:WARNING:Only Model saved as it was a pipeline.
2023-10-23 10:27:55,062:INFO:C:\Users\thoma\AppData\Local\Temp\tmps3mkt90d\Transformation Pipeline.pkl saved in current working directory
2023-10-23 10:27:55,068:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 10:27:55,068:INFO:save_model() successfully completed......................................
2023-10-23 10:27:55,164:INFO:SubProcess save_model() end ==================================
2023-10-23 10:27:55,252:INFO:setup() successfully completed in 4.06s...............
2023-10-23 10:27:55,252:INFO:Initializing create_model()
2023-10-23 10:27:55,252:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018BFA725310>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 10:27:55,252:INFO:Checking exceptions
2023-10-23 10:27:55,252:INFO:Importing libraries
2023-10-23 10:27:55,252:INFO:Copying training dataset
2023-10-23 10:27:55,277:INFO:Defining folds
2023-10-23 10:27:55,277:INFO:Declaring metric variables
2023-10-23 10:27:55,277:INFO:Importing untrained model
2023-10-23 10:27:55,277:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 10:27:55,277:INFO:Starting cross validation
2023-10-23 10:27:55,277:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 10:28:02,921:INFO:Calculating mean and std
2023-10-23 10:28:02,923:INFO:Creating metrics dataframe
2023-10-23 10:28:02,923:INFO:Finalizing model
2023-10-23 10:28:03,055:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006533 seconds.
2023-10-23 10:28:03,055:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 10:28:03,055:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 10:28:03,055:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 10:28:03,060:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-23 10:28:03,282:INFO:Creating Dashboard logs
2023-10-23 10:28:03,282:INFO:Model: Light Gradient Boosting Machine
2023-10-23 10:28:03,361:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 10:28:03,549:INFO:Initializing predict_model()
2023-10-23 10:28:03,549:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018BFA725310>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018B80298820>)
2023-10-23 10:28:03,549:INFO:Checking exceptions
2023-10-23 10:28:03,549:INFO:Preloading libraries
2023-10-23 10:28:03,817:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\_distutils_hack\__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2023-10-23 10:28:04,006:INFO:Uploading results into container
2023-10-23 10:28:04,006:INFO:Uploading model into container now
2023-10-23 10:28:04,014:INFO:_master_model_container: 1
2023-10-23 10:28:04,014:INFO:_display_container: 2
2023-10-23 10:28:04,014:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 10:28:04,014:INFO:create_model() successfully completed......................................
2023-10-23 10:28:04,118:INFO:Initializing tune_model()
2023-10-23 10:28:04,118:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018BFA725310>)
2023-10-23 10:28:04,118:INFO:Checking exceptions
2023-10-23 10:28:04,132:INFO:Copying training dataset
2023-10-23 10:28:04,143:INFO:Checking base model
2023-10-23 10:28:04,143:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 10:28:04,143:INFO:Declaring metric variables
2023-10-23 10:28:04,143:INFO:Defining Hyperparameters
2023-10-23 10:28:04,244:INFO:Tuning with n_jobs=-1
2023-10-23 10:28:04,244:INFO:Initializing RandomizedSearchCV
2023-10-23 14:31:20,238:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-23 14:31:20,238:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-23 14:31:20,238:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-23 14:31:20,238:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-23 14:31:20,480:INFO:PyCaret RegressionExperiment
2023-10-23 14:31:20,480:INFO:Logging name: exp_A
2023-10-23 14:31:20,480:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 14:31:20,480:INFO:version 3.1.0
2023-10-23 14:31:20,480:INFO:Initializing setup()
2023-10-23 14:31:20,480:INFO:self.USI: fafb
2023-10-23 14:31:20,480:INFO:self._variable_keys: {'gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', '_ml_usecase', 'gpu_param', 'exp_name_log', 'html_param', 'fold_generator', 'y', 'seed', 'y_train', 'transform_target_param', 'n_jobs_param', 'target_param', 'idx', '_available_plots', 'log_plots_param', 'memory', 'data', 'USI', 'X', 'logging_param', 'pipeline', 'exp_id', 'X_train', 'X_test', 'fold_groups_param'}
2023-10-23 14:31:20,480:INFO:Checking environment
2023-10-23 14:31:20,480:INFO:python_version: 3.8.18
2023-10-23 14:31:20,481:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 14:31:20,481:INFO:machine: AMD64
2023-10-23 14:31:20,481:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 14:31:20,481:INFO:Memory: svmem(total=16505954304, available=4661129216, percent=71.8, used=11844825088, free=4661129216)
2023-10-23 14:31:20,481:INFO:Physical Core: 8
2023-10-23 14:31:20,481:INFO:Logical Core: 16
2023-10-23 14:31:20,481:INFO:Checking libraries
2023-10-23 14:31:20,481:INFO:System:
2023-10-23 14:31:20,481:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 14:31:20,481:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 14:31:20,481:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 14:31:20,481:INFO:PyCaret required dependencies:
2023-10-23 14:31:20,573:INFO:                 pip: 23.3
2023-10-23 14:31:20,573:INFO:          setuptools: 68.0.0
2023-10-23 14:31:20,573:INFO:             pycaret: 3.1.0
2023-10-23 14:31:20,574:INFO:             IPython: 8.12.0
2023-10-23 14:31:20,574:INFO:          ipywidgets: 8.1.1
2023-10-23 14:31:20,574:INFO:                tqdm: 4.66.1
2023-10-23 14:31:20,574:INFO:               numpy: 1.23.5
2023-10-23 14:31:20,574:INFO:              pandas: 1.5.3
2023-10-23 14:31:20,574:INFO:              jinja2: 3.1.2
2023-10-23 14:31:20,574:INFO:               scipy: 1.10.1
2023-10-23 14:31:20,574:INFO:              joblib: 1.3.2
2023-10-23 14:31:20,574:INFO:             sklearn: 1.2.2
2023-10-23 14:31:20,574:INFO:                pyod: 1.1.0
2023-10-23 14:31:20,574:INFO:            imblearn: 0.11.0
2023-10-23 14:31:20,574:INFO:   category_encoders: 2.6.2
2023-10-23 14:31:20,574:INFO:            lightgbm: 4.1.0
2023-10-23 14:31:20,574:INFO:               numba: 0.58.1
2023-10-23 14:31:20,574:INFO:            requests: 2.31.0
2023-10-23 14:31:20,574:INFO:          matplotlib: 3.7.3
2023-10-23 14:31:20,574:INFO:          scikitplot: 0.3.7
2023-10-23 14:31:20,574:INFO:         yellowbrick: 1.5
2023-10-23 14:31:20,574:INFO:              plotly: 5.17.0
2023-10-23 14:31:20,574:INFO:    plotly-resampler: Not installed
2023-10-23 14:31:20,574:INFO:             kaleido: 0.2.1
2023-10-23 14:31:20,575:INFO:           schemdraw: 0.15
2023-10-23 14:31:20,575:INFO:         statsmodels: 0.14.0
2023-10-23 14:31:20,575:INFO:              sktime: 0.21.1
2023-10-23 14:31:20,575:INFO:               tbats: 1.1.3
2023-10-23 14:31:20,575:INFO:            pmdarima: 2.0.3
2023-10-23 14:31:20,575:INFO:              psutil: 5.9.0
2023-10-23 14:31:20,575:INFO:          markupsafe: 2.1.3
2023-10-23 14:31:20,575:INFO:             pickle5: Not installed
2023-10-23 14:31:20,575:INFO:         cloudpickle: 2.2.1
2023-10-23 14:31:20,575:INFO:         deprecation: 2.1.0
2023-10-23 14:31:20,575:INFO:              xxhash: 3.4.1
2023-10-23 14:31:20,575:INFO:           wurlitzer: Not installed
2023-10-23 14:31:20,575:INFO:PyCaret optional dependencies:
2023-10-23 14:31:20,591:INFO:                shap: Not installed
2023-10-23 14:31:20,591:INFO:           interpret: Not installed
2023-10-23 14:31:20,591:INFO:                umap: Not installed
2023-10-23 14:31:20,591:INFO:     ydata_profiling: Not installed
2023-10-23 14:31:20,592:INFO:  explainerdashboard: Not installed
2023-10-23 14:31:20,592:INFO:             autoviz: Not installed
2023-10-23 14:31:20,592:INFO:           fairlearn: Not installed
2023-10-23 14:31:20,592:INFO:          deepchecks: Not installed
2023-10-23 14:31:20,592:INFO:             xgboost: Not installed
2023-10-23 14:31:20,592:INFO:            catboost: 1.2.2
2023-10-23 14:31:20,592:INFO:              kmodes: Not installed
2023-10-23 14:31:20,592:INFO:             mlxtend: Not installed
2023-10-23 14:31:20,592:INFO:       statsforecast: Not installed
2023-10-23 14:31:20,592:INFO:        tune_sklearn: Not installed
2023-10-23 14:31:20,592:INFO:                 ray: Not installed
2023-10-23 14:31:20,592:INFO:            hyperopt: Not installed
2023-10-23 14:31:20,592:INFO:              optuna: Not installed
2023-10-23 14:31:20,592:INFO:               skopt: Not installed
2023-10-23 14:31:20,592:INFO:              mlflow: 2.7.1
2023-10-23 14:31:20,592:INFO:              gradio: Not installed
2023-10-23 14:31:20,593:INFO:             fastapi: Not installed
2023-10-23 14:31:20,593:INFO:             uvicorn: Not installed
2023-10-23 14:31:20,593:INFO:              m2cgen: Not installed
2023-10-23 14:31:20,593:INFO:           evidently: Not installed
2023-10-23 14:31:20,593:INFO:               fugue: Not installed
2023-10-23 14:31:20,593:INFO:           streamlit: Not installed
2023-10-23 14:31:20,593:INFO:             prophet: Not installed
2023-10-23 14:31:20,593:INFO:None
2023-10-23 14:31:20,593:INFO:Set up data.
2023-10-23 14:31:20,624:INFO:Set up folding strategy.
2023-10-23 14:31:20,624:INFO:Set up train/test split.
2023-10-23 14:31:20,660:INFO:Set up index.
2023-10-23 14:31:20,660:INFO:Assigning column types.
2023-10-23 14:31:20,691:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 14:31:20,691:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 14:31:20,700:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:31:20,700:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:31:20,791:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:31:20,838:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:31:20,838:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:31:20,838:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:31:20,838:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 14:31:20,838:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:31:20,854:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:31:20,934:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:31:20,991:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:31:20,991:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:31:20,992:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:31:20,992:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 14:31:20,998:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,003:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,082:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,119:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,119:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:31:21,119:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:31:21,138:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,143:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,225:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,276:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,276:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:31:21,276:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:31:21,276:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 14:31:21,295:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,381:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,435:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,436:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:31:21,436:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:31:21,436:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,535:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,586:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,591:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:31:21,591:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:31:21,591:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 14:31:21,684:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,736:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,737:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:31:21,737:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:31:21,837:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,891:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,891:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:31:21,891:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:31:21,891:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 14:31:22,006:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:31:22,065:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:31:22,066:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:31:22,153:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:31:22,210:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:31:22,210:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:31:22,211:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 14:31:22,351:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:31:22,352:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:31:22,517:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:31:22,517:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:31:22,518:INFO:Preparing preprocessing pipeline...
2023-10-23 14:31:22,518:INFO:Set up simple imputation.
2023-10-23 14:31:22,518:INFO:Set up column name cleaning.
2023-10-23 14:31:22,620:INFO:Finished creating preprocessing pipeline.
2023-10-23 14:31:22,626:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 14:31:22,626:INFO:Creating final display dataframe.
2023-10-23 14:31:22,894:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (34061, 50)
4        Transformed data shape   (34061, 50)
5   Transformed train set shape   (23842, 50)
6    Transformed test set shape   (10219, 50)
7              Numeric features            49
8      Rows with missing values         97.6%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_A
19                          USI          fafb
2023-10-23 14:31:23,033:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:31:23,033:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:31:23,176:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:31:23,176:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:31:23,176:INFO:Logging experiment in loggers
2023-10-23 14:31:23,521:INFO:SubProcess save_model() called ==================================
2023-10-23 14:31:23,540:INFO:Initializing save_model()
2023-10-23 14:31:23,540:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmp9ih1lsac\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 14:31:23,540:INFO:Adding model into prep_pipe
2023-10-23 14:31:23,540:WARNING:Only Model saved as it was a pipeline.
2023-10-23 14:31:23,552:INFO:C:\Users\thoma\AppData\Local\Temp\tmp9ih1lsac\Transformation Pipeline.pkl saved in current working directory
2023-10-23 14:31:23,553:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 14:31:23,553:INFO:save_model() successfully completed......................................
2023-10-23 14:31:23,666:INFO:SubProcess save_model() end ==================================
2023-10-23 14:31:23,750:INFO:setup() successfully completed in 2.7s...............
2023-10-23 14:31:23,750:INFO:Initializing create_model()
2023-10-23 14:31:23,750:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08C9C0F40>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:31:23,750:INFO:Checking exceptions
2023-10-23 14:31:23,754:INFO:Importing libraries
2023-10-23 14:31:23,754:INFO:Copying training dataset
2023-10-23 14:31:23,784:INFO:Defining folds
2023-10-23 14:31:23,784:INFO:Declaring metric variables
2023-10-23 14:31:23,784:INFO:Importing untrained model
2023-10-23 14:31:23,785:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:31:23,785:INFO:Starting cross validation
2023-10-23 14:31:23,794:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:31:33,183:INFO:Calculating mean and std
2023-10-23 14:31:33,186:INFO:Creating metrics dataframe
2023-10-23 14:31:33,189:INFO:Finalizing model
2023-10-23 14:31:33,309:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007339 seconds.
2023-10-23 14:31:33,309:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:31:33,310:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:31:33,311:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:31:33,312:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-23 14:31:33,643:INFO:Creating Dashboard logs
2023-10-23 14:31:33,643:INFO:Model: Light Gradient Boosting Machine
2023-10-23 14:31:33,772:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 14:31:34,007:INFO:Initializing predict_model()
2023-10-23 14:31:34,008:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08C9C0F40>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E0971B6EE0>)
2023-10-23 14:31:34,008:INFO:Checking exceptions
2023-10-23 14:31:34,008:INFO:Preloading libraries
2023-10-23 14:31:34,363:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\_distutils_hack\__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2023-10-23 14:31:34,627:INFO:Uploading results into container
2023-10-23 14:31:34,627:INFO:Uploading model into container now
2023-10-23 14:31:34,642:INFO:_master_model_container: 1
2023-10-23 14:31:34,642:INFO:_display_container: 2
2023-10-23 14:31:34,643:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:31:34,643:INFO:create_model() successfully completed......................................
2023-10-23 14:31:34,776:INFO:Initializing tune_model()
2023-10-23 14:31:34,776:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08C9C0F40>)
2023-10-23 14:31:34,776:INFO:Checking exceptions
2023-10-23 14:31:34,791:INFO:Copying training dataset
2023-10-23 14:31:34,810:INFO:Checking base model
2023-10-23 14:31:34,811:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 14:31:34,812:INFO:Declaring metric variables
2023-10-23 14:31:34,812:INFO:Defining Hyperparameters
2023-10-23 14:31:34,967:INFO:Tuning with n_jobs=-1
2023-10-23 14:31:34,968:INFO:Initializing RandomizedSearchCV
2023-10-23 14:32:26,101:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-23 14:32:26,102:INFO:Hyperparameter search completed
2023-10-23 14:32:26,103:INFO:SubProcess create_model() called ==================================
2023-10-23 14:32:26,104:INFO:Initializing create_model()
2023-10-23 14:32:26,104:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08C9C0F40>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E096F053A0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-23 14:32:26,104:INFO:Checking exceptions
2023-10-23 14:32:26,105:INFO:Importing libraries
2023-10-23 14:32:26,105:INFO:Copying training dataset
2023-10-23 14:32:26,137:INFO:Defining folds
2023-10-23 14:32:26,137:INFO:Declaring metric variables
2023-10-23 14:32:26,137:INFO:Importing untrained model
2023-10-23 14:32:26,138:INFO:Declaring custom model
2023-10-23 14:32:26,140:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:32:26,140:INFO:Starting cross validation
2023-10-23 14:32:26,142:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:32:34,733:INFO:Calculating mean and std
2023-10-23 14:32:34,734:INFO:Creating metrics dataframe
2023-10-23 14:32:34,738:INFO:Finalizing model
2023-10-23 14:32:34,801:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-23 14:32:34,801:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-23 14:32:34,801:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-23 14:32:34,842:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-23 14:32:34,842:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-23 14:32:34,842:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-23 14:32:34,851:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006217 seconds.
2023-10-23 14:32:34,851:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:32:34,852:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:32:34,853:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:32:34,855:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-23 14:32:36,016:INFO:Uploading results into container
2023-10-23 14:32:36,017:INFO:Uploading model into container now
2023-10-23 14:32:36,018:INFO:_master_model_container: 2
2023-10-23 14:32:36,018:INFO:_display_container: 3
2023-10-23 14:32:36,019:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-23 14:32:36,020:INFO:create_model() successfully completed......................................
2023-10-23 14:32:36,140:INFO:SubProcess create_model() end ==================================
2023-10-23 14:32:36,141:INFO:choose_better activated
2023-10-23 14:32:36,141:INFO:SubProcess create_model() called ==================================
2023-10-23 14:32:36,142:INFO:Initializing create_model()
2023-10-23 14:32:36,142:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08C9C0F40>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:32:36,142:INFO:Checking exceptions
2023-10-23 14:32:36,143:INFO:Importing libraries
2023-10-23 14:32:36,143:INFO:Copying training dataset
2023-10-23 14:32:36,165:INFO:Defining folds
2023-10-23 14:32:36,166:INFO:Declaring metric variables
2023-10-23 14:32:36,166:INFO:Importing untrained model
2023-10-23 14:32:36,166:INFO:Declaring custom model
2023-10-23 14:32:36,167:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:32:36,167:INFO:Starting cross validation
2023-10-23 14:32:36,168:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:32:38,715:INFO:Calculating mean and std
2023-10-23 14:32:38,715:INFO:Creating metrics dataframe
2023-10-23 14:32:38,718:INFO:Finalizing model
2023-10-23 14:32:38,816:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006205 seconds.
2023-10-23 14:32:38,816:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:32:38,817:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:32:38,817:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:32:38,819:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-23 14:32:39,027:INFO:Uploading results into container
2023-10-23 14:32:39,028:INFO:Uploading model into container now
2023-10-23 14:32:39,028:INFO:_master_model_container: 3
2023-10-23 14:32:39,028:INFO:_display_container: 4
2023-10-23 14:32:39,029:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:32:39,029:INFO:create_model() successfully completed......................................
2023-10-23 14:32:39,151:INFO:SubProcess create_model() end ==================================
2023-10-23 14:32:39,152:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8716
2023-10-23 14:32:39,153:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8712
2023-10-23 14:32:39,153:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-23 14:32:39,154:INFO:choose_better completed
2023-10-23 14:32:39,154:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-23 14:32:39,154:INFO:Creating Dashboard logs
2023-10-23 14:32:39,155:INFO:Model: Light Gradient Boosting Machine
2023-10-23 14:32:39,225:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 14:32:39,422:INFO:Initializing predict_model()
2023-10-23 14:32:39,422:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08C9C0F40>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E0970AACA0>)
2023-10-23 14:32:39,422:INFO:Checking exceptions
2023-10-23 14:32:39,422:INFO:Preloading libraries
2023-10-23 14:32:39,882:INFO:_master_model_container: 3
2023-10-23 14:32:39,883:INFO:_display_container: 3
2023-10-23 14:32:39,883:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:32:39,883:INFO:tune_model() successfully completed......................................
2023-10-23 14:32:39,991:INFO:Initializing ensemble_model()
2023-10-23 14:32:39,991:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08C9C0F40>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-23 14:32:39,991:INFO:Checking exceptions
2023-10-23 14:32:40,002:INFO:Importing libraries
2023-10-23 14:32:40,002:INFO:Copying training dataset
2023-10-23 14:32:40,003:INFO:Checking base model
2023-10-23 14:32:40,003:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 14:32:40,004:INFO:Importing untrained ensembler
2023-10-23 14:32:40,004:INFO:Ensemble method set to Bagging
2023-10-23 14:32:40,004:INFO:SubProcess create_model() called ==================================
2023-10-23 14:32:40,006:INFO:Initializing create_model()
2023-10-23 14:32:40,006:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08C9C0F40>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E096980A00>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:32:40,006:INFO:Checking exceptions
2023-10-23 14:32:40,006:INFO:Importing libraries
2023-10-23 14:32:40,006:INFO:Copying training dataset
2023-10-23 14:32:40,031:INFO:Defining folds
2023-10-23 14:32:40,031:INFO:Declaring metric variables
2023-10-23 14:32:40,032:INFO:Importing untrained model
2023-10-23 14:32:40,032:INFO:Declaring custom model
2023-10-23 14:32:40,033:INFO:Bagging Regressor Imported successfully
2023-10-23 14:32:40,034:INFO:Starting cross validation
2023-10-23 14:32:40,035:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:33:03,739:INFO:Calculating mean and std
2023-10-23 14:33:03,740:INFO:Creating metrics dataframe
2023-10-23 14:33:03,743:INFO:Finalizing model
2023-10-23 14:33:03,847:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005392 seconds.
2023-10-23 14:33:03,847:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:03,848:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:33:03,848:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:33:03,849:INFO:[LightGBM] [Info] Start training from score 626.831517
2023-10-23 14:33:04,126:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005093 seconds.
2023-10-23 14:33:04,126:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:04,126:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:33:04,127:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:33:04,127:INFO:[LightGBM] [Info] Start training from score 640.013980
2023-10-23 14:33:04,360:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005521 seconds.
2023-10-23 14:33:04,360:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:04,360:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:33:04,360:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:33:04,360:INFO:[LightGBM] [Info] Start training from score 623.946930
2023-10-23 14:33:04,628:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005296 seconds.
2023-10-23 14:33:04,628:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:04,629:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:33:04,629:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:33:04,629:INFO:[LightGBM] [Info] Start training from score 632.335152
2023-10-23 14:33:04,919:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006870 seconds.
2023-10-23 14:33:04,919:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:04,919:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:33:04,920:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:33:04,921:INFO:[LightGBM] [Info] Start training from score 620.070240
2023-10-23 14:33:05,194:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013481 seconds.
2023-10-23 14:33:05,195:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:05,195:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:33:05,196:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:33:05,202:INFO:[LightGBM] [Info] Start training from score 635.137343
2023-10-23 14:33:05,504:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005992 seconds.
2023-10-23 14:33:05,504:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:05,504:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:33:05,504:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:33:05,504:INFO:[LightGBM] [Info] Start training from score 620.066941
2023-10-23 14:33:05,783:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005717 seconds.
2023-10-23 14:33:05,783:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:05,783:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:33:05,783:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:33:05,783:INFO:[LightGBM] [Info] Start training from score 623.069874
2023-10-23 14:33:06,126:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007570 seconds.
2023-10-23 14:33:06,126:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:06,127:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:33:06,130:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:33:06,132:INFO:[LightGBM] [Info] Start training from score 633.817057
2023-10-23 14:33:06,447:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005651 seconds.
2023-10-23 14:33:06,447:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:06,447:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:33:06,448:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:33:06,448:INFO:[LightGBM] [Info] Start training from score 641.113408
2023-10-23 14:33:06,712:INFO:Uploading results into container
2023-10-23 14:33:06,713:INFO:Uploading model into container now
2023-10-23 14:33:06,714:INFO:_master_model_container: 4
2023-10-23 14:33:06,715:INFO:_display_container: 4
2023-10-23 14:33:06,717:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:33:06,717:INFO:create_model() successfully completed......................................
2023-10-23 14:33:06,840:INFO:SubProcess create_model() end ==================================
2023-10-23 14:33:06,840:INFO:Creating Dashboard logs
2023-10-23 14:33:06,841:INFO:Model: Bagging Regressor
2023-10-23 14:33:06,915:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-23 14:33:07,147:INFO:Initializing predict_model()
2023-10-23 14:33:07,147:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08C9C0F40>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E097086F70>)
2023-10-23 14:33:07,147:INFO:Checking exceptions
2023-10-23 14:33:07,147:INFO:Preloading libraries
2023-10-23 14:33:07,797:INFO:_master_model_container: 4
2023-10-23 14:33:07,797:INFO:_display_container: 4
2023-10-23 14:33:07,797:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:33:07,797:INFO:ensemble_model() successfully completed......................................
2023-10-23 14:33:07,914:INFO:Initializing finalize_model()
2023-10-23 14:33:07,914:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08C9C0F40>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-23 14:33:07,914:INFO:Finalizing BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:33:07,930:INFO:Initializing create_model()
2023-10-23 14:33:07,930:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08C9C0F40>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-23 14:33:07,930:INFO:Checking exceptions
2023-10-23 14:33:07,930:INFO:Importing libraries
2023-10-23 14:33:07,930:INFO:Copying training dataset
2023-10-23 14:33:07,930:INFO:Defining folds
2023-10-23 14:33:07,930:INFO:Declaring metric variables
2023-10-23 14:33:07,930:INFO:Importing untrained model
2023-10-23 14:33:07,930:INFO:Declaring custom model
2023-10-23 14:33:07,930:INFO:Bagging Regressor Imported successfully
2023-10-23 14:33:07,930:INFO:Cross validation set to False
2023-10-23 14:33:07,930:INFO:Fitting Model
2023-10-23 14:33:08,096:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009957 seconds.
2023-10-23 14:33:08,096:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:08,097:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:33:08,098:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:33:08,099:INFO:[LightGBM] [Info] Start training from score 634.491655
2023-10-23 14:33:08,482:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009853 seconds.
2023-10-23 14:33:08,482:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:08,482:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:33:08,483:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:33:08,485:INFO:[LightGBM] [Info] Start training from score 635.470959
2023-10-23 14:33:08,899:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009146 seconds.
2023-10-23 14:33:08,899:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:08,900:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:33:08,901:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:33:08,902:INFO:[LightGBM] [Info] Start training from score 634.053589
2023-10-23 14:33:09,365:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009197 seconds.
2023-10-23 14:33:09,365:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:09,365:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:33:09,365:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:33:09,365:INFO:[LightGBM] [Info] Start training from score 635.251785
2023-10-23 14:33:09,698:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008816 seconds.
2023-10-23 14:33:09,698:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:09,698:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:33:09,698:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:33:09,700:INFO:[LightGBM] [Info] Start training from score 627.555784
2023-10-23 14:33:10,053:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007364 seconds.
2023-10-23 14:33:10,053:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:10,054:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:33:10,054:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:33:10,056:INFO:[LightGBM] [Info] Start training from score 638.162596
2023-10-23 14:33:10,381:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007790 seconds.
2023-10-23 14:33:10,381:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:10,382:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:33:10,382:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:33:10,383:INFO:[LightGBM] [Info] Start training from score 633.181363
2023-10-23 14:33:10,722:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007785 seconds.
2023-10-23 14:33:10,722:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:10,723:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:33:10,723:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:33:10,724:INFO:[LightGBM] [Info] Start training from score 611.992287
2023-10-23 14:33:11,063:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007802 seconds.
2023-10-23 14:33:11,063:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:11,063:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:33:11,064:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:33:11,064:INFO:[LightGBM] [Info] Start training from score 638.181417
2023-10-23 14:33:11,383:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009670 seconds.
2023-10-23 14:33:11,383:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:11,383:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:33:11,383:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:33:11,383:INFO:[LightGBM] [Info] Start training from score 639.502137
2023-10-23 14:33:11,665:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:33:11,665:INFO:create_model() successfully completed......................................
2023-10-23 14:33:11,782:INFO:Creating Dashboard logs
2023-10-23 14:33:11,782:INFO:Model: Bagging Regressor
2023-10-23 14:33:11,860:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-23 14:33:12,279:INFO:_master_model_container: 4
2023-10-23 14:33:12,279:INFO:_display_container: 4
2023-10-23 14:33:12,290:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:33:12,290:INFO:finalize_model() successfully completed......................................
2023-10-23 14:33:12,404:INFO:Initializing save_model()
2023-10-23 14:33:12,404:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), model_name=final_model_for_location_A, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 14:33:12,404:INFO:Adding model into prep_pipe
2023-10-23 14:33:12,404:WARNING:Only Model saved as it was a pipeline.
2023-10-23 14:33:12,466:INFO:final_model_for_location_A.pkl saved in current working directory
2023-10-23 14:33:12,482:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:33:12,482:INFO:save_model() successfully completed......................................
2023-10-23 14:33:12,615:INFO:PyCaret RegressionExperiment
2023-10-23 14:33:12,615:INFO:Logging name: exp_B
2023-10-23 14:33:12,615:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 14:33:12,615:INFO:version 3.1.0
2023-10-23 14:33:12,615:INFO:Initializing setup()
2023-10-23 14:33:12,615:INFO:self.USI: 5eaa
2023-10-23 14:33:12,615:INFO:self._variable_keys: {'gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', '_ml_usecase', 'gpu_param', 'exp_name_log', 'html_param', 'fold_generator', 'y', 'seed', 'y_train', 'transform_target_param', 'n_jobs_param', 'target_param', 'idx', '_available_plots', 'log_plots_param', 'memory', 'data', 'USI', 'X', 'logging_param', 'pipeline', 'exp_id', 'X_train', 'X_test', 'fold_groups_param'}
2023-10-23 14:33:12,615:INFO:Checking environment
2023-10-23 14:33:12,615:INFO:python_version: 3.8.18
2023-10-23 14:33:12,615:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 14:33:12,615:INFO:machine: AMD64
2023-10-23 14:33:12,615:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 14:33:12,616:INFO:Memory: svmem(total=16505954304, available=2925641728, percent=82.3, used=13580312576, free=2925641728)
2023-10-23 14:33:12,616:INFO:Physical Core: 8
2023-10-23 14:33:12,616:INFO:Logical Core: 16
2023-10-23 14:33:12,616:INFO:Checking libraries
2023-10-23 14:33:12,616:INFO:System:
2023-10-23 14:33:12,616:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 14:33:12,616:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 14:33:12,616:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 14:33:12,616:INFO:PyCaret required dependencies:
2023-10-23 14:33:12,616:INFO:                 pip: 23.3
2023-10-23 14:33:12,617:INFO:          setuptools: 68.0.0
2023-10-23 14:33:12,617:INFO:             pycaret: 3.1.0
2023-10-23 14:33:12,617:INFO:             IPython: 8.12.0
2023-10-23 14:33:12,617:INFO:          ipywidgets: 8.1.1
2023-10-23 14:33:12,617:INFO:                tqdm: 4.66.1
2023-10-23 14:33:12,617:INFO:               numpy: 1.23.5
2023-10-23 14:33:12,617:INFO:              pandas: 1.5.3
2023-10-23 14:33:12,617:INFO:              jinja2: 3.1.2
2023-10-23 14:33:12,617:INFO:               scipy: 1.10.1
2023-10-23 14:33:12,617:INFO:              joblib: 1.3.2
2023-10-23 14:33:12,617:INFO:             sklearn: 1.2.2
2023-10-23 14:33:12,617:INFO:                pyod: 1.1.0
2023-10-23 14:33:12,617:INFO:            imblearn: 0.11.0
2023-10-23 14:33:12,617:INFO:   category_encoders: 2.6.2
2023-10-23 14:33:12,617:INFO:            lightgbm: 4.1.0
2023-10-23 14:33:12,618:INFO:               numba: 0.58.1
2023-10-23 14:33:12,618:INFO:            requests: 2.31.0
2023-10-23 14:33:12,618:INFO:          matplotlib: 3.7.3
2023-10-23 14:33:12,618:INFO:          scikitplot: 0.3.7
2023-10-23 14:33:12,618:INFO:         yellowbrick: 1.5
2023-10-23 14:33:12,618:INFO:              plotly: 5.17.0
2023-10-23 14:33:12,618:INFO:    plotly-resampler: Not installed
2023-10-23 14:33:12,618:INFO:             kaleido: 0.2.1
2023-10-23 14:33:12,618:INFO:           schemdraw: 0.15
2023-10-23 14:33:12,619:INFO:         statsmodels: 0.14.0
2023-10-23 14:33:12,619:INFO:              sktime: 0.21.1
2023-10-23 14:33:12,619:INFO:               tbats: 1.1.3
2023-10-23 14:33:12,619:INFO:            pmdarima: 2.0.3
2023-10-23 14:33:12,619:INFO:              psutil: 5.9.0
2023-10-23 14:33:12,619:INFO:          markupsafe: 2.1.3
2023-10-23 14:33:12,619:INFO:             pickle5: Not installed
2023-10-23 14:33:12,619:INFO:         cloudpickle: 2.2.1
2023-10-23 14:33:12,619:INFO:         deprecation: 2.1.0
2023-10-23 14:33:12,619:INFO:              xxhash: 3.4.1
2023-10-23 14:33:12,619:INFO:           wurlitzer: Not installed
2023-10-23 14:33:12,619:INFO:PyCaret optional dependencies:
2023-10-23 14:33:12,620:INFO:                shap: Not installed
2023-10-23 14:33:12,620:INFO:           interpret: Not installed
2023-10-23 14:33:12,620:INFO:                umap: Not installed
2023-10-23 14:33:12,620:INFO:     ydata_profiling: Not installed
2023-10-23 14:33:12,620:INFO:  explainerdashboard: Not installed
2023-10-23 14:33:12,620:INFO:             autoviz: Not installed
2023-10-23 14:33:12,620:INFO:           fairlearn: Not installed
2023-10-23 14:33:12,620:INFO:          deepchecks: Not installed
2023-10-23 14:33:12,620:INFO:             xgboost: Not installed
2023-10-23 14:33:12,620:INFO:            catboost: 1.2.2
2023-10-23 14:33:12,620:INFO:              kmodes: Not installed
2023-10-23 14:33:12,620:INFO:             mlxtend: Not installed
2023-10-23 14:33:12,620:INFO:       statsforecast: Not installed
2023-10-23 14:33:12,620:INFO:        tune_sklearn: Not installed
2023-10-23 14:33:12,621:INFO:                 ray: Not installed
2023-10-23 14:33:12,621:INFO:            hyperopt: Not installed
2023-10-23 14:33:12,621:INFO:              optuna: Not installed
2023-10-23 14:33:12,621:INFO:               skopt: Not installed
2023-10-23 14:33:12,621:INFO:              mlflow: 2.7.1
2023-10-23 14:33:12,621:INFO:              gradio: Not installed
2023-10-23 14:33:12,621:INFO:             fastapi: Not installed
2023-10-23 14:33:12,621:INFO:             uvicorn: Not installed
2023-10-23 14:33:12,621:INFO:              m2cgen: Not installed
2023-10-23 14:33:12,621:INFO:           evidently: Not installed
2023-10-23 14:33:12,621:INFO:               fugue: Not installed
2023-10-23 14:33:12,621:INFO:           streamlit: Not installed
2023-10-23 14:33:12,621:INFO:             prophet: Not installed
2023-10-23 14:33:12,622:INFO:None
2023-10-23 14:33:12,622:INFO:Set up data.
2023-10-23 14:33:12,660:INFO:Set up folding strategy.
2023-10-23 14:33:12,660:INFO:Set up train/test split.
2023-10-23 14:33:12,686:INFO:Set up index.
2023-10-23 14:33:12,688:INFO:Assigning column types.
2023-10-23 14:33:12,712:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 14:33:12,713:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 14:33:12,718:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:33:12,723:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:33:12,804:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:33:12,853:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:33:12,854:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:33:12,854:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:33:12,855:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 14:33:12,860:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:33:12,866:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:33:12,943:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:33:12,992:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:33:12,993:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:33:12,993:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:33:12,994:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 14:33:12,999:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,004:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,083:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,126:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,126:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:33:13,126:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:33:13,126:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,143:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,239:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,293:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,293:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:33:13,293:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:33:13,293:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 14:33:13,310:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,376:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,425:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,425:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:33:13,425:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:33:13,442:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,546:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,592:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,592:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:33:13,592:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:33:13,592:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 14:33:13,709:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,759:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,759:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:33:13,759:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:33:13,843:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,893:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,893:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:33:13,893:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:33:13,893:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 14:33:13,992:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:33:14,043:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:33:14,044:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:33:14,142:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:33:14,192:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:33:14,193:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:33:14,193:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 14:33:14,330:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:33:14,331:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:33:14,472:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:33:14,472:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:33:14,474:INFO:Preparing preprocessing pipeline...
2023-10-23 14:33:14,474:INFO:Set up simple imputation.
2023-10-23 14:33:14,477:INFO:Set up column name cleaning.
2023-10-23 14:33:14,547:INFO:Finished creating preprocessing pipeline.
2023-10-23 14:33:14,553:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 14:33:14,553:INFO:Creating final display dataframe.
2023-10-23 14:33:14,771:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (32819, 50)
4        Transformed data shape   (32819, 50)
5   Transformed train set shape   (22973, 50)
6    Transformed test set shape    (9846, 50)
7              Numeric features            49
8      Rows with missing values         95.9%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_B
19                          USI          5eaa
2023-10-23 14:33:14,933:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:33:14,934:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:33:15,078:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:33:15,078:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:33:15,079:INFO:Logging experiment in loggers
2023-10-23 14:33:15,206:INFO:SubProcess save_model() called ==================================
2023-10-23 14:33:15,210:INFO:Initializing save_model()
2023-10-23 14:33:15,210:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmplxeawuw9\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 14:33:15,210:INFO:Adding model into prep_pipe
2023-10-23 14:33:15,210:WARNING:Only Model saved as it was a pipeline.
2023-10-23 14:33:15,227:INFO:C:\Users\thoma\AppData\Local\Temp\tmplxeawuw9\Transformation Pipeline.pkl saved in current working directory
2023-10-23 14:33:15,229:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 14:33:15,229:INFO:save_model() successfully completed......................................
2023-10-23 14:33:15,343:INFO:SubProcess save_model() end ==================================
2023-10-23 14:33:15,406:INFO:setup() successfully completed in 2.47s...............
2023-10-23 14:33:15,406:INFO:Initializing create_model()
2023-10-23 14:33:15,406:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096DCF190>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:33:15,406:INFO:Checking exceptions
2023-10-23 14:33:15,410:INFO:Importing libraries
2023-10-23 14:33:15,410:INFO:Copying training dataset
2023-10-23 14:33:15,435:INFO:Defining folds
2023-10-23 14:33:15,435:INFO:Declaring metric variables
2023-10-23 14:33:15,435:INFO:Importing untrained model
2023-10-23 14:33:15,435:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:33:15,439:INFO:Starting cross validation
2023-10-23 14:33:15,440:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:33:17,998:INFO:Calculating mean and std
2023-10-23 14:33:18,000:INFO:Creating metrics dataframe
2023-10-23 14:33:18,002:INFO:Finalizing model
2023-10-23 14:33:18,101:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005265 seconds.
2023-10-23 14:33:18,101:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:18,101:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:33:18,102:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:33:18,103:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-23 14:33:18,346:INFO:Creating Dashboard logs
2023-10-23 14:33:18,347:INFO:Model: Light Gradient Boosting Machine
2023-10-23 14:33:18,448:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 14:33:18,669:INFO:Initializing predict_model()
2023-10-23 14:33:18,670:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096DCF190>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096789040>)
2023-10-23 14:33:18,670:INFO:Checking exceptions
2023-10-23 14:33:18,670:INFO:Preloading libraries
2023-10-23 14:33:19,177:INFO:Uploading results into container
2023-10-23 14:33:19,179:INFO:Uploading model into container now
2023-10-23 14:33:19,183:INFO:_master_model_container: 1
2023-10-23 14:33:19,183:INFO:_display_container: 2
2023-10-23 14:33:19,184:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:33:19,184:INFO:create_model() successfully completed......................................
2023-10-23 14:33:19,283:INFO:Initializing tune_model()
2023-10-23 14:33:19,283:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096DCF190>)
2023-10-23 14:33:19,283:INFO:Checking exceptions
2023-10-23 14:33:19,296:INFO:Copying training dataset
2023-10-23 14:33:19,311:INFO:Checking base model
2023-10-23 14:33:19,312:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 14:33:19,312:INFO:Declaring metric variables
2023-10-23 14:33:19,313:INFO:Defining Hyperparameters
2023-10-23 14:33:19,424:INFO:Tuning with n_jobs=-1
2023-10-23 14:33:19,424:INFO:Initializing RandomizedSearchCV
2023-10-23 14:34:01,842:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-23 14:34:01,844:INFO:Hyperparameter search completed
2023-10-23 14:34:01,844:INFO:SubProcess create_model() called ==================================
2023-10-23 14:34:01,845:INFO:Initializing create_model()
2023-10-23 14:34:01,846:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096DCF190>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E096AC0AC0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-23 14:34:01,846:INFO:Checking exceptions
2023-10-23 14:34:01,847:INFO:Importing libraries
2023-10-23 14:34:01,847:INFO:Copying training dataset
2023-10-23 14:34:01,879:INFO:Defining folds
2023-10-23 14:34:01,879:INFO:Declaring metric variables
2023-10-23 14:34:01,879:INFO:Importing untrained model
2023-10-23 14:34:01,879:INFO:Declaring custom model
2023-10-23 14:34:01,881:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:34:01,881:INFO:Starting cross validation
2023-10-23 14:34:01,883:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:34:10,558:INFO:Calculating mean and std
2023-10-23 14:34:10,558:INFO:Creating metrics dataframe
2023-10-23 14:34:10,563:INFO:Finalizing model
2023-10-23 14:34:10,612:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-23 14:34:10,612:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-23 14:34:10,612:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-23 14:34:10,658:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-23 14:34:10,658:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-23 14:34:10,658:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-23 14:34:10,658:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005687 seconds.
2023-10-23 14:34:10,658:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:10,658:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:34:10,673:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:34:10,673:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-23 14:34:11,591:INFO:Uploading results into container
2023-10-23 14:34:11,591:INFO:Uploading model into container now
2023-10-23 14:34:11,591:INFO:_master_model_container: 2
2023-10-23 14:34:11,591:INFO:_display_container: 3
2023-10-23 14:34:11,591:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-23 14:34:11,591:INFO:create_model() successfully completed......................................
2023-10-23 14:34:11,731:INFO:SubProcess create_model() end ==================================
2023-10-23 14:34:11,731:INFO:choose_better activated
2023-10-23 14:34:11,731:INFO:SubProcess create_model() called ==================================
2023-10-23 14:34:11,731:INFO:Initializing create_model()
2023-10-23 14:34:11,731:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096DCF190>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:34:11,731:INFO:Checking exceptions
2023-10-23 14:34:11,731:INFO:Importing libraries
2023-10-23 14:34:11,731:INFO:Copying training dataset
2023-10-23 14:34:11,749:INFO:Defining folds
2023-10-23 14:34:11,749:INFO:Declaring metric variables
2023-10-23 14:34:11,749:INFO:Importing untrained model
2023-10-23 14:34:11,749:INFO:Declaring custom model
2023-10-23 14:34:11,749:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:34:11,749:INFO:Starting cross validation
2023-10-23 14:34:11,749:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:34:14,239:INFO:Calculating mean and std
2023-10-23 14:34:14,239:INFO:Creating metrics dataframe
2023-10-23 14:34:14,239:INFO:Finalizing model
2023-10-23 14:34:14,344:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005003 seconds.
2023-10-23 14:34:14,344:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:14,344:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:34:14,344:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:34:14,344:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-23 14:34:14,560:INFO:Uploading results into container
2023-10-23 14:34:14,560:INFO:Uploading model into container now
2023-10-23 14:34:14,560:INFO:_master_model_container: 3
2023-10-23 14:34:14,560:INFO:_display_container: 4
2023-10-23 14:34:14,560:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:34:14,560:INFO:create_model() successfully completed......................................
2023-10-23 14:34:14,692:INFO:SubProcess create_model() end ==================================
2023-10-23 14:34:14,692:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8523
2023-10-23 14:34:14,692:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8523
2023-10-23 14:34:14,692:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-23 14:34:14,692:INFO:choose_better completed
2023-10-23 14:34:14,692:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-23 14:34:14,696:INFO:Creating Dashboard logs
2023-10-23 14:34:14,696:INFO:Model: Light Gradient Boosting Machine
2023-10-23 14:34:14,757:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 14:34:14,955:INFO:Initializing predict_model()
2023-10-23 14:34:14,956:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096DCF190>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096702B80>)
2023-10-23 14:34:14,956:INFO:Checking exceptions
2023-10-23 14:34:14,956:INFO:Preloading libraries
2023-10-23 14:34:15,442:INFO:_master_model_container: 3
2023-10-23 14:34:15,442:INFO:_display_container: 3
2023-10-23 14:34:15,442:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:34:15,442:INFO:tune_model() successfully completed......................................
2023-10-23 14:34:15,541:INFO:Initializing ensemble_model()
2023-10-23 14:34:15,541:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096DCF190>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-23 14:34:15,541:INFO:Checking exceptions
2023-10-23 14:34:15,541:INFO:Importing libraries
2023-10-23 14:34:15,557:INFO:Copying training dataset
2023-10-23 14:34:15,557:INFO:Checking base model
2023-10-23 14:34:15,557:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 14:34:15,557:INFO:Importing untrained ensembler
2023-10-23 14:34:15,557:INFO:Ensemble method set to Bagging
2023-10-23 14:34:15,557:INFO:SubProcess create_model() called ==================================
2023-10-23 14:34:15,557:INFO:Initializing create_model()
2023-10-23 14:34:15,557:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096DCF190>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E093358DC0>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:34:15,557:INFO:Checking exceptions
2023-10-23 14:34:15,557:INFO:Importing libraries
2023-10-23 14:34:15,557:INFO:Copying training dataset
2023-10-23 14:34:15,584:INFO:Defining folds
2023-10-23 14:34:15,584:INFO:Declaring metric variables
2023-10-23 14:34:15,584:INFO:Importing untrained model
2023-10-23 14:34:15,585:INFO:Declaring custom model
2023-10-23 14:34:15,586:INFO:Bagging Regressor Imported successfully
2023-10-23 14:34:15,586:INFO:Starting cross validation
2023-10-23 14:34:15,586:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:34:39,965:INFO:Calculating mean and std
2023-10-23 14:34:39,968:INFO:Creating metrics dataframe
2023-10-23 14:34:39,977:INFO:Finalizing model
2023-10-23 14:34:40,098:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005697 seconds.
2023-10-23 14:34:40,098:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:40,099:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:34:40,100:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:34:40,101:INFO:[LightGBM] [Info] Start training from score 99.624795
2023-10-23 14:34:40,488:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006397 seconds.
2023-10-23 14:34:40,488:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:40,488:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:34:40,488:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:34:40,488:INFO:[LightGBM] [Info] Start training from score 96.229614
2023-10-23 14:34:40,794:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007142 seconds.
2023-10-23 14:34:40,795:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:40,795:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:34:40,796:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:34:40,797:INFO:[LightGBM] [Info] Start training from score 95.360987
2023-10-23 14:34:41,165:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006056 seconds.
2023-10-23 14:34:41,165:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:41,166:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:34:41,167:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:34:41,168:INFO:[LightGBM] [Info] Start training from score 94.348528
2023-10-23 14:34:41,523:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006255 seconds.
2023-10-23 14:34:41,523:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:41,524:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:34:41,524:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:34:41,525:INFO:[LightGBM] [Info] Start training from score 95.509684
2023-10-23 14:34:41,805:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005180 seconds.
2023-10-23 14:34:41,805:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:41,805:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:34:41,806:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:34:41,807:INFO:[LightGBM] [Info] Start training from score 96.036959
2023-10-23 14:34:42,069:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005656 seconds.
2023-10-23 14:34:42,069:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:42,069:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:34:42,069:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:34:42,069:INFO:[LightGBM] [Info] Start training from score 97.844637
2023-10-23 14:34:42,339:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005494 seconds.
2023-10-23 14:34:42,339:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:42,339:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:34:42,339:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:34:42,339:INFO:[LightGBM] [Info] Start training from score 96.245614
2023-10-23 14:34:42,619:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007108 seconds.
2023-10-23 14:34:42,619:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:42,619:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:34:42,619:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:34:42,634:INFO:[LightGBM] [Info] Start training from score 97.594984
2023-10-23 14:34:42,901:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005595 seconds.
2023-10-23 14:34:42,901:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:42,917:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:34:42,918:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:34:42,918:INFO:[LightGBM] [Info] Start training from score 96.370407
2023-10-23 14:34:43,133:INFO:Uploading results into container
2023-10-23 14:34:43,134:INFO:Uploading model into container now
2023-10-23 14:34:43,136:INFO:_master_model_container: 4
2023-10-23 14:34:43,136:INFO:_display_container: 4
2023-10-23 14:34:43,138:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:34:43,138:INFO:create_model() successfully completed......................................
2023-10-23 14:34:43,255:INFO:SubProcess create_model() end ==================================
2023-10-23 14:34:43,255:INFO:Creating Dashboard logs
2023-10-23 14:34:43,255:INFO:Model: Bagging Regressor
2023-10-23 14:34:43,328:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-23 14:34:43,568:INFO:Initializing predict_model()
2023-10-23 14:34:43,568:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096DCF190>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096702DC0>)
2023-10-23 14:34:43,568:INFO:Checking exceptions
2023-10-23 14:34:43,568:INFO:Preloading libraries
2023-10-23 14:34:44,167:INFO:_master_model_container: 4
2023-10-23 14:34:44,167:INFO:_display_container: 4
2023-10-23 14:34:44,167:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:34:44,167:INFO:ensemble_model() successfully completed......................................
2023-10-23 14:34:44,272:INFO:Initializing finalize_model()
2023-10-23 14:34:44,272:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096DCF190>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-23 14:34:44,282:INFO:Finalizing BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:34:44,298:INFO:Initializing create_model()
2023-10-23 14:34:44,299:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096DCF190>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-23 14:34:44,299:INFO:Checking exceptions
2023-10-23 14:34:44,300:INFO:Importing libraries
2023-10-23 14:34:44,300:INFO:Copying training dataset
2023-10-23 14:34:44,301:INFO:Defining folds
2023-10-23 14:34:44,301:INFO:Declaring metric variables
2023-10-23 14:34:44,301:INFO:Importing untrained model
2023-10-23 14:34:44,301:INFO:Declaring custom model
2023-10-23 14:34:44,303:INFO:Bagging Regressor Imported successfully
2023-10-23 14:34:44,304:INFO:Cross validation set to False
2023-10-23 14:34:44,304:INFO:Fitting Model
2023-10-23 14:34:44,479:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017216 seconds.
2023-10-23 14:34:44,479:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:44,480:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:34:44,481:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:34:44,482:INFO:[LightGBM] [Info] Start training from score 96.465021
2023-10-23 14:34:44,857:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008815 seconds.
2023-10-23 14:34:44,868:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:44,868:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:34:44,868:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:34:44,868:INFO:[LightGBM] [Info] Start training from score 97.264361
2023-10-23 14:34:45,254:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008657 seconds.
2023-10-23 14:34:45,254:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:45,254:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:34:45,254:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:34:45,254:INFO:[LightGBM] [Info] Start training from score 95.842370
2023-10-23 14:34:45,684:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008002 seconds.
2023-10-23 14:34:45,684:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:45,684:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:34:45,684:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:34:45,684:INFO:[LightGBM] [Info] Start training from score 95.431515
2023-10-23 14:34:46,034:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008044 seconds.
2023-10-23 14:34:46,034:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:46,034:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:34:46,034:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:34:46,034:INFO:[LightGBM] [Info] Start training from score 97.222213
2023-10-23 14:34:46,383:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009419 seconds.
2023-10-23 14:34:46,383:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:46,383:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:34:46,383:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:34:46,383:INFO:[LightGBM] [Info] Start training from score 97.332701
2023-10-23 14:34:46,766:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007627 seconds.
2023-10-23 14:34:46,766:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:46,766:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:34:46,766:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:34:46,766:INFO:[LightGBM] [Info] Start training from score 96.452612
2023-10-23 14:34:47,167:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007072 seconds.
2023-10-23 14:34:47,167:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:47,168:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:34:47,168:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:34:47,168:INFO:[LightGBM] [Info] Start training from score 97.322509
2023-10-23 14:34:47,483:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007806 seconds.
2023-10-23 14:34:47,483:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:47,499:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:34:47,499:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:34:47,500:INFO:[LightGBM] [Info] Start training from score 96.419103
2023-10-23 14:34:47,840:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008775 seconds.
2023-10-23 14:34:47,840:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:47,840:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:34:47,840:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:34:47,840:INFO:[LightGBM] [Info] Start training from score 95.095963
2023-10-23 14:34:48,115:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:34:48,115:INFO:create_model() successfully completed......................................
2023-10-23 14:34:48,240:INFO:Creating Dashboard logs
2023-10-23 14:34:48,246:INFO:Model: Bagging Regressor
2023-10-23 14:34:48,316:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-23 14:34:48,729:INFO:_master_model_container: 4
2023-10-23 14:34:48,729:INFO:_display_container: 4
2023-10-23 14:34:48,740:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:34:48,740:INFO:finalize_model() successfully completed......................................
2023-10-23 14:34:48,849:INFO:Initializing save_model()
2023-10-23 14:34:48,849:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), model_name=final_model_for_location_B, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 14:34:48,849:INFO:Adding model into prep_pipe
2023-10-23 14:34:48,849:WARNING:Only Model saved as it was a pipeline.
2023-10-23 14:34:48,914:INFO:final_model_for_location_B.pkl saved in current working directory
2023-10-23 14:34:48,930:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:34:48,930:INFO:save_model() successfully completed......................................
2023-10-23 14:34:49,064:INFO:PyCaret RegressionExperiment
2023-10-23 14:34:49,064:INFO:Logging name: exp_C
2023-10-23 14:34:49,064:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 14:34:49,064:INFO:version 3.1.0
2023-10-23 14:34:49,065:INFO:Initializing setup()
2023-10-23 14:34:49,065:INFO:self.USI: cd30
2023-10-23 14:34:49,065:INFO:self._variable_keys: {'gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', '_ml_usecase', 'gpu_param', 'exp_name_log', 'html_param', 'fold_generator', 'y', 'seed', 'y_train', 'transform_target_param', 'n_jobs_param', 'target_param', 'idx', '_available_plots', 'log_plots_param', 'memory', 'data', 'USI', 'X', 'logging_param', 'pipeline', 'exp_id', 'X_train', 'X_test', 'fold_groups_param'}
2023-10-23 14:34:49,065:INFO:Checking environment
2023-10-23 14:34:49,065:INFO:python_version: 3.8.18
2023-10-23 14:34:49,065:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 14:34:49,065:INFO:machine: AMD64
2023-10-23 14:34:49,065:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 14:34:49,065:INFO:Memory: svmem(total=16505954304, available=2277785600, percent=86.2, used=14228168704, free=2277785600)
2023-10-23 14:34:49,065:INFO:Physical Core: 8
2023-10-23 14:34:49,065:INFO:Logical Core: 16
2023-10-23 14:34:49,065:INFO:Checking libraries
2023-10-23 14:34:49,065:INFO:System:
2023-10-23 14:34:49,065:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 14:34:49,065:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 14:34:49,065:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 14:34:49,065:INFO:PyCaret required dependencies:
2023-10-23 14:34:49,065:INFO:                 pip: 23.3
2023-10-23 14:34:49,065:INFO:          setuptools: 68.0.0
2023-10-23 14:34:49,065:INFO:             pycaret: 3.1.0
2023-10-23 14:34:49,065:INFO:             IPython: 8.12.0
2023-10-23 14:34:49,065:INFO:          ipywidgets: 8.1.1
2023-10-23 14:34:49,065:INFO:                tqdm: 4.66.1
2023-10-23 14:34:49,065:INFO:               numpy: 1.23.5
2023-10-23 14:34:49,065:INFO:              pandas: 1.5.3
2023-10-23 14:34:49,065:INFO:              jinja2: 3.1.2
2023-10-23 14:34:49,065:INFO:               scipy: 1.10.1
2023-10-23 14:34:49,065:INFO:              joblib: 1.3.2
2023-10-23 14:34:49,065:INFO:             sklearn: 1.2.2
2023-10-23 14:34:49,065:INFO:                pyod: 1.1.0
2023-10-23 14:34:49,065:INFO:            imblearn: 0.11.0
2023-10-23 14:34:49,065:INFO:   category_encoders: 2.6.2
2023-10-23 14:34:49,065:INFO:            lightgbm: 4.1.0
2023-10-23 14:34:49,065:INFO:               numba: 0.58.1
2023-10-23 14:34:49,065:INFO:            requests: 2.31.0
2023-10-23 14:34:49,065:INFO:          matplotlib: 3.7.3
2023-10-23 14:34:49,065:INFO:          scikitplot: 0.3.7
2023-10-23 14:34:49,065:INFO:         yellowbrick: 1.5
2023-10-23 14:34:49,065:INFO:              plotly: 5.17.0
2023-10-23 14:34:49,065:INFO:    plotly-resampler: Not installed
2023-10-23 14:34:49,065:INFO:             kaleido: 0.2.1
2023-10-23 14:34:49,065:INFO:           schemdraw: 0.15
2023-10-23 14:34:49,065:INFO:         statsmodels: 0.14.0
2023-10-23 14:34:49,065:INFO:              sktime: 0.21.1
2023-10-23 14:34:49,065:INFO:               tbats: 1.1.3
2023-10-23 14:34:49,065:INFO:            pmdarima: 2.0.3
2023-10-23 14:34:49,065:INFO:              psutil: 5.9.0
2023-10-23 14:34:49,065:INFO:          markupsafe: 2.1.3
2023-10-23 14:34:49,065:INFO:             pickle5: Not installed
2023-10-23 14:34:49,065:INFO:         cloudpickle: 2.2.1
2023-10-23 14:34:49,065:INFO:         deprecation: 2.1.0
2023-10-23 14:34:49,065:INFO:              xxhash: 3.4.1
2023-10-23 14:34:49,065:INFO:           wurlitzer: Not installed
2023-10-23 14:34:49,065:INFO:PyCaret optional dependencies:
2023-10-23 14:34:49,065:INFO:                shap: Not installed
2023-10-23 14:34:49,065:INFO:           interpret: Not installed
2023-10-23 14:34:49,065:INFO:                umap: Not installed
2023-10-23 14:34:49,065:INFO:     ydata_profiling: Not installed
2023-10-23 14:34:49,065:INFO:  explainerdashboard: Not installed
2023-10-23 14:34:49,065:INFO:             autoviz: Not installed
2023-10-23 14:34:49,065:INFO:           fairlearn: Not installed
2023-10-23 14:34:49,065:INFO:          deepchecks: Not installed
2023-10-23 14:34:49,065:INFO:             xgboost: Not installed
2023-10-23 14:34:49,065:INFO:            catboost: 1.2.2
2023-10-23 14:34:49,065:INFO:              kmodes: Not installed
2023-10-23 14:34:49,065:INFO:             mlxtend: Not installed
2023-10-23 14:34:49,065:INFO:       statsforecast: Not installed
2023-10-23 14:34:49,065:INFO:        tune_sklearn: Not installed
2023-10-23 14:34:49,065:INFO:                 ray: Not installed
2023-10-23 14:34:49,065:INFO:            hyperopt: Not installed
2023-10-23 14:34:49,065:INFO:              optuna: Not installed
2023-10-23 14:34:49,065:INFO:               skopt: Not installed
2023-10-23 14:34:49,065:INFO:              mlflow: 2.7.1
2023-10-23 14:34:49,065:INFO:              gradio: Not installed
2023-10-23 14:34:49,065:INFO:             fastapi: Not installed
2023-10-23 14:34:49,065:INFO:             uvicorn: Not installed
2023-10-23 14:34:49,065:INFO:              m2cgen: Not installed
2023-10-23 14:34:49,065:INFO:           evidently: Not installed
2023-10-23 14:34:49,065:INFO:               fugue: Not installed
2023-10-23 14:34:49,065:INFO:           streamlit: Not installed
2023-10-23 14:34:49,065:INFO:             prophet: Not installed
2023-10-23 14:34:49,065:INFO:None
2023-10-23 14:34:49,065:INFO:Set up data.
2023-10-23 14:34:49,098:INFO:Set up folding strategy.
2023-10-23 14:34:49,098:INFO:Set up train/test split.
2023-10-23 14:34:49,115:INFO:Set up index.
2023-10-23 14:34:49,115:INFO:Assigning column types.
2023-10-23 14:34:49,145:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 14:34:49,145:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,151:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,153:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,242:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,285:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,285:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:34:49,285:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:34:49,285:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,300:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,305:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,382:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,433:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,433:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:34:49,433:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:34:49,433:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 14:34:49,433:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,447:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,530:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,581:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,582:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:34:49,582:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:34:49,585:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,585:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,664:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,718:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,718:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:34:49,718:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:34:49,718:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 14:34:49,731:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,803:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,847:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,847:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:34:49,847:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:34:49,864:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,948:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,998:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,998:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:34:49,998:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:34:49,998:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 14:34:50,084:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:34:50,134:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:34:50,134:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:34:50,134:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:34:50,247:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:34:50,302:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:34:50,302:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:34:50,302:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:34:50,302:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 14:34:50,425:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:34:50,490:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:34:50,490:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:34:50,594:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:34:50,663:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:34:50,663:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:34:50,664:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 14:34:50,828:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:34:50,828:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:34:51,013:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:34:51,013:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:34:51,013:INFO:Preparing preprocessing pipeline...
2023-10-23 14:34:51,013:INFO:Set up simple imputation.
2023-10-23 14:34:51,028:INFO:Set up column name cleaning.
2023-10-23 14:34:51,096:INFO:Finished creating preprocessing pipeline.
2023-10-23 14:34:51,110:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 14:34:51,110:INFO:Creating final display dataframe.
2023-10-23 14:34:51,314:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (26071, 50)
4        Transformed data shape   (26071, 50)
5   Transformed train set shape   (18249, 50)
6    Transformed test set shape    (7822, 50)
7              Numeric features            49
8      Rows with missing values         95.9%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_C
19                          USI          cd30
2023-10-23 14:34:51,448:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:34:51,448:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:34:51,595:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:34:51,595:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:34:51,611:INFO:Logging experiment in loggers
2023-10-23 14:34:51,761:INFO:SubProcess save_model() called ==================================
2023-10-23 14:34:51,782:INFO:Initializing save_model()
2023-10-23 14:34:51,782:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmpmgj36nu5\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 14:34:51,782:INFO:Adding model into prep_pipe
2023-10-23 14:34:51,783:WARNING:Only Model saved as it was a pipeline.
2023-10-23 14:34:51,783:INFO:C:\Users\thoma\AppData\Local\Temp\tmpmgj36nu5\Transformation Pipeline.pkl saved in current working directory
2023-10-23 14:34:51,798:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 14:34:51,798:INFO:save_model() successfully completed......................................
2023-10-23 14:34:51,913:INFO:SubProcess save_model() end ==================================
2023-10-23 14:34:51,978:INFO:setup() successfully completed in 2.56s...............
2023-10-23 14:34:51,978:INFO:Initializing create_model()
2023-10-23 14:34:51,978:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84F40>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:34:51,978:INFO:Checking exceptions
2023-10-23 14:34:51,978:INFO:Importing libraries
2023-10-23 14:34:51,978:INFO:Copying training dataset
2023-10-23 14:34:51,996:INFO:Defining folds
2023-10-23 14:34:51,996:INFO:Declaring metric variables
2023-10-23 14:34:51,996:INFO:Importing untrained model
2023-10-23 14:34:52,010:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:34:52,010:INFO:Starting cross validation
2023-10-23 14:34:52,012:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:34:54,863:INFO:Calculating mean and std
2023-10-23 14:34:54,865:INFO:Creating metrics dataframe
2023-10-23 14:34:54,868:INFO:Finalizing model
2023-10-23 14:34:54,941:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004423 seconds.
2023-10-23 14:34:54,941:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:54,941:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:34:54,941:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:34:54,941:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-23 14:34:55,194:INFO:Creating Dashboard logs
2023-10-23 14:34:55,195:INFO:Model: Light Gradient Boosting Machine
2023-10-23 14:34:55,290:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 14:34:55,492:INFO:Initializing predict_model()
2023-10-23 14:34:55,492:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84F40>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096EA8EE0>)
2023-10-23 14:34:55,492:INFO:Checking exceptions
2023-10-23 14:34:55,492:INFO:Preloading libraries
2023-10-23 14:34:55,993:INFO:Uploading results into container
2023-10-23 14:34:55,993:INFO:Uploading model into container now
2023-10-23 14:34:55,993:INFO:_master_model_container: 1
2023-10-23 14:34:55,993:INFO:_display_container: 2
2023-10-23 14:34:55,993:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:34:55,993:INFO:create_model() successfully completed......................................
2023-10-23 14:34:56,110:INFO:Initializing tune_model()
2023-10-23 14:34:56,110:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84F40>)
2023-10-23 14:34:56,110:INFO:Checking exceptions
2023-10-23 14:34:56,125:INFO:Copying training dataset
2023-10-23 14:34:56,141:INFO:Checking base model
2023-10-23 14:34:56,141:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 14:34:56,145:INFO:Declaring metric variables
2023-10-23 14:34:56,145:INFO:Defining Hyperparameters
2023-10-23 14:34:56,264:INFO:Tuning with n_jobs=-1
2023-10-23 14:34:56,265:INFO:Initializing RandomizedSearchCV
2023-10-23 14:35:33,443:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-23 14:35:33,444:INFO:Hyperparameter search completed
2023-10-23 14:35:33,445:INFO:SubProcess create_model() called ==================================
2023-10-23 14:35:33,446:INFO:Initializing create_model()
2023-10-23 14:35:33,446:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84F40>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E096DBC580>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-23 14:35:33,446:INFO:Checking exceptions
2023-10-23 14:35:33,447:INFO:Importing libraries
2023-10-23 14:35:33,447:INFO:Copying training dataset
2023-10-23 14:35:33,469:INFO:Defining folds
2023-10-23 14:35:33,469:INFO:Declaring metric variables
2023-10-23 14:35:33,469:INFO:Importing untrained model
2023-10-23 14:35:33,475:INFO:Declaring custom model
2023-10-23 14:35:33,476:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:35:33,476:INFO:Starting cross validation
2023-10-23 14:35:33,478:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:35:42,059:INFO:Calculating mean and std
2023-10-23 14:35:42,059:INFO:Creating metrics dataframe
2023-10-23 14:35:42,059:INFO:Finalizing model
2023-10-23 14:35:42,117:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-23 14:35:42,117:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-23 14:35:42,117:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-23 14:35:42,135:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-23 14:35:42,135:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-23 14:35:42,135:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-23 14:35:42,151:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004649 seconds.
2023-10-23 14:35:42,151:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:35:42,151:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:35:42,151:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:35:42,151:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-23 14:35:42,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:35:42,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:35:42,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:35:42,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:35:42,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:35:42,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:35:42,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:35:42,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:35:43,388:INFO:Uploading results into container
2023-10-23 14:35:43,403:INFO:Uploading model into container now
2023-10-23 14:35:43,403:INFO:_master_model_container: 2
2023-10-23 14:35:43,403:INFO:_display_container: 3
2023-10-23 14:35:43,403:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-23 14:35:43,403:INFO:create_model() successfully completed......................................
2023-10-23 14:35:43,534:INFO:SubProcess create_model() end ==================================
2023-10-23 14:35:43,534:INFO:choose_better activated
2023-10-23 14:35:43,534:INFO:SubProcess create_model() called ==================================
2023-10-23 14:35:43,534:INFO:Initializing create_model()
2023-10-23 14:35:43,534:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84F40>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:35:43,534:INFO:Checking exceptions
2023-10-23 14:35:43,534:INFO:Importing libraries
2023-10-23 14:35:43,534:INFO:Copying training dataset
2023-10-23 14:35:43,557:INFO:Defining folds
2023-10-23 14:35:43,557:INFO:Declaring metric variables
2023-10-23 14:35:43,557:INFO:Importing untrained model
2023-10-23 14:35:43,557:INFO:Declaring custom model
2023-10-23 14:35:43,557:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:35:43,557:INFO:Starting cross validation
2023-10-23 14:35:43,557:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:35:45,883:INFO:Calculating mean and std
2023-10-23 14:35:45,883:INFO:Creating metrics dataframe
2023-10-23 14:35:45,883:INFO:Finalizing model
2023-10-23 14:35:45,966:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005855 seconds.
2023-10-23 14:35:45,966:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:35:45,966:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:35:45,966:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:35:45,966:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-23 14:35:46,183:INFO:Uploading results into container
2023-10-23 14:35:46,183:INFO:Uploading model into container now
2023-10-23 14:35:46,183:INFO:_master_model_container: 3
2023-10-23 14:35:46,183:INFO:_display_container: 4
2023-10-23 14:35:46,183:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:35:46,183:INFO:create_model() successfully completed......................................
2023-10-23 14:35:46,299:INFO:SubProcess create_model() end ==================================
2023-10-23 14:35:46,299:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.905
2023-10-23 14:35:46,299:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8993
2023-10-23 14:35:46,299:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-23 14:35:46,299:INFO:choose_better completed
2023-10-23 14:35:46,299:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-23 14:35:46,299:INFO:Creating Dashboard logs
2023-10-23 14:35:46,299:INFO:Model: Light Gradient Boosting Machine
2023-10-23 14:35:46,366:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 14:35:46,569:INFO:Initializing predict_model()
2023-10-23 14:35:46,569:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84F40>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096EA88B0>)
2023-10-23 14:35:46,569:INFO:Checking exceptions
2023-10-23 14:35:46,569:INFO:Preloading libraries
2023-10-23 14:35:47,018:INFO:_master_model_container: 3
2023-10-23 14:35:47,018:INFO:_display_container: 3
2023-10-23 14:35:47,018:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:35:47,018:INFO:tune_model() successfully completed......................................
2023-10-23 14:35:47,122:INFO:Initializing ensemble_model()
2023-10-23 14:35:47,122:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84F40>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-23 14:35:47,122:INFO:Checking exceptions
2023-10-23 14:35:47,138:INFO:Importing libraries
2023-10-23 14:35:47,138:INFO:Copying training dataset
2023-10-23 14:35:47,138:INFO:Checking base model
2023-10-23 14:35:47,138:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 14:35:47,138:INFO:Importing untrained ensembler
2023-10-23 14:35:47,138:INFO:Ensemble method set to Bagging
2023-10-23 14:35:47,138:INFO:SubProcess create_model() called ==================================
2023-10-23 14:35:47,138:INFO:Initializing create_model()
2023-10-23 14:35:47,138:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84F40>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E0971C0DF0>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:35:47,138:INFO:Checking exceptions
2023-10-23 14:35:47,138:INFO:Importing libraries
2023-10-23 14:35:47,138:INFO:Copying training dataset
2023-10-23 14:35:47,174:INFO:Defining folds
2023-10-23 14:35:47,174:INFO:Declaring metric variables
2023-10-23 14:35:47,174:INFO:Importing untrained model
2023-10-23 14:35:47,174:INFO:Declaring custom model
2023-10-23 14:35:47,176:INFO:Bagging Regressor Imported successfully
2023-10-23 14:35:47,177:INFO:Starting cross validation
2023-10-23 14:35:47,178:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:36:10,530:INFO:Calculating mean and std
2023-10-23 14:36:10,530:INFO:Creating metrics dataframe
2023-10-23 14:36:10,530:INFO:Finalizing model
2023-10-23 14:36:10,646:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005017 seconds.
2023-10-23 14:36:10,646:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:10,646:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:36:10,646:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:36:10,646:INFO:[LightGBM] [Info] Start training from score 77.044367
2023-10-23 14:36:10,912:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004618 seconds.
2023-10-23 14:36:10,912:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:10,912:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:36:10,912:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:36:10,912:INFO:[LightGBM] [Info] Start training from score 76.520588
2023-10-23 14:36:11,179:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005437 seconds.
2023-10-23 14:36:11,179:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:11,179:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:36:11,179:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:36:11,179:INFO:[LightGBM] [Info] Start training from score 76.462170
2023-10-23 14:36:11,446:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005279 seconds.
2023-10-23 14:36:11,446:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:11,446:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:36:11,446:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:36:11,446:INFO:[LightGBM] [Info] Start training from score 77.386428
2023-10-23 14:36:11,711:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005075 seconds.
2023-10-23 14:36:11,711:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:11,711:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:36:11,711:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:36:11,711:INFO:[LightGBM] [Info] Start training from score 73.916304
2023-10-23 14:36:11,961:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004452 seconds.
2023-10-23 14:36:11,961:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:11,961:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:36:11,961:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:36:11,977:INFO:[LightGBM] [Info] Start training from score 75.879633
2023-10-23 14:36:12,235:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004582 seconds.
2023-10-23 14:36:12,235:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:12,235:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:36:12,235:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:36:12,235:INFO:[LightGBM] [Info] Start training from score 75.615395
2023-10-23 14:36:12,494:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004239 seconds.
2023-10-23 14:36:12,494:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:12,494:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:36:12,494:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:36:12,494:INFO:[LightGBM] [Info] Start training from score 79.544595
2023-10-23 14:36:12,777:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005002 seconds.
2023-10-23 14:36:12,777:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:12,777:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:36:12,777:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:36:12,777:INFO:[LightGBM] [Info] Start training from score 76.012052
2023-10-23 14:36:13,094:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004560 seconds.
2023-10-23 14:36:13,094:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:13,094:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:36:13,094:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:36:13,094:INFO:[LightGBM] [Info] Start training from score 78.124037
2023-10-23 14:36:13,323:INFO:Uploading results into container
2023-10-23 14:36:13,325:INFO:Uploading model into container now
2023-10-23 14:36:13,326:INFO:_master_model_container: 4
2023-10-23 14:36:13,326:INFO:_display_container: 4
2023-10-23 14:36:13,327:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:36:13,327:INFO:create_model() successfully completed......................................
2023-10-23 14:36:13,443:INFO:SubProcess create_model() end ==================================
2023-10-23 14:36:13,443:INFO:Creating Dashboard logs
2023-10-23 14:36:13,443:INFO:Model: Bagging Regressor
2023-10-23 14:36:13,514:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-23 14:36:13,764:INFO:Initializing predict_model()
2023-10-23 14:36:13,764:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84F40>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096EA8670>)
2023-10-23 14:36:13,764:INFO:Checking exceptions
2023-10-23 14:36:13,764:INFO:Preloading libraries
2023-10-23 14:36:14,361:INFO:_master_model_container: 4
2023-10-23 14:36:14,361:INFO:_display_container: 4
2023-10-23 14:36:14,362:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:36:14,363:INFO:ensemble_model() successfully completed......................................
2023-10-23 14:36:14,458:INFO:Initializing finalize_model()
2023-10-23 14:36:14,458:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84F40>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-23 14:36:14,459:INFO:Finalizing BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:36:14,464:INFO:Initializing create_model()
2023-10-23 14:36:14,464:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84F40>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-23 14:36:14,464:INFO:Checking exceptions
2023-10-23 14:36:14,464:INFO:Importing libraries
2023-10-23 14:36:14,464:INFO:Copying training dataset
2023-10-23 14:36:14,464:INFO:Defining folds
2023-10-23 14:36:14,464:INFO:Declaring metric variables
2023-10-23 14:36:14,464:INFO:Importing untrained model
2023-10-23 14:36:14,464:INFO:Declaring custom model
2023-10-23 14:36:14,475:INFO:Bagging Regressor Imported successfully
2023-10-23 14:36:14,476:INFO:Cross validation set to False
2023-10-23 14:36:14,476:INFO:Fitting Model
2023-10-23 14:36:14,559:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008366 seconds.
2023-10-23 14:36:14,559:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:14,559:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:36:14,559:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:36:14,575:INFO:[LightGBM] [Info] Start training from score 77.360615
2023-10-23 14:36:14,929:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006046 seconds.
2023-10-23 14:36:14,929:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:14,945:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:36:14,945:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:36:14,945:INFO:[LightGBM] [Info] Start training from score 78.162759
2023-10-23 14:36:15,246:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006855 seconds.
2023-10-23 14:36:15,246:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:15,247:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:36:15,247:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:36:15,247:INFO:[LightGBM] [Info] Start training from score 77.185434
2023-10-23 14:36:15,545:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008025 seconds.
2023-10-23 14:36:15,545:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:15,545:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:36:15,545:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:36:15,545:INFO:[LightGBM] [Info] Start training from score 78.293126
2023-10-23 14:36:15,947:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007751 seconds.
2023-10-23 14:36:15,947:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:15,947:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:36:15,947:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:36:15,947:INFO:[LightGBM] [Info] Start training from score 75.493649
2023-10-23 14:36:16,251:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007603 seconds.
2023-10-23 14:36:16,251:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:16,251:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:36:16,252:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:36:16,252:INFO:[LightGBM] [Info] Start training from score 77.467219
2023-10-23 14:36:16,543:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005685 seconds.
2023-10-23 14:36:16,543:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:16,543:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:36:16,543:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:36:16,543:INFO:[LightGBM] [Info] Start training from score 77.083598
2023-10-23 14:36:16,849:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006492 seconds.
2023-10-23 14:36:16,849:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:16,849:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:36:16,849:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:36:16,849:INFO:[LightGBM] [Info] Start training from score 79.854607
2023-10-23 14:36:17,144:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006850 seconds.
2023-10-23 14:36:17,144:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:17,144:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:36:17,144:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:36:17,144:INFO:[LightGBM] [Info] Start training from score 76.153078
2023-10-23 14:36:17,461:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006621 seconds.
2023-10-23 14:36:17,461:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:17,461:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:36:17,461:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:36:17,461:INFO:[LightGBM] [Info] Start training from score 78.843978
2023-10-23 14:36:17,730:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:36:17,730:INFO:create_model() successfully completed......................................
2023-10-23 14:36:17,844:INFO:Creating Dashboard logs
2023-10-23 14:36:17,844:INFO:Model: Bagging Regressor
2023-10-23 14:36:17,923:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-23 14:36:18,341:INFO:_master_model_container: 4
2023-10-23 14:36:18,341:INFO:_display_container: 4
2023-10-23 14:36:18,357:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:36:18,357:INFO:finalize_model() successfully completed......................................
2023-10-23 14:36:18,477:INFO:Initializing save_model()
2023-10-23 14:36:18,477:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), model_name=final_model_for_location_C, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 14:36:18,477:INFO:Adding model into prep_pipe
2023-10-23 14:36:18,477:WARNING:Only Model saved as it was a pipeline.
2023-10-23 14:36:18,541:INFO:final_model_for_location_C.pkl saved in current working directory
2023-10-23 14:36:18,556:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:36:18,556:INFO:save_model() successfully completed......................................
2023-10-23 14:36:19,990:INFO:Initializing load_model()
2023-10-23 14:36:19,990:INFO:load_model(model_name=final_model_for_location_A, platform=None, authentication=None, verbose=True)
2023-10-23 14:36:20,024:INFO:Initializing load_model()
2023-10-23 14:36:20,024:INFO:load_model(model_name=final_model_for_location_B, platform=None, authentication=None, verbose=True)
2023-10-23 14:36:20,082:INFO:Initializing load_model()
2023-10-23 14:36:20,083:INFO:load_model(model_name=final_model_for_location_C, platform=None, authentication=None, verbose=True)
2023-10-23 14:36:20,152:INFO:Initializing predict_model()
2023-10-23 14:36:20,152:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84F40>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E0970AA5E0>)
2023-10-23 14:36:20,153:INFO:Checking exceptions
2023-10-23 14:36:20,153:INFO:Preloading libraries
2023-10-23 14:36:20,153:INFO:Set up data.
2023-10-23 14:36:20,183:INFO:Set up index.
2023-10-23 14:36:20,386:INFO:Initializing predict_model()
2023-10-23 14:36:20,386:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84F40>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E0970AA5E0>)
2023-10-23 14:36:20,386:INFO:Checking exceptions
2023-10-23 14:36:20,386:INFO:Preloading libraries
2023-10-23 14:36:20,386:INFO:Set up data.
2023-10-23 14:36:20,402:INFO:Set up index.
2023-10-23 14:36:20,593:INFO:Initializing predict_model()
2023-10-23 14:36:20,594:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84F40>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E0970AA5E0>)
2023-10-23 14:36:20,594:INFO:Checking exceptions
2023-10-23 14:36:20,594:INFO:Preloading libraries
2023-10-23 14:36:20,594:INFO:Set up data.
2023-10-23 14:36:20,611:INFO:Set up index.
2023-10-23 14:44:05,097:INFO:PyCaret RegressionExperiment
2023-10-23 14:44:05,097:INFO:Logging name: exp_A
2023-10-23 14:44:05,098:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 14:44:05,098:INFO:version 3.1.0
2023-10-23 14:44:05,098:INFO:Initializing setup()
2023-10-23 14:44:05,098:INFO:self.USI: 9317
2023-10-23 14:44:05,099:INFO:self._variable_keys: {'gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', '_ml_usecase', 'gpu_param', 'exp_name_log', 'html_param', 'fold_generator', 'y', 'seed', 'y_train', 'transform_target_param', 'n_jobs_param', 'target_param', 'idx', '_available_plots', 'log_plots_param', 'memory', 'data', 'USI', 'X', 'logging_param', 'pipeline', 'exp_id', 'X_train', 'X_test', 'fold_groups_param'}
2023-10-23 14:44:05,099:INFO:Checking environment
2023-10-23 14:44:05,099:INFO:python_version: 3.8.18
2023-10-23 14:44:05,099:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 14:44:05,099:INFO:machine: AMD64
2023-10-23 14:44:05,099:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 14:44:05,100:INFO:Memory: svmem(total=16505954304, available=4620279808, percent=72.0, used=11885674496, free=4620279808)
2023-10-23 14:44:05,100:INFO:Physical Core: 8
2023-10-23 14:44:05,100:INFO:Logical Core: 16
2023-10-23 14:44:05,100:INFO:Checking libraries
2023-10-23 14:44:05,100:INFO:System:
2023-10-23 14:44:05,101:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 14:44:05,101:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 14:44:05,101:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 14:44:05,101:INFO:PyCaret required dependencies:
2023-10-23 14:44:05,101:INFO:                 pip: 23.3
2023-10-23 14:44:05,101:INFO:          setuptools: 68.0.0
2023-10-23 14:44:05,101:INFO:             pycaret: 3.1.0
2023-10-23 14:44:05,101:INFO:             IPython: 8.12.0
2023-10-23 14:44:05,101:INFO:          ipywidgets: 8.1.1
2023-10-23 14:44:05,101:INFO:                tqdm: 4.66.1
2023-10-23 14:44:05,101:INFO:               numpy: 1.23.5
2023-10-23 14:44:05,101:INFO:              pandas: 1.5.3
2023-10-23 14:44:05,101:INFO:              jinja2: 3.1.2
2023-10-23 14:44:05,101:INFO:               scipy: 1.10.1
2023-10-23 14:44:05,101:INFO:              joblib: 1.3.2
2023-10-23 14:44:05,102:INFO:             sklearn: 1.2.2
2023-10-23 14:44:05,102:INFO:                pyod: 1.1.0
2023-10-23 14:44:05,102:INFO:            imblearn: 0.11.0
2023-10-23 14:44:05,102:INFO:   category_encoders: 2.6.2
2023-10-23 14:44:05,102:INFO:            lightgbm: 4.1.0
2023-10-23 14:44:05,102:INFO:               numba: 0.58.1
2023-10-23 14:44:05,102:INFO:            requests: 2.31.0
2023-10-23 14:44:05,102:INFO:          matplotlib: 3.7.3
2023-10-23 14:44:05,102:INFO:          scikitplot: 0.3.7
2023-10-23 14:44:05,102:INFO:         yellowbrick: 1.5
2023-10-23 14:44:05,102:INFO:              plotly: 5.17.0
2023-10-23 14:44:05,102:INFO:    plotly-resampler: Not installed
2023-10-23 14:44:05,102:INFO:             kaleido: 0.2.1
2023-10-23 14:44:05,102:INFO:           schemdraw: 0.15
2023-10-23 14:44:05,102:INFO:         statsmodels: 0.14.0
2023-10-23 14:44:05,102:INFO:              sktime: 0.21.1
2023-10-23 14:44:05,102:INFO:               tbats: 1.1.3
2023-10-23 14:44:05,102:INFO:            pmdarima: 2.0.3
2023-10-23 14:44:05,103:INFO:              psutil: 5.9.0
2023-10-23 14:44:05,103:INFO:          markupsafe: 2.1.3
2023-10-23 14:44:05,103:INFO:             pickle5: Not installed
2023-10-23 14:44:05,103:INFO:         cloudpickle: 2.2.1
2023-10-23 14:44:05,103:INFO:         deprecation: 2.1.0
2023-10-23 14:44:05,103:INFO:              xxhash: 3.4.1
2023-10-23 14:44:05,103:INFO:           wurlitzer: Not installed
2023-10-23 14:44:05,103:INFO:PyCaret optional dependencies:
2023-10-23 14:44:05,103:INFO:                shap: Not installed
2023-10-23 14:44:05,103:INFO:           interpret: Not installed
2023-10-23 14:44:05,103:INFO:                umap: Not installed
2023-10-23 14:44:05,103:INFO:     ydata_profiling: Not installed
2023-10-23 14:44:05,103:INFO:  explainerdashboard: Not installed
2023-10-23 14:44:05,103:INFO:             autoviz: Not installed
2023-10-23 14:44:05,104:INFO:           fairlearn: Not installed
2023-10-23 14:44:05,104:INFO:          deepchecks: Not installed
2023-10-23 14:44:05,104:INFO:             xgboost: Not installed
2023-10-23 14:44:05,104:INFO:            catboost: 1.2.2
2023-10-23 14:44:05,104:INFO:              kmodes: Not installed
2023-10-23 14:44:05,104:INFO:             mlxtend: Not installed
2023-10-23 14:44:05,104:INFO:       statsforecast: Not installed
2023-10-23 14:44:05,104:INFO:        tune_sklearn: Not installed
2023-10-23 14:44:05,104:INFO:                 ray: Not installed
2023-10-23 14:44:05,104:INFO:            hyperopt: Not installed
2023-10-23 14:44:05,104:INFO:              optuna: Not installed
2023-10-23 14:44:05,104:INFO:               skopt: Not installed
2023-10-23 14:44:05,104:INFO:              mlflow: 2.7.1
2023-10-23 14:44:05,104:INFO:              gradio: Not installed
2023-10-23 14:44:05,104:INFO:             fastapi: Not installed
2023-10-23 14:44:05,104:INFO:             uvicorn: Not installed
2023-10-23 14:44:05,105:INFO:              m2cgen: Not installed
2023-10-23 14:44:05,105:INFO:           evidently: Not installed
2023-10-23 14:44:05,105:INFO:               fugue: Not installed
2023-10-23 14:44:05,105:INFO:           streamlit: Not installed
2023-10-23 14:44:05,105:INFO:             prophet: Not installed
2023-10-23 14:44:05,106:INFO:None
2023-10-23 14:44:05,106:INFO:Set up data.
2023-10-23 14:44:05,140:INFO:Set up folding strategy.
2023-10-23 14:44:05,141:INFO:Set up train/test split.
2023-10-23 14:44:05,167:INFO:Set up index.
2023-10-23 14:44:05,169:INFO:Assigning column types.
2023-10-23 14:44:05,192:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 14:44:05,194:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,199:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,204:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,290:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,356:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,358:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:44:05,358:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:44:05,359:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,365:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,371:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,450:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,499:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,500:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:44:05,500:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:44:05,501:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 14:44:05,506:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,512:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,596:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,647:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,647:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:44:05,648:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:44:05,653:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,659:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,741:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,793:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,794:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:44:05,794:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:44:05,795:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 14:44:05,806:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,890:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,947:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,948:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:44:05,948:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:44:05,960:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:44:06,057:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:44:06,125:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:44:06,126:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:44:06,126:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:44:06,128:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 14:44:06,231:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:44:06,286:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:44:06,287:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:44:06,287:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:44:06,383:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:44:06,436:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:44:06,437:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:44:06,437:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:44:06,438:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 14:44:06,552:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:44:06,603:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:44:06,603:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:44:06,691:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:44:06,752:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:44:06,754:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:44:06,755:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 14:44:06,913:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:44:06,913:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:44:07,055:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:44:07,055:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:44:07,057:INFO:Preparing preprocessing pipeline...
2023-10-23 14:44:07,057:INFO:Set up simple imputation.
2023-10-23 14:44:07,060:INFO:Set up column name cleaning.
2023-10-23 14:44:07,130:INFO:Finished creating preprocessing pipeline.
2023-10-23 14:44:07,135:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 14:44:07,136:INFO:Creating final display dataframe.
2023-10-23 14:44:07,340:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (34061, 49)
4        Transformed data shape   (34061, 49)
5   Transformed train set shape   (23842, 49)
6    Transformed test set shape   (10219, 49)
7              Numeric features            48
8      Rows with missing values         23.1%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_A
19                          USI          9317
2023-10-23 14:44:07,479:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:44:07,479:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:44:07,621:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:44:07,621:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:44:07,622:INFO:Logging experiment in loggers
2023-10-23 14:44:07,745:INFO:SubProcess save_model() called ==================================
2023-10-23 14:44:07,760:INFO:Initializing save_model()
2023-10-23 14:44:07,760:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmpl_wn4l99\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 14:44:07,760:INFO:Adding model into prep_pipe
2023-10-23 14:44:07,760:WARNING:Only Model saved as it was a pipeline.
2023-10-23 14:44:07,765:INFO:C:\Users\thoma\AppData\Local\Temp\tmpl_wn4l99\Transformation Pipeline.pkl saved in current working directory
2023-10-23 14:44:07,772:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 14:44:07,772:INFO:save_model() successfully completed......................................
2023-10-23 14:44:07,904:INFO:SubProcess save_model() end ==================================
2023-10-23 14:44:07,962:INFO:setup() successfully completed in 2.53s...............
2023-10-23 14:44:07,963:INFO:Initializing create_model()
2023-10-23 14:44:07,963:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84FD0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:44:07,963:INFO:Checking exceptions
2023-10-23 14:44:07,967:INFO:Importing libraries
2023-10-23 14:44:07,968:INFO:Copying training dataset
2023-10-23 14:44:07,992:INFO:Defining folds
2023-10-23 14:44:07,992:INFO:Declaring metric variables
2023-10-23 14:44:07,993:INFO:Importing untrained model
2023-10-23 14:44:07,993:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:44:07,993:INFO:Starting cross validation
2023-10-23 14:44:07,995:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:44:16,927:INFO:Calculating mean and std
2023-10-23 14:44:16,928:INFO:Creating metrics dataframe
2023-10-23 14:44:16,931:INFO:Finalizing model
2023-10-23 14:44:17,012:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005245 seconds.
2023-10-23 14:44:17,012:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:44:17,012:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:44:17,013:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:44:17,014:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-23 14:44:17,241:INFO:Creating Dashboard logs
2023-10-23 14:44:17,242:INFO:Model: Light Gradient Boosting Machine
2023-10-23 14:44:17,335:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 14:44:17,526:INFO:Initializing predict_model()
2023-10-23 14:44:17,526:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84FD0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E08C7A5160>)
2023-10-23 14:44:17,526:INFO:Checking exceptions
2023-10-23 14:44:17,526:INFO:Preloading libraries
2023-10-23 14:44:18,009:INFO:Uploading results into container
2023-10-23 14:44:18,010:INFO:Uploading model into container now
2023-10-23 14:44:18,018:INFO:_master_model_container: 1
2023-10-23 14:44:18,019:INFO:_display_container: 2
2023-10-23 14:44:18,020:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:44:18,020:INFO:create_model() successfully completed......................................
2023-10-23 14:44:18,137:INFO:Initializing tune_model()
2023-10-23 14:44:18,137:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84FD0>)
2023-10-23 14:44:18,138:INFO:Checking exceptions
2023-10-23 14:44:18,150:INFO:Copying training dataset
2023-10-23 14:44:18,165:INFO:Checking base model
2023-10-23 14:44:18,166:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 14:44:18,166:INFO:Declaring metric variables
2023-10-23 14:44:18,166:INFO:Defining Hyperparameters
2023-10-23 14:44:18,278:INFO:Tuning with n_jobs=-1
2023-10-23 14:44:18,278:INFO:Initializing RandomizedSearchCV
2023-10-23 14:45:08,698:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-23 14:45:08,699:INFO:Hyperparameter search completed
2023-10-23 14:45:08,699:INFO:SubProcess create_model() called ==================================
2023-10-23 14:45:08,700:INFO:Initializing create_model()
2023-10-23 14:45:08,700:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84FD0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E0C7ECD820>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-23 14:45:08,700:INFO:Checking exceptions
2023-10-23 14:45:08,701:INFO:Importing libraries
2023-10-23 14:45:08,701:INFO:Copying training dataset
2023-10-23 14:45:08,726:INFO:Defining folds
2023-10-23 14:45:08,726:INFO:Declaring metric variables
2023-10-23 14:45:08,726:INFO:Importing untrained model
2023-10-23 14:45:08,726:INFO:Declaring custom model
2023-10-23 14:45:08,726:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:45:08,726:INFO:Starting cross validation
2023-10-23 14:45:08,733:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:45:17,878:INFO:Calculating mean and std
2023-10-23 14:45:17,878:INFO:Creating metrics dataframe
2023-10-23 14:45:17,878:INFO:Finalizing model
2023-10-23 14:45:17,939:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-23 14:45:17,943:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-23 14:45:17,943:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-23 14:45:17,981:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-23 14:45:17,981:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-23 14:45:17,981:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-23 14:45:17,990:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006455 seconds.
2023-10-23 14:45:17,990:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:17,990:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:45:17,990:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:45:17,993:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-23 14:45:19,086:INFO:Uploading results into container
2023-10-23 14:45:19,086:INFO:Uploading model into container now
2023-10-23 14:45:19,086:INFO:_master_model_container: 2
2023-10-23 14:45:19,086:INFO:_display_container: 3
2023-10-23 14:45:19,086:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-23 14:45:19,086:INFO:create_model() successfully completed......................................
2023-10-23 14:45:19,218:INFO:SubProcess create_model() end ==================================
2023-10-23 14:45:19,218:INFO:choose_better activated
2023-10-23 14:45:19,218:INFO:SubProcess create_model() called ==================================
2023-10-23 14:45:19,218:INFO:Initializing create_model()
2023-10-23 14:45:19,218:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84FD0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:45:19,218:INFO:Checking exceptions
2023-10-23 14:45:19,218:INFO:Importing libraries
2023-10-23 14:45:19,218:INFO:Copying training dataset
2023-10-23 14:45:19,253:INFO:Defining folds
2023-10-23 14:45:19,253:INFO:Declaring metric variables
2023-10-23 14:45:19,253:INFO:Importing untrained model
2023-10-23 14:45:19,253:INFO:Declaring custom model
2023-10-23 14:45:19,254:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:45:19,254:INFO:Starting cross validation
2023-10-23 14:45:19,254:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:45:22,115:INFO:Calculating mean and std
2023-10-23 14:45:22,115:INFO:Creating metrics dataframe
2023-10-23 14:45:22,115:INFO:Finalizing model
2023-10-23 14:45:22,199:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006830 seconds.
2023-10-23 14:45:22,199:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:22,199:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:45:22,199:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:45:22,199:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-23 14:45:22,451:INFO:Uploading results into container
2023-10-23 14:45:22,451:INFO:Uploading model into container now
2023-10-23 14:45:22,451:INFO:_master_model_container: 3
2023-10-23 14:45:22,451:INFO:_display_container: 4
2023-10-23 14:45:22,451:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:45:22,451:INFO:create_model() successfully completed......................................
2023-10-23 14:45:22,590:INFO:SubProcess create_model() end ==================================
2023-10-23 14:45:22,590:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8716
2023-10-23 14:45:22,590:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8712
2023-10-23 14:45:22,590:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-23 14:45:22,590:INFO:choose_better completed
2023-10-23 14:45:22,590:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-23 14:45:22,590:INFO:Creating Dashboard logs
2023-10-23 14:45:22,590:INFO:Model: Light Gradient Boosting Machine
2023-10-23 14:45:22,679:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 14:45:22,874:INFO:Initializing predict_model()
2023-10-23 14:45:22,874:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84FD0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E08C6C3AF0>)
2023-10-23 14:45:22,874:INFO:Checking exceptions
2023-10-23 14:45:22,874:INFO:Preloading libraries
2023-10-23 14:45:23,391:INFO:_master_model_container: 3
2023-10-23 14:45:23,391:INFO:_display_container: 3
2023-10-23 14:45:23,391:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:45:23,391:INFO:tune_model() successfully completed......................................
2023-10-23 14:45:23,507:INFO:Initializing ensemble_model()
2023-10-23 14:45:23,507:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84FD0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-23 14:45:23,507:INFO:Checking exceptions
2023-10-23 14:45:23,524:INFO:Importing libraries
2023-10-23 14:45:23,524:INFO:Copying training dataset
2023-10-23 14:45:23,524:INFO:Checking base model
2023-10-23 14:45:23,524:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 14:45:23,524:INFO:Importing untrained ensembler
2023-10-23 14:45:23,524:INFO:Ensemble method set to Bagging
2023-10-23 14:45:23,524:INFO:SubProcess create_model() called ==================================
2023-10-23 14:45:23,524:INFO:Initializing create_model()
2023-10-23 14:45:23,524:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84FD0>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E096CDC790>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:45:23,524:INFO:Checking exceptions
2023-10-23 14:45:23,524:INFO:Importing libraries
2023-10-23 14:45:23,524:INFO:Copying training dataset
2023-10-23 14:45:23,541:INFO:Defining folds
2023-10-23 14:45:23,541:INFO:Declaring metric variables
2023-10-23 14:45:23,541:INFO:Importing untrained model
2023-10-23 14:45:23,541:INFO:Declaring custom model
2023-10-23 14:45:23,541:INFO:Bagging Regressor Imported successfully
2023-10-23 14:45:23,541:INFO:Starting cross validation
2023-10-23 14:45:23,555:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:45:48,468:INFO:Calculating mean and std
2023-10-23 14:45:48,468:INFO:Creating metrics dataframe
2023-10-23 14:45:48,468:INFO:Finalizing model
2023-10-23 14:45:48,559:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005709 seconds.
2023-10-23 14:45:48,559:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:48,559:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:45:48,559:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:45:48,567:INFO:[LightGBM] [Info] Start training from score 626.831517
2023-10-23 14:45:48,856:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007452 seconds.
2023-10-23 14:45:48,856:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:48,857:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:45:48,857:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:45:48,858:INFO:[LightGBM] [Info] Start training from score 640.013980
2023-10-23 14:45:49,182:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005122 seconds.
2023-10-23 14:45:49,182:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:49,182:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:45:49,184:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:45:49,184:INFO:[LightGBM] [Info] Start training from score 623.946930
2023-10-23 14:45:49,440:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005796 seconds.
2023-10-23 14:45:49,440:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:49,440:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:45:49,455:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:45:49,455:INFO:[LightGBM] [Info] Start training from score 632.335152
2023-10-23 14:45:49,756:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007570 seconds.
2023-10-23 14:45:49,756:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:49,756:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:45:49,757:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:45:49,758:INFO:[LightGBM] [Info] Start training from score 620.070240
2023-10-23 14:45:50,021:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005001 seconds.
2023-10-23 14:45:50,021:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:50,021:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:45:50,021:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:45:50,021:INFO:[LightGBM] [Info] Start training from score 635.137343
2023-10-23 14:45:50,352:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005117 seconds.
2023-10-23 14:45:50,352:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:50,353:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:45:50,353:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:45:50,354:INFO:[LightGBM] [Info] Start training from score 620.066941
2023-10-23 14:45:50,672:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005249 seconds.
2023-10-23 14:45:50,672:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:50,673:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:45:50,673:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:45:50,674:INFO:[LightGBM] [Info] Start training from score 623.069874
2023-10-23 14:45:50,950:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005444 seconds.
2023-10-23 14:45:50,950:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:50,951:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:45:50,951:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:45:50,952:INFO:[LightGBM] [Info] Start training from score 633.817057
2023-10-23 14:45:51,237:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005689 seconds.
2023-10-23 14:45:51,237:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:51,237:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:45:51,237:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:45:51,237:INFO:[LightGBM] [Info] Start training from score 641.113408
2023-10-23 14:45:51,491:INFO:Uploading results into container
2023-10-23 14:45:51,491:INFO:Uploading model into container now
2023-10-23 14:45:51,491:INFO:_master_model_container: 4
2023-10-23 14:45:51,491:INFO:_display_container: 4
2023-10-23 14:45:51,499:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:45:51,499:INFO:create_model() successfully completed......................................
2023-10-23 14:45:51,632:INFO:SubProcess create_model() end ==================================
2023-10-23 14:45:51,632:INFO:Creating Dashboard logs
2023-10-23 14:45:51,632:INFO:Model: Bagging Regressor
2023-10-23 14:45:51,700:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-23 14:45:51,908:INFO:Initializing predict_model()
2023-10-23 14:45:51,908:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84FD0>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E08C6C3B80>)
2023-10-23 14:45:51,908:INFO:Checking exceptions
2023-10-23 14:45:51,908:INFO:Preloading libraries
2023-10-23 14:45:52,568:INFO:_master_model_container: 4
2023-10-23 14:45:52,568:INFO:_display_container: 4
2023-10-23 14:45:52,568:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:45:52,568:INFO:ensemble_model() successfully completed......................................
2023-10-23 14:45:52,684:INFO:Initializing finalize_model()
2023-10-23 14:45:52,684:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84FD0>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-23 14:45:52,684:INFO:Finalizing BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:45:52,701:INFO:Initializing create_model()
2023-10-23 14:45:52,701:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84FD0>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-23 14:45:52,701:INFO:Checking exceptions
2023-10-23 14:45:52,702:INFO:Importing libraries
2023-10-23 14:45:52,702:INFO:Copying training dataset
2023-10-23 14:45:52,702:INFO:Defining folds
2023-10-23 14:45:52,702:INFO:Declaring metric variables
2023-10-23 14:45:52,702:INFO:Importing untrained model
2023-10-23 14:45:52,702:INFO:Declaring custom model
2023-10-23 14:45:52,702:INFO:Bagging Regressor Imported successfully
2023-10-23 14:45:52,702:INFO:Cross validation set to False
2023-10-23 14:45:52,702:INFO:Fitting Model
2023-10-23 14:45:52,834:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008321 seconds.
2023-10-23 14:45:52,834:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:52,834:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:45:52,834:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:45:52,847:INFO:[LightGBM] [Info] Start training from score 634.491655
2023-10-23 14:45:53,204:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007528 seconds.
2023-10-23 14:45:53,204:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:53,204:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:45:53,204:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:45:53,204:INFO:[LightGBM] [Info] Start training from score 635.470959
2023-10-23 14:45:53,547:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006774 seconds.
2023-10-23 14:45:53,547:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:53,547:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:45:53,547:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:45:53,547:INFO:[LightGBM] [Info] Start training from score 634.053589
2023-10-23 14:45:53,980:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010125 seconds.
2023-10-23 14:45:53,980:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:53,981:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:45:53,981:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:45:53,982:INFO:[LightGBM] [Info] Start training from score 635.251785
2023-10-23 14:45:54,421:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008669 seconds.
2023-10-23 14:45:54,421:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:54,421:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:45:54,421:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:45:54,421:INFO:[LightGBM] [Info] Start training from score 627.555784
2023-10-23 14:45:54,780:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008666 seconds.
2023-10-23 14:45:54,780:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:54,780:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:45:54,780:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:45:54,780:INFO:[LightGBM] [Info] Start training from score 638.162596
2023-10-23 14:45:55,231:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007516 seconds.
2023-10-23 14:45:55,231:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:55,231:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:45:55,231:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:45:55,231:INFO:[LightGBM] [Info] Start training from score 633.181363
2023-10-23 14:45:55,595:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009193 seconds.
2023-10-23 14:45:55,595:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:55,596:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:45:55,597:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:45:55,598:INFO:[LightGBM] [Info] Start training from score 611.992287
2023-10-23 14:45:55,950:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007659 seconds.
2023-10-23 14:45:55,951:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:55,951:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:45:55,951:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:45:55,951:INFO:[LightGBM] [Info] Start training from score 638.181417
2023-10-23 14:45:56,282:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007908 seconds.
2023-10-23 14:45:56,283:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:56,283:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:45:56,284:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:45:56,285:INFO:[LightGBM] [Info] Start training from score 639.502137
2023-10-23 14:45:56,559:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:45:56,559:INFO:create_model() successfully completed......................................
2023-10-23 14:45:56,679:INFO:Creating Dashboard logs
2023-10-23 14:45:56,679:INFO:Model: Bagging Regressor
2023-10-23 14:45:56,749:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-23 14:45:57,134:INFO:_master_model_container: 4
2023-10-23 14:45:57,134:INFO:_display_container: 4
2023-10-23 14:45:57,149:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:45:57,149:INFO:finalize_model() successfully completed......................................
2023-10-23 14:45:57,266:INFO:Initializing save_model()
2023-10-23 14:45:57,266:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), model_name=final_model_for_location_A, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 14:45:57,266:INFO:Adding model into prep_pipe
2023-10-23 14:45:57,266:WARNING:Only Model saved as it was a pipeline.
2023-10-23 14:45:57,330:INFO:final_model_for_location_A.pkl saved in current working directory
2023-10-23 14:45:57,346:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:45:57,346:INFO:save_model() successfully completed......................................
2023-10-23 14:45:57,492:INFO:PyCaret RegressionExperiment
2023-10-23 14:45:57,492:INFO:Logging name: exp_B
2023-10-23 14:45:57,492:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 14:45:57,492:INFO:version 3.1.0
2023-10-23 14:45:57,492:INFO:Initializing setup()
2023-10-23 14:45:57,492:INFO:self.USI: b9ca
2023-10-23 14:45:57,492:INFO:self._variable_keys: {'gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', '_ml_usecase', 'gpu_param', 'exp_name_log', 'html_param', 'fold_generator', 'y', 'seed', 'y_train', 'transform_target_param', 'n_jobs_param', 'target_param', 'idx', '_available_plots', 'log_plots_param', 'memory', 'data', 'USI', 'X', 'logging_param', 'pipeline', 'exp_id', 'X_train', 'X_test', 'fold_groups_param'}
2023-10-23 14:45:57,492:INFO:Checking environment
2023-10-23 14:45:57,492:INFO:python_version: 3.8.18
2023-10-23 14:45:57,492:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 14:45:57,492:INFO:machine: AMD64
2023-10-23 14:45:57,492:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 14:45:57,492:INFO:Memory: svmem(total=16505954304, available=2717450240, percent=83.5, used=13788504064, free=2717450240)
2023-10-23 14:45:57,492:INFO:Physical Core: 8
2023-10-23 14:45:57,492:INFO:Logical Core: 16
2023-10-23 14:45:57,492:INFO:Checking libraries
2023-10-23 14:45:57,492:INFO:System:
2023-10-23 14:45:57,492:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 14:45:57,492:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 14:45:57,492:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 14:45:57,492:INFO:PyCaret required dependencies:
2023-10-23 14:45:57,492:INFO:                 pip: 23.3
2023-10-23 14:45:57,492:INFO:          setuptools: 68.0.0
2023-10-23 14:45:57,492:INFO:             pycaret: 3.1.0
2023-10-23 14:45:57,492:INFO:             IPython: 8.12.0
2023-10-23 14:45:57,492:INFO:          ipywidgets: 8.1.1
2023-10-23 14:45:57,492:INFO:                tqdm: 4.66.1
2023-10-23 14:45:57,492:INFO:               numpy: 1.23.5
2023-10-23 14:45:57,492:INFO:              pandas: 1.5.3
2023-10-23 14:45:57,492:INFO:              jinja2: 3.1.2
2023-10-23 14:45:57,492:INFO:               scipy: 1.10.1
2023-10-23 14:45:57,492:INFO:              joblib: 1.3.2
2023-10-23 14:45:57,492:INFO:             sklearn: 1.2.2
2023-10-23 14:45:57,492:INFO:                pyod: 1.1.0
2023-10-23 14:45:57,492:INFO:            imblearn: 0.11.0
2023-10-23 14:45:57,492:INFO:   category_encoders: 2.6.2
2023-10-23 14:45:57,492:INFO:            lightgbm: 4.1.0
2023-10-23 14:45:57,492:INFO:               numba: 0.58.1
2023-10-23 14:45:57,492:INFO:            requests: 2.31.0
2023-10-23 14:45:57,492:INFO:          matplotlib: 3.7.3
2023-10-23 14:45:57,492:INFO:          scikitplot: 0.3.7
2023-10-23 14:45:57,492:INFO:         yellowbrick: 1.5
2023-10-23 14:45:57,492:INFO:              plotly: 5.17.0
2023-10-23 14:45:57,492:INFO:    plotly-resampler: Not installed
2023-10-23 14:45:57,492:INFO:             kaleido: 0.2.1
2023-10-23 14:45:57,492:INFO:           schemdraw: 0.15
2023-10-23 14:45:57,492:INFO:         statsmodels: 0.14.0
2023-10-23 14:45:57,492:INFO:              sktime: 0.21.1
2023-10-23 14:45:57,492:INFO:               tbats: 1.1.3
2023-10-23 14:45:57,492:INFO:            pmdarima: 2.0.3
2023-10-23 14:45:57,492:INFO:              psutil: 5.9.0
2023-10-23 14:45:57,492:INFO:          markupsafe: 2.1.3
2023-10-23 14:45:57,492:INFO:             pickle5: Not installed
2023-10-23 14:45:57,492:INFO:         cloudpickle: 2.2.1
2023-10-23 14:45:57,492:INFO:         deprecation: 2.1.0
2023-10-23 14:45:57,492:INFO:              xxhash: 3.4.1
2023-10-23 14:45:57,492:INFO:           wurlitzer: Not installed
2023-10-23 14:45:57,492:INFO:PyCaret optional dependencies:
2023-10-23 14:45:57,492:INFO:                shap: Not installed
2023-10-23 14:45:57,492:INFO:           interpret: Not installed
2023-10-23 14:45:57,492:INFO:                umap: Not installed
2023-10-23 14:45:57,492:INFO:     ydata_profiling: Not installed
2023-10-23 14:45:57,492:INFO:  explainerdashboard: Not installed
2023-10-23 14:45:57,492:INFO:             autoviz: Not installed
2023-10-23 14:45:57,492:INFO:           fairlearn: Not installed
2023-10-23 14:45:57,492:INFO:          deepchecks: Not installed
2023-10-23 14:45:57,492:INFO:             xgboost: Not installed
2023-10-23 14:45:57,492:INFO:            catboost: 1.2.2
2023-10-23 14:45:57,492:INFO:              kmodes: Not installed
2023-10-23 14:45:57,492:INFO:             mlxtend: Not installed
2023-10-23 14:45:57,492:INFO:       statsforecast: Not installed
2023-10-23 14:45:57,492:INFO:        tune_sklearn: Not installed
2023-10-23 14:45:57,492:INFO:                 ray: Not installed
2023-10-23 14:45:57,492:INFO:            hyperopt: Not installed
2023-10-23 14:45:57,492:INFO:              optuna: Not installed
2023-10-23 14:45:57,492:INFO:               skopt: Not installed
2023-10-23 14:45:57,492:INFO:              mlflow: 2.7.1
2023-10-23 14:45:57,492:INFO:              gradio: Not installed
2023-10-23 14:45:57,492:INFO:             fastapi: Not installed
2023-10-23 14:45:57,492:INFO:             uvicorn: Not installed
2023-10-23 14:45:57,492:INFO:              m2cgen: Not installed
2023-10-23 14:45:57,492:INFO:           evidently: Not installed
2023-10-23 14:45:57,492:INFO:               fugue: Not installed
2023-10-23 14:45:57,492:INFO:           streamlit: Not installed
2023-10-23 14:45:57,492:INFO:             prophet: Not installed
2023-10-23 14:45:57,492:INFO:None
2023-10-23 14:45:57,492:INFO:Set up data.
2023-10-23 14:45:57,529:INFO:Set up folding strategy.
2023-10-23 14:45:57,530:INFO:Set up train/test split.
2023-10-23 14:45:57,545:INFO:Set up index.
2023-10-23 14:45:57,545:INFO:Assigning column types.
2023-10-23 14:45:57,561:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 14:45:57,561:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 14:45:57,581:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:45:57,581:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:45:57,662:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:45:57,712:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:45:57,712:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:45:57,712:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:45:57,712:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 14:45:57,712:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:45:57,712:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:45:57,802:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:45:57,846:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:45:57,846:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:45:57,846:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:45:57,846:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 14:45:57,846:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:45:57,863:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:45:57,929:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:45:57,979:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:45:57,993:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:45:57,993:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:45:57,996:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,002:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,080:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,127:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,127:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:45:58,127:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:45:58,127:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 14:45:58,127:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,212:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,265:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,266:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:45:58,266:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:45:58,266:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,342:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,389:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,389:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:45:58,389:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:45:58,389:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 14:45:58,479:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,528:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,528:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:45:58,528:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:45:58,632:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,677:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,677:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:45:58,677:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:45:58,677:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 14:45:58,764:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,816:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:45:58,816:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:45:58,905:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,956:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:45:58,957:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:45:58,957:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 14:45:59,095:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:45:59,095:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:45:59,243:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:45:59,243:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:45:59,245:INFO:Preparing preprocessing pipeline...
2023-10-23 14:45:59,245:INFO:Set up simple imputation.
2023-10-23 14:45:59,248:INFO:Set up column name cleaning.
2023-10-23 14:45:59,324:INFO:Finished creating preprocessing pipeline.
2023-10-23 14:45:59,324:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 14:45:59,324:INFO:Creating final display dataframe.
2023-10-23 14:45:59,565:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (32819, 49)
4        Transformed data shape   (32819, 49)
5   Transformed train set shape   (22973, 49)
6    Transformed test set shape    (9846, 49)
7              Numeric features            48
8      Rows with missing values         19.9%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_B
19                          USI          b9ca
2023-10-23 14:45:59,707:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:45:59,718:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:45:59,854:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:45:59,854:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:45:59,854:INFO:Logging experiment in loggers
2023-10-23 14:45:59,961:INFO:SubProcess save_model() called ==================================
2023-10-23 14:45:59,981:INFO:Initializing save_model()
2023-10-23 14:45:59,981:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmpe7u471_g\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 14:45:59,981:INFO:Adding model into prep_pipe
2023-10-23 14:45:59,982:WARNING:Only Model saved as it was a pipeline.
2023-10-23 14:45:59,986:INFO:C:\Users\thoma\AppData\Local\Temp\tmpe7u471_g\Transformation Pipeline.pkl saved in current working directory
2023-10-23 14:45:59,993:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 14:45:59,993:INFO:save_model() successfully completed......................................
2023-10-23 14:46:00,105:INFO:SubProcess save_model() end ==================================
2023-10-23 14:46:00,160:INFO:setup() successfully completed in 2.38s...............
2023-10-23 14:46:00,160:INFO:Initializing create_model()
2023-10-23 14:46:00,160:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E87DF0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:46:00,160:INFO:Checking exceptions
2023-10-23 14:46:00,160:INFO:Importing libraries
2023-10-23 14:46:00,160:INFO:Copying training dataset
2023-10-23 14:46:00,184:INFO:Defining folds
2023-10-23 14:46:00,184:INFO:Declaring metric variables
2023-10-23 14:46:00,184:INFO:Importing untrained model
2023-10-23 14:46:00,184:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:46:00,184:INFO:Starting cross validation
2023-10-23 14:46:00,191:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:46:03,398:INFO:Calculating mean and std
2023-10-23 14:46:03,398:INFO:Creating metrics dataframe
2023-10-23 14:46:03,398:INFO:Finalizing model
2023-10-23 14:46:03,498:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005603 seconds.
2023-10-23 14:46:03,498:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:46:03,499:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:46:03,499:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:46:03,500:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-23 14:46:03,727:INFO:Creating Dashboard logs
2023-10-23 14:46:03,727:INFO:Model: Light Gradient Boosting Machine
2023-10-23 14:46:03,815:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 14:46:03,992:INFO:Initializing predict_model()
2023-10-23 14:46:03,992:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E87DF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096364A60>)
2023-10-23 14:46:03,992:INFO:Checking exceptions
2023-10-23 14:46:03,992:INFO:Preloading libraries
2023-10-23 14:46:04,463:INFO:Uploading results into container
2023-10-23 14:46:04,463:INFO:Uploading model into container now
2023-10-23 14:46:04,463:INFO:_master_model_container: 1
2023-10-23 14:46:04,463:INFO:_display_container: 2
2023-10-23 14:46:04,463:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:46:04,463:INFO:create_model() successfully completed......................................
2023-10-23 14:46:04,604:INFO:Initializing tune_model()
2023-10-23 14:46:04,604:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E87DF0>)
2023-10-23 14:46:04,604:INFO:Checking exceptions
2023-10-23 14:46:04,611:INFO:Copying training dataset
2023-10-23 14:46:04,620:INFO:Checking base model
2023-10-23 14:46:04,620:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 14:46:04,620:INFO:Declaring metric variables
2023-10-23 14:46:04,620:INFO:Defining Hyperparameters
2023-10-23 14:46:04,727:INFO:Tuning with n_jobs=-1
2023-10-23 14:46:04,727:INFO:Initializing RandomizedSearchCV
2023-10-23 14:46:50,700:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-23 14:46:50,701:INFO:Hyperparameter search completed
2023-10-23 14:46:50,701:INFO:SubProcess create_model() called ==================================
2023-10-23 14:46:50,702:INFO:Initializing create_model()
2023-10-23 14:46:50,703:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E87DF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E0962FA850>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-23 14:46:50,703:INFO:Checking exceptions
2023-10-23 14:46:50,703:INFO:Importing libraries
2023-10-23 14:46:50,703:INFO:Copying training dataset
2023-10-23 14:46:50,737:INFO:Defining folds
2023-10-23 14:46:50,737:INFO:Declaring metric variables
2023-10-23 14:46:50,737:INFO:Importing untrained model
2023-10-23 14:46:50,737:INFO:Declaring custom model
2023-10-23 14:46:50,738:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:46:50,739:INFO:Starting cross validation
2023-10-23 14:46:50,740:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:47:00,304:INFO:Calculating mean and std
2023-10-23 14:47:00,306:INFO:Creating metrics dataframe
2023-10-23 14:47:00,309:INFO:Finalizing model
2023-10-23 14:47:00,360:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-23 14:47:00,360:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-23 14:47:00,361:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-23 14:47:00,394:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-23 14:47:00,394:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-23 14:47:00,394:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-23 14:47:00,395:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001608 seconds.
2023-10-23 14:47:00,395:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-23 14:47:00,395:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-23 14:47:00,395:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:47:00,395:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:47:00,395:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-23 14:47:01,750:INFO:Uploading results into container
2023-10-23 14:47:01,752:INFO:Uploading model into container now
2023-10-23 14:47:01,753:INFO:_master_model_container: 2
2023-10-23 14:47:01,753:INFO:_display_container: 3
2023-10-23 14:47:01,754:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-23 14:47:01,756:INFO:create_model() successfully completed......................................
2023-10-23 14:47:01,891:INFO:SubProcess create_model() end ==================================
2023-10-23 14:47:01,891:INFO:choose_better activated
2023-10-23 14:47:01,891:INFO:SubProcess create_model() called ==================================
2023-10-23 14:47:01,891:INFO:Initializing create_model()
2023-10-23 14:47:01,891:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E87DF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:47:01,891:INFO:Checking exceptions
2023-10-23 14:47:01,891:INFO:Importing libraries
2023-10-23 14:47:01,891:INFO:Copying training dataset
2023-10-23 14:47:01,908:INFO:Defining folds
2023-10-23 14:47:01,908:INFO:Declaring metric variables
2023-10-23 14:47:01,908:INFO:Importing untrained model
2023-10-23 14:47:01,908:INFO:Declaring custom model
2023-10-23 14:47:01,908:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:47:01,908:INFO:Starting cross validation
2023-10-23 14:47:01,908:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:47:04,461:INFO:Calculating mean and std
2023-10-23 14:47:04,461:INFO:Creating metrics dataframe
2023-10-23 14:47:04,461:INFO:Finalizing model
2023-10-23 14:47:04,544:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004684 seconds.
2023-10-23 14:47:04,544:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:04,544:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:47:04,545:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:47:04,545:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-23 14:47:04,822:INFO:Uploading results into container
2023-10-23 14:47:04,822:INFO:Uploading model into container now
2023-10-23 14:47:04,822:INFO:_master_model_container: 3
2023-10-23 14:47:04,822:INFO:_display_container: 4
2023-10-23 14:47:04,822:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:47:04,822:INFO:create_model() successfully completed......................................
2023-10-23 14:47:04,939:INFO:SubProcess create_model() end ==================================
2023-10-23 14:47:04,954:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8523
2023-10-23 14:47:04,955:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8523
2023-10-23 14:47:04,955:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-23 14:47:04,955:INFO:choose_better completed
2023-10-23 14:47:04,955:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-23 14:47:04,955:INFO:Creating Dashboard logs
2023-10-23 14:47:04,955:INFO:Model: Light Gradient Boosting Machine
2023-10-23 14:47:05,022:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 14:47:05,238:INFO:Initializing predict_model()
2023-10-23 14:47:05,238:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E87DF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E0970E9D30>)
2023-10-23 14:47:05,238:INFO:Checking exceptions
2023-10-23 14:47:05,238:INFO:Preloading libraries
2023-10-23 14:47:05,760:INFO:_master_model_container: 3
2023-10-23 14:47:05,760:INFO:_display_container: 3
2023-10-23 14:47:05,761:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:47:05,761:INFO:tune_model() successfully completed......................................
2023-10-23 14:47:05,860:INFO:Initializing ensemble_model()
2023-10-23 14:47:05,860:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E87DF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-23 14:47:05,860:INFO:Checking exceptions
2023-10-23 14:47:05,874:INFO:Importing libraries
2023-10-23 14:47:05,874:INFO:Copying training dataset
2023-10-23 14:47:05,874:INFO:Checking base model
2023-10-23 14:47:05,874:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 14:47:05,874:INFO:Importing untrained ensembler
2023-10-23 14:47:05,874:INFO:Ensemble method set to Bagging
2023-10-23 14:47:05,874:INFO:SubProcess create_model() called ==================================
2023-10-23 14:47:05,874:INFO:Initializing create_model()
2023-10-23 14:47:05,874:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E87DF0>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E096781040>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:47:05,874:INFO:Checking exceptions
2023-10-23 14:47:05,874:INFO:Importing libraries
2023-10-23 14:47:05,874:INFO:Copying training dataset
2023-10-23 14:47:05,905:INFO:Defining folds
2023-10-23 14:47:05,905:INFO:Declaring metric variables
2023-10-23 14:47:05,905:INFO:Importing untrained model
2023-10-23 14:47:05,905:INFO:Declaring custom model
2023-10-23 14:47:05,909:INFO:Bagging Regressor Imported successfully
2023-10-23 14:47:05,909:INFO:Starting cross validation
2023-10-23 14:47:05,910:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:47:29,635:INFO:Calculating mean and std
2023-10-23 14:47:29,637:INFO:Creating metrics dataframe
2023-10-23 14:47:29,639:INFO:Finalizing model
2023-10-23 14:47:29,724:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005547 seconds.
2023-10-23 14:47:29,724:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:29,724:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:47:29,734:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:47:29,735:INFO:[LightGBM] [Info] Start training from score 99.624795
2023-10-23 14:47:30,054:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005853 seconds.
2023-10-23 14:47:30,054:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:30,054:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:47:30,054:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:47:30,054:INFO:[LightGBM] [Info] Start training from score 96.229614
2023-10-23 14:47:30,338:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005411 seconds.
2023-10-23 14:47:30,338:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:30,338:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:47:30,338:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:47:30,338:INFO:[LightGBM] [Info] Start training from score 95.360987
2023-10-23 14:47:30,623:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007590 seconds.
2023-10-23 14:47:30,623:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:30,623:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:47:30,623:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:47:30,623:INFO:[LightGBM] [Info] Start training from score 94.348528
2023-10-23 14:47:30,976:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005415 seconds.
2023-10-23 14:47:30,976:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:30,976:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:47:30,976:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:47:30,976:INFO:[LightGBM] [Info] Start training from score 95.509684
2023-10-23 14:47:31,253:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005506 seconds.
2023-10-23 14:47:31,254:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:31,254:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:47:31,255:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:47:31,256:INFO:[LightGBM] [Info] Start training from score 96.036959
2023-10-23 14:47:31,558:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005650 seconds.
2023-10-23 14:47:31,558:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:31,558:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:47:31,565:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:47:31,566:INFO:[LightGBM] [Info] Start training from score 97.844637
2023-10-23 14:47:31,883:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007215 seconds.
2023-10-23 14:47:31,883:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:31,883:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:47:31,883:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:47:31,883:INFO:[LightGBM] [Info] Start training from score 96.245614
2023-10-23 14:47:32,193:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005736 seconds.
2023-10-23 14:47:32,194:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:32,194:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:47:32,194:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:47:32,195:INFO:[LightGBM] [Info] Start training from score 97.594984
2023-10-23 14:47:32,515:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005202 seconds.
2023-10-23 14:47:32,515:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:32,516:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:47:32,517:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:47:32,517:INFO:[LightGBM] [Info] Start training from score 96.370407
2023-10-23 14:47:32,767:INFO:Uploading results into container
2023-10-23 14:47:32,767:INFO:Uploading model into container now
2023-10-23 14:47:32,767:INFO:_master_model_container: 4
2023-10-23 14:47:32,767:INFO:_display_container: 4
2023-10-23 14:47:32,773:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:47:32,773:INFO:create_model() successfully completed......................................
2023-10-23 14:47:32,905:INFO:SubProcess create_model() end ==================================
2023-10-23 14:47:32,906:INFO:Creating Dashboard logs
2023-10-23 14:47:32,906:INFO:Model: Bagging Regressor
2023-10-23 14:47:32,968:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-23 14:47:33,173:INFO:Initializing predict_model()
2023-10-23 14:47:33,173:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E87DF0>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096B345E0>)
2023-10-23 14:47:33,173:INFO:Checking exceptions
2023-10-23 14:47:33,173:INFO:Preloading libraries
2023-10-23 14:47:33,827:INFO:_master_model_container: 4
2023-10-23 14:47:33,827:INFO:_display_container: 4
2023-10-23 14:47:33,830:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:47:33,830:INFO:ensemble_model() successfully completed......................................
2023-10-23 14:47:33,965:INFO:Initializing finalize_model()
2023-10-23 14:47:33,965:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E87DF0>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-23 14:47:33,965:INFO:Finalizing BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:47:33,982:INFO:Initializing create_model()
2023-10-23 14:47:33,982:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E87DF0>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-23 14:47:33,982:INFO:Checking exceptions
2023-10-23 14:47:33,982:INFO:Importing libraries
2023-10-23 14:47:33,982:INFO:Copying training dataset
2023-10-23 14:47:33,982:INFO:Defining folds
2023-10-23 14:47:33,982:INFO:Declaring metric variables
2023-10-23 14:47:33,982:INFO:Importing untrained model
2023-10-23 14:47:33,982:INFO:Declaring custom model
2023-10-23 14:47:33,982:INFO:Bagging Regressor Imported successfully
2023-10-23 14:47:33,982:INFO:Cross validation set to False
2023-10-23 14:47:33,982:INFO:Fitting Model
2023-10-23 14:47:34,142:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009669 seconds.
2023-10-23 14:47:34,142:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:34,143:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:47:34,143:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:47:34,145:INFO:[LightGBM] [Info] Start training from score 96.465021
2023-10-23 14:47:34,513:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006795 seconds.
2023-10-23 14:47:34,513:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:34,513:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:47:34,514:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:47:34,515:INFO:[LightGBM] [Info] Start training from score 97.264361
2023-10-23 14:47:34,883:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010233 seconds.
2023-10-23 14:47:34,883:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:34,883:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:47:34,883:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:47:34,883:INFO:[LightGBM] [Info] Start training from score 95.842370
2023-10-23 14:47:35,429:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009869 seconds.
2023-10-23 14:47:35,429:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:35,430:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:47:35,431:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:47:35,431:INFO:[LightGBM] [Info] Start training from score 95.431515
2023-10-23 14:47:35,829:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009113 seconds.
2023-10-23 14:47:35,829:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:35,829:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:47:35,829:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:47:35,829:INFO:[LightGBM] [Info] Start training from score 97.222213
2023-10-23 14:47:36,301:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013524 seconds.
2023-10-23 14:47:36,301:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:36,302:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:47:36,303:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:47:36,303:INFO:[LightGBM] [Info] Start training from score 97.332701
2023-10-23 14:47:36,665:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009251 seconds.
2023-10-23 14:47:36,666:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:36,666:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:47:36,667:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:47:36,668:INFO:[LightGBM] [Info] Start training from score 96.452612
2023-10-23 14:47:37,030:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008704 seconds.
2023-10-23 14:47:37,030:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:37,030:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:47:37,030:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:47:37,030:INFO:[LightGBM] [Info] Start training from score 97.322509
2023-10-23 14:47:37,373:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009085 seconds.
2023-10-23 14:47:37,373:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:37,374:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:47:37,374:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:47:37,376:INFO:[LightGBM] [Info] Start training from score 96.419103
2023-10-23 14:47:37,708:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007364 seconds.
2023-10-23 14:47:37,708:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:37,709:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:47:37,709:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:47:37,710:INFO:[LightGBM] [Info] Start training from score 95.095963
2023-10-23 14:47:37,973:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:47:37,973:INFO:create_model() successfully completed......................................
2023-10-23 14:47:38,102:INFO:Creating Dashboard logs
2023-10-23 14:47:38,103:INFO:Model: Bagging Regressor
2023-10-23 14:47:38,171:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-23 14:47:38,565:INFO:_master_model_container: 4
2023-10-23 14:47:38,565:INFO:_display_container: 4
2023-10-23 14:47:38,575:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:47:38,575:INFO:finalize_model() successfully completed......................................
2023-10-23 14:47:38,691:INFO:Initializing save_model()
2023-10-23 14:47:38,691:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), model_name=final_model_for_location_B, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 14:47:38,691:INFO:Adding model into prep_pipe
2023-10-23 14:47:38,691:WARNING:Only Model saved as it was a pipeline.
2023-10-23 14:47:38,751:INFO:final_model_for_location_B.pkl saved in current working directory
2023-10-23 14:47:38,771:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:47:38,771:INFO:save_model() successfully completed......................................
2023-10-23 14:47:38,912:INFO:PyCaret RegressionExperiment
2023-10-23 14:47:38,912:INFO:Logging name: exp_C
2023-10-23 14:47:38,912:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 14:47:38,912:INFO:version 3.1.0
2023-10-23 14:47:38,912:INFO:Initializing setup()
2023-10-23 14:47:38,912:INFO:self.USI: 349b
2023-10-23 14:47:38,912:INFO:self._variable_keys: {'gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', '_ml_usecase', 'gpu_param', 'exp_name_log', 'html_param', 'fold_generator', 'y', 'seed', 'y_train', 'transform_target_param', 'n_jobs_param', 'target_param', 'idx', '_available_plots', 'log_plots_param', 'memory', 'data', 'USI', 'X', 'logging_param', 'pipeline', 'exp_id', 'X_train', 'X_test', 'fold_groups_param'}
2023-10-23 14:47:38,912:INFO:Checking environment
2023-10-23 14:47:38,913:INFO:python_version: 3.8.18
2023-10-23 14:47:38,913:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 14:47:38,913:INFO:machine: AMD64
2023-10-23 14:47:38,913:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 14:47:38,913:INFO:Memory: svmem(total=16505954304, available=2728316928, percent=83.5, used=13777637376, free=2728316928)
2023-10-23 14:47:38,913:INFO:Physical Core: 8
2023-10-23 14:47:38,913:INFO:Logical Core: 16
2023-10-23 14:47:38,913:INFO:Checking libraries
2023-10-23 14:47:38,914:INFO:System:
2023-10-23 14:47:38,914:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 14:47:38,914:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 14:47:38,914:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 14:47:38,914:INFO:PyCaret required dependencies:
2023-10-23 14:47:38,914:INFO:                 pip: 23.3
2023-10-23 14:47:38,914:INFO:          setuptools: 68.0.0
2023-10-23 14:47:38,914:INFO:             pycaret: 3.1.0
2023-10-23 14:47:38,914:INFO:             IPython: 8.12.0
2023-10-23 14:47:38,914:INFO:          ipywidgets: 8.1.1
2023-10-23 14:47:38,914:INFO:                tqdm: 4.66.1
2023-10-23 14:47:38,914:INFO:               numpy: 1.23.5
2023-10-23 14:47:38,914:INFO:              pandas: 1.5.3
2023-10-23 14:47:38,914:INFO:              jinja2: 3.1.2
2023-10-23 14:47:38,914:INFO:               scipy: 1.10.1
2023-10-23 14:47:38,915:INFO:              joblib: 1.3.2
2023-10-23 14:47:38,915:INFO:             sklearn: 1.2.2
2023-10-23 14:47:38,915:INFO:                pyod: 1.1.0
2023-10-23 14:47:38,915:INFO:            imblearn: 0.11.0
2023-10-23 14:47:38,915:INFO:   category_encoders: 2.6.2
2023-10-23 14:47:38,915:INFO:            lightgbm: 4.1.0
2023-10-23 14:47:38,915:INFO:               numba: 0.58.1
2023-10-23 14:47:38,915:INFO:            requests: 2.31.0
2023-10-23 14:47:38,915:INFO:          matplotlib: 3.7.3
2023-10-23 14:47:38,915:INFO:          scikitplot: 0.3.7
2023-10-23 14:47:38,915:INFO:         yellowbrick: 1.5
2023-10-23 14:47:38,915:INFO:              plotly: 5.17.0
2023-10-23 14:47:38,916:INFO:    plotly-resampler: Not installed
2023-10-23 14:47:38,916:INFO:             kaleido: 0.2.1
2023-10-23 14:47:38,916:INFO:           schemdraw: 0.15
2023-10-23 14:47:38,916:INFO:         statsmodels: 0.14.0
2023-10-23 14:47:38,916:INFO:              sktime: 0.21.1
2023-10-23 14:47:38,916:INFO:               tbats: 1.1.3
2023-10-23 14:47:38,916:INFO:            pmdarima: 2.0.3
2023-10-23 14:47:38,916:INFO:              psutil: 5.9.0
2023-10-23 14:47:38,916:INFO:          markupsafe: 2.1.3
2023-10-23 14:47:38,916:INFO:             pickle5: Not installed
2023-10-23 14:47:38,916:INFO:         cloudpickle: 2.2.1
2023-10-23 14:47:38,916:INFO:         deprecation: 2.1.0
2023-10-23 14:47:38,916:INFO:              xxhash: 3.4.1
2023-10-23 14:47:38,916:INFO:           wurlitzer: Not installed
2023-10-23 14:47:38,916:INFO:PyCaret optional dependencies:
2023-10-23 14:47:38,917:INFO:                shap: Not installed
2023-10-23 14:47:38,917:INFO:           interpret: Not installed
2023-10-23 14:47:38,917:INFO:                umap: Not installed
2023-10-23 14:47:38,917:INFO:     ydata_profiling: Not installed
2023-10-23 14:47:38,917:INFO:  explainerdashboard: Not installed
2023-10-23 14:47:38,917:INFO:             autoviz: Not installed
2023-10-23 14:47:38,917:INFO:           fairlearn: Not installed
2023-10-23 14:47:38,917:INFO:          deepchecks: Not installed
2023-10-23 14:47:38,917:INFO:             xgboost: Not installed
2023-10-23 14:47:38,917:INFO:            catboost: 1.2.2
2023-10-23 14:47:38,917:INFO:              kmodes: Not installed
2023-10-23 14:47:38,917:INFO:             mlxtend: Not installed
2023-10-23 14:47:38,917:INFO:       statsforecast: Not installed
2023-10-23 14:47:38,917:INFO:        tune_sklearn: Not installed
2023-10-23 14:47:38,917:INFO:                 ray: Not installed
2023-10-23 14:47:38,917:INFO:            hyperopt: Not installed
2023-10-23 14:47:38,917:INFO:              optuna: Not installed
2023-10-23 14:47:38,917:INFO:               skopt: Not installed
2023-10-23 14:47:38,917:INFO:              mlflow: 2.7.1
2023-10-23 14:47:38,918:INFO:              gradio: Not installed
2023-10-23 14:47:38,918:INFO:             fastapi: Not installed
2023-10-23 14:47:38,918:INFO:             uvicorn: Not installed
2023-10-23 14:47:38,918:INFO:              m2cgen: Not installed
2023-10-23 14:47:38,918:INFO:           evidently: Not installed
2023-10-23 14:47:38,918:INFO:               fugue: Not installed
2023-10-23 14:47:38,918:INFO:           streamlit: Not installed
2023-10-23 14:47:38,918:INFO:             prophet: Not installed
2023-10-23 14:47:38,918:INFO:None
2023-10-23 14:47:38,918:INFO:Set up data.
2023-10-23 14:47:38,948:INFO:Set up folding strategy.
2023-10-23 14:47:38,948:INFO:Set up train/test split.
2023-10-23 14:47:38,969:INFO:Set up index.
2023-10-23 14:47:38,970:INFO:Assigning column types.
2023-10-23 14:47:38,989:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 14:47:38,990:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 14:47:38,995:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,000:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,078:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,140:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,140:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:47:39,141:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:47:39,141:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,147:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,153:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,233:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,282:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,283:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:47:39,283:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:47:39,283:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 14:47:39,289:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,294:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,369:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,417:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,418:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:47:39,418:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:47:39,425:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,430:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,503:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,552:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,553:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:47:39,553:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:47:39,554:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 14:47:39,565:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,639:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,688:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,689:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:47:39,689:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:47:39,700:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,773:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,821:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,822:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:47:39,822:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:47:39,823:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 14:47:39,908:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,957:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,958:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:47:39,958:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:47:40,051:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:47:40,089:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:47:40,089:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:47:40,089:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:47:40,089:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 14:47:40,178:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:47:40,232:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:47:40,232:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:47:40,310:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:47:40,362:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:47:40,362:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:47:40,362:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 14:47:40,501:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:47:40,501:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:47:40,655:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:47:40,656:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:47:40,657:INFO:Preparing preprocessing pipeline...
2023-10-23 14:47:40,657:INFO:Set up simple imputation.
2023-10-23 14:47:40,660:INFO:Set up column name cleaning.
2023-10-23 14:47:40,740:INFO:Finished creating preprocessing pipeline.
2023-10-23 14:47:40,740:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 14:47:40,740:INFO:Creating final display dataframe.
2023-10-23 14:47:40,979:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (26071, 49)
4        Transformed data shape   (26071, 49)
5   Transformed train set shape   (18249, 49)
6    Transformed test set shape    (7822, 49)
7              Numeric features            48
8      Rows with missing values         25.0%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_C
19                          USI          349b
2023-10-23 14:47:41,125:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:47:41,126:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:47:41,278:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:47:41,278:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:47:41,280:INFO:Logging experiment in loggers
2023-10-23 14:47:41,414:INFO:SubProcess save_model() called ==================================
2023-10-23 14:47:41,430:INFO:Initializing save_model()
2023-10-23 14:47:41,430:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmpy9t5z0ne\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 14:47:41,430:INFO:Adding model into prep_pipe
2023-10-23 14:47:41,430:WARNING:Only Model saved as it was a pipeline.
2023-10-23 14:47:41,434:INFO:C:\Users\thoma\AppData\Local\Temp\tmpy9t5z0ne\Transformation Pipeline.pkl saved in current working directory
2023-10-23 14:47:41,442:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 14:47:41,442:INFO:save_model() successfully completed......................................
2023-10-23 14:47:41,566:INFO:SubProcess save_model() end ==================================
2023-10-23 14:47:41,628:INFO:setup() successfully completed in 2.37s...............
2023-10-23 14:47:41,629:INFO:Initializing create_model()
2023-10-23 14:47:41,629:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E095E7AF70>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:47:41,629:INFO:Checking exceptions
2023-10-23 14:47:41,633:INFO:Importing libraries
2023-10-23 14:47:41,633:INFO:Copying training dataset
2023-10-23 14:47:41,656:INFO:Defining folds
2023-10-23 14:47:41,656:INFO:Declaring metric variables
2023-10-23 14:47:41,656:INFO:Importing untrained model
2023-10-23 14:47:41,657:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:47:41,657:INFO:Starting cross validation
2023-10-23 14:47:41,659:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:47:44,812:INFO:Calculating mean and std
2023-10-23 14:47:44,814:INFO:Creating metrics dataframe
2023-10-23 14:47:44,819:INFO:Finalizing model
2023-10-23 14:47:44,903:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003910 seconds.
2023-10-23 14:47:44,904:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:44,904:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:47:44,905:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:47:44,905:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-23 14:47:45,157:INFO:Creating Dashboard logs
2023-10-23 14:47:45,157:INFO:Model: Light Gradient Boosting Machine
2023-10-23 14:47:45,256:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 14:47:45,455:INFO:Initializing predict_model()
2023-10-23 14:47:45,455:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E095E7AF70>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096789310>)
2023-10-23 14:47:45,455:INFO:Checking exceptions
2023-10-23 14:47:45,455:INFO:Preloading libraries
2023-10-23 14:47:45,958:INFO:Uploading results into container
2023-10-23 14:47:45,958:INFO:Uploading model into container now
2023-10-23 14:47:45,958:INFO:_master_model_container: 1
2023-10-23 14:47:45,958:INFO:_display_container: 2
2023-10-23 14:47:45,958:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:47:45,958:INFO:create_model() successfully completed......................................
2023-10-23 14:47:46,069:INFO:Initializing tune_model()
2023-10-23 14:47:46,069:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E095E7AF70>)
2023-10-23 14:47:46,069:INFO:Checking exceptions
2023-10-23 14:47:46,082:INFO:Copying training dataset
2023-10-23 14:47:46,085:INFO:Checking base model
2023-10-23 14:47:46,085:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 14:47:46,085:INFO:Declaring metric variables
2023-10-23 14:47:46,085:INFO:Defining Hyperparameters
2023-10-23 14:47:46,232:INFO:Tuning with n_jobs=-1
2023-10-23 14:47:46,232:INFO:Initializing RandomizedSearchCV
2023-10-23 14:48:24,018:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-23 14:48:24,019:INFO:Hyperparameter search completed
2023-10-23 14:48:24,019:INFO:SubProcess create_model() called ==================================
2023-10-23 14:48:24,020:INFO:Initializing create_model()
2023-10-23 14:48:24,021:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E095E7AF70>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E096CD9760>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-23 14:48:24,021:INFO:Checking exceptions
2023-10-23 14:48:24,021:INFO:Importing libraries
2023-10-23 14:48:24,021:INFO:Copying training dataset
2023-10-23 14:48:24,050:INFO:Defining folds
2023-10-23 14:48:24,050:INFO:Declaring metric variables
2023-10-23 14:48:24,050:INFO:Importing untrained model
2023-10-23 14:48:24,051:INFO:Declaring custom model
2023-10-23 14:48:24,052:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:48:24,052:INFO:Starting cross validation
2023-10-23 14:48:24,054:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:48:34,839:INFO:Calculating mean and std
2023-10-23 14:48:34,840:INFO:Creating metrics dataframe
2023-10-23 14:48:34,844:INFO:Finalizing model
2023-10-23 14:48:34,890:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-23 14:48:34,890:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-23 14:48:34,890:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-23 14:48:34,916:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-23 14:48:34,916:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-23 14:48:34,916:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-23 14:48:34,922:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004448 seconds.
2023-10-23 14:48:34,922:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:48:34,923:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:48:34,923:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:48:34,925:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-23 14:48:34,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:48:34,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:48:34,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:48:34,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:48:34,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:48:34,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:48:34,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:48:34,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:48:36,170:INFO:Uploading results into container
2023-10-23 14:48:36,171:INFO:Uploading model into container now
2023-10-23 14:48:36,172:INFO:_master_model_container: 2
2023-10-23 14:48:36,172:INFO:_display_container: 3
2023-10-23 14:48:36,173:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-23 14:48:36,174:INFO:create_model() successfully completed......................................
2023-10-23 14:48:36,327:INFO:SubProcess create_model() end ==================================
2023-10-23 14:48:36,327:INFO:choose_better activated
2023-10-23 14:48:36,327:INFO:SubProcess create_model() called ==================================
2023-10-23 14:48:36,328:INFO:Initializing create_model()
2023-10-23 14:48:36,328:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E095E7AF70>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:48:36,329:INFO:Checking exceptions
2023-10-23 14:48:36,330:INFO:Importing libraries
2023-10-23 14:48:36,330:INFO:Copying training dataset
2023-10-23 14:48:36,354:INFO:Defining folds
2023-10-23 14:48:36,354:INFO:Declaring metric variables
2023-10-23 14:48:36,354:INFO:Importing untrained model
2023-10-23 14:48:36,354:INFO:Declaring custom model
2023-10-23 14:48:36,355:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:48:36,356:INFO:Starting cross validation
2023-10-23 14:48:36,357:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:48:39,155:INFO:Calculating mean and std
2023-10-23 14:48:39,155:INFO:Creating metrics dataframe
2023-10-23 14:48:39,155:INFO:Finalizing model
2023-10-23 14:48:39,233:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005192 seconds.
2023-10-23 14:48:39,233:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:48:39,233:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:48:39,233:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:48:39,233:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-23 14:48:39,479:INFO:Uploading results into container
2023-10-23 14:48:39,480:INFO:Uploading model into container now
2023-10-23 14:48:39,481:INFO:_master_model_container: 3
2023-10-23 14:48:39,481:INFO:_display_container: 4
2023-10-23 14:48:39,481:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:48:39,481:INFO:create_model() successfully completed......................................
2023-10-23 14:48:39,626:INFO:SubProcess create_model() end ==================================
2023-10-23 14:48:39,628:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.905
2023-10-23 14:48:39,629:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8993
2023-10-23 14:48:39,629:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-23 14:48:39,629:INFO:choose_better completed
2023-10-23 14:48:39,629:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-23 14:48:39,630:INFO:Creating Dashboard logs
2023-10-23 14:48:39,630:INFO:Model: Light Gradient Boosting Machine
2023-10-23 14:48:39,700:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 14:48:39,888:INFO:Initializing predict_model()
2023-10-23 14:48:39,889:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E095E7AF70>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096CAF550>)
2023-10-23 14:48:39,889:INFO:Checking exceptions
2023-10-23 14:48:39,889:INFO:Preloading libraries
2023-10-23 14:48:40,388:INFO:_master_model_container: 3
2023-10-23 14:48:40,389:INFO:_display_container: 3
2023-10-23 14:48:40,389:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:48:40,389:INFO:tune_model() successfully completed......................................
2023-10-23 14:48:40,504:INFO:Initializing ensemble_model()
2023-10-23 14:48:40,504:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E095E7AF70>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-23 14:48:40,504:INFO:Checking exceptions
2023-10-23 14:48:40,515:INFO:Importing libraries
2023-10-23 14:48:40,516:INFO:Copying training dataset
2023-10-23 14:48:40,516:INFO:Checking base model
2023-10-23 14:48:40,516:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 14:48:40,517:INFO:Importing untrained ensembler
2023-10-23 14:48:40,517:INFO:Ensemble method set to Bagging
2023-10-23 14:48:40,517:INFO:SubProcess create_model() called ==================================
2023-10-23 14:48:40,518:INFO:Initializing create_model()
2023-10-23 14:48:40,518:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E095E7AF70>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E096EFA970>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:48:40,518:INFO:Checking exceptions
2023-10-23 14:48:40,518:INFO:Importing libraries
2023-10-23 14:48:40,518:INFO:Copying training dataset
2023-10-23 14:48:40,540:INFO:Defining folds
2023-10-23 14:48:40,540:INFO:Declaring metric variables
2023-10-23 14:48:40,540:INFO:Importing untrained model
2023-10-23 14:48:40,540:INFO:Declaring custom model
2023-10-23 14:48:40,542:INFO:Bagging Regressor Imported successfully
2023-10-23 14:48:40,542:INFO:Starting cross validation
2023-10-23 14:48:40,544:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:49:08,614:INFO:Calculating mean and std
2023-10-23 14:49:08,616:INFO:Creating metrics dataframe
2023-10-23 14:49:08,620:INFO:Finalizing model
2023-10-23 14:49:08,715:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004583 seconds.
2023-10-23 14:49:08,716:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:08,716:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:49:08,717:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:49:08,717:INFO:[LightGBM] [Info] Start training from score 77.044367
2023-10-23 14:49:09,016:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005129 seconds.
2023-10-23 14:49:09,016:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:09,017:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:49:09,017:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:49:09,019:INFO:[LightGBM] [Info] Start training from score 76.520588
2023-10-23 14:49:09,297:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005449 seconds.
2023-10-23 14:49:09,297:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:09,298:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:49:09,298:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:49:09,299:INFO:[LightGBM] [Info] Start training from score 76.462170
2023-10-23 14:49:09,559:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004986 seconds.
2023-10-23 14:49:09,559:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:09,560:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:49:09,560:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:49:09,561:INFO:[LightGBM] [Info] Start training from score 77.386428
2023-10-23 14:49:09,830:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004397 seconds.
2023-10-23 14:49:09,831:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:09,831:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:49:09,832:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:49:09,832:INFO:[LightGBM] [Info] Start training from score 73.916304
2023-10-23 14:49:10,118:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004851 seconds.
2023-10-23 14:49:10,118:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:10,119:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:49:10,119:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:49:10,119:INFO:[LightGBM] [Info] Start training from score 75.879633
2023-10-23 14:49:10,391:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004740 seconds.
2023-10-23 14:49:10,391:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:10,391:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:49:10,391:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:49:10,392:INFO:[LightGBM] [Info] Start training from score 75.615395
2023-10-23 14:49:10,669:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005798 seconds.
2023-10-23 14:49:10,669:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:10,670:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:49:10,670:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:49:10,671:INFO:[LightGBM] [Info] Start training from score 79.544595
2023-10-23 14:49:10,955:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004772 seconds.
2023-10-23 14:49:10,955:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:10,955:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:49:10,956:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:49:10,956:INFO:[LightGBM] [Info] Start training from score 76.012052
2023-10-23 14:49:11,212:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005272 seconds.
2023-10-23 14:49:11,212:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:11,212:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:49:11,213:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:49:11,213:INFO:[LightGBM] [Info] Start training from score 78.124037
2023-10-23 14:49:11,439:INFO:Uploading results into container
2023-10-23 14:49:11,440:INFO:Uploading model into container now
2023-10-23 14:49:11,441:INFO:_master_model_container: 4
2023-10-23 14:49:11,442:INFO:_display_container: 4
2023-10-23 14:49:11,443:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:49:11,444:INFO:create_model() successfully completed......................................
2023-10-23 14:49:11,580:INFO:SubProcess create_model() end ==================================
2023-10-23 14:49:11,581:INFO:Creating Dashboard logs
2023-10-23 14:49:11,581:INFO:Model: Bagging Regressor
2023-10-23 14:49:11,655:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-23 14:49:11,884:INFO:Initializing predict_model()
2023-10-23 14:49:11,884:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E095E7AF70>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096CAF700>)
2023-10-23 14:49:11,884:INFO:Checking exceptions
2023-10-23 14:49:11,884:INFO:Preloading libraries
2023-10-23 14:49:12,495:INFO:_master_model_container: 4
2023-10-23 14:49:12,496:INFO:_display_container: 4
2023-10-23 14:49:12,497:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:49:12,497:INFO:ensemble_model() successfully completed......................................
2023-10-23 14:49:12,611:INFO:Initializing finalize_model()
2023-10-23 14:49:12,611:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E095E7AF70>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-23 14:49:12,611:INFO:Finalizing BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:49:12,624:INFO:Initializing create_model()
2023-10-23 14:49:12,624:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E095E7AF70>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-23 14:49:12,624:INFO:Checking exceptions
2023-10-23 14:49:12,625:INFO:Importing libraries
2023-10-23 14:49:12,625:INFO:Copying training dataset
2023-10-23 14:49:12,626:INFO:Defining folds
2023-10-23 14:49:12,626:INFO:Declaring metric variables
2023-10-23 14:49:12,626:INFO:Importing untrained model
2023-10-23 14:49:12,626:INFO:Declaring custom model
2023-10-23 14:49:12,627:INFO:Bagging Regressor Imported successfully
2023-10-23 14:49:12,627:INFO:Cross validation set to False
2023-10-23 14:49:12,627:INFO:Fitting Model
2023-10-23 14:49:12,725:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006446 seconds.
2023-10-23 14:49:12,725:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:12,725:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:49:12,725:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:49:12,729:INFO:[LightGBM] [Info] Start training from score 77.360615
2023-10-23 14:49:13,083:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006861 seconds.
2023-10-23 14:49:13,083:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:13,098:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:49:13,098:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:49:13,100:INFO:[LightGBM] [Info] Start training from score 78.162759
2023-10-23 14:49:13,369:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005830 seconds.
2023-10-23 14:49:13,369:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:13,370:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:49:13,370:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:49:13,371:INFO:[LightGBM] [Info] Start training from score 77.185434
2023-10-23 14:49:13,737:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006602 seconds.
2023-10-23 14:49:13,737:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:13,748:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:49:13,749:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:49:13,750:INFO:[LightGBM] [Info] Start training from score 78.293126
2023-10-23 14:49:14,101:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005662 seconds.
2023-10-23 14:49:14,101:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:14,101:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:49:14,101:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:49:14,101:INFO:[LightGBM] [Info] Start training from score 75.493649
2023-10-23 14:49:14,399:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006417 seconds.
2023-10-23 14:49:14,399:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:14,399:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:49:14,399:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:49:14,399:INFO:[LightGBM] [Info] Start training from score 77.467219
2023-10-23 14:49:14,765:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006263 seconds.
2023-10-23 14:49:14,765:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:14,765:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:49:14,765:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:49:14,765:INFO:[LightGBM] [Info] Start training from score 77.083598
2023-10-23 14:49:15,103:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005896 seconds.
2023-10-23 14:49:15,103:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:15,104:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:49:15,104:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:49:15,104:INFO:[LightGBM] [Info] Start training from score 79.854607
2023-10-23 14:49:15,383:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005470 seconds.
2023-10-23 14:49:15,383:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:15,383:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:49:15,383:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:49:15,383:INFO:[LightGBM] [Info] Start training from score 76.153078
2023-10-23 14:49:15,653:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005816 seconds.
2023-10-23 14:49:15,653:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:15,653:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:49:15,653:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:49:15,653:INFO:[LightGBM] [Info] Start training from score 78.843978
2023-10-23 14:49:15,884:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:49:15,884:INFO:create_model() successfully completed......................................
2023-10-23 14:49:16,015:INFO:Creating Dashboard logs
2023-10-23 14:49:16,015:INFO:Model: Bagging Regressor
2023-10-23 14:49:16,084:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-23 14:49:16,451:INFO:_master_model_container: 4
2023-10-23 14:49:16,451:INFO:_display_container: 4
2023-10-23 14:49:16,451:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:49:16,451:INFO:finalize_model() successfully completed......................................
2023-10-23 14:49:16,577:INFO:Initializing save_model()
2023-10-23 14:49:16,577:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), model_name=final_model_for_location_C, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 14:49:16,577:INFO:Adding model into prep_pipe
2023-10-23 14:49:16,577:WARNING:Only Model saved as it was a pipeline.
2023-10-23 14:49:16,632:INFO:final_model_for_location_C.pkl saved in current working directory
2023-10-23 14:49:16,648:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:49:16,648:INFO:save_model() successfully completed......................................
2023-10-23 14:49:17,818:INFO:Initializing load_model()
2023-10-23 14:49:17,818:INFO:load_model(model_name=final_model_for_location_A, platform=None, authentication=None, verbose=True)
2023-10-23 14:49:17,858:INFO:Initializing load_model()
2023-10-23 14:49:17,858:INFO:load_model(model_name=final_model_for_location_B, platform=None, authentication=None, verbose=True)
2023-10-23 14:49:17,900:INFO:Initializing load_model()
2023-10-23 14:49:17,900:INFO:load_model(model_name=final_model_for_location_C, platform=None, authentication=None, verbose=True)
2023-10-23 14:49:17,959:INFO:Initializing predict_model()
2023-10-23 14:49:17,959:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E095E7AF70>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096C5B160>)
2023-10-23 14:49:17,959:INFO:Checking exceptions
2023-10-23 14:49:17,960:INFO:Preloading libraries
2023-10-23 14:49:17,960:INFO:Set up data.
2023-10-23 14:49:17,993:INFO:Set up index.
2023-10-23 14:49:18,207:INFO:Initializing predict_model()
2023-10-23 14:49:18,207:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E095E7AF70>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096C5B160>)
2023-10-23 14:49:18,207:INFO:Checking exceptions
2023-10-23 14:49:18,207:INFO:Preloading libraries
2023-10-23 14:49:18,207:INFO:Set up data.
2023-10-23 14:49:18,207:INFO:Set up index.
2023-10-23 14:49:18,394:INFO:Initializing predict_model()
2023-10-23 14:49:18,394:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E095E7AF70>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096C5B160>)
2023-10-23 14:49:18,394:INFO:Checking exceptions
2023-10-23 14:49:18,394:INFO:Preloading libraries
2023-10-23 14:49:18,394:INFO:Set up data.
2023-10-23 14:49:18,409:INFO:Set up index.
2023-10-23 15:34:25,905:INFO:PyCaret RegressionExperiment
2023-10-23 15:34:25,905:INFO:Logging name: exp_A
2023-10-23 15:34:25,906:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 15:34:25,906:INFO:version 3.1.0
2023-10-23 15:34:25,907:INFO:Initializing setup()
2023-10-23 15:34:25,907:INFO:self.USI: 5315
2023-10-23 15:34:25,908:INFO:self._variable_keys: {'gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', '_ml_usecase', 'gpu_param', 'exp_name_log', 'html_param', 'fold_generator', 'y', 'seed', 'y_train', 'transform_target_param', 'n_jobs_param', 'target_param', 'idx', '_available_plots', 'log_plots_param', 'memory', 'data', 'USI', 'X', 'logging_param', 'pipeline', 'exp_id', 'X_train', 'X_test', 'fold_groups_param'}
2023-10-23 15:34:25,908:INFO:Checking environment
2023-10-23 15:34:25,909:INFO:python_version: 3.8.18
2023-10-23 15:34:25,909:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 15:34:25,910:INFO:machine: AMD64
2023-10-23 15:34:25,910:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 15:34:25,910:INFO:Memory: svmem(total=16505954304, available=4813242368, percent=70.8, used=11692711936, free=4813242368)
2023-10-23 15:34:25,911:INFO:Physical Core: 8
2023-10-23 15:34:25,911:INFO:Logical Core: 16
2023-10-23 15:34:25,912:INFO:Checking libraries
2023-10-23 15:34:25,912:INFO:System:
2023-10-23 15:34:25,912:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 15:34:25,912:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 15:34:25,912:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 15:34:25,913:INFO:PyCaret required dependencies:
2023-10-23 15:34:25,913:INFO:                 pip: 23.3
2023-10-23 15:34:25,913:INFO:          setuptools: 68.0.0
2023-10-23 15:34:25,914:INFO:             pycaret: 3.1.0
2023-10-23 15:34:25,914:INFO:             IPython: 8.12.0
2023-10-23 15:34:25,914:INFO:          ipywidgets: 8.1.1
2023-10-23 15:34:25,915:INFO:                tqdm: 4.66.1
2023-10-23 15:34:25,915:INFO:               numpy: 1.23.5
2023-10-23 15:34:25,915:INFO:              pandas: 1.5.3
2023-10-23 15:34:25,916:INFO:              jinja2: 3.1.2
2023-10-23 15:34:25,916:INFO:               scipy: 1.10.1
2023-10-23 15:34:25,917:INFO:              joblib: 1.3.2
2023-10-23 15:34:25,917:INFO:             sklearn: 1.2.2
2023-10-23 15:34:25,917:INFO:                pyod: 1.1.0
2023-10-23 15:34:25,918:INFO:            imblearn: 0.11.0
2023-10-23 15:34:25,918:INFO:   category_encoders: 2.6.2
2023-10-23 15:34:25,918:INFO:            lightgbm: 4.1.0
2023-10-23 15:34:25,918:INFO:               numba: 0.58.1
2023-10-23 15:34:25,919:INFO:            requests: 2.31.0
2023-10-23 15:34:25,919:INFO:          matplotlib: 3.7.3
2023-10-23 15:34:25,919:INFO:          scikitplot: 0.3.7
2023-10-23 15:34:25,919:INFO:         yellowbrick: 1.5
2023-10-23 15:34:25,919:INFO:              plotly: 5.17.0
2023-10-23 15:34:25,920:INFO:    plotly-resampler: Not installed
2023-10-23 15:34:25,920:INFO:             kaleido: 0.2.1
2023-10-23 15:34:25,920:INFO:           schemdraw: 0.15
2023-10-23 15:34:25,920:INFO:         statsmodels: 0.14.0
2023-10-23 15:34:25,921:INFO:              sktime: 0.21.1
2023-10-23 15:34:25,921:INFO:               tbats: 1.1.3
2023-10-23 15:34:25,921:INFO:            pmdarima: 2.0.3
2023-10-23 15:34:25,921:INFO:              psutil: 5.9.0
2023-10-23 15:34:25,922:INFO:          markupsafe: 2.1.3
2023-10-23 15:34:25,922:INFO:             pickle5: Not installed
2023-10-23 15:34:25,922:INFO:         cloudpickle: 2.2.1
2023-10-23 15:34:25,922:INFO:         deprecation: 2.1.0
2023-10-23 15:34:25,922:INFO:              xxhash: 3.4.1
2023-10-23 15:34:25,922:INFO:           wurlitzer: Not installed
2023-10-23 15:34:25,923:INFO:PyCaret optional dependencies:
2023-10-23 15:34:25,923:INFO:                shap: Not installed
2023-10-23 15:34:25,923:INFO:           interpret: Not installed
2023-10-23 15:34:25,923:INFO:                umap: Not installed
2023-10-23 15:34:25,923:INFO:     ydata_profiling: Not installed
2023-10-23 15:34:25,923:INFO:  explainerdashboard: Not installed
2023-10-23 15:34:25,923:INFO:             autoviz: Not installed
2023-10-23 15:34:25,924:INFO:           fairlearn: Not installed
2023-10-23 15:34:25,924:INFO:          deepchecks: Not installed
2023-10-23 15:34:25,924:INFO:             xgboost: Not installed
2023-10-23 15:34:25,924:INFO:            catboost: 1.2.2
2023-10-23 15:34:25,924:INFO:              kmodes: Not installed
2023-10-23 15:34:25,924:INFO:             mlxtend: Not installed
2023-10-23 15:34:25,924:INFO:       statsforecast: Not installed
2023-10-23 15:34:25,924:INFO:        tune_sklearn: Not installed
2023-10-23 15:34:25,924:INFO:                 ray: Not installed
2023-10-23 15:34:25,924:INFO:            hyperopt: Not installed
2023-10-23 15:34:25,924:INFO:              optuna: Not installed
2023-10-23 15:34:25,924:INFO:               skopt: Not installed
2023-10-23 15:34:25,925:INFO:              mlflow: 2.7.1
2023-10-23 15:34:25,925:INFO:              gradio: Not installed
2023-10-23 15:34:25,925:INFO:             fastapi: Not installed
2023-10-23 15:34:25,925:INFO:             uvicorn: Not installed
2023-10-23 15:34:25,925:INFO:              m2cgen: Not installed
2023-10-23 15:34:25,925:INFO:           evidently: Not installed
2023-10-23 15:34:25,925:INFO:               fugue: Not installed
2023-10-23 15:34:25,925:INFO:           streamlit: Not installed
2023-10-23 15:34:25,925:INFO:             prophet: Not installed
2023-10-23 15:34:25,925:INFO:None
2023-10-23 15:34:25,925:INFO:Set up data.
2023-10-23 15:34:25,966:INFO:Set up folding strategy.
2023-10-23 15:34:25,966:INFO:Set up train/test split.
2023-10-23 15:34:26,010:INFO:Set up index.
2023-10-23 15:34:26,012:INFO:Assigning column types.
2023-10-23 15:34:26,044:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 15:34:26,045:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,050:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,055:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,140:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,175:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,175:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 15:34:26,175:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 15:34:26,175:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,192:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,198:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,282:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,322:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,322:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 15:34:26,322:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 15:34:26,322:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 15:34:26,338:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,338:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,425:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,457:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,457:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 15:34:26,457:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 15:34:26,474:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,483:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,564:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,611:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,611:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 15:34:26,612:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 15:34:26,612:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 15:34:26,620:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,699:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,746:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,747:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 15:34:26,748:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 15:34:26,758:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,835:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,878:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,878:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 15:34:26,878:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 15:34:26,878:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 15:34:26,979:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 15:34:27,029:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 15:34:27,030:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 15:34:27,030:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 15:34:27,112:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 15:34:27,160:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 15:34:27,160:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 15:34:27,160:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 15:34:27,160:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 15:34:27,246:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 15:34:27,297:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 15:34:27,297:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 15:34:27,378:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 15:34:27,427:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 15:34:27,427:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 15:34:27,427:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 15:34:27,572:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 15:34:27,573:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 15:34:27,709:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 15:34:27,709:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 15:34:27,709:INFO:Preparing preprocessing pipeline...
2023-10-23 15:34:27,709:INFO:Set up date feature engineering.
2023-10-23 15:34:27,709:INFO:Set up simple imputation.
2023-10-23 15:34:27,727:INFO:Set up encoding of ordinal features.
2023-10-23 15:34:27,760:INFO:Set up encoding of categorical features.
2023-10-23 15:34:27,760:INFO:Set up polynomial features.
2023-10-23 15:34:27,760:INFO:Set up removing outliers.
2023-10-23 15:34:27,763:INFO:Set up column name cleaning.
2023-10-23 15:34:29,924:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:34:58,498:INFO:Finished creating preprocessing pipeline.
2023-10-23 15:34:58,597:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_ene...
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 15:34:58,597:INFO:Creating final display dataframe.
2023-10-23 15:34:59,551:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:35:31,806:INFO:Setup _display_container:                     Description          Value
0                    Session id            123
1                        Target         target
2                   Target type     Regression
3           Original data shape    (34061, 52)
4        Transformed data shape  (32868, 1540)
5   Transformed train set shape  (22649, 1540)
6    Transformed test set shape  (10219, 1540)
7              Ordinal features              4
8              Numeric features             44
9                 Date features              3
10         Categorical features              4
11     Rows with missing values          90.5%
12                   Preprocess           True
13              Imputation type         simple
14           Numeric imputation           mean
15       Categorical imputation           mode
16     Maximum one-hot encoding             25
17              Encoding method           None
18          Polynomial features           True
19            Polynomial degree              2
20              Remove outliers           True
21           Outliers threshold           0.05
22               Fold Generator          KFold
23                  Fold Number             10
24                     CPU Jobs             -1
25                      Use GPU          False
26               Log Experiment   MlflowLogger
27              Experiment Name          exp_A
28                          USI           5315
2023-10-23 15:35:31,941:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 15:35:31,941:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 15:35:32,091:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 15:35:32,091:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 15:35:32,091:INFO:Logging experiment in loggers
2023-10-23 15:35:32,220:INFO:SubProcess save_model() called ==================================
2023-10-23 15:35:32,455:INFO:Initializing save_model()
2023-10-23 15:35:32,455:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_ene...
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmptj34vz9k\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_ene...
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 15:35:32,456:INFO:Adding model into prep_pipe
2023-10-23 15:35:32,456:WARNING:Only Model saved as it was a pipeline.
2023-10-23 15:35:32,539:INFO:C:\Users\thoma\AppData\Local\Temp\tmptj34vz9k\Transformation Pipeline.pkl saved in current working directory
2023-10-23 15:35:32,686:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_ene...
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 15:35:32,686:INFO:save_model() successfully completed......................................
2023-10-23 15:35:32,819:INFO:SubProcess save_model() end ==================================
2023-10-23 15:35:32,908:INFO:setup() successfully completed in 66.19s...............
2023-10-23 15:35:32,908:INFO:Initializing create_model()
2023-10-23 15:35:32,908:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E99F10>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 15:35:32,908:INFO:Checking exceptions
2023-10-23 15:35:32,908:INFO:Importing libraries
2023-10-23 15:35:32,908:INFO:Copying training dataset
2023-10-23 15:35:32,937:INFO:Defining folds
2023-10-23 15:35:32,937:INFO:Declaring metric variables
2023-10-23 15:35:32,937:INFO:Importing untrained model
2023-10-23 15:35:32,937:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 15:35:32,938:INFO:Starting cross validation
2023-10-23 15:35:32,955:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 15:35:47,304:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:35:49,487:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:35:52,996:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:35:53,109:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:35:53,351:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:35:53,375:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:35:53,405:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:35:53,561:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:35:54,541:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:35:54,961:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:38:06,176:INFO:Calculating mean and std
2023-10-23 15:38:06,179:INFO:Creating metrics dataframe
2023-10-23 15:38:06,185:INFO:Finalizing model
2023-10-23 15:38:08,048:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:38:38,454:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-10-23 15:38:38,704:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.223384 seconds.
2023-10-23 15:38:38,704:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 15:38:38,713:INFO:[LightGBM] [Info] Total Bins 232794
2023-10-23 15:38:38,726:INFO:[LightGBM] [Info] Number of data points in the train set: 22649, number of used features: 1345
2023-10-23 15:38:38,733:INFO:[LightGBM] [Info] Start training from score 606.666216
2023-10-23 15:38:43,078:INFO:Creating Dashboard logs
2023-10-23 15:38:43,079:INFO:Model: Light Gradient Boosting Machine
2023-10-23 15:38:43,172:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 15:38:43,362:INFO:Initializing predict_model()
2023-10-23 15:38:43,362:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E99F10>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096917790>)
2023-10-23 15:38:43,362:INFO:Checking exceptions
2023-10-23 15:38:43,362:INFO:Preloading libraries
2023-10-23 15:38:44,406:INFO:Uploading results into container
2023-10-23 15:38:44,407:INFO:Uploading model into container now
2023-10-23 15:38:44,411:INFO:_master_model_container: 1
2023-10-23 15:38:44,411:INFO:_display_container: 2
2023-10-23 15:38:44,411:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 15:38:44,411:INFO:create_model() successfully completed......................................
2023-10-23 15:38:44,519:INFO:Initializing tune_model()
2023-10-23 15:38:44,519:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E99F10>)
2023-10-23 15:38:44,519:INFO:Checking exceptions
2023-10-23 15:38:44,531:INFO:Copying training dataset
2023-10-23 15:38:44,547:INFO:Checking base model
2023-10-23 15:38:44,547:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 15:38:44,548:INFO:Declaring metric variables
2023-10-23 15:38:44,548:INFO:Defining Hyperparameters
2023-10-23 15:38:44,680:INFO:Tuning with n_jobs=-1
2023-10-23 15:38:44,680:INFO:Initializing RandomizedSearchCV
2023-10-23 15:38:50,024:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:38:50,235:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:38:50,241:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:38:50,322:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:38:50,380:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:38:51,140:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:38:52,430:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:38:53,602:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:38:56,451:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:38:57,759:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:39:11,085:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:39:15,396:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:39:18,112:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:39:18,362:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:39:18,338:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:39:22,480:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:42:36,169:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:42:36,986:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:42:37,024:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:42:41,282:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:42:42,248:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:42:49,428:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:45:04,986:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:45:07,811:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:45:08,544:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:45:09,201:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:47:04,166:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:47:09,347:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:47:13,807:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:47:19,719:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:47:23,268:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:47:28,714:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:47:39,264:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:47:39,629:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:47:40,942:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:47:44,029:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:50:08,362:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:50:15,309:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:50:23,751:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:50:31,598:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:50:34,042:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:50:39,920:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:51:58,020:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:52:19,390:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:52:48,417:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:52:54,807:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:52:57,721:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:54:05,758:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:54:07,956:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:54:11,427:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:54:21,147:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:54:34,032:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:55:15,782:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:55:27,499:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:55:32,744:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:55:36,344:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:56:04,775:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:56:13,978:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:56:42,689:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:56:53,540:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:56:57,575:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:57:05,901:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:57:54,063:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:58:03,571:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:58:09,325:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:58:29,959:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:58:36,158:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:59:04,221:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:59:06,591:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:00:05,727:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:00:07,418:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:00:08,351:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:00:16,061:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:00:22,339:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:00:38,676:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:01:23,447:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:01:26,518:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:01:52,281:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:03:13,735:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:03:19,809:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:03:26,537:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:03:28,652:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:03:42,907:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:04:27,004:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:05:00,437:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:05:01,656:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:06:08,687:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:06:12,213:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:06:15,646:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:06:22,378:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:06:50,004:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:07:42,384:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:07:44,824:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:07:57,963:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:08:05,856:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:08:10,393:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:08:54,165:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:08:58,154:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:09:31,797:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:09:40,328:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:10:54,754:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-23 16:10:54,816:INFO:Hyperparameter search completed
2023-10-23 16:10:54,816:INFO:SubProcess create_model() called ==================================
2023-10-23 16:10:54,852:INFO:Initializing create_model()
2023-10-23 16:10:54,853:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E99F10>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E096CBA7C0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-23 16:10:54,853:INFO:Checking exceptions
2023-10-23 16:10:54,853:INFO:Importing libraries
2023-10-23 16:10:54,853:INFO:Copying training dataset
2023-10-23 16:10:54,983:INFO:Defining folds
2023-10-23 16:10:54,983:INFO:Declaring metric variables
2023-10-23 16:10:54,983:INFO:Importing untrained model
2023-10-23 16:10:54,983:INFO:Declaring custom model
2023-10-23 16:10:55,008:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 16:10:55,010:INFO:Starting cross validation
2023-10-23 16:10:55,116:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 16:10:59,300:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:10:59,452:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:10:59,454:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:10:59,484:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:10:59,516:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:10:59,531:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:10:59,531:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:10:59,552:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:10:59,567:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:10:59,598:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:13:50,554:INFO:Calculating mean and std
2023-10-23 16:13:50,557:INFO:Creating metrics dataframe
2023-10-23 16:13:50,571:INFO:Finalizing model
2023-10-23 16:13:52,101:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:22:40,449:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-23 16:22:40,449:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-23 16:22:40,449:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-23 16:22:41,574:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-10-23 16:22:41,580:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-23 16:22:41,580:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-23 16:22:41,580:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-23 16:22:41,775:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.143808 seconds.
2023-10-23 16:22:41,775:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 16:22:41,790:INFO:[LightGBM] [Info] Total Bins 232481
2023-10-23 16:22:41,822:INFO:[LightGBM] [Info] Number of data points in the train set: 22649, number of used features: 1315
2023-10-23 16:22:41,829:INFO:[LightGBM] [Info] Start training from score 606.666216
2023-10-23 16:22:52,605:INFO:Uploading results into container
2023-10-23 16:22:52,605:INFO:Uploading model into container now
2023-10-23 16:22:52,605:INFO:_master_model_container: 2
2023-10-23 16:22:52,605:INFO:_display_container: 3
2023-10-23 16:22:52,605:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-23 16:22:52,605:INFO:create_model() successfully completed......................................
2023-10-23 16:22:52,965:INFO:SubProcess create_model() end ==================================
2023-10-23 16:22:52,966:INFO:choose_better activated
2023-10-23 16:22:52,966:INFO:SubProcess create_model() called ==================================
2023-10-23 16:22:52,967:INFO:Initializing create_model()
2023-10-23 16:22:52,967:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E99F10>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 16:22:52,967:INFO:Checking exceptions
2023-10-23 16:22:52,970:INFO:Importing libraries
2023-10-23 16:22:52,970:INFO:Copying training dataset
2023-10-23 16:22:53,000:INFO:Defining folds
2023-10-23 16:22:53,000:INFO:Declaring metric variables
2023-10-23 16:22:53,001:INFO:Importing untrained model
2023-10-23 16:22:53,001:INFO:Declaring custom model
2023-10-23 16:22:53,001:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 16:22:53,002:INFO:Starting cross validation
2023-10-23 16:22:53,017:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 16:22:54,671:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:22:54,699:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:22:58,033:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\joblib\externals\loky\process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(

2023-10-23 16:23:09,016:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:23:09,053:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:23:09,369:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:23:09,418:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:23:09,479:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:23:09,495:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:23:09,557:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:23:16,645:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:25:11,644:INFO:Calculating mean and std
2023-10-23 16:25:11,644:INFO:Creating metrics dataframe
2023-10-23 16:25:11,644:INFO:Finalizing model
2023-10-23 16:25:13,055:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:25:43,076:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-10-23 16:25:43,330:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.219583 seconds.
2023-10-23 16:25:43,331:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 16:25:43,331:INFO:[LightGBM] [Info] Total Bins 232794
2023-10-23 16:25:43,357:INFO:[LightGBM] [Info] Number of data points in the train set: 22649, number of used features: 1345
2023-10-23 16:25:43,363:INFO:[LightGBM] [Info] Start training from score 606.666216
2023-10-23 16:25:48,104:INFO:Uploading results into container
2023-10-23 16:25:48,106:INFO:Uploading model into container now
2023-10-23 16:25:48,107:INFO:_master_model_container: 3
2023-10-23 16:25:48,108:INFO:_display_container: 4
2023-10-23 16:25:48,109:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 16:25:48,110:INFO:create_model() successfully completed......................................
2023-10-23 16:25:48,237:INFO:SubProcess create_model() end ==================================
2023-10-23 16:25:48,238:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8741
2023-10-23 16:25:48,239:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8681
2023-10-23 16:25:48,239:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-23 16:25:48,239:INFO:choose_better completed
2023-10-23 16:25:48,239:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-23 16:25:48,240:INFO:Creating Dashboard logs
2023-10-23 16:25:48,240:INFO:Model: Light Gradient Boosting Machine
2023-10-23 16:25:48,347:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 16:25:48,596:INFO:Initializing predict_model()
2023-10-23 16:25:48,596:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E99F10>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E0969F5B80>)
2023-10-23 16:25:48,596:INFO:Checking exceptions
2023-10-23 16:25:48,596:INFO:Preloading libraries
2023-10-23 16:25:49,798:INFO:_master_model_container: 3
2023-10-23 16:25:49,798:INFO:_display_container: 3
2023-10-23 16:25:49,799:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 16:25:49,799:INFO:tune_model() successfully completed......................................
2023-10-23 16:25:49,911:INFO:Initializing ensemble_model()
2023-10-23 16:25:49,911:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E99F10>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-23 16:25:49,911:INFO:Checking exceptions
2023-10-23 16:25:49,926:INFO:Importing libraries
2023-10-23 16:25:49,926:INFO:Copying training dataset
2023-10-23 16:25:49,926:INFO:Checking base model
2023-10-23 16:25:49,926:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 16:25:49,926:INFO:Importing untrained ensembler
2023-10-23 16:25:49,926:INFO:Ensemble method set to Bagging
2023-10-23 16:25:49,926:INFO:SubProcess create_model() called ==================================
2023-10-23 16:25:49,926:INFO:Initializing create_model()
2023-10-23 16:25:49,926:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E99F10>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E096FDF460>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 16:25:49,926:INFO:Checking exceptions
2023-10-23 16:25:49,926:INFO:Importing libraries
2023-10-23 16:25:49,926:INFO:Copying training dataset
2023-10-23 16:25:49,958:INFO:Defining folds
2023-10-23 16:25:49,958:INFO:Declaring metric variables
2023-10-23 16:25:49,963:INFO:Importing untrained model
2023-10-23 16:25:49,963:INFO:Declaring custom model
2023-10-23 16:25:49,964:INFO:Bagging Regressor Imported successfully
2023-10-23 16:25:49,964:INFO:Starting cross validation
2023-10-23 16:25:49,983:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 16:25:53,072:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:25:53,095:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:25:53,097:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:25:53,105:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:26:00,476:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:26:02,001:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:26:03,863:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:26:03,896:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:26:03,913:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:26:04,113:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:36:32,445:INFO:Calculating mean and std
2023-10-23 16:36:32,445:INFO:Creating metrics dataframe
2023-10-23 16:36:32,461:INFO:Finalizing model
2023-10-23 16:36:35,082:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:37:07,574:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.206368 seconds.
2023-10-23 16:37:07,574:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 16:37:07,589:INFO:[LightGBM] [Info] Total Bins 232794
2023-10-23 16:37:07,602:INFO:[LightGBM] [Info] Number of data points in the train set: 22649, number of used features: 1345
2023-10-23 16:37:07,609:INFO:[LightGBM] [Info] Start training from score 592.277916
2023-10-23 16:37:14,053:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.227693 seconds.
2023-10-23 16:37:14,053:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 16:37:14,066:INFO:[LightGBM] [Info] Total Bins 232794
2023-10-23 16:37:14,081:INFO:[LightGBM] [Info] Number of data points in the train set: 22649, number of used features: 1345
2023-10-23 16:37:14,087:INFO:[LightGBM] [Info] Start training from score 596.652180
2023-10-23 16:37:20,346:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.208540 seconds.
2023-10-23 16:37:20,346:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 16:37:20,362:INFO:[LightGBM] [Info] Total Bins 232794
2023-10-23 16:37:20,378:INFO:[LightGBM] [Info] Number of data points in the train set: 22649, number of used features: 1345
2023-10-23 16:37:20,378:INFO:[LightGBM] [Info] Start training from score 606.990889
2023-10-23 16:37:26,745:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.222399 seconds.
2023-10-23 16:37:26,745:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 16:37:26,745:INFO:[LightGBM] [Info] Total Bins 232794
2023-10-23 16:37:26,771:INFO:[LightGBM] [Info] Number of data points in the train set: 22649, number of used features: 1345
2023-10-23 16:37:26,771:INFO:[LightGBM] [Info] Start training from score 605.150146
2023-10-23 16:37:32,910:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.203082 seconds.
2023-10-23 16:37:32,910:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 16:37:32,926:INFO:[LightGBM] [Info] Total Bins 232794
2023-10-23 16:37:32,942:INFO:[LightGBM] [Info] Number of data points in the train set: 22649, number of used features: 1345
2023-10-23 16:37:32,942:INFO:[LightGBM] [Info] Start training from score 609.237003
2023-10-23 16:37:38,984:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.190139 seconds.
2023-10-23 16:37:38,984:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 16:37:38,996:INFO:[LightGBM] [Info] Total Bins 232794
2023-10-23 16:37:39,011:INFO:[LightGBM] [Info] Number of data points in the train set: 22649, number of used features: 1345
2023-10-23 16:37:39,018:INFO:[LightGBM] [Info] Start training from score 613.224395
2023-10-23 16:37:44,918:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.227321 seconds.
2023-10-23 16:37:44,918:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 16:37:44,933:INFO:[LightGBM] [Info] Total Bins 232794
2023-10-23 16:37:44,933:INFO:[LightGBM] [Info] Number of data points in the train set: 22649, number of used features: 1345
2023-10-23 16:37:44,952:INFO:[LightGBM] [Info] Start training from score 605.921137
2023-10-23 16:37:50,969:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.218161 seconds.
2023-10-23 16:37:50,969:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 16:37:50,982:INFO:[LightGBM] [Info] Total Bins 232794
2023-10-23 16:37:50,997:INFO:[LightGBM] [Info] Number of data points in the train set: 22649, number of used features: 1345
2023-10-23 16:37:51,003:INFO:[LightGBM] [Info] Start training from score 610.527528
2023-10-23 16:37:57,237:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.199628 seconds.
2023-10-23 16:37:57,237:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 16:37:57,237:INFO:[LightGBM] [Info] Total Bins 232794
2023-10-23 16:37:57,253:INFO:[LightGBM] [Info] Number of data points in the train set: 22649, number of used features: 1345
2023-10-23 16:37:57,269:INFO:[LightGBM] [Info] Start training from score 596.385075
2023-10-23 16:38:03,096:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.212540 seconds.
2023-10-23 16:38:03,096:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 16:38:03,111:INFO:[LightGBM] [Info] Total Bins 232794
2023-10-23 16:38:03,127:INFO:[LightGBM] [Info] Number of data points in the train set: 22649, number of used features: 1345
2023-10-23 16:38:03,127:INFO:[LightGBM] [Info] Start training from score 617.000194
2023-10-23 16:38:07,692:INFO:Uploading results into container
2023-10-23 16:38:07,693:INFO:Uploading model into container now
2023-10-23 16:38:07,695:INFO:_master_model_container: 4
2023-10-23 16:38:07,695:INFO:_display_container: 4
2023-10-23 16:38:07,698:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 16:38:07,698:INFO:create_model() successfully completed......................................
2023-10-23 16:38:07,876:INFO:SubProcess create_model() end ==================================
2023-10-23 16:38:07,877:INFO:Creating Dashboard logs
2023-10-23 16:38:07,878:INFO:Model: Bagging Regressor
2023-10-23 16:38:07,955:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-23 16:38:08,190:INFO:Initializing predict_model()
2023-10-23 16:38:08,190:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E99F10>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E0969F59D0>)
2023-10-23 16:38:08,190:INFO:Checking exceptions
2023-10-23 16:38:08,190:INFO:Preloading libraries
2023-10-23 16:38:11,527:INFO:_master_model_container: 4
2023-10-23 16:38:11,527:INFO:_display_container: 4
2023-10-23 16:38:11,528:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 16:38:11,528:INFO:ensemble_model() successfully completed......................................
2023-10-23 16:38:11,647:INFO:Initializing finalize_model()
2023-10-23 16:38:11,648:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E99F10>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-23 16:38:11,648:INFO:Finalizing BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 16:38:11,665:INFO:Initializing create_model()
2023-10-23 16:38:11,666:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E99F10>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-23 16:38:11,666:INFO:Checking exceptions
2023-10-23 16:38:11,667:INFO:Importing libraries
2023-10-23 16:38:11,667:INFO:Copying training dataset
2023-10-23 16:38:11,668:INFO:Defining folds
2023-10-23 16:38:11,668:INFO:Declaring metric variables
2023-10-23 16:38:11,669:INFO:Importing untrained model
2023-10-23 16:38:11,669:INFO:Declaring custom model
2023-10-23 16:38:11,670:INFO:Bagging Regressor Imported successfully
2023-10-23 16:38:11,686:INFO:Cross validation set to False
2023-10-23 16:38:11,686:INFO:Fitting Model
2023-10-23 16:38:13,703:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:38:59,700:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.324973 seconds.
2023-10-23 16:38:59,700:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 16:38:59,711:INFO:[LightGBM] [Info] Total Bins 242793
2023-10-23 16:38:59,733:INFO:[LightGBM] [Info] Number of data points in the train set: 32358, number of used features: 1351
2023-10-23 16:38:59,741:INFO:[LightGBM] [Info] Start training from score 597.761451
2023-10-23 16:39:07,932:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.287680 seconds.
2023-10-23 16:39:07,933:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 16:39:07,947:INFO:[LightGBM] [Info] Total Bins 242793
2023-10-23 16:39:07,961:INFO:[LightGBM] [Info] Number of data points in the train set: 32358, number of used features: 1351
2023-10-23 16:39:07,968:INFO:[LightGBM] [Info] Start training from score 607.260245
2023-10-23 16:39:15,494:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.285359 seconds.
2023-10-23 16:39:15,494:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 16:39:15,512:INFO:[LightGBM] [Info] Total Bins 242793
2023-10-23 16:39:15,526:INFO:[LightGBM] [Info] Number of data points in the train set: 32358, number of used features: 1351
2023-10-23 16:39:15,533:INFO:[LightGBM] [Info] Start training from score 605.801669
2023-10-23 16:39:22,518:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.257753 seconds.
2023-10-23 16:39:22,518:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 16:39:22,533:INFO:[LightGBM] [Info] Total Bins 242793
2023-10-23 16:39:22,549:INFO:[LightGBM] [Info] Number of data points in the train set: 32358, number of used features: 1351
2023-10-23 16:39:22,549:INFO:[LightGBM] [Info] Start training from score 605.479179
2023-10-23 16:39:29,347:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.240337 seconds.
2023-10-23 16:39:29,347:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 16:39:29,362:INFO:[LightGBM] [Info] Total Bins 242793
2023-10-23 16:39:29,378:INFO:[LightGBM] [Info] Number of data points in the train set: 32358, number of used features: 1351
2023-10-23 16:39:29,392:INFO:[LightGBM] [Info] Start training from score 608.362876
2023-10-23 16:39:36,236:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.257255 seconds.
2023-10-23 16:39:36,236:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 16:39:36,251:INFO:[LightGBM] [Info] Total Bins 242793
2023-10-23 16:39:36,266:INFO:[LightGBM] [Info] Number of data points in the train set: 32358, number of used features: 1351
2023-10-23 16:39:36,268:INFO:[LightGBM] [Info] Start training from score 605.088243
2023-10-23 16:39:43,526:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.296148 seconds.
2023-10-23 16:39:43,526:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 16:39:43,539:INFO:[LightGBM] [Info] Total Bins 242793
2023-10-23 16:39:43,552:INFO:[LightGBM] [Info] Number of data points in the train set: 32358, number of used features: 1351
2023-10-23 16:39:43,559:INFO:[LightGBM] [Info] Start training from score 589.251700
2023-10-23 16:39:50,638:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.268260 seconds.
2023-10-23 16:39:50,638:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 16:39:50,638:INFO:[LightGBM] [Info] Total Bins 242793
2023-10-23 16:39:50,667:INFO:[LightGBM] [Info] Number of data points in the train set: 32358, number of used features: 1351
2023-10-23 16:39:50,673:INFO:[LightGBM] [Info] Start training from score 613.625471
2023-10-23 16:39:57,568:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.279579 seconds.
2023-10-23 16:39:57,569:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 16:39:57,573:INFO:[LightGBM] [Info] Total Bins 242793
2023-10-23 16:39:57,589:INFO:[LightGBM] [Info] Number of data points in the train set: 32358, number of used features: 1351
2023-10-23 16:39:57,604:INFO:[LightGBM] [Info] Start training from score 606.512936
2023-10-23 16:40:04,875:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.261967 seconds.
2023-10-23 16:40:04,875:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 16:40:04,887:INFO:[LightGBM] [Info] Total Bins 242793
2023-10-23 16:40:04,900:INFO:[LightGBM] [Info] Number of data points in the train set: 32358, number of used features: 1351
2023-10-23 16:40:04,906:INFO:[LightGBM] [Info] Start training from score 603.315563
2023-10-23 16:40:10,175:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_...
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 16:40:10,175:INFO:create_model() successfully completed......................................
2023-10-23 16:40:10,274:INFO:Creating Dashboard logs
2023-10-23 16:40:10,290:INFO:Model: Bagging Regressor
2023-10-23 16:40:10,350:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-23 16:40:10,729:INFO:_master_model_container: 4
2023-10-23 16:40:10,729:INFO:_display_container: 4
2023-10-23 16:40:10,854:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_...
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 16:40:10,854:INFO:finalize_model() successfully completed......................................
2023-10-23 16:40:11,186:INFO:Initializing save_model()
2023-10-23 16:40:11,186:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_...
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), model_name=final_model_for_location_A, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_ene...
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 16:40:11,186:INFO:Adding model into prep_pipe
2023-10-23 16:40:11,186:WARNING:Only Model saved as it was a pipeline.
2023-10-23 16:40:11,338:INFO:final_model_for_location_A.pkl saved in current working directory
2023-10-23 16:40:11,510:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_...
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 16:40:11,510:INFO:save_model() successfully completed......................................
2023-10-23 16:40:11,683:INFO:PyCaret RegressionExperiment
2023-10-23 16:40:11,683:INFO:Logging name: exp_B
2023-10-23 16:40:11,683:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 16:40:11,683:INFO:version 3.1.0
2023-10-23 16:40:11,683:INFO:Initializing setup()
2023-10-23 16:40:11,683:INFO:self.USI: 058a
2023-10-23 16:40:11,683:INFO:self._variable_keys: {'gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', '_ml_usecase', 'gpu_param', 'exp_name_log', 'html_param', 'fold_generator', 'y', 'seed', 'y_train', 'transform_target_param', 'n_jobs_param', 'target_param', 'idx', '_available_plots', 'log_plots_param', 'memory', 'data', 'USI', 'X', 'logging_param', 'pipeline', 'exp_id', 'X_train', 'X_test', 'fold_groups_param'}
2023-10-23 16:40:11,683:INFO:Checking environment
2023-10-23 16:40:11,683:INFO:python_version: 3.8.18
2023-10-23 16:40:11,683:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 16:40:11,683:INFO:machine: AMD64
2023-10-23 16:40:11,683:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 16:40:11,683:INFO:Memory: svmem(total=16505954304, available=7316000768, percent=55.7, used=9189953536, free=7316000768)
2023-10-23 16:40:11,683:INFO:Physical Core: 8
2023-10-23 16:40:11,683:INFO:Logical Core: 16
2023-10-23 16:40:11,683:INFO:Checking libraries
2023-10-23 16:40:11,683:INFO:System:
2023-10-23 16:40:11,683:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 16:40:11,683:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 16:40:11,683:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 16:40:11,683:INFO:PyCaret required dependencies:
2023-10-23 16:40:11,683:INFO:                 pip: 23.3
2023-10-23 16:40:11,683:INFO:          setuptools: 68.0.0
2023-10-23 16:40:11,683:INFO:             pycaret: 3.1.0
2023-10-23 16:40:11,683:INFO:             IPython: 8.12.0
2023-10-23 16:40:11,683:INFO:          ipywidgets: 8.1.1
2023-10-23 16:40:11,683:INFO:                tqdm: 4.66.1
2023-10-23 16:40:11,683:INFO:               numpy: 1.23.5
2023-10-23 16:40:11,683:INFO:              pandas: 1.5.3
2023-10-23 16:40:11,683:INFO:              jinja2: 3.1.2
2023-10-23 16:40:11,683:INFO:               scipy: 1.10.1
2023-10-23 16:40:11,683:INFO:              joblib: 1.3.2
2023-10-23 16:40:11,683:INFO:             sklearn: 1.2.2
2023-10-23 16:40:11,683:INFO:                pyod: 1.1.0
2023-10-23 16:40:11,683:INFO:            imblearn: 0.11.0
2023-10-23 16:40:11,683:INFO:   category_encoders: 2.6.2
2023-10-23 16:40:11,683:INFO:            lightgbm: 4.1.0
2023-10-23 16:40:11,683:INFO:               numba: 0.58.1
2023-10-23 16:40:11,683:INFO:            requests: 2.31.0
2023-10-23 16:40:11,683:INFO:          matplotlib: 3.7.3
2023-10-23 16:40:11,683:INFO:          scikitplot: 0.3.7
2023-10-23 16:40:11,683:INFO:         yellowbrick: 1.5
2023-10-23 16:40:11,683:INFO:              plotly: 5.17.0
2023-10-23 16:40:11,683:INFO:    plotly-resampler: Not installed
2023-10-23 16:40:11,683:INFO:             kaleido: 0.2.1
2023-10-23 16:40:11,683:INFO:           schemdraw: 0.15
2023-10-23 16:40:11,683:INFO:         statsmodels: 0.14.0
2023-10-23 16:40:11,683:INFO:              sktime: 0.21.1
2023-10-23 16:40:11,683:INFO:               tbats: 1.1.3
2023-10-23 16:40:11,683:INFO:            pmdarima: 2.0.3
2023-10-23 16:40:11,683:INFO:              psutil: 5.9.0
2023-10-23 16:40:11,683:INFO:          markupsafe: 2.1.3
2023-10-23 16:40:11,683:INFO:             pickle5: Not installed
2023-10-23 16:40:11,683:INFO:         cloudpickle: 2.2.1
2023-10-23 16:40:11,683:INFO:         deprecation: 2.1.0
2023-10-23 16:40:11,683:INFO:              xxhash: 3.4.1
2023-10-23 16:40:11,683:INFO:           wurlitzer: Not installed
2023-10-23 16:40:11,683:INFO:PyCaret optional dependencies:
2023-10-23 16:40:11,683:INFO:                shap: Not installed
2023-10-23 16:40:11,683:INFO:           interpret: Not installed
2023-10-23 16:40:11,683:INFO:                umap: Not installed
2023-10-23 16:40:11,683:INFO:     ydata_profiling: Not installed
2023-10-23 16:40:11,683:INFO:  explainerdashboard: Not installed
2023-10-23 16:40:11,683:INFO:             autoviz: Not installed
2023-10-23 16:40:11,683:INFO:           fairlearn: Not installed
2023-10-23 16:40:11,683:INFO:          deepchecks: Not installed
2023-10-23 16:40:11,683:INFO:             xgboost: Not installed
2023-10-23 16:40:11,683:INFO:            catboost: 1.2.2
2023-10-23 16:40:11,683:INFO:              kmodes: Not installed
2023-10-23 16:40:11,683:INFO:             mlxtend: Not installed
2023-10-23 16:40:11,683:INFO:       statsforecast: Not installed
2023-10-23 16:40:11,683:INFO:        tune_sklearn: Not installed
2023-10-23 16:40:11,683:INFO:                 ray: Not installed
2023-10-23 16:40:11,683:INFO:            hyperopt: Not installed
2023-10-23 16:40:11,683:INFO:              optuna: Not installed
2023-10-23 16:40:11,683:INFO:               skopt: Not installed
2023-10-23 16:40:11,683:INFO:              mlflow: 2.7.1
2023-10-23 16:40:11,683:INFO:              gradio: Not installed
2023-10-23 16:40:11,683:INFO:             fastapi: Not installed
2023-10-23 16:40:11,683:INFO:             uvicorn: Not installed
2023-10-23 16:40:11,683:INFO:              m2cgen: Not installed
2023-10-23 16:40:11,683:INFO:           evidently: Not installed
2023-10-23 16:40:11,683:INFO:               fugue: Not installed
2023-10-23 16:40:11,683:INFO:           streamlit: Not installed
2023-10-23 16:40:11,683:INFO:             prophet: Not installed
2023-10-23 16:40:11,683:INFO:None
2023-10-23 16:40:11,683:INFO:Set up data.
2023-10-23 16:40:11,731:INFO:Set up folding strategy.
2023-10-23 16:40:11,731:INFO:Set up train/test split.
2023-10-23 16:40:11,748:INFO:Set up index.
2023-10-23 16:40:11,760:INFO:Assigning column types.
2023-10-23 16:40:11,776:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 16:40:11,776:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 16:40:11,776:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 16:40:11,791:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 16:40:11,877:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 16:40:11,927:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 16:40:11,928:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 16:40:11,928:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 16:40:11,929:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 16:40:11,934:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 16:40:11,940:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 16:40:12,007:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 16:40:12,074:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 16:40:12,075:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 16:40:12,075:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 16:40:12,076:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 16:40:12,081:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 16:40:12,086:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 16:40:12,170:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 16:40:12,221:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 16:40:12,222:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 16:40:12,222:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 16:40:12,228:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 16:40:12,234:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 16:40:12,311:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 16:40:12,358:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 16:40:12,358:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 16:40:12,358:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 16:40:12,358:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 16:40:12,380:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 16:40:12,465:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 16:40:12,516:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 16:40:12,517:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 16:40:12,517:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 16:40:12,528:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 16:40:12,609:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 16:40:12,660:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 16:40:12,661:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 16:40:12,661:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 16:40:12,661:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 16:40:12,753:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 16:40:12,804:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 16:40:12,804:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 16:40:12,805:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 16:40:12,896:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 16:40:12,942:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 16:40:12,942:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 16:40:12,942:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 16:40:12,942:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 16:40:13,036:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 16:40:13,095:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 16:40:13,095:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 16:40:13,187:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 16:40:13,238:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 16:40:13,239:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 16:40:13,240:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 16:40:13,378:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 16:40:13,378:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 16:40:13,525:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 16:40:13,525:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 16:40:13,527:INFO:Preparing preprocessing pipeline...
2023-10-23 16:40:13,527:INFO:Set up date feature engineering.
2023-10-23 16:40:13,527:INFO:Set up simple imputation.
2023-10-23 16:40:13,541:INFO:Set up encoding of ordinal features.
2023-10-23 16:40:13,560:INFO:Set up encoding of categorical features.
2023-10-23 16:40:13,560:INFO:Set up polynomial features.
2023-10-23 16:40:13,560:INFO:Set up removing outliers.
2023-10-23 16:40:13,560:INFO:Set up column name cleaning.
2023-10-23 16:40:15,210:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:40:44,389:INFO:Finished creating preprocessing pipeline.
2023-10-23 16:40:44,500:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_ene...
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 16:40:44,500:INFO:Creating final display dataframe.
2023-10-23 16:40:45,555:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:41:16,904:INFO:Setup _display_container:                     Description          Value
0                    Session id            123
1                        Target         target
2                   Target type     Regression
3           Original data shape    (32819, 52)
4        Transformed data shape  (31670, 1540)
5   Transformed train set shape  (21824, 1540)
6    Transformed test set shape   (9846, 1540)
7              Ordinal features              4
8              Numeric features             44
9                 Date features              3
10         Categorical features              4
11     Rows with missing values          91.9%
12                   Preprocess           True
13              Imputation type         simple
14           Numeric imputation           mean
15       Categorical imputation           mode
16     Maximum one-hot encoding             25
17              Encoding method           None
18          Polynomial features           True
19            Polynomial degree              2
20              Remove outliers           True
21           Outliers threshold           0.05
22               Fold Generator          KFold
23                  Fold Number             10
24                     CPU Jobs             -1
25                      Use GPU          False
26               Log Experiment   MlflowLogger
27              Experiment Name          exp_B
28                          USI           058a
2023-10-23 16:41:17,116:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 16:41:17,116:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 16:41:17,324:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 16:41:17,324:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 16:41:17,324:INFO:Logging experiment in loggers
2023-10-23 16:41:17,450:INFO:SubProcess save_model() called ==================================
2023-10-23 16:41:17,682:INFO:Initializing save_model()
2023-10-23 16:41:17,682:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_ene...
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmpsd4_qcqb\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_ene...
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 16:41:17,682:INFO:Adding model into prep_pipe
2023-10-23 16:41:17,682:WARNING:Only Model saved as it was a pipeline.
2023-10-23 16:41:17,745:INFO:C:\Users\thoma\AppData\Local\Temp\tmpsd4_qcqb\Transformation Pipeline.pkl saved in current working directory
2023-10-23 16:41:17,868:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_ene...
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 16:41:17,868:INFO:save_model() successfully completed......................................
2023-10-23 16:41:17,993:INFO:SubProcess save_model() end ==================================
2023-10-23 16:41:18,089:INFO:setup() successfully completed in 65.64s...............
2023-10-23 16:41:18,089:INFO:Initializing create_model()
2023-10-23 16:41:18,089:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08C2D2100>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 16:41:18,089:INFO:Checking exceptions
2023-10-23 16:41:18,089:INFO:Importing libraries
2023-10-23 16:41:18,089:INFO:Copying training dataset
2023-10-23 16:41:18,124:INFO:Defining folds
2023-10-23 16:41:18,124:INFO:Declaring metric variables
2023-10-23 16:41:18,124:INFO:Importing untrained model
2023-10-23 16:41:18,125:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 16:41:18,125:INFO:Starting cross validation
2023-10-23 16:41:18,140:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 16:41:21,529:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:41:21,957:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:41:21,986:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:41:22,037:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:41:22,286:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:41:22,300:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:41:32,151:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:41:32,178:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:41:32,613:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:41:33,093:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:43:38,600:INFO:Calculating mean and std
2023-10-23 16:43:38,600:INFO:Creating metrics dataframe
2023-10-23 16:43:38,616:INFO:Finalizing model
2023-10-23 16:43:40,093:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:44:09,070:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-10-23 16:44:09,279:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.184109 seconds.
2023-10-23 16:44:09,279:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 16:44:09,295:INFO:[LightGBM] [Info] Total Bins 233817
2023-10-23 16:44:09,311:INFO:[LightGBM] [Info] Number of data points in the train set: 21824, number of used features: 1351
2023-10-23 16:44:09,326:INFO:[LightGBM] [Info] Start training from score 87.170575
2023-10-23 16:44:14,058:INFO:Creating Dashboard logs
2023-10-23 16:44:14,059:INFO:Model: Light Gradient Boosting Machine
2023-10-23 16:44:14,164:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 16:44:14,448:INFO:Initializing predict_model()
2023-10-23 16:44:14,448:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08C2D2100>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E0970AA310>)
2023-10-23 16:44:14,448:INFO:Checking exceptions
2023-10-23 16:44:14,448:INFO:Preloading libraries
2023-10-23 16:44:15,682:INFO:Uploading results into container
2023-10-23 16:44:15,682:INFO:Uploading model into container now
2023-10-23 16:44:15,698:INFO:_master_model_container: 1
2023-10-23 16:44:15,698:INFO:_display_container: 2
2023-10-23 16:44:15,698:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 16:44:15,698:INFO:create_model() successfully completed......................................
2023-10-23 16:44:15,808:INFO:Initializing tune_model()
2023-10-23 16:44:15,808:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08C2D2100>)
2023-10-23 16:44:15,808:INFO:Checking exceptions
2023-10-23 16:44:15,824:INFO:Copying training dataset
2023-10-23 16:44:15,839:INFO:Checking base model
2023-10-23 16:44:15,839:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 16:44:15,855:INFO:Declaring metric variables
2023-10-23 16:44:15,855:INFO:Defining Hyperparameters
2023-10-23 16:44:16,006:INFO:Tuning with n_jobs=-1
2023-10-23 16:44:16,006:INFO:Initializing RandomizedSearchCV
2023-10-23 16:44:21,095:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:44:21,399:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:44:21,527:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:44:21,637:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:44:21,652:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:44:21,881:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:44:21,921:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:44:24,125:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:44:24,478:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:44:25,159:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:44:43,439:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:44:48,272:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:44:48,537:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:44:48,921:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:44:51,033:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:44:54,505:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:48:00,191:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:48:03,862:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:48:03,937:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:48:05,434:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:48:11,982:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:48:13,103:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:50:15,716:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:50:16,174:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:50:21,182:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:50:23,070:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:51:43,676:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:51:57,315:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:51:58,289:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:52:02,678:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:52:05,465:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:52:06,573:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:52:24,834:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:52:27,383:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:52:31,901:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:52:32,531:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:54:57,007:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:55:09,921:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:55:18,580:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:55:21,535:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:56:54,250:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:57:01,441:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:57:01,977:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:57:03,624:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:57:11,405:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:57:15,485:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:57:39,788:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:57:41,352:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:57:50,599:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:58:03,826:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:58:44,378:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:59:32,699:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 16:59:34,759:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:00:02,101:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:00:40,352:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:00:44,255:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:00:51,078:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:01:19,333:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:01:54,289:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:01:57,915:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:02:11,839:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:02:35,441:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:02:45,828:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:03:09,984:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:03:27,443:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:03:31,706:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:04:27,727:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:04:37,202:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:04:40,837:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:05:04,250:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:05:40,918:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:05:47,633:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:06:26,410:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:06:38,484:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:06:47,128:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:07:15,138:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:08:32,304:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:08:32,924:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:08:37,618:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:08:55,525:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:09:03,558:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:09:05,780:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:09:16,698:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:10:15,078:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:10:35,198:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:10:42,790:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:13:19,840:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:13:25,520:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:13:38,703:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:13:43,661:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:13:49,761:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:14:14,284:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:14:42,741:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:14:44,501:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:15:02,469:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:15:41,642:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:16:04,591:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:16:24,352:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 17:16:32,294:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:15:07,029:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:16:21,562:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-23 18:16:21,625:INFO:Hyperparameter search completed
2023-10-23 18:16:21,625:INFO:SubProcess create_model() called ==================================
2023-10-23 18:16:21,656:INFO:Initializing create_model()
2023-10-23 18:16:21,656:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08C2D2100>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E09705FAF0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-23 18:16:21,656:INFO:Checking exceptions
2023-10-23 18:16:21,656:INFO:Importing libraries
2023-10-23 18:16:21,672:INFO:Copying training dataset
2023-10-23 18:16:21,798:INFO:Defining folds
2023-10-23 18:16:21,814:INFO:Declaring metric variables
2023-10-23 18:16:21,814:INFO:Importing untrained model
2023-10-23 18:16:21,814:INFO:Declaring custom model
2023-10-23 18:16:21,830:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 18:16:21,830:INFO:Starting cross validation
2023-10-23 18:16:21,987:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 18:16:27,454:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:16:28,007:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:16:28,117:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:16:28,458:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:16:28,726:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:16:29,153:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:16:29,511:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:16:29,685:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:16:29,780:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:16:30,032:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:20:19,921:INFO:Calculating mean and std
2023-10-23 18:20:19,955:INFO:Creating metrics dataframe
2023-10-23 18:20:20,056:INFO:Finalizing model
2023-10-23 18:20:22,901:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:21:09,300:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-23 18:21:09,300:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-23 18:21:09,300:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-23 18:21:11,592:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-10-23 18:21:11,604:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-23 18:21:11,604:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-23 18:21:11,604:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-23 18:21:11,847:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.186331 seconds.
2023-10-23 18:21:11,847:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 18:21:11,857:INFO:[LightGBM] [Info] Total Bins 233635
2023-10-23 18:21:11,913:INFO:[LightGBM] [Info] Number of data points in the train set: 21824, number of used features: 1332
2023-10-23 18:21:11,921:INFO:[LightGBM] [Info] Start training from score 87.170575
2023-10-23 18:21:26,235:INFO:Uploading results into container
2023-10-23 18:21:26,235:INFO:Uploading model into container now
2023-10-23 18:21:26,250:INFO:_master_model_container: 2
2023-10-23 18:21:26,252:INFO:_display_container: 3
2023-10-23 18:21:26,257:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-23 18:21:26,257:INFO:create_model() successfully completed......................................
2023-10-23 18:21:27,216:INFO:SubProcess create_model() end ==================================
2023-10-23 18:21:27,218:INFO:choose_better activated
2023-10-23 18:21:27,218:INFO:SubProcess create_model() called ==================================
2023-10-23 18:21:27,220:INFO:Initializing create_model()
2023-10-23 18:21:27,220:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08C2D2100>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 18:21:27,220:INFO:Checking exceptions
2023-10-23 18:21:27,220:INFO:Importing libraries
2023-10-23 18:21:27,220:INFO:Copying training dataset
2023-10-23 18:21:27,291:INFO:Defining folds
2023-10-23 18:21:27,291:INFO:Declaring metric variables
2023-10-23 18:21:27,291:INFO:Importing untrained model
2023-10-23 18:21:27,291:INFO:Declaring custom model
2023-10-23 18:21:27,300:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 18:21:27,300:INFO:Starting cross validation
2023-10-23 18:21:27,320:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 18:21:33,348:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:21:33,453:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:21:34,421:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:21:34,545:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:21:34,878:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:21:34,944:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:21:35,171:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:21:35,211:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:21:35,307:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:21:35,494:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:24:17,309:INFO:Calculating mean and std
2023-10-23 18:24:17,311:INFO:Creating metrics dataframe
2023-10-23 18:24:17,311:INFO:Finalizing model
2023-10-23 18:24:20,073:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:24:56,455:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-10-23 18:24:56,685:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.200380 seconds.
2023-10-23 18:24:56,685:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 18:24:56,694:INFO:[LightGBM] [Info] Total Bins 233817
2023-10-23 18:24:56,714:INFO:[LightGBM] [Info] Number of data points in the train set: 21824, number of used features: 1351
2023-10-23 18:24:56,714:INFO:[LightGBM] [Info] Start training from score 87.170575
2023-10-23 18:25:01,651:INFO:Uploading results into container
2023-10-23 18:25:01,651:INFO:Uploading model into container now
2023-10-23 18:25:01,655:INFO:_master_model_container: 3
2023-10-23 18:25:01,655:INFO:_display_container: 4
2023-10-23 18:25:01,660:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 18:25:01,660:INFO:create_model() successfully completed......................................
2023-10-23 18:25:01,972:INFO:SubProcess create_model() end ==================================
2023-10-23 18:25:01,979:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.877
2023-10-23 18:25:01,979:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8708
2023-10-23 18:25:01,979:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-23 18:25:01,979:INFO:choose_better completed
2023-10-23 18:25:01,979:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-23 18:25:01,979:INFO:Creating Dashboard logs
2023-10-23 18:25:01,979:INFO:Model: Light Gradient Boosting Machine
2023-10-23 18:25:02,156:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 18:25:02,539:INFO:Initializing predict_model()
2023-10-23 18:25:02,539:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08C2D2100>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E0969F8F70>)
2023-10-23 18:25:02,539:INFO:Checking exceptions
2023-10-23 18:25:02,539:INFO:Preloading libraries
2023-10-23 18:25:03,805:INFO:_master_model_container: 3
2023-10-23 18:25:03,805:INFO:_display_container: 3
2023-10-23 18:25:03,805:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 18:25:03,817:INFO:tune_model() successfully completed......................................
2023-10-23 18:25:03,971:INFO:Initializing ensemble_model()
2023-10-23 18:25:03,971:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08C2D2100>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-23 18:25:03,971:INFO:Checking exceptions
2023-10-23 18:25:03,988:INFO:Importing libraries
2023-10-23 18:25:03,988:INFO:Copying training dataset
2023-10-23 18:25:03,988:INFO:Checking base model
2023-10-23 18:25:03,988:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 18:25:03,988:INFO:Importing untrained ensembler
2023-10-23 18:25:03,988:INFO:Ensemble method set to Bagging
2023-10-23 18:25:03,988:INFO:SubProcess create_model() called ==================================
2023-10-23 18:25:03,988:INFO:Initializing create_model()
2023-10-23 18:25:03,988:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08C2D2100>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E09705FAF0>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 18:25:03,988:INFO:Checking exceptions
2023-10-23 18:25:03,988:INFO:Importing libraries
2023-10-23 18:25:03,988:INFO:Copying training dataset
2023-10-23 18:25:04,029:INFO:Defining folds
2023-10-23 18:25:04,029:INFO:Declaring metric variables
2023-10-23 18:25:04,029:INFO:Importing untrained model
2023-10-23 18:25:04,029:INFO:Declaring custom model
2023-10-23 18:25:04,031:INFO:Bagging Regressor Imported successfully
2023-10-23 18:25:04,031:INFO:Starting cross validation
2023-10-23 18:25:04,045:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 18:25:07,018:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:25:07,153:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:25:07,207:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:25:07,232:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:25:17,142:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:25:17,174:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:25:17,246:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:25:17,442:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:25:17,526:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:25:17,611:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:36:19,770:INFO:Calculating mean and std
2023-10-23 18:36:19,775:INFO:Creating metrics dataframe
2023-10-23 18:36:19,782:INFO:Finalizing model
2023-10-23 18:36:21,249:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:36:50,229:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.195797 seconds.
2023-10-23 18:36:50,230:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 18:36:50,241:INFO:[LightGBM] [Info] Total Bins 233817
2023-10-23 18:36:50,254:INFO:[LightGBM] [Info] Number of data points in the train set: 21824, number of used features: 1351
2023-10-23 18:36:50,261:INFO:[LightGBM] [Info] Start training from score 86.477747
2023-10-23 18:36:55,962:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.189669 seconds.
2023-10-23 18:36:55,962:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 18:36:55,975:INFO:[LightGBM] [Info] Total Bins 233817
2023-10-23 18:36:55,989:INFO:[LightGBM] [Info] Number of data points in the train set: 21824, number of used features: 1351
2023-10-23 18:36:55,995:INFO:[LightGBM] [Info] Start training from score 87.868417
2023-10-23 18:37:01,666:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.174560 seconds.
2023-10-23 18:37:01,666:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 18:37:01,677:INFO:[LightGBM] [Info] Total Bins 233817
2023-10-23 18:37:01,690:INFO:[LightGBM] [Info] Number of data points in the train set: 21824, number of used features: 1351
2023-10-23 18:37:01,696:INFO:[LightGBM] [Info] Start training from score 86.796000
2023-10-23 18:37:07,662:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.184517 seconds.
2023-10-23 18:37:07,662:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 18:37:07,674:INFO:[LightGBM] [Info] Total Bins 233817
2023-10-23 18:37:07,688:INFO:[LightGBM] [Info] Number of data points in the train set: 21824, number of used features: 1351
2023-10-23 18:37:07,695:INFO:[LightGBM] [Info] Start training from score 86.556618
2023-10-23 18:37:13,681:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.175294 seconds.
2023-10-23 18:37:13,681:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 18:37:13,691:INFO:[LightGBM] [Info] Total Bins 233817
2023-10-23 18:37:13,705:INFO:[LightGBM] [Info] Number of data points in the train set: 21824, number of used features: 1351
2023-10-23 18:37:13,711:INFO:[LightGBM] [Info] Start training from score 89.020029
2023-10-23 18:37:19,244:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.183865 seconds.
2023-10-23 18:37:19,244:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 18:37:19,255:INFO:[LightGBM] [Info] Total Bins 233817
2023-10-23 18:37:19,268:INFO:[LightGBM] [Info] Number of data points in the train set: 21824, number of used features: 1351
2023-10-23 18:37:19,274:INFO:[LightGBM] [Info] Start training from score 86.056933
2023-10-23 18:37:24,815:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.183615 seconds.
2023-10-23 18:37:24,815:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 18:37:24,827:INFO:[LightGBM] [Info] Total Bins 233817
2023-10-23 18:37:24,840:INFO:[LightGBM] [Info] Number of data points in the train set: 21824, number of used features: 1351
2023-10-23 18:37:24,847:INFO:[LightGBM] [Info] Start training from score 86.291382
2023-10-23 18:37:30,458:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.196630 seconds.
2023-10-23 18:37:30,458:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 18:37:30,469:INFO:[LightGBM] [Info] Total Bins 233817
2023-10-23 18:37:30,482:INFO:[LightGBM] [Info] Number of data points in the train set: 21824, number of used features: 1351
2023-10-23 18:37:30,488:INFO:[LightGBM] [Info] Start training from score 87.596713
2023-10-23 18:37:36,160:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.182475 seconds.
2023-10-23 18:37:36,160:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 18:37:36,172:INFO:[LightGBM] [Info] Total Bins 233817
2023-10-23 18:37:36,185:INFO:[LightGBM] [Info] Number of data points in the train set: 21824, number of used features: 1351
2023-10-23 18:37:36,191:INFO:[LightGBM] [Info] Start training from score 87.740429
2023-10-23 18:37:41,849:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.196867 seconds.
2023-10-23 18:37:41,849:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 18:37:41,862:INFO:[LightGBM] [Info] Total Bins 233817
2023-10-23 18:37:41,874:INFO:[LightGBM] [Info] Number of data points in the train set: 21824, number of used features: 1351
2023-10-23 18:37:41,881:INFO:[LightGBM] [Info] Start training from score 86.778880
2023-10-23 18:40:51,636:INFO:Uploading results into container
2023-10-23 18:40:51,637:INFO:Uploading model into container now
2023-10-23 18:40:51,639:INFO:_master_model_container: 4
2023-10-23 18:40:51,639:INFO:_display_container: 4
2023-10-23 18:40:51,641:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 18:40:51,641:INFO:create_model() successfully completed......................................
2023-10-23 18:40:51,829:INFO:SubProcess create_model() end ==================================
2023-10-23 18:40:51,830:INFO:Creating Dashboard logs
2023-10-23 18:40:51,831:INFO:Model: Bagging Regressor
2023-10-23 18:40:51,954:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-23 18:40:52,357:INFO:Initializing predict_model()
2023-10-23 18:40:52,358:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08C2D2100>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096BE3040>)
2023-10-23 18:40:52,358:INFO:Checking exceptions
2023-10-23 18:40:52,358:INFO:Preloading libraries
2023-10-23 18:40:55,928:INFO:_master_model_container: 4
2023-10-23 18:40:55,929:INFO:_display_container: 4
2023-10-23 18:40:55,930:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 18:40:55,930:INFO:ensemble_model() successfully completed......................................
2023-10-23 18:40:56,043:INFO:Initializing finalize_model()
2023-10-23 18:40:56,043:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08C2D2100>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-23 18:40:56,044:INFO:Finalizing BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 18:40:56,061:INFO:Initializing create_model()
2023-10-23 18:40:56,061:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08C2D2100>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-23 18:40:56,061:INFO:Checking exceptions
2023-10-23 18:40:56,062:INFO:Importing libraries
2023-10-23 18:40:56,063:INFO:Copying training dataset
2023-10-23 18:40:56,064:INFO:Defining folds
2023-10-23 18:40:56,064:INFO:Declaring metric variables
2023-10-23 18:40:56,065:INFO:Importing untrained model
2023-10-23 18:40:56,065:INFO:Declaring custom model
2023-10-23 18:40:56,066:INFO:Bagging Regressor Imported successfully
2023-10-23 18:40:56,085:INFO:Cross validation set to False
2023-10-23 18:40:56,085:INFO:Fitting Model
2023-10-23 18:40:58,128:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:41:42,111:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.256464 seconds.
2023-10-23 18:41:42,111:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 18:41:42,128:INFO:[LightGBM] [Info] Total Bins 238615
2023-10-23 18:41:42,142:INFO:[LightGBM] [Info] Number of data points in the train set: 31178, number of used features: 1351
2023-10-23 18:41:42,150:INFO:[LightGBM] [Info] Start training from score 87.615090
2023-10-23 18:41:50,267:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.262954 seconds.
2023-10-23 18:41:50,268:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 18:41:50,285:INFO:[LightGBM] [Info] Total Bins 238615
2023-10-23 18:41:50,300:INFO:[LightGBM] [Info] Number of data points in the train set: 31178, number of used features: 1351
2023-10-23 18:41:50,308:INFO:[LightGBM] [Info] Start training from score 88.439914
2023-10-23 18:41:57,952:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.244242 seconds.
2023-10-23 18:41:57,952:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 18:41:57,970:INFO:[LightGBM] [Info] Total Bins 238615
2023-10-23 18:41:57,986:INFO:[LightGBM] [Info] Number of data points in the train set: 31178, number of used features: 1351
2023-10-23 18:41:57,994:INFO:[LightGBM] [Info] Start training from score 88.578185
2023-10-23 18:42:05,535:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.249489 seconds.
2023-10-23 18:42:05,535:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 18:42:05,554:INFO:[LightGBM] [Info] Total Bins 238615
2023-10-23 18:42:05,570:INFO:[LightGBM] [Info] Number of data points in the train set: 31178, number of used features: 1351
2023-10-23 18:42:05,576:INFO:[LightGBM] [Info] Start training from score 87.647904
2023-10-23 18:42:12,780:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.258439 seconds.
2023-10-23 18:42:12,780:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 18:42:12,799:INFO:[LightGBM] [Info] Total Bins 238615
2023-10-23 18:42:12,814:INFO:[LightGBM] [Info] Number of data points in the train set: 31178, number of used features: 1351
2023-10-23 18:42:12,821:INFO:[LightGBM] [Info] Start training from score 86.973206
2023-10-23 18:42:19,675:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.238736 seconds.
2023-10-23 18:42:19,675:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 18:42:19,690:INFO:[LightGBM] [Info] Total Bins 238615
2023-10-23 18:42:19,703:INFO:[LightGBM] [Info] Number of data points in the train set: 31178, number of used features: 1351
2023-10-23 18:42:19,710:INFO:[LightGBM] [Info] Start training from score 87.270872
2023-10-23 18:42:26,560:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.233831 seconds.
2023-10-23 18:42:26,560:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 18:42:26,576:INFO:[LightGBM] [Info] Total Bins 238615
2023-10-23 18:42:26,590:INFO:[LightGBM] [Info] Number of data points in the train set: 31178, number of used features: 1351
2023-10-23 18:42:26,597:INFO:[LightGBM] [Info] Start training from score 88.951808
2023-10-23 18:42:33,387:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.219145 seconds.
2023-10-23 18:42:33,387:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 18:42:33,408:INFO:[LightGBM] [Info] Total Bins 238615
2023-10-23 18:42:33,422:INFO:[LightGBM] [Info] Number of data points in the train set: 31178, number of used features: 1351
2023-10-23 18:42:33,428:INFO:[LightGBM] [Info] Start training from score 87.237123
2023-10-23 18:42:40,302:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.222826 seconds.
2023-10-23 18:42:40,303:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 18:42:40,320:INFO:[LightGBM] [Info] Total Bins 238615
2023-10-23 18:42:40,332:INFO:[LightGBM] [Info] Number of data points in the train set: 31178, number of used features: 1351
2023-10-23 18:42:40,338:INFO:[LightGBM] [Info] Start training from score 88.094591
2023-10-23 18:42:47,044:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.238970 seconds.
2023-10-23 18:42:47,044:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 18:42:47,060:INFO:[LightGBM] [Info] Total Bins 238615
2023-10-23 18:42:47,073:INFO:[LightGBM] [Info] Number of data points in the train set: 31178, number of used features: 1351
2023-10-23 18:42:47,079:INFO:[LightGBM] [Info] Start training from score 88.130873
2023-10-23 18:42:52,224:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_...
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 18:42:52,224:INFO:create_model() successfully completed......................................
2023-10-23 18:42:52,333:INFO:Creating Dashboard logs
2023-10-23 18:42:52,334:INFO:Model: Bagging Regressor
2023-10-23 18:42:52,415:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-23 18:42:52,867:INFO:_master_model_container: 4
2023-10-23 18:42:52,867:INFO:_display_container: 4
2023-10-23 18:42:53,010:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_...
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 18:42:53,010:INFO:finalize_model() successfully completed......................................
2023-10-23 18:42:53,399:INFO:Initializing save_model()
2023-10-23 18:42:53,400:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_...
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), model_name=final_model_for_location_B, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_ene...
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 18:42:53,400:INFO:Adding model into prep_pipe
2023-10-23 18:42:53,400:WARNING:Only Model saved as it was a pipeline.
2023-10-23 18:42:53,585:INFO:final_model_for_location_B.pkl saved in current working directory
2023-10-23 18:42:53,727:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_...
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 18:42:53,727:INFO:save_model() successfully completed......................................
2023-10-23 18:42:53,940:INFO:PyCaret RegressionExperiment
2023-10-23 18:42:53,940:INFO:Logging name: exp_C
2023-10-23 18:42:53,941:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 18:42:53,941:INFO:version 3.1.0
2023-10-23 18:42:53,941:INFO:Initializing setup()
2023-10-23 18:42:53,941:INFO:self.USI: c25c
2023-10-23 18:42:53,941:INFO:self._variable_keys: {'gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', '_ml_usecase', 'gpu_param', 'exp_name_log', 'html_param', 'fold_generator', 'y', 'seed', 'y_train', 'transform_target_param', 'n_jobs_param', 'target_param', 'idx', '_available_plots', 'log_plots_param', 'memory', 'data', 'USI', 'X', 'logging_param', 'pipeline', 'exp_id', 'X_train', 'X_test', 'fold_groups_param'}
2023-10-23 18:42:53,941:INFO:Checking environment
2023-10-23 18:42:53,941:INFO:python_version: 3.8.18
2023-10-23 18:42:53,941:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 18:42:53,941:INFO:machine: AMD64
2023-10-23 18:42:53,941:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 18:42:53,941:INFO:Memory: svmem(total=16505954304, available=6493900800, percent=60.7, used=10012053504, free=6493900800)
2023-10-23 18:42:53,942:INFO:Physical Core: 8
2023-10-23 18:42:53,942:INFO:Logical Core: 16
2023-10-23 18:42:53,942:INFO:Checking libraries
2023-10-23 18:42:53,942:INFO:System:
2023-10-23 18:42:53,942:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 18:42:53,942:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 18:42:53,942:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 18:42:53,942:INFO:PyCaret required dependencies:
2023-10-23 18:42:53,942:INFO:                 pip: 23.3
2023-10-23 18:42:53,943:INFO:          setuptools: 68.0.0
2023-10-23 18:42:53,943:INFO:             pycaret: 3.1.0
2023-10-23 18:42:53,943:INFO:             IPython: 8.12.0
2023-10-23 18:42:53,943:INFO:          ipywidgets: 8.1.1
2023-10-23 18:42:53,943:INFO:                tqdm: 4.66.1
2023-10-23 18:42:53,943:INFO:               numpy: 1.23.5
2023-10-23 18:42:53,943:INFO:              pandas: 1.5.3
2023-10-23 18:42:53,943:INFO:              jinja2: 3.1.2
2023-10-23 18:42:53,943:INFO:               scipy: 1.10.1
2023-10-23 18:42:53,943:INFO:              joblib: 1.3.2
2023-10-23 18:42:53,943:INFO:             sklearn: 1.2.2
2023-10-23 18:42:53,943:INFO:                pyod: 1.1.0
2023-10-23 18:42:53,943:INFO:            imblearn: 0.11.0
2023-10-23 18:42:53,943:INFO:   category_encoders: 2.6.2
2023-10-23 18:42:53,943:INFO:            lightgbm: 4.1.0
2023-10-23 18:42:53,943:INFO:               numba: 0.58.1
2023-10-23 18:42:53,943:INFO:            requests: 2.31.0
2023-10-23 18:42:53,944:INFO:          matplotlib: 3.7.3
2023-10-23 18:42:53,944:INFO:          scikitplot: 0.3.7
2023-10-23 18:42:53,944:INFO:         yellowbrick: 1.5
2023-10-23 18:42:53,944:INFO:              plotly: 5.17.0
2023-10-23 18:42:53,944:INFO:    plotly-resampler: Not installed
2023-10-23 18:42:53,944:INFO:             kaleido: 0.2.1
2023-10-23 18:42:53,944:INFO:           schemdraw: 0.15
2023-10-23 18:42:53,944:INFO:         statsmodels: 0.14.0
2023-10-23 18:42:53,944:INFO:              sktime: 0.21.1
2023-10-23 18:42:53,944:INFO:               tbats: 1.1.3
2023-10-23 18:42:53,944:INFO:            pmdarima: 2.0.3
2023-10-23 18:42:53,944:INFO:              psutil: 5.9.0
2023-10-23 18:42:53,944:INFO:          markupsafe: 2.1.3
2023-10-23 18:42:53,944:INFO:             pickle5: Not installed
2023-10-23 18:42:53,944:INFO:         cloudpickle: 2.2.1
2023-10-23 18:42:53,944:INFO:         deprecation: 2.1.0
2023-10-23 18:42:53,944:INFO:              xxhash: 3.4.1
2023-10-23 18:42:53,944:INFO:           wurlitzer: Not installed
2023-10-23 18:42:53,944:INFO:PyCaret optional dependencies:
2023-10-23 18:42:53,945:INFO:                shap: Not installed
2023-10-23 18:42:53,945:INFO:           interpret: Not installed
2023-10-23 18:42:53,945:INFO:                umap: Not installed
2023-10-23 18:42:53,945:INFO:     ydata_profiling: Not installed
2023-10-23 18:42:53,945:INFO:  explainerdashboard: Not installed
2023-10-23 18:42:53,945:INFO:             autoviz: Not installed
2023-10-23 18:42:53,945:INFO:           fairlearn: Not installed
2023-10-23 18:42:53,945:INFO:          deepchecks: Not installed
2023-10-23 18:42:53,945:INFO:             xgboost: Not installed
2023-10-23 18:42:53,945:INFO:            catboost: 1.2.2
2023-10-23 18:42:53,945:INFO:              kmodes: Not installed
2023-10-23 18:42:53,945:INFO:             mlxtend: Not installed
2023-10-23 18:42:53,945:INFO:       statsforecast: Not installed
2023-10-23 18:42:53,945:INFO:        tune_sklearn: Not installed
2023-10-23 18:42:53,945:INFO:                 ray: Not installed
2023-10-23 18:42:53,945:INFO:            hyperopt: Not installed
2023-10-23 18:42:53,945:INFO:              optuna: Not installed
2023-10-23 18:42:53,946:INFO:               skopt: Not installed
2023-10-23 18:42:53,946:INFO:              mlflow: 2.7.1
2023-10-23 18:42:53,946:INFO:              gradio: Not installed
2023-10-23 18:42:53,946:INFO:             fastapi: Not installed
2023-10-23 18:42:53,946:INFO:             uvicorn: Not installed
2023-10-23 18:42:53,946:INFO:              m2cgen: Not installed
2023-10-23 18:42:53,946:INFO:           evidently: Not installed
2023-10-23 18:42:53,946:INFO:               fugue: Not installed
2023-10-23 18:42:53,946:INFO:           streamlit: Not installed
2023-10-23 18:42:53,946:INFO:             prophet: Not installed
2023-10-23 18:42:53,946:INFO:None
2023-10-23 18:42:53,946:INFO:Set up data.
2023-10-23 18:42:53,986:INFO:Set up folding strategy.
2023-10-23 18:42:53,986:INFO:Set up train/test split.
2023-10-23 18:42:54,013:INFO:Set up index.
2023-10-23 18:42:54,016:INFO:Assigning column types.
2023-10-23 18:42:54,036:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 18:42:54,037:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 18:42:54,042:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 18:42:54,047:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 18:42:54,126:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 18:42:54,176:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 18:42:54,176:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 18:42:54,177:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 18:42:54,178:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 18:42:54,185:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 18:42:54,191:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 18:42:54,292:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 18:42:54,351:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 18:42:54,352:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 18:42:54,352:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 18:42:54,353:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 18:42:54,358:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 18:42:54,364:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 18:42:54,451:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 18:42:54,510:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 18:42:54,511:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 18:42:54,511:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 18:42:54,519:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 18:42:54,527:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 18:42:54,618:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 18:42:54,681:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 18:42:54,682:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 18:42:54,682:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 18:42:54,683:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 18:42:54,693:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 18:42:54,784:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 18:42:54,847:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 18:42:54,850:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 18:42:54,851:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 18:42:54,866:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 18:42:54,976:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 18:42:55,032:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 18:42:55,033:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 18:42:55,033:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 18:42:55,034:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 18:42:55,126:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 18:42:55,178:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 18:42:55,179:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 18:42:55,179:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 18:42:55,269:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 18:42:55,366:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 18:42:55,366:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 18:42:55,366:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 18:42:55,367:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 18:42:55,466:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 18:42:55,520:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 18:42:55,520:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 18:42:55,613:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 18:42:55,664:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 18:42:55,664:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 18:42:55,665:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 18:42:55,817:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 18:42:55,818:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 18:42:55,977:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 18:42:55,978:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 18:42:55,988:INFO:Preparing preprocessing pipeline...
2023-10-23 18:42:55,988:INFO:Set up date feature engineering.
2023-10-23 18:42:55,989:INFO:Set up simple imputation.
2023-10-23 18:42:56,003:INFO:Set up encoding of ordinal features.
2023-10-23 18:42:56,027:INFO:Set up encoding of categorical features.
2023-10-23 18:42:56,027:INFO:Set up polynomial features.
2023-10-23 18:42:56,027:INFO:Set up removing outliers.
2023-10-23 18:42:56,031:INFO:Set up column name cleaning.
2023-10-23 18:42:57,463:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:43:21,114:INFO:Finished creating preprocessing pipeline.
2023-10-23 18:43:21,262:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_ene...
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 18:43:21,263:INFO:Creating final display dataframe.
2023-10-23 18:43:22,194:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:43:47,289:INFO:Setup _display_container:                     Description          Value
0                    Session id            123
1                        Target         target
2                   Target type     Regression
3           Original data shape    (26071, 52)
4        Transformed data shape  (25158, 1540)
5   Transformed train set shape  (17336, 1540)
6    Transformed test set shape   (7822, 1540)
7              Ordinal features              4
8              Numeric features             44
9                 Date features              3
10         Categorical features              4
11     Rows with missing values          92.4%
12                   Preprocess           True
13              Imputation type         simple
14           Numeric imputation           mean
15       Categorical imputation           mode
16     Maximum one-hot encoding             25
17              Encoding method           None
18          Polynomial features           True
19            Polynomial degree              2
20              Remove outliers           True
21           Outliers threshold           0.05
22               Fold Generator          KFold
23                  Fold Number             10
24                     CPU Jobs             -1
25                      Use GPU          False
26               Log Experiment   MlflowLogger
27              Experiment Name          exp_C
28                          USI           c25c
2023-10-23 18:43:47,453:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 18:43:47,453:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 18:43:47,610:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 18:43:47,611:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 18:43:47,612:INFO:Logging experiment in loggers
2023-10-23 18:43:47,775:INFO:SubProcess save_model() called ==================================
2023-10-23 18:43:48,004:INFO:Initializing save_model()
2023-10-23 18:43:48,004:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_ene...
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmpowfahtnk\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_ene...
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 18:43:48,004:INFO:Adding model into prep_pipe
2023-10-23 18:43:48,004:WARNING:Only Model saved as it was a pipeline.
2023-10-23 18:43:48,091:INFO:C:\Users\thoma\AppData\Local\Temp\tmpowfahtnk\Transformation Pipeline.pkl saved in current working directory
2023-10-23 18:43:48,222:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_ene...
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 18:43:48,223:INFO:save_model() successfully completed......................................
2023-10-23 18:43:48,350:INFO:SubProcess save_model() end ==================================
2023-10-23 18:43:48,432:INFO:setup() successfully completed in 53.68s...............
2023-10-23 18:43:48,432:INFO:Initializing create_model()
2023-10-23 18:43:48,433:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08966F460>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 18:43:48,433:INFO:Checking exceptions
2023-10-23 18:43:48,436:INFO:Importing libraries
2023-10-23 18:43:48,436:INFO:Copying training dataset
2023-10-23 18:43:48,461:INFO:Defining folds
2023-10-23 18:43:48,462:INFO:Declaring metric variables
2023-10-23 18:43:48,462:INFO:Importing untrained model
2023-10-23 18:43:48,463:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 18:43:48,463:INFO:Starting cross validation
2023-10-23 18:43:48,483:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 18:43:52,661:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:43:52,986:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:43:53,845:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:43:54,731:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:43:54,836:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:43:55,056:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:43:55,227:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:43:55,227:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:43:55,260:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:43:55,258:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:46:13,610:INFO:Calculating mean and std
2023-10-23 18:46:13,612:INFO:Creating metrics dataframe
2023-10-23 18:46:13,612:INFO:Finalizing model
2023-10-23 18:46:14,977:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:46:38,211:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-10-23 18:46:38,391:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.157900 seconds.
2023-10-23 18:46:38,391:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 18:46:38,391:INFO:[LightGBM] [Info] Total Bins 251738
2023-10-23 18:46:38,412:INFO:[LightGBM] [Info] Number of data points in the train set: 17336, number of used features: 1429
2023-10-23 18:46:38,423:INFO:[LightGBM] [Info] Start training from score 68.816679
2023-10-23 18:46:42,686:INFO:Creating Dashboard logs
2023-10-23 18:46:42,686:INFO:Model: Light Gradient Boosting Machine
2023-10-23 18:46:42,771:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 18:46:42,973:INFO:Initializing predict_model()
2023-10-23 18:46:42,973:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08966F460>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E08C5764C0>)
2023-10-23 18:46:42,973:INFO:Checking exceptions
2023-10-23 18:46:42,973:INFO:Preloading libraries
2023-10-23 18:46:43,920:INFO:Uploading results into container
2023-10-23 18:46:43,920:INFO:Uploading model into container now
2023-10-23 18:46:43,920:INFO:_master_model_container: 1
2023-10-23 18:46:43,920:INFO:_display_container: 2
2023-10-23 18:46:43,920:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 18:46:43,920:INFO:create_model() successfully completed......................................
2023-10-23 18:46:44,050:INFO:Initializing tune_model()
2023-10-23 18:46:44,050:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08966F460>)
2023-10-23 18:46:44,050:INFO:Checking exceptions
2023-10-23 18:46:44,053:INFO:Copying training dataset
2023-10-23 18:46:44,069:INFO:Checking base model
2023-10-23 18:46:44,069:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 18:46:44,069:INFO:Declaring metric variables
2023-10-23 18:46:44,069:INFO:Defining Hyperparameters
2023-10-23 18:46:44,219:INFO:Tuning with n_jobs=-1
2023-10-23 18:46:44,219:INFO:Initializing RandomizedSearchCV
2023-10-23 18:46:48,984:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:46:49,023:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:46:49,031:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:46:49,160:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:46:49,176:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:46:49,255:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:46:49,419:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:46:49,492:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:46:49,547:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:46:49,639:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:47:03,387:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:47:06,880:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:47:07,099:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:47:09,965:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:47:10,113:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:47:10,395:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:49:41,240:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:49:42,113:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:49:44,247:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:49:44,670:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:49:46,361:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 18:49:53,829:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:41:03,782:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:41:04,054:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:41:04,453:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:42:22,542:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:42:28,850:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:42:28,861:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:42:35,608:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:42:38,516:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:42:38,508:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:43:48,070:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:43:53,459:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:43:57,210:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:44:51,717:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:45:20,384:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:45:43,582:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:46:12,734:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:46:22,176:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:46:35,943:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:47:12,819:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:47:28,842:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:47:36,591:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:47:54,148:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:47:54,389:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:47:57,270:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:48:01,542:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:48:36,450:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:49:07,622:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:49:21,749:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:49:34,161:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:50:04,592:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:50:12,003:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:50:32,836:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:50:39,216:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:50:41,428:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:51:13,307:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:51:41,060:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:51:45,548:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:51:51,715:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:52:03,670:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:52:12,786:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:52:53,521:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:53:04,036:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:53:05,584:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:53:50,789:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:54:00,638:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:54:03,095:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:54:39,191:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:54:55,050:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:54:59,341:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:55:39,683:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:55:46,818:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:55:53,387:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:56:30,557:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:57:16,136:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:57:45,262:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:57:51,520:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:58:10,942:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:58:25,800:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:58:27,095:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:58:32,893:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:58:37,182:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:59:48,081:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 19:59:50,693:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:00:08,761:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:00:09,917:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:00:32,804:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:00:44,783:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:01:14,770:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:01:56,811:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:02:15,739:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:02:19,549:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:02:29,053:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:02:43,790:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:03:42,467:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:03:46,430:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:03:47,660:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:04:04,203:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:05:13,755:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-23 20:05:13,833:INFO:Hyperparameter search completed
2023-10-23 20:05:13,834:INFO:SubProcess create_model() called ==================================
2023-10-23 20:05:13,856:INFO:Initializing create_model()
2023-10-23 20:05:13,863:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08966F460>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E096C66400>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-23 20:05:13,864:INFO:Checking exceptions
2023-10-23 20:05:13,868:INFO:Importing libraries
2023-10-23 20:05:13,871:INFO:Copying training dataset
2023-10-23 20:05:14,026:INFO:Defining folds
2023-10-23 20:05:14,027:INFO:Declaring metric variables
2023-10-23 20:05:14,035:INFO:Importing untrained model
2023-10-23 20:05:14,035:INFO:Declaring custom model
2023-10-23 20:05:14,041:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 20:05:14,041:INFO:Starting cross validation
2023-10-23 20:05:14,216:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 20:05:17,486:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:05:17,642:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:05:17,642:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:05:17,719:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:05:17,750:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:05:17,766:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:05:17,782:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:05:17,813:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:05:17,882:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:05:17,924:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:07:53,776:INFO:Calculating mean and std
2023-10-23 20:07:53,776:INFO:Creating metrics dataframe
2023-10-23 20:07:53,806:INFO:Finalizing model
2023-10-23 20:07:55,273:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:08:17,189:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-23 20:08:17,189:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-23 20:08:17,189:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-23 20:08:18,372:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-10-23 20:08:18,372:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-23 20:08:18,372:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-23 20:08:18,372:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-23 20:08:18,508:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.094758 seconds.
2023-10-23 20:08:18,508:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 20:08:18,524:INFO:[LightGBM] [Info] Total Bins 251542
2023-10-23 20:08:18,555:INFO:[LightGBM] [Info] Number of data points in the train set: 17336, number of used features: 1408
2023-10-23 20:08:18,562:INFO:[LightGBM] [Info] Start training from score 68.816679
2023-10-23 20:08:18,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 20:08:18,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 20:08:18,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 20:08:18,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 20:08:18,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 20:08:18,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 20:08:18,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 20:08:18,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 20:08:18,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 20:08:18,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 20:08:27,750:INFO:Uploading results into container
2023-10-23 20:08:27,752:INFO:Uploading model into container now
2023-10-23 20:08:27,753:INFO:_master_model_container: 2
2023-10-23 20:08:27,753:INFO:_display_container: 3
2023-10-23 20:08:27,753:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-23 20:08:27,753:INFO:create_model() successfully completed......................................
2023-10-23 20:08:28,147:INFO:SubProcess create_model() end ==================================
2023-10-23 20:08:28,147:INFO:choose_better activated
2023-10-23 20:08:28,147:INFO:SubProcess create_model() called ==================================
2023-10-23 20:08:28,147:INFO:Initializing create_model()
2023-10-23 20:08:28,147:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08966F460>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 20:08:28,147:INFO:Checking exceptions
2023-10-23 20:08:28,147:INFO:Importing libraries
2023-10-23 20:08:28,147:INFO:Copying training dataset
2023-10-23 20:08:28,180:INFO:Defining folds
2023-10-23 20:08:28,180:INFO:Declaring metric variables
2023-10-23 20:08:28,180:INFO:Importing untrained model
2023-10-23 20:08:28,181:INFO:Declaring custom model
2023-10-23 20:08:28,182:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 20:08:28,182:INFO:Starting cross validation
2023-10-23 20:08:28,200:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 20:08:30,979:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:08:31,051:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:08:31,095:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:08:31,095:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:08:31,178:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:08:31,281:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:08:31,297:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:08:31,395:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:08:31,411:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:08:31,428:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:10:28,193:INFO:Calculating mean and std
2023-10-23 20:10:28,193:INFO:Creating metrics dataframe
2023-10-23 20:10:28,193:INFO:Finalizing model
2023-10-23 20:10:29,346:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:10:53,172:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-10-23 20:10:53,361:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.172845 seconds.
2023-10-23 20:10:53,361:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 20:10:53,376:INFO:[LightGBM] [Info] Total Bins 251738
2023-10-23 20:10:53,392:INFO:[LightGBM] [Info] Number of data points in the train set: 17336, number of used features: 1429
2023-10-23 20:10:53,392:INFO:[LightGBM] [Info] Start training from score 68.816679
2023-10-23 20:10:57,767:INFO:Uploading results into container
2023-10-23 20:10:57,769:INFO:Uploading model into container now
2023-10-23 20:10:57,769:INFO:_master_model_container: 3
2023-10-23 20:10:57,769:INFO:_display_container: 4
2023-10-23 20:10:57,770:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 20:10:57,770:INFO:create_model() successfully completed......................................
2023-10-23 20:10:57,906:INFO:SubProcess create_model() end ==================================
2023-10-23 20:10:57,908:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.9059
2023-10-23 20:10:57,908:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8962
2023-10-23 20:10:57,908:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-23 20:10:57,908:INFO:choose_better completed
2023-10-23 20:10:57,908:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-23 20:10:57,908:INFO:Creating Dashboard logs
2023-10-23 20:10:57,908:INFO:Model: Light Gradient Boosting Machine
2023-10-23 20:10:58,039:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 20:10:58,299:INFO:Initializing predict_model()
2023-10-23 20:10:58,299:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08966F460>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E08AA90EE0>)
2023-10-23 20:10:58,299:INFO:Checking exceptions
2023-10-23 20:10:58,300:INFO:Preloading libraries
2023-10-23 20:10:59,360:INFO:_master_model_container: 3
2023-10-23 20:10:59,360:INFO:_display_container: 3
2023-10-23 20:10:59,360:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 20:10:59,360:INFO:tune_model() successfully completed......................................
2023-10-23 20:10:59,472:INFO:Initializing ensemble_model()
2023-10-23 20:10:59,472:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08966F460>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-23 20:10:59,472:INFO:Checking exceptions
2023-10-23 20:10:59,472:INFO:Importing libraries
2023-10-23 20:10:59,472:INFO:Copying training dataset
2023-10-23 20:10:59,472:INFO:Checking base model
2023-10-23 20:10:59,472:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 20:10:59,488:INFO:Importing untrained ensembler
2023-10-23 20:10:59,488:INFO:Ensemble method set to Bagging
2023-10-23 20:10:59,488:INFO:SubProcess create_model() called ==================================
2023-10-23 20:10:59,489:INFO:Initializing create_model()
2023-10-23 20:10:59,489:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08966F460>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E096EBDF40>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 20:10:59,489:INFO:Checking exceptions
2023-10-23 20:10:59,489:INFO:Importing libraries
2023-10-23 20:10:59,489:INFO:Copying training dataset
2023-10-23 20:10:59,513:INFO:Defining folds
2023-10-23 20:10:59,514:INFO:Declaring metric variables
2023-10-23 20:10:59,514:INFO:Importing untrained model
2023-10-23 20:10:59,514:INFO:Declaring custom model
2023-10-23 20:10:59,515:INFO:Bagging Regressor Imported successfully
2023-10-23 20:10:59,516:INFO:Starting cross validation
2023-10-23 20:10:59,536:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 20:11:02,741:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:11:02,757:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:11:02,773:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:11:02,796:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:11:02,838:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:11:02,846:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:11:02,846:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:11:03,079:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:11:03,111:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:11:03,111:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:20:33,604:INFO:Calculating mean and std
2023-10-23 20:20:33,608:INFO:Creating metrics dataframe
2023-10-23 20:20:33,613:INFO:Finalizing model
2023-10-23 20:20:34,929:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:20:57,980:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.163917 seconds.
2023-10-23 20:20:57,980:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 20:20:57,993:INFO:[LightGBM] [Info] Total Bins 251738
2023-10-23 20:20:58,008:INFO:[LightGBM] [Info] Number of data points in the train set: 17336, number of used features: 1429
2023-10-23 20:20:58,016:INFO:[LightGBM] [Info] Start training from score 68.128391
2023-10-23 20:21:03,674:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.170095 seconds.
2023-10-23 20:21:03,675:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 20:21:03,686:INFO:[LightGBM] [Info] Total Bins 251738
2023-10-23 20:21:03,700:INFO:[LightGBM] [Info] Number of data points in the train set: 17336, number of used features: 1429
2023-10-23 20:21:03,707:INFO:[LightGBM] [Info] Start training from score 67.944566
2023-10-23 20:21:13,033:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.168761 seconds.
2023-10-23 20:21:13,034:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 20:21:13,045:INFO:[LightGBM] [Info] Total Bins 251738
2023-10-23 20:21:13,059:INFO:[LightGBM] [Info] Number of data points in the train set: 17336, number of used features: 1429
2023-10-23 20:21:13,066:INFO:[LightGBM] [Info] Start training from score 67.708130
2023-10-23 20:21:18,254:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.157809 seconds.
2023-10-23 20:21:18,254:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 20:21:18,266:INFO:[LightGBM] [Info] Total Bins 251738
2023-10-23 20:21:18,280:INFO:[LightGBM] [Info] Number of data points in the train set: 17336, number of used features: 1429
2023-10-23 20:21:18,287:INFO:[LightGBM] [Info] Start training from score 67.881912
2023-10-23 20:21:23,431:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.160299 seconds.
2023-10-23 20:21:23,431:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 20:21:23,440:INFO:[LightGBM] [Info] Total Bins 251738
2023-10-23 20:21:23,455:INFO:[LightGBM] [Info] Number of data points in the train set: 17336, number of used features: 1429
2023-10-23 20:21:23,462:INFO:[LightGBM] [Info] Start training from score 67.254592
2023-10-23 20:21:28,612:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.157486 seconds.
2023-10-23 20:21:28,612:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 20:21:28,622:INFO:[LightGBM] [Info] Total Bins 251738
2023-10-23 20:21:28,637:INFO:[LightGBM] [Info] Number of data points in the train set: 17336, number of used features: 1429
2023-10-23 20:21:28,644:INFO:[LightGBM] [Info] Start training from score 68.683202
2023-10-23 20:21:33,738:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.160219 seconds.
2023-10-23 20:21:33,738:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 20:21:33,748:INFO:[LightGBM] [Info] Total Bins 251738
2023-10-23 20:21:33,763:INFO:[LightGBM] [Info] Number of data points in the train set: 17336, number of used features: 1429
2023-10-23 20:21:33,769:INFO:[LightGBM] [Info] Start training from score 69.230684
2023-10-23 20:21:38,812:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.148917 seconds.
2023-10-23 20:21:38,812:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 20:21:38,822:INFO:[LightGBM] [Info] Total Bins 251738
2023-10-23 20:21:38,838:INFO:[LightGBM] [Info] Number of data points in the train set: 17336, number of used features: 1429
2023-10-23 20:21:38,845:INFO:[LightGBM] [Info] Start training from score 68.843992
2023-10-23 20:21:43,980:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.160422 seconds.
2023-10-23 20:21:43,980:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 20:21:43,990:INFO:[LightGBM] [Info] Total Bins 251738
2023-10-23 20:21:44,004:INFO:[LightGBM] [Info] Number of data points in the train set: 17336, number of used features: 1429
2023-10-23 20:21:44,011:INFO:[LightGBM] [Info] Start training from score 69.610988
2023-10-23 20:21:49,114:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.158086 seconds.
2023-10-23 20:21:49,114:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 20:21:49,124:INFO:[LightGBM] [Info] Total Bins 251738
2023-10-23 20:21:49,137:INFO:[LightGBM] [Info] Number of data points in the train set: 17336, number of used features: 1429
2023-10-23 20:21:49,143:INFO:[LightGBM] [Info] Start training from score 70.576808
2023-10-23 20:21:53,296:INFO:Uploading results into container
2023-10-23 20:21:53,297:INFO:Uploading model into container now
2023-10-23 20:21:53,298:INFO:_master_model_container: 4
2023-10-23 20:21:53,298:INFO:_display_container: 4
2023-10-23 20:21:53,300:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 20:21:53,301:INFO:create_model() successfully completed......................................
2023-10-23 20:21:53,479:INFO:SubProcess create_model() end ==================================
2023-10-23 20:21:53,479:INFO:Creating Dashboard logs
2023-10-23 20:21:53,480:INFO:Model: Bagging Regressor
2023-10-23 20:21:53,550:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-23 20:21:53,779:INFO:Initializing predict_model()
2023-10-23 20:21:53,780:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08966F460>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E08AA90790>)
2023-10-23 20:21:53,780:INFO:Checking exceptions
2023-10-23 20:21:53,780:INFO:Preloading libraries
2023-10-23 20:21:56,459:INFO:_master_model_container: 4
2023-10-23 20:21:56,460:INFO:_display_container: 4
2023-10-23 20:21:56,460:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 20:21:56,461:INFO:ensemble_model() successfully completed......................................
2023-10-23 20:21:56,564:INFO:Initializing finalize_model()
2023-10-23 20:21:56,564:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08966F460>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-23 20:21:56,565:INFO:Finalizing BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 20:21:56,578:INFO:Initializing create_model()
2023-10-23 20:21:56,578:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08966F460>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-23 20:21:56,578:INFO:Checking exceptions
2023-10-23 20:21:56,579:INFO:Importing libraries
2023-10-23 20:21:56,579:INFO:Copying training dataset
2023-10-23 20:21:56,580:INFO:Defining folds
2023-10-23 20:21:56,580:INFO:Declaring metric variables
2023-10-23 20:21:56,580:INFO:Importing untrained model
2023-10-23 20:21:56,580:INFO:Declaring custom model
2023-10-23 20:21:56,581:INFO:Bagging Regressor Imported successfully
2023-10-23 20:21:56,596:INFO:Cross validation set to False
2023-10-23 20:21:56,596:INFO:Fitting Model
2023-10-23 20:21:58,310:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 20:31:20,108:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.207596 seconds.
2023-10-23 20:31:20,109:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 20:31:20,122:INFO:[LightGBM] [Info] Total Bins 262693
2023-10-23 20:31:20,137:INFO:[LightGBM] [Info] Number of data points in the train set: 24767, number of used features: 1438
2023-10-23 20:31:20,139:INFO:[LightGBM] [Info] Start training from score 70.009941
2023-10-23 20:31:27,259:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.227810 seconds.
2023-10-23 20:31:27,259:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 20:31:27,277:INFO:[LightGBM] [Info] Total Bins 262693
2023-10-23 20:31:27,291:INFO:[LightGBM] [Info] Number of data points in the train set: 24767, number of used features: 1438
2023-10-23 20:31:27,300:INFO:[LightGBM] [Info] Start training from score 68.396762
2023-10-23 20:31:34,649:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.237882 seconds.
2023-10-23 20:31:34,649:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 20:31:34,664:INFO:[LightGBM] [Info] Total Bins 262693
2023-10-23 20:31:34,687:INFO:[LightGBM] [Info] Number of data points in the train set: 24767, number of used features: 1438
2023-10-23 20:31:34,696:INFO:[LightGBM] [Info] Start training from score 69.038145
2023-10-23 20:31:41,894:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.222506 seconds.
2023-10-23 20:31:41,894:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 20:31:41,921:INFO:[LightGBM] [Info] Total Bins 262693
2023-10-23 20:31:41,936:INFO:[LightGBM] [Info] Number of data points in the train set: 24767, number of used features: 1438
2023-10-23 20:31:41,943:INFO:[LightGBM] [Info] Start training from score 68.538279
2023-10-23 20:31:48,885:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.194419 seconds.
2023-10-23 20:31:48,885:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 20:31:48,902:INFO:[LightGBM] [Info] Total Bins 262693
2023-10-23 20:31:48,916:INFO:[LightGBM] [Info] Number of data points in the train set: 24767, number of used features: 1438
2023-10-23 20:31:48,931:INFO:[LightGBM] [Info] Start training from score 67.562566
2023-10-23 20:31:55,632:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.218762 seconds.
2023-10-23 20:31:55,632:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 20:31:55,660:INFO:[LightGBM] [Info] Total Bins 262693
2023-10-23 20:31:55,683:INFO:[LightGBM] [Info] Number of data points in the train set: 24767, number of used features: 1438
2023-10-23 20:31:55,692:INFO:[LightGBM] [Info] Start training from score 70.083539
2023-10-23 20:32:02,388:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.200789 seconds.
2023-10-23 20:32:02,388:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 20:32:02,404:INFO:[LightGBM] [Info] Total Bins 262693
2023-10-23 20:32:02,419:INFO:[LightGBM] [Info] Number of data points in the train set: 24767, number of used features: 1438
2023-10-23 20:32:02,419:INFO:[LightGBM] [Info] Start training from score 68.131763
2023-10-23 20:32:09,074:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.205266 seconds.
2023-10-23 20:32:09,074:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 20:32:09,089:INFO:[LightGBM] [Info] Total Bins 262693
2023-10-23 20:32:09,103:INFO:[LightGBM] [Info] Number of data points in the train set: 24767, number of used features: 1438
2023-10-23 20:32:09,116:INFO:[LightGBM] [Info] Start training from score 68.213136
2023-10-23 20:32:15,905:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.228434 seconds.
2023-10-23 20:32:15,905:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 20:32:15,921:INFO:[LightGBM] [Info] Total Bins 262693
2023-10-23 20:32:15,948:INFO:[LightGBM] [Info] Number of data points in the train set: 24767, number of used features: 1438
2023-10-23 20:32:15,956:INFO:[LightGBM] [Info] Start training from score 69.164086
2023-10-23 20:32:22,427:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.197543 seconds.
2023-10-23 20:32:22,427:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 20:32:22,446:INFO:[LightGBM] [Info] Total Bins 262693
2023-10-23 20:32:22,466:INFO:[LightGBM] [Info] Number of data points in the train set: 24767, number of used features: 1438
2023-10-23 20:32:22,473:INFO:[LightGBM] [Info] Start training from score 67.052122
2023-10-23 20:32:27,734:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_...
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 20:32:27,734:INFO:create_model() successfully completed......................................
2023-10-23 20:32:27,851:INFO:Creating Dashboard logs
2023-10-23 20:32:27,851:INFO:Model: Bagging Regressor
2023-10-23 20:32:27,901:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-23 20:32:28,300:INFO:_master_model_container: 4
2023-10-23 20:32:28,300:INFO:_display_container: 4
2023-10-23 20:32:28,404:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_...
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 20:32:28,404:INFO:finalize_model() successfully completed......................................
2023-10-23 20:32:28,700:INFO:Initializing save_model()
2023-10-23 20:32:28,700:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_...
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), model_name=final_model_for_location_C, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_ene...
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 20:32:28,700:INFO:Adding model into prep_pipe
2023-10-23 20:32:28,700:WARNING:Only Model saved as it was a pipeline.
2023-10-23 20:32:28,855:INFO:final_model_for_location_C.pkl saved in current working directory
2023-10-23 20:32:28,993:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_...
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 20:32:28,993:INFO:save_model() successfully completed......................................
2023-10-23 20:32:30,311:INFO:Initializing load_model()
2023-10-23 20:32:30,312:INFO:load_model(model_name=final_model_for_location_A, platform=None, authentication=None, verbose=True)
2023-10-23 20:32:30,458:INFO:Initializing load_model()
2023-10-23 20:32:30,459:INFO:load_model(model_name=final_model_for_location_B, platform=None, authentication=None, verbose=True)
2023-10-23 20:32:30,595:INFO:Initializing load_model()
2023-10-23 20:32:30,595:INFO:load_model(model_name=final_model_for_location_C, platform=None, authentication=None, verbose=True)
2023-10-23 20:32:30,882:INFO:Initializing predict_model()
2023-10-23 20:32:30,882:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08966F460>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_ene...
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096B204C0>)
2023-10-23 20:32:30,882:INFO:Checking exceptions
2023-10-23 20:32:30,882:INFO:Preloading libraries
2023-10-23 20:32:30,882:INFO:Set up data.
2023-10-23 20:32:30,897:INFO:Set up index.
2023-10-23 20:45:32,793:INFO:Initializing load_model()
2023-10-23 20:45:32,793:INFO:load_model(model_name=final_model_for_location_A, platform=None, authentication=None, verbose=True)
2023-10-23 20:45:32,907:INFO:Initializing load_model()
2023-10-23 20:45:32,907:INFO:load_model(model_name=final_model_for_location_B, platform=None, authentication=None, verbose=True)
2023-10-23 20:45:33,023:INFO:Initializing load_model()
2023-10-23 20:45:33,023:INFO:load_model(model_name=final_model_for_location_C, platform=None, authentication=None, verbose=True)
2023-10-23 20:45:33,267:INFO:Initializing predict_model()
2023-10-23 20:45:33,267:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08966F460>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_ene...
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E08E7D0310>)
2023-10-23 20:45:33,267:INFO:Checking exceptions
2023-10-23 20:45:33,268:INFO:Preloading libraries
2023-10-23 20:45:33,268:INFO:Set up data.
2023-10-23 20:45:33,284:INFO:Set up index.
2023-10-23 20:46:07,780:INFO:Initializing load_model()
2023-10-23 20:46:07,780:INFO:load_model(model_name=final_model_for_location_A, platform=None, authentication=None, verbose=True)
2023-10-23 20:46:07,868:INFO:Initializing load_model()
2023-10-23 20:46:07,869:INFO:load_model(model_name=final_model_for_location_B, platform=None, authentication=None, verbose=True)
2023-10-23 20:46:07,973:INFO:Initializing load_model()
2023-10-23 20:46:07,973:INFO:load_model(model_name=final_model_for_location_C, platform=None, authentication=None, verbose=True)
2023-10-23 20:46:08,227:INFO:Initializing predict_model()
2023-10-23 20:46:08,227:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08966F460>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_ene...
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096F49A60>)
2023-10-23 20:46:08,227:INFO:Checking exceptions
2023-10-23 20:46:08,227:INFO:Preloading libraries
2023-10-23 20:46:08,227:INFO:Set up data.
2023-10-23 20:46:08,239:INFO:Set up index.
2023-10-23 22:38:55,519:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-23 22:38:55,519:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-23 22:38:55,519:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-23 22:38:55,520:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-23 22:42:37,503:INFO:PyCaret RegressionExperiment
2023-10-23 22:42:37,503:INFO:Logging name: exp_A
2023-10-23 22:42:37,503:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 22:42:37,504:INFO:version 3.1.0
2023-10-23 22:42:37,504:INFO:Initializing setup()
2023-10-23 22:42:37,505:INFO:self.USI: 698f
2023-10-23 22:42:37,507:INFO:self._variable_keys: {'memory', 'X_train', 'fold_generator', 'log_plots_param', 'data', 'logging_param', 'target_param', 'exp_id', 'X_test', 'html_param', 'USI', 'transform_target_param', 'idx', 'pipeline', 'fold_shuffle_param', 'seed', 'y_test', 'y_train', 'n_jobs_param', '_ml_usecase', 'gpu_n_jobs_param', 'exp_name_log', 'fold_groups_param', '_available_plots', 'y', 'X', 'gpu_param'}
2023-10-23 22:42:37,507:INFO:Checking environment
2023-10-23 22:42:37,507:INFO:python_version: 3.8.18
2023-10-23 22:42:37,507:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 22:42:37,507:INFO:machine: AMD64
2023-10-23 22:42:37,507:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 22:42:37,507:INFO:Memory: svmem(total=16505954304, available=5543264256, percent=66.4, used=10962690048, free=5543264256)
2023-10-23 22:42:37,507:INFO:Physical Core: 8
2023-10-23 22:42:37,507:INFO:Logical Core: 16
2023-10-23 22:42:37,507:INFO:Checking libraries
2023-10-23 22:42:37,507:INFO:System:
2023-10-23 22:42:37,507:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 22:42:37,507:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 22:42:37,507:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 22:42:37,507:INFO:PyCaret required dependencies:
2023-10-23 22:42:37,602:INFO:                 pip: 23.3
2023-10-23 22:42:37,602:INFO:          setuptools: 68.0.0
2023-10-23 22:42:37,602:INFO:             pycaret: 3.1.0
2023-10-23 22:42:37,602:INFO:             IPython: 8.12.0
2023-10-23 22:42:37,602:INFO:          ipywidgets: 8.1.1
2023-10-23 22:42:37,602:INFO:                tqdm: 4.66.1
2023-10-23 22:42:37,602:INFO:               numpy: 1.23.5
2023-10-23 22:42:37,602:INFO:              pandas: 1.5.3
2023-10-23 22:42:37,602:INFO:              jinja2: 3.1.2
2023-10-23 22:42:37,602:INFO:               scipy: 1.10.1
2023-10-23 22:42:37,602:INFO:              joblib: 1.3.2
2023-10-23 22:42:37,602:INFO:             sklearn: 1.2.2
2023-10-23 22:42:37,602:INFO:                pyod: 1.1.0
2023-10-23 22:42:37,602:INFO:            imblearn: 0.11.0
2023-10-23 22:42:37,602:INFO:   category_encoders: 2.6.2
2023-10-23 22:42:37,602:INFO:            lightgbm: 4.1.0
2023-10-23 22:42:37,602:INFO:               numba: 0.58.1
2023-10-23 22:42:37,602:INFO:            requests: 2.31.0
2023-10-23 22:42:37,602:INFO:          matplotlib: 3.7.3
2023-10-23 22:42:37,602:INFO:          scikitplot: 0.3.7
2023-10-23 22:42:37,602:INFO:         yellowbrick: 1.5
2023-10-23 22:42:37,602:INFO:              plotly: 5.17.0
2023-10-23 22:42:37,602:INFO:    plotly-resampler: Not installed
2023-10-23 22:42:37,602:INFO:             kaleido: 0.2.1
2023-10-23 22:42:37,602:INFO:           schemdraw: 0.15
2023-10-23 22:42:37,602:INFO:         statsmodels: 0.14.0
2023-10-23 22:42:37,602:INFO:              sktime: 0.21.1
2023-10-23 22:42:37,602:INFO:               tbats: 1.1.3
2023-10-23 22:42:37,602:INFO:            pmdarima: 2.0.3
2023-10-23 22:42:37,602:INFO:              psutil: 5.9.0
2023-10-23 22:42:37,602:INFO:          markupsafe: 2.1.3
2023-10-23 22:42:37,602:INFO:             pickle5: Not installed
2023-10-23 22:42:37,602:INFO:         cloudpickle: 2.2.1
2023-10-23 22:42:37,602:INFO:         deprecation: 2.1.0
2023-10-23 22:42:37,610:INFO:              xxhash: 3.4.1
2023-10-23 22:42:37,610:INFO:           wurlitzer: Not installed
2023-10-23 22:42:37,610:INFO:PyCaret optional dependencies:
2023-10-23 22:42:37,626:INFO:                shap: Not installed
2023-10-23 22:42:37,626:INFO:           interpret: Not installed
2023-10-23 22:42:37,626:INFO:                umap: Not installed
2023-10-23 22:42:37,626:INFO:     ydata_profiling: Not installed
2023-10-23 22:42:37,626:INFO:  explainerdashboard: Not installed
2023-10-23 22:42:37,626:INFO:             autoviz: Not installed
2023-10-23 22:42:37,626:INFO:           fairlearn: Not installed
2023-10-23 22:42:37,626:INFO:          deepchecks: Not installed
2023-10-23 22:42:37,626:INFO:             xgboost: Not installed
2023-10-23 22:42:37,627:INFO:            catboost: 1.2.2
2023-10-23 22:42:37,627:INFO:              kmodes: Not installed
2023-10-23 22:42:37,627:INFO:             mlxtend: Not installed
2023-10-23 22:42:37,627:INFO:       statsforecast: Not installed
2023-10-23 22:42:37,627:INFO:        tune_sklearn: Not installed
2023-10-23 22:42:37,627:INFO:                 ray: Not installed
2023-10-23 22:42:37,627:INFO:            hyperopt: Not installed
2023-10-23 22:42:37,627:INFO:              optuna: Not installed
2023-10-23 22:42:37,627:INFO:               skopt: Not installed
2023-10-23 22:42:37,627:INFO:              mlflow: 2.7.1
2023-10-23 22:42:37,627:INFO:              gradio: Not installed
2023-10-23 22:42:37,627:INFO:             fastapi: Not installed
2023-10-23 22:42:37,627:INFO:             uvicorn: Not installed
2023-10-23 22:42:37,627:INFO:              m2cgen: Not installed
2023-10-23 22:42:37,627:INFO:           evidently: Not installed
2023-10-23 22:42:37,627:INFO:               fugue: Not installed
2023-10-23 22:42:37,627:INFO:           streamlit: Not installed
2023-10-23 22:42:37,627:INFO:             prophet: Not installed
2023-10-23 22:42:37,627:INFO:None
2023-10-23 22:42:37,627:INFO:Set up data.
2023-10-23 22:42:37,661:INFO:Set up folding strategy.
2023-10-23 22:42:37,662:INFO:Set up train/test split.
2023-10-23 22:42:37,683:INFO:Set up index.
2023-10-23 22:42:37,685:INFO:Assigning column types.
2023-10-23 22:42:37,697:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 22:42:37,697:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 22:42:37,710:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 22:42:37,715:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:42:37,793:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:42:37,841:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:42:37,841:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:42:37,843:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:42:37,843:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 22:42:37,849:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 22:42:37,850:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:42:37,927:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:42:37,979:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:42:37,980:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:42:37,980:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:42:37,981:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 22:42:37,986:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 22:42:37,991:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:42:38,066:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:42:38,111:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:42:38,111:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:42:38,111:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:42:38,111:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 22:42:38,111:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:42:38,199:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:42:38,245:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:42:38,245:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:42:38,245:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:42:38,245:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 22:42:38,260:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:42:38,328:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:42:38,382:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:42:38,383:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:42:38,383:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:42:38,393:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:42:38,461:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:42:38,511:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:42:38,511:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:42:38,511:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:42:38,511:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 22:42:38,594:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:42:38,646:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:42:38,646:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:42:38,646:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:42:38,728:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:42:38,777:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:42:38,777:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:42:38,777:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:42:38,777:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 22:42:38,877:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:42:38,935:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:42:38,935:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:42:39,026:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:42:39,066:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:42:39,066:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:42:39,066:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 22:42:39,218:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:42:39,218:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:42:39,349:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:42:39,349:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:42:39,361:INFO:Preparing preprocessing pipeline...
2023-10-23 22:42:39,361:INFO:Set up date feature engineering.
2023-10-23 22:42:39,361:INFO:Set up simple imputation.
2023-10-23 22:42:39,364:INFO:Set up encoding of ordinal features.
2023-10-23 22:42:39,382:INFO:Set up encoding of categorical features.
2023-10-23 22:42:39,382:INFO:Set up variance threshold.
2023-10-23 22:42:39,382:INFO:Set up removing outliers.
2023-10-23 22:42:39,382:INFO:Set up column name cleaning.
2023-10-23 22:42:39,915:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 22:42:41,647:INFO:Finished creating preprocessing pipeline.
2023-10-23 22:42:41,727:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 22:42:41,727:INFO:Creating final display dataframe.
2023-10-23 22:42:42,212:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 22:42:44,626:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (34061, 48)
4        Transformed data shape   (32868, 37)
5   Transformed train set shape   (22649, 37)
6    Transformed test set shape   (10219, 37)
7              Ordinal features             2
8              Numeric features            43
9                 Date features             1
10         Categorical features             3
11     Rows with missing values         97.6%
12                   Preprocess          True
13              Imputation type        simple
14           Numeric imputation          mean
15       Categorical imputation          mode
16     Maximum one-hot encoding            25
17              Encoding method          None
18       Low variance threshold          0.05
19              Remove outliers          True
20           Outliers threshold          0.05
21               Fold Generator         KFold
22                  Fold Number            10
23                     CPU Jobs            -1
24                      Use GPU         False
25               Log Experiment  MlflowLogger
26              Experiment Name         exp_A
27                          USI          698f
2023-10-23 22:42:44,762:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:42:44,762:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:42:44,905:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:42:44,905:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:42:44,907:INFO:Logging experiment in loggers
2023-10-23 22:45:30,642:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\3621255004.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  a = merged_data_a.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 22:45:30,673:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\3621255004.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  b = merged_data_b.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 22:45:30,720:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\3621255004.py:3: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  c = merged_data_c.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 22:45:30,829:INFO:PyCaret RegressionExperiment
2023-10-23 22:45:30,829:INFO:Logging name: exp_A
2023-10-23 22:45:30,830:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 22:45:30,831:INFO:version 3.1.0
2023-10-23 22:45:30,831:INFO:Initializing setup()
2023-10-23 22:45:30,831:INFO:self.USI: 849d
2023-10-23 22:45:30,832:INFO:self._variable_keys: {'memory', 'X_train', 'fold_generator', 'log_plots_param', 'data', 'logging_param', 'target_param', 'exp_id', 'X_test', 'html_param', 'USI', 'transform_target_param', 'idx', 'pipeline', 'fold_shuffle_param', 'seed', 'y_test', 'y_train', 'n_jobs_param', '_ml_usecase', 'gpu_n_jobs_param', 'exp_name_log', 'fold_groups_param', '_available_plots', 'y', 'X', 'gpu_param'}
2023-10-23 22:45:30,832:INFO:Checking environment
2023-10-23 22:45:30,832:INFO:python_version: 3.8.18
2023-10-23 22:45:30,832:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 22:45:30,832:INFO:machine: AMD64
2023-10-23 22:45:30,833:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 22:45:30,833:INFO:Memory: svmem(total=16505954304, available=5303865344, percent=67.9, used=11202088960, free=5303865344)
2023-10-23 22:45:30,833:INFO:Physical Core: 8
2023-10-23 22:45:30,834:INFO:Logical Core: 16
2023-10-23 22:45:30,834:INFO:Checking libraries
2023-10-23 22:45:30,834:INFO:System:
2023-10-23 22:45:30,834:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 22:45:30,835:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 22:45:30,835:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 22:45:30,835:INFO:PyCaret required dependencies:
2023-10-23 22:45:30,835:INFO:                 pip: 23.3
2023-10-23 22:45:30,836:INFO:          setuptools: 68.0.0
2023-10-23 22:45:30,836:INFO:             pycaret: 3.1.0
2023-10-23 22:45:30,836:INFO:             IPython: 8.12.0
2023-10-23 22:45:30,836:INFO:          ipywidgets: 8.1.1
2023-10-23 22:45:30,836:INFO:                tqdm: 4.66.1
2023-10-23 22:45:30,837:INFO:               numpy: 1.23.5
2023-10-23 22:45:30,837:INFO:              pandas: 1.5.3
2023-10-23 22:45:30,837:INFO:              jinja2: 3.1.2
2023-10-23 22:45:30,838:INFO:               scipy: 1.10.1
2023-10-23 22:45:30,838:INFO:              joblib: 1.3.2
2023-10-23 22:45:30,838:INFO:             sklearn: 1.2.2
2023-10-23 22:45:30,838:INFO:                pyod: 1.1.0
2023-10-23 22:45:30,838:INFO:            imblearn: 0.11.0
2023-10-23 22:45:30,838:INFO:   category_encoders: 2.6.2
2023-10-23 22:45:30,838:INFO:            lightgbm: 4.1.0
2023-10-23 22:45:30,838:INFO:               numba: 0.58.1
2023-10-23 22:45:30,838:INFO:            requests: 2.31.0
2023-10-23 22:45:30,838:INFO:          matplotlib: 3.7.3
2023-10-23 22:45:30,839:INFO:          scikitplot: 0.3.7
2023-10-23 22:45:30,839:INFO:         yellowbrick: 1.5
2023-10-23 22:45:30,839:INFO:              plotly: 5.17.0
2023-10-23 22:45:30,839:INFO:    plotly-resampler: Not installed
2023-10-23 22:45:30,839:INFO:             kaleido: 0.2.1
2023-10-23 22:45:30,839:INFO:           schemdraw: 0.15
2023-10-23 22:45:30,839:INFO:         statsmodels: 0.14.0
2023-10-23 22:45:30,839:INFO:              sktime: 0.21.1
2023-10-23 22:45:30,839:INFO:               tbats: 1.1.3
2023-10-23 22:45:30,839:INFO:            pmdarima: 2.0.3
2023-10-23 22:45:30,839:INFO:              psutil: 5.9.0
2023-10-23 22:45:30,839:INFO:          markupsafe: 2.1.3
2023-10-23 22:45:30,839:INFO:             pickle5: Not installed
2023-10-23 22:45:30,839:INFO:         cloudpickle: 2.2.1
2023-10-23 22:45:30,839:INFO:         deprecation: 2.1.0
2023-10-23 22:45:30,839:INFO:              xxhash: 3.4.1
2023-10-23 22:45:30,839:INFO:           wurlitzer: Not installed
2023-10-23 22:45:30,839:INFO:PyCaret optional dependencies:
2023-10-23 22:45:30,839:INFO:                shap: Not installed
2023-10-23 22:45:30,840:INFO:           interpret: Not installed
2023-10-23 22:45:30,840:INFO:                umap: Not installed
2023-10-23 22:45:30,840:INFO:     ydata_profiling: Not installed
2023-10-23 22:45:30,840:INFO:  explainerdashboard: Not installed
2023-10-23 22:45:30,840:INFO:             autoviz: Not installed
2023-10-23 22:45:30,840:INFO:           fairlearn: Not installed
2023-10-23 22:45:30,840:INFO:          deepchecks: Not installed
2023-10-23 22:45:30,840:INFO:             xgboost: Not installed
2023-10-23 22:45:30,840:INFO:            catboost: 1.2.2
2023-10-23 22:45:30,840:INFO:              kmodes: Not installed
2023-10-23 22:45:30,840:INFO:             mlxtend: Not installed
2023-10-23 22:45:30,840:INFO:       statsforecast: Not installed
2023-10-23 22:45:30,840:INFO:        tune_sklearn: Not installed
2023-10-23 22:45:30,840:INFO:                 ray: Not installed
2023-10-23 22:45:30,840:INFO:            hyperopt: Not installed
2023-10-23 22:45:30,840:INFO:              optuna: Not installed
2023-10-23 22:45:30,840:INFO:               skopt: Not installed
2023-10-23 22:45:30,840:INFO:              mlflow: 2.7.1
2023-10-23 22:45:30,840:INFO:              gradio: Not installed
2023-10-23 22:45:30,840:INFO:             fastapi: Not installed
2023-10-23 22:45:30,840:INFO:             uvicorn: Not installed
2023-10-23 22:45:30,841:INFO:              m2cgen: Not installed
2023-10-23 22:45:30,841:INFO:           evidently: Not installed
2023-10-23 22:45:30,841:INFO:               fugue: Not installed
2023-10-23 22:45:30,841:INFO:           streamlit: Not installed
2023-10-23 22:45:30,841:INFO:             prophet: Not installed
2023-10-23 22:45:30,841:INFO:None
2023-10-23 22:45:30,841:INFO:Set up data.
2023-10-23 22:45:30,886:INFO:Set up folding strategy.
2023-10-23 22:45:30,886:INFO:Set up train/test split.
2023-10-23 22:45:30,914:INFO:Set up index.
2023-10-23 22:45:30,916:INFO:Assigning column types.
2023-10-23 22:45:30,929:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 22:45:30,945:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 22:45:30,945:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 22:45:30,960:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:45:31,044:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:45:31,122:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:45:31,123:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:45:31,123:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:45:31,124:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 22:45:31,124:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 22:45:31,124:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:45:31,229:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:45:31,302:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:45:31,302:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:45:31,302:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:45:31,302:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 22:45:31,302:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 22:45:31,320:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:45:31,417:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:45:31,472:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:45:31,472:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:45:31,472:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:45:31,488:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 22:45:31,495:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:45:31,584:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:45:31,624:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:45:31,639:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:45:31,639:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:45:31,639:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 22:45:31,639:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:45:31,742:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:45:31,799:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:45:31,799:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:45:31,799:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:45:31,815:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:45:31,921:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:45:31,991:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:45:31,992:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:45:31,993:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:45:31,993:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 22:45:32,090:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:45:32,138:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:45:32,138:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:45:32,138:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:45:32,268:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:45:32,324:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:45:32,324:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:45:32,324:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:45:32,324:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 22:45:32,443:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:45:32,503:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:45:32,504:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:45:32,603:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:45:32,663:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:45:32,663:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:45:32,674:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 22:45:32,854:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:45:32,855:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:45:33,020:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:45:33,020:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:45:33,020:INFO:Preparing preprocessing pipeline...
2023-10-23 22:45:33,020:INFO:Set up date feature engineering.
2023-10-23 22:45:33,020:INFO:Set up simple imputation.
2023-10-23 22:45:33,035:INFO:Set up encoding of ordinal features.
2023-10-23 22:45:33,069:INFO:Set up encoding of categorical features.
2023-10-23 22:45:33,070:INFO:Set up variance threshold.
2023-10-23 22:45:33,070:INFO:Set up removing outliers.
2023-10-23 22:45:33,075:INFO:Set up column name cleaning.
2023-10-23 22:45:33,508:INFO:Finished creating preprocessing pipeline.
2023-10-23 22:45:33,605:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 22:45:33,605:INFO:Creating final display dataframe.
2023-10-23 22:45:34,502:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (34061, 48)
4        Transformed data shape   (32868, 37)
5   Transformed train set shape   (22649, 37)
6    Transformed test set shape   (10219, 37)
7              Ordinal features             2
8              Numeric features            43
9                 Date features             1
10         Categorical features             3
11     Rows with missing values         97.6%
12                   Preprocess          True
13              Imputation type        simple
14           Numeric imputation          mean
15       Categorical imputation          mode
16     Maximum one-hot encoding            25
17              Encoding method          None
18       Low variance threshold          0.05
19              Remove outliers          True
20           Outliers threshold          0.05
21               Fold Generator         KFold
22                  Fold Number            10
23                     CPU Jobs            -1
24                      Use GPU         False
25               Log Experiment  MlflowLogger
26              Experiment Name         exp_A
27                          USI          849d
2023-10-23 22:45:34,665:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:45:34,665:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:45:34,825:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:45:34,826:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:45:34,826:INFO:Logging experiment in loggers
2023-10-23 22:48:15,067:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\3621255004.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  a = merged_data_a.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 22:48:15,102:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\3621255004.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  b = merged_data_b.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 22:48:15,134:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\3621255004.py:3: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  c = merged_data_c.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 22:48:15,217:INFO:PyCaret RegressionExperiment
2023-10-23 22:48:15,218:INFO:Logging name: exp_A
2023-10-23 22:48:15,218:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 22:48:15,218:INFO:version 3.1.0
2023-10-23 22:48:15,218:INFO:Initializing setup()
2023-10-23 22:48:15,218:INFO:self.USI: 6253
2023-10-23 22:48:15,218:INFO:self._variable_keys: {'memory', 'X_train', 'fold_generator', 'log_plots_param', 'data', 'logging_param', 'target_param', 'exp_id', 'X_test', 'html_param', 'USI', 'transform_target_param', 'idx', 'pipeline', 'fold_shuffle_param', 'seed', 'y_test', 'y_train', 'n_jobs_param', '_ml_usecase', 'gpu_n_jobs_param', 'exp_name_log', 'fold_groups_param', '_available_plots', 'y', 'X', 'gpu_param'}
2023-10-23 22:48:15,218:INFO:Checking environment
2023-10-23 22:48:15,219:INFO:python_version: 3.8.18
2023-10-23 22:48:15,219:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 22:48:15,219:INFO:machine: AMD64
2023-10-23 22:48:15,219:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 22:48:15,219:INFO:Memory: svmem(total=16505954304, available=5317984256, percent=67.8, used=11187970048, free=5317984256)
2023-10-23 22:48:15,219:INFO:Physical Core: 8
2023-10-23 22:48:15,219:INFO:Logical Core: 16
2023-10-23 22:48:15,220:INFO:Checking libraries
2023-10-23 22:48:15,220:INFO:System:
2023-10-23 22:48:15,220:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 22:48:15,220:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 22:48:15,220:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 22:48:15,220:INFO:PyCaret required dependencies:
2023-10-23 22:48:15,220:INFO:                 pip: 23.3
2023-10-23 22:48:15,220:INFO:          setuptools: 68.0.0
2023-10-23 22:48:15,222:INFO:             pycaret: 3.1.0
2023-10-23 22:48:15,222:INFO:             IPython: 8.12.0
2023-10-23 22:48:15,222:INFO:          ipywidgets: 8.1.1
2023-10-23 22:48:15,222:INFO:                tqdm: 4.66.1
2023-10-23 22:48:15,222:INFO:               numpy: 1.23.5
2023-10-23 22:48:15,222:INFO:              pandas: 1.5.3
2023-10-23 22:48:15,222:INFO:              jinja2: 3.1.2
2023-10-23 22:48:15,222:INFO:               scipy: 1.10.1
2023-10-23 22:48:15,222:INFO:              joblib: 1.3.2
2023-10-23 22:48:15,222:INFO:             sklearn: 1.2.2
2023-10-23 22:48:15,223:INFO:                pyod: 1.1.0
2023-10-23 22:48:15,223:INFO:            imblearn: 0.11.0
2023-10-23 22:48:15,223:INFO:   category_encoders: 2.6.2
2023-10-23 22:48:15,223:INFO:            lightgbm: 4.1.0
2023-10-23 22:48:15,223:INFO:               numba: 0.58.1
2023-10-23 22:48:15,223:INFO:            requests: 2.31.0
2023-10-23 22:48:15,223:INFO:          matplotlib: 3.7.3
2023-10-23 22:48:15,223:INFO:          scikitplot: 0.3.7
2023-10-23 22:48:15,223:INFO:         yellowbrick: 1.5
2023-10-23 22:48:15,223:INFO:              plotly: 5.17.0
2023-10-23 22:48:15,223:INFO:    plotly-resampler: Not installed
2023-10-23 22:48:15,223:INFO:             kaleido: 0.2.1
2023-10-23 22:48:15,224:INFO:           schemdraw: 0.15
2023-10-23 22:48:15,224:INFO:         statsmodels: 0.14.0
2023-10-23 22:48:15,224:INFO:              sktime: 0.21.1
2023-10-23 22:48:15,224:INFO:               tbats: 1.1.3
2023-10-23 22:48:15,224:INFO:            pmdarima: 2.0.3
2023-10-23 22:48:15,224:INFO:              psutil: 5.9.0
2023-10-23 22:48:15,224:INFO:          markupsafe: 2.1.3
2023-10-23 22:48:15,224:INFO:             pickle5: Not installed
2023-10-23 22:48:15,224:INFO:         cloudpickle: 2.2.1
2023-10-23 22:48:15,224:INFO:         deprecation: 2.1.0
2023-10-23 22:48:15,224:INFO:              xxhash: 3.4.1
2023-10-23 22:48:15,224:INFO:           wurlitzer: Not installed
2023-10-23 22:48:15,224:INFO:PyCaret optional dependencies:
2023-10-23 22:48:15,224:INFO:                shap: Not installed
2023-10-23 22:48:15,225:INFO:           interpret: Not installed
2023-10-23 22:48:15,225:INFO:                umap: Not installed
2023-10-23 22:48:15,225:INFO:     ydata_profiling: Not installed
2023-10-23 22:48:15,225:INFO:  explainerdashboard: Not installed
2023-10-23 22:48:15,225:INFO:             autoviz: Not installed
2023-10-23 22:48:15,225:INFO:           fairlearn: Not installed
2023-10-23 22:48:15,225:INFO:          deepchecks: Not installed
2023-10-23 22:48:15,225:INFO:             xgboost: Not installed
2023-10-23 22:48:15,225:INFO:            catboost: 1.2.2
2023-10-23 22:48:15,225:INFO:              kmodes: Not installed
2023-10-23 22:48:15,225:INFO:             mlxtend: Not installed
2023-10-23 22:48:15,225:INFO:       statsforecast: Not installed
2023-10-23 22:48:15,225:INFO:        tune_sklearn: Not installed
2023-10-23 22:48:15,225:INFO:                 ray: Not installed
2023-10-23 22:48:15,226:INFO:            hyperopt: Not installed
2023-10-23 22:48:15,226:INFO:              optuna: Not installed
2023-10-23 22:48:15,226:INFO:               skopt: Not installed
2023-10-23 22:48:15,226:INFO:              mlflow: 2.7.1
2023-10-23 22:48:15,226:INFO:              gradio: Not installed
2023-10-23 22:48:15,226:INFO:             fastapi: Not installed
2023-10-23 22:48:15,226:INFO:             uvicorn: Not installed
2023-10-23 22:48:15,226:INFO:              m2cgen: Not installed
2023-10-23 22:48:15,226:INFO:           evidently: Not installed
2023-10-23 22:48:15,226:INFO:               fugue: Not installed
2023-10-23 22:48:15,226:INFO:           streamlit: Not installed
2023-10-23 22:48:15,226:INFO:             prophet: Not installed
2023-10-23 22:48:15,226:INFO:None
2023-10-23 22:48:15,227:INFO:Set up data.
2023-10-23 22:48:15,255:INFO:Set up folding strategy.
2023-10-23 22:48:15,255:INFO:Set up train/test split.
2023-10-23 22:48:15,267:INFO:Set up index.
2023-10-23 22:48:15,267:INFO:Assigning column types.
2023-10-23 22:48:15,302:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 22:48:15,302:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 22:48:15,307:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 22:48:15,307:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:48:15,387:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:48:15,434:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:48:15,434:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:48:15,434:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:48:15,434:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 22:48:15,434:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 22:48:15,452:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:48:15,520:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:48:15,572:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:48:15,572:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:48:15,572:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:48:15,572:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 22:48:15,587:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 22:48:15,587:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:48:15,667:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:48:15,704:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:48:15,704:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:48:15,704:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:48:15,720:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 22:48:15,720:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:48:15,804:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:48:15,838:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:48:15,838:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:48:15,853:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:48:15,853:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 22:48:15,853:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:48:15,936:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:48:15,983:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:48:15,983:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:48:15,983:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:48:16,001:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:48:16,069:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:48:16,125:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:48:16,125:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:48:16,125:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:48:16,126:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 22:48:16,204:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:48:16,250:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:48:16,250:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:48:16,250:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:48:16,337:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:48:16,400:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:48:16,400:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:48:16,400:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:48:16,400:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 22:48:16,484:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:48:16,536:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:48:16,536:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:48:16,621:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:48:16,668:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:48:16,668:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:48:16,668:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 22:48:16,800:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:48:16,800:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:48:16,937:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:48:16,937:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:48:16,937:INFO:Preparing preprocessing pipeline...
2023-10-23 22:48:16,937:INFO:Set up date feature engineering.
2023-10-23 22:48:16,937:INFO:Set up simple imputation.
2023-10-23 22:48:16,952:INFO:Set up encoding of ordinal features.
2023-10-23 22:48:16,952:INFO:Set up encoding of categorical features.
2023-10-23 22:48:16,952:INFO:Set up variance threshold.
2023-10-23 22:48:16,952:INFO:Set up removing outliers.
2023-10-23 22:48:16,968:INFO:Set up column name cleaning.
2023-10-23 22:48:17,269:INFO:Finished creating preprocessing pipeline.
2023-10-23 22:48:17,320:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 22:48:17,320:INFO:Creating final display dataframe.
2023-10-23 22:48:17,466:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (34061, 48)
4        Transformed data shape  (32868, 37)
5   Transformed train set shape  (22649, 37)
6    Transformed test set shape  (10219, 37)
7              Ordinal features            2
8              Numeric features           43
9                 Date features            1
10         Categorical features            3
11     Rows with missing values        97.6%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18       Low variance threshold         0.05
19              Remove outliers         True
20           Outliers threshold         0.05
21               Fold Generator        KFold
22                  Fold Number           10
23                     CPU Jobs           -1
24                      Use GPU        False
25               Log Experiment        False
26              Experiment Name        exp_A
27                          USI         6253
2023-10-23 22:48:17,602:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:48:17,602:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:48:17,735:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:48:17,735:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:48:17,735:INFO:setup() successfully completed in 2.53s...............
2023-10-23 22:49:13,504:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\3621255004.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  a = merged_data_a.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 22:49:13,535:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\3621255004.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  b = merged_data_b.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 22:49:13,585:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\3621255004.py:3: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  c = merged_data_c.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 22:49:13,668:INFO:PyCaret RegressionExperiment
2023-10-23 22:49:13,668:INFO:Logging name: exp_A
2023-10-23 22:49:13,668:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 22:49:13,668:INFO:version 3.1.0
2023-10-23 22:49:13,668:INFO:Initializing setup()
2023-10-23 22:49:13,668:INFO:self.USI: bc90
2023-10-23 22:49:13,668:INFO:self._variable_keys: {'memory', 'X_train', 'fold_generator', 'log_plots_param', 'data', 'logging_param', 'target_param', 'exp_id', 'X_test', 'html_param', 'USI', 'transform_target_param', 'idx', 'pipeline', 'fold_shuffle_param', 'seed', 'y_test', 'y_train', 'n_jobs_param', '_ml_usecase', 'gpu_n_jobs_param', 'exp_name_log', 'fold_groups_param', '_available_plots', 'y', 'X', 'gpu_param'}
2023-10-23 22:49:13,668:INFO:Checking environment
2023-10-23 22:49:13,668:INFO:python_version: 3.8.18
2023-10-23 22:49:13,668:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 22:49:13,668:INFO:machine: AMD64
2023-10-23 22:49:13,668:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 22:49:13,668:INFO:Memory: svmem(total=16505954304, available=5302415360, percent=67.9, used=11203538944, free=5302415360)
2023-10-23 22:49:13,668:INFO:Physical Core: 8
2023-10-23 22:49:13,668:INFO:Logical Core: 16
2023-10-23 22:49:13,668:INFO:Checking libraries
2023-10-23 22:49:13,668:INFO:System:
2023-10-23 22:49:13,668:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 22:49:13,668:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 22:49:13,668:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 22:49:13,668:INFO:PyCaret required dependencies:
2023-10-23 22:49:13,668:INFO:                 pip: 23.3
2023-10-23 22:49:13,668:INFO:          setuptools: 68.0.0
2023-10-23 22:49:13,668:INFO:             pycaret: 3.1.0
2023-10-23 22:49:13,668:INFO:             IPython: 8.12.0
2023-10-23 22:49:13,668:INFO:          ipywidgets: 8.1.1
2023-10-23 22:49:13,668:INFO:                tqdm: 4.66.1
2023-10-23 22:49:13,668:INFO:               numpy: 1.23.5
2023-10-23 22:49:13,668:INFO:              pandas: 1.5.3
2023-10-23 22:49:13,668:INFO:              jinja2: 3.1.2
2023-10-23 22:49:13,668:INFO:               scipy: 1.10.1
2023-10-23 22:49:13,668:INFO:              joblib: 1.3.2
2023-10-23 22:49:13,668:INFO:             sklearn: 1.2.2
2023-10-23 22:49:13,668:INFO:                pyod: 1.1.0
2023-10-23 22:49:13,668:INFO:            imblearn: 0.11.0
2023-10-23 22:49:13,668:INFO:   category_encoders: 2.6.2
2023-10-23 22:49:13,668:INFO:            lightgbm: 4.1.0
2023-10-23 22:49:13,668:INFO:               numba: 0.58.1
2023-10-23 22:49:13,668:INFO:            requests: 2.31.0
2023-10-23 22:49:13,668:INFO:          matplotlib: 3.7.3
2023-10-23 22:49:13,668:INFO:          scikitplot: 0.3.7
2023-10-23 22:49:13,668:INFO:         yellowbrick: 1.5
2023-10-23 22:49:13,683:INFO:              plotly: 5.17.0
2023-10-23 22:49:13,683:INFO:    plotly-resampler: Not installed
2023-10-23 22:49:13,683:INFO:             kaleido: 0.2.1
2023-10-23 22:49:13,683:INFO:           schemdraw: 0.15
2023-10-23 22:49:13,683:INFO:         statsmodels: 0.14.0
2023-10-23 22:49:13,683:INFO:              sktime: 0.21.1
2023-10-23 22:49:13,683:INFO:               tbats: 1.1.3
2023-10-23 22:49:13,683:INFO:            pmdarima: 2.0.3
2023-10-23 22:49:13,683:INFO:              psutil: 5.9.0
2023-10-23 22:49:13,683:INFO:          markupsafe: 2.1.3
2023-10-23 22:49:13,683:INFO:             pickle5: Not installed
2023-10-23 22:49:13,683:INFO:         cloudpickle: 2.2.1
2023-10-23 22:49:13,683:INFO:         deprecation: 2.1.0
2023-10-23 22:49:13,683:INFO:              xxhash: 3.4.1
2023-10-23 22:49:13,683:INFO:           wurlitzer: Not installed
2023-10-23 22:49:13,683:INFO:PyCaret optional dependencies:
2023-10-23 22:49:13,684:INFO:                shap: Not installed
2023-10-23 22:49:13,684:INFO:           interpret: Not installed
2023-10-23 22:49:13,684:INFO:                umap: Not installed
2023-10-23 22:49:13,684:INFO:     ydata_profiling: Not installed
2023-10-23 22:49:13,684:INFO:  explainerdashboard: Not installed
2023-10-23 22:49:13,684:INFO:             autoviz: Not installed
2023-10-23 22:49:13,684:INFO:           fairlearn: Not installed
2023-10-23 22:49:13,684:INFO:          deepchecks: Not installed
2023-10-23 22:49:13,684:INFO:             xgboost: Not installed
2023-10-23 22:49:13,684:INFO:            catboost: 1.2.2
2023-10-23 22:49:13,684:INFO:              kmodes: Not installed
2023-10-23 22:49:13,684:INFO:             mlxtend: Not installed
2023-10-23 22:49:13,684:INFO:       statsforecast: Not installed
2023-10-23 22:49:13,684:INFO:        tune_sklearn: Not installed
2023-10-23 22:49:13,684:INFO:                 ray: Not installed
2023-10-23 22:49:13,685:INFO:            hyperopt: Not installed
2023-10-23 22:49:13,685:INFO:              optuna: Not installed
2023-10-23 22:49:13,685:INFO:               skopt: Not installed
2023-10-23 22:49:13,685:INFO:              mlflow: 2.7.1
2023-10-23 22:49:13,685:INFO:              gradio: Not installed
2023-10-23 22:49:13,685:INFO:             fastapi: Not installed
2023-10-23 22:49:13,685:INFO:             uvicorn: Not installed
2023-10-23 22:49:13,685:INFO:              m2cgen: Not installed
2023-10-23 22:49:13,685:INFO:           evidently: Not installed
2023-10-23 22:49:13,685:INFO:               fugue: Not installed
2023-10-23 22:49:13,685:INFO:           streamlit: Not installed
2023-10-23 22:49:13,685:INFO:             prophet: Not installed
2023-10-23 22:49:13,685:INFO:None
2023-10-23 22:49:13,685:INFO:Set up data.
2023-10-23 22:49:13,719:INFO:Set up folding strategy.
2023-10-23 22:49:13,720:INFO:Set up train/test split.
2023-10-23 22:49:13,742:INFO:Set up index.
2023-10-23 22:49:13,743:INFO:Assigning column types.
2023-10-23 22:49:13,753:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 22:49:13,753:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 22:49:13,768:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 22:49:13,768:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:49:13,851:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:49:13,901:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:49:13,901:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:49:13,901:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:49:13,901:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 22:49:13,901:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 22:49:13,901:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:49:13,984:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:49:14,034:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:49:14,034:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:49:14,034:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:49:14,034:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 22:49:14,034:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 22:49:14,051:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:49:14,125:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:49:14,174:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:49:14,175:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:49:14,175:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:49:14,178:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 22:49:14,186:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:49:14,263:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:49:14,308:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:49:14,308:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:49:14,308:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:49:14,308:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 22:49:14,318:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:49:14,399:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:49:14,434:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:49:14,434:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:49:14,434:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:49:14,451:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:49:14,534:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:49:14,582:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:49:14,583:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:49:14,583:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:49:14,584:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 22:49:14,670:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:49:14,717:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:49:14,718:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:49:14,718:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:49:14,806:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:49:14,853:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:49:14,853:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:49:14,853:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:49:14,853:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 22:49:14,933:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:49:14,978:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:49:14,978:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:49:15,072:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:49:15,121:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:49:15,121:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:49:15,121:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 22:49:15,252:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:49:15,252:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:49:15,382:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:49:15,382:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:49:15,382:INFO:Preparing preprocessing pipeline...
2023-10-23 22:49:15,382:INFO:Set up date feature engineering.
2023-10-23 22:49:15,382:INFO:Set up simple imputation.
2023-10-23 22:49:15,398:INFO:Set up encoding of ordinal features.
2023-10-23 22:49:15,419:INFO:Set up encoding of categorical features.
2023-10-23 22:49:15,419:INFO:Set up variance threshold.
2023-10-23 22:49:15,419:INFO:Set up removing outliers.
2023-10-23 22:49:15,420:INFO:Set up column name cleaning.
2023-10-23 22:49:15,722:INFO:Finished creating preprocessing pipeline.
2023-10-23 22:49:15,783:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 22:49:15,783:INFO:Creating final display dataframe.
2023-10-23 22:49:15,922:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (34061, 48)
4        Transformed data shape  (32868, 37)
5   Transformed train set shape  (22649, 37)
6    Transformed test set shape  (10219, 37)
7              Ordinal features            2
8              Numeric features           43
9                 Date features            1
10         Categorical features            3
11     Rows with missing values        97.6%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18       Low variance threshold         0.05
19              Remove outliers         True
20           Outliers threshold         0.05
21               Fold Generator        KFold
22                  Fold Number           10
23                     CPU Jobs           -1
24                      Use GPU        False
25               Log Experiment        False
26              Experiment Name        exp_A
27                          USI         bc90
2023-10-23 22:49:16,053:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:49:16,053:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:49:16,200:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:49:16,200:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:49:16,201:INFO:setup() successfully completed in 2.55s...............
2023-10-23 22:49:29,501:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\3621255004.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  a = merged_data_a.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 22:49:29,538:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\3621255004.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  b = merged_data_b.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 22:49:29,579:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\3621255004.py:3: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  c = merged_data_c.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 22:49:29,649:INFO:PyCaret RegressionExperiment
2023-10-23 22:49:29,653:INFO:Logging name: exp_A
2023-10-23 22:49:29,653:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 22:49:29,653:INFO:version 3.1.0
2023-10-23 22:49:29,653:INFO:Initializing setup()
2023-10-23 22:49:29,653:INFO:self.USI: dea2
2023-10-23 22:49:29,653:INFO:self._variable_keys: {'memory', 'X_train', 'fold_generator', 'log_plots_param', 'data', 'logging_param', 'target_param', 'exp_id', 'X_test', 'html_param', 'USI', 'transform_target_param', 'idx', 'pipeline', 'fold_shuffle_param', 'seed', 'y_test', 'y_train', 'n_jobs_param', '_ml_usecase', 'gpu_n_jobs_param', 'exp_name_log', 'fold_groups_param', '_available_plots', 'y', 'X', 'gpu_param'}
2023-10-23 22:49:29,653:INFO:Checking environment
2023-10-23 22:49:29,653:INFO:python_version: 3.8.18
2023-10-23 22:49:29,653:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 22:49:29,653:INFO:machine: AMD64
2023-10-23 22:49:29,653:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 22:49:29,653:INFO:Memory: svmem(total=16505954304, available=5235671040, percent=68.3, used=11270283264, free=5235671040)
2023-10-23 22:49:29,653:INFO:Physical Core: 8
2023-10-23 22:49:29,653:INFO:Logical Core: 16
2023-10-23 22:49:29,653:INFO:Checking libraries
2023-10-23 22:49:29,653:INFO:System:
2023-10-23 22:49:29,653:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 22:49:29,654:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 22:49:29,654:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 22:49:29,654:INFO:PyCaret required dependencies:
2023-10-23 22:49:29,654:INFO:                 pip: 23.3
2023-10-23 22:49:29,654:INFO:          setuptools: 68.0.0
2023-10-23 22:49:29,654:INFO:             pycaret: 3.1.0
2023-10-23 22:49:29,654:INFO:             IPython: 8.12.0
2023-10-23 22:49:29,654:INFO:          ipywidgets: 8.1.1
2023-10-23 22:49:29,654:INFO:                tqdm: 4.66.1
2023-10-23 22:49:29,654:INFO:               numpy: 1.23.5
2023-10-23 22:49:29,655:INFO:              pandas: 1.5.3
2023-10-23 22:49:29,655:INFO:              jinja2: 3.1.2
2023-10-23 22:49:29,655:INFO:               scipy: 1.10.1
2023-10-23 22:49:29,655:INFO:              joblib: 1.3.2
2023-10-23 22:49:29,655:INFO:             sklearn: 1.2.2
2023-10-23 22:49:29,655:INFO:                pyod: 1.1.0
2023-10-23 22:49:29,655:INFO:            imblearn: 0.11.0
2023-10-23 22:49:29,655:INFO:   category_encoders: 2.6.2
2023-10-23 22:49:29,655:INFO:            lightgbm: 4.1.0
2023-10-23 22:49:29,655:INFO:               numba: 0.58.1
2023-10-23 22:49:29,655:INFO:            requests: 2.31.0
2023-10-23 22:49:29,655:INFO:          matplotlib: 3.7.3
2023-10-23 22:49:29,655:INFO:          scikitplot: 0.3.7
2023-10-23 22:49:29,655:INFO:         yellowbrick: 1.5
2023-10-23 22:49:29,655:INFO:              plotly: 5.17.0
2023-10-23 22:49:29,655:INFO:    plotly-resampler: Not installed
2023-10-23 22:49:29,655:INFO:             kaleido: 0.2.1
2023-10-23 22:49:29,656:INFO:           schemdraw: 0.15
2023-10-23 22:49:29,656:INFO:         statsmodels: 0.14.0
2023-10-23 22:49:29,656:INFO:              sktime: 0.21.1
2023-10-23 22:49:29,656:INFO:               tbats: 1.1.3
2023-10-23 22:49:29,656:INFO:            pmdarima: 2.0.3
2023-10-23 22:49:29,656:INFO:              psutil: 5.9.0
2023-10-23 22:49:29,656:INFO:          markupsafe: 2.1.3
2023-10-23 22:49:29,656:INFO:             pickle5: Not installed
2023-10-23 22:49:29,656:INFO:         cloudpickle: 2.2.1
2023-10-23 22:49:29,656:INFO:         deprecation: 2.1.0
2023-10-23 22:49:29,656:INFO:              xxhash: 3.4.1
2023-10-23 22:49:29,657:INFO:           wurlitzer: Not installed
2023-10-23 22:49:29,657:INFO:PyCaret optional dependencies:
2023-10-23 22:49:29,657:INFO:                shap: Not installed
2023-10-23 22:49:29,657:INFO:           interpret: Not installed
2023-10-23 22:49:29,657:INFO:                umap: Not installed
2023-10-23 22:49:29,657:INFO:     ydata_profiling: Not installed
2023-10-23 22:49:29,657:INFO:  explainerdashboard: Not installed
2023-10-23 22:49:29,657:INFO:             autoviz: Not installed
2023-10-23 22:49:29,657:INFO:           fairlearn: Not installed
2023-10-23 22:49:29,657:INFO:          deepchecks: Not installed
2023-10-23 22:49:29,657:INFO:             xgboost: Not installed
2023-10-23 22:49:29,657:INFO:            catboost: 1.2.2
2023-10-23 22:49:29,658:INFO:              kmodes: Not installed
2023-10-23 22:49:29,658:INFO:             mlxtend: Not installed
2023-10-23 22:49:29,658:INFO:       statsforecast: Not installed
2023-10-23 22:49:29,658:INFO:        tune_sklearn: Not installed
2023-10-23 22:49:29,658:INFO:                 ray: Not installed
2023-10-23 22:49:29,658:INFO:            hyperopt: Not installed
2023-10-23 22:49:29,658:INFO:              optuna: Not installed
2023-10-23 22:49:29,658:INFO:               skopt: Not installed
2023-10-23 22:49:29,658:INFO:              mlflow: 2.7.1
2023-10-23 22:49:29,658:INFO:              gradio: Not installed
2023-10-23 22:49:29,658:INFO:             fastapi: Not installed
2023-10-23 22:49:29,658:INFO:             uvicorn: Not installed
2023-10-23 22:49:29,658:INFO:              m2cgen: Not installed
2023-10-23 22:49:29,658:INFO:           evidently: Not installed
2023-10-23 22:49:29,658:INFO:               fugue: Not installed
2023-10-23 22:49:29,658:INFO:           streamlit: Not installed
2023-10-23 22:49:29,658:INFO:             prophet: Not installed
2023-10-23 22:49:29,659:INFO:None
2023-10-23 22:49:29,659:INFO:Set up data.
2023-10-23 22:49:29,693:INFO:Set up folding strategy.
2023-10-23 22:49:29,693:INFO:Set up train/test split.
2023-10-23 22:49:29,716:INFO:Set up index.
2023-10-23 22:49:29,718:INFO:Assigning column types.
2023-10-23 22:49:29,738:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 22:49:29,738:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 22:49:29,738:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 22:49:29,749:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:49:29,822:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:49:29,870:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:49:29,870:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:49:29,870:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:49:29,870:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 22:49:29,870:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 22:49:29,889:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:49:29,958:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:49:30,004:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:49:30,004:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:49:30,004:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:49:30,004:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 22:49:30,004:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 22:49:30,020:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:49:30,091:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:49:30,138:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:49:30,138:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:49:30,138:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:49:30,150:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 22:49:30,154:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:49:30,224:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:49:30,275:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:49:30,275:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:49:30,275:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:49:30,275:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 22:49:30,293:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:49:30,358:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:49:30,410:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:49:30,410:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:49:30,410:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:49:30,425:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:49:30,496:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:49:30,551:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:49:30,551:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:49:30,552:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:49:30,552:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 22:49:30,641:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:49:30,688:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:49:30,689:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:49:30,689:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:49:30,770:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:49:30,825:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:49:30,826:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:49:30,826:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:49:30,826:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 22:49:30,904:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:49:30,961:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:49:30,961:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:49:31,044:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:49:31,095:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:49:31,095:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:49:31,095:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 22:49:31,241:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:49:31,241:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:49:31,376:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:49:31,376:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:49:31,376:INFO:Preparing preprocessing pipeline...
2023-10-23 22:49:31,376:INFO:Set up date feature engineering.
2023-10-23 22:49:31,376:INFO:Set up simple imputation.
2023-10-23 22:49:31,391:INFO:Set up encoding of ordinal features.
2023-10-23 22:49:31,403:INFO:Set up encoding of categorical features.
2023-10-23 22:49:31,404:INFO:Set up variance threshold.
2023-10-23 22:49:31,404:INFO:Set up removing outliers.
2023-10-23 22:49:31,407:INFO:Set up column name cleaning.
2023-10-23 22:49:31,757:INFO:Finished creating preprocessing pipeline.
2023-10-23 22:49:31,830:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 22:49:31,830:INFO:Creating final display dataframe.
2023-10-23 22:49:31,971:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (34061, 48)
4        Transformed data shape  (32868, 37)
5   Transformed train set shape  (22649, 37)
6    Transformed test set shape  (10219, 37)
7              Ordinal features            2
8              Numeric features           43
9                 Date features            1
10         Categorical features            3
11     Rows with missing values        97.6%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18       Low variance threshold         0.05
19              Remove outliers         True
20           Outliers threshold         0.05
21               Fold Generator        KFold
22                  Fold Number           10
23                     CPU Jobs           -1
24                      Use GPU        False
25               Log Experiment        False
26              Experiment Name        exp_A
27                          USI         dea2
2023-10-23 22:49:32,103:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:49:32,103:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:49:32,240:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:49:32,240:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:49:32,240:INFO:setup() successfully completed in 2.6s...............
2023-10-23 22:49:32,240:INFO:Initializing compare_models()
2023-10-23 22:49:32,240:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020359667850>, include=['catboost', 'lightgbm'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000020359667850>, 'include': ['catboost', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-10-23 22:49:32,240:INFO:Checking exceptions
2023-10-23 22:49:32,254:INFO:Preparing display monitor
2023-10-23 22:49:32,256:INFO:Initializing CatBoost Regressor
2023-10-23 22:49:32,256:INFO:Total runtime is 0.0 minutes
2023-10-23 22:49:32,256:INFO:SubProcess create_model() called ==================================
2023-10-23 22:49:32,256:INFO:Initializing create_model()
2023-10-23 22:49:32,256:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020359667850>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002035B56BCD0>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 22:49:32,256:INFO:Checking exceptions
2023-10-23 22:49:32,256:INFO:Importing libraries
2023-10-23 22:49:32,256:INFO:Copying training dataset
2023-10-23 22:49:32,284:INFO:Defining folds
2023-10-23 22:49:32,284:INFO:Declaring metric variables
2023-10-23 22:49:32,284:INFO:Importing untrained model
2023-10-23 22:49:32,286:INFO:CatBoost Regressor Imported successfully
2023-10-23 22:49:32,287:INFO:Starting cross validation
2023-10-23 22:49:32,292:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 22:49:39,686:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 22:49:39,718:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 22:49:39,746:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 22:49:39,758:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 22:49:39,758:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 22:49:39,772:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 22:49:39,788:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 22:49:39,803:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 22:49:39,803:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 22:49:39,803:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 22:50:13,169:INFO:Calculating mean and std
2023-10-23 22:50:13,169:INFO:Creating metrics dataframe
2023-10-23 22:50:13,169:INFO:Uploading results into container
2023-10-23 22:50:13,169:INFO:Uploading model into container now
2023-10-23 22:50:13,169:INFO:_master_model_container: 1
2023-10-23 22:50:13,169:INFO:_display_container: 2
2023-10-23 22:50:13,169:INFO:<catboost.core.CatBoostRegressor object at 0x000002035C1C7DC0>
2023-10-23 22:50:13,169:INFO:create_model() successfully completed......................................
2023-10-23 22:50:13,390:INFO:SubProcess create_model() end ==================================
2023-10-23 22:50:13,390:INFO:Creating metrics dataframe
2023-10-23 22:50:13,401:INFO:Initializing Light Gradient Boosting Machine
2023-10-23 22:50:13,402:INFO:Total runtime is 0.6857690572738647 minutes
2023-10-23 22:50:13,402:INFO:SubProcess create_model() called ==================================
2023-10-23 22:50:13,402:INFO:Initializing create_model()
2023-10-23 22:50:13,402:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020359667850>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002035B56BCD0>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 22:50:13,402:INFO:Checking exceptions
2023-10-23 22:50:13,402:INFO:Importing libraries
2023-10-23 22:50:13,402:INFO:Copying training dataset
2023-10-23 22:50:13,418:INFO:Defining folds
2023-10-23 22:50:13,418:INFO:Declaring metric variables
2023-10-23 22:50:13,418:INFO:Importing untrained model
2023-10-23 22:50:13,418:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 22:50:13,418:INFO:Starting cross validation
2023-10-23 22:50:13,418:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 22:50:14,367:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 22:50:14,367:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 22:50:14,384:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 22:50:14,390:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 22:50:19,635:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 22:50:20,356:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 22:50:20,403:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 22:50:20,419:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 22:50:20,689:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 22:50:22,227:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 22:50:27,612:INFO:Calculating mean and std
2023-10-23 22:50:27,612:INFO:Creating metrics dataframe
2023-10-23 22:50:27,612:INFO:Uploading results into container
2023-10-23 22:50:27,612:INFO:Uploading model into container now
2023-10-23 22:50:27,612:INFO:_master_model_container: 2
2023-10-23 22:50:27,612:INFO:_display_container: 2
2023-10-23 22:50:27,612:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 22:50:27,612:INFO:create_model() successfully completed......................................
2023-10-23 22:50:27,790:INFO:SubProcess create_model() end ==================================
2023-10-23 22:50:27,790:INFO:Creating metrics dataframe
2023-10-23 22:50:27,806:INFO:Initializing create_model()
2023-10-23 22:50:27,806:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020359667850>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 22:50:27,806:INFO:Checking exceptions
2023-10-23 22:50:27,806:INFO:Importing libraries
2023-10-23 22:50:27,806:INFO:Copying training dataset
2023-10-23 22:50:27,830:INFO:Defining folds
2023-10-23 22:50:27,830:INFO:Declaring metric variables
2023-10-23 22:50:27,830:INFO:Importing untrained model
2023-10-23 22:50:27,830:INFO:Declaring custom model
2023-10-23 22:50:27,832:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 22:50:27,832:INFO:Cross validation set to False
2023-10-23 22:50:27,832:INFO:Fitting Model
2023-10-23 22:50:28,239:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 22:50:29,704:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004197 seconds.
2023-10-23 22:50:29,720:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 22:50:29,720:INFO:[LightGBM] [Info] Total Bins 5949
2023-10-23 22:50:29,721:INFO:[LightGBM] [Info] Number of data points in the train set: 22649, number of used features: 36
2023-10-23 22:50:29,722:INFO:[LightGBM] [Info] Start training from score 528.587231
2023-10-23 22:50:29,888:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 22:50:29,888:INFO:create_model() successfully completed......................................
2023-10-23 22:50:30,088:INFO:_master_model_container: 2
2023-10-23 22:50:30,088:INFO:_display_container: 2
2023-10-23 22:50:30,088:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 22:50:30,088:INFO:compare_models() successfully completed......................................
2023-10-23 22:50:30,103:INFO:Initializing finalize_model()
2023-10-23 22:50:30,104:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020359667850>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-23 22:50:30,105:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 22:50:30,105:INFO:Initializing create_model()
2023-10-23 22:50:30,105:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020359667850>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-23 22:50:30,105:INFO:Checking exceptions
2023-10-23 22:50:30,120:INFO:Importing libraries
2023-10-23 22:50:30,120:INFO:Copying training dataset
2023-10-23 22:50:30,121:INFO:Defining folds
2023-10-23 22:50:30,121:INFO:Declaring metric variables
2023-10-23 22:50:30,121:INFO:Importing untrained model
2023-10-23 22:50:30,121:INFO:Declaring custom model
2023-10-23 22:50:30,123:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 22:50:30,124:INFO:Cross validation set to False
2023-10-23 22:50:30,124:INFO:Fitting Model
2023-10-23 22:50:30,638:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 22:55:25,743:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\3621255004.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  a = merged_data_a.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 22:55:25,777:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\3621255004.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  b = merged_data_b.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 22:55:25,810:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\3621255004.py:3: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  c = merged_data_c.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 22:55:25,894:INFO:PyCaret RegressionExperiment
2023-10-23 22:55:25,894:INFO:Logging name: exp_A
2023-10-23 22:55:25,894:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 22:55:25,895:INFO:version 3.1.0
2023-10-23 22:55:25,895:INFO:Initializing setup()
2023-10-23 22:55:25,895:INFO:self.USI: 3389
2023-10-23 22:55:25,895:INFO:self._variable_keys: {'memory', 'X_train', 'fold_generator', 'log_plots_param', 'data', 'logging_param', 'target_param', 'exp_id', 'X_test', 'html_param', 'USI', 'transform_target_param', 'idx', 'pipeline', 'fold_shuffle_param', 'seed', 'y_test', 'y_train', 'n_jobs_param', '_ml_usecase', 'gpu_n_jobs_param', 'exp_name_log', 'fold_groups_param', '_available_plots', 'y', 'X', 'gpu_param'}
2023-10-23 22:55:25,895:INFO:Checking environment
2023-10-23 22:55:25,895:INFO:python_version: 3.8.18
2023-10-23 22:55:25,895:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 22:55:25,895:INFO:machine: AMD64
2023-10-23 22:55:25,895:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 22:55:25,895:INFO:Memory: svmem(total=16505954304, available=3811106816, percent=76.9, used=12694847488, free=3811106816)
2023-10-23 22:55:25,895:INFO:Physical Core: 8
2023-10-23 22:55:25,895:INFO:Logical Core: 16
2023-10-23 22:55:25,895:INFO:Checking libraries
2023-10-23 22:55:25,895:INFO:System:
2023-10-23 22:55:25,896:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 22:55:25,896:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 22:55:25,896:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 22:55:25,896:INFO:PyCaret required dependencies:
2023-10-23 22:55:25,896:INFO:                 pip: 23.3
2023-10-23 22:55:25,896:INFO:          setuptools: 68.0.0
2023-10-23 22:55:25,896:INFO:             pycaret: 3.1.0
2023-10-23 22:55:25,896:INFO:             IPython: 8.12.0
2023-10-23 22:55:25,896:INFO:          ipywidgets: 8.1.1
2023-10-23 22:55:25,896:INFO:                tqdm: 4.66.1
2023-10-23 22:55:25,896:INFO:               numpy: 1.23.5
2023-10-23 22:55:25,896:INFO:              pandas: 1.5.3
2023-10-23 22:55:25,896:INFO:              jinja2: 3.1.2
2023-10-23 22:55:25,897:INFO:               scipy: 1.10.1
2023-10-23 22:55:25,897:INFO:              joblib: 1.3.2
2023-10-23 22:55:25,897:INFO:             sklearn: 1.2.2
2023-10-23 22:55:25,897:INFO:                pyod: 1.1.0
2023-10-23 22:55:25,897:INFO:            imblearn: 0.11.0
2023-10-23 22:55:25,897:INFO:   category_encoders: 2.6.2
2023-10-23 22:55:25,897:INFO:            lightgbm: 4.1.0
2023-10-23 22:55:25,897:INFO:               numba: 0.58.1
2023-10-23 22:55:25,897:INFO:            requests: 2.31.0
2023-10-23 22:55:25,897:INFO:          matplotlib: 3.7.3
2023-10-23 22:55:25,897:INFO:          scikitplot: 0.3.7
2023-10-23 22:55:25,897:INFO:         yellowbrick: 1.5
2023-10-23 22:55:25,897:INFO:              plotly: 5.17.0
2023-10-23 22:55:25,897:INFO:    plotly-resampler: Not installed
2023-10-23 22:55:25,897:INFO:             kaleido: 0.2.1
2023-10-23 22:55:25,897:INFO:           schemdraw: 0.15
2023-10-23 22:55:25,897:INFO:         statsmodels: 0.14.0
2023-10-23 22:55:25,898:INFO:              sktime: 0.21.1
2023-10-23 22:55:25,898:INFO:               tbats: 1.1.3
2023-10-23 22:55:25,898:INFO:            pmdarima: 2.0.3
2023-10-23 22:55:25,898:INFO:              psutil: 5.9.0
2023-10-23 22:55:25,898:INFO:          markupsafe: 2.1.3
2023-10-23 22:55:25,898:INFO:             pickle5: Not installed
2023-10-23 22:55:25,898:INFO:         cloudpickle: 2.2.1
2023-10-23 22:55:25,898:INFO:         deprecation: 2.1.0
2023-10-23 22:55:25,898:INFO:              xxhash: 3.4.1
2023-10-23 22:55:25,898:INFO:           wurlitzer: Not installed
2023-10-23 22:55:25,898:INFO:PyCaret optional dependencies:
2023-10-23 22:55:25,898:INFO:                shap: Not installed
2023-10-23 22:55:25,898:INFO:           interpret: Not installed
2023-10-23 22:55:25,898:INFO:                umap: Not installed
2023-10-23 22:55:25,898:INFO:     ydata_profiling: Not installed
2023-10-23 22:55:25,898:INFO:  explainerdashboard: Not installed
2023-10-23 22:55:25,898:INFO:             autoviz: Not installed
2023-10-23 22:55:25,898:INFO:           fairlearn: Not installed
2023-10-23 22:55:25,898:INFO:          deepchecks: Not installed
2023-10-23 22:55:25,898:INFO:             xgboost: Not installed
2023-10-23 22:55:25,898:INFO:            catboost: 1.2.2
2023-10-23 22:55:25,899:INFO:              kmodes: Not installed
2023-10-23 22:55:25,899:INFO:             mlxtend: Not installed
2023-10-23 22:55:25,899:INFO:       statsforecast: Not installed
2023-10-23 22:55:25,899:INFO:        tune_sklearn: Not installed
2023-10-23 22:55:25,899:INFO:                 ray: Not installed
2023-10-23 22:55:25,899:INFO:            hyperopt: Not installed
2023-10-23 22:55:25,899:INFO:              optuna: Not installed
2023-10-23 22:55:25,899:INFO:               skopt: Not installed
2023-10-23 22:55:25,899:INFO:              mlflow: 2.7.1
2023-10-23 22:55:25,899:INFO:              gradio: Not installed
2023-10-23 22:55:25,899:INFO:             fastapi: Not installed
2023-10-23 22:55:25,899:INFO:             uvicorn: Not installed
2023-10-23 22:55:25,899:INFO:              m2cgen: Not installed
2023-10-23 22:55:25,899:INFO:           evidently: Not installed
2023-10-23 22:55:25,899:INFO:               fugue: Not installed
2023-10-23 22:55:25,899:INFO:           streamlit: Not installed
2023-10-23 22:55:25,899:INFO:             prophet: Not installed
2023-10-23 22:55:25,899:INFO:None
2023-10-23 22:55:25,899:INFO:Set up data.
2023-10-23 22:55:25,928:INFO:Set up folding strategy.
2023-10-23 22:55:25,928:INFO:Set up train/test split.
2023-10-23 22:55:25,945:INFO:Set up index.
2023-10-23 22:55:25,960:INFO:Assigning column types.
2023-10-23 22:55:25,979:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 22:55:25,979:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 22:55:25,979:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 22:55:25,994:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:55:26,061:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:55:26,128:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:55:26,128:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:55:26,128:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:55:26,128:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 22:55:26,142:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 22:55:26,145:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:55:26,228:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:55:26,275:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:55:26,276:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:55:26,276:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:55:26,276:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 22:55:26,276:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 22:55:26,276:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:55:26,363:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:55:26,411:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:55:26,412:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:55:26,412:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:55:26,417:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 22:55:26,417:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:55:26,501:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:55:26,549:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:55:26,550:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:55:26,551:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:55:26,551:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 22:55:26,561:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:55:26,635:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:55:26,685:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:55:26,685:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:55:26,685:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:55:26,698:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:55:26,776:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:55:26,818:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:55:26,818:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:55:26,818:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:55:26,825:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 22:55:26,917:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:55:26,968:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:55:26,969:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:55:26,969:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:55:27,060:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:55:27,107:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:55:27,109:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:55:27,109:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:55:27,109:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 22:55:27,199:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:55:27,244:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:55:27,244:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:55:27,334:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:55:27,383:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:55:27,383:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:55:27,384:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 22:55:27,516:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:55:27,516:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:55:27,649:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:55:27,649:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:55:27,649:INFO:Preparing preprocessing pipeline...
2023-10-23 22:55:27,649:INFO:Set up date feature engineering.
2023-10-23 22:55:27,649:INFO:Set up simple imputation.
2023-10-23 22:55:27,665:INFO:Set up encoding of ordinal features.
2023-10-23 22:55:27,681:INFO:Set up encoding of categorical features.
2023-10-23 22:55:27,681:INFO:Set up variance threshold.
2023-10-23 22:55:27,681:INFO:Set up column name cleaning.
2023-10-23 22:55:27,992:INFO:Finished creating preprocessing pipeline.
2023-10-23 22:55:28,046:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 22:55:28,046:INFO:Creating final display dataframe.
2023-10-23 22:55:28,777:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (34061, 48)
4        Transformed data shape  (34061, 37)
5   Transformed train set shape  (23842, 37)
6    Transformed test set shape  (10219, 37)
7              Ordinal features            2
8              Numeric features           43
9                 Date features            1
10         Categorical features            3
11     Rows with missing values        97.6%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18       Low variance threshold         0.05
19               Fold Generator        KFold
20                  Fold Number           10
21                     CPU Jobs           -1
22                      Use GPU        False
23               Log Experiment        False
24              Experiment Name        exp_A
25                          USI         3389
2023-10-23 22:55:28,929:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:55:28,929:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:55:29,080:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:55:29,080:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:55:29,080:INFO:setup() successfully completed in 3.2s...............
2023-10-23 22:55:29,080:INFO:Initializing compare_models()
2023-10-23 22:55:29,080:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035FC00280>, include=['catboost', 'lightgbm'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002035FC00280>, 'include': ['catboost', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-10-23 22:55:29,080:INFO:Checking exceptions
2023-10-23 22:55:29,092:INFO:Preparing display monitor
2023-10-23 22:55:29,092:INFO:Initializing CatBoost Regressor
2023-10-23 22:55:29,092:INFO:Total runtime is 0.0 minutes
2023-10-23 22:55:29,092:INFO:SubProcess create_model() called ==================================
2023-10-23 22:55:29,092:INFO:Initializing create_model()
2023-10-23 22:55:29,092:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035FC00280>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002035A367FA0>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 22:55:29,092:INFO:Checking exceptions
2023-10-23 22:55:29,092:INFO:Importing libraries
2023-10-23 22:55:29,092:INFO:Copying training dataset
2023-10-23 22:55:29,131:INFO:Defining folds
2023-10-23 22:55:29,131:INFO:Declaring metric variables
2023-10-23 22:55:29,132:INFO:Importing untrained model
2023-10-23 22:55:29,132:INFO:CatBoost Regressor Imported successfully
2023-10-23 22:55:29,132:INFO:Starting cross validation
2023-10-23 22:55:29,134:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 22:56:04,995:INFO:Calculating mean and std
2023-10-23 22:56:04,995:INFO:Creating metrics dataframe
2023-10-23 22:56:04,995:INFO:Uploading results into container
2023-10-23 22:56:04,995:INFO:Uploading model into container now
2023-10-23 22:56:04,995:INFO:_master_model_container: 1
2023-10-23 22:56:04,995:INFO:_display_container: 2
2023-10-23 22:56:04,995:INFO:<catboost.core.CatBoostRegressor object at 0x0000020359319AC0>
2023-10-23 22:56:04,995:INFO:create_model() successfully completed......................................
2023-10-23 22:56:05,215:INFO:SubProcess create_model() end ==================================
2023-10-23 22:56:05,215:INFO:Creating metrics dataframe
2023-10-23 22:56:05,218:INFO:Initializing Light Gradient Boosting Machine
2023-10-23 22:56:05,218:INFO:Total runtime is 0.6020943323771158 minutes
2023-10-23 22:56:05,218:INFO:SubProcess create_model() called ==================================
2023-10-23 22:56:05,218:INFO:Initializing create_model()
2023-10-23 22:56:05,218:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035FC00280>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002035A367FA0>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 22:56:05,218:INFO:Checking exceptions
2023-10-23 22:56:05,218:INFO:Importing libraries
2023-10-23 22:56:05,218:INFO:Copying training dataset
2023-10-23 22:56:05,234:INFO:Defining folds
2023-10-23 22:56:05,234:INFO:Declaring metric variables
2023-10-23 22:56:05,234:INFO:Importing untrained model
2023-10-23 22:56:05,234:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 22:56:05,234:INFO:Starting cross validation
2023-10-23 22:56:05,234:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 22:56:12,088:INFO:Calculating mean and std
2023-10-23 22:56:12,088:INFO:Creating metrics dataframe
2023-10-23 22:56:12,088:INFO:Uploading results into container
2023-10-23 22:56:12,088:INFO:Uploading model into container now
2023-10-23 22:56:12,088:INFO:_master_model_container: 2
2023-10-23 22:56:12,088:INFO:_display_container: 2
2023-10-23 22:56:12,088:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 22:56:12,088:INFO:create_model() successfully completed......................................
2023-10-23 22:56:12,288:INFO:SubProcess create_model() end ==================================
2023-10-23 22:56:12,288:INFO:Creating metrics dataframe
2023-10-23 22:56:12,288:INFO:Initializing create_model()
2023-10-23 22:56:12,288:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035FC00280>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 22:56:12,288:INFO:Checking exceptions
2023-10-23 22:56:12,288:INFO:Importing libraries
2023-10-23 22:56:12,288:INFO:Copying training dataset
2023-10-23 22:56:12,305:INFO:Defining folds
2023-10-23 22:56:12,321:INFO:Declaring metric variables
2023-10-23 22:56:12,321:INFO:Importing untrained model
2023-10-23 22:56:12,321:INFO:Declaring custom model
2023-10-23 22:56:12,322:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 22:56:12,324:INFO:Cross validation set to False
2023-10-23 22:56:12,324:INFO:Fitting Model
2023-10-23 22:56:12,571:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004051 seconds.
2023-10-23 22:56:12,571:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 22:56:12,571:INFO:[LightGBM] [Info] Total Bins 6029
2023-10-23 22:56:12,571:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 36
2023-10-23 22:56:12,571:INFO:[LightGBM] [Info] Start training from score 616.864890
2023-10-23 22:56:12,755:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 22:56:12,755:INFO:create_model() successfully completed......................................
2023-10-23 22:56:12,977:INFO:_master_model_container: 2
2023-10-23 22:56:12,977:INFO:_display_container: 2
2023-10-23 22:56:12,977:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 22:56:12,977:INFO:compare_models() successfully completed......................................
2023-10-23 22:56:12,977:INFO:Initializing finalize_model()
2023-10-23 22:56:12,977:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035FC00280>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-23 22:56:12,977:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 22:56:12,988:INFO:Initializing create_model()
2023-10-23 22:56:12,988:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035FC00280>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-23 22:56:12,988:INFO:Checking exceptions
2023-10-23 22:56:12,988:INFO:Importing libraries
2023-10-23 22:56:12,988:INFO:Copying training dataset
2023-10-23 22:56:12,988:INFO:Defining folds
2023-10-23 22:56:12,988:INFO:Declaring metric variables
2023-10-23 22:56:12,988:INFO:Importing untrained model
2023-10-23 22:56:12,988:INFO:Declaring custom model
2023-10-23 22:56:12,988:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 22:56:13,003:INFO:Cross validation set to False
2023-10-23 22:56:13,003:INFO:Fitting Model
2023-10-23 22:56:13,436:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009902 seconds.
2023-10-23 22:56:13,436:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 22:56:13,437:INFO:[LightGBM] [Info] Total Bins 6436
2023-10-23 22:56:13,437:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 37
2023-10-23 22:56:13,440:INFO:[LightGBM] [Info] Start training from score 631.011165
2023-10-23 22:56:13,743:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-23 22:56:13,743:INFO:create_model() successfully completed......................................
2023-10-23 22:56:13,966:INFO:_master_model_container: 2
2023-10-23 22:56:13,966:INFO:_display_container: 2
2023-10-23 22:56:14,025:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-23 22:56:14,025:INFO:finalize_model() successfully completed......................................
2023-10-23 22:56:14,325:INFO:Initializing save_model()
2023-10-23 22:56:14,325:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_A, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 22:56:14,325:INFO:Adding model into prep_pipe
2023-10-23 22:56:14,325:WARNING:Only Model saved as it was a pipeline.
2023-10-23 22:56:14,341:INFO:final_model_for_location_A.pkl saved in current working directory
2023-10-23 22:56:14,457:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-23 22:56:14,457:INFO:save_model() successfully completed......................................
2023-10-23 22:56:34,991:INFO:PyCaret RegressionExperiment
2023-10-23 22:56:34,991:INFO:Logging name: exp_A
2023-10-23 22:56:34,991:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 22:56:34,992:INFO:version 3.1.0
2023-10-23 22:56:34,992:INFO:Initializing setup()
2023-10-23 22:56:34,992:INFO:self.USI: 3f43
2023-10-23 22:56:34,992:INFO:self._variable_keys: {'memory', 'X_train', 'fold_generator', 'log_plots_param', 'data', 'logging_param', 'target_param', 'exp_id', 'X_test', 'html_param', 'USI', 'transform_target_param', 'idx', 'pipeline', 'fold_shuffle_param', 'seed', 'y_test', 'y_train', 'n_jobs_param', '_ml_usecase', 'gpu_n_jobs_param', 'exp_name_log', 'fold_groups_param', '_available_plots', 'y', 'X', 'gpu_param'}
2023-10-23 22:56:34,992:INFO:Checking environment
2023-10-23 22:56:34,992:INFO:python_version: 3.8.18
2023-10-23 22:56:34,992:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 22:56:34,992:INFO:machine: AMD64
2023-10-23 22:56:34,992:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 22:56:34,993:INFO:Memory: svmem(total=16505954304, available=3259396096, percent=80.3, used=13246558208, free=3259396096)
2023-10-23 22:56:34,993:INFO:Physical Core: 8
2023-10-23 22:56:34,993:INFO:Logical Core: 16
2023-10-23 22:56:34,993:INFO:Checking libraries
2023-10-23 22:56:34,993:INFO:System:
2023-10-23 22:56:34,993:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 22:56:34,994:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 22:56:34,994:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 22:56:34,994:INFO:PyCaret required dependencies:
2023-10-23 22:56:34,994:INFO:                 pip: 23.3
2023-10-23 22:56:34,994:INFO:          setuptools: 68.0.0
2023-10-23 22:56:34,994:INFO:             pycaret: 3.1.0
2023-10-23 22:56:34,994:INFO:             IPython: 8.12.0
2023-10-23 22:56:34,994:INFO:          ipywidgets: 8.1.1
2023-10-23 22:56:34,994:INFO:                tqdm: 4.66.1
2023-10-23 22:56:34,994:INFO:               numpy: 1.23.5
2023-10-23 22:56:34,996:INFO:              pandas: 1.5.3
2023-10-23 22:56:34,996:INFO:              jinja2: 3.1.2
2023-10-23 22:56:34,996:INFO:               scipy: 1.10.1
2023-10-23 22:56:34,996:INFO:              joblib: 1.3.2
2023-10-23 22:56:34,996:INFO:             sklearn: 1.2.2
2023-10-23 22:56:34,996:INFO:                pyod: 1.1.0
2023-10-23 22:56:34,996:INFO:            imblearn: 0.11.0
2023-10-23 22:56:34,996:INFO:   category_encoders: 2.6.2
2023-10-23 22:56:34,996:INFO:            lightgbm: 4.1.0
2023-10-23 22:56:34,997:INFO:               numba: 0.58.1
2023-10-23 22:56:34,997:INFO:            requests: 2.31.0
2023-10-23 22:56:34,997:INFO:          matplotlib: 3.7.3
2023-10-23 22:56:34,997:INFO:          scikitplot: 0.3.7
2023-10-23 22:56:34,997:INFO:         yellowbrick: 1.5
2023-10-23 22:56:34,997:INFO:              plotly: 5.17.0
2023-10-23 22:56:34,997:INFO:    plotly-resampler: Not installed
2023-10-23 22:56:34,997:INFO:             kaleido: 0.2.1
2023-10-23 22:56:34,997:INFO:           schemdraw: 0.15
2023-10-23 22:56:34,997:INFO:         statsmodels: 0.14.0
2023-10-23 22:56:34,998:INFO:              sktime: 0.21.1
2023-10-23 22:56:34,998:INFO:               tbats: 1.1.3
2023-10-23 22:56:34,998:INFO:            pmdarima: 2.0.3
2023-10-23 22:56:34,998:INFO:              psutil: 5.9.0
2023-10-23 22:56:34,998:INFO:          markupsafe: 2.1.3
2023-10-23 22:56:34,998:INFO:             pickle5: Not installed
2023-10-23 22:56:34,998:INFO:         cloudpickle: 2.2.1
2023-10-23 22:56:34,998:INFO:         deprecation: 2.1.0
2023-10-23 22:56:34,998:INFO:              xxhash: 3.4.1
2023-10-23 22:56:34,998:INFO:           wurlitzer: Not installed
2023-10-23 22:56:34,999:INFO:PyCaret optional dependencies:
2023-10-23 22:56:34,999:INFO:                shap: Not installed
2023-10-23 22:56:34,999:INFO:           interpret: Not installed
2023-10-23 22:56:34,999:INFO:                umap: Not installed
2023-10-23 22:56:34,999:INFO:     ydata_profiling: Not installed
2023-10-23 22:56:34,999:INFO:  explainerdashboard: Not installed
2023-10-23 22:56:34,999:INFO:             autoviz: Not installed
2023-10-23 22:56:34,999:INFO:           fairlearn: Not installed
2023-10-23 22:56:34,999:INFO:          deepchecks: Not installed
2023-10-23 22:56:34,999:INFO:             xgboost: Not installed
2023-10-23 22:56:34,999:INFO:            catboost: 1.2.2
2023-10-23 22:56:34,999:INFO:              kmodes: Not installed
2023-10-23 22:56:35,000:INFO:             mlxtend: Not installed
2023-10-23 22:56:35,000:INFO:       statsforecast: Not installed
2023-10-23 22:56:35,000:INFO:        tune_sklearn: Not installed
2023-10-23 22:56:35,000:INFO:                 ray: Not installed
2023-10-23 22:56:35,000:INFO:            hyperopt: Not installed
2023-10-23 22:56:35,000:INFO:              optuna: Not installed
2023-10-23 22:56:35,000:INFO:               skopt: Not installed
2023-10-23 22:56:35,000:INFO:              mlflow: 2.7.1
2023-10-23 22:56:35,001:INFO:              gradio: Not installed
2023-10-23 22:56:35,001:INFO:             fastapi: Not installed
2023-10-23 22:56:35,001:INFO:             uvicorn: Not installed
2023-10-23 22:56:35,001:INFO:              m2cgen: Not installed
2023-10-23 22:56:35,001:INFO:           evidently: Not installed
2023-10-23 22:56:35,001:INFO:               fugue: Not installed
2023-10-23 22:56:35,001:INFO:           streamlit: Not installed
2023-10-23 22:56:35,001:INFO:             prophet: Not installed
2023-10-23 22:56:35,001:INFO:None
2023-10-23 22:56:35,001:INFO:Set up data.
2023-10-23 22:56:35,036:INFO:Set up folding strategy.
2023-10-23 22:56:35,036:INFO:Set up train/test split.
2023-10-23 22:56:35,078:INFO:Set up index.
2023-10-23 22:56:35,080:INFO:Assigning column types.
2023-10-23 22:56:35,102:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 22:56:35,102:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 22:56:35,105:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 22:56:35,105:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:56:35,191:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:56:35,246:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:56:35,246:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:56:35,246:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:56:35,246:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 22:56:35,252:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 22:56:35,257:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:56:35,335:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:56:35,375:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:56:35,375:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:56:35,375:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:56:35,375:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 22:56:35,387:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 22:56:35,391:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:56:35,470:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:56:35,520:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:56:35,520:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:56:35,520:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:56:35,520:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 22:56:35,520:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:56:35,611:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:56:35,670:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:56:35,670:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:56:35,671:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:56:35,671:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 22:56:35,682:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:56:35,753:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:56:35,803:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:56:35,803:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:56:35,803:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:56:35,820:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:56:35,902:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:56:35,952:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:56:35,953:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:56:35,953:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:56:35,953:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 22:56:36,041:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:56:36,095:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:56:36,095:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:56:36,096:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:56:36,187:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:56:36,236:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:56:36,236:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:56:36,236:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:56:36,236:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 22:56:36,319:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:56:36,372:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:56:36,372:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:56:36,457:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:56:36,509:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:56:36,509:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:56:36,509:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 22:56:36,650:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:56:36,650:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:56:36,788:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:56:36,788:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:56:36,790:INFO:Preparing preprocessing pipeline...
2023-10-23 22:56:36,791:INFO:Set up date feature engineering.
2023-10-23 22:56:36,791:INFO:Set up simple imputation.
2023-10-23 22:56:36,801:INFO:Set up encoding of ordinal features.
2023-10-23 22:56:36,814:INFO:Set up encoding of categorical features.
2023-10-23 22:56:36,815:INFO:Set up variance threshold.
2023-10-23 22:56:36,817:INFO:Set up column name cleaning.
2023-10-23 22:56:37,103:INFO:Finished creating preprocessing pipeline.
2023-10-23 22:56:37,157:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 22:56:37,157:INFO:Creating final display dataframe.
2023-10-23 22:56:37,305:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (34061, 48)
4        Transformed data shape  (34061, 37)
5   Transformed train set shape  (23842, 37)
6    Transformed test set shape  (10219, 37)
7              Ordinal features            2
8              Numeric features           43
9                 Date features            1
10         Categorical features            3
11     Rows with missing values        97.6%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18       Low variance threshold         0.05
19               Fold Generator        KFold
20                  Fold Number           10
21                     CPU Jobs           -1
22                      Use GPU        False
23               Log Experiment        False
24              Experiment Name        exp_A
25                          USI         3f43
2023-10-23 22:56:37,435:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:56:37,435:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:56:37,590:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:56:37,590:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:56:37,590:INFO:setup() successfully completed in 2.61s...............
2023-10-23 22:56:37,590:INFO:Initializing compare_models()
2023-10-23 22:56:37,590:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000203595E6460>, include=['catboost', 'lightgbm'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000203595E6460>, 'include': ['catboost', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-10-23 22:56:37,590:INFO:Checking exceptions
2023-10-23 22:56:37,605:INFO:Preparing display monitor
2023-10-23 22:56:37,611:INFO:Initializing CatBoost Regressor
2023-10-23 22:56:37,611:INFO:Total runtime is 0.0 minutes
2023-10-23 22:56:37,612:INFO:SubProcess create_model() called ==================================
2023-10-23 22:56:37,612:INFO:Initializing create_model()
2023-10-23 22:56:37,612:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000203595E6460>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000203592DD250>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 22:56:37,612:INFO:Checking exceptions
2023-10-23 22:56:37,612:INFO:Importing libraries
2023-10-23 22:56:37,612:INFO:Copying training dataset
2023-10-23 22:56:37,641:INFO:Defining folds
2023-10-23 22:56:37,641:INFO:Declaring metric variables
2023-10-23 22:56:37,641:INFO:Importing untrained model
2023-10-23 22:56:37,641:INFO:CatBoost Regressor Imported successfully
2023-10-23 22:56:37,642:INFO:Starting cross validation
2023-10-23 22:56:37,644:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 22:57:14,441:INFO:Calculating mean and std
2023-10-23 22:57:14,441:INFO:Creating metrics dataframe
2023-10-23 22:57:14,441:INFO:Uploading results into container
2023-10-23 22:57:14,441:INFO:Uploading model into container now
2023-10-23 22:57:14,441:INFO:_master_model_container: 1
2023-10-23 22:57:14,441:INFO:_display_container: 2
2023-10-23 22:57:14,441:INFO:<catboost.core.CatBoostRegressor object at 0x000002035C356DC0>
2023-10-23 22:57:14,441:INFO:create_model() successfully completed......................................
2023-10-23 22:57:14,724:INFO:SubProcess create_model() end ==================================
2023-10-23 22:57:14,724:INFO:Creating metrics dataframe
2023-10-23 22:57:14,736:INFO:Initializing Light Gradient Boosting Machine
2023-10-23 22:57:14,736:INFO:Total runtime is 0.6187543590863546 minutes
2023-10-23 22:57:14,736:INFO:SubProcess create_model() called ==================================
2023-10-23 22:57:14,737:INFO:Initializing create_model()
2023-10-23 22:57:14,737:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000203595E6460>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000203592DD250>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 22:57:14,737:INFO:Checking exceptions
2023-10-23 22:57:14,737:INFO:Importing libraries
2023-10-23 22:57:14,737:INFO:Copying training dataset
2023-10-23 22:57:14,767:INFO:Defining folds
2023-10-23 22:57:14,768:INFO:Declaring metric variables
2023-10-23 22:57:14,769:INFO:Importing untrained model
2023-10-23 22:57:14,770:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 22:57:14,770:INFO:Starting cross validation
2023-10-23 22:57:14,772:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 22:57:18,152:INFO:Calculating mean and std
2023-10-23 22:57:18,154:INFO:Creating metrics dataframe
2023-10-23 22:57:18,154:INFO:Uploading results into container
2023-10-23 22:57:18,154:INFO:Uploading model into container now
2023-10-23 22:57:18,154:INFO:_master_model_container: 2
2023-10-23 22:57:18,154:INFO:_display_container: 2
2023-10-23 22:57:18,154:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 22:57:18,154:INFO:create_model() successfully completed......................................
2023-10-23 22:57:18,351:INFO:SubProcess create_model() end ==================================
2023-10-23 22:57:18,351:INFO:Creating metrics dataframe
2023-10-23 22:57:18,367:INFO:Initializing create_model()
2023-10-23 22:57:18,367:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000203595E6460>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 22:57:18,367:INFO:Checking exceptions
2023-10-23 22:57:18,369:INFO:Importing libraries
2023-10-23 22:57:18,369:INFO:Copying training dataset
2023-10-23 22:57:18,386:INFO:Defining folds
2023-10-23 22:57:18,386:INFO:Declaring metric variables
2023-10-23 22:57:18,386:INFO:Importing untrained model
2023-10-23 22:57:18,386:INFO:Declaring custom model
2023-10-23 22:57:18,386:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 22:57:18,386:INFO:Cross validation set to False
2023-10-23 22:57:18,386:INFO:Fitting Model
2023-10-23 22:57:18,650:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004165 seconds.
2023-10-23 22:57:18,665:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 22:57:18,665:INFO:[LightGBM] [Info] Total Bins 6029
2023-10-23 22:57:18,666:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 36
2023-10-23 22:57:18,667:INFO:[LightGBM] [Info] Start training from score 616.864890
2023-10-23 22:57:18,887:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 22:57:18,887:INFO:create_model() successfully completed......................................
2023-10-23 22:57:19,122:INFO:_master_model_container: 2
2023-10-23 22:57:19,122:INFO:_display_container: 2
2023-10-23 22:57:19,122:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 22:57:19,122:INFO:compare_models() successfully completed......................................
2023-10-23 22:57:19,122:INFO:Initializing finalize_model()
2023-10-23 22:57:19,122:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000203595E6460>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-23 22:57:19,122:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 22:57:19,139:INFO:Initializing create_model()
2023-10-23 22:57:19,139:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000203595E6460>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-23 22:57:19,139:INFO:Checking exceptions
2023-10-23 22:57:19,139:INFO:Importing libraries
2023-10-23 22:57:19,139:INFO:Copying training dataset
2023-10-23 22:57:19,139:INFO:Defining folds
2023-10-23 22:57:19,139:INFO:Declaring metric variables
2023-10-23 22:57:19,139:INFO:Importing untrained model
2023-10-23 22:57:19,139:INFO:Declaring custom model
2023-10-23 22:57:19,139:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 22:57:19,149:INFO:Cross validation set to False
2023-10-23 22:57:19,149:INFO:Fitting Model
2023-10-23 22:57:19,532:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007552 seconds.
2023-10-23 22:57:19,533:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 22:57:19,533:INFO:[LightGBM] [Info] Total Bins 6436
2023-10-23 22:57:19,534:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 37
2023-10-23 22:57:19,535:INFO:[LightGBM] [Info] Start training from score 631.011165
2023-10-23 22:57:19,989:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-23 22:57:19,989:INFO:create_model() successfully completed......................................
2023-10-23 22:57:20,200:INFO:_master_model_container: 2
2023-10-23 22:57:20,200:INFO:_display_container: 2
2023-10-23 22:57:20,253:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-23 22:57:20,253:INFO:finalize_model() successfully completed......................................
2023-10-23 22:57:20,567:INFO:Initializing save_model()
2023-10-23 22:57:20,567:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_A, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 22:57:20,567:INFO:Adding model into prep_pipe
2023-10-23 22:57:20,567:WARNING:Only Model saved as it was a pipeline.
2023-10-23 22:57:20,590:INFO:final_model_for_location_A.pkl saved in current working directory
2023-10-23 22:57:20,699:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-23 22:57:20,699:INFO:save_model() successfully completed......................................
2023-10-23 22:57:20,949:INFO:Initializing plot_model()
2023-10-23 22:57:20,949:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000203595E6460>, system=True)
2023-10-23 22:57:20,949:INFO:Checking exceptions
2023-10-23 22:58:43,406:INFO:PyCaret RegressionExperiment
2023-10-23 22:58:43,406:INFO:Logging name: exp_A
2023-10-23 22:58:43,406:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 22:58:43,406:INFO:version 3.1.0
2023-10-23 22:58:43,406:INFO:Initializing setup()
2023-10-23 22:58:43,412:INFO:self.USI: e948
2023-10-23 22:58:43,412:INFO:self._variable_keys: {'memory', 'X_train', 'fold_generator', 'log_plots_param', 'data', 'logging_param', 'target_param', 'exp_id', 'X_test', 'html_param', 'USI', 'transform_target_param', 'idx', 'pipeline', 'fold_shuffle_param', 'seed', 'y_test', 'y_train', 'n_jobs_param', '_ml_usecase', 'gpu_n_jobs_param', 'exp_name_log', 'fold_groups_param', '_available_plots', 'y', 'X', 'gpu_param'}
2023-10-23 22:58:43,412:INFO:Checking environment
2023-10-23 22:58:43,412:INFO:python_version: 3.8.18
2023-10-23 22:58:43,413:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 22:58:43,413:INFO:machine: AMD64
2023-10-23 22:58:43,413:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 22:58:43,413:INFO:Memory: svmem(total=16505954304, available=2908631040, percent=82.4, used=13597323264, free=2908631040)
2023-10-23 22:58:43,413:INFO:Physical Core: 8
2023-10-23 22:58:43,415:INFO:Logical Core: 16
2023-10-23 22:58:43,415:INFO:Checking libraries
2023-10-23 22:58:43,415:INFO:System:
2023-10-23 22:58:43,415:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 22:58:43,416:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 22:58:43,416:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 22:58:43,416:INFO:PyCaret required dependencies:
2023-10-23 22:58:43,416:INFO:                 pip: 23.3
2023-10-23 22:58:43,417:INFO:          setuptools: 68.0.0
2023-10-23 22:58:43,417:INFO:             pycaret: 3.1.0
2023-10-23 22:58:43,417:INFO:             IPython: 8.12.0
2023-10-23 22:58:43,417:INFO:          ipywidgets: 8.1.1
2023-10-23 22:58:43,417:INFO:                tqdm: 4.66.1
2023-10-23 22:58:43,418:INFO:               numpy: 1.23.5
2023-10-23 22:58:43,418:INFO:              pandas: 1.5.3
2023-10-23 22:58:43,418:INFO:              jinja2: 3.1.2
2023-10-23 22:58:43,418:INFO:               scipy: 1.10.1
2023-10-23 22:58:43,419:INFO:              joblib: 1.3.2
2023-10-23 22:58:43,419:INFO:             sklearn: 1.2.2
2023-10-23 22:58:43,419:INFO:                pyod: 1.1.0
2023-10-23 22:58:43,419:INFO:            imblearn: 0.11.0
2023-10-23 22:58:43,419:INFO:   category_encoders: 2.6.2
2023-10-23 22:58:43,419:INFO:            lightgbm: 4.1.0
2023-10-23 22:58:43,419:INFO:               numba: 0.58.1
2023-10-23 22:58:43,419:INFO:            requests: 2.31.0
2023-10-23 22:58:43,419:INFO:          matplotlib: 3.7.3
2023-10-23 22:58:43,419:INFO:          scikitplot: 0.3.7
2023-10-23 22:58:43,419:INFO:         yellowbrick: 1.5
2023-10-23 22:58:43,419:INFO:              plotly: 5.17.0
2023-10-23 22:58:43,419:INFO:    plotly-resampler: Not installed
2023-10-23 22:58:43,419:INFO:             kaleido: 0.2.1
2023-10-23 22:58:43,419:INFO:           schemdraw: 0.15
2023-10-23 22:58:43,419:INFO:         statsmodels: 0.14.0
2023-10-23 22:58:43,419:INFO:              sktime: 0.21.1
2023-10-23 22:58:43,419:INFO:               tbats: 1.1.3
2023-10-23 22:58:43,419:INFO:            pmdarima: 2.0.3
2023-10-23 22:58:43,419:INFO:              psutil: 5.9.0
2023-10-23 22:58:43,419:INFO:          markupsafe: 2.1.3
2023-10-23 22:58:43,419:INFO:             pickle5: Not installed
2023-10-23 22:58:43,419:INFO:         cloudpickle: 2.2.1
2023-10-23 22:58:43,419:INFO:         deprecation: 2.1.0
2023-10-23 22:58:43,419:INFO:              xxhash: 3.4.1
2023-10-23 22:58:43,419:INFO:           wurlitzer: Not installed
2023-10-23 22:58:43,419:INFO:PyCaret optional dependencies:
2023-10-23 22:58:43,419:INFO:                shap: Not installed
2023-10-23 22:58:43,419:INFO:           interpret: Not installed
2023-10-23 22:58:43,419:INFO:                umap: Not installed
2023-10-23 22:58:43,419:INFO:     ydata_profiling: Not installed
2023-10-23 22:58:43,419:INFO:  explainerdashboard: Not installed
2023-10-23 22:58:43,419:INFO:             autoviz: Not installed
2023-10-23 22:58:43,419:INFO:           fairlearn: Not installed
2023-10-23 22:58:43,419:INFO:          deepchecks: Not installed
2023-10-23 22:58:43,419:INFO:             xgboost: Not installed
2023-10-23 22:58:43,419:INFO:            catboost: 1.2.2
2023-10-23 22:58:43,419:INFO:              kmodes: Not installed
2023-10-23 22:58:43,419:INFO:             mlxtend: Not installed
2023-10-23 22:58:43,419:INFO:       statsforecast: Not installed
2023-10-23 22:58:43,419:INFO:        tune_sklearn: Not installed
2023-10-23 22:58:43,419:INFO:                 ray: Not installed
2023-10-23 22:58:43,419:INFO:            hyperopt: Not installed
2023-10-23 22:58:43,419:INFO:              optuna: Not installed
2023-10-23 22:58:43,419:INFO:               skopt: Not installed
2023-10-23 22:58:43,419:INFO:              mlflow: 2.7.1
2023-10-23 22:58:43,419:INFO:              gradio: Not installed
2023-10-23 22:58:43,419:INFO:             fastapi: Not installed
2023-10-23 22:58:43,419:INFO:             uvicorn: Not installed
2023-10-23 22:58:43,419:INFO:              m2cgen: Not installed
2023-10-23 22:58:43,419:INFO:           evidently: Not installed
2023-10-23 22:58:43,419:INFO:               fugue: Not installed
2023-10-23 22:58:43,419:INFO:           streamlit: Not installed
2023-10-23 22:58:43,419:INFO:             prophet: Not installed
2023-10-23 22:58:43,419:INFO:None
2023-10-23 22:58:43,419:INFO:Set up data.
2023-10-23 22:58:43,452:INFO:Set up folding strategy.
2023-10-23 22:58:43,452:INFO:Set up train/test split.
2023-10-23 22:58:43,480:INFO:Set up index.
2023-10-23 22:58:43,480:INFO:Assigning column types.
2023-10-23 22:58:43,505:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 22:58:43,505:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 22:58:43,510:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 22:58:43,515:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:58:43,579:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:58:43,635:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:58:43,635:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:58:43,635:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:58:43,635:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 22:58:43,647:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 22:58:43,652:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:58:43,729:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:58:43,775:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:58:43,775:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:58:43,775:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:58:43,775:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 22:58:43,783:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 22:58:43,784:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:58:43,863:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:58:43,912:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:58:43,913:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:58:43,913:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:58:43,913:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 22:58:43,913:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:58:43,999:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:58:44,048:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:58:44,049:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:58:44,049:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:58:44,050:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 22:58:44,055:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:58:44,140:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:58:44,181:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:58:44,181:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:58:44,181:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:58:44,197:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 22:58:44,264:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:58:44,313:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:58:44,313:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:58:44,313:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:58:44,328:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 22:58:44,414:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:58:44,464:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:58:44,464:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:58:44,464:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:58:44,552:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:58:44,599:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 22:58:44,599:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:58:44,599:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:58:44,599:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 22:58:44,679:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:58:44,729:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:58:44,729:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:58:44,816:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 22:58:44,873:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:58:44,873:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:58:44,873:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 22:58:45,013:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:58:45,013:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:58:45,152:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:58:45,152:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:58:45,153:INFO:Preparing preprocessing pipeline...
2023-10-23 22:58:45,153:INFO:Set up date feature engineering.
2023-10-23 22:58:45,153:INFO:Set up simple imputation.
2023-10-23 22:58:45,153:INFO:Set up encoding of ordinal features.
2023-10-23 22:58:45,168:INFO:Set up encoding of categorical features.
2023-10-23 22:58:45,168:INFO:Set up variance threshold.
2023-10-23 22:58:45,168:INFO:Set up column name cleaning.
2023-10-23 22:58:45,479:INFO:Finished creating preprocessing pipeline.
2023-10-23 22:58:45,538:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 22:58:45,538:INFO:Creating final display dataframe.
2023-10-23 22:58:45,696:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (34061, 48)
4        Transformed data shape  (34061, 37)
5   Transformed train set shape  (23842, 37)
6    Transformed test set shape  (10219, 37)
7              Ordinal features            2
8              Numeric features           43
9                 Date features            1
10         Categorical features            3
11     Rows with missing values        97.6%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18       Low variance threshold         0.05
19               Fold Generator        KFold
20                  Fold Number           10
21                     CPU Jobs           -1
22                      Use GPU        False
23               Log Experiment        False
24              Experiment Name        exp_A
25                          USI         e948
2023-10-23 22:58:45,862:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:58:45,863:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:58:45,995:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 22:58:45,995:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 22:58:45,995:INFO:setup() successfully completed in 2.6s...............
2023-10-23 22:58:45,995:INFO:Initializing compare_models()
2023-10-23 22:58:45,995:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002036306D970>, include=['catboost', 'lightgbm'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002036306D970>, 'include': ['catboost', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-10-23 22:58:45,995:INFO:Checking exceptions
2023-10-23 22:58:46,015:INFO:Preparing display monitor
2023-10-23 22:58:46,020:INFO:Initializing CatBoost Regressor
2023-10-23 22:58:46,020:INFO:Total runtime is 0.0 minutes
2023-10-23 22:58:46,020:INFO:SubProcess create_model() called ==================================
2023-10-23 22:58:46,021:INFO:Initializing create_model()
2023-10-23 22:58:46,021:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002036306D970>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002035A263CA0>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 22:58:46,021:INFO:Checking exceptions
2023-10-23 22:58:46,021:INFO:Importing libraries
2023-10-23 22:58:46,021:INFO:Copying training dataset
2023-10-23 22:58:46,044:INFO:Defining folds
2023-10-23 22:58:46,044:INFO:Declaring metric variables
2023-10-23 22:58:46,044:INFO:Importing untrained model
2023-10-23 22:58:46,045:INFO:CatBoost Regressor Imported successfully
2023-10-23 22:58:46,045:INFO:Starting cross validation
2023-10-23 22:58:46,047:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 22:59:16,954:INFO:Calculating mean and std
2023-10-23 22:59:16,954:INFO:Creating metrics dataframe
2023-10-23 22:59:16,954:INFO:Uploading results into container
2023-10-23 22:59:16,954:INFO:Uploading model into container now
2023-10-23 22:59:16,954:INFO:_master_model_container: 1
2023-10-23 22:59:16,954:INFO:_display_container: 2
2023-10-23 22:59:16,954:INFO:<catboost.core.CatBoostRegressor object at 0x000002035AF8A730>
2023-10-23 22:59:16,954:INFO:create_model() successfully completed......................................
2023-10-23 22:59:17,173:INFO:SubProcess create_model() end ==================================
2023-10-23 22:59:17,173:INFO:Creating metrics dataframe
2023-10-23 22:59:17,173:INFO:Initializing Light Gradient Boosting Machine
2023-10-23 22:59:17,173:INFO:Total runtime is 0.5192282478014628 minutes
2023-10-23 22:59:17,173:INFO:SubProcess create_model() called ==================================
2023-10-23 22:59:17,173:INFO:Initializing create_model()
2023-10-23 22:59:17,173:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002036306D970>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002035A263CA0>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 22:59:17,173:INFO:Checking exceptions
2023-10-23 22:59:17,173:INFO:Importing libraries
2023-10-23 22:59:17,173:INFO:Copying training dataset
2023-10-23 22:59:17,205:INFO:Defining folds
2023-10-23 22:59:17,205:INFO:Declaring metric variables
2023-10-23 22:59:17,205:INFO:Importing untrained model
2023-10-23 22:59:17,205:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 22:59:17,205:INFO:Starting cross validation
2023-10-23 22:59:17,205:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 22:59:20,415:INFO:Calculating mean and std
2023-10-23 22:59:20,417:INFO:Creating metrics dataframe
2023-10-23 22:59:20,420:INFO:Uploading results into container
2023-10-23 22:59:20,421:INFO:Uploading model into container now
2023-10-23 22:59:20,421:INFO:_master_model_container: 2
2023-10-23 22:59:20,422:INFO:_display_container: 2
2023-10-23 22:59:20,422:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 22:59:20,422:INFO:create_model() successfully completed......................................
2023-10-23 22:59:20,617:INFO:SubProcess create_model() end ==================================
2023-10-23 22:59:20,617:INFO:Creating metrics dataframe
2023-10-23 22:59:20,635:INFO:Initializing create_model()
2023-10-23 22:59:20,636:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002036306D970>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 22:59:20,636:INFO:Checking exceptions
2023-10-23 22:59:20,637:INFO:Importing libraries
2023-10-23 22:59:20,637:INFO:Copying training dataset
2023-10-23 22:59:20,653:INFO:Defining folds
2023-10-23 22:59:20,653:INFO:Declaring metric variables
2023-10-23 22:59:20,653:INFO:Importing untrained model
2023-10-23 22:59:20,653:INFO:Declaring custom model
2023-10-23 22:59:20,653:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 22:59:20,653:INFO:Cross validation set to False
2023-10-23 22:59:20,653:INFO:Fitting Model
2023-10-23 22:59:20,915:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004869 seconds.
2023-10-23 22:59:20,915:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 22:59:20,915:INFO:[LightGBM] [Info] Total Bins 6029
2023-10-23 22:59:20,915:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 36
2023-10-23 22:59:20,915:INFO:[LightGBM] [Info] Start training from score 616.864890
2023-10-23 22:59:21,147:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 22:59:21,147:INFO:create_model() successfully completed......................................
2023-10-23 22:59:21,389:INFO:_master_model_container: 2
2023-10-23 22:59:21,389:INFO:_display_container: 2
2023-10-23 22:59:21,389:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 22:59:21,389:INFO:compare_models() successfully completed......................................
2023-10-23 22:59:21,391:INFO:Initializing finalize_model()
2023-10-23 22:59:21,391:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002036306D970>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-23 22:59:21,391:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 22:59:21,404:INFO:Initializing create_model()
2023-10-23 22:59:21,404:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002036306D970>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-23 22:59:21,404:INFO:Checking exceptions
2023-10-23 22:59:21,404:INFO:Importing libraries
2023-10-23 22:59:21,404:INFO:Copying training dataset
2023-10-23 22:59:21,404:INFO:Defining folds
2023-10-23 22:59:21,404:INFO:Declaring metric variables
2023-10-23 22:59:21,404:INFO:Importing untrained model
2023-10-23 22:59:21,404:INFO:Declaring custom model
2023-10-23 22:59:21,404:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 22:59:21,404:INFO:Cross validation set to False
2023-10-23 22:59:21,404:INFO:Fitting Model
2023-10-23 22:59:21,781:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009368 seconds.
2023-10-23 22:59:21,781:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 22:59:21,781:INFO:[LightGBM] [Info] Total Bins 6436
2023-10-23 22:59:21,781:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 37
2023-10-23 22:59:21,781:INFO:[LightGBM] [Info] Start training from score 631.011165
2023-10-23 22:59:22,148:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-23 22:59:22,148:INFO:create_model() successfully completed......................................
2023-10-23 22:59:22,348:INFO:_master_model_container: 2
2023-10-23 22:59:22,348:INFO:_display_container: 2
2023-10-23 22:59:22,414:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-23 22:59:22,414:INFO:finalize_model() successfully completed......................................
2023-10-23 22:59:22,730:INFO:Initializing save_model()
2023-10-23 22:59:22,730:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_A, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 22:59:22,730:INFO:Adding model into prep_pipe
2023-10-23 22:59:22,730:WARNING:Only Model saved as it was a pipeline.
2023-10-23 22:59:22,746:INFO:final_model_for_location_A.pkl saved in current working directory
2023-10-23 22:59:22,847:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-23 22:59:22,847:INFO:save_model() successfully completed......................................
2023-10-23 22:59:23,114:INFO:Initializing plot_model()
2023-10-23 22:59:23,114:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002036306D970>, system=True)
2023-10-23 22:59:23,114:INFO:Checking exceptions
2023-10-23 22:59:23,114:INFO:Preloading libraries
2023-10-23 22:59:23,130:INFO:Copying training dataset
2023-10-23 22:59:23,131:INFO:Plot type: residuals
2023-10-23 22:59:23,371:INFO:Fitting Model
2023-10-23 23:00:12,469:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\985316847.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  a = merged_data_a.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 23:00:12,506:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\985316847.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  b = merged_data_b.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 23:00:12,545:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\985316847.py:3: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  c = merged_data_c.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 23:00:12,573:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\985316847.py:19: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  X_test_estimated_a = X_test_estimated_a.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 23:00:12,573:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\985316847.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  X_test_estimated_b = X_test_estimated_b.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 23:00:12,573:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\985316847.py:21: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  X_test_estimated_c = X_test_estimated_c.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 23:00:12,628:INFO:PyCaret RegressionExperiment
2023-10-23 23:00:12,628:INFO:Logging name: exp_A
2023-10-23 23:00:12,629:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 23:00:12,629:INFO:version 3.1.0
2023-10-23 23:00:12,629:INFO:Initializing setup()
2023-10-23 23:00:12,629:INFO:self.USI: 93a6
2023-10-23 23:00:12,629:INFO:self._variable_keys: {'memory', 'X_train', 'fold_generator', 'log_plots_param', 'data', 'logging_param', 'target_param', 'exp_id', 'X_test', 'html_param', 'USI', 'transform_target_param', 'idx', 'pipeline', 'fold_shuffle_param', 'seed', 'y_test', 'y_train', 'n_jobs_param', '_ml_usecase', 'gpu_n_jobs_param', 'exp_name_log', 'fold_groups_param', '_available_plots', 'y', 'X', 'gpu_param'}
2023-10-23 23:00:12,629:INFO:Checking environment
2023-10-23 23:00:12,629:INFO:python_version: 3.8.18
2023-10-23 23:00:12,629:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 23:00:12,629:INFO:machine: AMD64
2023-10-23 23:00:12,629:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 23:00:12,630:INFO:Memory: svmem(total=16505954304, available=2832936960, percent=82.8, used=13673017344, free=2832936960)
2023-10-23 23:00:12,630:INFO:Physical Core: 8
2023-10-23 23:00:12,630:INFO:Logical Core: 16
2023-10-23 23:00:12,630:INFO:Checking libraries
2023-10-23 23:00:12,630:INFO:System:
2023-10-23 23:00:12,630:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 23:00:12,630:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 23:00:12,630:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 23:00:12,630:INFO:PyCaret required dependencies:
2023-10-23 23:00:12,630:INFO:                 pip: 23.3
2023-10-23 23:00:12,630:INFO:          setuptools: 68.0.0
2023-10-23 23:00:12,630:INFO:             pycaret: 3.1.0
2023-10-23 23:00:12,630:INFO:             IPython: 8.12.0
2023-10-23 23:00:12,630:INFO:          ipywidgets: 8.1.1
2023-10-23 23:00:12,630:INFO:                tqdm: 4.66.1
2023-10-23 23:00:12,630:INFO:               numpy: 1.23.5
2023-10-23 23:00:12,630:INFO:              pandas: 1.5.3
2023-10-23 23:00:12,630:INFO:              jinja2: 3.1.2
2023-10-23 23:00:12,630:INFO:               scipy: 1.10.1
2023-10-23 23:00:12,630:INFO:              joblib: 1.3.2
2023-10-23 23:00:12,630:INFO:             sklearn: 1.2.2
2023-10-23 23:00:12,630:INFO:                pyod: 1.1.0
2023-10-23 23:00:12,631:INFO:            imblearn: 0.11.0
2023-10-23 23:00:12,631:INFO:   category_encoders: 2.6.2
2023-10-23 23:00:12,631:INFO:            lightgbm: 4.1.0
2023-10-23 23:00:12,631:INFO:               numba: 0.58.1
2023-10-23 23:00:12,631:INFO:            requests: 2.31.0
2023-10-23 23:00:12,631:INFO:          matplotlib: 3.7.3
2023-10-23 23:00:12,631:INFO:          scikitplot: 0.3.7
2023-10-23 23:00:12,631:INFO:         yellowbrick: 1.5
2023-10-23 23:00:12,631:INFO:              plotly: 5.17.0
2023-10-23 23:00:12,631:INFO:    plotly-resampler: Not installed
2023-10-23 23:00:12,631:INFO:             kaleido: 0.2.1
2023-10-23 23:00:12,631:INFO:           schemdraw: 0.15
2023-10-23 23:00:12,631:INFO:         statsmodels: 0.14.0
2023-10-23 23:00:12,631:INFO:              sktime: 0.21.1
2023-10-23 23:00:12,631:INFO:               tbats: 1.1.3
2023-10-23 23:00:12,631:INFO:            pmdarima: 2.0.3
2023-10-23 23:00:12,631:INFO:              psutil: 5.9.0
2023-10-23 23:00:12,631:INFO:          markupsafe: 2.1.3
2023-10-23 23:00:12,631:INFO:             pickle5: Not installed
2023-10-23 23:00:12,631:INFO:         cloudpickle: 2.2.1
2023-10-23 23:00:12,631:INFO:         deprecation: 2.1.0
2023-10-23 23:00:12,631:INFO:              xxhash: 3.4.1
2023-10-23 23:00:12,631:INFO:           wurlitzer: Not installed
2023-10-23 23:00:12,631:INFO:PyCaret optional dependencies:
2023-10-23 23:00:12,632:INFO:                shap: Not installed
2023-10-23 23:00:12,632:INFO:           interpret: Not installed
2023-10-23 23:00:12,632:INFO:                umap: Not installed
2023-10-23 23:00:12,632:INFO:     ydata_profiling: Not installed
2023-10-23 23:00:12,632:INFO:  explainerdashboard: Not installed
2023-10-23 23:00:12,632:INFO:             autoviz: Not installed
2023-10-23 23:00:12,632:INFO:           fairlearn: Not installed
2023-10-23 23:00:12,632:INFO:          deepchecks: Not installed
2023-10-23 23:00:12,632:INFO:             xgboost: Not installed
2023-10-23 23:00:12,632:INFO:            catboost: 1.2.2
2023-10-23 23:00:12,632:INFO:              kmodes: Not installed
2023-10-23 23:00:12,632:INFO:             mlxtend: Not installed
2023-10-23 23:00:12,632:INFO:       statsforecast: Not installed
2023-10-23 23:00:12,632:INFO:        tune_sklearn: Not installed
2023-10-23 23:00:12,632:INFO:                 ray: Not installed
2023-10-23 23:00:12,632:INFO:            hyperopt: Not installed
2023-10-23 23:00:12,632:INFO:              optuna: Not installed
2023-10-23 23:00:12,632:INFO:               skopt: Not installed
2023-10-23 23:00:12,632:INFO:              mlflow: 2.7.1
2023-10-23 23:00:12,632:INFO:              gradio: Not installed
2023-10-23 23:00:12,632:INFO:             fastapi: Not installed
2023-10-23 23:00:12,632:INFO:             uvicorn: Not installed
2023-10-23 23:00:12,632:INFO:              m2cgen: Not installed
2023-10-23 23:00:12,632:INFO:           evidently: Not installed
2023-10-23 23:00:12,632:INFO:               fugue: Not installed
2023-10-23 23:00:12,632:INFO:           streamlit: Not installed
2023-10-23 23:00:12,633:INFO:             prophet: Not installed
2023-10-23 23:00:12,633:INFO:None
2023-10-23 23:00:12,633:INFO:Set up data.
2023-10-23 23:00:12,663:INFO:Set up folding strategy.
2023-10-23 23:00:12,663:INFO:Set up train/test split.
2023-10-23 23:00:12,678:INFO:Set up index.
2023-10-23 23:00:12,678:INFO:Assigning column types.
2023-10-23 23:00:12,708:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 23:00:12,709:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 23:00:12,713:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:00:12,713:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:00:12,795:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:00:12,844:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:00:12,844:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:00:12,845:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:00:12,845:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 23:00:12,850:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:00:12,855:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:00:12,924:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:00:12,980:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:00:12,980:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:00:12,980:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:00:12,980:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 23:00:12,980:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:00:12,988:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:00:13,056:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:00:13,110:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:00:13,110:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:00:13,110:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:00:13,110:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:00:13,126:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:00:13,195:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:00:13,242:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:00:13,242:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:00:13,242:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:00:13,242:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 23:00:13,258:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:00:13,336:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:00:13,384:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:00:13,385:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:00:13,385:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:00:13,389:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:00:13,458:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:00:13,511:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:00:13,511:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:00:13,511:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:00:13,517:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 23:00:13,601:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:00:13,649:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:00:13,649:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:00:13,650:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:00:13,738:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:00:13,787:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:00:13,788:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:00:13,788:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:00:13,788:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 23:00:13,874:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:00:13,921:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:00:13,921:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:00:14,007:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:00:14,045:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:00:14,045:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:00:14,061:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 23:00:14,190:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:00:14,190:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:00:14,324:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:00:14,324:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:00:14,324:INFO:Preparing preprocessing pipeline...
2023-10-23 23:00:14,324:INFO:Set up date feature engineering.
2023-10-23 23:00:14,324:INFO:Set up simple imputation.
2023-10-23 23:00:14,340:INFO:Set up encoding of ordinal features.
2023-10-23 23:00:14,357:INFO:Set up encoding of categorical features.
2023-10-23 23:00:14,357:INFO:Set up variance threshold.
2023-10-23 23:00:14,357:INFO:Set up column name cleaning.
2023-10-23 23:00:14,647:INFO:Finished creating preprocessing pipeline.
2023-10-23 23:00:14,711:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 23:00:14,711:INFO:Creating final display dataframe.
2023-10-23 23:00:14,845:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (34061, 48)
4        Transformed data shape  (34061, 37)
5   Transformed train set shape  (23842, 37)
6    Transformed test set shape  (10219, 37)
7              Ordinal features            2
8              Numeric features           43
9                 Date features            1
10         Categorical features            3
11     Rows with missing values        97.6%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18       Low variance threshold         0.05
19               Fold Generator        KFold
20                  Fold Number           10
21                     CPU Jobs           -1
22                      Use GPU        False
23               Log Experiment        False
24              Experiment Name        exp_A
25                          USI         93a6
2023-10-23 23:00:14,991:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:00:14,991:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:00:15,133:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:00:15,133:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:00:15,133:INFO:setup() successfully completed in 2.51s...............
2023-10-23 23:00:15,133:INFO:Initializing compare_models()
2023-10-23 23:00:15,133:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035B3E2250>, include=['catboost', 'lightgbm'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002035B3E2250>, 'include': ['catboost', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-10-23 23:00:15,133:INFO:Checking exceptions
2023-10-23 23:00:15,149:INFO:Preparing display monitor
2023-10-23 23:00:15,155:INFO:Initializing CatBoost Regressor
2023-10-23 23:00:15,155:INFO:Total runtime is 0.0 minutes
2023-10-23 23:00:15,155:INFO:SubProcess create_model() called ==================================
2023-10-23 23:00:15,155:INFO:Initializing create_model()
2023-10-23 23:00:15,155:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035B3E2250>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002035D13FDC0>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 23:00:15,155:INFO:Checking exceptions
2023-10-23 23:00:15,155:INFO:Importing libraries
2023-10-23 23:00:15,155:INFO:Copying training dataset
2023-10-23 23:00:15,170:INFO:Defining folds
2023-10-23 23:00:15,170:INFO:Declaring metric variables
2023-10-23 23:00:15,170:INFO:Importing untrained model
2023-10-23 23:00:15,170:INFO:CatBoost Regressor Imported successfully
2023-10-23 23:00:15,170:INFO:Starting cross validation
2023-10-23 23:00:15,170:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 23:00:46,380:INFO:Calculating mean and std
2023-10-23 23:00:46,380:INFO:Creating metrics dataframe
2023-10-23 23:00:46,380:INFO:Uploading results into container
2023-10-23 23:00:46,380:INFO:Uploading model into container now
2023-10-23 23:00:46,380:INFO:_master_model_container: 1
2023-10-23 23:00:46,380:INFO:_display_container: 2
2023-10-23 23:00:46,380:INFO:<catboost.core.CatBoostRegressor object at 0x000002035950C9A0>
2023-10-23 23:00:46,380:INFO:create_model() successfully completed......................................
2023-10-23 23:00:46,597:INFO:SubProcess create_model() end ==================================
2023-10-23 23:00:46,597:INFO:Creating metrics dataframe
2023-10-23 23:00:46,613:INFO:Initializing Light Gradient Boosting Machine
2023-10-23 23:00:46,613:INFO:Total runtime is 0.524294642607371 minutes
2023-10-23 23:00:46,613:INFO:SubProcess create_model() called ==================================
2023-10-23 23:00:46,613:INFO:Initializing create_model()
2023-10-23 23:00:46,613:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035B3E2250>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002035D13FDC0>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 23:00:46,613:INFO:Checking exceptions
2023-10-23 23:00:46,613:INFO:Importing libraries
2023-10-23 23:00:46,613:INFO:Copying training dataset
2023-10-23 23:00:46,629:INFO:Defining folds
2023-10-23 23:00:46,629:INFO:Declaring metric variables
2023-10-23 23:00:46,629:INFO:Importing untrained model
2023-10-23 23:00:46,629:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 23:00:46,629:INFO:Starting cross validation
2023-10-23 23:00:46,629:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 23:00:50,027:INFO:Calculating mean and std
2023-10-23 23:00:50,030:INFO:Creating metrics dataframe
2023-10-23 23:00:50,030:INFO:Uploading results into container
2023-10-23 23:00:50,030:INFO:Uploading model into container now
2023-10-23 23:00:50,030:INFO:_master_model_container: 2
2023-10-23 23:00:50,030:INFO:_display_container: 2
2023-10-23 23:00:50,030:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:00:50,030:INFO:create_model() successfully completed......................................
2023-10-23 23:00:50,241:INFO:SubProcess create_model() end ==================================
2023-10-23 23:00:50,241:INFO:Creating metrics dataframe
2023-10-23 23:00:50,262:INFO:Initializing create_model()
2023-10-23 23:00:50,262:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035B3E2250>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 23:00:50,262:INFO:Checking exceptions
2023-10-23 23:00:50,263:INFO:Importing libraries
2023-10-23 23:00:50,263:INFO:Copying training dataset
2023-10-23 23:00:50,284:INFO:Defining folds
2023-10-23 23:00:50,284:INFO:Declaring metric variables
2023-10-23 23:00:50,284:INFO:Importing untrained model
2023-10-23 23:00:50,284:INFO:Declaring custom model
2023-10-23 23:00:50,284:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 23:00:50,284:INFO:Cross validation set to False
2023-10-23 23:00:50,284:INFO:Fitting Model
2023-10-23 23:00:50,584:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004742 seconds.
2023-10-23 23:00:50,584:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 23:00:50,584:INFO:[LightGBM] [Info] Total Bins 6029
2023-10-23 23:00:50,584:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 36
2023-10-23 23:00:50,584:INFO:[LightGBM] [Info] Start training from score 616.864890
2023-10-23 23:00:50,792:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:00:50,793:INFO:create_model() successfully completed......................................
2023-10-23 23:00:51,029:INFO:_master_model_container: 2
2023-10-23 23:00:51,029:INFO:_display_container: 2
2023-10-23 23:00:51,029:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:00:51,029:INFO:compare_models() successfully completed......................................
2023-10-23 23:00:51,029:INFO:Initializing finalize_model()
2023-10-23 23:00:51,029:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035B3E2250>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-23 23:00:51,029:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:00:51,045:INFO:Initializing create_model()
2023-10-23 23:00:51,045:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035B3E2250>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-23 23:00:51,045:INFO:Checking exceptions
2023-10-23 23:00:51,045:INFO:Importing libraries
2023-10-23 23:00:51,045:INFO:Copying training dataset
2023-10-23 23:00:51,048:INFO:Defining folds
2023-10-23 23:00:51,048:INFO:Declaring metric variables
2023-10-23 23:00:51,049:INFO:Importing untrained model
2023-10-23 23:00:51,049:INFO:Declaring custom model
2023-10-23 23:00:51,050:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 23:00:51,050:INFO:Cross validation set to False
2023-10-23 23:00:51,050:INFO:Fitting Model
2023-10-23 23:00:51,414:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009426 seconds.
2023-10-23 23:00:51,414:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 23:00:51,414:INFO:[LightGBM] [Info] Total Bins 6436
2023-10-23 23:00:51,414:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 37
2023-10-23 23:00:51,414:INFO:[LightGBM] [Info] Start training from score 631.011165
2023-10-23 23:00:51,762:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-23 23:00:51,762:INFO:create_model() successfully completed......................................
2023-10-23 23:00:51,961:INFO:_master_model_container: 2
2023-10-23 23:00:51,961:INFO:_display_container: 2
2023-10-23 23:00:52,024:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-23 23:00:52,024:INFO:finalize_model() successfully completed......................................
2023-10-23 23:00:52,357:INFO:Initializing save_model()
2023-10-23 23:00:52,357:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_A, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 23:00:52,357:INFO:Adding model into prep_pipe
2023-10-23 23:00:52,357:WARNING:Only Model saved as it was a pipeline.
2023-10-23 23:00:52,362:INFO:final_model_for_location_A.pkl saved in current working directory
2023-10-23 23:00:52,479:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-23 23:00:52,479:INFO:save_model() successfully completed......................................
2023-10-23 23:00:52,747:INFO:Initializing plot_model()
2023-10-23 23:00:52,747:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035B3E2250>, system=True)
2023-10-23 23:00:52,747:INFO:Checking exceptions
2023-10-23 23:00:52,759:INFO:Preloading libraries
2023-10-23 23:00:52,767:INFO:Copying training dataset
2023-10-23 23:00:52,767:INFO:Plot type: residuals
2023-10-23 23:00:52,989:INFO:Fitting Model
2023-10-23 23:01:49,442:INFO:PyCaret RegressionExperiment
2023-10-23 23:01:49,442:INFO:Logging name: exp_A
2023-10-23 23:01:49,443:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 23:01:49,443:INFO:version 3.1.0
2023-10-23 23:01:49,443:INFO:Initializing setup()
2023-10-23 23:01:49,443:INFO:self.USI: e00c
2023-10-23 23:01:49,443:INFO:self._variable_keys: {'memory', 'X_train', 'fold_generator', 'log_plots_param', 'data', 'logging_param', 'target_param', 'exp_id', 'X_test', 'html_param', 'USI', 'transform_target_param', 'idx', 'pipeline', 'fold_shuffle_param', 'seed', 'y_test', 'y_train', 'n_jobs_param', '_ml_usecase', 'gpu_n_jobs_param', 'exp_name_log', 'fold_groups_param', '_available_plots', 'y', 'X', 'gpu_param'}
2023-10-23 23:01:49,443:INFO:Checking environment
2023-10-23 23:01:49,443:INFO:python_version: 3.8.18
2023-10-23 23:01:49,443:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 23:01:49,443:INFO:machine: AMD64
2023-10-23 23:01:49,443:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 23:01:49,443:INFO:Memory: svmem(total=16505954304, available=2779561984, percent=83.2, used=13726392320, free=2779561984)
2023-10-23 23:01:49,443:INFO:Physical Core: 8
2023-10-23 23:01:49,443:INFO:Logical Core: 16
2023-10-23 23:01:49,443:INFO:Checking libraries
2023-10-23 23:01:49,443:INFO:System:
2023-10-23 23:01:49,443:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 23:01:49,443:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 23:01:49,443:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 23:01:49,443:INFO:PyCaret required dependencies:
2023-10-23 23:01:49,443:INFO:                 pip: 23.3
2023-10-23 23:01:49,443:INFO:          setuptools: 68.0.0
2023-10-23 23:01:49,443:INFO:             pycaret: 3.1.0
2023-10-23 23:01:49,443:INFO:             IPython: 8.12.0
2023-10-23 23:01:49,443:INFO:          ipywidgets: 8.1.1
2023-10-23 23:01:49,443:INFO:                tqdm: 4.66.1
2023-10-23 23:01:49,443:INFO:               numpy: 1.23.5
2023-10-23 23:01:49,443:INFO:              pandas: 1.5.3
2023-10-23 23:01:49,443:INFO:              jinja2: 3.1.2
2023-10-23 23:01:49,443:INFO:               scipy: 1.10.1
2023-10-23 23:01:49,443:INFO:              joblib: 1.3.2
2023-10-23 23:01:49,443:INFO:             sklearn: 1.2.2
2023-10-23 23:01:49,443:INFO:                pyod: 1.1.0
2023-10-23 23:01:49,443:INFO:            imblearn: 0.11.0
2023-10-23 23:01:49,443:INFO:   category_encoders: 2.6.2
2023-10-23 23:01:49,443:INFO:            lightgbm: 4.1.0
2023-10-23 23:01:49,443:INFO:               numba: 0.58.1
2023-10-23 23:01:49,443:INFO:            requests: 2.31.0
2023-10-23 23:01:49,443:INFO:          matplotlib: 3.7.3
2023-10-23 23:01:49,443:INFO:          scikitplot: 0.3.7
2023-10-23 23:01:49,443:INFO:         yellowbrick: 1.5
2023-10-23 23:01:49,443:INFO:              plotly: 5.17.0
2023-10-23 23:01:49,443:INFO:    plotly-resampler: Not installed
2023-10-23 23:01:49,443:INFO:             kaleido: 0.2.1
2023-10-23 23:01:49,443:INFO:           schemdraw: 0.15
2023-10-23 23:01:49,443:INFO:         statsmodels: 0.14.0
2023-10-23 23:01:49,443:INFO:              sktime: 0.21.1
2023-10-23 23:01:49,443:INFO:               tbats: 1.1.3
2023-10-23 23:01:49,443:INFO:            pmdarima: 2.0.3
2023-10-23 23:01:49,443:INFO:              psutil: 5.9.0
2023-10-23 23:01:49,443:INFO:          markupsafe: 2.1.3
2023-10-23 23:01:49,443:INFO:             pickle5: Not installed
2023-10-23 23:01:49,443:INFO:         cloudpickle: 2.2.1
2023-10-23 23:01:49,443:INFO:         deprecation: 2.1.0
2023-10-23 23:01:49,443:INFO:              xxhash: 3.4.1
2023-10-23 23:01:49,443:INFO:           wurlitzer: Not installed
2023-10-23 23:01:49,443:INFO:PyCaret optional dependencies:
2023-10-23 23:01:49,443:INFO:                shap: Not installed
2023-10-23 23:01:49,443:INFO:           interpret: Not installed
2023-10-23 23:01:49,443:INFO:                umap: Not installed
2023-10-23 23:01:49,443:INFO:     ydata_profiling: Not installed
2023-10-23 23:01:49,443:INFO:  explainerdashboard: Not installed
2023-10-23 23:01:49,443:INFO:             autoviz: Not installed
2023-10-23 23:01:49,443:INFO:           fairlearn: Not installed
2023-10-23 23:01:49,443:INFO:          deepchecks: Not installed
2023-10-23 23:01:49,443:INFO:             xgboost: Not installed
2023-10-23 23:01:49,443:INFO:            catboost: 1.2.2
2023-10-23 23:01:49,443:INFO:              kmodes: Not installed
2023-10-23 23:01:49,443:INFO:             mlxtend: Not installed
2023-10-23 23:01:49,443:INFO:       statsforecast: Not installed
2023-10-23 23:01:49,443:INFO:        tune_sklearn: Not installed
2023-10-23 23:01:49,443:INFO:                 ray: Not installed
2023-10-23 23:01:49,443:INFO:            hyperopt: Not installed
2023-10-23 23:01:49,443:INFO:              optuna: Not installed
2023-10-23 23:01:49,443:INFO:               skopt: Not installed
2023-10-23 23:01:49,443:INFO:              mlflow: 2.7.1
2023-10-23 23:01:49,443:INFO:              gradio: Not installed
2023-10-23 23:01:49,443:INFO:             fastapi: Not installed
2023-10-23 23:01:49,443:INFO:             uvicorn: Not installed
2023-10-23 23:01:49,443:INFO:              m2cgen: Not installed
2023-10-23 23:01:49,443:INFO:           evidently: Not installed
2023-10-23 23:01:49,443:INFO:               fugue: Not installed
2023-10-23 23:01:49,443:INFO:           streamlit: Not installed
2023-10-23 23:01:49,443:INFO:             prophet: Not installed
2023-10-23 23:01:49,443:INFO:None
2023-10-23 23:01:49,443:INFO:Set up data.
2023-10-23 23:01:49,483:INFO:Set up folding strategy.
2023-10-23 23:01:49,483:INFO:Set up train/test split.
2023-10-23 23:01:49,504:INFO:Set up index.
2023-10-23 23:01:49,506:INFO:Assigning column types.
2023-10-23 23:01:49,512:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 23:01:49,512:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 23:01:49,529:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:01:49,533:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:01:49,599:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:01:49,650:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:01:49,650:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:01:49,650:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:01:49,650:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 23:01:49,661:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:01:49,665:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:01:49,743:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:01:49,792:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:01:49,795:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:01:49,795:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:01:49,796:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 23:01:49,797:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:01:49,797:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:01:49,893:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:01:49,942:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:01:49,942:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:01:49,958:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:01:49,960:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:01:49,960:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:01:50,043:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:01:50,077:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:01:50,091:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:01:50,091:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:01:50,093:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 23:01:50,093:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:01:50,177:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:01:50,226:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:01:50,226:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:01:50,227:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:01:50,235:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:01:50,315:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:01:50,363:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:01:50,364:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:01:50,364:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:01:50,365:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 23:01:50,442:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:01:50,503:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:01:50,504:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:01:50,504:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:01:50,607:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:01:50,660:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:01:50,660:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:01:50,661:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:01:50,661:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 23:01:50,752:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:01:50,802:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:01:50,803:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:01:50,877:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:01:50,926:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:01:50,926:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:01:50,926:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 23:01:51,074:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:01:51,075:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:01:51,217:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:01:51,217:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:01:51,218:INFO:Preparing preprocessing pipeline...
2023-10-23 23:01:51,219:INFO:Set up date feature engineering.
2023-10-23 23:01:51,219:INFO:Set up simple imputation.
2023-10-23 23:01:51,226:INFO:Set up encoding of ordinal features.
2023-10-23 23:01:51,241:INFO:Set up encoding of categorical features.
2023-10-23 23:01:51,241:INFO:Set up variance threshold.
2023-10-23 23:01:51,245:INFO:Set up column name cleaning.
2023-10-23 23:01:51,525:INFO:Finished creating preprocessing pipeline.
2023-10-23 23:01:51,582:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 23:01:51,582:INFO:Creating final display dataframe.
2023-10-23 23:01:51,734:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (34061, 48)
4        Transformed data shape  (34061, 37)
5   Transformed train set shape  (23842, 37)
6    Transformed test set shape  (10219, 37)
7              Ordinal features            2
8              Numeric features           43
9                 Date features            1
10         Categorical features            3
11     Rows with missing values        97.6%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18       Low variance threshold         0.05
19               Fold Generator        KFold
20                  Fold Number           10
21                     CPU Jobs           -1
22                      Use GPU        False
23               Log Experiment        False
24              Experiment Name        exp_A
25                          USI         e00c
2023-10-23 23:01:51,864:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:01:51,864:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:01:51,991:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:01:51,991:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:01:52,008:INFO:setup() successfully completed in 2.58s...............
2023-10-23 23:01:52,008:INFO:Initializing compare_models()
2023-10-23 23:01:52,009:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035CA37F40>, include=['catboost', 'lightgbm'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002035CA37F40>, 'include': ['catboost', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-10-23 23:01:52,009:INFO:Checking exceptions
2023-10-23 23:01:52,016:INFO:Preparing display monitor
2023-10-23 23:01:52,016:INFO:Initializing CatBoost Regressor
2023-10-23 23:01:52,016:INFO:Total runtime is 0.0 minutes
2023-10-23 23:01:52,016:INFO:SubProcess create_model() called ==================================
2023-10-23 23:01:52,016:INFO:Initializing create_model()
2023-10-23 23:01:52,016:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035CA37F40>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002035D0CAF70>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 23:01:52,016:INFO:Checking exceptions
2023-10-23 23:01:52,016:INFO:Importing libraries
2023-10-23 23:01:52,016:INFO:Copying training dataset
2023-10-23 23:01:52,047:INFO:Defining folds
2023-10-23 23:01:52,047:INFO:Declaring metric variables
2023-10-23 23:01:52,047:INFO:Importing untrained model
2023-10-23 23:01:52,047:INFO:CatBoost Regressor Imported successfully
2023-10-23 23:01:52,048:INFO:Starting cross validation
2023-10-23 23:01:52,049:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 23:02:23,132:INFO:Calculating mean and std
2023-10-23 23:02:23,133:INFO:Creating metrics dataframe
2023-10-23 23:02:23,133:INFO:Uploading results into container
2023-10-23 23:02:23,133:INFO:Uploading model into container now
2023-10-23 23:02:23,133:INFO:_master_model_container: 1
2023-10-23 23:02:23,133:INFO:_display_container: 2
2023-10-23 23:02:23,133:INFO:<catboost.core.CatBoostRegressor object at 0x000002035A2482B0>
2023-10-23 23:02:23,133:INFO:create_model() successfully completed......................................
2023-10-23 23:02:23,382:INFO:SubProcess create_model() end ==================================
2023-10-23 23:02:23,382:INFO:Creating metrics dataframe
2023-10-23 23:02:23,382:INFO:Initializing Light Gradient Boosting Machine
2023-10-23 23:02:23,382:INFO:Total runtime is 0.5227707823117574 minutes
2023-10-23 23:02:23,382:INFO:SubProcess create_model() called ==================================
2023-10-23 23:02:23,382:INFO:Initializing create_model()
2023-10-23 23:02:23,382:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035CA37F40>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002035D0CAF70>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 23:02:23,382:INFO:Checking exceptions
2023-10-23 23:02:23,382:INFO:Importing libraries
2023-10-23 23:02:23,382:INFO:Copying training dataset
2023-10-23 23:02:23,415:INFO:Defining folds
2023-10-23 23:02:23,415:INFO:Declaring metric variables
2023-10-23 23:02:23,415:INFO:Importing untrained model
2023-10-23 23:02:23,415:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 23:02:23,415:INFO:Starting cross validation
2023-10-23 23:02:23,415:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 23:02:26,479:INFO:Calculating mean and std
2023-10-23 23:02:26,479:INFO:Creating metrics dataframe
2023-10-23 23:02:26,479:INFO:Uploading results into container
2023-10-23 23:02:26,479:INFO:Uploading model into container now
2023-10-23 23:02:26,479:INFO:_master_model_container: 2
2023-10-23 23:02:26,479:INFO:_display_container: 2
2023-10-23 23:02:26,479:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:02:26,479:INFO:create_model() successfully completed......................................
2023-10-23 23:02:26,696:INFO:SubProcess create_model() end ==================================
2023-10-23 23:02:26,696:INFO:Creating metrics dataframe
2023-10-23 23:02:26,696:INFO:Initializing create_model()
2023-10-23 23:02:26,696:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035CA37F40>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 23:02:26,696:INFO:Checking exceptions
2023-10-23 23:02:26,696:INFO:Importing libraries
2023-10-23 23:02:26,696:INFO:Copying training dataset
2023-10-23 23:02:26,732:INFO:Defining folds
2023-10-23 23:02:26,732:INFO:Declaring metric variables
2023-10-23 23:02:26,733:INFO:Importing untrained model
2023-10-23 23:02:26,733:INFO:Declaring custom model
2023-10-23 23:02:26,733:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 23:02:26,733:INFO:Cross validation set to False
2023-10-23 23:02:26,733:INFO:Fitting Model
2023-10-23 23:02:26,995:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004732 seconds.
2023-10-23 23:02:26,995:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 23:02:26,995:INFO:[LightGBM] [Info] Total Bins 6029
2023-10-23 23:02:26,995:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 36
2023-10-23 23:02:26,995:INFO:[LightGBM] [Info] Start training from score 616.864890
2023-10-23 23:02:27,212:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:02:27,212:INFO:create_model() successfully completed......................................
2023-10-23 23:02:27,461:INFO:_master_model_container: 2
2023-10-23 23:02:27,461:INFO:_display_container: 2
2023-10-23 23:02:27,461:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:02:27,461:INFO:compare_models() successfully completed......................................
2023-10-23 23:02:27,461:INFO:Initializing finalize_model()
2023-10-23 23:02:27,461:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035CA37F40>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-23 23:02:27,461:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:02:27,481:INFO:Initializing create_model()
2023-10-23 23:02:27,481:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035CA37F40>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-23 23:02:27,481:INFO:Checking exceptions
2023-10-23 23:02:27,482:INFO:Importing libraries
2023-10-23 23:02:27,482:INFO:Copying training dataset
2023-10-23 23:02:27,484:INFO:Defining folds
2023-10-23 23:02:27,484:INFO:Declaring metric variables
2023-10-23 23:02:27,485:INFO:Importing untrained model
2023-10-23 23:02:27,485:INFO:Declaring custom model
2023-10-23 23:02:27,486:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 23:02:27,486:INFO:Cross validation set to False
2023-10-23 23:02:27,486:INFO:Fitting Model
2023-10-23 23:02:27,875:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007729 seconds.
2023-10-23 23:02:27,875:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 23:02:27,875:INFO:[LightGBM] [Info] Total Bins 6436
2023-10-23 23:02:27,875:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 37
2023-10-23 23:02:27,875:INFO:[LightGBM] [Info] Start training from score 631.011165
2023-10-23 23:02:28,266:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-23 23:02:28,266:INFO:create_model() successfully completed......................................
2023-10-23 23:02:28,466:INFO:_master_model_container: 2
2023-10-23 23:02:28,466:INFO:_display_container: 2
2023-10-23 23:02:28,529:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-23 23:02:28,529:INFO:finalize_model() successfully completed......................................
2023-10-23 23:02:28,846:INFO:Initializing save_model()
2023-10-23 23:02:28,846:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_A, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 23:02:28,846:INFO:Adding model into prep_pipe
2023-10-23 23:02:28,846:WARNING:Only Model saved as it was a pipeline.
2023-10-23 23:02:28,861:INFO:final_model_for_location_A.pkl saved in current working directory
2023-10-23 23:02:28,980:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-23 23:02:28,980:INFO:save_model() successfully completed......................................
2023-10-23 23:02:29,234:INFO:PyCaret RegressionExperiment
2023-10-23 23:02:29,234:INFO:Logging name: exp_B
2023-10-23 23:02:29,234:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 23:02:29,234:INFO:version 3.1.0
2023-10-23 23:02:29,234:INFO:Initializing setup()
2023-10-23 23:02:29,234:INFO:self.USI: b9f1
2023-10-23 23:02:29,234:INFO:self._variable_keys: {'memory', 'X_train', 'fold_generator', 'log_plots_param', 'data', 'logging_param', 'target_param', 'exp_id', 'X_test', 'html_param', 'USI', 'transform_target_param', 'idx', 'pipeline', 'fold_shuffle_param', 'seed', 'y_test', 'y_train', 'n_jobs_param', '_ml_usecase', 'gpu_n_jobs_param', 'exp_name_log', 'fold_groups_param', '_available_plots', 'y', 'X', 'gpu_param'}
2023-10-23 23:02:29,234:INFO:Checking environment
2023-10-23 23:02:29,234:INFO:python_version: 3.8.18
2023-10-23 23:02:29,234:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 23:02:29,234:INFO:machine: AMD64
2023-10-23 23:02:29,234:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 23:02:29,234:INFO:Memory: svmem(total=16505954304, available=2964119552, percent=82.0, used=13541834752, free=2964119552)
2023-10-23 23:02:29,234:INFO:Physical Core: 8
2023-10-23 23:02:29,234:INFO:Logical Core: 16
2023-10-23 23:02:29,234:INFO:Checking libraries
2023-10-23 23:02:29,234:INFO:System:
2023-10-23 23:02:29,234:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 23:02:29,234:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 23:02:29,234:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 23:02:29,234:INFO:PyCaret required dependencies:
2023-10-23 23:02:29,234:INFO:                 pip: 23.3
2023-10-23 23:02:29,234:INFO:          setuptools: 68.0.0
2023-10-23 23:02:29,234:INFO:             pycaret: 3.1.0
2023-10-23 23:02:29,234:INFO:             IPython: 8.12.0
2023-10-23 23:02:29,234:INFO:          ipywidgets: 8.1.1
2023-10-23 23:02:29,234:INFO:                tqdm: 4.66.1
2023-10-23 23:02:29,234:INFO:               numpy: 1.23.5
2023-10-23 23:02:29,234:INFO:              pandas: 1.5.3
2023-10-23 23:02:29,234:INFO:              jinja2: 3.1.2
2023-10-23 23:02:29,234:INFO:               scipy: 1.10.1
2023-10-23 23:02:29,234:INFO:              joblib: 1.3.2
2023-10-23 23:02:29,234:INFO:             sklearn: 1.2.2
2023-10-23 23:02:29,234:INFO:                pyod: 1.1.0
2023-10-23 23:02:29,234:INFO:            imblearn: 0.11.0
2023-10-23 23:02:29,234:INFO:   category_encoders: 2.6.2
2023-10-23 23:02:29,234:INFO:            lightgbm: 4.1.0
2023-10-23 23:02:29,234:INFO:               numba: 0.58.1
2023-10-23 23:02:29,234:INFO:            requests: 2.31.0
2023-10-23 23:02:29,234:INFO:          matplotlib: 3.7.3
2023-10-23 23:02:29,234:INFO:          scikitplot: 0.3.7
2023-10-23 23:02:29,234:INFO:         yellowbrick: 1.5
2023-10-23 23:02:29,242:INFO:              plotly: 5.17.0
2023-10-23 23:02:29,242:INFO:    plotly-resampler: Not installed
2023-10-23 23:02:29,242:INFO:             kaleido: 0.2.1
2023-10-23 23:02:29,242:INFO:           schemdraw: 0.15
2023-10-23 23:02:29,242:INFO:         statsmodels: 0.14.0
2023-10-23 23:02:29,242:INFO:              sktime: 0.21.1
2023-10-23 23:02:29,242:INFO:               tbats: 1.1.3
2023-10-23 23:02:29,242:INFO:            pmdarima: 2.0.3
2023-10-23 23:02:29,242:INFO:              psutil: 5.9.0
2023-10-23 23:02:29,242:INFO:          markupsafe: 2.1.3
2023-10-23 23:02:29,242:INFO:             pickle5: Not installed
2023-10-23 23:02:29,242:INFO:         cloudpickle: 2.2.1
2023-10-23 23:02:29,242:INFO:         deprecation: 2.1.0
2023-10-23 23:02:29,242:INFO:              xxhash: 3.4.1
2023-10-23 23:02:29,242:INFO:           wurlitzer: Not installed
2023-10-23 23:02:29,242:INFO:PyCaret optional dependencies:
2023-10-23 23:02:29,242:INFO:                shap: Not installed
2023-10-23 23:02:29,243:INFO:           interpret: Not installed
2023-10-23 23:02:29,243:INFO:                umap: Not installed
2023-10-23 23:02:29,243:INFO:     ydata_profiling: Not installed
2023-10-23 23:02:29,243:INFO:  explainerdashboard: Not installed
2023-10-23 23:02:29,243:INFO:             autoviz: Not installed
2023-10-23 23:02:29,243:INFO:           fairlearn: Not installed
2023-10-23 23:02:29,243:INFO:          deepchecks: Not installed
2023-10-23 23:02:29,243:INFO:             xgboost: Not installed
2023-10-23 23:02:29,243:INFO:            catboost: 1.2.2
2023-10-23 23:02:29,243:INFO:              kmodes: Not installed
2023-10-23 23:02:29,243:INFO:             mlxtend: Not installed
2023-10-23 23:02:29,243:INFO:       statsforecast: Not installed
2023-10-23 23:02:29,243:INFO:        tune_sklearn: Not installed
2023-10-23 23:02:29,243:INFO:                 ray: Not installed
2023-10-23 23:02:29,243:INFO:            hyperopt: Not installed
2023-10-23 23:02:29,243:INFO:              optuna: Not installed
2023-10-23 23:02:29,243:INFO:               skopt: Not installed
2023-10-23 23:02:29,243:INFO:              mlflow: 2.7.1
2023-10-23 23:02:29,243:INFO:              gradio: Not installed
2023-10-23 23:02:29,243:INFO:             fastapi: Not installed
2023-10-23 23:02:29,243:INFO:             uvicorn: Not installed
2023-10-23 23:02:29,244:INFO:              m2cgen: Not installed
2023-10-23 23:02:29,244:INFO:           evidently: Not installed
2023-10-23 23:02:29,244:INFO:               fugue: Not installed
2023-10-23 23:02:29,244:INFO:           streamlit: Not installed
2023-10-23 23:02:29,244:INFO:             prophet: Not installed
2023-10-23 23:02:29,244:INFO:None
2023-10-23 23:02:29,244:INFO:Set up data.
2023-10-23 23:04:26,165:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\4277538481.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  a = merged_data_a.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 23:04:26,197:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\4277538481.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  b = merged_data_b.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 23:04:26,250:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\4277538481.py:3: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  c = merged_data_c.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 23:04:26,461:INFO:PyCaret RegressionExperiment
2023-10-23 23:04:26,461:INFO:Logging name: exp_A
2023-10-23 23:04:26,461:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 23:04:26,462:INFO:version 3.1.0
2023-10-23 23:04:26,462:INFO:Initializing setup()
2023-10-23 23:04:26,462:INFO:self.USI: 8d7e
2023-10-23 23:04:26,462:INFO:self._variable_keys: {'memory', 'X_train', 'fold_generator', 'log_plots_param', 'data', 'logging_param', 'target_param', 'exp_id', 'X_test', 'html_param', 'USI', 'transform_target_param', 'idx', 'pipeline', 'fold_shuffle_param', 'seed', 'y_test', 'y_train', 'n_jobs_param', '_ml_usecase', 'gpu_n_jobs_param', 'exp_name_log', 'fold_groups_param', '_available_plots', 'y', 'X', 'gpu_param'}
2023-10-23 23:04:26,462:INFO:Checking environment
2023-10-23 23:04:26,462:INFO:python_version: 3.8.18
2023-10-23 23:04:26,463:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 23:04:26,463:INFO:machine: AMD64
2023-10-23 23:04:26,463:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 23:04:26,463:INFO:Memory: svmem(total=16505954304, available=2864279552, percent=82.6, used=13641674752, free=2864279552)
2023-10-23 23:04:26,463:INFO:Physical Core: 8
2023-10-23 23:04:26,463:INFO:Logical Core: 16
2023-10-23 23:04:26,463:INFO:Checking libraries
2023-10-23 23:04:26,464:INFO:System:
2023-10-23 23:04:26,464:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 23:04:26,464:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 23:04:26,464:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 23:04:26,464:INFO:PyCaret required dependencies:
2023-10-23 23:04:26,464:INFO:                 pip: 23.3
2023-10-23 23:04:26,465:INFO:          setuptools: 68.0.0
2023-10-23 23:04:26,465:INFO:             pycaret: 3.1.0
2023-10-23 23:04:26,465:INFO:             IPython: 8.12.0
2023-10-23 23:04:26,465:INFO:          ipywidgets: 8.1.1
2023-10-23 23:04:26,465:INFO:                tqdm: 4.66.1
2023-10-23 23:04:26,465:INFO:               numpy: 1.23.5
2023-10-23 23:04:26,465:INFO:              pandas: 1.5.3
2023-10-23 23:04:26,465:INFO:              jinja2: 3.1.2
2023-10-23 23:04:26,465:INFO:               scipy: 1.10.1
2023-10-23 23:04:26,465:INFO:              joblib: 1.3.2
2023-10-23 23:04:26,465:INFO:             sklearn: 1.2.2
2023-10-23 23:04:26,465:INFO:                pyod: 1.1.0
2023-10-23 23:04:26,466:INFO:            imblearn: 0.11.0
2023-10-23 23:04:26,466:INFO:   category_encoders: 2.6.2
2023-10-23 23:04:26,466:INFO:            lightgbm: 4.1.0
2023-10-23 23:04:26,466:INFO:               numba: 0.58.1
2023-10-23 23:04:26,466:INFO:            requests: 2.31.0
2023-10-23 23:04:26,466:INFO:          matplotlib: 3.7.3
2023-10-23 23:04:26,466:INFO:          scikitplot: 0.3.7
2023-10-23 23:04:26,466:INFO:         yellowbrick: 1.5
2023-10-23 23:04:26,466:INFO:              plotly: 5.17.0
2023-10-23 23:04:26,466:INFO:    plotly-resampler: Not installed
2023-10-23 23:04:26,467:INFO:             kaleido: 0.2.1
2023-10-23 23:04:26,467:INFO:           schemdraw: 0.15
2023-10-23 23:04:26,467:INFO:         statsmodels: 0.14.0
2023-10-23 23:04:26,467:INFO:              sktime: 0.21.1
2023-10-23 23:04:26,467:INFO:               tbats: 1.1.3
2023-10-23 23:04:26,467:INFO:            pmdarima: 2.0.3
2023-10-23 23:04:26,467:INFO:              psutil: 5.9.0
2023-10-23 23:04:26,467:INFO:          markupsafe: 2.1.3
2023-10-23 23:04:26,467:INFO:             pickle5: Not installed
2023-10-23 23:04:26,467:INFO:         cloudpickle: 2.2.1
2023-10-23 23:04:26,467:INFO:         deprecation: 2.1.0
2023-10-23 23:04:26,467:INFO:              xxhash: 3.4.1
2023-10-23 23:04:26,467:INFO:           wurlitzer: Not installed
2023-10-23 23:04:26,467:INFO:PyCaret optional dependencies:
2023-10-23 23:04:26,467:INFO:                shap: Not installed
2023-10-23 23:04:26,467:INFO:           interpret: Not installed
2023-10-23 23:04:26,467:INFO:                umap: Not installed
2023-10-23 23:04:26,467:INFO:     ydata_profiling: Not installed
2023-10-23 23:04:26,467:INFO:  explainerdashboard: Not installed
2023-10-23 23:04:26,467:INFO:             autoviz: Not installed
2023-10-23 23:04:26,467:INFO:           fairlearn: Not installed
2023-10-23 23:04:26,467:INFO:          deepchecks: Not installed
2023-10-23 23:04:26,467:INFO:             xgboost: Not installed
2023-10-23 23:04:26,467:INFO:            catboost: 1.2.2
2023-10-23 23:04:26,467:INFO:              kmodes: Not installed
2023-10-23 23:04:26,467:INFO:             mlxtend: Not installed
2023-10-23 23:04:26,467:INFO:       statsforecast: Not installed
2023-10-23 23:04:26,467:INFO:        tune_sklearn: Not installed
2023-10-23 23:04:26,467:INFO:                 ray: Not installed
2023-10-23 23:04:26,467:INFO:            hyperopt: Not installed
2023-10-23 23:04:26,467:INFO:              optuna: Not installed
2023-10-23 23:04:26,467:INFO:               skopt: Not installed
2023-10-23 23:04:26,467:INFO:              mlflow: 2.7.1
2023-10-23 23:04:26,467:INFO:              gradio: Not installed
2023-10-23 23:04:26,467:INFO:             fastapi: Not installed
2023-10-23 23:04:26,467:INFO:             uvicorn: Not installed
2023-10-23 23:04:26,467:INFO:              m2cgen: Not installed
2023-10-23 23:04:26,467:INFO:           evidently: Not installed
2023-10-23 23:04:26,467:INFO:               fugue: Not installed
2023-10-23 23:04:26,467:INFO:           streamlit: Not installed
2023-10-23 23:04:26,467:INFO:             prophet: Not installed
2023-10-23 23:04:26,467:INFO:None
2023-10-23 23:04:26,467:INFO:Set up data.
2023-10-23 23:04:26,513:INFO:Set up folding strategy.
2023-10-23 23:04:26,513:INFO:Set up train/test split.
2023-10-23 23:04:26,531:INFO:Set up index.
2023-10-23 23:04:26,531:INFO:Assigning column types.
2023-10-23 23:04:26,556:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 23:04:26,557:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 23:04:26,562:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:04:26,567:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:04:26,643:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:04:26,686:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:04:26,686:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:04:26,686:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:04:26,686:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 23:04:26,686:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:04:26,701:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:04:26,765:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:04:26,818:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:04:26,818:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:04:26,818:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:04:26,818:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 23:04:26,818:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:04:26,833:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:04:26,896:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:04:26,943:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:04:26,943:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:04:26,943:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:04:26,963:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:04:26,968:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:04:27,043:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:04:27,081:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:04:27,081:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:04:27,081:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:04:27,081:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 23:04:27,096:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:04:27,180:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:04:27,229:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:04:27,229:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:04:27,229:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:04:27,229:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:04:27,317:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:04:27,366:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:04:27,366:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:04:27,366:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:04:27,366:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 23:04:27,452:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:04:27,496:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:04:27,496:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:04:27,496:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:04:27,577:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:04:27,624:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:04:27,624:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:04:27,624:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:04:27,624:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 23:04:27,720:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:04:27,770:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:04:27,771:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:04:27,856:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:04:27,903:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:04:27,904:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:04:27,904:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 23:04:28,036:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:04:28,036:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:04:28,171:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:04:28,171:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:04:28,173:INFO:Preparing preprocessing pipeline...
2023-10-23 23:04:28,173:INFO:Set up date feature engineering.
2023-10-23 23:04:28,173:INFO:Set up simple imputation.
2023-10-23 23:04:28,184:INFO:Set up encoding of ordinal features.
2023-10-23 23:04:28,196:INFO:Set up encoding of categorical features.
2023-10-23 23:04:28,196:INFO:Set up variance threshold.
2023-10-23 23:04:28,199:INFO:Set up column name cleaning.
2023-10-23 23:04:28,496:INFO:Finished creating preprocessing pipeline.
2023-10-23 23:04:28,559:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 23:04:28,559:INFO:Creating final display dataframe.
2023-10-23 23:04:28,690:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (34061, 48)
4        Transformed data shape  (34061, 37)
5   Transformed train set shape  (23842, 37)
6    Transformed test set shape  (10219, 37)
7              Ordinal features            2
8              Numeric features           43
9                 Date features            1
10         Categorical features            3
11     Rows with missing values        97.6%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18       Low variance threshold         0.05
19               Fold Generator        KFold
20                  Fold Number           10
21                     CPU Jobs           -1
22                      Use GPU        False
23               Log Experiment        False
24              Experiment Name        exp_A
25                          USI         8d7e
2023-10-23 23:04:28,830:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:04:28,830:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:04:28,962:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:04:28,962:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:04:28,962:INFO:setup() successfully completed in 2.51s...............
2023-10-23 23:04:28,962:INFO:Initializing compare_models()
2023-10-23 23:04:28,962:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035D088760>, include=['catboost', 'lightgbm'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002035D088760>, 'include': ['catboost', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-10-23 23:04:28,962:INFO:Checking exceptions
2023-10-23 23:04:28,978:INFO:Preparing display monitor
2023-10-23 23:04:28,982:INFO:Initializing CatBoost Regressor
2023-10-23 23:04:28,983:INFO:Total runtime is 1.6756852467854817e-05 minutes
2023-10-23 23:04:28,983:INFO:SubProcess create_model() called ==================================
2023-10-23 23:04:28,983:INFO:Initializing create_model()
2023-10-23 23:04:28,983:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035D088760>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000203590CC370>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 23:04:28,983:INFO:Checking exceptions
2023-10-23 23:04:28,983:INFO:Importing libraries
2023-10-23 23:04:28,984:INFO:Copying training dataset
2023-10-23 23:04:29,004:INFO:Defining folds
2023-10-23 23:04:29,005:INFO:Declaring metric variables
2023-10-23 23:04:29,005:INFO:Importing untrained model
2023-10-23 23:04:29,005:INFO:CatBoost Regressor Imported successfully
2023-10-23 23:04:29,005:INFO:Starting cross validation
2023-10-23 23:04:29,007:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 23:04:59,654:INFO:Calculating mean and std
2023-10-23 23:04:59,654:INFO:Creating metrics dataframe
2023-10-23 23:04:59,654:INFO:Uploading results into container
2023-10-23 23:04:59,654:INFO:Uploading model into container now
2023-10-23 23:04:59,654:INFO:_master_model_container: 1
2023-10-23 23:04:59,654:INFO:_display_container: 2
2023-10-23 23:04:59,654:INFO:<catboost.core.CatBoostRegressor object at 0x000002035947AC40>
2023-10-23 23:04:59,654:INFO:create_model() successfully completed......................................
2023-10-23 23:04:59,886:INFO:SubProcess create_model() end ==================================
2023-10-23 23:04:59,886:INFO:Creating metrics dataframe
2023-10-23 23:04:59,903:INFO:Initializing Light Gradient Boosting Machine
2023-10-23 23:04:59,903:INFO:Total runtime is 0.5153535882631938 minutes
2023-10-23 23:04:59,903:INFO:SubProcess create_model() called ==================================
2023-10-23 23:04:59,903:INFO:Initializing create_model()
2023-10-23 23:04:59,903:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035D088760>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000203590CC370>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 23:04:59,903:INFO:Checking exceptions
2023-10-23 23:04:59,903:INFO:Importing libraries
2023-10-23 23:04:59,903:INFO:Copying training dataset
2023-10-23 23:04:59,919:INFO:Defining folds
2023-10-23 23:04:59,919:INFO:Declaring metric variables
2023-10-23 23:04:59,919:INFO:Importing untrained model
2023-10-23 23:04:59,919:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 23:04:59,919:INFO:Starting cross validation
2023-10-23 23:04:59,919:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 23:05:02,817:INFO:Calculating mean and std
2023-10-23 23:05:02,817:INFO:Creating metrics dataframe
2023-10-23 23:05:02,817:INFO:Uploading results into container
2023-10-23 23:05:02,817:INFO:Uploading model into container now
2023-10-23 23:05:02,817:INFO:_master_model_container: 2
2023-10-23 23:05:02,817:INFO:_display_container: 2
2023-10-23 23:05:02,817:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:05:02,817:INFO:create_model() successfully completed......................................
2023-10-23 23:05:03,033:INFO:SubProcess create_model() end ==================================
2023-10-23 23:05:03,033:INFO:Creating metrics dataframe
2023-10-23 23:05:03,033:INFO:Initializing create_model()
2023-10-23 23:05:03,033:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035D088760>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 23:05:03,033:INFO:Checking exceptions
2023-10-23 23:05:03,033:INFO:Importing libraries
2023-10-23 23:05:03,033:INFO:Copying training dataset
2023-10-23 23:05:03,069:INFO:Defining folds
2023-10-23 23:05:03,069:INFO:Declaring metric variables
2023-10-23 23:05:03,069:INFO:Importing untrained model
2023-10-23 23:05:03,069:INFO:Declaring custom model
2023-10-23 23:05:03,069:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 23:05:03,069:INFO:Cross validation set to False
2023-10-23 23:05:03,069:INFO:Fitting Model
2023-10-23 23:05:03,333:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004498 seconds.
2023-10-23 23:05:03,333:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 23:05:03,333:INFO:[LightGBM] [Info] Total Bins 6029
2023-10-23 23:05:03,333:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 36
2023-10-23 23:05:03,333:INFO:[LightGBM] [Info] Start training from score 616.864890
2023-10-23 23:05:03,539:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:05:03,539:INFO:create_model() successfully completed......................................
2023-10-23 23:05:03,782:INFO:_master_model_container: 2
2023-10-23 23:05:03,785:INFO:_display_container: 2
2023-10-23 23:05:03,785:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:05:03,785:INFO:compare_models() successfully completed......................................
2023-10-23 23:05:03,786:INFO:Initializing finalize_model()
2023-10-23 23:05:03,786:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035D088760>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-23 23:05:03,786:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:05:03,806:INFO:Initializing create_model()
2023-10-23 23:05:03,807:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035D088760>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-23 23:05:03,807:INFO:Checking exceptions
2023-10-23 23:05:03,808:INFO:Importing libraries
2023-10-23 23:05:03,808:INFO:Copying training dataset
2023-10-23 23:05:03,809:INFO:Defining folds
2023-10-23 23:05:03,809:INFO:Declaring metric variables
2023-10-23 23:05:03,810:INFO:Importing untrained model
2023-10-23 23:05:03,810:INFO:Declaring custom model
2023-10-23 23:05:03,811:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 23:05:03,814:INFO:Cross validation set to False
2023-10-23 23:05:03,814:INFO:Fitting Model
2023-10-23 23:05:04,233:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007727 seconds.
2023-10-23 23:05:04,234:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 23:05:04,234:INFO:[LightGBM] [Info] Total Bins 6436
2023-10-23 23:05:04,234:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 37
2023-10-23 23:05:04,235:INFO:[LightGBM] [Info] Start training from score 631.011165
2023-10-23 23:05:04,559:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-23 23:05:04,575:INFO:create_model() successfully completed......................................
2023-10-23 23:05:04,772:INFO:_master_model_container: 2
2023-10-23 23:05:04,772:INFO:_display_container: 2
2023-10-23 23:05:04,852:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-23 23:05:04,852:INFO:finalize_model() successfully completed......................................
2023-10-23 23:05:05,170:INFO:Initializing save_model()
2023-10-23 23:05:05,170:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_A, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 23:05:05,170:INFO:Adding model into prep_pipe
2023-10-23 23:05:05,170:WARNING:Only Model saved as it was a pipeline.
2023-10-23 23:05:05,189:INFO:final_model_for_location_A.pkl saved in current working directory
2023-10-23 23:05:05,300:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-23 23:05:05,301:INFO:save_model() successfully completed......................................
2023-10-23 23:05:05,535:INFO:PyCaret RegressionExperiment
2023-10-23 23:05:05,535:INFO:Logging name: exp_B
2023-10-23 23:05:05,535:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 23:05:05,535:INFO:version 3.1.0
2023-10-23 23:05:05,535:INFO:Initializing setup()
2023-10-23 23:05:05,535:INFO:self.USI: b79c
2023-10-23 23:05:05,536:INFO:self._variable_keys: {'memory', 'X_train', 'fold_generator', 'log_plots_param', 'data', 'logging_param', 'target_param', 'exp_id', 'X_test', 'html_param', 'USI', 'transform_target_param', 'idx', 'pipeline', 'fold_shuffle_param', 'seed', 'y_test', 'y_train', 'n_jobs_param', '_ml_usecase', 'gpu_n_jobs_param', 'exp_name_log', 'fold_groups_param', '_available_plots', 'y', 'X', 'gpu_param'}
2023-10-23 23:05:05,536:INFO:Checking environment
2023-10-23 23:05:05,536:INFO:python_version: 3.8.18
2023-10-23 23:05:05,536:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 23:05:05,536:INFO:machine: AMD64
2023-10-23 23:05:05,536:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 23:05:05,536:INFO:Memory: svmem(total=16505954304, available=2918068224, percent=82.3, used=13587886080, free=2918068224)
2023-10-23 23:05:05,536:INFO:Physical Core: 8
2023-10-23 23:05:05,536:INFO:Logical Core: 16
2023-10-23 23:05:05,536:INFO:Checking libraries
2023-10-23 23:05:05,537:INFO:System:
2023-10-23 23:05:05,537:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 23:05:05,537:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 23:05:05,537:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 23:05:05,537:INFO:PyCaret required dependencies:
2023-10-23 23:05:05,537:INFO:                 pip: 23.3
2023-10-23 23:05:05,538:INFO:          setuptools: 68.0.0
2023-10-23 23:05:05,538:INFO:             pycaret: 3.1.0
2023-10-23 23:05:05,538:INFO:             IPython: 8.12.0
2023-10-23 23:05:05,538:INFO:          ipywidgets: 8.1.1
2023-10-23 23:05:05,538:INFO:                tqdm: 4.66.1
2023-10-23 23:05:05,538:INFO:               numpy: 1.23.5
2023-10-23 23:05:05,538:INFO:              pandas: 1.5.3
2023-10-23 23:05:05,538:INFO:              jinja2: 3.1.2
2023-10-23 23:05:05,538:INFO:               scipy: 1.10.1
2023-10-23 23:05:05,538:INFO:              joblib: 1.3.2
2023-10-23 23:05:05,538:INFO:             sklearn: 1.2.2
2023-10-23 23:05:05,538:INFO:                pyod: 1.1.0
2023-10-23 23:05:05,539:INFO:            imblearn: 0.11.0
2023-10-23 23:05:05,539:INFO:   category_encoders: 2.6.2
2023-10-23 23:05:05,539:INFO:            lightgbm: 4.1.0
2023-10-23 23:05:05,539:INFO:               numba: 0.58.1
2023-10-23 23:05:05,539:INFO:            requests: 2.31.0
2023-10-23 23:05:05,539:INFO:          matplotlib: 3.7.3
2023-10-23 23:05:05,539:INFO:          scikitplot: 0.3.7
2023-10-23 23:05:05,539:INFO:         yellowbrick: 1.5
2023-10-23 23:05:05,539:INFO:              plotly: 5.17.0
2023-10-23 23:05:05,539:INFO:    plotly-resampler: Not installed
2023-10-23 23:05:05,539:INFO:             kaleido: 0.2.1
2023-10-23 23:05:05,539:INFO:           schemdraw: 0.15
2023-10-23 23:05:05,539:INFO:         statsmodels: 0.14.0
2023-10-23 23:05:05,539:INFO:              sktime: 0.21.1
2023-10-23 23:05:05,539:INFO:               tbats: 1.1.3
2023-10-23 23:05:05,539:INFO:            pmdarima: 2.0.3
2023-10-23 23:05:05,539:INFO:              psutil: 5.9.0
2023-10-23 23:05:05,539:INFO:          markupsafe: 2.1.3
2023-10-23 23:05:05,540:INFO:             pickle5: Not installed
2023-10-23 23:05:05,540:INFO:         cloudpickle: 2.2.1
2023-10-23 23:05:05,540:INFO:         deprecation: 2.1.0
2023-10-23 23:05:05,540:INFO:              xxhash: 3.4.1
2023-10-23 23:05:05,540:INFO:           wurlitzer: Not installed
2023-10-23 23:05:05,540:INFO:PyCaret optional dependencies:
2023-10-23 23:05:05,540:INFO:                shap: Not installed
2023-10-23 23:05:05,540:INFO:           interpret: Not installed
2023-10-23 23:05:05,540:INFO:                umap: Not installed
2023-10-23 23:05:05,540:INFO:     ydata_profiling: Not installed
2023-10-23 23:05:05,540:INFO:  explainerdashboard: Not installed
2023-10-23 23:05:05,540:INFO:             autoviz: Not installed
2023-10-23 23:05:05,542:INFO:           fairlearn: Not installed
2023-10-23 23:05:05,542:INFO:          deepchecks: Not installed
2023-10-23 23:05:05,542:INFO:             xgboost: Not installed
2023-10-23 23:05:05,542:INFO:            catboost: 1.2.2
2023-10-23 23:05:05,542:INFO:              kmodes: Not installed
2023-10-23 23:05:05,542:INFO:             mlxtend: Not installed
2023-10-23 23:05:05,542:INFO:       statsforecast: Not installed
2023-10-23 23:05:05,542:INFO:        tune_sklearn: Not installed
2023-10-23 23:05:05,542:INFO:                 ray: Not installed
2023-10-23 23:05:05,542:INFO:            hyperopt: Not installed
2023-10-23 23:05:05,542:INFO:              optuna: Not installed
2023-10-23 23:05:05,542:INFO:               skopt: Not installed
2023-10-23 23:05:05,542:INFO:              mlflow: 2.7.1
2023-10-23 23:05:05,542:INFO:              gradio: Not installed
2023-10-23 23:05:05,542:INFO:             fastapi: Not installed
2023-10-23 23:05:05,542:INFO:             uvicorn: Not installed
2023-10-23 23:05:05,542:INFO:              m2cgen: Not installed
2023-10-23 23:05:05,542:INFO:           evidently: Not installed
2023-10-23 23:05:05,542:INFO:               fugue: Not installed
2023-10-23 23:05:05,542:INFO:           streamlit: Not installed
2023-10-23 23:05:05,542:INFO:             prophet: Not installed
2023-10-23 23:05:05,542:INFO:None
2023-10-23 23:05:05,542:INFO:Set up data.
2023-10-23 23:05:29,762:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\846850907.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  a = merged_data_a.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 23:05:29,795:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\846850907.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  b = merged_data_b.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 23:05:29,828:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\846850907.py:3: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  c = merged_data_c.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 23:05:30,026:INFO:PyCaret RegressionExperiment
2023-10-23 23:05:30,026:INFO:Logging name: exp_A
2023-10-23 23:05:30,026:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 23:05:30,026:INFO:version 3.1.0
2023-10-23 23:05:30,027:INFO:Initializing setup()
2023-10-23 23:05:30,027:INFO:self.USI: fe39
2023-10-23 23:05:30,027:INFO:self._variable_keys: {'memory', 'X_train', 'fold_generator', 'log_plots_param', 'data', 'logging_param', 'target_param', 'exp_id', 'X_test', 'html_param', 'USI', 'transform_target_param', 'idx', 'pipeline', 'fold_shuffle_param', 'seed', 'y_test', 'y_train', 'n_jobs_param', '_ml_usecase', 'gpu_n_jobs_param', 'exp_name_log', 'fold_groups_param', '_available_plots', 'y', 'X', 'gpu_param'}
2023-10-23 23:05:30,027:INFO:Checking environment
2023-10-23 23:05:30,027:INFO:python_version: 3.8.18
2023-10-23 23:05:30,027:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 23:05:30,027:INFO:machine: AMD64
2023-10-23 23:05:30,027:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 23:05:30,027:INFO:Memory: svmem(total=16505954304, available=2856574976, percent=82.7, used=13649379328, free=2856574976)
2023-10-23 23:05:30,028:INFO:Physical Core: 8
2023-10-23 23:05:30,028:INFO:Logical Core: 16
2023-10-23 23:05:30,028:INFO:Checking libraries
2023-10-23 23:05:30,028:INFO:System:
2023-10-23 23:05:30,028:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 23:05:30,028:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 23:05:30,028:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 23:05:30,028:INFO:PyCaret required dependencies:
2023-10-23 23:05:30,028:INFO:                 pip: 23.3
2023-10-23 23:05:30,028:INFO:          setuptools: 68.0.0
2023-10-23 23:05:30,028:INFO:             pycaret: 3.1.0
2023-10-23 23:05:30,028:INFO:             IPython: 8.12.0
2023-10-23 23:05:30,029:INFO:          ipywidgets: 8.1.1
2023-10-23 23:05:30,029:INFO:                tqdm: 4.66.1
2023-10-23 23:05:30,029:INFO:               numpy: 1.23.5
2023-10-23 23:05:30,029:INFO:              pandas: 1.5.3
2023-10-23 23:05:30,029:INFO:              jinja2: 3.1.2
2023-10-23 23:05:30,029:INFO:               scipy: 1.10.1
2023-10-23 23:05:30,029:INFO:              joblib: 1.3.2
2023-10-23 23:05:30,029:INFO:             sklearn: 1.2.2
2023-10-23 23:05:30,029:INFO:                pyod: 1.1.0
2023-10-23 23:05:30,029:INFO:            imblearn: 0.11.0
2023-10-23 23:05:30,029:INFO:   category_encoders: 2.6.2
2023-10-23 23:05:30,029:INFO:            lightgbm: 4.1.0
2023-10-23 23:05:30,029:INFO:               numba: 0.58.1
2023-10-23 23:05:30,030:INFO:            requests: 2.31.0
2023-10-23 23:05:30,030:INFO:          matplotlib: 3.7.3
2023-10-23 23:05:30,030:INFO:          scikitplot: 0.3.7
2023-10-23 23:05:30,030:INFO:         yellowbrick: 1.5
2023-10-23 23:05:30,030:INFO:              plotly: 5.17.0
2023-10-23 23:05:30,030:INFO:    plotly-resampler: Not installed
2023-10-23 23:05:30,030:INFO:             kaleido: 0.2.1
2023-10-23 23:05:30,030:INFO:           schemdraw: 0.15
2023-10-23 23:05:30,030:INFO:         statsmodels: 0.14.0
2023-10-23 23:05:30,030:INFO:              sktime: 0.21.1
2023-10-23 23:05:30,030:INFO:               tbats: 1.1.3
2023-10-23 23:05:30,030:INFO:            pmdarima: 2.0.3
2023-10-23 23:05:30,031:INFO:              psutil: 5.9.0
2023-10-23 23:05:30,031:INFO:          markupsafe: 2.1.3
2023-10-23 23:05:30,031:INFO:             pickle5: Not installed
2023-10-23 23:05:30,031:INFO:         cloudpickle: 2.2.1
2023-10-23 23:05:30,031:INFO:         deprecation: 2.1.0
2023-10-23 23:05:30,031:INFO:              xxhash: 3.4.1
2023-10-23 23:05:30,031:INFO:           wurlitzer: Not installed
2023-10-23 23:05:30,031:INFO:PyCaret optional dependencies:
2023-10-23 23:05:30,031:INFO:                shap: Not installed
2023-10-23 23:05:30,032:INFO:           interpret: Not installed
2023-10-23 23:05:30,032:INFO:                umap: Not installed
2023-10-23 23:05:30,032:INFO:     ydata_profiling: Not installed
2023-10-23 23:05:30,032:INFO:  explainerdashboard: Not installed
2023-10-23 23:05:30,032:INFO:             autoviz: Not installed
2023-10-23 23:05:30,032:INFO:           fairlearn: Not installed
2023-10-23 23:05:30,032:INFO:          deepchecks: Not installed
2023-10-23 23:05:30,032:INFO:             xgboost: Not installed
2023-10-23 23:05:30,032:INFO:            catboost: 1.2.2
2023-10-23 23:05:30,032:INFO:              kmodes: Not installed
2023-10-23 23:05:30,032:INFO:             mlxtend: Not installed
2023-10-23 23:05:30,032:INFO:       statsforecast: Not installed
2023-10-23 23:05:30,032:INFO:        tune_sklearn: Not installed
2023-10-23 23:05:30,032:INFO:                 ray: Not installed
2023-10-23 23:05:30,032:INFO:            hyperopt: Not installed
2023-10-23 23:05:30,033:INFO:              optuna: Not installed
2023-10-23 23:05:30,033:INFO:               skopt: Not installed
2023-10-23 23:05:30,033:INFO:              mlflow: 2.7.1
2023-10-23 23:05:30,033:INFO:              gradio: Not installed
2023-10-23 23:05:30,033:INFO:             fastapi: Not installed
2023-10-23 23:05:30,033:INFO:             uvicorn: Not installed
2023-10-23 23:05:30,033:INFO:              m2cgen: Not installed
2023-10-23 23:05:30,033:INFO:           evidently: Not installed
2023-10-23 23:05:30,033:INFO:               fugue: Not installed
2023-10-23 23:05:30,033:INFO:           streamlit: Not installed
2023-10-23 23:05:30,033:INFO:             prophet: Not installed
2023-10-23 23:05:30,034:INFO:None
2023-10-23 23:05:30,034:INFO:Set up data.
2023-10-23 23:05:30,065:INFO:Set up folding strategy.
2023-10-23 23:05:30,065:INFO:Set up train/test split.
2023-10-23 23:05:30,102:INFO:Set up index.
2023-10-23 23:05:30,103:INFO:Assigning column types.
2023-10-23 23:05:30,120:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 23:05:30,120:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 23:05:30,129:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:05:30,135:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:05:30,210:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:05:30,262:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:05:30,263:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:05:30,263:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:05:30,264:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 23:05:30,266:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:05:30,266:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:05:30,341:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:05:30,388:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:05:30,388:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:05:30,388:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:05:30,388:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 23:05:30,388:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:05:30,405:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:05:30,484:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:05:30,533:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:05:30,534:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:05:30,534:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:05:30,534:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:05:30,544:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:05:30,617:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:05:30,663:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:05:30,663:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:05:30,663:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:05:30,663:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 23:05:30,678:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:05:30,742:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:05:30,802:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:05:30,803:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:05:30,804:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:05:30,814:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:05:30,875:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:05:30,935:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:05:30,935:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:05:30,935:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:05:30,935:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 23:05:31,025:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:05:31,067:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:05:31,067:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:05:31,067:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:05:31,185:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:05:31,248:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:05:31,248:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:05:31,248:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:05:31,248:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 23:05:31,333:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:05:31,376:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:05:31,376:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:05:31,470:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:05:31,524:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:05:31,524:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:05:31,525:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 23:05:31,661:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:05:31,661:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:05:31,793:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:05:31,793:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:05:31,793:INFO:Preparing preprocessing pipeline...
2023-10-23 23:05:31,793:INFO:Set up date feature engineering.
2023-10-23 23:05:31,793:INFO:Set up simple imputation.
2023-10-23 23:05:31,808:INFO:Set up encoding of ordinal features.
2023-10-23 23:05:31,810:INFO:Set up encoding of categorical features.
2023-10-23 23:05:31,810:INFO:Set up variance threshold.
2023-10-23 23:05:31,824:INFO:Set up column name cleaning.
2023-10-23 23:05:32,116:INFO:Finished creating preprocessing pipeline.
2023-10-23 23:05:32,165:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 23:05:32,165:INFO:Creating final display dataframe.
2023-10-23 23:05:32,309:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (34061, 48)
4        Transformed data shape  (34061, 37)
5   Transformed train set shape  (23842, 37)
6    Transformed test set shape  (10219, 37)
7              Ordinal features            2
8              Numeric features           43
9                 Date features            1
10         Categorical features            3
11     Rows with missing values        97.6%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18       Low variance threshold         0.05
19               Fold Generator        KFold
20                  Fold Number           10
21                     CPU Jobs           -1
22                      Use GPU        False
23               Log Experiment        False
24              Experiment Name        exp_A
25                          USI         fe39
2023-10-23 23:05:32,442:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:05:32,442:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:05:32,581:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:05:32,582:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:05:32,583:INFO:setup() successfully completed in 2.57s...............
2023-10-23 23:05:32,583:INFO:Initializing compare_models()
2023-10-23 23:05:32,583:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035EFBF400>, include=['catboost', 'lightgbm'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002035EFBF400>, 'include': ['catboost', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-10-23 23:05:32,583:INFO:Checking exceptions
2023-10-23 23:05:32,592:INFO:Preparing display monitor
2023-10-23 23:05:32,596:INFO:Initializing CatBoost Regressor
2023-10-23 23:05:32,596:INFO:Total runtime is 0.0 minutes
2023-10-23 23:05:32,596:INFO:SubProcess create_model() called ==================================
2023-10-23 23:05:32,596:INFO:Initializing create_model()
2023-10-23 23:05:32,596:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035EFBF400>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020359F36BE0>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 23:05:32,596:INFO:Checking exceptions
2023-10-23 23:05:32,597:INFO:Importing libraries
2023-10-23 23:05:32,597:INFO:Copying training dataset
2023-10-23 23:05:32,612:INFO:Defining folds
2023-10-23 23:05:32,612:INFO:Declaring metric variables
2023-10-23 23:05:32,612:INFO:Importing untrained model
2023-10-23 23:05:32,612:INFO:CatBoost Regressor Imported successfully
2023-10-23 23:05:32,612:INFO:Starting cross validation
2023-10-23 23:05:32,624:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 23:06:04,300:INFO:Calculating mean and std
2023-10-23 23:06:04,302:INFO:Creating metrics dataframe
2023-10-23 23:06:04,307:INFO:Uploading results into container
2023-10-23 23:06:04,307:INFO:Uploading model into container now
2023-10-23 23:06:04,308:INFO:_master_model_container: 1
2023-10-23 23:06:04,308:INFO:_display_container: 2
2023-10-23 23:06:04,308:INFO:<catboost.core.CatBoostRegressor object at 0x000002035B566B50>
2023-10-23 23:06:04,308:INFO:create_model() successfully completed......................................
2023-10-23 23:06:04,516:INFO:SubProcess create_model() end ==================================
2023-10-23 23:06:04,516:INFO:Creating metrics dataframe
2023-10-23 23:06:04,516:INFO:Initializing Light Gradient Boosting Machine
2023-10-23 23:06:04,516:INFO:Total runtime is 0.5319992979367574 minutes
2023-10-23 23:06:04,516:INFO:SubProcess create_model() called ==================================
2023-10-23 23:06:04,516:INFO:Initializing create_model()
2023-10-23 23:06:04,516:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035EFBF400>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020359F36BE0>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 23:06:04,516:INFO:Checking exceptions
2023-10-23 23:06:04,516:INFO:Importing libraries
2023-10-23 23:06:04,516:INFO:Copying training dataset
2023-10-23 23:06:04,549:INFO:Defining folds
2023-10-23 23:06:04,549:INFO:Declaring metric variables
2023-10-23 23:06:04,549:INFO:Importing untrained model
2023-10-23 23:06:04,549:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 23:06:04,549:INFO:Starting cross validation
2023-10-23 23:06:04,549:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 23:06:07,646:INFO:Calculating mean and std
2023-10-23 23:06:07,646:INFO:Creating metrics dataframe
2023-10-23 23:06:07,646:INFO:Uploading results into container
2023-10-23 23:06:07,646:INFO:Uploading model into container now
2023-10-23 23:06:07,646:INFO:_master_model_container: 2
2023-10-23 23:06:07,646:INFO:_display_container: 2
2023-10-23 23:06:07,646:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:06:07,646:INFO:create_model() successfully completed......................................
2023-10-23 23:06:07,883:INFO:SubProcess create_model() end ==================================
2023-10-23 23:06:07,883:INFO:Creating metrics dataframe
2023-10-23 23:06:07,891:INFO:Initializing create_model()
2023-10-23 23:06:07,891:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035EFBF400>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 23:06:07,891:INFO:Checking exceptions
2023-10-23 23:06:07,893:INFO:Importing libraries
2023-10-23 23:06:07,893:INFO:Copying training dataset
2023-10-23 23:06:07,922:INFO:Defining folds
2023-10-23 23:06:07,923:INFO:Declaring metric variables
2023-10-23 23:06:07,923:INFO:Importing untrained model
2023-10-23 23:06:07,923:INFO:Declaring custom model
2023-10-23 23:06:07,924:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 23:06:07,927:INFO:Cross validation set to False
2023-10-23 23:06:07,927:INFO:Fitting Model
2023-10-23 23:06:08,196:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005960 seconds.
2023-10-23 23:06:08,196:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 23:06:08,196:INFO:[LightGBM] [Info] Total Bins 6029
2023-10-23 23:06:08,196:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 36
2023-10-23 23:06:08,196:INFO:[LightGBM] [Info] Start training from score 616.864890
2023-10-23 23:06:08,412:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:06:08,412:INFO:create_model() successfully completed......................................
2023-10-23 23:06:08,663:INFO:_master_model_container: 2
2023-10-23 23:06:08,663:INFO:_display_container: 2
2023-10-23 23:06:08,663:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:06:08,663:INFO:compare_models() successfully completed......................................
2023-10-23 23:06:08,663:INFO:Initializing finalize_model()
2023-10-23 23:06:08,663:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035EFBF400>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-23 23:06:08,663:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:06:08,686:INFO:Initializing create_model()
2023-10-23 23:06:08,686:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035EFBF400>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-23 23:06:08,686:INFO:Checking exceptions
2023-10-23 23:06:08,686:INFO:Importing libraries
2023-10-23 23:06:08,686:INFO:Copying training dataset
2023-10-23 23:06:08,686:INFO:Defining folds
2023-10-23 23:06:08,686:INFO:Declaring metric variables
2023-10-23 23:06:08,686:INFO:Importing untrained model
2023-10-23 23:06:08,686:INFO:Declaring custom model
2023-10-23 23:06:08,686:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 23:06:08,695:INFO:Cross validation set to False
2023-10-23 23:06:08,696:INFO:Fitting Model
2023-10-23 23:06:09,084:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008815 seconds.
2023-10-23 23:06:09,084:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 23:06:09,084:INFO:[LightGBM] [Info] Total Bins 6436
2023-10-23 23:06:09,084:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 37
2023-10-23 23:06:09,084:INFO:[LightGBM] [Info] Start training from score 631.011165
2023-10-23 23:06:09,431:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-23 23:06:09,431:INFO:create_model() successfully completed......................................
2023-10-23 23:06:09,633:INFO:_master_model_container: 2
2023-10-23 23:06:09,633:INFO:_display_container: 2
2023-10-23 23:06:09,699:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-23 23:06:09,699:INFO:finalize_model() successfully completed......................................
2023-10-23 23:06:10,018:INFO:Initializing save_model()
2023-10-23 23:06:10,018:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_A, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 23:06:10,018:INFO:Adding model into prep_pipe
2023-10-23 23:06:10,018:WARNING:Only Model saved as it was a pipeline.
2023-10-23 23:06:10,033:INFO:final_model_for_location_A.pkl saved in current working directory
2023-10-23 23:06:10,152:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-23 23:06:10,152:INFO:save_model() successfully completed......................................
2023-10-23 23:06:10,400:INFO:PyCaret RegressionExperiment
2023-10-23 23:06:10,400:INFO:Logging name: exp_B
2023-10-23 23:06:10,400:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 23:06:10,400:INFO:version 3.1.0
2023-10-23 23:06:10,400:INFO:Initializing setup()
2023-10-23 23:06:10,400:INFO:self.USI: aa77
2023-10-23 23:06:10,400:INFO:self._variable_keys: {'memory', 'X_train', 'fold_generator', 'log_plots_param', 'data', 'logging_param', 'target_param', 'exp_id', 'X_test', 'html_param', 'USI', 'transform_target_param', 'idx', 'pipeline', 'fold_shuffle_param', 'seed', 'y_test', 'y_train', 'n_jobs_param', '_ml_usecase', 'gpu_n_jobs_param', 'exp_name_log', 'fold_groups_param', '_available_plots', 'y', 'X', 'gpu_param'}
2023-10-23 23:06:10,400:INFO:Checking environment
2023-10-23 23:06:10,400:INFO:python_version: 3.8.18
2023-10-23 23:06:10,400:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 23:06:10,400:INFO:machine: AMD64
2023-10-23 23:06:10,400:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 23:06:10,401:INFO:Memory: svmem(total=16505954304, available=2962755584, percent=82.1, used=13543198720, free=2962755584)
2023-10-23 23:06:10,401:INFO:Physical Core: 8
2023-10-23 23:06:10,401:INFO:Logical Core: 16
2023-10-23 23:06:10,401:INFO:Checking libraries
2023-10-23 23:06:10,401:INFO:System:
2023-10-23 23:06:10,401:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 23:06:10,401:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 23:06:10,401:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 23:06:10,401:INFO:PyCaret required dependencies:
2023-10-23 23:06:10,401:INFO:                 pip: 23.3
2023-10-23 23:06:10,401:INFO:          setuptools: 68.0.0
2023-10-23 23:06:10,401:INFO:             pycaret: 3.1.0
2023-10-23 23:06:10,401:INFO:             IPython: 8.12.0
2023-10-23 23:06:10,401:INFO:          ipywidgets: 8.1.1
2023-10-23 23:06:10,402:INFO:                tqdm: 4.66.1
2023-10-23 23:06:10,402:INFO:               numpy: 1.23.5
2023-10-23 23:06:10,402:INFO:              pandas: 1.5.3
2023-10-23 23:06:10,402:INFO:              jinja2: 3.1.2
2023-10-23 23:06:10,402:INFO:               scipy: 1.10.1
2023-10-23 23:06:10,402:INFO:              joblib: 1.3.2
2023-10-23 23:06:10,402:INFO:             sklearn: 1.2.2
2023-10-23 23:06:10,402:INFO:                pyod: 1.1.0
2023-10-23 23:06:10,402:INFO:            imblearn: 0.11.0
2023-10-23 23:06:10,402:INFO:   category_encoders: 2.6.2
2023-10-23 23:06:10,402:INFO:            lightgbm: 4.1.0
2023-10-23 23:06:10,402:INFO:               numba: 0.58.1
2023-10-23 23:06:10,402:INFO:            requests: 2.31.0
2023-10-23 23:06:10,402:INFO:          matplotlib: 3.7.3
2023-10-23 23:06:10,402:INFO:          scikitplot: 0.3.7
2023-10-23 23:06:10,403:INFO:         yellowbrick: 1.5
2023-10-23 23:06:10,403:INFO:              plotly: 5.17.0
2023-10-23 23:06:10,403:INFO:    plotly-resampler: Not installed
2023-10-23 23:06:10,403:INFO:             kaleido: 0.2.1
2023-10-23 23:06:10,403:INFO:           schemdraw: 0.15
2023-10-23 23:06:10,403:INFO:         statsmodels: 0.14.0
2023-10-23 23:06:10,403:INFO:              sktime: 0.21.1
2023-10-23 23:06:10,403:INFO:               tbats: 1.1.3
2023-10-23 23:06:10,403:INFO:            pmdarima: 2.0.3
2023-10-23 23:06:10,404:INFO:              psutil: 5.9.0
2023-10-23 23:06:10,404:INFO:          markupsafe: 2.1.3
2023-10-23 23:06:10,404:INFO:             pickle5: Not installed
2023-10-23 23:06:10,404:INFO:         cloudpickle: 2.2.1
2023-10-23 23:06:10,404:INFO:         deprecation: 2.1.0
2023-10-23 23:06:10,404:INFO:              xxhash: 3.4.1
2023-10-23 23:06:10,404:INFO:           wurlitzer: Not installed
2023-10-23 23:06:10,404:INFO:PyCaret optional dependencies:
2023-10-23 23:06:10,404:INFO:                shap: Not installed
2023-10-23 23:06:10,404:INFO:           interpret: Not installed
2023-10-23 23:06:10,404:INFO:                umap: Not installed
2023-10-23 23:06:10,404:INFO:     ydata_profiling: Not installed
2023-10-23 23:06:10,404:INFO:  explainerdashboard: Not installed
2023-10-23 23:06:10,404:INFO:             autoviz: Not installed
2023-10-23 23:06:10,404:INFO:           fairlearn: Not installed
2023-10-23 23:06:10,404:INFO:          deepchecks: Not installed
2023-10-23 23:06:10,404:INFO:             xgboost: Not installed
2023-10-23 23:06:10,404:INFO:            catboost: 1.2.2
2023-10-23 23:06:10,404:INFO:              kmodes: Not installed
2023-10-23 23:06:10,404:INFO:             mlxtend: Not installed
2023-10-23 23:06:10,404:INFO:       statsforecast: Not installed
2023-10-23 23:06:10,404:INFO:        tune_sklearn: Not installed
2023-10-23 23:06:10,404:INFO:                 ray: Not installed
2023-10-23 23:06:10,404:INFO:            hyperopt: Not installed
2023-10-23 23:06:10,404:INFO:              optuna: Not installed
2023-10-23 23:06:10,404:INFO:               skopt: Not installed
2023-10-23 23:06:10,404:INFO:              mlflow: 2.7.1
2023-10-23 23:06:10,404:INFO:              gradio: Not installed
2023-10-23 23:06:10,404:INFO:             fastapi: Not installed
2023-10-23 23:06:10,404:INFO:             uvicorn: Not installed
2023-10-23 23:06:10,404:INFO:              m2cgen: Not installed
2023-10-23 23:06:10,404:INFO:           evidently: Not installed
2023-10-23 23:06:10,404:INFO:               fugue: Not installed
2023-10-23 23:06:10,404:INFO:           streamlit: Not installed
2023-10-23 23:06:10,404:INFO:             prophet: Not installed
2023-10-23 23:06:10,404:INFO:None
2023-10-23 23:06:10,404:INFO:Set up data.
2023-10-23 23:07:34,312:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\985316847.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  a = merged_data_a.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 23:07:34,347:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\985316847.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  b = merged_data_b.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 23:07:34,394:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\985316847.py:3: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  c = merged_data_c.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 23:07:34,427:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\985316847.py:19: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  X_test_estimated_a = X_test_estimated_a.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 23:07:34,432:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\985316847.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  X_test_estimated_b = X_test_estimated_b.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 23:07:34,437:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\985316847.py:21: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  X_test_estimated_c = X_test_estimated_c.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 23:07:34,476:INFO:PyCaret RegressionExperiment
2023-10-23 23:07:34,476:INFO:Logging name: exp_A
2023-10-23 23:07:34,476:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 23:07:34,476:INFO:version 3.1.0
2023-10-23 23:07:34,476:INFO:Initializing setup()
2023-10-23 23:07:34,476:INFO:self.USI: 0618
2023-10-23 23:07:34,476:INFO:self._variable_keys: {'memory', 'X_train', 'fold_generator', 'log_plots_param', 'data', 'logging_param', 'target_param', 'exp_id', 'X_test', 'html_param', 'USI', 'transform_target_param', 'idx', 'pipeline', 'fold_shuffle_param', 'seed', 'y_test', 'y_train', 'n_jobs_param', '_ml_usecase', 'gpu_n_jobs_param', 'exp_name_log', 'fold_groups_param', '_available_plots', 'y', 'X', 'gpu_param'}
2023-10-23 23:07:34,476:INFO:Checking environment
2023-10-23 23:07:34,476:INFO:python_version: 3.8.18
2023-10-23 23:07:34,476:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 23:07:34,476:INFO:machine: AMD64
2023-10-23 23:07:34,476:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 23:07:34,476:INFO:Memory: svmem(total=16505954304, available=3115831296, percent=81.1, used=13390123008, free=3115831296)
2023-10-23 23:07:34,476:INFO:Physical Core: 8
2023-10-23 23:07:34,476:INFO:Logical Core: 16
2023-10-23 23:07:34,476:INFO:Checking libraries
2023-10-23 23:07:34,476:INFO:System:
2023-10-23 23:07:34,476:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 23:07:34,476:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 23:07:34,476:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 23:07:34,476:INFO:PyCaret required dependencies:
2023-10-23 23:07:34,476:INFO:                 pip: 23.3
2023-10-23 23:07:34,476:INFO:          setuptools: 68.0.0
2023-10-23 23:07:34,476:INFO:             pycaret: 3.1.0
2023-10-23 23:07:34,476:INFO:             IPython: 8.12.0
2023-10-23 23:07:34,476:INFO:          ipywidgets: 8.1.1
2023-10-23 23:07:34,476:INFO:                tqdm: 4.66.1
2023-10-23 23:07:34,476:INFO:               numpy: 1.23.5
2023-10-23 23:07:34,476:INFO:              pandas: 1.5.3
2023-10-23 23:07:34,476:INFO:              jinja2: 3.1.2
2023-10-23 23:07:34,476:INFO:               scipy: 1.10.1
2023-10-23 23:07:34,476:INFO:              joblib: 1.3.2
2023-10-23 23:07:34,476:INFO:             sklearn: 1.2.2
2023-10-23 23:07:34,476:INFO:                pyod: 1.1.0
2023-10-23 23:07:34,476:INFO:            imblearn: 0.11.0
2023-10-23 23:07:34,476:INFO:   category_encoders: 2.6.2
2023-10-23 23:07:34,476:INFO:            lightgbm: 4.1.0
2023-10-23 23:07:34,476:INFO:               numba: 0.58.1
2023-10-23 23:07:34,476:INFO:            requests: 2.31.0
2023-10-23 23:07:34,476:INFO:          matplotlib: 3.7.3
2023-10-23 23:07:34,476:INFO:          scikitplot: 0.3.7
2023-10-23 23:07:34,476:INFO:         yellowbrick: 1.5
2023-10-23 23:07:34,476:INFO:              plotly: 5.17.0
2023-10-23 23:07:34,476:INFO:    plotly-resampler: Not installed
2023-10-23 23:07:34,476:INFO:             kaleido: 0.2.1
2023-10-23 23:07:34,476:INFO:           schemdraw: 0.15
2023-10-23 23:07:34,476:INFO:         statsmodels: 0.14.0
2023-10-23 23:07:34,476:INFO:              sktime: 0.21.1
2023-10-23 23:07:34,476:INFO:               tbats: 1.1.3
2023-10-23 23:07:34,476:INFO:            pmdarima: 2.0.3
2023-10-23 23:07:34,476:INFO:              psutil: 5.9.0
2023-10-23 23:07:34,476:INFO:          markupsafe: 2.1.3
2023-10-23 23:07:34,476:INFO:             pickle5: Not installed
2023-10-23 23:07:34,476:INFO:         cloudpickle: 2.2.1
2023-10-23 23:07:34,476:INFO:         deprecation: 2.1.0
2023-10-23 23:07:34,476:INFO:              xxhash: 3.4.1
2023-10-23 23:07:34,476:INFO:           wurlitzer: Not installed
2023-10-23 23:07:34,476:INFO:PyCaret optional dependencies:
2023-10-23 23:07:34,476:INFO:                shap: Not installed
2023-10-23 23:07:34,476:INFO:           interpret: Not installed
2023-10-23 23:07:34,476:INFO:                umap: Not installed
2023-10-23 23:07:34,476:INFO:     ydata_profiling: Not installed
2023-10-23 23:07:34,476:INFO:  explainerdashboard: Not installed
2023-10-23 23:07:34,476:INFO:             autoviz: Not installed
2023-10-23 23:07:34,476:INFO:           fairlearn: Not installed
2023-10-23 23:07:34,476:INFO:          deepchecks: Not installed
2023-10-23 23:07:34,476:INFO:             xgboost: Not installed
2023-10-23 23:07:34,476:INFO:            catboost: 1.2.2
2023-10-23 23:07:34,476:INFO:              kmodes: Not installed
2023-10-23 23:07:34,476:INFO:             mlxtend: Not installed
2023-10-23 23:07:34,476:INFO:       statsforecast: Not installed
2023-10-23 23:07:34,476:INFO:        tune_sklearn: Not installed
2023-10-23 23:07:34,476:INFO:                 ray: Not installed
2023-10-23 23:07:34,476:INFO:            hyperopt: Not installed
2023-10-23 23:07:34,476:INFO:              optuna: Not installed
2023-10-23 23:07:34,476:INFO:               skopt: Not installed
2023-10-23 23:07:34,476:INFO:              mlflow: 2.7.1
2023-10-23 23:07:34,476:INFO:              gradio: Not installed
2023-10-23 23:07:34,476:INFO:             fastapi: Not installed
2023-10-23 23:07:34,476:INFO:             uvicorn: Not installed
2023-10-23 23:07:34,476:INFO:              m2cgen: Not installed
2023-10-23 23:07:34,476:INFO:           evidently: Not installed
2023-10-23 23:07:34,476:INFO:               fugue: Not installed
2023-10-23 23:07:34,476:INFO:           streamlit: Not installed
2023-10-23 23:07:34,476:INFO:             prophet: Not installed
2023-10-23 23:07:34,476:INFO:None
2023-10-23 23:07:34,476:INFO:Set up data.
2023-10-23 23:07:34,509:INFO:Set up folding strategy.
2023-10-23 23:07:34,509:INFO:Set up train/test split.
2023-10-23 23:07:34,542:INFO:Set up index.
2023-10-23 23:07:34,542:INFO:Assigning column types.
2023-10-23 23:07:34,566:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 23:07:34,566:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 23:07:34,571:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:07:34,575:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:07:34,653:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:07:34,695:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:07:34,695:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:07:34,695:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:07:34,695:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 23:07:34,695:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:07:34,711:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:07:34,781:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:07:34,833:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:07:34,833:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:07:34,833:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:07:34,833:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 23:07:34,842:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:07:34,848:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:07:34,924:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:07:34,973:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:07:34,974:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:07:34,974:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:07:34,976:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:07:34,976:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:07:35,060:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:07:35,108:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:07:35,108:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:07:35,108:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:07:35,108:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 23:07:35,108:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:07:35,192:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:07:35,239:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:07:35,239:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:07:35,239:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:07:35,255:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:07:35,326:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:07:35,376:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:07:35,376:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:07:35,376:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:07:35,376:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 23:07:35,473:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:07:35,523:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:07:35,523:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:07:35,523:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:07:35,610:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:07:35,666:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:07:35,666:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:07:35,666:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:07:35,666:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 23:07:35,763:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:07:35,813:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:07:35,813:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:07:35,899:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:07:35,948:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:07:35,948:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:07:35,948:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 23:07:36,096:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:07:36,096:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:07:36,223:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:07:36,223:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:07:36,223:INFO:Preparing preprocessing pipeline...
2023-10-23 23:07:36,223:INFO:Set up date feature engineering.
2023-10-23 23:07:36,223:INFO:Set up simple imputation.
2023-10-23 23:07:36,239:INFO:Set up encoding of ordinal features.
2023-10-23 23:07:36,258:INFO:Set up encoding of categorical features.
2023-10-23 23:07:36,258:INFO:Set up variance threshold.
2023-10-23 23:07:36,258:INFO:Set up column name cleaning.
2023-10-23 23:07:36,534:INFO:Finished creating preprocessing pipeline.
2023-10-23 23:07:36,607:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 23:07:36,608:INFO:Creating final display dataframe.
2023-10-23 23:07:36,747:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (34061, 48)
4        Transformed data shape  (34061, 37)
5   Transformed train set shape  (23842, 37)
6    Transformed test set shape  (10219, 37)
7              Ordinal features            2
8              Numeric features           43
9                 Date features            1
10         Categorical features            3
11     Rows with missing values        97.6%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18       Low variance threshold         0.05
19               Fold Generator        KFold
20                  Fold Number           10
21                     CPU Jobs           -1
22                      Use GPU        False
23               Log Experiment        False
24              Experiment Name        exp_A
25                          USI         0618
2023-10-23 23:07:36,898:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:07:36,899:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:07:37,036:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:07:37,036:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:07:37,036:INFO:setup() successfully completed in 2.57s...............
2023-10-23 23:07:37,036:INFO:Initializing compare_models()
2023-10-23 23:07:37,036:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035975F820>, include=['catboost', 'lightgbm'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002035975F820>, 'include': ['catboost', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-10-23 23:07:37,036:INFO:Checking exceptions
2023-10-23 23:07:37,041:INFO:Preparing display monitor
2023-10-23 23:07:37,041:INFO:Initializing CatBoost Regressor
2023-10-23 23:07:37,041:INFO:Total runtime is 0.0 minutes
2023-10-23 23:07:37,041:INFO:SubProcess create_model() called ==================================
2023-10-23 23:07:37,041:INFO:Initializing create_model()
2023-10-23 23:07:37,041:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035975F820>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000203592B4100>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 23:07:37,041:INFO:Checking exceptions
2023-10-23 23:07:37,041:INFO:Importing libraries
2023-10-23 23:07:37,041:INFO:Copying training dataset
2023-10-23 23:07:37,074:INFO:Defining folds
2023-10-23 23:07:37,074:INFO:Declaring metric variables
2023-10-23 23:07:37,074:INFO:Importing untrained model
2023-10-23 23:07:37,074:INFO:CatBoost Regressor Imported successfully
2023-10-23 23:07:37,074:INFO:Starting cross validation
2023-10-23 23:07:37,074:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 23:08:11,276:INFO:Calculating mean and std
2023-10-23 23:08:11,278:INFO:Creating metrics dataframe
2023-10-23 23:08:11,278:INFO:Uploading results into container
2023-10-23 23:08:11,278:INFO:Uploading model into container now
2023-10-23 23:08:11,278:INFO:_master_model_container: 1
2023-10-23 23:08:11,278:INFO:_display_container: 2
2023-10-23 23:08:11,278:INFO:<catboost.core.CatBoostRegressor object at 0x000002035C1217F0>
2023-10-23 23:08:11,278:INFO:create_model() successfully completed......................................
2023-10-23 23:08:11,612:INFO:SubProcess create_model() end ==================================
2023-10-23 23:08:11,612:INFO:Creating metrics dataframe
2023-10-23 23:08:11,612:INFO:Initializing Light Gradient Boosting Machine
2023-10-23 23:08:11,612:INFO:Total runtime is 0.5761906464894613 minutes
2023-10-23 23:08:11,612:INFO:SubProcess create_model() called ==================================
2023-10-23 23:08:11,612:INFO:Initializing create_model()
2023-10-23 23:08:11,612:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035975F820>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000203592B4100>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 23:08:11,612:INFO:Checking exceptions
2023-10-23 23:08:11,612:INFO:Importing libraries
2023-10-23 23:08:11,612:INFO:Copying training dataset
2023-10-23 23:08:11,646:INFO:Defining folds
2023-10-23 23:08:11,646:INFO:Declaring metric variables
2023-10-23 23:08:11,646:INFO:Importing untrained model
2023-10-23 23:08:11,646:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 23:08:11,646:INFO:Starting cross validation
2023-10-23 23:08:11,646:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 23:08:15,276:INFO:Calculating mean and std
2023-10-23 23:08:15,276:INFO:Creating metrics dataframe
2023-10-23 23:08:15,276:INFO:Uploading results into container
2023-10-23 23:08:15,276:INFO:Uploading model into container now
2023-10-23 23:08:15,276:INFO:_master_model_container: 2
2023-10-23 23:08:15,276:INFO:_display_container: 2
2023-10-23 23:08:15,276:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:08:15,276:INFO:create_model() successfully completed......................................
2023-10-23 23:08:15,530:INFO:SubProcess create_model() end ==================================
2023-10-23 23:08:15,530:INFO:Creating metrics dataframe
2023-10-23 23:08:15,530:INFO:Initializing create_model()
2023-10-23 23:08:15,530:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035975F820>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 23:08:15,530:INFO:Checking exceptions
2023-10-23 23:08:15,530:INFO:Importing libraries
2023-10-23 23:08:15,530:INFO:Copying training dataset
2023-10-23 23:08:15,565:INFO:Defining folds
2023-10-23 23:08:15,565:INFO:Declaring metric variables
2023-10-23 23:08:15,565:INFO:Importing untrained model
2023-10-23 23:08:15,565:INFO:Declaring custom model
2023-10-23 23:08:15,565:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 23:08:15,565:INFO:Cross validation set to False
2023-10-23 23:08:15,565:INFO:Fitting Model
2023-10-23 23:08:15,849:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009372 seconds.
2023-10-23 23:08:15,849:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 23:08:15,849:INFO:[LightGBM] [Info] Total Bins 6029
2023-10-23 23:08:15,849:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 36
2023-10-23 23:08:15,849:INFO:[LightGBM] [Info] Start training from score 616.864890
2023-10-23 23:08:16,096:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:08:16,096:INFO:create_model() successfully completed......................................
2023-10-23 23:08:16,380:INFO:_master_model_container: 2
2023-10-23 23:08:16,380:INFO:_display_container: 2
2023-10-23 23:08:16,380:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:08:16,380:INFO:compare_models() successfully completed......................................
2023-10-23 23:08:16,380:INFO:Initializing finalize_model()
2023-10-23 23:08:16,380:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035975F820>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-23 23:08:16,380:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:08:16,401:INFO:Initializing create_model()
2023-10-23 23:08:16,401:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035975F820>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-23 23:08:16,401:INFO:Checking exceptions
2023-10-23 23:08:16,401:INFO:Importing libraries
2023-10-23 23:08:16,401:INFO:Copying training dataset
2023-10-23 23:08:16,401:INFO:Defining folds
2023-10-23 23:08:16,401:INFO:Declaring metric variables
2023-10-23 23:08:16,401:INFO:Importing untrained model
2023-10-23 23:08:16,401:INFO:Declaring custom model
2023-10-23 23:08:16,401:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 23:08:16,408:INFO:Cross validation set to False
2023-10-23 23:08:16,408:INFO:Fitting Model
2023-10-23 23:08:16,805:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006454 seconds.
2023-10-23 23:08:16,805:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 23:08:16,806:INFO:[LightGBM] [Info] Total Bins 6436
2023-10-23 23:08:16,807:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 37
2023-10-23 23:08:16,807:INFO:[LightGBM] [Info] Start training from score 631.011165
2023-10-23 23:08:17,130:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-23 23:08:17,130:INFO:create_model() successfully completed......................................
2023-10-23 23:08:17,362:INFO:_master_model_container: 2
2023-10-23 23:08:17,362:INFO:_display_container: 2
2023-10-23 23:08:17,426:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-23 23:08:17,427:INFO:finalize_model() successfully completed......................................
2023-10-23 23:08:17,778:INFO:Initializing save_model()
2023-10-23 23:08:17,778:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_A, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 23:08:17,778:INFO:Adding model into prep_pipe
2023-10-23 23:08:17,778:WARNING:Only Model saved as it was a pipeline.
2023-10-23 23:08:17,795:INFO:final_model_for_location_A.pkl saved in current working directory
2023-10-23 23:08:17,896:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-23 23:08:17,896:INFO:save_model() successfully completed......................................
2023-10-23 23:08:18,146:INFO:PyCaret RegressionExperiment
2023-10-23 23:08:18,146:INFO:Logging name: exp_B
2023-10-23 23:08:18,146:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 23:08:18,146:INFO:version 3.1.0
2023-10-23 23:08:18,146:INFO:Initializing setup()
2023-10-23 23:08:18,146:INFO:self.USI: d864
2023-10-23 23:08:18,146:INFO:self._variable_keys: {'memory', 'X_train', 'fold_generator', 'log_plots_param', 'data', 'logging_param', 'target_param', 'exp_id', 'X_test', 'html_param', 'USI', 'transform_target_param', 'idx', 'pipeline', 'fold_shuffle_param', 'seed', 'y_test', 'y_train', 'n_jobs_param', '_ml_usecase', 'gpu_n_jobs_param', 'exp_name_log', 'fold_groups_param', '_available_plots', 'y', 'X', 'gpu_param'}
2023-10-23 23:08:18,146:INFO:Checking environment
2023-10-23 23:08:18,146:INFO:python_version: 3.8.18
2023-10-23 23:08:18,146:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 23:08:18,146:INFO:machine: AMD64
2023-10-23 23:08:18,146:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 23:08:18,146:INFO:Memory: svmem(total=16505954304, available=2951757824, percent=82.1, used=13554196480, free=2951757824)
2023-10-23 23:08:18,146:INFO:Physical Core: 8
2023-10-23 23:08:18,146:INFO:Logical Core: 16
2023-10-23 23:08:18,146:INFO:Checking libraries
2023-10-23 23:08:18,146:INFO:System:
2023-10-23 23:08:18,146:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 23:08:18,146:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 23:08:18,146:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 23:08:18,146:INFO:PyCaret required dependencies:
2023-10-23 23:08:18,146:INFO:                 pip: 23.3
2023-10-23 23:08:18,146:INFO:          setuptools: 68.0.0
2023-10-23 23:08:18,146:INFO:             pycaret: 3.1.0
2023-10-23 23:08:18,146:INFO:             IPython: 8.12.0
2023-10-23 23:08:18,146:INFO:          ipywidgets: 8.1.1
2023-10-23 23:08:18,146:INFO:                tqdm: 4.66.1
2023-10-23 23:08:18,146:INFO:               numpy: 1.23.5
2023-10-23 23:08:18,146:INFO:              pandas: 1.5.3
2023-10-23 23:08:18,146:INFO:              jinja2: 3.1.2
2023-10-23 23:08:18,146:INFO:               scipy: 1.10.1
2023-10-23 23:08:18,146:INFO:              joblib: 1.3.2
2023-10-23 23:08:18,146:INFO:             sklearn: 1.2.2
2023-10-23 23:08:18,146:INFO:                pyod: 1.1.0
2023-10-23 23:08:18,146:INFO:            imblearn: 0.11.0
2023-10-23 23:08:18,146:INFO:   category_encoders: 2.6.2
2023-10-23 23:08:18,146:INFO:            lightgbm: 4.1.0
2023-10-23 23:08:18,154:INFO:               numba: 0.58.1
2023-10-23 23:08:18,154:INFO:            requests: 2.31.0
2023-10-23 23:08:18,154:INFO:          matplotlib: 3.7.3
2023-10-23 23:08:18,154:INFO:          scikitplot: 0.3.7
2023-10-23 23:08:18,154:INFO:         yellowbrick: 1.5
2023-10-23 23:08:18,154:INFO:              plotly: 5.17.0
2023-10-23 23:08:18,154:INFO:    plotly-resampler: Not installed
2023-10-23 23:08:18,154:INFO:             kaleido: 0.2.1
2023-10-23 23:08:18,154:INFO:           schemdraw: 0.15
2023-10-23 23:08:18,154:INFO:         statsmodels: 0.14.0
2023-10-23 23:08:18,154:INFO:              sktime: 0.21.1
2023-10-23 23:08:18,154:INFO:               tbats: 1.1.3
2023-10-23 23:08:18,154:INFO:            pmdarima: 2.0.3
2023-10-23 23:08:18,154:INFO:              psutil: 5.9.0
2023-10-23 23:08:18,155:INFO:          markupsafe: 2.1.3
2023-10-23 23:08:18,155:INFO:             pickle5: Not installed
2023-10-23 23:08:18,155:INFO:         cloudpickle: 2.2.1
2023-10-23 23:08:18,155:INFO:         deprecation: 2.1.0
2023-10-23 23:08:18,155:INFO:              xxhash: 3.4.1
2023-10-23 23:08:18,155:INFO:           wurlitzer: Not installed
2023-10-23 23:08:18,155:INFO:PyCaret optional dependencies:
2023-10-23 23:08:18,155:INFO:                shap: Not installed
2023-10-23 23:08:18,155:INFO:           interpret: Not installed
2023-10-23 23:08:18,155:INFO:                umap: Not installed
2023-10-23 23:08:18,155:INFO:     ydata_profiling: Not installed
2023-10-23 23:08:18,155:INFO:  explainerdashboard: Not installed
2023-10-23 23:08:18,155:INFO:             autoviz: Not installed
2023-10-23 23:08:18,155:INFO:           fairlearn: Not installed
2023-10-23 23:08:18,155:INFO:          deepchecks: Not installed
2023-10-23 23:08:18,155:INFO:             xgboost: Not installed
2023-10-23 23:08:18,155:INFO:            catboost: 1.2.2
2023-10-23 23:08:18,156:INFO:              kmodes: Not installed
2023-10-23 23:08:18,156:INFO:             mlxtend: Not installed
2023-10-23 23:08:18,156:INFO:       statsforecast: Not installed
2023-10-23 23:08:18,156:INFO:        tune_sklearn: Not installed
2023-10-23 23:08:18,156:INFO:                 ray: Not installed
2023-10-23 23:08:18,156:INFO:            hyperopt: Not installed
2023-10-23 23:08:18,156:INFO:              optuna: Not installed
2023-10-23 23:08:18,156:INFO:               skopt: Not installed
2023-10-23 23:08:18,156:INFO:              mlflow: 2.7.1
2023-10-23 23:08:18,156:INFO:              gradio: Not installed
2023-10-23 23:08:18,156:INFO:             fastapi: Not installed
2023-10-23 23:08:18,156:INFO:             uvicorn: Not installed
2023-10-23 23:08:18,156:INFO:              m2cgen: Not installed
2023-10-23 23:08:18,156:INFO:           evidently: Not installed
2023-10-23 23:08:18,156:INFO:               fugue: Not installed
2023-10-23 23:08:18,157:INFO:           streamlit: Not installed
2023-10-23 23:08:18,157:INFO:             prophet: Not installed
2023-10-23 23:08:18,157:INFO:None
2023-10-23 23:08:18,157:INFO:Set up data.
2023-10-23 23:10:40,758:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\3641526700.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  a = merged_data_a.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 23:10:40,794:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\3641526700.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  b = merged_data_b.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 23:10:40,827:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\3641526700.py:3: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  c = merged_data_c.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 23:10:40,874:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\3641526700.py:23: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  X_test_estimated_a = X_test_estimated_a.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 23:10:40,877:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\3641526700.py:24: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  X_test_estimated_b = X_test_estimated_b.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 23:10:40,877:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\3641526700.py:25: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  X_test_estimated_c = X_test_estimated_c.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 23:10:40,930:INFO:PyCaret RegressionExperiment
2023-10-23 23:10:40,931:INFO:Logging name: exp_A
2023-10-23 23:10:40,931:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 23:10:40,931:INFO:version 3.1.0
2023-10-23 23:10:40,931:INFO:Initializing setup()
2023-10-23 23:10:40,931:INFO:self.USI: 96cc
2023-10-23 23:10:40,931:INFO:self._variable_keys: {'memory', 'X_train', 'fold_generator', 'log_plots_param', 'data', 'logging_param', 'target_param', 'exp_id', 'X_test', 'html_param', 'USI', 'transform_target_param', 'idx', 'pipeline', 'fold_shuffle_param', 'seed', 'y_test', 'y_train', 'n_jobs_param', '_ml_usecase', 'gpu_n_jobs_param', 'exp_name_log', 'fold_groups_param', '_available_plots', 'y', 'X', 'gpu_param'}
2023-10-23 23:10:40,931:INFO:Checking environment
2023-10-23 23:10:40,931:INFO:python_version: 3.8.18
2023-10-23 23:10:40,932:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 23:10:40,932:INFO:machine: AMD64
2023-10-23 23:10:40,932:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 23:10:40,932:INFO:Memory: svmem(total=16505954304, available=2716459008, percent=83.5, used=13789495296, free=2716459008)
2023-10-23 23:10:40,932:INFO:Physical Core: 8
2023-10-23 23:10:40,932:INFO:Logical Core: 16
2023-10-23 23:10:40,932:INFO:Checking libraries
2023-10-23 23:10:40,932:INFO:System:
2023-10-23 23:10:40,932:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 23:10:40,932:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 23:10:40,932:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 23:10:40,932:INFO:PyCaret required dependencies:
2023-10-23 23:10:40,933:INFO:                 pip: 23.3
2023-10-23 23:10:40,933:INFO:          setuptools: 68.0.0
2023-10-23 23:10:40,933:INFO:             pycaret: 3.1.0
2023-10-23 23:10:40,933:INFO:             IPython: 8.12.0
2023-10-23 23:10:40,933:INFO:          ipywidgets: 8.1.1
2023-10-23 23:10:40,933:INFO:                tqdm: 4.66.1
2023-10-23 23:10:40,933:INFO:               numpy: 1.23.5
2023-10-23 23:10:40,933:INFO:              pandas: 1.5.3
2023-10-23 23:10:40,933:INFO:              jinja2: 3.1.2
2023-10-23 23:10:40,933:INFO:               scipy: 1.10.1
2023-10-23 23:10:40,933:INFO:              joblib: 1.3.2
2023-10-23 23:10:40,933:INFO:             sklearn: 1.2.2
2023-10-23 23:10:40,933:INFO:                pyod: 1.1.0
2023-10-23 23:10:40,933:INFO:            imblearn: 0.11.0
2023-10-23 23:10:40,933:INFO:   category_encoders: 2.6.2
2023-10-23 23:10:40,933:INFO:            lightgbm: 4.1.0
2023-10-23 23:10:40,933:INFO:               numba: 0.58.1
2023-10-23 23:10:40,933:INFO:            requests: 2.31.0
2023-10-23 23:10:40,934:INFO:          matplotlib: 3.7.3
2023-10-23 23:10:40,934:INFO:          scikitplot: 0.3.7
2023-10-23 23:10:40,934:INFO:         yellowbrick: 1.5
2023-10-23 23:10:40,934:INFO:              plotly: 5.17.0
2023-10-23 23:10:40,934:INFO:    plotly-resampler: Not installed
2023-10-23 23:10:40,934:INFO:             kaleido: 0.2.1
2023-10-23 23:10:40,934:INFO:           schemdraw: 0.15
2023-10-23 23:10:40,934:INFO:         statsmodels: 0.14.0
2023-10-23 23:10:40,934:INFO:              sktime: 0.21.1
2023-10-23 23:10:40,934:INFO:               tbats: 1.1.3
2023-10-23 23:10:40,934:INFO:            pmdarima: 2.0.3
2023-10-23 23:10:40,934:INFO:              psutil: 5.9.0
2023-10-23 23:10:40,935:INFO:          markupsafe: 2.1.3
2023-10-23 23:10:40,935:INFO:             pickle5: Not installed
2023-10-23 23:10:40,935:INFO:         cloudpickle: 2.2.1
2023-10-23 23:10:40,935:INFO:         deprecation: 2.1.0
2023-10-23 23:10:40,935:INFO:              xxhash: 3.4.1
2023-10-23 23:10:40,935:INFO:           wurlitzer: Not installed
2023-10-23 23:10:40,935:INFO:PyCaret optional dependencies:
2023-10-23 23:10:40,935:INFO:                shap: Not installed
2023-10-23 23:10:40,936:INFO:           interpret: Not installed
2023-10-23 23:10:40,936:INFO:                umap: Not installed
2023-10-23 23:10:40,936:INFO:     ydata_profiling: Not installed
2023-10-23 23:10:40,936:INFO:  explainerdashboard: Not installed
2023-10-23 23:10:40,936:INFO:             autoviz: Not installed
2023-10-23 23:10:40,936:INFO:           fairlearn: Not installed
2023-10-23 23:10:40,936:INFO:          deepchecks: Not installed
2023-10-23 23:10:40,936:INFO:             xgboost: Not installed
2023-10-23 23:10:40,936:INFO:            catboost: 1.2.2
2023-10-23 23:10:40,936:INFO:              kmodes: Not installed
2023-10-23 23:10:40,936:INFO:             mlxtend: Not installed
2023-10-23 23:10:40,936:INFO:       statsforecast: Not installed
2023-10-23 23:10:40,936:INFO:        tune_sklearn: Not installed
2023-10-23 23:10:40,936:INFO:                 ray: Not installed
2023-10-23 23:10:40,936:INFO:            hyperopt: Not installed
2023-10-23 23:10:40,936:INFO:              optuna: Not installed
2023-10-23 23:10:40,936:INFO:               skopt: Not installed
2023-10-23 23:10:40,937:INFO:              mlflow: 2.7.1
2023-10-23 23:10:40,937:INFO:              gradio: Not installed
2023-10-23 23:10:40,937:INFO:             fastapi: Not installed
2023-10-23 23:10:40,937:INFO:             uvicorn: Not installed
2023-10-23 23:10:40,937:INFO:              m2cgen: Not installed
2023-10-23 23:10:40,937:INFO:           evidently: Not installed
2023-10-23 23:10:40,937:INFO:               fugue: Not installed
2023-10-23 23:10:40,937:INFO:           streamlit: Not installed
2023-10-23 23:10:40,938:INFO:             prophet: Not installed
2023-10-23 23:10:40,938:INFO:None
2023-10-23 23:10:40,938:INFO:Set up data.
2023-10-23 23:10:40,979:INFO:Set up folding strategy.
2023-10-23 23:10:40,979:INFO:Set up train/test split.
2023-10-23 23:10:41,014:INFO:Set up index.
2023-10-23 23:10:41,017:INFO:Assigning column types.
2023-10-23 23:10:41,046:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 23:10:41,046:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 23:10:41,051:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:10:41,056:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:10:41,134:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:10:41,183:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:10:41,184:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:10:41,184:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:10:41,184:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 23:10:41,189:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:10:41,194:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:10:41,270:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:10:41,318:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:10:41,319:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:10:41,319:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:10:41,319:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 23:10:41,325:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:10:41,331:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:10:41,405:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:10:41,453:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:10:41,453:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:10:41,454:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:10:41,459:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:10:41,464:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:10:41,538:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:10:41,586:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:10:41,587:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:10:41,587:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:10:41,587:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 23:10:41,587:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:10:41,671:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:10:41,703:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:10:41,720:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:10:41,720:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:10:41,721:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:10:41,804:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:10:41,839:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:10:41,854:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:10:41,854:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:10:41,855:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 23:10:41,940:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:10:41,988:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:10:41,989:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:10:41,989:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:10:42,076:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:10:42,125:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:10:42,126:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:10:42,126:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:10:42,126:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 23:10:42,212:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:10:42,261:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:10:42,261:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:10:42,337:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:10:42,386:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:10:42,386:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:10:42,386:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 23:10:42,528:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:10:42,528:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:10:42,662:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:10:42,662:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:10:42,669:INFO:Preparing preprocessing pipeline...
2023-10-23 23:10:42,670:INFO:Set up date feature engineering.
2023-10-23 23:10:42,670:INFO:Set up simple imputation.
2023-10-23 23:10:42,679:INFO:Set up encoding of ordinal features.
2023-10-23 23:10:42,692:INFO:Set up encoding of categorical features.
2023-10-23 23:10:42,692:INFO:Set up variance threshold.
2023-10-23 23:10:42,695:INFO:Set up column name cleaning.
2023-10-23 23:10:42,988:INFO:Finished creating preprocessing pipeline.
2023-10-23 23:10:43,057:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 23:10:43,058:INFO:Creating final display dataframe.
2023-10-23 23:10:43,202:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (34061, 48)
4        Transformed data shape  (34061, 37)
5   Transformed train set shape  (23842, 37)
6    Transformed test set shape  (10219, 37)
7              Ordinal features            2
8              Numeric features           43
9                 Date features            1
10         Categorical features            3
11     Rows with missing values        97.6%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18       Low variance threshold         0.05
19               Fold Generator        KFold
20                  Fold Number           10
21                     CPU Jobs           -1
22                      Use GPU        False
23               Log Experiment        False
24              Experiment Name        exp_A
25                          USI         96cc
2023-10-23 23:10:43,335:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:10:43,335:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:10:43,470:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:10:43,470:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:10:43,470:INFO:setup() successfully completed in 2.55s...............
2023-10-23 23:10:43,470:INFO:Initializing compare_models()
2023-10-23 23:10:43,470:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020359037D60>, include=['catboost', 'lightgbm'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000020359037D60>, 'include': ['catboost', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-10-23 23:10:43,470:INFO:Checking exceptions
2023-10-23 23:10:43,486:INFO:Preparing display monitor
2023-10-23 23:10:43,488:INFO:Initializing CatBoost Regressor
2023-10-23 23:10:43,488:INFO:Total runtime is 0.0 minutes
2023-10-23 23:10:43,488:INFO:SubProcess create_model() called ==================================
2023-10-23 23:10:43,488:INFO:Initializing create_model()
2023-10-23 23:10:43,488:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020359037D60>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002035B4693A0>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 23:10:43,488:INFO:Checking exceptions
2023-10-23 23:10:43,488:INFO:Importing libraries
2023-10-23 23:10:43,488:INFO:Copying training dataset
2023-10-23 23:10:43,522:INFO:Defining folds
2023-10-23 23:10:43,522:INFO:Declaring metric variables
2023-10-23 23:10:43,522:INFO:Importing untrained model
2023-10-23 23:10:43,522:INFO:CatBoost Regressor Imported successfully
2023-10-23 23:10:43,522:INFO:Starting cross validation
2023-10-23 23:10:43,522:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 23:11:14,894:INFO:Calculating mean and std
2023-10-23 23:11:14,894:INFO:Creating metrics dataframe
2023-10-23 23:11:14,894:INFO:Uploading results into container
2023-10-23 23:11:14,894:INFO:Uploading model into container now
2023-10-23 23:11:14,894:INFO:_master_model_container: 1
2023-10-23 23:11:14,894:INFO:_display_container: 2
2023-10-23 23:11:14,894:INFO:<catboost.core.CatBoostRegressor object at 0x000002035D13FE20>
2023-10-23 23:11:14,894:INFO:create_model() successfully completed......................................
2023-10-23 23:11:15,110:INFO:SubProcess create_model() end ==================================
2023-10-23 23:11:15,110:INFO:Creating metrics dataframe
2023-10-23 23:11:15,125:INFO:Initializing Light Gradient Boosting Machine
2023-10-23 23:11:15,125:INFO:Total runtime is 0.5272811889648438 minutes
2023-10-23 23:11:15,125:INFO:SubProcess create_model() called ==================================
2023-10-23 23:11:15,126:INFO:Initializing create_model()
2023-10-23 23:11:15,126:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020359037D60>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002035B4693A0>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 23:11:15,126:INFO:Checking exceptions
2023-10-23 23:11:15,126:INFO:Importing libraries
2023-10-23 23:11:15,126:INFO:Copying training dataset
2023-10-23 23:11:15,143:INFO:Defining folds
2023-10-23 23:11:15,143:INFO:Declaring metric variables
2023-10-23 23:11:15,143:INFO:Importing untrained model
2023-10-23 23:11:15,143:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 23:11:15,143:INFO:Starting cross validation
2023-10-23 23:11:15,143:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 23:11:18,468:INFO:Calculating mean and std
2023-10-23 23:11:18,468:INFO:Creating metrics dataframe
2023-10-23 23:11:18,468:INFO:Uploading results into container
2023-10-23 23:11:18,468:INFO:Uploading model into container now
2023-10-23 23:11:18,468:INFO:_master_model_container: 2
2023-10-23 23:11:18,468:INFO:_display_container: 2
2023-10-23 23:11:18,468:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:11:18,468:INFO:create_model() successfully completed......................................
2023-10-23 23:11:18,677:INFO:SubProcess create_model() end ==================================
2023-10-23 23:11:18,677:INFO:Creating metrics dataframe
2023-10-23 23:11:18,693:INFO:Initializing create_model()
2023-10-23 23:11:18,693:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020359037D60>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 23:11:18,693:INFO:Checking exceptions
2023-10-23 23:11:18,693:INFO:Importing libraries
2023-10-23 23:11:18,693:INFO:Copying training dataset
2023-10-23 23:11:18,712:INFO:Defining folds
2023-10-23 23:11:18,712:INFO:Declaring metric variables
2023-10-23 23:11:18,712:INFO:Importing untrained model
2023-10-23 23:11:18,712:INFO:Declaring custom model
2023-10-23 23:11:18,712:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 23:11:18,712:INFO:Cross validation set to False
2023-10-23 23:11:18,712:INFO:Fitting Model
2023-10-23 23:11:18,978:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005204 seconds.
2023-10-23 23:11:18,978:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 23:11:18,978:INFO:[LightGBM] [Info] Total Bins 6029
2023-10-23 23:11:18,978:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 36
2023-10-23 23:11:18,978:INFO:[LightGBM] [Info] Start training from score 616.864890
2023-10-23 23:11:19,196:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:11:19,196:INFO:create_model() successfully completed......................................
2023-10-23 23:11:19,457:INFO:_master_model_container: 2
2023-10-23 23:11:19,457:INFO:_display_container: 2
2023-10-23 23:11:19,457:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:11:19,463:INFO:compare_models() successfully completed......................................
2023-10-23 23:11:19,463:INFO:Initializing finalize_model()
2023-10-23 23:11:19,463:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020359037D60>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-23 23:11:19,463:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:11:19,479:INFO:Initializing create_model()
2023-10-23 23:11:19,479:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020359037D60>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-23 23:11:19,479:INFO:Checking exceptions
2023-10-23 23:11:19,481:INFO:Importing libraries
2023-10-23 23:11:19,481:INFO:Copying training dataset
2023-10-23 23:11:19,482:INFO:Defining folds
2023-10-23 23:11:19,482:INFO:Declaring metric variables
2023-10-23 23:11:19,483:INFO:Importing untrained model
2023-10-23 23:11:19,483:INFO:Declaring custom model
2023-10-23 23:11:19,484:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 23:11:19,484:INFO:Cross validation set to False
2023-10-23 23:11:19,484:INFO:Fitting Model
2023-10-23 23:11:19,915:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006580 seconds.
2023-10-23 23:11:19,915:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 23:11:19,930:INFO:[LightGBM] [Info] Total Bins 6436
2023-10-23 23:11:19,930:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 37
2023-10-23 23:11:19,930:INFO:[LightGBM] [Info] Start training from score 631.011165
2023-10-23 23:11:20,244:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-23 23:11:20,244:INFO:create_model() successfully completed......................................
2023-10-23 23:11:20,445:INFO:_master_model_container: 2
2023-10-23 23:11:20,445:INFO:_display_container: 2
2023-10-23 23:11:20,510:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-23 23:11:20,510:INFO:finalize_model() successfully completed......................................
2023-10-23 23:11:20,855:INFO:Initializing save_model()
2023-10-23 23:11:20,855:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_A, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 23:11:20,856:INFO:Adding model into prep_pipe
2023-10-23 23:11:20,856:WARNING:Only Model saved as it was a pipeline.
2023-10-23 23:11:20,863:INFO:final_model_for_location_A.pkl saved in current working directory
2023-10-23 23:11:20,980:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-23 23:11:20,980:INFO:save_model() successfully completed......................................
2023-10-23 23:11:21,220:INFO:PyCaret RegressionExperiment
2023-10-23 23:11:21,220:INFO:Logging name: exp_B
2023-10-23 23:11:21,220:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 23:11:21,220:INFO:version 3.1.0
2023-10-23 23:11:21,220:INFO:Initializing setup()
2023-10-23 23:11:21,220:INFO:self.USI: 1b12
2023-10-23 23:11:21,220:INFO:self._variable_keys: {'memory', 'X_train', 'fold_generator', 'log_plots_param', 'data', 'logging_param', 'target_param', 'exp_id', 'X_test', 'html_param', 'USI', 'transform_target_param', 'idx', 'pipeline', 'fold_shuffle_param', 'seed', 'y_test', 'y_train', 'n_jobs_param', '_ml_usecase', 'gpu_n_jobs_param', 'exp_name_log', 'fold_groups_param', '_available_plots', 'y', 'X', 'gpu_param'}
2023-10-23 23:11:21,221:INFO:Checking environment
2023-10-23 23:11:21,221:INFO:python_version: 3.8.18
2023-10-23 23:11:21,221:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 23:11:21,221:INFO:machine: AMD64
2023-10-23 23:11:21,221:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 23:11:21,221:INFO:Memory: svmem(total=16505954304, available=2790125568, percent=83.1, used=13715828736, free=2790125568)
2023-10-23 23:11:21,221:INFO:Physical Core: 8
2023-10-23 23:11:21,221:INFO:Logical Core: 16
2023-10-23 23:11:21,221:INFO:Checking libraries
2023-10-23 23:11:21,221:INFO:System:
2023-10-23 23:11:21,221:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 23:11:21,221:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 23:11:21,221:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 23:11:21,221:INFO:PyCaret required dependencies:
2023-10-23 23:11:21,222:INFO:                 pip: 23.3
2023-10-23 23:11:21,222:INFO:          setuptools: 68.0.0
2023-10-23 23:11:21,222:INFO:             pycaret: 3.1.0
2023-10-23 23:11:21,222:INFO:             IPython: 8.12.0
2023-10-23 23:11:21,222:INFO:          ipywidgets: 8.1.1
2023-10-23 23:11:21,222:INFO:                tqdm: 4.66.1
2023-10-23 23:11:21,222:INFO:               numpy: 1.23.5
2023-10-23 23:11:21,222:INFO:              pandas: 1.5.3
2023-10-23 23:11:21,222:INFO:              jinja2: 3.1.2
2023-10-23 23:11:21,222:INFO:               scipy: 1.10.1
2023-10-23 23:11:21,222:INFO:              joblib: 1.3.2
2023-10-23 23:11:21,222:INFO:             sklearn: 1.2.2
2023-10-23 23:11:21,222:INFO:                pyod: 1.1.0
2023-10-23 23:11:21,222:INFO:            imblearn: 0.11.0
2023-10-23 23:11:21,222:INFO:   category_encoders: 2.6.2
2023-10-23 23:11:21,222:INFO:            lightgbm: 4.1.0
2023-10-23 23:11:21,223:INFO:               numba: 0.58.1
2023-10-23 23:11:21,223:INFO:            requests: 2.31.0
2023-10-23 23:11:21,223:INFO:          matplotlib: 3.7.3
2023-10-23 23:11:21,223:INFO:          scikitplot: 0.3.7
2023-10-23 23:11:21,223:INFO:         yellowbrick: 1.5
2023-10-23 23:11:21,223:INFO:              plotly: 5.17.0
2023-10-23 23:11:21,223:INFO:    plotly-resampler: Not installed
2023-10-23 23:11:21,223:INFO:             kaleido: 0.2.1
2023-10-23 23:11:21,223:INFO:           schemdraw: 0.15
2023-10-23 23:11:21,223:INFO:         statsmodels: 0.14.0
2023-10-23 23:11:21,223:INFO:              sktime: 0.21.1
2023-10-23 23:11:21,223:INFO:               tbats: 1.1.3
2023-10-23 23:11:21,223:INFO:            pmdarima: 2.0.3
2023-10-23 23:11:21,223:INFO:              psutil: 5.9.0
2023-10-23 23:11:21,223:INFO:          markupsafe: 2.1.3
2023-10-23 23:11:21,223:INFO:             pickle5: Not installed
2023-10-23 23:11:21,224:INFO:         cloudpickle: 2.2.1
2023-10-23 23:11:21,224:INFO:         deprecation: 2.1.0
2023-10-23 23:11:21,224:INFO:              xxhash: 3.4.1
2023-10-23 23:11:21,224:INFO:           wurlitzer: Not installed
2023-10-23 23:11:21,224:INFO:PyCaret optional dependencies:
2023-10-23 23:11:21,224:INFO:                shap: Not installed
2023-10-23 23:11:21,224:INFO:           interpret: Not installed
2023-10-23 23:11:21,224:INFO:                umap: Not installed
2023-10-23 23:11:21,224:INFO:     ydata_profiling: Not installed
2023-10-23 23:11:21,224:INFO:  explainerdashboard: Not installed
2023-10-23 23:11:21,224:INFO:             autoviz: Not installed
2023-10-23 23:11:21,224:INFO:           fairlearn: Not installed
2023-10-23 23:11:21,224:INFO:          deepchecks: Not installed
2023-10-23 23:11:21,224:INFO:             xgboost: Not installed
2023-10-23 23:11:21,224:INFO:            catboost: 1.2.2
2023-10-23 23:11:21,224:INFO:              kmodes: Not installed
2023-10-23 23:11:21,224:INFO:             mlxtend: Not installed
2023-10-23 23:11:21,225:INFO:       statsforecast: Not installed
2023-10-23 23:11:21,225:INFO:        tune_sklearn: Not installed
2023-10-23 23:11:21,225:INFO:                 ray: Not installed
2023-10-23 23:11:21,225:INFO:            hyperopt: Not installed
2023-10-23 23:11:21,225:INFO:              optuna: Not installed
2023-10-23 23:11:21,225:INFO:               skopt: Not installed
2023-10-23 23:11:21,225:INFO:              mlflow: 2.7.1
2023-10-23 23:11:21,225:INFO:              gradio: Not installed
2023-10-23 23:11:21,225:INFO:             fastapi: Not installed
2023-10-23 23:11:21,225:INFO:             uvicorn: Not installed
2023-10-23 23:11:21,225:INFO:              m2cgen: Not installed
2023-10-23 23:11:21,225:INFO:           evidently: Not installed
2023-10-23 23:11:21,225:INFO:               fugue: Not installed
2023-10-23 23:11:21,225:INFO:           streamlit: Not installed
2023-10-23 23:11:21,225:INFO:             prophet: Not installed
2023-10-23 23:11:21,225:INFO:None
2023-10-23 23:11:21,225:INFO:Set up data.
2023-10-23 23:12:57,744:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\1803319295.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  a = merged_data_a.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 23:12:57,780:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\1803319295.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  b = merged_data_b.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 23:12:57,821:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\1803319295.py:3: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  c = merged_data_c.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 23:12:57,842:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\1803319295.py:21: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  X_test_estimated_a = X_test_estimated_a.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 23:12:57,856:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\1803319295.py:22: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  X_test_estimated_b = X_test_estimated_b.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 23:12:57,863:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\1803319295.py:23: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  X_test_estimated_c = X_test_estimated_c.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 23:12:57,932:INFO:PyCaret RegressionExperiment
2023-10-23 23:12:57,934:INFO:Logging name: exp_A
2023-10-23 23:12:57,934:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 23:12:57,935:INFO:version 3.1.0
2023-10-23 23:12:57,935:INFO:Initializing setup()
2023-10-23 23:12:57,935:INFO:self.USI: 1e7f
2023-10-23 23:12:57,935:INFO:self._variable_keys: {'memory', 'X_train', 'fold_generator', 'log_plots_param', 'data', 'logging_param', 'target_param', 'exp_id', 'X_test', 'html_param', 'USI', 'transform_target_param', 'idx', 'pipeline', 'fold_shuffle_param', 'seed', 'y_test', 'y_train', 'n_jobs_param', '_ml_usecase', 'gpu_n_jobs_param', 'exp_name_log', 'fold_groups_param', '_available_plots', 'y', 'X', 'gpu_param'}
2023-10-23 23:12:57,935:INFO:Checking environment
2023-10-23 23:12:57,935:INFO:python_version: 3.8.18
2023-10-23 23:12:57,935:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 23:12:57,936:INFO:machine: AMD64
2023-10-23 23:12:57,936:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 23:12:57,936:INFO:Memory: svmem(total=16505954304, available=2710958080, percent=83.6, used=13794996224, free=2710958080)
2023-10-23 23:12:57,936:INFO:Physical Core: 8
2023-10-23 23:12:57,936:INFO:Logical Core: 16
2023-10-23 23:12:57,936:INFO:Checking libraries
2023-10-23 23:12:57,937:INFO:System:
2023-10-23 23:12:57,937:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 23:12:57,937:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 23:12:57,937:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 23:12:57,937:INFO:PyCaret required dependencies:
2023-10-23 23:12:57,937:INFO:                 pip: 23.3
2023-10-23 23:12:57,937:INFO:          setuptools: 68.0.0
2023-10-23 23:12:57,937:INFO:             pycaret: 3.1.0
2023-10-23 23:12:57,937:INFO:             IPython: 8.12.0
2023-10-23 23:12:57,937:INFO:          ipywidgets: 8.1.1
2023-10-23 23:12:57,937:INFO:                tqdm: 4.66.1
2023-10-23 23:12:57,937:INFO:               numpy: 1.23.5
2023-10-23 23:12:57,937:INFO:              pandas: 1.5.3
2023-10-23 23:12:57,937:INFO:              jinja2: 3.1.2
2023-10-23 23:12:57,937:INFO:               scipy: 1.10.1
2023-10-23 23:12:57,937:INFO:              joblib: 1.3.2
2023-10-23 23:12:57,937:INFO:             sklearn: 1.2.2
2023-10-23 23:12:57,937:INFO:                pyod: 1.1.0
2023-10-23 23:12:57,938:INFO:            imblearn: 0.11.0
2023-10-23 23:12:57,938:INFO:   category_encoders: 2.6.2
2023-10-23 23:12:57,938:INFO:            lightgbm: 4.1.0
2023-10-23 23:12:57,938:INFO:               numba: 0.58.1
2023-10-23 23:12:57,938:INFO:            requests: 2.31.0
2023-10-23 23:12:57,938:INFO:          matplotlib: 3.7.3
2023-10-23 23:12:57,938:INFO:          scikitplot: 0.3.7
2023-10-23 23:12:57,938:INFO:         yellowbrick: 1.5
2023-10-23 23:12:57,938:INFO:              plotly: 5.17.0
2023-10-23 23:12:57,938:INFO:    plotly-resampler: Not installed
2023-10-23 23:12:57,938:INFO:             kaleido: 0.2.1
2023-10-23 23:12:57,938:INFO:           schemdraw: 0.15
2023-10-23 23:12:57,938:INFO:         statsmodels: 0.14.0
2023-10-23 23:12:57,938:INFO:              sktime: 0.21.1
2023-10-23 23:12:57,938:INFO:               tbats: 1.1.3
2023-10-23 23:12:57,938:INFO:            pmdarima: 2.0.3
2023-10-23 23:12:57,938:INFO:              psutil: 5.9.0
2023-10-23 23:12:57,938:INFO:          markupsafe: 2.1.3
2023-10-23 23:12:57,938:INFO:             pickle5: Not installed
2023-10-23 23:12:57,938:INFO:         cloudpickle: 2.2.1
2023-10-23 23:12:57,938:INFO:         deprecation: 2.1.0
2023-10-23 23:12:57,939:INFO:              xxhash: 3.4.1
2023-10-23 23:12:57,939:INFO:           wurlitzer: Not installed
2023-10-23 23:12:57,939:INFO:PyCaret optional dependencies:
2023-10-23 23:12:57,939:INFO:                shap: Not installed
2023-10-23 23:12:57,939:INFO:           interpret: Not installed
2023-10-23 23:12:57,939:INFO:                umap: Not installed
2023-10-23 23:12:57,939:INFO:     ydata_profiling: Not installed
2023-10-23 23:12:57,939:INFO:  explainerdashboard: Not installed
2023-10-23 23:12:57,939:INFO:             autoviz: Not installed
2023-10-23 23:12:57,939:INFO:           fairlearn: Not installed
2023-10-23 23:12:57,939:INFO:          deepchecks: Not installed
2023-10-23 23:12:57,939:INFO:             xgboost: Not installed
2023-10-23 23:12:57,939:INFO:            catboost: 1.2.2
2023-10-23 23:12:57,939:INFO:              kmodes: Not installed
2023-10-23 23:12:57,939:INFO:             mlxtend: Not installed
2023-10-23 23:12:57,939:INFO:       statsforecast: Not installed
2023-10-23 23:12:57,939:INFO:        tune_sklearn: Not installed
2023-10-23 23:12:57,939:INFO:                 ray: Not installed
2023-10-23 23:12:57,939:INFO:            hyperopt: Not installed
2023-10-23 23:12:57,939:INFO:              optuna: Not installed
2023-10-23 23:12:57,939:INFO:               skopt: Not installed
2023-10-23 23:12:57,939:INFO:              mlflow: 2.7.1
2023-10-23 23:12:57,940:INFO:              gradio: Not installed
2023-10-23 23:12:57,940:INFO:             fastapi: Not installed
2023-10-23 23:12:57,940:INFO:             uvicorn: Not installed
2023-10-23 23:12:57,940:INFO:              m2cgen: Not installed
2023-10-23 23:12:57,940:INFO:           evidently: Not installed
2023-10-23 23:12:57,941:INFO:               fugue: Not installed
2023-10-23 23:12:57,941:INFO:           streamlit: Not installed
2023-10-23 23:12:57,941:INFO:             prophet: Not installed
2023-10-23 23:12:57,941:INFO:None
2023-10-23 23:12:57,941:INFO:Set up data.
2023-10-23 23:12:57,974:INFO:Set up folding strategy.
2023-10-23 23:12:57,975:INFO:Set up train/test split.
2023-10-23 23:12:57,997:INFO:Set up index.
2023-10-23 23:12:57,999:INFO:Assigning column types.
2023-10-23 23:12:58,019:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 23:12:58,020:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 23:12:58,026:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:12:58,032:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:12:58,124:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:12:58,179:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:12:58,180:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:12:58,180:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:12:58,180:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 23:12:58,180:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:12:58,191:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:12:58,264:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:12:58,314:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:12:58,314:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:12:58,314:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:12:58,314:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 23:12:58,314:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:12:58,329:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:12:58,413:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:12:58,463:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:12:58,463:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:12:58,463:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:12:58,463:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:12:58,463:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:12:58,546:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:12:58,598:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:12:58,598:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:12:58,598:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:12:58,598:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 23:12:58,608:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:12:58,692:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:12:58,743:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:12:58,743:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:12:58,743:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:12:58,759:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:12:58,829:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:12:58,877:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:12:58,877:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:12:58,877:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:12:58,877:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 23:12:58,979:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:12:59,026:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:12:59,026:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:12:59,026:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:12:59,128:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:12:59,179:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:12:59,179:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:12:59,179:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:12:59,179:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 23:12:59,272:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:12:59,322:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:12:59,322:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:12:59,410:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:12:59,456:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:12:59,456:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:12:59,456:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 23:12:59,596:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:12:59,596:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:12:59,744:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:12:59,744:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:12:59,744:INFO:Preparing preprocessing pipeline...
2023-10-23 23:12:59,744:INFO:Set up date feature engineering.
2023-10-23 23:12:59,744:INFO:Set up simple imputation.
2023-10-23 23:12:59,760:INFO:Set up encoding of ordinal features.
2023-10-23 23:12:59,779:INFO:Set up encoding of categorical features.
2023-10-23 23:12:59,779:INFO:Set up variance threshold.
2023-10-23 23:12:59,779:INFO:Set up column name cleaning.
2023-10-23 23:13:00,111:INFO:Finished creating preprocessing pipeline.
2023-10-23 23:13:00,174:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 23:13:00,174:INFO:Creating final display dataframe.
2023-10-23 23:13:00,313:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (34061, 48)
4        Transformed data shape  (34061, 37)
5   Transformed train set shape  (23842, 37)
6    Transformed test set shape  (10219, 37)
7              Ordinal features            2
8              Numeric features           43
9                 Date features            1
10         Categorical features            3
11     Rows with missing values        97.6%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18       Low variance threshold         0.05
19               Fold Generator        KFold
20                  Fold Number           10
21                     CPU Jobs           -1
22                      Use GPU        False
23               Log Experiment        False
24              Experiment Name        exp_A
25                          USI         1e7f
2023-10-23 23:13:00,460:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:13:00,460:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:13:00,592:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:13:00,592:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:13:00,607:INFO:setup() successfully completed in 2.7s...............
2023-10-23 23:13:00,607:INFO:Initializing compare_models()
2023-10-23 23:13:00,607:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035B5668E0>, include=['catboost', 'lightgbm'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002035B5668E0>, 'include': ['catboost', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-10-23 23:13:00,607:INFO:Checking exceptions
2023-10-23 23:13:00,607:INFO:Preparing display monitor
2023-10-23 23:13:00,623:INFO:Initializing CatBoost Regressor
2023-10-23 23:13:00,624:INFO:Total runtime is 1.7599264780680338e-05 minutes
2023-10-23 23:13:00,624:INFO:SubProcess create_model() called ==================================
2023-10-23 23:13:00,624:INFO:Initializing create_model()
2023-10-23 23:13:00,624:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035B5668E0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002035EF8A940>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 23:13:00,624:INFO:Checking exceptions
2023-10-23 23:13:00,625:INFO:Importing libraries
2023-10-23 23:13:00,625:INFO:Copying training dataset
2023-10-23 23:13:00,644:INFO:Defining folds
2023-10-23 23:13:00,644:INFO:Declaring metric variables
2023-10-23 23:13:00,644:INFO:Importing untrained model
2023-10-23 23:13:00,644:INFO:CatBoost Regressor Imported successfully
2023-10-23 23:13:00,644:INFO:Starting cross validation
2023-10-23 23:13:00,644:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 23:13:32,613:INFO:Calculating mean and std
2023-10-23 23:13:32,613:INFO:Creating metrics dataframe
2023-10-23 23:13:32,613:INFO:Uploading results into container
2023-10-23 23:13:32,613:INFO:Uploading model into container now
2023-10-23 23:13:32,613:INFO:_master_model_container: 1
2023-10-23 23:13:32,613:INFO:_display_container: 2
2023-10-23 23:13:32,613:INFO:<catboost.core.CatBoostRegressor object at 0x000002035EF660A0>
2023-10-23 23:13:32,613:INFO:create_model() successfully completed......................................
2023-10-23 23:13:32,870:INFO:SubProcess create_model() end ==================================
2023-10-23 23:13:32,870:INFO:Creating metrics dataframe
2023-10-23 23:13:32,879:INFO:Initializing Light Gradient Boosting Machine
2023-10-23 23:13:32,879:INFO:Total runtime is 0.5376013437906901 minutes
2023-10-23 23:13:32,879:INFO:SubProcess create_model() called ==================================
2023-10-23 23:13:32,879:INFO:Initializing create_model()
2023-10-23 23:13:32,879:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035B5668E0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002035EF8A940>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 23:13:32,879:INFO:Checking exceptions
2023-10-23 23:13:32,879:INFO:Importing libraries
2023-10-23 23:13:32,879:INFO:Copying training dataset
2023-10-23 23:13:32,895:INFO:Defining folds
2023-10-23 23:13:32,895:INFO:Declaring metric variables
2023-10-23 23:13:32,895:INFO:Importing untrained model
2023-10-23 23:13:32,895:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 23:13:32,895:INFO:Starting cross validation
2023-10-23 23:13:32,895:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 23:13:36,076:INFO:Calculating mean and std
2023-10-23 23:13:36,076:INFO:Creating metrics dataframe
2023-10-23 23:13:36,076:INFO:Uploading results into container
2023-10-23 23:13:36,076:INFO:Uploading model into container now
2023-10-23 23:13:36,076:INFO:_master_model_container: 2
2023-10-23 23:13:36,076:INFO:_display_container: 2
2023-10-23 23:13:36,076:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:13:36,076:INFO:create_model() successfully completed......................................
2023-10-23 23:13:36,293:INFO:SubProcess create_model() end ==================================
2023-10-23 23:13:36,293:INFO:Creating metrics dataframe
2023-10-23 23:13:36,309:INFO:Initializing create_model()
2023-10-23 23:13:36,309:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035B5668E0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 23:13:36,309:INFO:Checking exceptions
2023-10-23 23:13:36,310:INFO:Importing libraries
2023-10-23 23:13:36,310:INFO:Copying training dataset
2023-10-23 23:13:36,331:INFO:Defining folds
2023-10-23 23:13:36,331:INFO:Declaring metric variables
2023-10-23 23:13:36,331:INFO:Importing untrained model
2023-10-23 23:13:36,331:INFO:Declaring custom model
2023-10-23 23:13:36,331:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 23:13:36,331:INFO:Cross validation set to False
2023-10-23 23:13:36,331:INFO:Fitting Model
2023-10-23 23:13:36,592:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003551 seconds.
2023-10-23 23:13:36,592:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 23:13:36,592:INFO:[LightGBM] [Info] Total Bins 6029
2023-10-23 23:13:36,592:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 36
2023-10-23 23:13:36,592:INFO:[LightGBM] [Info] Start training from score 616.864890
2023-10-23 23:13:36,775:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:13:36,775:INFO:create_model() successfully completed......................................
2023-10-23 23:13:37,009:INFO:_master_model_container: 2
2023-10-23 23:13:37,009:INFO:_display_container: 2
2023-10-23 23:13:37,024:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:13:37,024:INFO:compare_models() successfully completed......................................
2023-10-23 23:13:37,025:INFO:Initializing finalize_model()
2023-10-23 23:13:37,025:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035B5668E0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-23 23:13:37,026:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:13:37,039:INFO:Initializing create_model()
2023-10-23 23:13:37,039:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035B5668E0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-23 23:13:37,039:INFO:Checking exceptions
2023-10-23 23:13:37,040:INFO:Importing libraries
2023-10-23 23:13:37,041:INFO:Copying training dataset
2023-10-23 23:13:37,042:INFO:Defining folds
2023-10-23 23:13:37,042:INFO:Declaring metric variables
2023-10-23 23:13:37,043:INFO:Importing untrained model
2023-10-23 23:13:37,043:INFO:Declaring custom model
2023-10-23 23:13:37,043:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 23:13:37,044:INFO:Cross validation set to False
2023-10-23 23:13:37,044:INFO:Fitting Model
2023-10-23 23:13:37,417:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006207 seconds.
2023-10-23 23:13:37,417:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 23:13:37,417:INFO:[LightGBM] [Info] Total Bins 6436
2023-10-23 23:13:37,417:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 37
2023-10-23 23:13:37,417:INFO:[LightGBM] [Info] Start training from score 631.011165
2023-10-23 23:13:37,794:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-23 23:13:37,794:INFO:create_model() successfully completed......................................
2023-10-23 23:13:38,013:INFO:_master_model_container: 2
2023-10-23 23:13:38,013:INFO:_display_container: 2
2023-10-23 23:13:38,062:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-23 23:13:38,062:INFO:finalize_model() successfully completed......................................
2023-10-23 23:13:38,394:INFO:Initializing save_model()
2023-10-23 23:13:38,394:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_A, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 23:13:38,394:INFO:Adding model into prep_pipe
2023-10-23 23:13:38,394:WARNING:Only Model saved as it was a pipeline.
2023-10-23 23:13:38,410:INFO:final_model_for_location_A.pkl saved in current working directory
2023-10-23 23:13:38,535:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-23 23:13:38,535:INFO:save_model() successfully completed......................................
2023-10-23 23:13:38,778:INFO:PyCaret RegressionExperiment
2023-10-23 23:13:38,778:INFO:Logging name: exp_B
2023-10-23 23:13:38,778:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 23:13:38,778:INFO:version 3.1.0
2023-10-23 23:13:38,778:INFO:Initializing setup()
2023-10-23 23:13:38,778:INFO:self.USI: 3834
2023-10-23 23:13:38,778:INFO:self._variable_keys: {'memory', 'X_train', 'fold_generator', 'log_plots_param', 'data', 'logging_param', 'target_param', 'exp_id', 'X_test', 'html_param', 'USI', 'transform_target_param', 'idx', 'pipeline', 'fold_shuffle_param', 'seed', 'y_test', 'y_train', 'n_jobs_param', '_ml_usecase', 'gpu_n_jobs_param', 'exp_name_log', 'fold_groups_param', '_available_plots', 'y', 'X', 'gpu_param'}
2023-10-23 23:13:38,778:INFO:Checking environment
2023-10-23 23:13:38,779:INFO:python_version: 3.8.18
2023-10-23 23:13:38,779:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 23:13:38,779:INFO:machine: AMD64
2023-10-23 23:13:38,779:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 23:13:38,779:INFO:Memory: svmem(total=16505954304, available=2815393792, percent=82.9, used=13690560512, free=2815393792)
2023-10-23 23:13:38,779:INFO:Physical Core: 8
2023-10-23 23:13:38,779:INFO:Logical Core: 16
2023-10-23 23:13:38,779:INFO:Checking libraries
2023-10-23 23:13:38,779:INFO:System:
2023-10-23 23:13:38,779:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 23:13:38,779:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 23:13:38,779:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 23:13:38,779:INFO:PyCaret required dependencies:
2023-10-23 23:13:38,779:INFO:                 pip: 23.3
2023-10-23 23:13:38,779:INFO:          setuptools: 68.0.0
2023-10-23 23:13:38,780:INFO:             pycaret: 3.1.0
2023-10-23 23:13:38,780:INFO:             IPython: 8.12.0
2023-10-23 23:13:38,780:INFO:          ipywidgets: 8.1.1
2023-10-23 23:13:38,780:INFO:                tqdm: 4.66.1
2023-10-23 23:13:38,780:INFO:               numpy: 1.23.5
2023-10-23 23:13:38,780:INFO:              pandas: 1.5.3
2023-10-23 23:13:38,780:INFO:              jinja2: 3.1.2
2023-10-23 23:13:38,780:INFO:               scipy: 1.10.1
2023-10-23 23:13:38,780:INFO:              joblib: 1.3.2
2023-10-23 23:13:38,780:INFO:             sklearn: 1.2.2
2023-10-23 23:13:38,780:INFO:                pyod: 1.1.0
2023-10-23 23:13:38,780:INFO:            imblearn: 0.11.0
2023-10-23 23:13:38,780:INFO:   category_encoders: 2.6.2
2023-10-23 23:13:38,780:INFO:            lightgbm: 4.1.0
2023-10-23 23:13:38,780:INFO:               numba: 0.58.1
2023-10-23 23:13:38,780:INFO:            requests: 2.31.0
2023-10-23 23:13:38,780:INFO:          matplotlib: 3.7.3
2023-10-23 23:13:38,780:INFO:          scikitplot: 0.3.7
2023-10-23 23:13:38,780:INFO:         yellowbrick: 1.5
2023-10-23 23:13:38,780:INFO:              plotly: 5.17.0
2023-10-23 23:13:38,781:INFO:    plotly-resampler: Not installed
2023-10-23 23:13:38,781:INFO:             kaleido: 0.2.1
2023-10-23 23:13:38,781:INFO:           schemdraw: 0.15
2023-10-23 23:13:38,781:INFO:         statsmodels: 0.14.0
2023-10-23 23:13:38,781:INFO:              sktime: 0.21.1
2023-10-23 23:13:38,781:INFO:               tbats: 1.1.3
2023-10-23 23:13:38,781:INFO:            pmdarima: 2.0.3
2023-10-23 23:13:38,781:INFO:              psutil: 5.9.0
2023-10-23 23:13:38,781:INFO:          markupsafe: 2.1.3
2023-10-23 23:13:38,781:INFO:             pickle5: Not installed
2023-10-23 23:13:38,781:INFO:         cloudpickle: 2.2.1
2023-10-23 23:13:38,781:INFO:         deprecation: 2.1.0
2023-10-23 23:13:38,781:INFO:              xxhash: 3.4.1
2023-10-23 23:13:38,781:INFO:           wurlitzer: Not installed
2023-10-23 23:13:38,781:INFO:PyCaret optional dependencies:
2023-10-23 23:13:38,781:INFO:                shap: Not installed
2023-10-23 23:13:38,782:INFO:           interpret: Not installed
2023-10-23 23:13:38,782:INFO:                umap: Not installed
2023-10-23 23:13:38,782:INFO:     ydata_profiling: Not installed
2023-10-23 23:13:38,782:INFO:  explainerdashboard: Not installed
2023-10-23 23:13:38,782:INFO:             autoviz: Not installed
2023-10-23 23:13:38,782:INFO:           fairlearn: Not installed
2023-10-23 23:13:38,782:INFO:          deepchecks: Not installed
2023-10-23 23:13:38,782:INFO:             xgboost: Not installed
2023-10-23 23:13:38,782:INFO:            catboost: 1.2.2
2023-10-23 23:13:38,782:INFO:              kmodes: Not installed
2023-10-23 23:13:38,782:INFO:             mlxtend: Not installed
2023-10-23 23:13:38,782:INFO:       statsforecast: Not installed
2023-10-23 23:13:38,782:INFO:        tune_sklearn: Not installed
2023-10-23 23:13:38,782:INFO:                 ray: Not installed
2023-10-23 23:13:38,782:INFO:            hyperopt: Not installed
2023-10-23 23:13:38,782:INFO:              optuna: Not installed
2023-10-23 23:13:38,783:INFO:               skopt: Not installed
2023-10-23 23:13:38,783:INFO:              mlflow: 2.7.1
2023-10-23 23:13:38,783:INFO:              gradio: Not installed
2023-10-23 23:13:38,783:INFO:             fastapi: Not installed
2023-10-23 23:13:38,783:INFO:             uvicorn: Not installed
2023-10-23 23:13:38,783:INFO:              m2cgen: Not installed
2023-10-23 23:13:38,783:INFO:           evidently: Not installed
2023-10-23 23:13:38,783:INFO:               fugue: Not installed
2023-10-23 23:13:38,783:INFO:           streamlit: Not installed
2023-10-23 23:13:38,783:INFO:             prophet: Not installed
2023-10-23 23:13:38,783:INFO:None
2023-10-23 23:13:38,783:INFO:Set up data.
2023-10-23 23:13:38,816:INFO:Set up folding strategy.
2023-10-23 23:13:38,816:INFO:Set up train/test split.
2023-10-23 23:13:38,835:INFO:Set up index.
2023-10-23 23:13:38,836:INFO:Assigning column types.
2023-10-23 23:13:38,840:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 23:13:38,840:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 23:13:38,859:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:13:38,863:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:13:38,936:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:13:38,979:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:13:38,979:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:13:38,979:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:13:38,979:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 23:13:38,996:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:13:38,996:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:13:39,063:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:13:39,125:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:13:39,125:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:13:39,125:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:13:39,125:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 23:13:39,125:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:13:39,137:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:13:39,210:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:13:39,257:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:13:39,257:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:13:39,257:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:13:39,257:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:13:39,273:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:13:39,343:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:13:39,395:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:13:39,395:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:13:39,395:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:13:39,395:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 23:13:39,411:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:13:39,493:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:13:39,543:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:13:39,544:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:13:39,544:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:13:39,544:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:13:39,628:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:13:39,675:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:13:39,675:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:13:39,675:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:13:39,675:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 23:13:39,761:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:13:39,812:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:13:39,812:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:13:39,812:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:13:39,908:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:13:39,945:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:13:39,945:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:13:39,945:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:13:39,945:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 23:13:40,045:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:13:40,096:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:13:40,096:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:13:40,193:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:13:40,241:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:13:40,241:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:13:40,241:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 23:13:40,378:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:13:40,378:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:13:40,519:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:13:40,519:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:13:40,519:INFO:Preparing preprocessing pipeline...
2023-10-23 23:13:40,519:INFO:Set up date feature engineering.
2023-10-23 23:13:40,519:INFO:Set up simple imputation.
2023-10-23 23:13:40,519:INFO:Set up encoding of ordinal features.
2023-10-23 23:13:40,544:INFO:Set up encoding of categorical features.
2023-10-23 23:13:40,545:INFO:Set up variance threshold.
2023-10-23 23:13:40,547:INFO:Set up column name cleaning.
2023-10-23 23:13:40,859:INFO:Finished creating preprocessing pipeline.
2023-10-23 23:13:40,925:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 23:13:40,925:INFO:Creating final display dataframe.
2023-10-23 23:13:41,509:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (32819, 48)
4        Transformed data shape  (32819, 37)
5   Transformed train set shape  (22973, 37)
6    Transformed test set shape   (9846, 37)
7              Ordinal features            2
8              Numeric features           43
9                 Date features            1
10         Categorical features            3
11     Rows with missing values        95.9%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18       Low variance threshold         0.05
19               Fold Generator        KFold
20                  Fold Number           10
21                     CPU Jobs           -1
22                      Use GPU        False
23               Log Experiment        False
24              Experiment Name        exp_B
25                          USI         3834
2023-10-23 23:13:41,656:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:13:41,656:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:13:41,796:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:13:41,796:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:13:41,796:INFO:setup() successfully completed in 3.03s...............
2023-10-23 23:13:41,796:INFO:Initializing compare_models()
2023-10-23 23:13:41,796:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000203579CC3D0>, include=['catboost', 'lightgbm'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000203579CC3D0>, 'include': ['catboost', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-10-23 23:13:41,796:INFO:Checking exceptions
2023-10-23 23:13:41,810:INFO:Preparing display monitor
2023-10-23 23:13:41,813:INFO:Initializing CatBoost Regressor
2023-10-23 23:13:41,813:INFO:Total runtime is 0.0 minutes
2023-10-23 23:13:41,813:INFO:SubProcess create_model() called ==================================
2023-10-23 23:13:41,813:INFO:Initializing create_model()
2023-10-23 23:13:41,813:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000203579CC3D0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020359CFE880>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 23:13:41,813:INFO:Checking exceptions
2023-10-23 23:13:41,813:INFO:Importing libraries
2023-10-23 23:13:41,813:INFO:Copying training dataset
2023-10-23 23:13:41,839:INFO:Defining folds
2023-10-23 23:13:41,839:INFO:Declaring metric variables
2023-10-23 23:13:41,839:INFO:Importing untrained model
2023-10-23 23:13:41,839:INFO:CatBoost Regressor Imported successfully
2023-10-23 23:13:41,839:INFO:Starting cross validation
2023-10-23 23:13:41,841:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 23:14:13,628:INFO:Calculating mean and std
2023-10-23 23:14:13,628:INFO:Creating metrics dataframe
2023-10-23 23:14:13,628:INFO:Uploading results into container
2023-10-23 23:14:13,628:INFO:Uploading model into container now
2023-10-23 23:14:13,628:INFO:_master_model_container: 1
2023-10-23 23:14:13,628:INFO:_display_container: 2
2023-10-23 23:14:13,628:INFO:<catboost.core.CatBoostRegressor object at 0x0000020359B967F0>
2023-10-23 23:14:13,628:INFO:create_model() successfully completed......................................
2023-10-23 23:14:13,845:INFO:SubProcess create_model() end ==================================
2023-10-23 23:14:13,845:INFO:Creating metrics dataframe
2023-10-23 23:14:13,849:INFO:Initializing Light Gradient Boosting Machine
2023-10-23 23:14:13,849:INFO:Total runtime is 0.5339254816373189 minutes
2023-10-23 23:14:13,849:INFO:SubProcess create_model() called ==================================
2023-10-23 23:14:13,850:INFO:Initializing create_model()
2023-10-23 23:14:13,850:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000203579CC3D0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020359CFE880>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 23:14:13,850:INFO:Checking exceptions
2023-10-23 23:14:13,850:INFO:Importing libraries
2023-10-23 23:14:13,850:INFO:Copying training dataset
2023-10-23 23:14:13,861:INFO:Defining folds
2023-10-23 23:14:13,861:INFO:Declaring metric variables
2023-10-23 23:14:13,861:INFO:Importing untrained model
2023-10-23 23:14:13,861:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 23:14:13,861:INFO:Starting cross validation
2023-10-23 23:14:13,875:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 23:14:17,192:INFO:Calculating mean and std
2023-10-23 23:14:17,192:INFO:Creating metrics dataframe
2023-10-23 23:14:17,192:INFO:Uploading results into container
2023-10-23 23:14:17,192:INFO:Uploading model into container now
2023-10-23 23:14:17,192:INFO:_master_model_container: 2
2023-10-23 23:14:17,192:INFO:_display_container: 2
2023-10-23 23:14:17,192:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:14:17,192:INFO:create_model() successfully completed......................................
2023-10-23 23:14:17,409:INFO:SubProcess create_model() end ==================================
2023-10-23 23:14:17,409:INFO:Creating metrics dataframe
2023-10-23 23:14:17,424:INFO:Initializing create_model()
2023-10-23 23:14:17,425:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000203579CC3D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 23:14:17,425:INFO:Checking exceptions
2023-10-23 23:14:17,426:INFO:Importing libraries
2023-10-23 23:14:17,426:INFO:Copying training dataset
2023-10-23 23:14:17,444:INFO:Defining folds
2023-10-23 23:14:17,444:INFO:Declaring metric variables
2023-10-23 23:14:17,444:INFO:Importing untrained model
2023-10-23 23:14:17,444:INFO:Declaring custom model
2023-10-23 23:14:17,444:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 23:14:17,444:INFO:Cross validation set to False
2023-10-23 23:14:17,444:INFO:Fitting Model
2023-10-23 23:14:17,708:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004809 seconds.
2023-10-23 23:14:17,708:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 23:14:17,708:INFO:[LightGBM] [Info] Total Bins 6071
2023-10-23 23:14:17,708:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 36
2023-10-23 23:14:17,708:INFO:[LightGBM] [Info] Start training from score 117.072182
2023-10-23 23:14:17,939:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:14:17,939:INFO:create_model() successfully completed......................................
2023-10-23 23:14:18,181:INFO:_master_model_container: 2
2023-10-23 23:14:18,181:INFO:_display_container: 2
2023-10-23 23:14:18,181:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:14:18,181:INFO:compare_models() successfully completed......................................
2023-10-23 23:14:18,181:INFO:Initializing finalize_model()
2023-10-23 23:14:18,181:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000203579CC3D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-23 23:14:18,181:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:14:18,194:INFO:Initializing create_model()
2023-10-23 23:14:18,194:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000203579CC3D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-23 23:14:18,194:INFO:Checking exceptions
2023-10-23 23:14:18,194:INFO:Importing libraries
2023-10-23 23:14:18,194:INFO:Copying training dataset
2023-10-23 23:14:18,194:INFO:Defining folds
2023-10-23 23:14:18,194:INFO:Declaring metric variables
2023-10-23 23:14:18,194:INFO:Importing untrained model
2023-10-23 23:14:18,194:INFO:Declaring custom model
2023-10-23 23:14:18,194:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 23:14:18,194:INFO:Cross validation set to False
2023-10-23 23:14:18,194:INFO:Fitting Model
2023-10-23 23:14:18,572:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006257 seconds.
2023-10-23 23:14:18,572:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 23:14:18,572:INFO:[LightGBM] [Info] Total Bins 6395
2023-10-23 23:14:18,572:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 37
2023-10-23 23:14:18,572:INFO:[LightGBM] [Info] Start training from score 96.893335
2023-10-23 23:14:18,897:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-23 23:14:18,897:INFO:create_model() successfully completed......................................
2023-10-23 23:14:19,096:INFO:_master_model_container: 2
2023-10-23 23:14:19,096:INFO:_display_container: 2
2023-10-23 23:14:19,159:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-23 23:14:19,159:INFO:finalize_model() successfully completed......................................
2023-10-23 23:14:19,461:INFO:Initializing save_model()
2023-10-23 23:14:19,461:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_B, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 23:14:19,461:INFO:Adding model into prep_pipe
2023-10-23 23:14:19,461:WARNING:Only Model saved as it was a pipeline.
2023-10-23 23:14:19,491:INFO:final_model_for_location_B.pkl saved in current working directory
2023-10-23 23:14:19,597:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-23 23:14:19,597:INFO:save_model() successfully completed......................................
2023-10-23 23:14:19,839:INFO:PyCaret RegressionExperiment
2023-10-23 23:14:19,839:INFO:Logging name: exp_C
2023-10-23 23:14:19,839:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 23:14:19,839:INFO:version 3.1.0
2023-10-23 23:14:19,839:INFO:Initializing setup()
2023-10-23 23:14:19,839:INFO:self.USI: 373e
2023-10-23 23:14:19,839:INFO:self._variable_keys: {'memory', 'X_train', 'fold_generator', 'log_plots_param', 'data', 'logging_param', 'target_param', 'exp_id', 'X_test', 'html_param', 'USI', 'transform_target_param', 'idx', 'pipeline', 'fold_shuffle_param', 'seed', 'y_test', 'y_train', 'n_jobs_param', '_ml_usecase', 'gpu_n_jobs_param', 'exp_name_log', 'fold_groups_param', '_available_plots', 'y', 'X', 'gpu_param'}
2023-10-23 23:14:19,840:INFO:Checking environment
2023-10-23 23:14:19,840:INFO:python_version: 3.8.18
2023-10-23 23:14:19,840:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 23:14:19,840:INFO:machine: AMD64
2023-10-23 23:14:19,840:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 23:14:19,840:INFO:Memory: svmem(total=16505954304, available=2849058816, percent=82.7, used=13656895488, free=2849058816)
2023-10-23 23:14:19,840:INFO:Physical Core: 8
2023-10-23 23:14:19,840:INFO:Logical Core: 16
2023-10-23 23:14:19,840:INFO:Checking libraries
2023-10-23 23:14:19,840:INFO:System:
2023-10-23 23:14:19,840:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 23:14:19,840:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 23:14:19,840:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 23:14:19,840:INFO:PyCaret required dependencies:
2023-10-23 23:14:19,840:INFO:                 pip: 23.3
2023-10-23 23:14:19,840:INFO:          setuptools: 68.0.0
2023-10-23 23:14:19,841:INFO:             pycaret: 3.1.0
2023-10-23 23:14:19,841:INFO:             IPython: 8.12.0
2023-10-23 23:14:19,841:INFO:          ipywidgets: 8.1.1
2023-10-23 23:14:19,841:INFO:                tqdm: 4.66.1
2023-10-23 23:14:19,841:INFO:               numpy: 1.23.5
2023-10-23 23:14:19,841:INFO:              pandas: 1.5.3
2023-10-23 23:14:19,841:INFO:              jinja2: 3.1.2
2023-10-23 23:14:19,841:INFO:               scipy: 1.10.1
2023-10-23 23:14:19,841:INFO:              joblib: 1.3.2
2023-10-23 23:14:19,841:INFO:             sklearn: 1.2.2
2023-10-23 23:14:19,841:INFO:                pyod: 1.1.0
2023-10-23 23:14:19,841:INFO:            imblearn: 0.11.0
2023-10-23 23:14:19,841:INFO:   category_encoders: 2.6.2
2023-10-23 23:14:19,841:INFO:            lightgbm: 4.1.0
2023-10-23 23:14:19,841:INFO:               numba: 0.58.1
2023-10-23 23:14:19,841:INFO:            requests: 2.31.0
2023-10-23 23:14:19,841:INFO:          matplotlib: 3.7.3
2023-10-23 23:14:19,842:INFO:          scikitplot: 0.3.7
2023-10-23 23:14:19,842:INFO:         yellowbrick: 1.5
2023-10-23 23:14:19,842:INFO:              plotly: 5.17.0
2023-10-23 23:14:19,842:INFO:    plotly-resampler: Not installed
2023-10-23 23:14:19,842:INFO:             kaleido: 0.2.1
2023-10-23 23:14:19,842:INFO:           schemdraw: 0.15
2023-10-23 23:14:19,842:INFO:         statsmodels: 0.14.0
2023-10-23 23:14:19,842:INFO:              sktime: 0.21.1
2023-10-23 23:14:19,843:INFO:               tbats: 1.1.3
2023-10-23 23:14:19,843:INFO:            pmdarima: 2.0.3
2023-10-23 23:14:19,843:INFO:              psutil: 5.9.0
2023-10-23 23:14:19,843:INFO:          markupsafe: 2.1.3
2023-10-23 23:14:19,843:INFO:             pickle5: Not installed
2023-10-23 23:14:19,843:INFO:         cloudpickle: 2.2.1
2023-10-23 23:14:19,843:INFO:         deprecation: 2.1.0
2023-10-23 23:14:19,843:INFO:              xxhash: 3.4.1
2023-10-23 23:14:19,843:INFO:           wurlitzer: Not installed
2023-10-23 23:14:19,843:INFO:PyCaret optional dependencies:
2023-10-23 23:14:19,843:INFO:                shap: Not installed
2023-10-23 23:14:19,843:INFO:           interpret: Not installed
2023-10-23 23:14:19,843:INFO:                umap: Not installed
2023-10-23 23:14:19,843:INFO:     ydata_profiling: Not installed
2023-10-23 23:14:19,843:INFO:  explainerdashboard: Not installed
2023-10-23 23:14:19,843:INFO:             autoviz: Not installed
2023-10-23 23:14:19,843:INFO:           fairlearn: Not installed
2023-10-23 23:14:19,843:INFO:          deepchecks: Not installed
2023-10-23 23:14:19,844:INFO:             xgboost: Not installed
2023-10-23 23:14:19,844:INFO:            catboost: 1.2.2
2023-10-23 23:14:19,844:INFO:              kmodes: Not installed
2023-10-23 23:14:19,844:INFO:             mlxtend: Not installed
2023-10-23 23:14:19,844:INFO:       statsforecast: Not installed
2023-10-23 23:14:19,844:INFO:        tune_sklearn: Not installed
2023-10-23 23:14:19,844:INFO:                 ray: Not installed
2023-10-23 23:14:19,844:INFO:            hyperopt: Not installed
2023-10-23 23:14:19,844:INFO:              optuna: Not installed
2023-10-23 23:14:19,844:INFO:               skopt: Not installed
2023-10-23 23:14:19,844:INFO:              mlflow: 2.7.1
2023-10-23 23:14:19,844:INFO:              gradio: Not installed
2023-10-23 23:14:19,844:INFO:             fastapi: Not installed
2023-10-23 23:14:19,844:INFO:             uvicorn: Not installed
2023-10-23 23:14:19,844:INFO:              m2cgen: Not installed
2023-10-23 23:14:19,844:INFO:           evidently: Not installed
2023-10-23 23:14:19,844:INFO:               fugue: Not installed
2023-10-23 23:14:19,844:INFO:           streamlit: Not installed
2023-10-23 23:14:19,844:INFO:             prophet: Not installed
2023-10-23 23:14:19,844:INFO:None
2023-10-23 23:14:19,845:INFO:Set up data.
2023-10-23 23:14:19,863:INFO:Set up folding strategy.
2023-10-23 23:14:19,872:INFO:Set up train/test split.
2023-10-23 23:14:19,887:INFO:Set up index.
2023-10-23 23:14:19,888:INFO:Assigning column types.
2023-10-23 23:14:19,903:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 23:14:19,903:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 23:14:19,908:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:14:19,912:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:14:19,984:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:14:20,028:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:14:20,028:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:14:20,028:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:14:20,028:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 23:14:20,028:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:14:20,043:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:14:20,114:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:14:20,161:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:14:20,161:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:14:20,161:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:14:20,161:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 23:14:20,173:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:14:20,179:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:14:20,244:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:14:20,292:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:14:20,292:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:14:20,292:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:14:20,292:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:14:20,307:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:14:20,377:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:14:20,424:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:14:20,424:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:14:20,424:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:14:20,424:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 23:14:20,443:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:14:20,508:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:14:20,563:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:14:20,563:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:14:20,563:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:14:20,563:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:14:20,645:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:14:20,694:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:14:20,694:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:14:20,694:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:14:20,694:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 23:14:20,785:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:14:20,826:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:14:20,826:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:14:20,826:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:14:20,909:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:14:20,956:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:14:20,956:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:14:20,956:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:14:20,956:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 23:14:21,044:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:14:21,110:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:14:21,110:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:14:21,189:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:14:21,244:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:14:21,244:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:14:21,244:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 23:14:21,375:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:14:21,375:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:14:21,506:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:14:21,506:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:14:21,506:INFO:Preparing preprocessing pipeline...
2023-10-23 23:14:21,506:INFO:Set up date feature engineering.
2023-10-23 23:14:21,506:INFO:Set up simple imputation.
2023-10-23 23:14:21,529:INFO:Set up encoding of ordinal features.
2023-10-23 23:14:21,529:INFO:Set up encoding of categorical features.
2023-10-23 23:14:21,529:INFO:Set up variance threshold.
2023-10-23 23:14:21,529:INFO:Set up column name cleaning.
2023-10-23 23:14:21,792:INFO:Finished creating preprocessing pipeline.
2023-10-23 23:14:21,845:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 23:14:21,845:INFO:Creating final display dataframe.
2023-10-23 23:14:22,392:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (26071, 48)
4        Transformed data shape  (26071, 41)
5   Transformed train set shape  (18249, 41)
6    Transformed test set shape   (7822, 41)
7              Ordinal features            2
8              Numeric features           43
9                 Date features            1
10         Categorical features            3
11     Rows with missing values        95.9%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18       Low variance threshold         0.05
19               Fold Generator        KFold
20                  Fold Number           10
21                     CPU Jobs           -1
22                      Use GPU        False
23               Log Experiment        False
24              Experiment Name        exp_C
25                          USI         373e
2023-10-23 23:14:22,524:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:14:22,524:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:14:22,655:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:14:22,655:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:14:22,655:INFO:setup() successfully completed in 2.82s...............
2023-10-23 23:14:22,655:INFO:Initializing compare_models()
2023-10-23 23:14:22,655:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035D0C3610>, include=['catboost', 'lightgbm'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002035D0C3610>, 'include': ['catboost', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-10-23 23:14:22,655:INFO:Checking exceptions
2023-10-23 23:14:22,655:INFO:Preparing display monitor
2023-10-23 23:14:22,674:INFO:Initializing CatBoost Regressor
2023-10-23 23:14:22,674:INFO:Total runtime is 0.0 minutes
2023-10-23 23:14:22,674:INFO:SubProcess create_model() called ==================================
2023-10-23 23:14:22,674:INFO:Initializing create_model()
2023-10-23 23:14:22,674:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035D0C3610>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000203593DA040>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 23:14:22,674:INFO:Checking exceptions
2023-10-23 23:14:22,674:INFO:Importing libraries
2023-10-23 23:14:22,675:INFO:Copying training dataset
2023-10-23 23:14:22,695:INFO:Defining folds
2023-10-23 23:14:22,695:INFO:Declaring metric variables
2023-10-23 23:14:22,695:INFO:Importing untrained model
2023-10-23 23:14:22,696:INFO:CatBoost Regressor Imported successfully
2023-10-23 23:14:22,696:INFO:Starting cross validation
2023-10-23 23:14:22,697:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 23:14:51,487:INFO:Calculating mean and std
2023-10-23 23:14:51,487:INFO:Creating metrics dataframe
2023-10-23 23:14:51,487:INFO:Uploading results into container
2023-10-23 23:14:51,487:INFO:Uploading model into container now
2023-10-23 23:14:51,487:INFO:_master_model_container: 1
2023-10-23 23:14:51,487:INFO:_display_container: 2
2023-10-23 23:14:51,487:INFO:<catboost.core.CatBoostRegressor object at 0x0000020359E96FD0>
2023-10-23 23:14:51,487:INFO:create_model() successfully completed......................................
2023-10-23 23:14:51,699:INFO:SubProcess create_model() end ==================================
2023-10-23 23:14:51,699:INFO:Creating metrics dataframe
2023-10-23 23:14:51,699:INFO:Initializing Light Gradient Boosting Machine
2023-10-23 23:14:51,699:INFO:Total runtime is 0.48375812768936155 minutes
2023-10-23 23:14:51,699:INFO:SubProcess create_model() called ==================================
2023-10-23 23:14:51,699:INFO:Initializing create_model()
2023-10-23 23:14:51,699:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035D0C3610>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000203593DA040>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 23:14:51,699:INFO:Checking exceptions
2023-10-23 23:14:51,699:INFO:Importing libraries
2023-10-23 23:14:51,699:INFO:Copying training dataset
2023-10-23 23:14:51,731:INFO:Defining folds
2023-10-23 23:14:51,731:INFO:Declaring metric variables
2023-10-23 23:14:51,731:INFO:Importing untrained model
2023-10-23 23:14:51,731:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 23:14:51,731:INFO:Starting cross validation
2023-10-23 23:14:51,731:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 23:14:54,497:INFO:Calculating mean and std
2023-10-23 23:14:54,497:INFO:Creating metrics dataframe
2023-10-23 23:14:54,497:INFO:Uploading results into container
2023-10-23 23:14:54,497:INFO:Uploading model into container now
2023-10-23 23:14:54,497:INFO:_master_model_container: 2
2023-10-23 23:14:54,497:INFO:_display_container: 2
2023-10-23 23:14:54,497:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:14:54,497:INFO:create_model() successfully completed......................................
2023-10-23 23:14:54,748:INFO:SubProcess create_model() end ==================================
2023-10-23 23:14:54,748:INFO:Creating metrics dataframe
2023-10-23 23:14:54,763:INFO:Initializing create_model()
2023-10-23 23:14:54,763:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035D0C3610>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 23:14:54,763:INFO:Checking exceptions
2023-10-23 23:14:54,763:INFO:Importing libraries
2023-10-23 23:14:54,763:INFO:Copying training dataset
2023-10-23 23:14:54,779:INFO:Defining folds
2023-10-23 23:14:54,779:INFO:Declaring metric variables
2023-10-23 23:14:54,779:INFO:Importing untrained model
2023-10-23 23:14:54,779:INFO:Declaring custom model
2023-10-23 23:14:54,779:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 23:14:54,779:INFO:Cross validation set to False
2023-10-23 23:14:54,779:INFO:Fitting Model
2023-10-23 23:14:55,052:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004707 seconds.
2023-10-23 23:14:55,052:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 23:14:55,052:INFO:[LightGBM] [Info] Total Bins 6250
2023-10-23 23:14:55,052:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 40
2023-10-23 23:14:55,052:INFO:[LightGBM] [Info] Start training from score 96.094131
2023-10-23 23:14:55,235:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:14:55,235:INFO:create_model() successfully completed......................................
2023-10-23 23:14:55,481:INFO:_master_model_container: 2
2023-10-23 23:14:55,481:INFO:_display_container: 2
2023-10-23 23:14:55,481:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:14:55,481:INFO:compare_models() successfully completed......................................
2023-10-23 23:14:55,481:INFO:Initializing finalize_model()
2023-10-23 23:14:55,481:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035D0C3610>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-23 23:14:55,481:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:14:55,497:INFO:Initializing create_model()
2023-10-23 23:14:55,497:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035D0C3610>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-23 23:14:55,497:INFO:Checking exceptions
2023-10-23 23:14:55,497:INFO:Importing libraries
2023-10-23 23:14:55,497:INFO:Copying training dataset
2023-10-23 23:14:55,501:INFO:Defining folds
2023-10-23 23:14:55,501:INFO:Declaring metric variables
2023-10-23 23:14:55,501:INFO:Importing untrained model
2023-10-23 23:14:55,501:INFO:Declaring custom model
2023-10-23 23:14:55,501:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 23:14:55,501:INFO:Cross validation set to False
2023-10-23 23:14:55,501:INFO:Fitting Model
2023-10-23 23:14:55,819:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007468 seconds.
2023-10-23 23:14:55,819:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 23:14:55,819:INFO:[LightGBM] [Info] Total Bins 6628
2023-10-23 23:14:55,819:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 41
2023-10-23 23:14:55,819:INFO:[LightGBM] [Info] Start training from score 77.700043
2023-10-23 23:14:56,149:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-23 23:14:56,149:INFO:create_model() successfully completed......................................
2023-10-23 23:14:56,364:INFO:_master_model_container: 2
2023-10-23 23:14:56,364:INFO:_display_container: 2
2023-10-23 23:14:56,415:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-23 23:14:56,415:INFO:finalize_model() successfully completed......................................
2023-10-23 23:14:56,747:INFO:Initializing save_model()
2023-10-23 23:14:56,747:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_C, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 23:14:56,747:INFO:Adding model into prep_pipe
2023-10-23 23:14:56,747:WARNING:Only Model saved as it was a pipeline.
2023-10-23 23:14:56,762:INFO:final_model_for_location_C.pkl saved in current working directory
2023-10-23 23:14:56,862:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-23 23:14:56,878:INFO:save_model() successfully completed......................................
2023-10-23 23:14:57,185:INFO:Initializing load_model()
2023-10-23 23:14:57,185:INFO:load_model(model_name=final_model_for_location_A, platform=None, authentication=None, verbose=True)
2023-10-23 23:14:57,211:INFO:Initializing load_model()
2023-10-23 23:14:57,211:INFO:load_model(model_name=final_model_for_location_B, platform=None, authentication=None, verbose=True)
2023-10-23 23:14:57,248:INFO:Initializing load_model()
2023-10-23 23:14:57,248:INFO:load_model(model_name=final_model_for_location_C, platform=None, authentication=None, verbose=True)
2023-10-23 23:21:48,518:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\1803319295.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  a = merged_data_a.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 23:21:48,553:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\1803319295.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  b = merged_data_b.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 23:21:48,586:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\1803319295.py:3: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  c = merged_data_c.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 23:21:48,620:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\1803319295.py:21: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  X_test_estimated_a = X_test_estimated_a.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 23:21:48,620:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\1803319295.py:22: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  X_test_estimated_b = X_test_estimated_b.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 23:21:48,629:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_20620\1803319295.py:23: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  X_test_estimated_c = X_test_estimated_c.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-23 23:21:48,692:INFO:PyCaret RegressionExperiment
2023-10-23 23:21:48,692:INFO:Logging name: exp_A
2023-10-23 23:21:48,693:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 23:21:48,693:INFO:version 3.1.0
2023-10-23 23:21:48,693:INFO:Initializing setup()
2023-10-23 23:21:48,694:INFO:self.USI: 4103
2023-10-23 23:21:48,694:INFO:self._variable_keys: {'memory', 'X_train', 'fold_generator', 'log_plots_param', 'data', 'logging_param', 'target_param', 'exp_id', 'X_test', 'html_param', 'USI', 'transform_target_param', 'idx', 'pipeline', 'fold_shuffle_param', 'seed', 'y_test', 'y_train', 'n_jobs_param', '_ml_usecase', 'gpu_n_jobs_param', 'exp_name_log', 'fold_groups_param', '_available_plots', 'y', 'X', 'gpu_param'}
2023-10-23 23:21:48,694:INFO:Checking environment
2023-10-23 23:21:48,694:INFO:python_version: 3.8.18
2023-10-23 23:21:48,694:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 23:21:48,694:INFO:machine: AMD64
2023-10-23 23:21:48,694:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 23:21:48,695:INFO:Memory: svmem(total=16505954304, available=5366054912, percent=67.5, used=11139899392, free=5366054912)
2023-10-23 23:21:48,695:INFO:Physical Core: 8
2023-10-23 23:21:48,695:INFO:Logical Core: 16
2023-10-23 23:21:48,695:INFO:Checking libraries
2023-10-23 23:21:48,695:INFO:System:
2023-10-23 23:21:48,695:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 23:21:48,695:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 23:21:48,695:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 23:21:48,695:INFO:PyCaret required dependencies:
2023-10-23 23:21:48,695:INFO:                 pip: 23.3
2023-10-23 23:21:48,695:INFO:          setuptools: 68.0.0
2023-10-23 23:21:48,695:INFO:             pycaret: 3.1.0
2023-10-23 23:21:48,695:INFO:             IPython: 8.12.0
2023-10-23 23:21:48,695:INFO:          ipywidgets: 8.1.1
2023-10-23 23:21:48,695:INFO:                tqdm: 4.66.1
2023-10-23 23:21:48,695:INFO:               numpy: 1.23.5
2023-10-23 23:21:48,695:INFO:              pandas: 1.5.3
2023-10-23 23:21:48,695:INFO:              jinja2: 3.1.2
2023-10-23 23:21:48,695:INFO:               scipy: 1.10.1
2023-10-23 23:21:48,695:INFO:              joblib: 1.3.2
2023-10-23 23:21:48,695:INFO:             sklearn: 1.2.2
2023-10-23 23:21:48,696:INFO:                pyod: 1.1.0
2023-10-23 23:21:48,696:INFO:            imblearn: 0.11.0
2023-10-23 23:21:48,696:INFO:   category_encoders: 2.6.2
2023-10-23 23:21:48,696:INFO:            lightgbm: 4.1.0
2023-10-23 23:21:48,696:INFO:               numba: 0.58.1
2023-10-23 23:21:48,696:INFO:            requests: 2.31.0
2023-10-23 23:21:48,696:INFO:          matplotlib: 3.7.3
2023-10-23 23:21:48,696:INFO:          scikitplot: 0.3.7
2023-10-23 23:21:48,696:INFO:         yellowbrick: 1.5
2023-10-23 23:21:48,696:INFO:              plotly: 5.17.0
2023-10-23 23:21:48,696:INFO:    plotly-resampler: Not installed
2023-10-23 23:21:48,696:INFO:             kaleido: 0.2.1
2023-10-23 23:21:48,696:INFO:           schemdraw: 0.15
2023-10-23 23:21:48,696:INFO:         statsmodels: 0.14.0
2023-10-23 23:21:48,696:INFO:              sktime: 0.21.1
2023-10-23 23:21:48,696:INFO:               tbats: 1.1.3
2023-10-23 23:21:48,696:INFO:            pmdarima: 2.0.3
2023-10-23 23:21:48,696:INFO:              psutil: 5.9.0
2023-10-23 23:21:48,696:INFO:          markupsafe: 2.1.3
2023-10-23 23:21:48,696:INFO:             pickle5: Not installed
2023-10-23 23:21:48,696:INFO:         cloudpickle: 2.2.1
2023-10-23 23:21:48,696:INFO:         deprecation: 2.1.0
2023-10-23 23:21:48,696:INFO:              xxhash: 3.4.1
2023-10-23 23:21:48,696:INFO:           wurlitzer: Not installed
2023-10-23 23:21:48,696:INFO:PyCaret optional dependencies:
2023-10-23 23:21:48,697:INFO:                shap: Not installed
2023-10-23 23:21:48,697:INFO:           interpret: Not installed
2023-10-23 23:21:48,697:INFO:                umap: Not installed
2023-10-23 23:21:48,697:INFO:     ydata_profiling: Not installed
2023-10-23 23:21:48,697:INFO:  explainerdashboard: Not installed
2023-10-23 23:21:48,697:INFO:             autoviz: Not installed
2023-10-23 23:21:48,697:INFO:           fairlearn: Not installed
2023-10-23 23:21:48,697:INFO:          deepchecks: Not installed
2023-10-23 23:21:48,697:INFO:             xgboost: Not installed
2023-10-23 23:21:48,697:INFO:            catboost: 1.2.2
2023-10-23 23:21:48,697:INFO:              kmodes: Not installed
2023-10-23 23:21:48,697:INFO:             mlxtend: Not installed
2023-10-23 23:21:48,697:INFO:       statsforecast: Not installed
2023-10-23 23:21:48,697:INFO:        tune_sklearn: Not installed
2023-10-23 23:21:48,697:INFO:                 ray: Not installed
2023-10-23 23:21:48,697:INFO:            hyperopt: Not installed
2023-10-23 23:21:48,697:INFO:              optuna: Not installed
2023-10-23 23:21:48,697:INFO:               skopt: Not installed
2023-10-23 23:21:48,697:INFO:              mlflow: 2.7.1
2023-10-23 23:21:48,697:INFO:              gradio: Not installed
2023-10-23 23:21:48,697:INFO:             fastapi: Not installed
2023-10-23 23:21:48,697:INFO:             uvicorn: Not installed
2023-10-23 23:21:48,697:INFO:              m2cgen: Not installed
2023-10-23 23:21:48,697:INFO:           evidently: Not installed
2023-10-23 23:21:48,698:INFO:               fugue: Not installed
2023-10-23 23:21:48,698:INFO:           streamlit: Not installed
2023-10-23 23:21:48,698:INFO:             prophet: Not installed
2023-10-23 23:21:48,698:INFO:None
2023-10-23 23:21:48,698:INFO:Set up data.
2023-10-23 23:21:48,722:INFO:Set up folding strategy.
2023-10-23 23:21:48,729:INFO:Set up train/test split.
2023-10-23 23:21:48,747:INFO:Set up index.
2023-10-23 23:21:48,747:INFO:Assigning column types.
2023-10-23 23:21:48,762:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 23:21:48,762:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 23:21:48,778:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:21:48,778:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:21:48,856:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:21:48,904:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:21:48,904:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:21:48,904:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:21:48,904:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 23:21:48,904:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:21:48,904:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:21:48,992:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:21:49,041:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:21:49,041:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:21:49,042:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:21:49,042:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 23:21:49,042:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:21:49,042:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:21:49,118:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:21:49,171:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:21:49,171:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:21:49,171:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:21:49,171:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:21:49,187:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:21:49,252:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:21:49,304:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:21:49,304:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:21:49,304:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:21:49,304:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 23:21:49,322:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:21:49,387:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:21:49,434:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:21:49,434:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:21:49,434:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:21:49,450:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:21:49,530:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:21:49,570:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:21:49,570:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:21:49,570:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:21:49,570:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 23:21:49,667:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:21:49,713:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:21:49,713:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:21:49,713:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:21:49,805:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:21:49,852:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:21:49,852:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:21:49,852:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:21:49,852:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 23:21:49,937:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:21:49,984:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:21:49,984:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:21:50,067:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:21:50,120:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:21:50,120:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:21:50,120:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 23:21:50,254:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:21:50,254:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:21:50,382:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:21:50,382:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:21:50,382:INFO:Preparing preprocessing pipeline...
2023-10-23 23:21:50,382:INFO:Set up date feature engineering.
2023-10-23 23:21:50,382:INFO:Set up simple imputation.
2023-10-23 23:21:50,397:INFO:Set up encoding of ordinal features.
2023-10-23 23:21:50,422:INFO:Set up encoding of categorical features.
2023-10-23 23:21:50,422:INFO:Set up variance threshold.
2023-10-23 23:21:50,422:INFO:Set up column name cleaning.
2023-10-23 23:21:50,728:INFO:Finished creating preprocessing pipeline.
2023-10-23 23:21:50,789:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 23:21:50,789:INFO:Creating final display dataframe.
2023-10-23 23:21:50,918:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (34061, 48)
4        Transformed data shape  (34061, 37)
5   Transformed train set shape  (23842, 37)
6    Transformed test set shape  (10219, 37)
7              Ordinal features            2
8              Numeric features           43
9                 Date features            1
10         Categorical features            3
11     Rows with missing values        97.6%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18       Low variance threshold         0.05
19               Fold Generator        KFold
20                  Fold Number           10
21                     CPU Jobs           -1
22                      Use GPU        False
23               Log Experiment        False
24              Experiment Name        exp_A
25                          USI         4103
2023-10-23 23:21:51,054:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:21:51,054:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:21:51,184:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:21:51,184:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:21:51,184:INFO:setup() successfully completed in 2.5s...............
2023-10-23 23:21:51,184:INFO:Initializing compare_models()
2023-10-23 23:21:51,184:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035D664DF0>, include=['catboost', 'lightgbm'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002035D664DF0>, 'include': ['catboost', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-10-23 23:21:51,184:INFO:Checking exceptions
2023-10-23 23:21:51,200:INFO:Preparing display monitor
2023-10-23 23:21:51,200:INFO:Initializing CatBoost Regressor
2023-10-23 23:21:51,200:INFO:Total runtime is 0.0 minutes
2023-10-23 23:21:51,200:INFO:SubProcess create_model() called ==================================
2023-10-23 23:21:51,200:INFO:Initializing create_model()
2023-10-23 23:21:51,200:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035D664DF0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000203590D4D60>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 23:21:51,200:INFO:Checking exceptions
2023-10-23 23:21:51,200:INFO:Importing libraries
2023-10-23 23:21:51,200:INFO:Copying training dataset
2023-10-23 23:21:51,235:INFO:Defining folds
2023-10-23 23:21:51,235:INFO:Declaring metric variables
2023-10-23 23:21:51,235:INFO:Importing untrained model
2023-10-23 23:21:51,236:INFO:CatBoost Regressor Imported successfully
2023-10-23 23:21:51,236:INFO:Starting cross validation
2023-10-23 23:21:51,238:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 23:22:27,993:INFO:Calculating mean and std
2023-10-23 23:22:27,993:INFO:Creating metrics dataframe
2023-10-23 23:22:27,993:INFO:Uploading results into container
2023-10-23 23:22:27,993:INFO:Uploading model into container now
2023-10-23 23:22:27,993:INFO:_master_model_container: 1
2023-10-23 23:22:27,993:INFO:_display_container: 2
2023-10-23 23:22:27,993:INFO:<catboost.core.CatBoostRegressor object at 0x00000203590CC100>
2023-10-23 23:22:27,993:INFO:create_model() successfully completed......................................
2023-10-23 23:22:28,224:INFO:SubProcess create_model() end ==================================
2023-10-23 23:22:28,224:INFO:Creating metrics dataframe
2023-10-23 23:22:28,224:INFO:Initializing Light Gradient Boosting Machine
2023-10-23 23:22:28,224:INFO:Total runtime is 0.6170758167902629 minutes
2023-10-23 23:22:28,224:INFO:SubProcess create_model() called ==================================
2023-10-23 23:22:28,224:INFO:Initializing create_model()
2023-10-23 23:22:28,224:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035D664DF0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000203590D4D60>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 23:22:28,224:INFO:Checking exceptions
2023-10-23 23:22:28,224:INFO:Importing libraries
2023-10-23 23:22:28,224:INFO:Copying training dataset
2023-10-23 23:22:28,256:INFO:Defining folds
2023-10-23 23:22:28,256:INFO:Declaring metric variables
2023-10-23 23:22:28,256:INFO:Importing untrained model
2023-10-23 23:22:28,256:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 23:22:28,256:INFO:Starting cross validation
2023-10-23 23:22:28,256:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 23:22:37,429:INFO:Calculating mean and std
2023-10-23 23:22:37,429:INFO:Creating metrics dataframe
2023-10-23 23:22:37,429:INFO:Uploading results into container
2023-10-23 23:22:37,429:INFO:Uploading model into container now
2023-10-23 23:22:37,429:INFO:_master_model_container: 2
2023-10-23 23:22:37,429:INFO:_display_container: 2
2023-10-23 23:22:37,429:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:22:37,429:INFO:create_model() successfully completed......................................
2023-10-23 23:22:37,711:INFO:SubProcess create_model() end ==================================
2023-10-23 23:22:37,711:INFO:Creating metrics dataframe
2023-10-23 23:22:37,712:INFO:Initializing create_model()
2023-10-23 23:22:37,712:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035D664DF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 23:22:37,712:INFO:Checking exceptions
2023-10-23 23:22:37,712:INFO:Importing libraries
2023-10-23 23:22:37,712:INFO:Copying training dataset
2023-10-23 23:22:37,750:INFO:Defining folds
2023-10-23 23:22:37,750:INFO:Declaring metric variables
2023-10-23 23:22:37,750:INFO:Importing untrained model
2023-10-23 23:22:37,750:INFO:Declaring custom model
2023-10-23 23:22:37,750:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 23:22:37,750:INFO:Cross validation set to False
2023-10-23 23:22:37,750:INFO:Fitting Model
2023-10-23 23:22:38,072:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005028 seconds.
2023-10-23 23:22:38,072:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 23:22:38,072:INFO:[LightGBM] [Info] Total Bins 6029
2023-10-23 23:22:38,072:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 36
2023-10-23 23:22:38,072:INFO:[LightGBM] [Info] Start training from score 616.864890
2023-10-23 23:22:38,272:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:22:38,272:INFO:create_model() successfully completed......................................
2023-10-23 23:22:38,511:INFO:_master_model_container: 2
2023-10-23 23:22:38,511:INFO:_display_container: 2
2023-10-23 23:22:38,511:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:22:38,511:INFO:compare_models() successfully completed......................................
2023-10-23 23:22:38,511:INFO:Initializing finalize_model()
2023-10-23 23:22:38,511:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035D664DF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-23 23:22:38,511:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:22:38,531:INFO:Initializing create_model()
2023-10-23 23:22:38,531:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035D664DF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-23 23:22:38,531:INFO:Checking exceptions
2023-10-23 23:22:38,532:INFO:Importing libraries
2023-10-23 23:22:38,532:INFO:Copying training dataset
2023-10-23 23:22:38,533:INFO:Defining folds
2023-10-23 23:22:38,533:INFO:Declaring metric variables
2023-10-23 23:22:38,533:INFO:Importing untrained model
2023-10-23 23:22:38,533:INFO:Declaring custom model
2023-10-23 23:22:38,534:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 23:22:38,536:INFO:Cross validation set to False
2023-10-23 23:22:38,536:INFO:Fitting Model
2023-10-23 23:22:38,905:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006578 seconds.
2023-10-23 23:22:38,905:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 23:22:38,905:INFO:[LightGBM] [Info] Total Bins 6436
2023-10-23 23:22:38,905:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 37
2023-10-23 23:22:38,905:INFO:[LightGBM] [Info] Start training from score 631.011165
2023-10-23 23:22:39,204:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-23 23:22:39,220:INFO:create_model() successfully completed......................................
2023-10-23 23:22:39,418:INFO:_master_model_container: 2
2023-10-23 23:22:39,418:INFO:_display_container: 2
2023-10-23 23:22:39,480:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-23 23:22:39,480:INFO:finalize_model() successfully completed......................................
2023-10-23 23:22:39,798:INFO:Initializing save_model()
2023-10-23 23:22:39,798:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_A, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 23:22:39,798:INFO:Adding model into prep_pipe
2023-10-23 23:22:39,798:WARNING:Only Model saved as it was a pipeline.
2023-10-23 23:22:39,814:INFO:final_model_for_location_A.pkl saved in current working directory
2023-10-23 23:22:39,933:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-23 23:22:39,933:INFO:save_model() successfully completed......................................
2023-10-23 23:22:40,169:INFO:PyCaret RegressionExperiment
2023-10-23 23:22:40,169:INFO:Logging name: exp_B
2023-10-23 23:22:40,169:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 23:22:40,169:INFO:version 3.1.0
2023-10-23 23:22:40,169:INFO:Initializing setup()
2023-10-23 23:22:40,169:INFO:self.USI: 63fd
2023-10-23 23:22:40,169:INFO:self._variable_keys: {'memory', 'X_train', 'fold_generator', 'log_plots_param', 'data', 'logging_param', 'target_param', 'exp_id', 'X_test', 'html_param', 'USI', 'transform_target_param', 'idx', 'pipeline', 'fold_shuffle_param', 'seed', 'y_test', 'y_train', 'n_jobs_param', '_ml_usecase', 'gpu_n_jobs_param', 'exp_name_log', 'fold_groups_param', '_available_plots', 'y', 'X', 'gpu_param'}
2023-10-23 23:22:40,169:INFO:Checking environment
2023-10-23 23:22:40,169:INFO:python_version: 3.8.18
2023-10-23 23:22:40,169:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 23:22:40,169:INFO:machine: AMD64
2023-10-23 23:22:40,169:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 23:22:40,169:INFO:Memory: svmem(total=16505954304, available=3286192128, percent=80.1, used=13219762176, free=3286192128)
2023-10-23 23:22:40,169:INFO:Physical Core: 8
2023-10-23 23:22:40,169:INFO:Logical Core: 16
2023-10-23 23:22:40,169:INFO:Checking libraries
2023-10-23 23:22:40,169:INFO:System:
2023-10-23 23:22:40,169:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 23:22:40,169:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 23:22:40,169:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 23:22:40,169:INFO:PyCaret required dependencies:
2023-10-23 23:22:40,169:INFO:                 pip: 23.3
2023-10-23 23:22:40,169:INFO:          setuptools: 68.0.0
2023-10-23 23:22:40,169:INFO:             pycaret: 3.1.0
2023-10-23 23:22:40,169:INFO:             IPython: 8.12.0
2023-10-23 23:22:40,169:INFO:          ipywidgets: 8.1.1
2023-10-23 23:22:40,169:INFO:                tqdm: 4.66.1
2023-10-23 23:22:40,169:INFO:               numpy: 1.23.5
2023-10-23 23:22:40,169:INFO:              pandas: 1.5.3
2023-10-23 23:22:40,169:INFO:              jinja2: 3.1.2
2023-10-23 23:22:40,169:INFO:               scipy: 1.10.1
2023-10-23 23:22:40,169:INFO:              joblib: 1.3.2
2023-10-23 23:22:40,169:INFO:             sklearn: 1.2.2
2023-10-23 23:22:40,169:INFO:                pyod: 1.1.0
2023-10-23 23:22:40,169:INFO:            imblearn: 0.11.0
2023-10-23 23:22:40,169:INFO:   category_encoders: 2.6.2
2023-10-23 23:22:40,169:INFO:            lightgbm: 4.1.0
2023-10-23 23:22:40,169:INFO:               numba: 0.58.1
2023-10-23 23:22:40,169:INFO:            requests: 2.31.0
2023-10-23 23:22:40,169:INFO:          matplotlib: 3.7.3
2023-10-23 23:22:40,169:INFO:          scikitplot: 0.3.7
2023-10-23 23:22:40,169:INFO:         yellowbrick: 1.5
2023-10-23 23:22:40,169:INFO:              plotly: 5.17.0
2023-10-23 23:22:40,169:INFO:    plotly-resampler: Not installed
2023-10-23 23:22:40,169:INFO:             kaleido: 0.2.1
2023-10-23 23:22:40,169:INFO:           schemdraw: 0.15
2023-10-23 23:22:40,169:INFO:         statsmodels: 0.14.0
2023-10-23 23:22:40,169:INFO:              sktime: 0.21.1
2023-10-23 23:22:40,169:INFO:               tbats: 1.1.3
2023-10-23 23:22:40,169:INFO:            pmdarima: 2.0.3
2023-10-23 23:22:40,169:INFO:              psutil: 5.9.0
2023-10-23 23:22:40,169:INFO:          markupsafe: 2.1.3
2023-10-23 23:22:40,169:INFO:             pickle5: Not installed
2023-10-23 23:22:40,169:INFO:         cloudpickle: 2.2.1
2023-10-23 23:22:40,169:INFO:         deprecation: 2.1.0
2023-10-23 23:22:40,169:INFO:              xxhash: 3.4.1
2023-10-23 23:22:40,169:INFO:           wurlitzer: Not installed
2023-10-23 23:22:40,169:INFO:PyCaret optional dependencies:
2023-10-23 23:22:40,169:INFO:                shap: Not installed
2023-10-23 23:22:40,169:INFO:           interpret: Not installed
2023-10-23 23:22:40,169:INFO:                umap: Not installed
2023-10-23 23:22:40,169:INFO:     ydata_profiling: Not installed
2023-10-23 23:22:40,169:INFO:  explainerdashboard: Not installed
2023-10-23 23:22:40,169:INFO:             autoviz: Not installed
2023-10-23 23:22:40,169:INFO:           fairlearn: Not installed
2023-10-23 23:22:40,169:INFO:          deepchecks: Not installed
2023-10-23 23:22:40,169:INFO:             xgboost: Not installed
2023-10-23 23:22:40,169:INFO:            catboost: 1.2.2
2023-10-23 23:22:40,169:INFO:              kmodes: Not installed
2023-10-23 23:22:40,169:INFO:             mlxtend: Not installed
2023-10-23 23:22:40,169:INFO:       statsforecast: Not installed
2023-10-23 23:22:40,169:INFO:        tune_sklearn: Not installed
2023-10-23 23:22:40,169:INFO:                 ray: Not installed
2023-10-23 23:22:40,169:INFO:            hyperopt: Not installed
2023-10-23 23:22:40,169:INFO:              optuna: Not installed
2023-10-23 23:22:40,169:INFO:               skopt: Not installed
2023-10-23 23:22:40,169:INFO:              mlflow: 2.7.1
2023-10-23 23:22:40,169:INFO:              gradio: Not installed
2023-10-23 23:22:40,169:INFO:             fastapi: Not installed
2023-10-23 23:22:40,169:INFO:             uvicorn: Not installed
2023-10-23 23:22:40,169:INFO:              m2cgen: Not installed
2023-10-23 23:22:40,169:INFO:           evidently: Not installed
2023-10-23 23:22:40,175:INFO:               fugue: Not installed
2023-10-23 23:22:40,175:INFO:           streamlit: Not installed
2023-10-23 23:22:40,175:INFO:             prophet: Not installed
2023-10-23 23:22:40,175:INFO:None
2023-10-23 23:22:40,175:INFO:Set up data.
2023-10-23 23:22:40,202:INFO:Set up folding strategy.
2023-10-23 23:22:40,202:INFO:Set up train/test split.
2023-10-23 23:22:40,224:INFO:Set up index.
2023-10-23 23:22:40,226:INFO:Assigning column types.
2023-10-23 23:22:40,243:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 23:22:40,244:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 23:22:40,249:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:22:40,249:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:22:40,328:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:22:40,376:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:22:40,376:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:22:40,376:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:22:40,376:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 23:22:40,381:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:22:40,381:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:22:40,466:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:22:40,513:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:22:40,513:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:22:40,513:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:22:40,513:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 23:22:40,513:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:22:40,513:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:22:40,598:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:22:40,644:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:22:40,644:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:22:40,644:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:22:40,644:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:22:40,660:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:22:40,729:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:22:40,784:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:22:40,784:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:22:40,784:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:22:40,784:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 23:22:40,784:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:22:40,862:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:22:40,914:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:22:40,914:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:22:40,914:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:22:40,930:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:22:41,014:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:22:41,061:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:22:41,061:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:22:41,061:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:22:41,061:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 23:22:41,148:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:22:41,200:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:22:41,200:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:22:41,200:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:22:41,279:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:22:41,333:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:22:41,333:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:22:41,333:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:22:41,333:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 23:22:41,415:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:22:41,461:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:22:41,461:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:22:41,548:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:22:41,611:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:22:41,611:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:22:41,611:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 23:22:41,731:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:22:41,746:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:22:41,878:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:22:41,878:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:22:41,878:INFO:Preparing preprocessing pipeline...
2023-10-23 23:22:41,878:INFO:Set up date feature engineering.
2023-10-23 23:22:41,878:INFO:Set up simple imputation.
2023-10-23 23:22:41,878:INFO:Set up encoding of ordinal features.
2023-10-23 23:22:41,894:INFO:Set up encoding of categorical features.
2023-10-23 23:22:41,894:INFO:Set up variance threshold.
2023-10-23 23:22:41,894:INFO:Set up column name cleaning.
2023-10-23 23:22:42,178:INFO:Finished creating preprocessing pipeline.
2023-10-23 23:22:42,245:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 23:22:42,245:INFO:Creating final display dataframe.
2023-10-23 23:22:42,377:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (32819, 48)
4        Transformed data shape  (32819, 37)
5   Transformed train set shape  (22973, 37)
6    Transformed test set shape   (9846, 37)
7              Ordinal features            2
8              Numeric features           43
9                 Date features            1
10         Categorical features            3
11     Rows with missing values        95.9%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18       Low variance threshold         0.05
19               Fold Generator        KFold
20                  Fold Number           10
21                     CPU Jobs           -1
22                      Use GPU        False
23               Log Experiment        False
24              Experiment Name        exp_B
25                          USI         63fd
2023-10-23 23:22:42,511:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:22:42,511:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:22:42,642:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:22:42,642:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:22:42,642:INFO:setup() successfully completed in 2.49s...............
2023-10-23 23:22:42,642:INFO:Initializing compare_models()
2023-10-23 23:22:42,642:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020362FE1280>, include=['catboost', 'lightgbm'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000020362FE1280>, 'include': ['catboost', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-10-23 23:22:42,642:INFO:Checking exceptions
2023-10-23 23:22:42,660:INFO:Preparing display monitor
2023-10-23 23:22:42,664:INFO:Initializing CatBoost Regressor
2023-10-23 23:22:42,665:INFO:Total runtime is 1.704692840576172e-05 minutes
2023-10-23 23:22:42,665:INFO:SubProcess create_model() called ==================================
2023-10-23 23:22:42,665:INFO:Initializing create_model()
2023-10-23 23:22:42,665:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020362FE1280>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000203594D5550>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 23:22:42,665:INFO:Checking exceptions
2023-10-23 23:22:42,665:INFO:Importing libraries
2023-10-23 23:22:42,665:INFO:Copying training dataset
2023-10-23 23:22:42,690:INFO:Defining folds
2023-10-23 23:22:42,690:INFO:Declaring metric variables
2023-10-23 23:22:42,690:INFO:Importing untrained model
2023-10-23 23:22:42,691:INFO:CatBoost Regressor Imported successfully
2023-10-23 23:22:42,691:INFO:Starting cross validation
2023-10-23 23:22:42,693:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 23:23:13,368:INFO:Calculating mean and std
2023-10-23 23:23:13,368:INFO:Creating metrics dataframe
2023-10-23 23:23:13,368:INFO:Uploading results into container
2023-10-23 23:23:13,368:INFO:Uploading model into container now
2023-10-23 23:23:13,368:INFO:_master_model_container: 1
2023-10-23 23:23:13,368:INFO:_display_container: 2
2023-10-23 23:23:13,368:INFO:<catboost.core.CatBoostRegressor object at 0x00000203591EFC70>
2023-10-23 23:23:13,368:INFO:create_model() successfully completed......................................
2023-10-23 23:23:13,625:INFO:SubProcess create_model() end ==================================
2023-10-23 23:23:13,625:INFO:Creating metrics dataframe
2023-10-23 23:23:13,634:INFO:Initializing Light Gradient Boosting Machine
2023-10-23 23:23:13,634:INFO:Total runtime is 0.51616903146108 minutes
2023-10-23 23:23:13,634:INFO:SubProcess create_model() called ==================================
2023-10-23 23:23:13,634:INFO:Initializing create_model()
2023-10-23 23:23:13,634:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020362FE1280>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000203594D5550>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 23:23:13,634:INFO:Checking exceptions
2023-10-23 23:23:13,634:INFO:Importing libraries
2023-10-23 23:23:13,634:INFO:Copying training dataset
2023-10-23 23:23:13,659:INFO:Defining folds
2023-10-23 23:23:13,659:INFO:Declaring metric variables
2023-10-23 23:23:13,660:INFO:Importing untrained model
2023-10-23 23:23:13,660:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 23:23:13,660:INFO:Starting cross validation
2023-10-23 23:23:13,660:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 23:23:17,270:INFO:Calculating mean and std
2023-10-23 23:23:17,271:INFO:Creating metrics dataframe
2023-10-23 23:23:17,271:INFO:Uploading results into container
2023-10-23 23:23:17,271:INFO:Uploading model into container now
2023-10-23 23:23:17,271:INFO:_master_model_container: 2
2023-10-23 23:23:17,271:INFO:_display_container: 2
2023-10-23 23:23:17,278:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:23:17,279:INFO:create_model() successfully completed......................................
2023-10-23 23:23:17,514:INFO:SubProcess create_model() end ==================================
2023-10-23 23:23:17,514:INFO:Creating metrics dataframe
2023-10-23 23:23:17,529:INFO:Initializing create_model()
2023-10-23 23:23:17,530:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020362FE1280>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 23:23:17,530:INFO:Checking exceptions
2023-10-23 23:23:17,531:INFO:Importing libraries
2023-10-23 23:23:17,531:INFO:Copying training dataset
2023-10-23 23:23:17,548:INFO:Defining folds
2023-10-23 23:23:17,548:INFO:Declaring metric variables
2023-10-23 23:23:17,548:INFO:Importing untrained model
2023-10-23 23:23:17,548:INFO:Declaring custom model
2023-10-23 23:23:17,548:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 23:23:17,548:INFO:Cross validation set to False
2023-10-23 23:23:17,548:INFO:Fitting Model
2023-10-23 23:23:17,830:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005245 seconds.
2023-10-23 23:23:17,830:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 23:23:17,830:INFO:[LightGBM] [Info] Total Bins 6071
2023-10-23 23:23:17,830:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 36
2023-10-23 23:23:17,830:INFO:[LightGBM] [Info] Start training from score 117.072182
2023-10-23 23:23:18,080:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:23:18,080:INFO:create_model() successfully completed......................................
2023-10-23 23:23:18,347:INFO:_master_model_container: 2
2023-10-23 23:23:18,347:INFO:_display_container: 2
2023-10-23 23:23:18,347:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:23:18,347:INFO:compare_models() successfully completed......................................
2023-10-23 23:23:18,347:INFO:Initializing finalize_model()
2023-10-23 23:23:18,347:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020362FE1280>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-23 23:23:18,347:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:23:18,363:INFO:Initializing create_model()
2023-10-23 23:23:18,363:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020362FE1280>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-23 23:23:18,363:INFO:Checking exceptions
2023-10-23 23:23:18,363:INFO:Importing libraries
2023-10-23 23:23:18,363:INFO:Copying training dataset
2023-10-23 23:23:18,363:INFO:Defining folds
2023-10-23 23:23:18,363:INFO:Declaring metric variables
2023-10-23 23:23:18,363:INFO:Importing untrained model
2023-10-23 23:23:18,363:INFO:Declaring custom model
2023-10-23 23:23:18,363:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 23:23:18,377:INFO:Cross validation set to False
2023-10-23 23:23:18,377:INFO:Fitting Model
2023-10-23 23:23:18,779:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007465 seconds.
2023-10-23 23:23:18,779:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 23:23:18,779:INFO:[LightGBM] [Info] Total Bins 6395
2023-10-23 23:23:18,779:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 37
2023-10-23 23:23:18,779:INFO:[LightGBM] [Info] Start training from score 96.893335
2023-10-23 23:23:19,216:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-23 23:23:19,216:INFO:create_model() successfully completed......................................
2023-10-23 23:23:19,435:INFO:_master_model_container: 2
2023-10-23 23:23:19,435:INFO:_display_container: 2
2023-10-23 23:23:19,503:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-23 23:23:19,503:INFO:finalize_model() successfully completed......................................
2023-10-23 23:23:19,832:INFO:Initializing save_model()
2023-10-23 23:23:19,832:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_B, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 23:23:19,832:INFO:Adding model into prep_pipe
2023-10-23 23:23:19,832:WARNING:Only Model saved as it was a pipeline.
2023-10-23 23:23:19,848:INFO:final_model_for_location_B.pkl saved in current working directory
2023-10-23 23:23:19,968:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-23 23:23:19,968:INFO:save_model() successfully completed......................................
2023-10-23 23:23:20,211:INFO:PyCaret RegressionExperiment
2023-10-23 23:23:20,211:INFO:Logging name: exp_C
2023-10-23 23:23:20,211:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 23:23:20,211:INFO:version 3.1.0
2023-10-23 23:23:20,211:INFO:Initializing setup()
2023-10-23 23:23:20,211:INFO:self.USI: 01d7
2023-10-23 23:23:20,211:INFO:self._variable_keys: {'memory', 'X_train', 'fold_generator', 'log_plots_param', 'data', 'logging_param', 'target_param', 'exp_id', 'X_test', 'html_param', 'USI', 'transform_target_param', 'idx', 'pipeline', 'fold_shuffle_param', 'seed', 'y_test', 'y_train', 'n_jobs_param', '_ml_usecase', 'gpu_n_jobs_param', 'exp_name_log', 'fold_groups_param', '_available_plots', 'y', 'X', 'gpu_param'}
2023-10-23 23:23:20,211:INFO:Checking environment
2023-10-23 23:23:20,211:INFO:python_version: 3.8.18
2023-10-23 23:23:20,211:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 23:23:20,211:INFO:machine: AMD64
2023-10-23 23:23:20,211:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 23:23:20,211:INFO:Memory: svmem(total=16505954304, available=3230482432, percent=80.4, used=13275471872, free=3230482432)
2023-10-23 23:23:20,211:INFO:Physical Core: 8
2023-10-23 23:23:20,211:INFO:Logical Core: 16
2023-10-23 23:23:20,211:INFO:Checking libraries
2023-10-23 23:23:20,211:INFO:System:
2023-10-23 23:23:20,212:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 23:23:20,212:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 23:23:20,212:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 23:23:20,212:INFO:PyCaret required dependencies:
2023-10-23 23:23:20,212:INFO:                 pip: 23.3
2023-10-23 23:23:20,212:INFO:          setuptools: 68.0.0
2023-10-23 23:23:20,212:INFO:             pycaret: 3.1.0
2023-10-23 23:23:20,212:INFO:             IPython: 8.12.0
2023-10-23 23:23:20,212:INFO:          ipywidgets: 8.1.1
2023-10-23 23:23:20,212:INFO:                tqdm: 4.66.1
2023-10-23 23:23:20,212:INFO:               numpy: 1.23.5
2023-10-23 23:23:20,212:INFO:              pandas: 1.5.3
2023-10-23 23:23:20,212:INFO:              jinja2: 3.1.2
2023-10-23 23:23:20,212:INFO:               scipy: 1.10.1
2023-10-23 23:23:20,212:INFO:              joblib: 1.3.2
2023-10-23 23:23:20,212:INFO:             sklearn: 1.2.2
2023-10-23 23:23:20,212:INFO:                pyod: 1.1.0
2023-10-23 23:23:20,213:INFO:            imblearn: 0.11.0
2023-10-23 23:23:20,213:INFO:   category_encoders: 2.6.2
2023-10-23 23:23:20,213:INFO:            lightgbm: 4.1.0
2023-10-23 23:23:20,213:INFO:               numba: 0.58.1
2023-10-23 23:23:20,213:INFO:            requests: 2.31.0
2023-10-23 23:23:20,213:INFO:          matplotlib: 3.7.3
2023-10-23 23:23:20,213:INFO:          scikitplot: 0.3.7
2023-10-23 23:23:20,213:INFO:         yellowbrick: 1.5
2023-10-23 23:23:20,213:INFO:              plotly: 5.17.0
2023-10-23 23:23:20,213:INFO:    plotly-resampler: Not installed
2023-10-23 23:23:20,213:INFO:             kaleido: 0.2.1
2023-10-23 23:23:20,214:INFO:           schemdraw: 0.15
2023-10-23 23:23:20,214:INFO:         statsmodels: 0.14.0
2023-10-23 23:23:20,214:INFO:              sktime: 0.21.1
2023-10-23 23:23:20,214:INFO:               tbats: 1.1.3
2023-10-23 23:23:20,214:INFO:            pmdarima: 2.0.3
2023-10-23 23:23:20,214:INFO:              psutil: 5.9.0
2023-10-23 23:23:20,214:INFO:          markupsafe: 2.1.3
2023-10-23 23:23:20,214:INFO:             pickle5: Not installed
2023-10-23 23:23:20,214:INFO:         cloudpickle: 2.2.1
2023-10-23 23:23:20,214:INFO:         deprecation: 2.1.0
2023-10-23 23:23:20,214:INFO:              xxhash: 3.4.1
2023-10-23 23:23:20,214:INFO:           wurlitzer: Not installed
2023-10-23 23:23:20,214:INFO:PyCaret optional dependencies:
2023-10-23 23:23:20,214:INFO:                shap: Not installed
2023-10-23 23:23:20,214:INFO:           interpret: Not installed
2023-10-23 23:23:20,214:INFO:                umap: Not installed
2023-10-23 23:23:20,214:INFO:     ydata_profiling: Not installed
2023-10-23 23:23:20,214:INFO:  explainerdashboard: Not installed
2023-10-23 23:23:20,214:INFO:             autoviz: Not installed
2023-10-23 23:23:20,214:INFO:           fairlearn: Not installed
2023-10-23 23:23:20,215:INFO:          deepchecks: Not installed
2023-10-23 23:23:20,215:INFO:             xgboost: Not installed
2023-10-23 23:23:20,215:INFO:            catboost: 1.2.2
2023-10-23 23:23:20,215:INFO:              kmodes: Not installed
2023-10-23 23:23:20,215:INFO:             mlxtend: Not installed
2023-10-23 23:23:20,215:INFO:       statsforecast: Not installed
2023-10-23 23:23:20,215:INFO:        tune_sklearn: Not installed
2023-10-23 23:23:20,215:INFO:                 ray: Not installed
2023-10-23 23:23:20,215:INFO:            hyperopt: Not installed
2023-10-23 23:23:20,215:INFO:              optuna: Not installed
2023-10-23 23:23:20,215:INFO:               skopt: Not installed
2023-10-23 23:23:20,215:INFO:              mlflow: 2.7.1
2023-10-23 23:23:20,215:INFO:              gradio: Not installed
2023-10-23 23:23:20,215:INFO:             fastapi: Not installed
2023-10-23 23:23:20,215:INFO:             uvicorn: Not installed
2023-10-23 23:23:20,215:INFO:              m2cgen: Not installed
2023-10-23 23:23:20,216:INFO:           evidently: Not installed
2023-10-23 23:23:20,216:INFO:               fugue: Not installed
2023-10-23 23:23:20,216:INFO:           streamlit: Not installed
2023-10-23 23:23:20,216:INFO:             prophet: Not installed
2023-10-23 23:23:20,217:INFO:None
2023-10-23 23:23:20,217:INFO:Set up data.
2023-10-23 23:23:20,244:INFO:Set up folding strategy.
2023-10-23 23:23:20,244:INFO:Set up train/test split.
2023-10-23 23:23:20,259:INFO:Set up index.
2023-10-23 23:23:20,261:INFO:Assigning column types.
2023-10-23 23:23:20,276:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 23:23:20,277:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 23:23:20,277:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:23:20,277:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:23:20,349:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:23:20,396:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:23:20,396:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:23:20,396:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:23:20,412:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 23:23:20,414:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:23:20,414:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:23:20,480:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:23:20,535:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:23:20,535:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:23:20,535:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:23:20,535:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 23:23:20,550:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:23:20,550:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:23:20,629:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:23:20,667:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:23:20,667:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:23:20,667:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:23:20,682:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 23:23:20,682:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:23:20,750:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:23:20,797:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:23:20,813:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:23:20,813:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:23:20,814:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 23:23:20,814:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:23:20,898:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:23:20,948:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:23:20,949:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:23:20,949:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:23:20,951:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 23:23:21,030:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:23:21,076:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:23:21,076:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:23:21,076:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:23:21,076:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 23:23:21,166:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:23:21,215:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:23:21,215:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:23:21,215:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:23:21,292:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:23:21,339:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 23:23:21,339:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:23:21,339:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:23:21,339:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 23:23:21,446:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:23:21,498:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:23:21,498:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:23:21,587:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 23:23:21,632:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:23:21,632:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:23:21,632:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 23:23:21,776:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:23:21,777:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:23:21,901:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:23:21,901:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:23:21,901:INFO:Preparing preprocessing pipeline...
2023-10-23 23:23:21,901:INFO:Set up date feature engineering.
2023-10-23 23:23:21,901:INFO:Set up simple imputation.
2023-10-23 23:23:21,916:INFO:Set up encoding of ordinal features.
2023-10-23 23:23:21,930:INFO:Set up encoding of categorical features.
2023-10-23 23:23:21,931:INFO:Set up variance threshold.
2023-10-23 23:23:21,933:INFO:Set up column name cleaning.
2023-10-23 23:23:22,177:INFO:Finished creating preprocessing pipeline.
2023-10-23 23:23:22,230:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 23:23:22,230:INFO:Creating final display dataframe.
2023-10-23 23:23:22,549:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (26071, 48)
4        Transformed data shape  (26071, 41)
5   Transformed train set shape  (18249, 41)
6    Transformed test set shape   (7822, 41)
7              Ordinal features            2
8              Numeric features           43
9                 Date features            1
10         Categorical features            3
11     Rows with missing values        95.9%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18       Low variance threshold         0.05
19               Fold Generator        KFold
20                  Fold Number           10
21                     CPU Jobs           -1
22                      Use GPU        False
23               Log Experiment        False
24              Experiment Name        exp_C
25                          USI         01d7
2023-10-23 23:23:22,680:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:23:22,680:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:23:22,817:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 23:23:22,817:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 23:23:22,817:INFO:setup() successfully completed in 2.61s...............
2023-10-23 23:23:22,817:INFO:Initializing compare_models()
2023-10-23 23:23:22,817:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035F0ADFA0>, include=['catboost', 'lightgbm'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002035F0ADFA0>, 'include': ['catboost', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-10-23 23:23:22,817:INFO:Checking exceptions
2023-10-23 23:23:22,828:INFO:Preparing display monitor
2023-10-23 23:23:22,828:INFO:Initializing CatBoost Regressor
2023-10-23 23:23:22,828:INFO:Total runtime is 0.0 minutes
2023-10-23 23:23:22,828:INFO:SubProcess create_model() called ==================================
2023-10-23 23:23:22,828:INFO:Initializing create_model()
2023-10-23 23:23:22,828:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035F0ADFA0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000203592FE820>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 23:23:22,828:INFO:Checking exceptions
2023-10-23 23:23:22,828:INFO:Importing libraries
2023-10-23 23:23:22,828:INFO:Copying training dataset
2023-10-23 23:23:22,859:INFO:Defining folds
2023-10-23 23:23:22,859:INFO:Declaring metric variables
2023-10-23 23:23:22,859:INFO:Importing untrained model
2023-10-23 23:23:22,860:INFO:CatBoost Regressor Imported successfully
2023-10-23 23:23:22,860:INFO:Starting cross validation
2023-10-23 23:23:22,862:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 23:23:54,671:INFO:Calculating mean and std
2023-10-23 23:23:54,671:INFO:Creating metrics dataframe
2023-10-23 23:23:54,671:INFO:Uploading results into container
2023-10-23 23:23:54,671:INFO:Uploading model into container now
2023-10-23 23:23:54,671:INFO:_master_model_container: 1
2023-10-23 23:23:54,671:INFO:_display_container: 2
2023-10-23 23:23:54,671:INFO:<catboost.core.CatBoostRegressor object at 0x0000020359708550>
2023-10-23 23:23:54,671:INFO:create_model() successfully completed......................................
2023-10-23 23:23:54,887:INFO:SubProcess create_model() end ==================================
2023-10-23 23:23:54,887:INFO:Creating metrics dataframe
2023-10-23 23:23:54,887:INFO:Initializing Light Gradient Boosting Machine
2023-10-23 23:23:54,887:INFO:Total runtime is 0.5343184868494669 minutes
2023-10-23 23:23:54,887:INFO:SubProcess create_model() called ==================================
2023-10-23 23:23:54,887:INFO:Initializing create_model()
2023-10-23 23:23:54,887:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035F0ADFA0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000203592FE820>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 23:23:54,887:INFO:Checking exceptions
2023-10-23 23:23:54,887:INFO:Importing libraries
2023-10-23 23:23:54,887:INFO:Copying training dataset
2023-10-23 23:23:54,918:INFO:Defining folds
2023-10-23 23:23:54,918:INFO:Declaring metric variables
2023-10-23 23:23:54,918:INFO:Importing untrained model
2023-10-23 23:23:54,918:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 23:23:54,918:INFO:Starting cross validation
2023-10-23 23:23:54,918:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 23:23:57,928:INFO:Calculating mean and std
2023-10-23 23:23:57,929:INFO:Creating metrics dataframe
2023-10-23 23:23:57,933:INFO:Uploading results into container
2023-10-23 23:23:57,934:INFO:Uploading model into container now
2023-10-23 23:23:57,935:INFO:_master_model_container: 2
2023-10-23 23:23:57,935:INFO:_display_container: 2
2023-10-23 23:23:57,936:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:23:57,936:INFO:create_model() successfully completed......................................
2023-10-23 23:23:58,153:INFO:SubProcess create_model() end ==================================
2023-10-23 23:23:58,153:INFO:Creating metrics dataframe
2023-10-23 23:23:58,163:INFO:Initializing create_model()
2023-10-23 23:23:58,163:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035F0ADFA0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 23:23:58,163:INFO:Checking exceptions
2023-10-23 23:23:58,163:INFO:Importing libraries
2023-10-23 23:23:58,163:INFO:Copying training dataset
2023-10-23 23:23:58,185:INFO:Defining folds
2023-10-23 23:23:58,185:INFO:Declaring metric variables
2023-10-23 23:23:58,185:INFO:Importing untrained model
2023-10-23 23:23:58,186:INFO:Declaring custom model
2023-10-23 23:23:58,186:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 23:23:58,188:INFO:Cross validation set to False
2023-10-23 23:23:58,188:INFO:Fitting Model
2023-10-23 23:23:58,412:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004080 seconds.
2023-10-23 23:23:58,412:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 23:23:58,412:INFO:[LightGBM] [Info] Total Bins 6250
2023-10-23 23:23:58,412:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 40
2023-10-23 23:23:58,412:INFO:[LightGBM] [Info] Start training from score 96.094131
2023-10-23 23:23:58,612:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:23:58,612:INFO:create_model() successfully completed......................................
2023-10-23 23:23:58,862:INFO:_master_model_container: 2
2023-10-23 23:23:58,862:INFO:_display_container: 2
2023-10-23 23:23:58,862:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:23:58,862:INFO:compare_models() successfully completed......................................
2023-10-23 23:23:58,862:INFO:Initializing finalize_model()
2023-10-23 23:23:58,862:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035F0ADFA0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-23 23:23:58,862:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 23:23:58,880:INFO:Initializing create_model()
2023-10-23 23:23:58,880:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035F0ADFA0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-23 23:23:58,880:INFO:Checking exceptions
2023-10-23 23:23:58,881:INFO:Importing libraries
2023-10-23 23:23:58,881:INFO:Copying training dataset
2023-10-23 23:23:58,882:INFO:Defining folds
2023-10-23 23:23:58,882:INFO:Declaring metric variables
2023-10-23 23:23:58,882:INFO:Importing untrained model
2023-10-23 23:23:58,883:INFO:Declaring custom model
2023-10-23 23:23:58,883:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 23:23:58,885:INFO:Cross validation set to False
2023-10-23 23:23:58,886:INFO:Fitting Model
2023-10-23 23:23:59,205:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007651 seconds.
2023-10-23 23:23:59,205:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 23:23:59,205:INFO:[LightGBM] [Info] Total Bins 6628
2023-10-23 23:23:59,205:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 41
2023-10-23 23:23:59,205:INFO:[LightGBM] [Info] Start training from score 77.700043
2023-10-23 23:23:59,553:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-23 23:23:59,553:INFO:create_model() successfully completed......................................
2023-10-23 23:23:59,767:INFO:_master_model_container: 2
2023-10-23 23:23:59,767:INFO:_display_container: 2
2023-10-23 23:23:59,834:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-23 23:23:59,834:INFO:finalize_model() successfully completed......................................
2023-10-23 23:24:00,182:INFO:Initializing save_model()
2023-10-23 23:24:00,182:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_C, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 23:24:00,182:INFO:Adding model into prep_pipe
2023-10-23 23:24:00,182:WARNING:Only Model saved as it was a pipeline.
2023-10-23 23:24:00,197:INFO:final_model_for_location_C.pkl saved in current working directory
2023-10-23 23:24:00,301:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-23 23:24:00,301:INFO:save_model() successfully completed......................................
2023-10-23 23:24:00,611:INFO:Initializing load_model()
2023-10-23 23:24:00,611:INFO:load_model(model_name=final_model_for_location_A, platform=None, authentication=None, verbose=True)
2023-10-23 23:24:00,635:INFO:Initializing load_model()
2023-10-23 23:24:00,635:INFO:load_model(model_name=final_model_for_location_B, platform=None, authentication=None, verbose=True)
2023-10-23 23:24:00,658:INFO:Initializing load_model()
2023-10-23 23:24:00,658:INFO:load_model(model_name=final_model_for_location_C, platform=None, authentication=None, verbose=True)
2023-10-23 23:24:00,805:INFO:Initializing predict_model()
2023-10-23 23:24:00,805:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002035F0ADFA0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020364F61CA0>)
2023-10-23 23:24:00,805:INFO:Checking exceptions
2023-10-23 23:24:00,805:INFO:Preloading libraries
2023-10-23 23:27:13,842:INFO:Initializing load_model()
2023-10-23 23:27:13,842:INFO:load_model(model_name=final_model_for_location_A, platform=None, authentication=None, verbose=True)
2023-10-23 23:27:13,851:INFO:Initializing load_model()
2023-10-23 23:27:13,851:INFO:load_model(model_name=final_model_for_location_B, platform=None, authentication=None, verbose=True)
2023-10-23 23:27:13,875:INFO:Initializing load_model()
2023-10-23 23:27:13,876:INFO:load_model(model_name=final_model_for_location_C, platform=None, authentication=None, verbose=True)
2023-10-23 23:28:52,245:INFO:Initializing load_model()
2023-10-23 23:28:52,245:INFO:load_model(model_name=final_model_for_location_A, platform=None, authentication=None, verbose=True)
2023-10-23 23:28:52,261:INFO:Initializing load_model()
2023-10-23 23:28:52,261:INFO:load_model(model_name=final_model_for_location_B, platform=None, authentication=None, verbose=True)
2023-10-23 23:28:52,276:INFO:Initializing load_model()
2023-10-23 23:28:52,276:INFO:load_model(model_name=final_model_for_location_C, platform=None, authentication=None, verbose=True)
2023-10-23 23:29:25,008:INFO:Initializing load_model()
2023-10-23 23:29:25,008:INFO:load_model(model_name=final_model_for_location_A, platform=None, authentication=None, verbose=True)
2023-10-23 23:29:25,019:INFO:Initializing load_model()
2023-10-23 23:29:25,021:INFO:load_model(model_name=final_model_for_location_B, platform=None, authentication=None, verbose=True)
2023-10-23 23:29:25,026:INFO:Initializing load_model()
2023-10-23 23:29:25,026:INFO:load_model(model_name=final_model_for_location_C, platform=None, authentication=None, verbose=True)
2023-10-23 23:34:11,064:INFO:PyCaret RegressionExperiment
2023-10-23 23:34:11,064:INFO:Logging name: exp_A
2023-10-23 23:34:11,065:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 23:34:11,066:INFO:version 3.1.0
2023-10-23 23:34:11,066:INFO:Initializing setup()
2023-10-23 23:34:11,067:INFO:self.USI: f5a8
2023-10-23 23:34:11,068:INFO:self._variable_keys: {'fold_generator', 'X_train', 'log_plots_param', 'data', 'target_param', 'X_test', 'html_param', 'transform_target_param', 'pipeline', 'fold_groups_param', 'X', 'gpu_param', 'memory', 'logging_param', 'exp_id', 'USI', 'idx', 'fold_shuffle_param', 'seed', 'y_test', 'y_train', 'n_jobs_param', '_ml_usecase', 'gpu_n_jobs_param', 'exp_name_log', '_available_plots', 'y'}
2023-10-23 23:34:11,068:INFO:Checking environment
2023-10-23 23:34:11,069:INFO:python_version: 3.8.18
2023-10-23 23:34:11,069:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 23:34:11,069:INFO:machine: AMD64
2023-10-23 23:34:11,069:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 23:34:11,070:INFO:Memory: svmem(total=16505954304, available=5390381056, percent=67.3, used=11115573248, free=5390381056)
2023-10-23 23:34:11,070:INFO:Physical Core: 8
2023-10-23 23:34:11,070:INFO:Logical Core: 16
2023-10-23 23:34:11,070:INFO:Checking libraries
2023-10-23 23:34:11,070:INFO:System:
2023-10-23 23:34:11,072:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 23:34:11,072:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 23:34:11,072:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 23:34:11,072:INFO:PyCaret required dependencies:
2023-10-23 23:34:11,072:INFO:                 pip: 23.3
2023-10-23 23:34:11,072:INFO:          setuptools: 68.0.0
2023-10-23 23:34:11,073:INFO:             pycaret: 3.1.0
2023-10-23 23:34:11,073:INFO:             IPython: 8.12.0
2023-10-23 23:34:11,073:INFO:          ipywidgets: 8.1.1
2023-10-23 23:34:11,073:INFO:                tqdm: 4.66.1
2023-10-23 23:34:11,073:INFO:               numpy: 1.23.5
2023-10-23 23:34:11,073:INFO:              pandas: 1.5.3
2023-10-23 23:34:11,074:INFO:              jinja2: 3.1.2
2023-10-23 23:34:11,074:INFO:               scipy: 1.10.1
2023-10-23 23:34:11,074:INFO:              joblib: 1.3.2
2023-10-23 23:34:11,074:INFO:             sklearn: 1.2.2
2023-10-23 23:34:11,074:INFO:                pyod: 1.1.0
2023-10-23 23:34:11,074:INFO:            imblearn: 0.11.0
2023-10-23 23:34:11,075:INFO:   category_encoders: 2.6.2
2023-10-23 23:34:11,075:INFO:            lightgbm: 4.1.0
2023-10-23 23:34:11,075:INFO:               numba: 0.58.1
2023-10-23 23:34:11,075:INFO:            requests: 2.31.0
2023-10-23 23:34:11,075:INFO:          matplotlib: 3.7.3
2023-10-23 23:34:11,075:INFO:          scikitplot: 0.3.7
2023-10-23 23:34:11,076:INFO:         yellowbrick: 1.5
2023-10-23 23:34:11,076:INFO:              plotly: 5.17.0
2023-10-23 23:34:11,076:INFO:    plotly-resampler: Not installed
2023-10-23 23:34:11,076:INFO:             kaleido: 0.2.1
2023-10-23 23:34:11,076:INFO:           schemdraw: 0.15
2023-10-23 23:34:11,076:INFO:         statsmodels: 0.14.0
2023-10-23 23:34:11,076:INFO:              sktime: 0.21.1
2023-10-23 23:34:11,078:INFO:               tbats: 1.1.3
2023-10-23 23:34:11,078:INFO:            pmdarima: 2.0.3
2023-10-23 23:34:11,078:INFO:              psutil: 5.9.0
2023-10-23 23:34:11,079:INFO:          markupsafe: 2.1.3
2023-10-23 23:34:11,079:INFO:             pickle5: Not installed
2023-10-23 23:34:11,080:INFO:         cloudpickle: 2.2.1
2023-10-23 23:34:11,080:INFO:         deprecation: 2.1.0
2023-10-23 23:34:11,080:INFO:              xxhash: 3.4.1
2023-10-23 23:34:11,080:INFO:           wurlitzer: Not installed
2023-10-23 23:34:11,080:INFO:PyCaret optional dependencies:
2023-10-23 23:34:11,081:INFO:                shap: Not installed
2023-10-23 23:34:11,081:INFO:           interpret: Not installed
2023-10-23 23:34:11,081:INFO:                umap: Not installed
2023-10-23 23:34:11,081:INFO:     ydata_profiling: Not installed
2023-10-23 23:34:11,081:INFO:  explainerdashboard: Not installed
2023-10-23 23:34:11,081:INFO:             autoviz: Not installed
2023-10-23 23:34:11,081:INFO:           fairlearn: Not installed
2023-10-23 23:34:11,082:INFO:          deepchecks: Not installed
2023-10-23 23:34:11,082:INFO:             xgboost: Not installed
2023-10-23 23:34:11,082:INFO:            catboost: 1.2.2
2023-10-23 23:34:11,082:INFO:              kmodes: Not installed
2023-10-23 23:34:11,082:INFO:             mlxtend: Not installed
2023-10-23 23:34:11,082:INFO:       statsforecast: Not installed
2023-10-23 23:34:11,082:INFO:        tune_sklearn: Not installed
2023-10-23 23:34:11,082:INFO:                 ray: Not installed
2023-10-23 23:34:11,082:INFO:            hyperopt: Not installed
2023-10-23 23:34:11,082:INFO:              optuna: Not installed
2023-10-23 23:34:11,082:INFO:               skopt: Not installed
2023-10-23 23:34:11,082:INFO:              mlflow: 2.7.1
2023-10-23 23:34:11,082:INFO:              gradio: Not installed
2023-10-23 23:34:11,082:INFO:             fastapi: Not installed
2023-10-23 23:34:11,082:INFO:             uvicorn: Not installed
2023-10-23 23:34:11,082:INFO:              m2cgen: Not installed
2023-10-23 23:34:11,083:INFO:           evidently: Not installed
2023-10-23 23:34:11,083:INFO:               fugue: Not installed
2023-10-23 23:34:11,083:INFO:           streamlit: Not installed
2023-10-23 23:34:11,083:INFO:             prophet: Not installed
2023-10-23 23:34:11,083:INFO:None
2023-10-23 23:34:11,083:INFO:Set up data.
2023-10-24 09:29:31,510:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-24 09:29:31,510:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-24 09:29:31,510:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-24 09:29:31,510:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-24 09:29:31,793:INFO:PyCaret RegressionExperiment
2023-10-24 09:29:31,793:INFO:Logging name: exp_A
2023-10-24 09:29:31,793:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 09:29:31,793:INFO:version 3.1.0
2023-10-24 09:29:31,793:INFO:Initializing setup()
2023-10-24 09:29:31,793:INFO:self.USI: adaa
2023-10-24 09:29:31,793:INFO:self._variable_keys: {'seed', 'logging_param', 'html_param', 'USI', 'data', 'y_train', 'pipeline', '_ml_usecase', 'gpu_n_jobs_param', 'X_test', 'X_train', 'memory', 'X', 'y_test', 'fold_shuffle_param', 'n_jobs_param', 'exp_name_log', 'y', '_available_plots', 'target_param', 'exp_id', 'idx', 'transform_target_param', 'log_plots_param', 'fold_groups_param', 'gpu_param', 'fold_generator'}
2023-10-24 09:29:31,793:INFO:Checking environment
2023-10-24 09:29:31,793:INFO:python_version: 3.8.18
2023-10-24 09:29:31,793:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-24 09:29:31,793:INFO:machine: AMD64
2023-10-24 09:29:31,793:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-24 09:29:31,793:INFO:Memory: svmem(total=16505954304, available=6854299648, percent=58.5, used=9651654656, free=6854299648)
2023-10-24 09:29:31,793:INFO:Physical Core: 8
2023-10-24 09:29:31,793:INFO:Logical Core: 16
2023-10-24 09:29:31,793:INFO:Checking libraries
2023-10-24 09:29:31,793:INFO:System:
2023-10-24 09:29:31,793:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-24 09:29:31,793:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-24 09:29:31,793:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-24 09:29:31,793:INFO:PyCaret required dependencies:
2023-10-24 09:29:31,887:INFO:                 pip: 23.3
2023-10-24 09:29:31,887:INFO:          setuptools: 68.0.0
2023-10-24 09:29:31,887:INFO:             pycaret: 3.1.0
2023-10-24 09:29:31,887:INFO:             IPython: 8.12.0
2023-10-24 09:29:31,887:INFO:          ipywidgets: 8.1.1
2023-10-24 09:29:31,887:INFO:                tqdm: 4.66.1
2023-10-24 09:29:31,887:INFO:               numpy: 1.23.5
2023-10-24 09:29:31,887:INFO:              pandas: 1.5.3
2023-10-24 09:29:31,887:INFO:              jinja2: 3.1.2
2023-10-24 09:29:31,887:INFO:               scipy: 1.10.1
2023-10-24 09:29:31,887:INFO:              joblib: 1.3.2
2023-10-24 09:29:31,887:INFO:             sklearn: 1.2.2
2023-10-24 09:29:31,887:INFO:                pyod: 1.1.0
2023-10-24 09:29:31,887:INFO:            imblearn: 0.11.0
2023-10-24 09:29:31,887:INFO:   category_encoders: 2.6.2
2023-10-24 09:29:31,887:INFO:            lightgbm: 4.1.0
2023-10-24 09:29:31,887:INFO:               numba: 0.58.1
2023-10-24 09:29:31,887:INFO:            requests: 2.31.0
2023-10-24 09:29:31,887:INFO:          matplotlib: 3.7.3
2023-10-24 09:29:31,887:INFO:          scikitplot: 0.3.7
2023-10-24 09:29:31,887:INFO:         yellowbrick: 1.5
2023-10-24 09:29:31,887:INFO:              plotly: 5.17.0
2023-10-24 09:29:31,887:INFO:    plotly-resampler: Not installed
2023-10-24 09:29:31,887:INFO:             kaleido: 0.2.1
2023-10-24 09:29:31,887:INFO:           schemdraw: 0.15
2023-10-24 09:29:31,887:INFO:         statsmodels: 0.14.0
2023-10-24 09:29:31,887:INFO:              sktime: 0.21.1
2023-10-24 09:29:31,887:INFO:               tbats: 1.1.3
2023-10-24 09:29:31,887:INFO:            pmdarima: 2.0.3
2023-10-24 09:29:31,887:INFO:              psutil: 5.9.0
2023-10-24 09:29:31,887:INFO:          markupsafe: 2.1.3
2023-10-24 09:29:31,887:INFO:             pickle5: Not installed
2023-10-24 09:29:31,887:INFO:         cloudpickle: 2.2.1
2023-10-24 09:29:31,887:INFO:         deprecation: 2.1.0
2023-10-24 09:29:31,887:INFO:              xxhash: 3.4.1
2023-10-24 09:29:31,887:INFO:           wurlitzer: Not installed
2023-10-24 09:29:31,887:INFO:PyCaret optional dependencies:
2023-10-24 09:29:31,902:INFO:                shap: Not installed
2023-10-24 09:29:31,902:INFO:           interpret: Not installed
2023-10-24 09:29:31,902:INFO:                umap: Not installed
2023-10-24 09:29:31,902:INFO:     ydata_profiling: Not installed
2023-10-24 09:29:31,902:INFO:  explainerdashboard: Not installed
2023-10-24 09:29:31,902:INFO:             autoviz: Not installed
2023-10-24 09:29:31,902:INFO:           fairlearn: Not installed
2023-10-24 09:29:31,902:INFO:          deepchecks: Not installed
2023-10-24 09:29:31,902:INFO:             xgboost: Not installed
2023-10-24 09:29:31,902:INFO:            catboost: 1.2.2
2023-10-24 09:29:31,902:INFO:              kmodes: Not installed
2023-10-24 09:29:31,902:INFO:             mlxtend: Not installed
2023-10-24 09:29:31,902:INFO:       statsforecast: Not installed
2023-10-24 09:29:31,902:INFO:        tune_sklearn: Not installed
2023-10-24 09:29:31,902:INFO:                 ray: Not installed
2023-10-24 09:29:31,902:INFO:            hyperopt: Not installed
2023-10-24 09:29:31,902:INFO:              optuna: Not installed
2023-10-24 09:29:31,902:INFO:               skopt: Not installed
2023-10-24 09:29:31,902:INFO:              mlflow: 2.7.1
2023-10-24 09:29:31,902:INFO:              gradio: Not installed
2023-10-24 09:29:31,902:INFO:             fastapi: Not installed
2023-10-24 09:29:31,902:INFO:             uvicorn: Not installed
2023-10-24 09:29:31,902:INFO:              m2cgen: Not installed
2023-10-24 09:29:31,902:INFO:           evidently: Not installed
2023-10-24 09:29:31,902:INFO:               fugue: Not installed
2023-10-24 09:29:31,902:INFO:           streamlit: Not installed
2023-10-24 09:29:31,902:INFO:             prophet: Not installed
2023-10-24 09:29:31,902:INFO:None
2023-10-24 09:29:31,902:INFO:Set up data.
2023-10-24 09:29:31,950:INFO:Set up folding strategy.
2023-10-24 09:29:31,950:INFO:Set up train/test split.
2023-10-24 09:29:31,965:INFO:Set up index.
2023-10-24 09:29:31,965:INFO:Assigning column types.
2023-10-24 09:29:31,997:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 09:29:31,997:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 09:29:31,997:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 09:29:31,997:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 09:29:32,094:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 09:29:32,139:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 09:29:32,139:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:29:32,139:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:29:32,139:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 09:29:32,154:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 09:29:32,154:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 09:29:32,239:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 09:29:32,295:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 09:29:32,295:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:29:32,295:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:29:32,295:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 09:29:32,295:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 09:29:32,295:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 09:29:32,389:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 09:29:32,440:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 09:29:32,440:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:29:32,440:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:29:32,440:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 09:29:32,452:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 09:29:32,530:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 09:29:32,577:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 09:29:32,577:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:29:32,577:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:29:32,577:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 09:29:32,593:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 09:29:32,671:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 09:29:32,734:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 09:29:32,735:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:29:32,736:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:29:32,740:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 09:29:32,816:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 09:29:32,883:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 09:29:32,883:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:29:32,884:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:29:32,884:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 09:29:32,967:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 09:29:33,029:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 09:29:33,029:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:29:33,029:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:29:33,124:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 09:29:33,171:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 09:29:33,171:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:29:33,171:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:29:33,171:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 09:29:33,274:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 09:29:33,323:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:29:33,323:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:29:33,424:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 09:29:33,483:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:29:33,483:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:29:33,484:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 09:29:33,624:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:29:33,624:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:29:33,774:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:29:33,774:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:29:33,774:INFO:Preparing preprocessing pipeline...
2023-10-24 09:29:33,774:INFO:Set up date feature engineering.
2023-10-24 09:29:33,774:INFO:Set up simple imputation.
2023-10-24 09:29:33,793:INFO:Set up encoding of ordinal features.
2023-10-24 09:29:33,809:INFO:Set up encoding of categorical features.
2023-10-24 09:29:33,810:INFO:Set up variance threshold.
2023-10-24 09:29:33,814:INFO:Set up column name cleaning.
2023-10-24 09:29:34,175:INFO:Finished creating preprocessing pipeline.
2023-10-24 09:29:34,250:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 09:29:34,250:INFO:Creating final display dataframe.
2023-10-24 09:29:34,440:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (34061, 48)
4        Transformed data shape  (34061, 37)
5   Transformed train set shape  (23842, 37)
6    Transformed test set shape  (10219, 37)
7              Ordinal features            2
8              Numeric features           43
9                 Date features            1
10         Categorical features            3
11     Rows with missing values        97.6%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18       Low variance threshold         0.05
19               Fold Generator        KFold
20                  Fold Number           10
21                     CPU Jobs           -1
22                      Use GPU        False
23               Log Experiment        False
24              Experiment Name        exp_A
25                          USI         adaa
2023-10-24 09:29:34,589:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:29:34,589:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:29:34,742:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:29:34,742:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:29:34,749:INFO:setup() successfully completed in 2.99s...............
2023-10-24 09:29:34,749:INFO:Initializing compare_models()
2023-10-24 09:29:34,749:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166BE6269D0>, include=['catboost', 'lightgbm'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000166BE6269D0>, 'include': ['catboost', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-10-24 09:29:34,749:INFO:Checking exceptions
2023-10-24 09:29:34,758:INFO:Preparing display monitor
2023-10-24 09:29:34,768:INFO:Initializing CatBoost Regressor
2023-10-24 09:29:34,768:INFO:Total runtime is 0.0 minutes
2023-10-24 09:29:34,769:INFO:SubProcess create_model() called ==================================
2023-10-24 09:29:34,770:INFO:Initializing create_model()
2023-10-24 09:29:34,770:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166BE6269D0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166CCA4AD60>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 09:29:34,770:INFO:Checking exceptions
2023-10-24 09:29:34,770:INFO:Importing libraries
2023-10-24 09:29:34,770:INFO:Copying training dataset
2023-10-24 09:29:34,792:INFO:Defining folds
2023-10-24 09:29:34,792:INFO:Declaring metric variables
2023-10-24 09:29:34,792:INFO:Importing untrained model
2023-10-24 09:29:34,800:INFO:CatBoost Regressor Imported successfully
2023-10-24 09:29:34,801:INFO:Starting cross validation
2023-10-24 09:29:34,806:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 09:30:09,071:INFO:Calculating mean and std
2023-10-24 09:30:09,071:INFO:Creating metrics dataframe
2023-10-24 09:30:09,075:INFO:Uploading results into container
2023-10-24 09:30:09,075:INFO:Uploading model into container now
2023-10-24 09:30:09,075:INFO:_master_model_container: 1
2023-10-24 09:30:09,075:INFO:_display_container: 2
2023-10-24 09:30:09,075:INFO:<catboost.core.CatBoostRegressor object at 0x00000166CC613D30>
2023-10-24 09:30:09,075:INFO:create_model() successfully completed......................................
2023-10-24 09:30:09,188:INFO:SubProcess create_model() end ==================================
2023-10-24 09:30:09,188:INFO:Creating metrics dataframe
2023-10-24 09:30:09,188:INFO:Initializing Light Gradient Boosting Machine
2023-10-24 09:30:09,188:INFO:Total runtime is 0.5736666997273763 minutes
2023-10-24 09:30:09,188:INFO:SubProcess create_model() called ==================================
2023-10-24 09:30:09,188:INFO:Initializing create_model()
2023-10-24 09:30:09,188:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166BE6269D0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166CCA4AD60>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 09:30:09,188:INFO:Checking exceptions
2023-10-24 09:30:09,203:INFO:Importing libraries
2023-10-24 09:30:09,203:INFO:Copying training dataset
2023-10-24 09:30:09,221:INFO:Defining folds
2023-10-24 09:30:09,221:INFO:Declaring metric variables
2023-10-24 09:30:09,221:INFO:Importing untrained model
2023-10-24 09:30:09,221:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 09:30:09,221:INFO:Starting cross validation
2023-10-24 09:30:09,221:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 09:30:16,115:INFO:Calculating mean and std
2023-10-24 09:30:16,115:INFO:Creating metrics dataframe
2023-10-24 09:30:16,115:INFO:Uploading results into container
2023-10-24 09:30:16,115:INFO:Uploading model into container now
2023-10-24 09:30:16,115:INFO:_master_model_container: 2
2023-10-24 09:30:16,115:INFO:_display_container: 2
2023-10-24 09:30:16,115:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 09:30:16,115:INFO:create_model() successfully completed......................................
2023-10-24 09:30:16,231:INFO:SubProcess create_model() end ==================================
2023-10-24 09:30:16,231:INFO:Creating metrics dataframe
2023-10-24 09:30:16,248:INFO:Initializing create_model()
2023-10-24 09:30:16,248:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166BE6269D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 09:30:16,248:INFO:Checking exceptions
2023-10-24 09:30:16,249:INFO:Importing libraries
2023-10-24 09:30:16,250:INFO:Copying training dataset
2023-10-24 09:30:16,269:INFO:Defining folds
2023-10-24 09:30:16,269:INFO:Declaring metric variables
2023-10-24 09:30:16,269:INFO:Importing untrained model
2023-10-24 09:30:16,269:INFO:Declaring custom model
2023-10-24 09:30:16,269:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 09:30:16,269:INFO:Cross validation set to False
2023-10-24 09:30:16,269:INFO:Fitting Model
2023-10-24 09:30:16,570:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006531 seconds.
2023-10-24 09:30:16,570:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 09:30:16,570:INFO:[LightGBM] [Info] Total Bins 6029
2023-10-24 09:30:16,570:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 36
2023-10-24 09:30:16,570:INFO:[LightGBM] [Info] Start training from score 616.864890
2023-10-24 09:30:16,798:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 09:30:16,798:INFO:create_model() successfully completed......................................
2023-10-24 09:30:16,914:INFO:_master_model_container: 2
2023-10-24 09:30:16,914:INFO:_display_container: 2
2023-10-24 09:30:16,930:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 09:30:16,931:INFO:compare_models() successfully completed......................................
2023-10-24 09:30:16,931:INFO:Initializing finalize_model()
2023-10-24 09:30:16,931:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166BE6269D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-24 09:30:16,931:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 09:30:16,931:INFO:Initializing create_model()
2023-10-24 09:30:16,946:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166BE6269D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-24 09:30:16,946:INFO:Checking exceptions
2023-10-24 09:30:16,948:INFO:Importing libraries
2023-10-24 09:30:16,948:INFO:Copying training dataset
2023-10-24 09:30:16,948:INFO:Defining folds
2023-10-24 09:30:16,948:INFO:Declaring metric variables
2023-10-24 09:30:16,948:INFO:Importing untrained model
2023-10-24 09:30:16,948:INFO:Declaring custom model
2023-10-24 09:30:16,948:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 09:30:16,948:INFO:Cross validation set to False
2023-10-24 09:30:16,948:INFO:Fitting Model
2023-10-24 09:30:17,348:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008364 seconds.
2023-10-24 09:30:17,348:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 09:30:17,348:INFO:[LightGBM] [Info] Total Bins 6436
2023-10-24 09:30:17,348:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 37
2023-10-24 09:30:17,348:INFO:[LightGBM] [Info] Start training from score 631.011165
2023-10-24 09:30:17,718:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 09:30:17,718:INFO:create_model() successfully completed......................................
2023-10-24 09:30:17,815:INFO:_master_model_container: 2
2023-10-24 09:30:17,816:INFO:_display_container: 2
2023-10-24 09:30:17,866:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 09:30:17,866:INFO:finalize_model() successfully completed......................................
2023-10-24 09:30:18,082:INFO:Initializing save_model()
2023-10-24 09:30:18,082:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_A, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-24 09:30:18,082:INFO:Adding model into prep_pipe
2023-10-24 09:30:18,082:WARNING:Only Model saved as it was a pipeline.
2023-10-24 09:30:18,096:INFO:final_model_for_location_A.pkl saved in current working directory
2023-10-24 09:30:18,215:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 09:30:18,215:INFO:save_model() successfully completed......................................
2023-10-24 09:30:18,348:INFO:PyCaret RegressionExperiment
2023-10-24 09:30:18,348:INFO:Logging name: exp_B
2023-10-24 09:30:18,348:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 09:30:18,348:INFO:version 3.1.0
2023-10-24 09:30:18,348:INFO:Initializing setup()
2023-10-24 09:30:18,348:INFO:self.USI: e121
2023-10-24 09:30:18,348:INFO:self._variable_keys: {'seed', 'logging_param', 'html_param', 'USI', 'data', 'y_train', 'pipeline', '_ml_usecase', 'gpu_n_jobs_param', 'X_test', 'X_train', 'memory', 'X', 'y_test', 'fold_shuffle_param', 'n_jobs_param', 'exp_name_log', 'y', '_available_plots', 'target_param', 'exp_id', 'idx', 'transform_target_param', 'log_plots_param', 'fold_groups_param', 'gpu_param', 'fold_generator'}
2023-10-24 09:30:18,348:INFO:Checking environment
2023-10-24 09:30:18,348:INFO:python_version: 3.8.18
2023-10-24 09:30:18,348:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-24 09:30:18,348:INFO:machine: AMD64
2023-10-24 09:30:18,348:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-24 09:30:18,350:INFO:Memory: svmem(total=16505954304, available=4937535488, percent=70.1, used=11568418816, free=4937535488)
2023-10-24 09:30:18,350:INFO:Physical Core: 8
2023-10-24 09:30:18,350:INFO:Logical Core: 16
2023-10-24 09:30:18,350:INFO:Checking libraries
2023-10-24 09:30:18,350:INFO:System:
2023-10-24 09:30:18,350:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-24 09:30:18,350:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-24 09:30:18,350:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-24 09:30:18,350:INFO:PyCaret required dependencies:
2023-10-24 09:30:18,351:INFO:                 pip: 23.3
2023-10-24 09:30:18,351:INFO:          setuptools: 68.0.0
2023-10-24 09:30:18,351:INFO:             pycaret: 3.1.0
2023-10-24 09:30:18,351:INFO:             IPython: 8.12.0
2023-10-24 09:30:18,351:INFO:          ipywidgets: 8.1.1
2023-10-24 09:30:18,351:INFO:                tqdm: 4.66.1
2023-10-24 09:30:18,351:INFO:               numpy: 1.23.5
2023-10-24 09:30:18,351:INFO:              pandas: 1.5.3
2023-10-24 09:30:18,351:INFO:              jinja2: 3.1.2
2023-10-24 09:30:18,351:INFO:               scipy: 1.10.1
2023-10-24 09:30:18,351:INFO:              joblib: 1.3.2
2023-10-24 09:30:18,351:INFO:             sklearn: 1.2.2
2023-10-24 09:30:18,352:INFO:                pyod: 1.1.0
2023-10-24 09:30:18,352:INFO:            imblearn: 0.11.0
2023-10-24 09:30:18,352:INFO:   category_encoders: 2.6.2
2023-10-24 09:30:18,352:INFO:            lightgbm: 4.1.0
2023-10-24 09:30:18,352:INFO:               numba: 0.58.1
2023-10-24 09:30:18,352:INFO:            requests: 2.31.0
2023-10-24 09:30:18,352:INFO:          matplotlib: 3.7.3
2023-10-24 09:30:18,352:INFO:          scikitplot: 0.3.7
2023-10-24 09:30:18,352:INFO:         yellowbrick: 1.5
2023-10-24 09:30:18,352:INFO:              plotly: 5.17.0
2023-10-24 09:30:18,352:INFO:    plotly-resampler: Not installed
2023-10-24 09:30:18,352:INFO:             kaleido: 0.2.1
2023-10-24 09:30:18,352:INFO:           schemdraw: 0.15
2023-10-24 09:30:18,352:INFO:         statsmodels: 0.14.0
2023-10-24 09:30:18,352:INFO:              sktime: 0.21.1
2023-10-24 09:30:18,352:INFO:               tbats: 1.1.3
2023-10-24 09:30:18,352:INFO:            pmdarima: 2.0.3
2023-10-24 09:30:18,352:INFO:              psutil: 5.9.0
2023-10-24 09:30:18,352:INFO:          markupsafe: 2.1.3
2023-10-24 09:30:18,353:INFO:             pickle5: Not installed
2023-10-24 09:30:18,353:INFO:         cloudpickle: 2.2.1
2023-10-24 09:30:18,353:INFO:         deprecation: 2.1.0
2023-10-24 09:30:18,353:INFO:              xxhash: 3.4.1
2023-10-24 09:30:18,353:INFO:           wurlitzer: Not installed
2023-10-24 09:30:18,353:INFO:PyCaret optional dependencies:
2023-10-24 09:30:18,353:INFO:                shap: Not installed
2023-10-24 09:30:18,353:INFO:           interpret: Not installed
2023-10-24 09:30:18,353:INFO:                umap: Not installed
2023-10-24 09:30:18,353:INFO:     ydata_profiling: Not installed
2023-10-24 09:30:18,353:INFO:  explainerdashboard: Not installed
2023-10-24 09:30:18,353:INFO:             autoviz: Not installed
2023-10-24 09:30:18,353:INFO:           fairlearn: Not installed
2023-10-24 09:30:18,354:INFO:          deepchecks: Not installed
2023-10-24 09:30:18,354:INFO:             xgboost: Not installed
2023-10-24 09:30:18,354:INFO:            catboost: 1.2.2
2023-10-24 09:30:18,354:INFO:              kmodes: Not installed
2023-10-24 09:30:18,354:INFO:             mlxtend: Not installed
2023-10-24 09:30:18,354:INFO:       statsforecast: Not installed
2023-10-24 09:30:18,354:INFO:        tune_sklearn: Not installed
2023-10-24 09:30:18,354:INFO:                 ray: Not installed
2023-10-24 09:30:18,354:INFO:            hyperopt: Not installed
2023-10-24 09:30:18,354:INFO:              optuna: Not installed
2023-10-24 09:30:18,354:INFO:               skopt: Not installed
2023-10-24 09:30:18,354:INFO:              mlflow: 2.7.1
2023-10-24 09:30:18,354:INFO:              gradio: Not installed
2023-10-24 09:30:18,354:INFO:             fastapi: Not installed
2023-10-24 09:30:18,354:INFO:             uvicorn: Not installed
2023-10-24 09:30:18,355:INFO:              m2cgen: Not installed
2023-10-24 09:30:18,355:INFO:           evidently: Not installed
2023-10-24 09:30:18,355:INFO:               fugue: Not installed
2023-10-24 09:30:18,355:INFO:           streamlit: Not installed
2023-10-24 09:30:18,355:INFO:             prophet: Not installed
2023-10-24 09:30:18,355:INFO:None
2023-10-24 09:30:18,355:INFO:Set up data.
2023-10-24 09:30:18,399:INFO:Set up folding strategy.
2023-10-24 09:30:18,399:INFO:Set up train/test split.
2023-10-24 09:30:18,413:INFO:Set up index.
2023-10-24 09:30:18,413:INFO:Assigning column types.
2023-10-24 09:30:18,428:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 09:30:18,444:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 09:30:18,450:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 09:30:18,450:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 09:30:18,529:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 09:30:18,586:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 09:30:18,586:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:30:18,586:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:30:18,586:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 09:30:18,602:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 09:30:18,602:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 09:30:18,684:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 09:30:18,731:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 09:30:18,731:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:30:18,731:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:30:18,731:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 09:30:18,746:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 09:30:18,746:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 09:30:18,829:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 09:30:18,883:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 09:30:18,883:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:30:18,883:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:30:18,883:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 09:30:18,898:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 09:30:18,981:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 09:30:19,030:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 09:30:19,030:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:30:19,030:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:30:19,030:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 09:30:19,045:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 09:30:19,114:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 09:30:19,183:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 09:30:19,183:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:30:19,183:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:30:19,199:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 09:30:19,262:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 09:30:19,316:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 09:30:19,316:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:30:19,316:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:30:19,316:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 09:30:19,417:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 09:30:19,472:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 09:30:19,473:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:30:19,473:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:30:19,565:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 09:30:19,615:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 09:30:19,615:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:30:19,615:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:30:19,615:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 09:30:19,730:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 09:30:19,783:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:30:19,783:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:30:19,885:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 09:30:19,949:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:30:19,949:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:30:19,950:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 09:30:20,097:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:30:20,097:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:30:20,246:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:30:20,247:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:30:20,248:INFO:Preparing preprocessing pipeline...
2023-10-24 09:30:20,248:INFO:Set up date feature engineering.
2023-10-24 09:30:20,248:INFO:Set up simple imputation.
2023-10-24 09:30:20,248:INFO:Set up encoding of ordinal features.
2023-10-24 09:30:20,266:INFO:Set up encoding of categorical features.
2023-10-24 09:30:20,266:INFO:Set up variance threshold.
2023-10-24 09:30:20,266:INFO:Set up column name cleaning.
2023-10-24 09:30:20,565:INFO:Finished creating preprocessing pipeline.
2023-10-24 09:30:20,632:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 09:30:20,632:INFO:Creating final display dataframe.
2023-10-24 09:30:20,799:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (32819, 48)
4        Transformed data shape  (32819, 37)
5   Transformed train set shape  (22973, 37)
6    Transformed test set shape   (9846, 37)
7              Ordinal features            2
8              Numeric features           43
9                 Date features            1
10         Categorical features            3
11     Rows with missing values        95.9%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18       Low variance threshold         0.05
19               Fold Generator        KFold
20                  Fold Number           10
21                     CPU Jobs           -1
22                      Use GPU        False
23               Log Experiment        False
24              Experiment Name        exp_B
25                          USI         e121
2023-10-24 09:30:20,998:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:30:20,998:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:30:21,197:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:30:21,197:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:30:21,197:INFO:setup() successfully completed in 2.86s...............
2023-10-24 09:30:21,197:INFO:Initializing compare_models()
2023-10-24 09:30:21,197:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166C8753790>, include=['catboost', 'lightgbm'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000166C8753790>, 'include': ['catboost', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-10-24 09:30:21,197:INFO:Checking exceptions
2023-10-24 09:30:21,217:INFO:Preparing display monitor
2023-10-24 09:30:21,217:INFO:Initializing CatBoost Regressor
2023-10-24 09:30:21,217:INFO:Total runtime is 0.0 minutes
2023-10-24 09:30:21,217:INFO:SubProcess create_model() called ==================================
2023-10-24 09:30:21,217:INFO:Initializing create_model()
2023-10-24 09:30:21,217:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166C8753790>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166CC20BDF0>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 09:30:21,217:INFO:Checking exceptions
2023-10-24 09:30:21,217:INFO:Importing libraries
2023-10-24 09:30:21,217:INFO:Copying training dataset
2023-10-24 09:30:21,247:INFO:Defining folds
2023-10-24 09:30:21,247:INFO:Declaring metric variables
2023-10-24 09:30:21,248:INFO:Importing untrained model
2023-10-24 09:30:21,248:INFO:CatBoost Regressor Imported successfully
2023-10-24 09:30:21,248:INFO:Starting cross validation
2023-10-24 09:30:21,252:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 09:30:49,205:INFO:Calculating mean and std
2023-10-24 09:30:49,206:INFO:Creating metrics dataframe
2023-10-24 09:30:49,206:INFO:Uploading results into container
2023-10-24 09:30:49,206:INFO:Uploading model into container now
2023-10-24 09:30:49,206:INFO:_master_model_container: 1
2023-10-24 09:30:49,206:INFO:_display_container: 2
2023-10-24 09:30:49,206:INFO:<catboost.core.CatBoostRegressor object at 0x00000166CC1E1520>
2023-10-24 09:30:49,206:INFO:create_model() successfully completed......................................
2023-10-24 09:30:49,305:INFO:SubProcess create_model() end ==================================
2023-10-24 09:30:49,305:INFO:Creating metrics dataframe
2023-10-24 09:30:49,306:INFO:Initializing Light Gradient Boosting Machine
2023-10-24 09:30:49,306:INFO:Total runtime is 0.4681630849838257 minutes
2023-10-24 09:30:49,306:INFO:SubProcess create_model() called ==================================
2023-10-24 09:30:49,306:INFO:Initializing create_model()
2023-10-24 09:30:49,306:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166C8753790>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166CC20BDF0>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 09:30:49,306:INFO:Checking exceptions
2023-10-24 09:30:49,306:INFO:Importing libraries
2023-10-24 09:30:49,306:INFO:Copying training dataset
2023-10-24 09:30:49,325:INFO:Defining folds
2023-10-24 09:30:49,325:INFO:Declaring metric variables
2023-10-24 09:30:49,325:INFO:Importing untrained model
2023-10-24 09:30:49,325:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 09:30:49,325:INFO:Starting cross validation
2023-10-24 09:30:49,336:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 09:30:52,322:INFO:Calculating mean and std
2023-10-24 09:30:52,322:INFO:Creating metrics dataframe
2023-10-24 09:30:52,322:INFO:Uploading results into container
2023-10-24 09:30:52,322:INFO:Uploading model into container now
2023-10-24 09:30:52,322:INFO:_master_model_container: 2
2023-10-24 09:30:52,322:INFO:_display_container: 2
2023-10-24 09:30:52,322:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 09:30:52,322:INFO:create_model() successfully completed......................................
2023-10-24 09:30:52,422:INFO:SubProcess create_model() end ==================================
2023-10-24 09:30:52,422:INFO:Creating metrics dataframe
2023-10-24 09:30:52,435:INFO:Initializing create_model()
2023-10-24 09:30:52,435:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166C8753790>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 09:30:52,435:INFO:Checking exceptions
2023-10-24 09:30:52,435:INFO:Importing libraries
2023-10-24 09:30:52,435:INFO:Copying training dataset
2023-10-24 09:30:52,455:INFO:Defining folds
2023-10-24 09:30:52,455:INFO:Declaring metric variables
2023-10-24 09:30:52,455:INFO:Importing untrained model
2023-10-24 09:30:52,455:INFO:Declaring custom model
2023-10-24 09:30:52,455:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 09:30:52,467:INFO:Cross validation set to False
2023-10-24 09:30:52,467:INFO:Fitting Model
2023-10-24 09:30:52,750:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004919 seconds.
2023-10-24 09:30:52,750:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 09:30:52,751:INFO:[LightGBM] [Info] Total Bins 6071
2023-10-24 09:30:52,751:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 36
2023-10-24 09:30:52,751:INFO:[LightGBM] [Info] Start training from score 117.072182
2023-10-24 09:30:53,012:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 09:30:53,012:INFO:create_model() successfully completed......................................
2023-10-24 09:30:53,134:INFO:_master_model_container: 2
2023-10-24 09:30:53,134:INFO:_display_container: 2
2023-10-24 09:30:53,134:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 09:30:53,134:INFO:compare_models() successfully completed......................................
2023-10-24 09:30:53,134:INFO:Initializing finalize_model()
2023-10-24 09:30:53,134:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166C8753790>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-24 09:30:53,134:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 09:30:53,155:INFO:Initializing create_model()
2023-10-24 09:30:53,155:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166C8753790>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-24 09:30:53,155:INFO:Checking exceptions
2023-10-24 09:30:53,155:INFO:Importing libraries
2023-10-24 09:30:53,155:INFO:Copying training dataset
2023-10-24 09:30:53,155:INFO:Defining folds
2023-10-24 09:30:53,155:INFO:Declaring metric variables
2023-10-24 09:30:53,155:INFO:Importing untrained model
2023-10-24 09:30:53,155:INFO:Declaring custom model
2023-10-24 09:30:53,155:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 09:30:53,155:INFO:Cross validation set to False
2023-10-24 09:30:53,155:INFO:Fitting Model
2023-10-24 09:30:53,550:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007203 seconds.
2023-10-24 09:30:53,550:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 09:30:53,550:INFO:[LightGBM] [Info] Total Bins 6395
2023-10-24 09:30:53,550:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 37
2023-10-24 09:30:53,550:INFO:[LightGBM] [Info] Start training from score 96.893335
2023-10-24 09:30:53,938:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 09:30:53,938:INFO:create_model() successfully completed......................................
2023-10-24 09:30:54,038:INFO:_master_model_container: 2
2023-10-24 09:30:54,038:INFO:_display_container: 2
2023-10-24 09:30:54,101:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 09:30:54,101:INFO:finalize_model() successfully completed......................................
2023-10-24 09:30:54,320:INFO:Initializing save_model()
2023-10-24 09:30:54,320:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_B, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-24 09:30:54,320:INFO:Adding model into prep_pipe
2023-10-24 09:30:54,320:WARNING:Only Model saved as it was a pipeline.
2023-10-24 09:30:54,320:INFO:final_model_for_location_B.pkl saved in current working directory
2023-10-24 09:30:54,437:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 09:30:54,437:INFO:save_model() successfully completed......................................
2023-10-24 09:30:54,586:INFO:PyCaret RegressionExperiment
2023-10-24 09:30:54,587:INFO:Logging name: exp_C
2023-10-24 09:30:54,587:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 09:30:54,587:INFO:version 3.1.0
2023-10-24 09:30:54,587:INFO:Initializing setup()
2023-10-24 09:30:54,587:INFO:self.USI: a5e7
2023-10-24 09:30:54,587:INFO:self._variable_keys: {'seed', 'logging_param', 'html_param', 'USI', 'data', 'y_train', 'pipeline', '_ml_usecase', 'gpu_n_jobs_param', 'X_test', 'X_train', 'memory', 'X', 'y_test', 'fold_shuffle_param', 'n_jobs_param', 'exp_name_log', 'y', '_available_plots', 'target_param', 'exp_id', 'idx', 'transform_target_param', 'log_plots_param', 'fold_groups_param', 'gpu_param', 'fold_generator'}
2023-10-24 09:30:54,587:INFO:Checking environment
2023-10-24 09:30:54,587:INFO:python_version: 3.8.18
2023-10-24 09:30:54,587:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-24 09:30:54,587:INFO:machine: AMD64
2023-10-24 09:30:54,587:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-24 09:30:54,587:INFO:Memory: svmem(total=16505954304, available=4950175744, percent=70.0, used=11555778560, free=4950175744)
2023-10-24 09:30:54,588:INFO:Physical Core: 8
2023-10-24 09:30:54,588:INFO:Logical Core: 16
2023-10-24 09:30:54,588:INFO:Checking libraries
2023-10-24 09:30:54,588:INFO:System:
2023-10-24 09:30:54,588:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-24 09:30:54,588:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-24 09:30:54,588:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-24 09:30:54,588:INFO:PyCaret required dependencies:
2023-10-24 09:30:54,588:INFO:                 pip: 23.3
2023-10-24 09:30:54,588:INFO:          setuptools: 68.0.0
2023-10-24 09:30:54,588:INFO:             pycaret: 3.1.0
2023-10-24 09:30:54,589:INFO:             IPython: 8.12.0
2023-10-24 09:30:54,589:INFO:          ipywidgets: 8.1.1
2023-10-24 09:30:54,589:INFO:                tqdm: 4.66.1
2023-10-24 09:30:54,589:INFO:               numpy: 1.23.5
2023-10-24 09:30:54,589:INFO:              pandas: 1.5.3
2023-10-24 09:30:54,589:INFO:              jinja2: 3.1.2
2023-10-24 09:30:54,589:INFO:               scipy: 1.10.1
2023-10-24 09:30:54,589:INFO:              joblib: 1.3.2
2023-10-24 09:30:54,589:INFO:             sklearn: 1.2.2
2023-10-24 09:30:54,589:INFO:                pyod: 1.1.0
2023-10-24 09:30:54,589:INFO:            imblearn: 0.11.0
2023-10-24 09:30:54,589:INFO:   category_encoders: 2.6.2
2023-10-24 09:30:54,589:INFO:            lightgbm: 4.1.0
2023-10-24 09:30:54,589:INFO:               numba: 0.58.1
2023-10-24 09:30:54,589:INFO:            requests: 2.31.0
2023-10-24 09:30:54,589:INFO:          matplotlib: 3.7.3
2023-10-24 09:30:54,589:INFO:          scikitplot: 0.3.7
2023-10-24 09:30:54,589:INFO:         yellowbrick: 1.5
2023-10-24 09:30:54,589:INFO:              plotly: 5.17.0
2023-10-24 09:30:54,589:INFO:    plotly-resampler: Not installed
2023-10-24 09:30:54,589:INFO:             kaleido: 0.2.1
2023-10-24 09:30:54,589:INFO:           schemdraw: 0.15
2023-10-24 09:30:54,589:INFO:         statsmodels: 0.14.0
2023-10-24 09:30:54,589:INFO:              sktime: 0.21.1
2023-10-24 09:30:54,589:INFO:               tbats: 1.1.3
2023-10-24 09:30:54,589:INFO:            pmdarima: 2.0.3
2023-10-24 09:30:54,589:INFO:              psutil: 5.9.0
2023-10-24 09:30:54,589:INFO:          markupsafe: 2.1.3
2023-10-24 09:30:54,589:INFO:             pickle5: Not installed
2023-10-24 09:30:54,589:INFO:         cloudpickle: 2.2.1
2023-10-24 09:30:54,589:INFO:         deprecation: 2.1.0
2023-10-24 09:30:54,589:INFO:              xxhash: 3.4.1
2023-10-24 09:30:54,589:INFO:           wurlitzer: Not installed
2023-10-24 09:30:54,589:INFO:PyCaret optional dependencies:
2023-10-24 09:30:54,589:INFO:                shap: Not installed
2023-10-24 09:30:54,589:INFO:           interpret: Not installed
2023-10-24 09:30:54,589:INFO:                umap: Not installed
2023-10-24 09:30:54,589:INFO:     ydata_profiling: Not installed
2023-10-24 09:30:54,589:INFO:  explainerdashboard: Not installed
2023-10-24 09:30:54,589:INFO:             autoviz: Not installed
2023-10-24 09:30:54,589:INFO:           fairlearn: Not installed
2023-10-24 09:30:54,589:INFO:          deepchecks: Not installed
2023-10-24 09:30:54,589:INFO:             xgboost: Not installed
2023-10-24 09:30:54,589:INFO:            catboost: 1.2.2
2023-10-24 09:30:54,589:INFO:              kmodes: Not installed
2023-10-24 09:30:54,589:INFO:             mlxtend: Not installed
2023-10-24 09:30:54,589:INFO:       statsforecast: Not installed
2023-10-24 09:30:54,589:INFO:        tune_sklearn: Not installed
2023-10-24 09:30:54,589:INFO:                 ray: Not installed
2023-10-24 09:30:54,589:INFO:            hyperopt: Not installed
2023-10-24 09:30:54,589:INFO:              optuna: Not installed
2023-10-24 09:30:54,589:INFO:               skopt: Not installed
2023-10-24 09:30:54,589:INFO:              mlflow: 2.7.1
2023-10-24 09:30:54,589:INFO:              gradio: Not installed
2023-10-24 09:30:54,589:INFO:             fastapi: Not installed
2023-10-24 09:30:54,589:INFO:             uvicorn: Not installed
2023-10-24 09:30:54,589:INFO:              m2cgen: Not installed
2023-10-24 09:30:54,589:INFO:           evidently: Not installed
2023-10-24 09:30:54,589:INFO:               fugue: Not installed
2023-10-24 09:30:54,589:INFO:           streamlit: Not installed
2023-10-24 09:30:54,589:INFO:             prophet: Not installed
2023-10-24 09:30:54,589:INFO:None
2023-10-24 09:30:54,589:INFO:Set up data.
2023-10-24 09:30:54,624:INFO:Set up folding strategy.
2023-10-24 09:30:54,624:INFO:Set up train/test split.
2023-10-24 09:30:54,642:INFO:Set up index.
2023-10-24 09:30:54,643:INFO:Assigning column types.
2023-10-24 09:30:54,650:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 09:30:54,650:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 09:30:54,665:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 09:30:54,665:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 09:30:54,736:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 09:30:54,807:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 09:30:54,807:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:30:54,807:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:30:54,807:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 09:30:54,807:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 09:30:54,815:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 09:30:54,900:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 09:30:54,953:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 09:30:54,953:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:30:54,953:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:30:54,953:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 09:30:54,969:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 09:30:54,969:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 09:30:55,053:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 09:30:55,116:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 09:30:55,116:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:30:55,116:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:30:55,116:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 09:30:55,132:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 09:30:55,216:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 09:30:55,269:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 09:30:55,269:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:30:55,269:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:30:55,269:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 09:30:55,285:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 09:30:55,370:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 09:30:55,437:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 09:30:55,437:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:30:55,437:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:30:55,437:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 09:30:55,549:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 09:30:55,621:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 09:30:55,621:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:30:55,621:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:30:55,621:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 09:30:55,734:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 09:30:55,808:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 09:30:55,808:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:30:55,808:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:30:55,933:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 09:30:56,002:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 09:30:56,002:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:30:56,002:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:30:56,002:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 09:30:56,095:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 09:30:56,150:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:30:56,150:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:30:56,250:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 09:30:56,297:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:30:56,297:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:30:56,297:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 09:30:56,436:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:30:56,436:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:30:56,583:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:30:56,583:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:30:56,583:INFO:Preparing preprocessing pipeline...
2023-10-24 09:30:56,583:INFO:Set up date feature engineering.
2023-10-24 09:30:56,583:INFO:Set up simple imputation.
2023-10-24 09:30:56,599:INFO:Set up encoding of ordinal features.
2023-10-24 09:30:56,615:INFO:Set up encoding of categorical features.
2023-10-24 09:30:56,615:INFO:Set up variance threshold.
2023-10-24 09:30:56,615:INFO:Set up column name cleaning.
2023-10-24 09:30:56,869:INFO:Finished creating preprocessing pipeline.
2023-10-24 09:30:56,947:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 09:30:56,947:INFO:Creating final display dataframe.
2023-10-24 09:30:57,283:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (26071, 48)
4        Transformed data shape  (26071, 41)
5   Transformed train set shape  (18249, 41)
6    Transformed test set shape   (7822, 41)
7              Ordinal features            2
8              Numeric features           43
9                 Date features            1
10         Categorical features            3
11     Rows with missing values        95.9%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18       Low variance threshold         0.05
19               Fold Generator        KFold
20                  Fold Number           10
21                     CPU Jobs           -1
22                      Use GPU        False
23               Log Experiment        False
24              Experiment Name        exp_C
25                          USI         a5e7
2023-10-24 09:30:57,435:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:30:57,435:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:30:57,582:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:30:57,582:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:30:57,582:INFO:setup() successfully completed in 3.01s...............
2023-10-24 09:30:57,582:INFO:Initializing compare_models()
2023-10-24 09:30:57,582:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CC1D51F0>, include=['catboost', 'lightgbm'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000166CC1D51F0>, 'include': ['catboost', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-10-24 09:30:57,582:INFO:Checking exceptions
2023-10-24 09:30:57,582:INFO:Preparing display monitor
2023-10-24 09:30:57,598:INFO:Initializing CatBoost Regressor
2023-10-24 09:30:57,598:INFO:Total runtime is 0.0 minutes
2023-10-24 09:30:57,598:INFO:SubProcess create_model() called ==================================
2023-10-24 09:30:57,598:INFO:Initializing create_model()
2023-10-24 09:30:57,598:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CC1D51F0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166CCAA4820>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 09:30:57,598:INFO:Checking exceptions
2023-10-24 09:30:57,600:INFO:Importing libraries
2023-10-24 09:30:57,600:INFO:Copying training dataset
2023-10-24 09:30:57,620:INFO:Defining folds
2023-10-24 09:30:57,621:INFO:Declaring metric variables
2023-10-24 09:30:57,621:INFO:Importing untrained model
2023-10-24 09:30:57,621:INFO:CatBoost Regressor Imported successfully
2023-10-24 09:30:57,621:INFO:Starting cross validation
2023-10-24 09:30:57,621:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 09:31:29,070:INFO:Calculating mean and std
2023-10-24 09:31:29,071:INFO:Creating metrics dataframe
2023-10-24 09:31:29,071:INFO:Uploading results into container
2023-10-24 09:31:29,071:INFO:Uploading model into container now
2023-10-24 09:31:29,071:INFO:_master_model_container: 1
2023-10-24 09:31:29,071:INFO:_display_container: 2
2023-10-24 09:31:29,071:INFO:<catboost.core.CatBoostRegressor object at 0x00000166CBBC50A0>
2023-10-24 09:31:29,071:INFO:create_model() successfully completed......................................
2023-10-24 09:31:29,171:INFO:SubProcess create_model() end ==================================
2023-10-24 09:31:29,171:INFO:Creating metrics dataframe
2023-10-24 09:31:29,171:INFO:Initializing Light Gradient Boosting Machine
2023-10-24 09:31:29,171:INFO:Total runtime is 0.5262277483940124 minutes
2023-10-24 09:31:29,171:INFO:SubProcess create_model() called ==================================
2023-10-24 09:31:29,171:INFO:Initializing create_model()
2023-10-24 09:31:29,171:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CC1D51F0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166CCAA4820>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 09:31:29,171:INFO:Checking exceptions
2023-10-24 09:31:29,171:INFO:Importing libraries
2023-10-24 09:31:29,171:INFO:Copying training dataset
2023-10-24 09:31:29,188:INFO:Defining folds
2023-10-24 09:31:29,188:INFO:Declaring metric variables
2023-10-24 09:31:29,188:INFO:Importing untrained model
2023-10-24 09:31:29,188:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 09:31:29,188:INFO:Starting cross validation
2023-10-24 09:31:29,203:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 09:31:32,124:INFO:Calculating mean and std
2023-10-24 09:31:32,124:INFO:Creating metrics dataframe
2023-10-24 09:31:32,124:INFO:Uploading results into container
2023-10-24 09:31:32,124:INFO:Uploading model into container now
2023-10-24 09:31:32,124:INFO:_master_model_container: 2
2023-10-24 09:31:32,124:INFO:_display_container: 2
2023-10-24 09:31:32,134:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 09:31:32,134:INFO:create_model() successfully completed......................................
2023-10-24 09:31:32,234:INFO:SubProcess create_model() end ==================================
2023-10-24 09:31:32,234:INFO:Creating metrics dataframe
2023-10-24 09:31:32,235:INFO:Initializing create_model()
2023-10-24 09:31:32,235:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CC1D51F0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 09:31:32,235:INFO:Checking exceptions
2023-10-24 09:31:32,235:INFO:Importing libraries
2023-10-24 09:31:32,235:INFO:Copying training dataset
2023-10-24 09:31:32,252:INFO:Defining folds
2023-10-24 09:31:32,252:INFO:Declaring metric variables
2023-10-24 09:31:32,252:INFO:Importing untrained model
2023-10-24 09:31:32,252:INFO:Declaring custom model
2023-10-24 09:31:32,252:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 09:31:32,252:INFO:Cross validation set to False
2023-10-24 09:31:32,252:INFO:Fitting Model
2023-10-24 09:31:32,501:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005428 seconds.
2023-10-24 09:31:32,501:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 09:31:32,502:INFO:[LightGBM] [Info] Total Bins 6250
2023-10-24 09:31:32,502:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 40
2023-10-24 09:31:32,503:INFO:[LightGBM] [Info] Start training from score 96.094131
2023-10-24 09:31:32,734:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 09:31:32,734:INFO:create_model() successfully completed......................................
2023-10-24 09:31:32,851:INFO:_master_model_container: 2
2023-10-24 09:31:32,851:INFO:_display_container: 2
2023-10-24 09:31:32,851:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 09:31:32,851:INFO:compare_models() successfully completed......................................
2023-10-24 09:31:32,851:INFO:Initializing finalize_model()
2023-10-24 09:31:32,851:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CC1D51F0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-24 09:31:32,851:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 09:31:32,874:INFO:Initializing create_model()
2023-10-24 09:31:32,874:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CC1D51F0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-24 09:31:32,874:INFO:Checking exceptions
2023-10-24 09:31:32,874:INFO:Importing libraries
2023-10-24 09:31:32,874:INFO:Copying training dataset
2023-10-24 09:31:32,874:INFO:Defining folds
2023-10-24 09:31:32,874:INFO:Declaring metric variables
2023-10-24 09:31:32,874:INFO:Importing untrained model
2023-10-24 09:31:32,874:INFO:Declaring custom model
2023-10-24 09:31:32,874:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 09:31:32,884:INFO:Cross validation set to False
2023-10-24 09:31:32,884:INFO:Fitting Model
2023-10-24 09:31:33,235:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006655 seconds.
2023-10-24 09:31:33,235:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 09:31:33,235:INFO:[LightGBM] [Info] Total Bins 6628
2023-10-24 09:31:33,235:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 41
2023-10-24 09:31:33,235:INFO:[LightGBM] [Info] Start training from score 77.700043
2023-10-24 09:31:33,621:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 09:31:33,622:INFO:create_model() successfully completed......................................
2023-10-24 09:31:33,718:INFO:_master_model_container: 2
2023-10-24 09:31:33,718:INFO:_display_container: 2
2023-10-24 09:31:33,768:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 09:31:33,768:INFO:finalize_model() successfully completed......................................
2023-10-24 09:31:33,984:INFO:Initializing save_model()
2023-10-24 09:31:33,984:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_C, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-24 09:31:33,984:INFO:Adding model into prep_pipe
2023-10-24 09:31:33,984:WARNING:Only Model saved as it was a pipeline.
2023-10-24 09:31:34,000:INFO:final_model_for_location_C.pkl saved in current working directory
2023-10-24 09:31:34,119:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 09:31:34,119:INFO:save_model() successfully completed......................................
2023-10-24 09:31:34,360:INFO:PyCaret RegressionExperiment
2023-10-24 09:31:34,360:INFO:Logging name: exp_A
2023-10-24 09:31:34,360:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 09:31:34,360:INFO:version 3.1.0
2023-10-24 09:31:34,360:INFO:Initializing setup()
2023-10-24 09:31:34,360:INFO:self.USI: 1e30
2023-10-24 09:31:34,360:INFO:self._variable_keys: {'logging_param', 'pipeline', '_ml_usecase', 'X_test', 'memory', 'y_test', 'n_jobs_param', 'exp_name_log', 'y', 'transform_target_param', 'fold_groups_param', 'gpu_param', 'seed', 'html_param', 'USI', 'data', 'y_train', 'gpu_n_jobs_param', 'X_train', 'X', 'fold_shuffle_param', '_available_plots', 'target_param', 'exp_id', 'idx', 'log_plots_param', 'fold_generator'}
2023-10-24 09:31:34,360:INFO:Checking environment
2023-10-24 09:31:34,360:INFO:python_version: 3.8.18
2023-10-24 09:31:34,360:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-24 09:31:34,360:INFO:machine: AMD64
2023-10-24 09:31:34,360:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-24 09:31:34,360:INFO:Memory: svmem(total=16505954304, available=4814946304, percent=70.8, used=11691008000, free=4814946304)
2023-10-24 09:31:34,360:INFO:Physical Core: 8
2023-10-24 09:31:34,360:INFO:Logical Core: 16
2023-10-24 09:31:34,360:INFO:Checking libraries
2023-10-24 09:31:34,360:INFO:System:
2023-10-24 09:31:34,360:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-24 09:31:34,360:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-24 09:31:34,360:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-24 09:31:34,360:INFO:PyCaret required dependencies:
2023-10-24 09:31:34,360:INFO:                 pip: 23.3
2023-10-24 09:31:34,360:INFO:          setuptools: 68.0.0
2023-10-24 09:31:34,360:INFO:             pycaret: 3.1.0
2023-10-24 09:31:34,360:INFO:             IPython: 8.12.0
2023-10-24 09:31:34,360:INFO:          ipywidgets: 8.1.1
2023-10-24 09:31:34,360:INFO:                tqdm: 4.66.1
2023-10-24 09:31:34,360:INFO:               numpy: 1.23.5
2023-10-24 09:31:34,360:INFO:              pandas: 1.5.3
2023-10-24 09:31:34,360:INFO:              jinja2: 3.1.2
2023-10-24 09:31:34,360:INFO:               scipy: 1.10.1
2023-10-24 09:31:34,360:INFO:              joblib: 1.3.2
2023-10-24 09:31:34,360:INFO:             sklearn: 1.2.2
2023-10-24 09:31:34,360:INFO:                pyod: 1.1.0
2023-10-24 09:31:34,360:INFO:            imblearn: 0.11.0
2023-10-24 09:31:34,360:INFO:   category_encoders: 2.6.2
2023-10-24 09:31:34,360:INFO:            lightgbm: 4.1.0
2023-10-24 09:31:34,360:INFO:               numba: 0.58.1
2023-10-24 09:31:34,360:INFO:            requests: 2.31.0
2023-10-24 09:31:34,360:INFO:          matplotlib: 3.7.3
2023-10-24 09:31:34,360:INFO:          scikitplot: 0.3.7
2023-10-24 09:31:34,360:INFO:         yellowbrick: 1.5
2023-10-24 09:31:34,360:INFO:              plotly: 5.17.0
2023-10-24 09:31:34,360:INFO:    plotly-resampler: Not installed
2023-10-24 09:31:34,360:INFO:             kaleido: 0.2.1
2023-10-24 09:31:34,360:INFO:           schemdraw: 0.15
2023-10-24 09:31:34,360:INFO:         statsmodels: 0.14.0
2023-10-24 09:31:34,360:INFO:              sktime: 0.21.1
2023-10-24 09:31:34,360:INFO:               tbats: 1.1.3
2023-10-24 09:31:34,360:INFO:            pmdarima: 2.0.3
2023-10-24 09:31:34,360:INFO:              psutil: 5.9.0
2023-10-24 09:31:34,360:INFO:          markupsafe: 2.1.3
2023-10-24 09:31:34,366:INFO:             pickle5: Not installed
2023-10-24 09:31:34,366:INFO:         cloudpickle: 2.2.1
2023-10-24 09:31:34,366:INFO:         deprecation: 2.1.0
2023-10-24 09:31:34,366:INFO:              xxhash: 3.4.1
2023-10-24 09:31:34,366:INFO:           wurlitzer: Not installed
2023-10-24 09:31:34,366:INFO:PyCaret optional dependencies:
2023-10-24 09:31:34,366:INFO:                shap: Not installed
2023-10-24 09:31:34,366:INFO:           interpret: Not installed
2023-10-24 09:31:34,366:INFO:                umap: Not installed
2023-10-24 09:31:34,366:INFO:     ydata_profiling: Not installed
2023-10-24 09:31:34,366:INFO:  explainerdashboard: Not installed
2023-10-24 09:31:34,366:INFO:             autoviz: Not installed
2023-10-24 09:31:34,366:INFO:           fairlearn: Not installed
2023-10-24 09:31:34,366:INFO:          deepchecks: Not installed
2023-10-24 09:31:34,367:INFO:             xgboost: Not installed
2023-10-24 09:31:34,367:INFO:            catboost: 1.2.2
2023-10-24 09:31:34,367:INFO:              kmodes: Not installed
2023-10-24 09:31:34,367:INFO:             mlxtend: Not installed
2023-10-24 09:31:34,367:INFO:       statsforecast: Not installed
2023-10-24 09:31:34,367:INFO:        tune_sklearn: Not installed
2023-10-24 09:31:34,367:INFO:                 ray: Not installed
2023-10-24 09:31:34,367:INFO:            hyperopt: Not installed
2023-10-24 09:31:34,367:INFO:              optuna: Not installed
2023-10-24 09:31:34,367:INFO:               skopt: Not installed
2023-10-24 09:31:34,367:INFO:              mlflow: 2.7.1
2023-10-24 09:31:34,367:INFO:              gradio: Not installed
2023-10-24 09:31:34,367:INFO:             fastapi: Not installed
2023-10-24 09:31:34,367:INFO:             uvicorn: Not installed
2023-10-24 09:31:34,367:INFO:              m2cgen: Not installed
2023-10-24 09:31:34,367:INFO:           evidently: Not installed
2023-10-24 09:31:34,367:INFO:               fugue: Not installed
2023-10-24 09:31:34,368:INFO:           streamlit: Not installed
2023-10-24 09:31:34,368:INFO:             prophet: Not installed
2023-10-24 09:31:34,368:INFO:None
2023-10-24 09:31:34,368:INFO:Set up data.
2023-10-24 09:37:21,711:INFO:PyCaret RegressionExperiment
2023-10-24 09:37:21,712:INFO:Logging name: exp_A
2023-10-24 09:37:21,712:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 09:37:21,712:INFO:version 3.1.0
2023-10-24 09:37:21,713:INFO:Initializing setup()
2023-10-24 09:37:21,713:INFO:self.USI: 4d09
2023-10-24 09:37:21,713:INFO:self._variable_keys: {'logging_param', 'pipeline', '_ml_usecase', 'X_test', 'memory', 'y_test', 'n_jobs_param', 'exp_name_log', 'y', 'transform_target_param', 'fold_groups_param', 'gpu_param', 'seed', 'html_param', 'USI', 'data', 'y_train', 'gpu_n_jobs_param', 'X_train', 'X', 'fold_shuffle_param', '_available_plots', 'target_param', 'exp_id', 'idx', 'log_plots_param', 'fold_generator'}
2023-10-24 09:37:21,713:INFO:Checking environment
2023-10-24 09:37:21,713:INFO:python_version: 3.8.18
2023-10-24 09:37:21,713:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-24 09:37:21,714:INFO:machine: AMD64
2023-10-24 09:37:21,714:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-24 09:37:21,714:INFO:Memory: svmem(total=16505954304, available=7212871680, percent=56.3, used=9293082624, free=7212871680)
2023-10-24 09:37:21,714:INFO:Physical Core: 8
2023-10-24 09:37:21,714:INFO:Logical Core: 16
2023-10-24 09:37:21,714:INFO:Checking libraries
2023-10-24 09:37:21,715:INFO:System:
2023-10-24 09:37:21,715:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-24 09:37:21,715:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-24 09:37:21,715:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-24 09:37:21,715:INFO:PyCaret required dependencies:
2023-10-24 09:37:21,715:INFO:                 pip: 23.3
2023-10-24 09:37:21,716:INFO:          setuptools: 68.0.0
2023-10-24 09:37:21,716:INFO:             pycaret: 3.1.0
2023-10-24 09:37:21,716:INFO:             IPython: 8.12.0
2023-10-24 09:37:21,716:INFO:          ipywidgets: 8.1.1
2023-10-24 09:37:21,716:INFO:                tqdm: 4.66.1
2023-10-24 09:37:21,717:INFO:               numpy: 1.23.5
2023-10-24 09:37:21,717:INFO:              pandas: 1.5.3
2023-10-24 09:37:21,717:INFO:              jinja2: 3.1.2
2023-10-24 09:37:21,717:INFO:               scipy: 1.10.1
2023-10-24 09:37:21,717:INFO:              joblib: 1.3.2
2023-10-24 09:37:21,719:INFO:             sklearn: 1.2.2
2023-10-24 09:37:21,719:INFO:                pyod: 1.1.0
2023-10-24 09:37:21,719:INFO:            imblearn: 0.11.0
2023-10-24 09:37:21,719:INFO:   category_encoders: 2.6.2
2023-10-24 09:37:21,719:INFO:            lightgbm: 4.1.0
2023-10-24 09:37:21,719:INFO:               numba: 0.58.1
2023-10-24 09:37:21,720:INFO:            requests: 2.31.0
2023-10-24 09:37:21,720:INFO:          matplotlib: 3.7.3
2023-10-24 09:37:21,720:INFO:          scikitplot: 0.3.7
2023-10-24 09:37:21,720:INFO:         yellowbrick: 1.5
2023-10-24 09:37:21,720:INFO:              plotly: 5.17.0
2023-10-24 09:37:21,720:INFO:    plotly-resampler: Not installed
2023-10-24 09:37:21,720:INFO:             kaleido: 0.2.1
2023-10-24 09:37:21,720:INFO:           schemdraw: 0.15
2023-10-24 09:37:21,720:INFO:         statsmodels: 0.14.0
2023-10-24 09:37:21,720:INFO:              sktime: 0.21.1
2023-10-24 09:37:21,720:INFO:               tbats: 1.1.3
2023-10-24 09:37:21,720:INFO:            pmdarima: 2.0.3
2023-10-24 09:37:21,720:INFO:              psutil: 5.9.0
2023-10-24 09:37:21,720:INFO:          markupsafe: 2.1.3
2023-10-24 09:37:21,721:INFO:             pickle5: Not installed
2023-10-24 09:37:21,721:INFO:         cloudpickle: 2.2.1
2023-10-24 09:37:21,721:INFO:         deprecation: 2.1.0
2023-10-24 09:37:21,721:INFO:              xxhash: 3.4.1
2023-10-24 09:37:21,721:INFO:           wurlitzer: Not installed
2023-10-24 09:37:21,721:INFO:PyCaret optional dependencies:
2023-10-24 09:37:21,721:INFO:                shap: Not installed
2023-10-24 09:37:21,721:INFO:           interpret: Not installed
2023-10-24 09:37:21,721:INFO:                umap: Not installed
2023-10-24 09:37:21,721:INFO:     ydata_profiling: Not installed
2023-10-24 09:37:21,721:INFO:  explainerdashboard: Not installed
2023-10-24 09:37:21,721:INFO:             autoviz: Not installed
2023-10-24 09:37:21,721:INFO:           fairlearn: Not installed
2023-10-24 09:37:21,721:INFO:          deepchecks: Not installed
2023-10-24 09:37:21,721:INFO:             xgboost: Not installed
2023-10-24 09:37:21,721:INFO:            catboost: 1.2.2
2023-10-24 09:37:21,721:INFO:              kmodes: Not installed
2023-10-24 09:37:21,721:INFO:             mlxtend: Not installed
2023-10-24 09:37:21,721:INFO:       statsforecast: Not installed
2023-10-24 09:37:21,721:INFO:        tune_sklearn: Not installed
2023-10-24 09:37:21,721:INFO:                 ray: Not installed
2023-10-24 09:37:21,721:INFO:            hyperopt: Not installed
2023-10-24 09:37:21,722:INFO:              optuna: Not installed
2023-10-24 09:37:21,722:INFO:               skopt: Not installed
2023-10-24 09:37:21,722:INFO:              mlflow: 2.7.1
2023-10-24 09:37:21,722:INFO:              gradio: Not installed
2023-10-24 09:37:21,722:INFO:             fastapi: Not installed
2023-10-24 09:37:21,722:INFO:             uvicorn: Not installed
2023-10-24 09:37:21,722:INFO:              m2cgen: Not installed
2023-10-24 09:37:21,722:INFO:           evidently: Not installed
2023-10-24 09:37:21,722:INFO:               fugue: Not installed
2023-10-24 09:37:21,722:INFO:           streamlit: Not installed
2023-10-24 09:37:21,722:INFO:             prophet: Not installed
2023-10-24 09:37:21,722:INFO:None
2023-10-24 09:37:21,722:INFO:Set up data.
2023-10-24 09:47:47,320:INFO:PyCaret RegressionExperiment
2023-10-24 09:47:47,320:INFO:Logging name: exp_A
2023-10-24 09:47:47,322:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 09:47:47,323:INFO:version 3.1.0
2023-10-24 09:47:47,324:INFO:Initializing setup()
2023-10-24 09:47:47,324:INFO:self.USI: 83d3
2023-10-24 09:47:47,324:INFO:self._variable_keys: {'logging_param', 'pipeline', '_ml_usecase', 'X_test', 'memory', 'y_test', 'n_jobs_param', 'exp_name_log', 'y', 'transform_target_param', 'fold_groups_param', 'gpu_param', 'seed', 'html_param', 'USI', 'data', 'y_train', 'gpu_n_jobs_param', 'X_train', 'X', 'fold_shuffle_param', '_available_plots', 'target_param', 'exp_id', 'idx', 'log_plots_param', 'fold_generator'}
2023-10-24 09:47:47,324:INFO:Checking environment
2023-10-24 09:47:47,324:INFO:python_version: 3.8.18
2023-10-24 09:47:47,324:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-24 09:47:47,324:INFO:machine: AMD64
2023-10-24 09:47:47,324:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-24 09:47:47,327:INFO:Memory: svmem(total=16505954304, available=7510949888, percent=54.5, used=8995004416, free=7510949888)
2023-10-24 09:47:47,327:INFO:Physical Core: 8
2023-10-24 09:47:47,327:INFO:Logical Core: 16
2023-10-24 09:47:47,327:INFO:Checking libraries
2023-10-24 09:47:47,327:INFO:System:
2023-10-24 09:47:47,327:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-24 09:47:47,327:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-24 09:47:47,327:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-24 09:47:47,327:INFO:PyCaret required dependencies:
2023-10-24 09:47:47,328:INFO:                 pip: 23.3
2023-10-24 09:47:47,328:INFO:          setuptools: 68.0.0
2023-10-24 09:47:47,328:INFO:             pycaret: 3.1.0
2023-10-24 09:47:47,328:INFO:             IPython: 8.12.0
2023-10-24 09:47:47,328:INFO:          ipywidgets: 8.1.1
2023-10-24 09:47:47,328:INFO:                tqdm: 4.66.1
2023-10-24 09:47:47,328:INFO:               numpy: 1.23.5
2023-10-24 09:47:47,328:INFO:              pandas: 1.5.3
2023-10-24 09:47:47,328:INFO:              jinja2: 3.1.2
2023-10-24 09:47:47,328:INFO:               scipy: 1.10.1
2023-10-24 09:47:47,328:INFO:              joblib: 1.3.2
2023-10-24 09:47:47,328:INFO:             sklearn: 1.2.2
2023-10-24 09:47:47,328:INFO:                pyod: 1.1.0
2023-10-24 09:47:47,328:INFO:            imblearn: 0.11.0
2023-10-24 09:47:47,328:INFO:   category_encoders: 2.6.2
2023-10-24 09:47:47,328:INFO:            lightgbm: 4.1.0
2023-10-24 09:47:47,328:INFO:               numba: 0.58.1
2023-10-24 09:47:47,328:INFO:            requests: 2.31.0
2023-10-24 09:47:47,328:INFO:          matplotlib: 3.7.3
2023-10-24 09:47:47,328:INFO:          scikitplot: 0.3.7
2023-10-24 09:47:47,328:INFO:         yellowbrick: 1.5
2023-10-24 09:47:47,328:INFO:              plotly: 5.17.0
2023-10-24 09:47:47,328:INFO:    plotly-resampler: Not installed
2023-10-24 09:47:47,328:INFO:             kaleido: 0.2.1
2023-10-24 09:47:47,328:INFO:           schemdraw: 0.15
2023-10-24 09:47:47,328:INFO:         statsmodels: 0.14.0
2023-10-24 09:47:47,328:INFO:              sktime: 0.21.1
2023-10-24 09:47:47,328:INFO:               tbats: 1.1.3
2023-10-24 09:47:47,328:INFO:            pmdarima: 2.0.3
2023-10-24 09:47:47,328:INFO:              psutil: 5.9.0
2023-10-24 09:47:47,328:INFO:          markupsafe: 2.1.3
2023-10-24 09:47:47,328:INFO:             pickle5: Not installed
2023-10-24 09:47:47,328:INFO:         cloudpickle: 2.2.1
2023-10-24 09:47:47,328:INFO:         deprecation: 2.1.0
2023-10-24 09:47:47,328:INFO:              xxhash: 3.4.1
2023-10-24 09:47:47,328:INFO:           wurlitzer: Not installed
2023-10-24 09:47:47,328:INFO:PyCaret optional dependencies:
2023-10-24 09:47:47,328:INFO:                shap: Not installed
2023-10-24 09:47:47,328:INFO:           interpret: Not installed
2023-10-24 09:47:47,328:INFO:                umap: Not installed
2023-10-24 09:47:47,328:INFO:     ydata_profiling: Not installed
2023-10-24 09:47:47,328:INFO:  explainerdashboard: Not installed
2023-10-24 09:47:47,328:INFO:             autoviz: Not installed
2023-10-24 09:47:47,328:INFO:           fairlearn: Not installed
2023-10-24 09:47:47,328:INFO:          deepchecks: Not installed
2023-10-24 09:47:47,328:INFO:             xgboost: Not installed
2023-10-24 09:47:47,328:INFO:            catboost: 1.2.2
2023-10-24 09:47:47,328:INFO:              kmodes: Not installed
2023-10-24 09:47:47,328:INFO:             mlxtend: Not installed
2023-10-24 09:47:47,328:INFO:       statsforecast: Not installed
2023-10-24 09:47:47,328:INFO:        tune_sklearn: Not installed
2023-10-24 09:47:47,328:INFO:                 ray: Not installed
2023-10-24 09:47:47,328:INFO:            hyperopt: Not installed
2023-10-24 09:47:47,328:INFO:              optuna: Not installed
2023-10-24 09:47:47,328:INFO:               skopt: Not installed
2023-10-24 09:47:47,328:INFO:              mlflow: 2.7.1
2023-10-24 09:47:47,328:INFO:              gradio: Not installed
2023-10-24 09:47:47,328:INFO:             fastapi: Not installed
2023-10-24 09:47:47,328:INFO:             uvicorn: Not installed
2023-10-24 09:47:47,328:INFO:              m2cgen: Not installed
2023-10-24 09:47:47,328:INFO:           evidently: Not installed
2023-10-24 09:47:47,328:INFO:               fugue: Not installed
2023-10-24 09:47:47,328:INFO:           streamlit: Not installed
2023-10-24 09:47:47,328:INFO:             prophet: Not installed
2023-10-24 09:47:47,328:INFO:None
2023-10-24 09:47:47,328:INFO:Set up data.
2023-10-24 09:47:47,355:INFO:Set up folding strategy.
2023-10-24 09:47:47,355:INFO:Set up train/test split.
2023-10-24 09:47:47,372:INFO:Set up index.
2023-10-24 09:47:47,372:INFO:Assigning column types.
2023-10-24 09:47:47,401:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 09:47:47,542:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:47:47,543:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:47:47,681:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:47:47,681:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:47:47,682:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 09:47:47,804:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:47:47,819:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:47:47,956:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:47:47,956:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:47:47,957:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 09:47:48,093:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:47:48,094:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:47:48,229:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:47:48,229:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:47:48,229:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 09:47:48,373:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:47:48,374:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:47:48,511:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:47:48,511:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:47:48,511:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 09:47:48,653:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:47:48,654:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:47:48,791:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:47:48,791:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:47:48,792:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 09:47:48,927:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:47:48,928:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:47:49,061:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:47:49,061:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:47:49,061:INFO:Preparing preprocessing pipeline...
2023-10-24 09:47:49,061:INFO:Set up date feature engineering.
2023-10-24 09:47:49,061:INFO:Set up simple imputation.
2023-10-24 09:47:49,078:INFO:Set up encoding of ordinal features.
2023-10-24 09:47:49,091:INFO:Set up encoding of categorical features.
2023-10-24 09:47:49,091:INFO:Set up variance threshold.
2023-10-24 09:47:49,094:INFO:Set up column name cleaning.
2023-10-24 09:47:49,403:INFO:Finished creating preprocessing pipeline.
2023-10-24 09:47:49,461:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 09:47:49,461:INFO:Creating final display dataframe.
2023-10-24 09:47:49,603:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (34061, 48)
4        Transformed data shape  (34061, 37)
5   Transformed train set shape  (23842, 37)
6    Transformed test set shape  (10219, 37)
7              Ordinal features            2
8              Numeric features           43
9                 Date features            1
10         Categorical features            3
11     Rows with missing values        97.6%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18       Low variance threshold         0.05
19               Fold Generator        KFold
20                  Fold Number           10
21                     CPU Jobs           -1
22                      Use GPU        False
23               Log Experiment        False
24              Experiment Name        exp_A
25                          USI         83d3
2023-10-24 09:47:49,743:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:47:49,744:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:47:49,876:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:47:49,876:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:47:49,876:INFO:setup() successfully completed in 2.56s...............
2023-10-24 09:51:36,594:INFO:PyCaret RegressionExperiment
2023-10-24 09:51:36,594:INFO:Logging name: exp_A
2023-10-24 09:51:36,594:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 09:51:36,594:INFO:version 3.1.0
2023-10-24 09:51:36,594:INFO:Initializing setup()
2023-10-24 09:51:36,594:INFO:self.USI: 6de0
2023-10-24 09:51:36,594:INFO:self._variable_keys: {'logging_param', 'pipeline', '_ml_usecase', 'X_test', 'memory', 'y_test', 'n_jobs_param', 'exp_name_log', 'y', 'transform_target_param', 'fold_groups_param', 'gpu_param', 'seed', 'html_param', 'USI', 'data', 'y_train', 'gpu_n_jobs_param', 'X_train', 'X', 'fold_shuffle_param', '_available_plots', 'target_param', 'exp_id', 'idx', 'log_plots_param', 'fold_generator'}
2023-10-24 09:51:36,594:INFO:Checking environment
2023-10-24 09:51:36,594:INFO:python_version: 3.8.18
2023-10-24 09:51:36,594:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-24 09:51:36,600:INFO:machine: AMD64
2023-10-24 09:51:36,600:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-24 09:51:36,601:INFO:Memory: svmem(total=16505954304, available=7531614208, percent=54.4, used=8974340096, free=7531614208)
2023-10-24 09:51:36,601:INFO:Physical Core: 8
2023-10-24 09:51:36,602:INFO:Logical Core: 16
2023-10-24 09:51:36,602:INFO:Checking libraries
2023-10-24 09:51:36,602:INFO:System:
2023-10-24 09:51:36,603:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-24 09:51:36,603:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-24 09:51:36,603:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-24 09:51:36,603:INFO:PyCaret required dependencies:
2023-10-24 09:51:36,604:INFO:                 pip: 23.3
2023-10-24 09:51:36,605:INFO:          setuptools: 68.0.0
2023-10-24 09:51:36,605:INFO:             pycaret: 3.1.0
2023-10-24 09:51:36,605:INFO:             IPython: 8.12.0
2023-10-24 09:51:36,605:INFO:          ipywidgets: 8.1.1
2023-10-24 09:51:36,605:INFO:                tqdm: 4.66.1
2023-10-24 09:51:36,607:INFO:               numpy: 1.23.5
2023-10-24 09:51:36,607:INFO:              pandas: 1.5.3
2023-10-24 09:51:36,608:INFO:              jinja2: 3.1.2
2023-10-24 09:51:36,608:INFO:               scipy: 1.10.1
2023-10-24 09:51:36,608:INFO:              joblib: 1.3.2
2023-10-24 09:51:36,608:INFO:             sklearn: 1.2.2
2023-10-24 09:51:36,609:INFO:                pyod: 1.1.0
2023-10-24 09:51:36,609:INFO:            imblearn: 0.11.0
2023-10-24 09:51:36,610:INFO:   category_encoders: 2.6.2
2023-10-24 09:51:36,610:INFO:            lightgbm: 4.1.0
2023-10-24 09:51:36,610:INFO:               numba: 0.58.1
2023-10-24 09:51:36,610:INFO:            requests: 2.31.0
2023-10-24 09:51:36,610:INFO:          matplotlib: 3.7.3
2023-10-24 09:51:36,610:INFO:          scikitplot: 0.3.7
2023-10-24 09:51:36,610:INFO:         yellowbrick: 1.5
2023-10-24 09:51:36,610:INFO:              plotly: 5.17.0
2023-10-24 09:51:36,614:INFO:    plotly-resampler: Not installed
2023-10-24 09:51:36,614:INFO:             kaleido: 0.2.1
2023-10-24 09:51:36,614:INFO:           schemdraw: 0.15
2023-10-24 09:51:36,614:INFO:         statsmodels: 0.14.0
2023-10-24 09:51:36,614:INFO:              sktime: 0.21.1
2023-10-24 09:51:36,615:INFO:               tbats: 1.1.3
2023-10-24 09:51:36,615:INFO:            pmdarima: 2.0.3
2023-10-24 09:51:36,615:INFO:              psutil: 5.9.0
2023-10-24 09:51:36,616:INFO:          markupsafe: 2.1.3
2023-10-24 09:51:36,616:INFO:             pickle5: Not installed
2023-10-24 09:51:36,616:INFO:         cloudpickle: 2.2.1
2023-10-24 09:51:36,616:INFO:         deprecation: 2.1.0
2023-10-24 09:51:36,616:INFO:              xxhash: 3.4.1
2023-10-24 09:51:36,616:INFO:           wurlitzer: Not installed
2023-10-24 09:51:36,616:INFO:PyCaret optional dependencies:
2023-10-24 09:51:36,616:INFO:                shap: Not installed
2023-10-24 09:51:36,616:INFO:           interpret: Not installed
2023-10-24 09:51:36,616:INFO:                umap: Not installed
2023-10-24 09:51:36,616:INFO:     ydata_profiling: Not installed
2023-10-24 09:51:36,616:INFO:  explainerdashboard: Not installed
2023-10-24 09:51:36,617:INFO:             autoviz: Not installed
2023-10-24 09:51:36,617:INFO:           fairlearn: Not installed
2023-10-24 09:51:36,617:INFO:          deepchecks: Not installed
2023-10-24 09:51:36,617:INFO:             xgboost: Not installed
2023-10-24 09:51:36,617:INFO:            catboost: 1.2.2
2023-10-24 09:51:36,617:INFO:              kmodes: Not installed
2023-10-24 09:51:36,617:INFO:             mlxtend: Not installed
2023-10-24 09:51:36,617:INFO:       statsforecast: Not installed
2023-10-24 09:51:36,617:INFO:        tune_sklearn: Not installed
2023-10-24 09:51:36,617:INFO:                 ray: Not installed
2023-10-24 09:51:36,617:INFO:            hyperopt: Not installed
2023-10-24 09:51:36,617:INFO:              optuna: Not installed
2023-10-24 09:51:36,617:INFO:               skopt: Not installed
2023-10-24 09:51:36,617:INFO:              mlflow: 2.7.1
2023-10-24 09:51:36,617:INFO:              gradio: Not installed
2023-10-24 09:51:36,617:INFO:             fastapi: Not installed
2023-10-24 09:51:36,617:INFO:             uvicorn: Not installed
2023-10-24 09:51:36,618:INFO:              m2cgen: Not installed
2023-10-24 09:51:36,618:INFO:           evidently: Not installed
2023-10-24 09:51:36,618:INFO:               fugue: Not installed
2023-10-24 09:51:36,618:INFO:           streamlit: Not installed
2023-10-24 09:51:36,618:INFO:             prophet: Not installed
2023-10-24 09:51:36,618:INFO:None
2023-10-24 09:51:36,618:INFO:Set up data.
2023-10-24 09:51:36,657:INFO:Set up folding strategy.
2023-10-24 09:51:36,657:INFO:Set up train/test split.
2023-10-24 09:51:36,678:INFO:Set up index.
2023-10-24 09:51:36,679:INFO:Assigning column types.
2023-10-24 09:51:36,700:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 09:51:36,835:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:51:36,835:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:51:36,971:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:51:36,971:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:51:36,971:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 09:51:37,115:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:51:37,115:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:51:37,249:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:51:37,249:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:51:37,249:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 09:51:37,386:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:51:37,386:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:51:37,515:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:51:37,515:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:51:37,515:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 09:51:37,655:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:51:37,656:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:51:37,789:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:51:37,789:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:51:37,789:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 09:51:37,916:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:51:37,916:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:51:38,064:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:51:38,065:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:51:38,065:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 09:51:38,199:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:51:38,200:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:51:38,337:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:51:38,337:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:51:38,337:INFO:Preparing preprocessing pipeline...
2023-10-24 09:51:38,337:INFO:Set up date feature engineering.
2023-10-24 09:51:38,337:INFO:Set up simple imputation.
2023-10-24 09:51:38,350:INFO:Set up encoding of ordinal features.
2023-10-24 09:51:38,356:INFO:Set up encoding of categorical features.
2023-10-24 09:51:38,356:INFO:Set up variance threshold.
2023-10-24 09:51:38,366:INFO:Set up column name cleaning.
2023-10-24 09:51:38,648:INFO:Finished creating preprocessing pipeline.
2023-10-24 09:51:38,698:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 09:51:38,698:INFO:Creating final display dataframe.
2023-10-24 09:51:38,837:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (34061, 48)
4        Transformed data shape  (34061, 37)
5   Transformed train set shape  (23842, 37)
6    Transformed test set shape  (10219, 37)
7              Ordinal features            2
8              Numeric features           43
9                 Date features            1
10         Categorical features            3
11     Rows with missing values        97.6%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18       Low variance threshold         0.05
19               Fold Generator        KFold
20                  Fold Number           10
21                     CPU Jobs           -1
22                      Use GPU        False
23               Log Experiment        False
24              Experiment Name        exp_A
25                          USI         6de0
2023-10-24 09:51:38,964:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:51:38,964:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:51:39,114:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:51:39,116:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:51:39,116:INFO:setup() successfully completed in 2.53s...............
2023-10-24 09:53:39,374:INFO:PyCaret RegressionExperiment
2023-10-24 09:53:39,375:INFO:Logging name: exp_A
2023-10-24 09:53:39,376:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 09:53:39,376:INFO:version 3.1.0
2023-10-24 09:53:39,376:INFO:Initializing setup()
2023-10-24 09:53:39,376:INFO:self.USI: 70ed
2023-10-24 09:53:39,377:INFO:self._variable_keys: {'logging_param', 'pipeline', '_ml_usecase', 'X_test', 'memory', 'y_test', 'n_jobs_param', 'exp_name_log', 'y', 'transform_target_param', 'fold_groups_param', 'gpu_param', 'seed', 'html_param', 'USI', 'data', 'y_train', 'gpu_n_jobs_param', 'X_train', 'X', 'fold_shuffle_param', '_available_plots', 'target_param', 'exp_id', 'idx', 'log_plots_param', 'fold_generator'}
2023-10-24 09:53:39,377:INFO:Checking environment
2023-10-24 09:53:39,377:INFO:python_version: 3.8.18
2023-10-24 09:53:39,378:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-24 09:53:39,378:INFO:machine: AMD64
2023-10-24 09:53:39,378:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-24 09:53:39,379:INFO:Memory: svmem(total=16505954304, available=7727190016, percent=53.2, used=8778764288, free=7727190016)
2023-10-24 09:53:39,379:INFO:Physical Core: 8
2023-10-24 09:53:39,380:INFO:Logical Core: 16
2023-10-24 09:53:39,380:INFO:Checking libraries
2023-10-24 09:53:39,381:INFO:System:
2023-10-24 09:53:39,381:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-24 09:53:39,381:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-24 09:53:39,382:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-24 09:53:39,382:INFO:PyCaret required dependencies:
2023-10-24 09:53:39,382:INFO:                 pip: 23.3
2023-10-24 09:53:39,383:INFO:          setuptools: 68.0.0
2023-10-24 09:53:39,383:INFO:             pycaret: 3.1.0
2023-10-24 09:53:39,383:INFO:             IPython: 8.12.0
2023-10-24 09:53:39,383:INFO:          ipywidgets: 8.1.1
2023-10-24 09:53:39,383:INFO:                tqdm: 4.66.1
2023-10-24 09:53:39,383:INFO:               numpy: 1.23.5
2023-10-24 09:53:39,383:INFO:              pandas: 1.5.3
2023-10-24 09:53:39,383:INFO:              jinja2: 3.1.2
2023-10-24 09:53:39,383:INFO:               scipy: 1.10.1
2023-10-24 09:53:39,383:INFO:              joblib: 1.3.2
2023-10-24 09:53:39,383:INFO:             sklearn: 1.2.2
2023-10-24 09:53:39,383:INFO:                pyod: 1.1.0
2023-10-24 09:53:39,383:INFO:            imblearn: 0.11.0
2023-10-24 09:53:39,383:INFO:   category_encoders: 2.6.2
2023-10-24 09:53:39,383:INFO:            lightgbm: 4.1.0
2023-10-24 09:53:39,383:INFO:               numba: 0.58.1
2023-10-24 09:53:39,383:INFO:            requests: 2.31.0
2023-10-24 09:53:39,383:INFO:          matplotlib: 3.7.3
2023-10-24 09:53:39,383:INFO:          scikitplot: 0.3.7
2023-10-24 09:53:39,383:INFO:         yellowbrick: 1.5
2023-10-24 09:53:39,383:INFO:              plotly: 5.17.0
2023-10-24 09:53:39,384:INFO:    plotly-resampler: Not installed
2023-10-24 09:53:39,384:INFO:             kaleido: 0.2.1
2023-10-24 09:53:39,384:INFO:           schemdraw: 0.15
2023-10-24 09:53:39,384:INFO:         statsmodels: 0.14.0
2023-10-24 09:53:39,384:INFO:              sktime: 0.21.1
2023-10-24 09:53:39,384:INFO:               tbats: 1.1.3
2023-10-24 09:53:39,384:INFO:            pmdarima: 2.0.3
2023-10-24 09:53:39,384:INFO:              psutil: 5.9.0
2023-10-24 09:53:39,384:INFO:          markupsafe: 2.1.3
2023-10-24 09:53:39,384:INFO:             pickle5: Not installed
2023-10-24 09:53:39,384:INFO:         cloudpickle: 2.2.1
2023-10-24 09:53:39,384:INFO:         deprecation: 2.1.0
2023-10-24 09:53:39,384:INFO:              xxhash: 3.4.1
2023-10-24 09:53:39,384:INFO:           wurlitzer: Not installed
2023-10-24 09:53:39,384:INFO:PyCaret optional dependencies:
2023-10-24 09:53:39,384:INFO:                shap: Not installed
2023-10-24 09:53:39,384:INFO:           interpret: Not installed
2023-10-24 09:53:39,384:INFO:                umap: Not installed
2023-10-24 09:53:39,384:INFO:     ydata_profiling: Not installed
2023-10-24 09:53:39,384:INFO:  explainerdashboard: Not installed
2023-10-24 09:53:39,384:INFO:             autoviz: Not installed
2023-10-24 09:53:39,385:INFO:           fairlearn: Not installed
2023-10-24 09:53:39,385:INFO:          deepchecks: Not installed
2023-10-24 09:53:39,385:INFO:             xgboost: Not installed
2023-10-24 09:53:39,386:INFO:            catboost: 1.2.2
2023-10-24 09:53:39,386:INFO:              kmodes: Not installed
2023-10-24 09:53:39,386:INFO:             mlxtend: Not installed
2023-10-24 09:53:39,386:INFO:       statsforecast: Not installed
2023-10-24 09:53:39,386:INFO:        tune_sklearn: Not installed
2023-10-24 09:53:39,386:INFO:                 ray: Not installed
2023-10-24 09:53:39,386:INFO:            hyperopt: Not installed
2023-10-24 09:53:39,386:INFO:              optuna: Not installed
2023-10-24 09:53:39,386:INFO:               skopt: Not installed
2023-10-24 09:53:39,386:INFO:              mlflow: 2.7.1
2023-10-24 09:53:39,386:INFO:              gradio: Not installed
2023-10-24 09:53:39,386:INFO:             fastapi: Not installed
2023-10-24 09:53:39,386:INFO:             uvicorn: Not installed
2023-10-24 09:53:39,386:INFO:              m2cgen: Not installed
2023-10-24 09:53:39,386:INFO:           evidently: Not installed
2023-10-24 09:53:39,386:INFO:               fugue: Not installed
2023-10-24 09:53:39,386:INFO:           streamlit: Not installed
2023-10-24 09:53:39,386:INFO:             prophet: Not installed
2023-10-24 09:53:39,386:INFO:None
2023-10-24 09:53:39,386:INFO:Set up data.
2023-10-24 09:53:39,424:INFO:Set up folding strategy.
2023-10-24 09:53:39,424:INFO:Set up train/test split.
2023-10-24 09:53:39,438:INFO:Set up index.
2023-10-24 09:53:39,447:INFO:Assigning column types.
2023-10-24 09:53:39,466:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 09:53:39,599:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:53:39,599:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:53:39,747:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:53:39,747:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:53:39,747:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 09:53:39,897:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:53:39,897:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:53:40,035:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:53:40,035:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:53:40,037:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 09:53:40,165:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:53:40,165:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:53:40,298:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:53:40,298:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:53:40,298:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 09:53:40,439:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:53:40,439:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:53:40,580:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:53:40,580:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:53:40,580:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 09:53:40,718:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:53:40,718:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:53:40,852:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:53:40,852:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:53:40,852:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 09:53:40,984:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:53:40,984:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:53:41,117:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:53:41,117:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:53:41,117:INFO:Preparing preprocessing pipeline...
2023-10-24 09:53:41,117:INFO:Set up date feature engineering.
2023-10-24 09:53:41,117:INFO:Set up simple imputation.
2023-10-24 09:53:41,136:INFO:Set up encoding of ordinal features.
2023-10-24 09:53:41,152:INFO:Set up encoding of categorical features.
2023-10-24 09:53:41,152:INFO:Set up variance threshold.
2023-10-24 09:53:41,152:INFO:Set up column name cleaning.
2023-10-24 09:53:41,445:INFO:Finished creating preprocessing pipeline.
2023-10-24 09:53:41,496:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 09:53:41,496:INFO:Creating final display dataframe.
2023-10-24 09:53:41,630:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (34061, 48)
4        Transformed data shape  (34061, 37)
5   Transformed train set shape  (23842, 37)
6    Transformed test set shape  (10219, 37)
7              Ordinal features            2
8              Numeric features           43
9                 Date features            1
10         Categorical features            3
11     Rows with missing values        97.6%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18       Low variance threshold         0.05
19               Fold Generator        KFold
20                  Fold Number           10
21                     CPU Jobs           -1
22                      Use GPU        False
23               Log Experiment        False
24              Experiment Name        exp_A
25                          USI         70ed
2023-10-24 09:53:41,763:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:53:41,763:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:53:41,896:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:53:41,896:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:53:41,911:INFO:setup() successfully completed in 2.56s...............
2023-10-24 09:53:58,499:INFO:PyCaret RegressionExperiment
2023-10-24 09:53:58,499:INFO:Logging name: exp_A
2023-10-24 09:53:58,499:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 09:53:58,499:INFO:version 3.1.0
2023-10-24 09:53:58,499:INFO:Initializing setup()
2023-10-24 09:53:58,499:INFO:self.USI: 3804
2023-10-24 09:53:58,499:INFO:self._variable_keys: {'logging_param', 'pipeline', '_ml_usecase', 'X_test', 'memory', 'y_test', 'n_jobs_param', 'exp_name_log', 'y', 'transform_target_param', 'fold_groups_param', 'gpu_param', 'seed', 'html_param', 'USI', 'data', 'y_train', 'gpu_n_jobs_param', 'X_train', 'X', 'fold_shuffle_param', '_available_plots', 'target_param', 'exp_id', 'idx', 'log_plots_param', 'fold_generator'}
2023-10-24 09:53:58,499:INFO:Checking environment
2023-10-24 09:53:58,499:INFO:python_version: 3.8.18
2023-10-24 09:53:58,499:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-24 09:53:58,499:INFO:machine: AMD64
2023-10-24 09:53:58,499:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-24 09:53:58,499:INFO:Memory: svmem(total=16505954304, available=7656284160, percent=53.6, used=8849670144, free=7656284160)
2023-10-24 09:53:58,499:INFO:Physical Core: 8
2023-10-24 09:53:58,499:INFO:Logical Core: 16
2023-10-24 09:53:58,499:INFO:Checking libraries
2023-10-24 09:53:58,499:INFO:System:
2023-10-24 09:53:58,499:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-24 09:53:58,499:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-24 09:53:58,499:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-24 09:53:58,499:INFO:PyCaret required dependencies:
2023-10-24 09:53:58,499:INFO:                 pip: 23.3
2023-10-24 09:53:58,499:INFO:          setuptools: 68.0.0
2023-10-24 09:53:58,499:INFO:             pycaret: 3.1.0
2023-10-24 09:53:58,499:INFO:             IPython: 8.12.0
2023-10-24 09:53:58,499:INFO:          ipywidgets: 8.1.1
2023-10-24 09:53:58,499:INFO:                tqdm: 4.66.1
2023-10-24 09:53:58,499:INFO:               numpy: 1.23.5
2023-10-24 09:53:58,499:INFO:              pandas: 1.5.3
2023-10-24 09:53:58,499:INFO:              jinja2: 3.1.2
2023-10-24 09:53:58,499:INFO:               scipy: 1.10.1
2023-10-24 09:53:58,499:INFO:              joblib: 1.3.2
2023-10-24 09:53:58,499:INFO:             sklearn: 1.2.2
2023-10-24 09:53:58,499:INFO:                pyod: 1.1.0
2023-10-24 09:53:58,499:INFO:            imblearn: 0.11.0
2023-10-24 09:53:58,499:INFO:   category_encoders: 2.6.2
2023-10-24 09:53:58,499:INFO:            lightgbm: 4.1.0
2023-10-24 09:53:58,499:INFO:               numba: 0.58.1
2023-10-24 09:53:58,499:INFO:            requests: 2.31.0
2023-10-24 09:53:58,499:INFO:          matplotlib: 3.7.3
2023-10-24 09:53:58,499:INFO:          scikitplot: 0.3.7
2023-10-24 09:53:58,499:INFO:         yellowbrick: 1.5
2023-10-24 09:53:58,499:INFO:              plotly: 5.17.0
2023-10-24 09:53:58,499:INFO:    plotly-resampler: Not installed
2023-10-24 09:53:58,499:INFO:             kaleido: 0.2.1
2023-10-24 09:53:58,499:INFO:           schemdraw: 0.15
2023-10-24 09:53:58,499:INFO:         statsmodels: 0.14.0
2023-10-24 09:53:58,499:INFO:              sktime: 0.21.1
2023-10-24 09:53:58,499:INFO:               tbats: 1.1.3
2023-10-24 09:53:58,499:INFO:            pmdarima: 2.0.3
2023-10-24 09:53:58,499:INFO:              psutil: 5.9.0
2023-10-24 09:53:58,499:INFO:          markupsafe: 2.1.3
2023-10-24 09:53:58,499:INFO:             pickle5: Not installed
2023-10-24 09:53:58,499:INFO:         cloudpickle: 2.2.1
2023-10-24 09:53:58,499:INFO:         deprecation: 2.1.0
2023-10-24 09:53:58,499:INFO:              xxhash: 3.4.1
2023-10-24 09:53:58,499:INFO:           wurlitzer: Not installed
2023-10-24 09:53:58,499:INFO:PyCaret optional dependencies:
2023-10-24 09:53:58,499:INFO:                shap: Not installed
2023-10-24 09:53:58,499:INFO:           interpret: Not installed
2023-10-24 09:53:58,499:INFO:                umap: Not installed
2023-10-24 09:53:58,499:INFO:     ydata_profiling: Not installed
2023-10-24 09:53:58,499:INFO:  explainerdashboard: Not installed
2023-10-24 09:53:58,499:INFO:             autoviz: Not installed
2023-10-24 09:53:58,499:INFO:           fairlearn: Not installed
2023-10-24 09:53:58,499:INFO:          deepchecks: Not installed
2023-10-24 09:53:58,499:INFO:             xgboost: Not installed
2023-10-24 09:53:58,499:INFO:            catboost: 1.2.2
2023-10-24 09:53:58,499:INFO:              kmodes: Not installed
2023-10-24 09:53:58,499:INFO:             mlxtend: Not installed
2023-10-24 09:53:58,499:INFO:       statsforecast: Not installed
2023-10-24 09:53:58,499:INFO:        tune_sklearn: Not installed
2023-10-24 09:53:58,499:INFO:                 ray: Not installed
2023-10-24 09:53:58,499:INFO:            hyperopt: Not installed
2023-10-24 09:53:58,499:INFO:              optuna: Not installed
2023-10-24 09:53:58,499:INFO:               skopt: Not installed
2023-10-24 09:53:58,499:INFO:              mlflow: 2.7.1
2023-10-24 09:53:58,499:INFO:              gradio: Not installed
2023-10-24 09:53:58,499:INFO:             fastapi: Not installed
2023-10-24 09:53:58,499:INFO:             uvicorn: Not installed
2023-10-24 09:53:58,499:INFO:              m2cgen: Not installed
2023-10-24 09:53:58,499:INFO:           evidently: Not installed
2023-10-24 09:53:58,499:INFO:               fugue: Not installed
2023-10-24 09:53:58,499:INFO:           streamlit: Not installed
2023-10-24 09:53:58,499:INFO:             prophet: Not installed
2023-10-24 09:53:58,499:INFO:None
2023-10-24 09:53:58,499:INFO:Set up data.
2023-10-24 09:53:58,532:INFO:Set up folding strategy.
2023-10-24 09:53:58,532:INFO:Set up train/test split.
2023-10-24 09:53:58,563:INFO:Set up index.
2023-10-24 09:53:58,565:INFO:Assigning column types.
2023-10-24 09:53:58,583:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 09:53:58,721:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:53:58,721:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:53:58,859:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:53:58,859:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:53:58,860:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 09:53:58,984:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:53:58,984:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:53:59,131:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:53:59,132:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:53:59,132:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 09:53:59,265:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:53:59,265:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:53:59,398:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:53:59,398:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:53:59,398:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 09:53:59,537:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:53:59,538:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:53:59,672:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:53:59,672:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:53:59,672:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 09:53:59,798:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:53:59,798:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:53:59,947:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:53:59,947:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:53:59,948:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 09:54:00,089:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:54:00,089:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:54:00,234:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:54:00,235:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:54:00,236:INFO:Preparing preprocessing pipeline...
2023-10-24 09:54:00,236:INFO:Set up date feature engineering.
2023-10-24 09:54:00,236:INFO:Set up simple imputation.
2023-10-24 09:54:00,246:INFO:Set up encoding of ordinal features.
2023-10-24 09:54:00,260:INFO:Set up encoding of categorical features.
2023-10-24 09:54:00,260:INFO:Set up variance threshold.
2023-10-24 09:54:00,263:INFO:Set up column name cleaning.
2023-10-24 09:54:00,563:INFO:Finished creating preprocessing pipeline.
2023-10-24 09:54:00,621:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 09:54:00,621:INFO:Creating final display dataframe.
2023-10-24 09:54:00,759:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (34061, 48)
4        Transformed data shape  (34061, 37)
5   Transformed train set shape  (23842, 37)
6    Transformed test set shape  (10219, 37)
7              Ordinal features            2
8              Numeric features           43
9                 Date features            1
10         Categorical features            3
11     Rows with missing values        97.6%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18       Low variance threshold         0.05
19               Fold Generator        KFold
20                  Fold Number           10
21                     CPU Jobs           -1
22                      Use GPU        False
23               Log Experiment        False
24              Experiment Name        exp_A
25                          USI         3804
2023-10-24 09:54:00,901:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:54:00,901:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:54:01,038:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 09:54:01,038:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 09:54:01,046:INFO:setup() successfully completed in 2.55s...............
2023-10-24 10:27:54,192:INFO:PyCaret RegressionExperiment
2023-10-24 10:27:54,193:INFO:Logging name: exp_A
2023-10-24 10:27:54,193:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 10:27:54,194:INFO:version 3.1.0
2023-10-24 10:27:54,194:INFO:Initializing setup()
2023-10-24 10:27:54,195:INFO:self.USI: e821
2023-10-24 10:27:54,196:INFO:self._variable_keys: {'logging_param', 'pipeline', '_ml_usecase', 'X_test', 'memory', 'y_test', 'n_jobs_param', 'exp_name_log', 'y', 'transform_target_param', 'fold_groups_param', 'gpu_param', 'seed', 'html_param', 'USI', 'data', 'y_train', 'gpu_n_jobs_param', 'X_train', 'X', 'fold_shuffle_param', '_available_plots', 'target_param', 'exp_id', 'idx', 'log_plots_param', 'fold_generator'}
2023-10-24 10:27:54,196:INFO:Checking environment
2023-10-24 10:27:54,196:INFO:python_version: 3.8.18
2023-10-24 10:27:54,196:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-24 10:27:54,197:INFO:machine: AMD64
2023-10-24 10:27:54,197:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-24 10:27:54,197:INFO:Memory: svmem(total=16505954304, available=6824189952, percent=58.7, used=9681764352, free=6824189952)
2023-10-24 10:27:54,197:INFO:Physical Core: 8
2023-10-24 10:27:54,198:INFO:Logical Core: 16
2023-10-24 10:27:54,198:INFO:Checking libraries
2023-10-24 10:27:54,198:INFO:System:
2023-10-24 10:27:54,199:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-24 10:27:54,199:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-24 10:27:54,199:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-24 10:27:54,199:INFO:PyCaret required dependencies:
2023-10-24 10:27:54,200:INFO:                 pip: 23.3
2023-10-24 10:27:54,200:INFO:          setuptools: 68.0.0
2023-10-24 10:27:54,200:INFO:             pycaret: 3.1.0
2023-10-24 10:27:54,200:INFO:             IPython: 8.12.0
2023-10-24 10:27:54,201:INFO:          ipywidgets: 8.1.1
2023-10-24 10:27:54,201:INFO:                tqdm: 4.66.1
2023-10-24 10:27:54,202:INFO:               numpy: 1.23.5
2023-10-24 10:27:54,202:INFO:              pandas: 1.5.3
2023-10-24 10:27:54,203:INFO:              jinja2: 3.1.2
2023-10-24 10:27:54,203:INFO:               scipy: 1.10.1
2023-10-24 10:27:54,204:INFO:              joblib: 1.3.2
2023-10-24 10:27:54,204:INFO:             sklearn: 1.2.2
2023-10-24 10:27:54,204:INFO:                pyod: 1.1.0
2023-10-24 10:27:54,204:INFO:            imblearn: 0.11.0
2023-10-24 10:27:54,204:INFO:   category_encoders: 2.6.2
2023-10-24 10:27:54,204:INFO:            lightgbm: 4.1.0
2023-10-24 10:27:54,204:INFO:               numba: 0.58.1
2023-10-24 10:27:54,204:INFO:            requests: 2.31.0
2023-10-24 10:27:54,204:INFO:          matplotlib: 3.7.3
2023-10-24 10:27:54,204:INFO:          scikitplot: 0.3.7
2023-10-24 10:27:54,204:INFO:         yellowbrick: 1.5
2023-10-24 10:27:54,204:INFO:              plotly: 5.17.0
2023-10-24 10:27:54,205:INFO:    plotly-resampler: Not installed
2023-10-24 10:27:54,205:INFO:             kaleido: 0.2.1
2023-10-24 10:27:54,205:INFO:           schemdraw: 0.15
2023-10-24 10:27:54,205:INFO:         statsmodels: 0.14.0
2023-10-24 10:27:54,205:INFO:              sktime: 0.21.1
2023-10-24 10:27:54,205:INFO:               tbats: 1.1.3
2023-10-24 10:27:54,205:INFO:            pmdarima: 2.0.3
2023-10-24 10:27:54,205:INFO:              psutil: 5.9.0
2023-10-24 10:27:54,205:INFO:          markupsafe: 2.1.3
2023-10-24 10:27:54,205:INFO:             pickle5: Not installed
2023-10-24 10:27:54,205:INFO:         cloudpickle: 2.2.1
2023-10-24 10:27:54,205:INFO:         deprecation: 2.1.0
2023-10-24 10:27:54,205:INFO:              xxhash: 3.4.1
2023-10-24 10:27:54,205:INFO:           wurlitzer: Not installed
2023-10-24 10:27:54,205:INFO:PyCaret optional dependencies:
2023-10-24 10:27:54,205:INFO:                shap: Not installed
2023-10-24 10:27:54,205:INFO:           interpret: Not installed
2023-10-24 10:27:54,205:INFO:                umap: Not installed
2023-10-24 10:27:54,205:INFO:     ydata_profiling: Not installed
2023-10-24 10:27:54,206:INFO:  explainerdashboard: Not installed
2023-10-24 10:27:54,206:INFO:             autoviz: Not installed
2023-10-24 10:27:54,206:INFO:           fairlearn: Not installed
2023-10-24 10:27:54,206:INFO:          deepchecks: Not installed
2023-10-24 10:27:54,206:INFO:             xgboost: Not installed
2023-10-24 10:27:54,206:INFO:            catboost: 1.2.2
2023-10-24 10:27:54,206:INFO:              kmodes: Not installed
2023-10-24 10:27:54,206:INFO:             mlxtend: Not installed
2023-10-24 10:27:54,206:INFO:       statsforecast: Not installed
2023-10-24 10:27:54,206:INFO:        tune_sklearn: Not installed
2023-10-24 10:27:54,206:INFO:                 ray: Not installed
2023-10-24 10:27:54,206:INFO:            hyperopt: Not installed
2023-10-24 10:27:54,206:INFO:              optuna: Not installed
2023-10-24 10:27:54,206:INFO:               skopt: Not installed
2023-10-24 10:27:54,206:INFO:              mlflow: 2.7.1
2023-10-24 10:27:54,206:INFO:              gradio: Not installed
2023-10-24 10:27:54,207:INFO:             fastapi: Not installed
2023-10-24 10:27:54,207:INFO:             uvicorn: Not installed
2023-10-24 10:27:54,207:INFO:              m2cgen: Not installed
2023-10-24 10:27:54,207:INFO:           evidently: Not installed
2023-10-24 10:27:54,207:INFO:               fugue: Not installed
2023-10-24 10:27:54,207:INFO:           streamlit: Not installed
2023-10-24 10:27:54,207:INFO:             prophet: Not installed
2023-10-24 10:27:54,207:INFO:None
2023-10-24 10:27:54,207:INFO:Set up data.
2023-10-24 10:27:54,255:INFO:Set up folding strategy.
2023-10-24 10:27:54,256:INFO:Set up train/test split.
2023-10-24 10:27:54,278:INFO:Set up index.
2023-10-24 10:27:54,280:INFO:Assigning column types.
2023-10-24 10:27:54,300:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 10:27:54,438:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:27:54,438:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:27:54,575:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:27:54,575:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:27:54,576:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 10:27:54,710:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:27:54,710:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:27:54,845:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:27:54,846:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:27:54,846:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 10:27:54,982:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:27:54,983:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:27:55,118:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:27:55,118:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:27:55,119:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 10:27:55,254:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:27:55,254:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:27:55,389:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:27:55,389:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:27:55,390:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 10:27:55,525:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:27:55,525:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:27:55,660:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:27:55,660:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:27:55,661:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 10:27:55,796:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:27:55,796:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:27:55,931:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:27:55,932:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:27:55,933:INFO:Preparing preprocessing pipeline...
2023-10-24 10:27:55,933:INFO:Set up date feature engineering.
2023-10-24 10:27:55,933:INFO:Set up simple imputation.
2023-10-24 10:27:55,943:INFO:Set up encoding of ordinal features.
2023-10-24 10:27:55,954:INFO:Set up encoding of categorical features.
2023-10-24 10:27:55,956:INFO:Set up variance threshold.
2023-10-24 10:27:55,958:INFO:Set up column name cleaning.
2023-10-24 10:27:56,236:INFO:Finished creating preprocessing pipeline.
2023-10-24 10:27:56,293:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 10:27:56,293:INFO:Creating final display dataframe.
2023-10-24 10:27:56,424:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (34061, 48)
4        Transformed data shape  (34061, 37)
5   Transformed train set shape  (23842, 37)
6    Transformed test set shape  (10219, 37)
7              Ordinal features            2
8              Numeric features           43
9                 Date features            1
10         Categorical features            3
11     Rows with missing values        97.6%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18       Low variance threshold         0.05
19               Fold Generator        KFold
20                  Fold Number           10
21                     CPU Jobs           -1
22                      Use GPU        False
23               Log Experiment        False
24              Experiment Name        exp_A
25                          USI         e821
2023-10-24 10:27:56,561:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:27:56,561:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:27:56,697:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:27:56,697:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:27:56,698:INFO:setup() successfully completed in 2.51s...............
2023-10-24 10:27:56,706:INFO:Initializing predict_model()
2023-10-24 10:27:56,707:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CD5E6B20>, estimator=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CD5E6B20>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000166CEFB7280>)
2023-10-24 10:27:56,707:INFO:Checking exceptions
2023-10-24 10:27:56,707:INFO:Preloading libraries
2023-10-24 10:27:56,707:INFO:Set up data.
2023-10-24 10:27:56,727:INFO:Set up index.
2023-10-24 10:36:05,805:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_1136\798405805.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  a = merged_data_a.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 10:36:05,860:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_1136\798405805.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  b = merged_data_b.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 10:36:05,894:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_1136\798405805.py:3: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  c = merged_data_c.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 10:39:54,303:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_1136\1075571308.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  a = merged_data_a.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 10:39:54,344:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_1136\1075571308.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  b = merged_data_b.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 10:39:54,417:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_1136\1075571308.py:3: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  c = merged_data_c.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 10:39:54,454:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_1136\1075571308.py:21: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  X_test_a = X_test_estimated_a.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 10:39:54,454:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_1136\1075571308.py:22: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  X_test_b = X_test_estimated_b.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 10:39:54,471:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_1136\1075571308.py:23: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  X_test_c = X_test_estimated_c.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 10:40:52,637:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-24 10:42:08,548:INFO:PyCaret RegressionExperiment
2023-10-24 10:42:08,548:INFO:Logging name: exp_A
2023-10-24 10:42:08,548:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 10:42:08,548:INFO:version 3.1.0
2023-10-24 10:42:08,548:INFO:Initializing setup()
2023-10-24 10:42:08,548:INFO:self.USI: e52e
2023-10-24 10:42:08,548:INFO:self._variable_keys: {'seed', 'logging_param', 'html_param', 'USI', 'data', 'y_train', 'pipeline', '_ml_usecase', 'gpu_n_jobs_param', 'X_test', 'X_train', 'memory', 'X', 'y_test', 'fold_shuffle_param', 'n_jobs_param', 'exp_name_log', 'y', '_available_plots', 'target_param', 'exp_id', 'idx', 'transform_target_param', 'log_plots_param', 'fold_groups_param', 'gpu_param', 'fold_generator'}
2023-10-24 10:42:08,548:INFO:Checking environment
2023-10-24 10:42:08,548:INFO:python_version: 3.8.18
2023-10-24 10:42:08,548:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-24 10:42:08,548:INFO:machine: AMD64
2023-10-24 10:42:08,548:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-24 10:42:08,548:INFO:Memory: svmem(total=16505954304, available=6786338816, percent=58.9, used=9719615488, free=6786338816)
2023-10-24 10:42:08,548:INFO:Physical Core: 8
2023-10-24 10:42:08,548:INFO:Logical Core: 16
2023-10-24 10:42:08,548:INFO:Checking libraries
2023-10-24 10:42:08,548:INFO:System:
2023-10-24 10:42:08,548:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-24 10:42:08,548:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-24 10:42:08,548:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-24 10:42:08,548:INFO:PyCaret required dependencies:
2023-10-24 10:42:08,548:INFO:                 pip: 23.3
2023-10-24 10:42:08,548:INFO:          setuptools: 68.0.0
2023-10-24 10:42:08,548:INFO:             pycaret: 3.1.0
2023-10-24 10:42:08,548:INFO:             IPython: 8.12.0
2023-10-24 10:42:08,548:INFO:          ipywidgets: 8.1.1
2023-10-24 10:42:08,548:INFO:                tqdm: 4.66.1
2023-10-24 10:42:08,548:INFO:               numpy: 1.23.5
2023-10-24 10:42:08,548:INFO:              pandas: 1.5.3
2023-10-24 10:42:08,548:INFO:              jinja2: 3.1.2
2023-10-24 10:42:08,548:INFO:               scipy: 1.10.1
2023-10-24 10:42:08,548:INFO:              joblib: 1.3.2
2023-10-24 10:42:08,548:INFO:             sklearn: 1.2.2
2023-10-24 10:42:08,548:INFO:                pyod: 1.1.0
2023-10-24 10:42:08,555:INFO:            imblearn: 0.11.0
2023-10-24 10:42:08,555:INFO:   category_encoders: 2.6.2
2023-10-24 10:42:08,556:INFO:            lightgbm: 4.1.0
2023-10-24 10:42:08,556:INFO:               numba: 0.58.1
2023-10-24 10:42:08,556:INFO:            requests: 2.31.0
2023-10-24 10:42:08,556:INFO:          matplotlib: 3.7.3
2023-10-24 10:42:08,556:INFO:          scikitplot: 0.3.7
2023-10-24 10:42:08,557:INFO:         yellowbrick: 1.5
2023-10-24 10:42:08,557:INFO:              plotly: 5.17.0
2023-10-24 10:42:08,557:INFO:    plotly-resampler: Not installed
2023-10-24 10:42:08,557:INFO:             kaleido: 0.2.1
2023-10-24 10:42:08,557:INFO:           schemdraw: 0.15
2023-10-24 10:42:08,557:INFO:         statsmodels: 0.14.0
2023-10-24 10:42:08,557:INFO:              sktime: 0.21.1
2023-10-24 10:42:08,558:INFO:               tbats: 1.1.3
2023-10-24 10:42:08,558:INFO:            pmdarima: 2.0.3
2023-10-24 10:42:08,558:INFO:              psutil: 5.9.0
2023-10-24 10:42:08,558:INFO:          markupsafe: 2.1.3
2023-10-24 10:42:08,558:INFO:             pickle5: Not installed
2023-10-24 10:42:08,559:INFO:         cloudpickle: 2.2.1
2023-10-24 10:42:08,559:INFO:         deprecation: 2.1.0
2023-10-24 10:42:08,559:INFO:              xxhash: 3.4.1
2023-10-24 10:42:08,559:INFO:           wurlitzer: Not installed
2023-10-24 10:42:08,559:INFO:PyCaret optional dependencies:
2023-10-24 10:42:08,560:INFO:                shap: Not installed
2023-10-24 10:42:08,560:INFO:           interpret: Not installed
2023-10-24 10:42:08,560:INFO:                umap: Not installed
2023-10-24 10:42:08,560:INFO:     ydata_profiling: Not installed
2023-10-24 10:42:08,560:INFO:  explainerdashboard: Not installed
2023-10-24 10:42:08,560:INFO:             autoviz: Not installed
2023-10-24 10:42:08,560:INFO:           fairlearn: Not installed
2023-10-24 10:42:08,560:INFO:          deepchecks: Not installed
2023-10-24 10:42:08,560:INFO:             xgboost: Not installed
2023-10-24 10:42:08,560:INFO:            catboost: 1.2.2
2023-10-24 10:42:08,560:INFO:              kmodes: Not installed
2023-10-24 10:42:08,560:INFO:             mlxtend: Not installed
2023-10-24 10:42:08,560:INFO:       statsforecast: Not installed
2023-10-24 10:42:08,560:INFO:        tune_sklearn: Not installed
2023-10-24 10:42:08,560:INFO:                 ray: Not installed
2023-10-24 10:42:08,560:INFO:            hyperopt: Not installed
2023-10-24 10:42:08,560:INFO:              optuna: Not installed
2023-10-24 10:42:08,560:INFO:               skopt: Not installed
2023-10-24 10:42:08,560:INFO:              mlflow: 2.7.1
2023-10-24 10:42:08,560:INFO:              gradio: Not installed
2023-10-24 10:42:08,560:INFO:             fastapi: Not installed
2023-10-24 10:42:08,560:INFO:             uvicorn: Not installed
2023-10-24 10:42:08,560:INFO:              m2cgen: Not installed
2023-10-24 10:42:08,560:INFO:           evidently: Not installed
2023-10-24 10:42:08,560:INFO:               fugue: Not installed
2023-10-24 10:42:08,560:INFO:           streamlit: Not installed
2023-10-24 10:42:08,560:INFO:             prophet: Not installed
2023-10-24 10:42:08,560:INFO:None
2023-10-24 10:42:08,560:INFO:Set up data.
2023-10-24 10:42:08,592:INFO:Set up folding strategy.
2023-10-24 10:42:08,592:INFO:Set up train/test split.
2023-10-24 10:42:08,606:INFO:Set up index.
2023-10-24 10:42:08,606:INFO:Assigning column types.
2023-10-24 10:42:08,623:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 10:42:08,623:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 10:42:08,639:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 10:42:08,644:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 10:42:08,718:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:42:08,757:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:42:08,757:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:42:08,757:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:42:08,757:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 10:42:08,774:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 10:42:08,779:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 10:42:08,856:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:42:08,890:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:42:08,905:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:42:08,905:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:42:08,906:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 10:42:08,910:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 10:42:08,910:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 10:42:08,991:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:42:09,038:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:42:09,039:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:42:09,039:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:42:09,044:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 10:42:09,049:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 10:42:09,122:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:42:09,171:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:42:09,172:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:42:09,172:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:42:09,173:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 10:42:09,178:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 10:42:09,262:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:42:09,310:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:42:09,310:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:42:09,310:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:42:09,323:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 10:42:09,395:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:42:09,447:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:42:09,447:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:42:09,447:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:42:09,447:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 10:42:09,535:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:42:09,572:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:42:09,572:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:42:09,572:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:42:09,672:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:42:09,727:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:42:09,727:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:42:09,727:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:42:09,727:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 10:42:09,805:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:42:09,856:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:42:09,856:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:42:09,946:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:42:09,994:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:42:09,994:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:42:09,994:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 10:42:10,126:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:42:10,126:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:42:10,276:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:42:10,276:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:42:10,277:INFO:Preparing preprocessing pipeline...
2023-10-24 10:42:10,278:INFO:Set up date feature engineering.
2023-10-24 10:42:10,278:INFO:Set up simple imputation.
2023-10-24 10:42:10,278:INFO:Set up encoding of ordinal features.
2023-10-24 10:42:10,294:INFO:Set up encoding of categorical features.
2023-10-24 10:42:10,294:INFO:Set up column name cleaning.
2023-10-24 10:42:10,544:INFO:Finished creating preprocessing pipeline.
2023-10-24 10:42:10,603:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 10:42:10,603:INFO:Creating final display dataframe.
2023-10-24 10:42:11,271:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (34061, 48)
4        Transformed data shape  (34061, 52)
5   Transformed train set shape  (23842, 52)
6    Transformed test set shape  (10219, 52)
7              Ordinal features            2
8              Numeric features           43
9                 Date features            1
10         Categorical features            3
11     Rows with missing values        97.6%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18               Fold Generator        KFold
19                  Fold Number           10
20                     CPU Jobs           -1
21                      Use GPU        False
22               Log Experiment        False
23              Experiment Name        exp_A
24                          USI         e52e
2023-10-24 10:42:11,409:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:42:11,409:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:42:11,542:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:42:11,542:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:42:11,542:INFO:setup() successfully completed in 3.0s...............
2023-10-24 10:42:11,542:INFO:Initializing compare_models()
2023-10-24 10:42:11,542:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CCDFA910>, include=['catboost', 'lightgbm'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000166CCDFA910>, 'include': ['catboost', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-10-24 10:42:11,542:INFO:Checking exceptions
2023-10-24 10:42:11,558:INFO:Preparing display monitor
2023-10-24 10:42:11,559:INFO:Initializing CatBoost Regressor
2023-10-24 10:42:11,559:INFO:Total runtime is 0.0 minutes
2023-10-24 10:42:11,559:INFO:SubProcess create_model() called ==================================
2023-10-24 10:42:11,559:INFO:Initializing create_model()
2023-10-24 10:42:11,559:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CCDFA910>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166D13E42E0>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 10:42:11,559:INFO:Checking exceptions
2023-10-24 10:42:11,559:INFO:Importing libraries
2023-10-24 10:42:11,559:INFO:Copying training dataset
2023-10-24 10:42:11,588:INFO:Defining folds
2023-10-24 10:42:11,589:INFO:Declaring metric variables
2023-10-24 10:42:11,589:INFO:Importing untrained model
2023-10-24 10:42:11,589:INFO:CatBoost Regressor Imported successfully
2023-10-24 10:42:11,589:INFO:Starting cross validation
2023-10-24 10:42:11,592:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 10:42:45,143:INFO:Calculating mean and std
2023-10-24 10:42:45,143:INFO:Creating metrics dataframe
2023-10-24 10:42:45,143:INFO:Uploading results into container
2023-10-24 10:42:45,143:INFO:Uploading model into container now
2023-10-24 10:42:45,143:INFO:_master_model_container: 1
2023-10-24 10:42:45,143:INFO:_display_container: 2
2023-10-24 10:42:45,143:INFO:<catboost.core.CatBoostRegressor object at 0x00000166CC63FBE0>
2023-10-24 10:42:45,143:INFO:create_model() successfully completed......................................
2023-10-24 10:42:45,293:INFO:SubProcess create_model() end ==================================
2023-10-24 10:42:45,293:INFO:Creating metrics dataframe
2023-10-24 10:42:45,293:INFO:Initializing Light Gradient Boosting Machine
2023-10-24 10:42:45,293:INFO:Total runtime is 0.5622382481892904 minutes
2023-10-24 10:42:45,293:INFO:SubProcess create_model() called ==================================
2023-10-24 10:42:45,293:INFO:Initializing create_model()
2023-10-24 10:42:45,293:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CCDFA910>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166D13E42E0>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 10:42:45,293:INFO:Checking exceptions
2023-10-24 10:42:45,293:INFO:Importing libraries
2023-10-24 10:42:45,293:INFO:Copying training dataset
2023-10-24 10:42:45,325:INFO:Defining folds
2023-10-24 10:42:45,326:INFO:Declaring metric variables
2023-10-24 10:42:45,326:INFO:Importing untrained model
2023-10-24 10:42:45,327:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 10:42:45,327:INFO:Starting cross validation
2023-10-24 10:42:45,329:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 10:42:52,071:INFO:Calculating mean and std
2023-10-24 10:42:52,073:INFO:Creating metrics dataframe
2023-10-24 10:42:52,073:INFO:Uploading results into container
2023-10-24 10:42:52,073:INFO:Uploading model into container now
2023-10-24 10:42:52,073:INFO:_master_model_container: 2
2023-10-24 10:42:52,073:INFO:_display_container: 2
2023-10-24 10:42:52,073:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 10:42:52,073:INFO:create_model() successfully completed......................................
2023-10-24 10:42:52,234:INFO:SubProcess create_model() end ==================================
2023-10-24 10:42:52,234:INFO:Creating metrics dataframe
2023-10-24 10:42:52,236:INFO:Initializing create_model()
2023-10-24 10:42:52,236:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CCDFA910>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 10:42:52,236:INFO:Checking exceptions
2023-10-24 10:42:52,236:INFO:Importing libraries
2023-10-24 10:42:52,236:INFO:Copying training dataset
2023-10-24 10:42:52,272:INFO:Defining folds
2023-10-24 10:42:52,272:INFO:Declaring metric variables
2023-10-24 10:42:52,273:INFO:Importing untrained model
2023-10-24 10:42:52,273:INFO:Declaring custom model
2023-10-24 10:42:52,273:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 10:42:52,275:INFO:Cross validation set to False
2023-10-24 10:42:52,275:INFO:Fitting Model
2023-10-24 10:42:52,517:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005781 seconds.
2023-10-24 10:42:52,517:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:42:52,517:INFO:[LightGBM] [Info] Total Bins 6408
2023-10-24 10:42:52,518:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 10:42:52,519:INFO:[LightGBM] [Info] Start training from score 616.864890
2023-10-24 10:42:52,693:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 10:42:52,694:INFO:create_model() successfully completed......................................
2023-10-24 10:42:52,857:INFO:_master_model_container: 2
2023-10-24 10:42:52,857:INFO:_display_container: 2
2023-10-24 10:42:52,857:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 10:42:52,857:INFO:compare_models() successfully completed......................................
2023-10-24 10:42:52,858:INFO:Initializing finalize_model()
2023-10-24 10:42:52,858:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CCDFA910>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-24 10:42:52,858:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 10:42:52,872:INFO:Initializing create_model()
2023-10-24 10:42:52,872:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CCDFA910>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-24 10:42:52,872:INFO:Checking exceptions
2023-10-24 10:42:52,873:INFO:Importing libraries
2023-10-24 10:42:52,873:INFO:Copying training dataset
2023-10-24 10:42:52,874:INFO:Defining folds
2023-10-24 10:42:52,874:INFO:Declaring metric variables
2023-10-24 10:42:52,875:INFO:Importing untrained model
2023-10-24 10:42:52,875:INFO:Declaring custom model
2023-10-24 10:42:52,876:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 10:42:52,877:INFO:Cross validation set to False
2023-10-24 10:42:52,877:INFO:Fitting Model
2023-10-24 10:42:53,207:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007410 seconds.
2023-10-24 10:42:53,208:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:42:53,208:INFO:[LightGBM] [Info] Total Bins 6836
2023-10-24 10:42:53,208:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 47
2023-10-24 10:42:53,210:INFO:[LightGBM] [Info] Start training from score 631.011165
2023-10-24 10:42:53,467:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 10:42:53,467:INFO:create_model() successfully completed......................................
2023-10-24 10:42:53,621:INFO:_master_model_container: 2
2023-10-24 10:42:53,623:INFO:_display_container: 2
2023-10-24 10:42:53,682:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 10:42:53,682:INFO:finalize_model() successfully completed......................................
2023-10-24 10:42:53,919:INFO:Initializing save_model()
2023-10-24 10:42:53,919:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_A, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-24 10:42:53,919:INFO:Adding model into prep_pipe
2023-10-24 10:42:53,919:WARNING:Only Model saved as it was a pipeline.
2023-10-24 10:42:53,935:INFO:final_model_for_location_A.pkl saved in current working directory
2023-10-24 10:42:54,038:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 10:42:54,038:INFO:save_model() successfully completed......................................
2023-10-24 10:42:54,191:INFO:PyCaret RegressionExperiment
2023-10-24 10:42:54,191:INFO:Logging name: exp_B
2023-10-24 10:42:54,191:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 10:42:54,191:INFO:version 3.1.0
2023-10-24 10:42:54,191:INFO:Initializing setup()
2023-10-24 10:42:54,191:INFO:self.USI: e054
2023-10-24 10:42:54,191:INFO:self._variable_keys: {'seed', 'logging_param', 'html_param', 'USI', 'data', 'y_train', 'pipeline', '_ml_usecase', 'gpu_n_jobs_param', 'X_test', 'X_train', 'memory', 'X', 'y_test', 'fold_shuffle_param', 'n_jobs_param', 'exp_name_log', 'y', '_available_plots', 'target_param', 'exp_id', 'idx', 'transform_target_param', 'log_plots_param', 'fold_groups_param', 'gpu_param', 'fold_generator'}
2023-10-24 10:42:54,191:INFO:Checking environment
2023-10-24 10:42:54,191:INFO:python_version: 3.8.18
2023-10-24 10:42:54,191:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-24 10:42:54,191:INFO:machine: AMD64
2023-10-24 10:42:54,191:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-24 10:42:54,191:INFO:Memory: svmem(total=16505954304, available=4531458048, percent=72.5, used=11974496256, free=4531458048)
2023-10-24 10:42:54,191:INFO:Physical Core: 8
2023-10-24 10:42:54,207:INFO:Logical Core: 16
2023-10-24 10:42:54,207:INFO:Checking libraries
2023-10-24 10:42:54,207:INFO:System:
2023-10-24 10:42:54,207:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-24 10:42:54,207:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-24 10:42:54,207:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-24 10:42:54,207:INFO:PyCaret required dependencies:
2023-10-24 10:42:54,207:INFO:                 pip: 23.3
2023-10-24 10:42:54,207:INFO:          setuptools: 68.0.0
2023-10-24 10:42:54,207:INFO:             pycaret: 3.1.0
2023-10-24 10:42:54,207:INFO:             IPython: 8.12.0
2023-10-24 10:42:54,207:INFO:          ipywidgets: 8.1.1
2023-10-24 10:42:54,207:INFO:                tqdm: 4.66.1
2023-10-24 10:42:54,207:INFO:               numpy: 1.23.5
2023-10-24 10:42:54,207:INFO:              pandas: 1.5.3
2023-10-24 10:42:54,207:INFO:              jinja2: 3.1.2
2023-10-24 10:42:54,207:INFO:               scipy: 1.10.1
2023-10-24 10:42:54,207:INFO:              joblib: 1.3.2
2023-10-24 10:42:54,207:INFO:             sklearn: 1.2.2
2023-10-24 10:42:54,207:INFO:                pyod: 1.1.0
2023-10-24 10:42:54,207:INFO:            imblearn: 0.11.0
2023-10-24 10:42:54,207:INFO:   category_encoders: 2.6.2
2023-10-24 10:42:54,207:INFO:            lightgbm: 4.1.0
2023-10-24 10:42:54,207:INFO:               numba: 0.58.1
2023-10-24 10:42:54,207:INFO:            requests: 2.31.0
2023-10-24 10:42:54,207:INFO:          matplotlib: 3.7.3
2023-10-24 10:42:54,207:INFO:          scikitplot: 0.3.7
2023-10-24 10:42:54,207:INFO:         yellowbrick: 1.5
2023-10-24 10:42:54,207:INFO:              plotly: 5.17.0
2023-10-24 10:42:54,207:INFO:    plotly-resampler: Not installed
2023-10-24 10:42:54,207:INFO:             kaleido: 0.2.1
2023-10-24 10:42:54,207:INFO:           schemdraw: 0.15
2023-10-24 10:42:54,207:INFO:         statsmodels: 0.14.0
2023-10-24 10:42:54,207:INFO:              sktime: 0.21.1
2023-10-24 10:42:54,207:INFO:               tbats: 1.1.3
2023-10-24 10:42:54,207:INFO:            pmdarima: 2.0.3
2023-10-24 10:42:54,207:INFO:              psutil: 5.9.0
2023-10-24 10:42:54,207:INFO:          markupsafe: 2.1.3
2023-10-24 10:42:54,207:INFO:             pickle5: Not installed
2023-10-24 10:42:54,207:INFO:         cloudpickle: 2.2.1
2023-10-24 10:42:54,210:INFO:         deprecation: 2.1.0
2023-10-24 10:42:54,210:INFO:              xxhash: 3.4.1
2023-10-24 10:42:54,210:INFO:           wurlitzer: Not installed
2023-10-24 10:42:54,210:INFO:PyCaret optional dependencies:
2023-10-24 10:42:54,210:INFO:                shap: Not installed
2023-10-24 10:42:54,210:INFO:           interpret: Not installed
2023-10-24 10:42:54,210:INFO:                umap: Not installed
2023-10-24 10:42:54,210:INFO:     ydata_profiling: Not installed
2023-10-24 10:42:54,210:INFO:  explainerdashboard: Not installed
2023-10-24 10:42:54,210:INFO:             autoviz: Not installed
2023-10-24 10:42:54,210:INFO:           fairlearn: Not installed
2023-10-24 10:42:54,210:INFO:          deepchecks: Not installed
2023-10-24 10:42:54,210:INFO:             xgboost: Not installed
2023-10-24 10:42:54,211:INFO:            catboost: 1.2.2
2023-10-24 10:42:54,211:INFO:              kmodes: Not installed
2023-10-24 10:42:54,211:INFO:             mlxtend: Not installed
2023-10-24 10:42:54,211:INFO:       statsforecast: Not installed
2023-10-24 10:42:54,211:INFO:        tune_sklearn: Not installed
2023-10-24 10:42:54,211:INFO:                 ray: Not installed
2023-10-24 10:42:54,211:INFO:            hyperopt: Not installed
2023-10-24 10:42:54,211:INFO:              optuna: Not installed
2023-10-24 10:42:54,211:INFO:               skopt: Not installed
2023-10-24 10:42:54,211:INFO:              mlflow: 2.7.1
2023-10-24 10:42:54,211:INFO:              gradio: Not installed
2023-10-24 10:42:54,211:INFO:             fastapi: Not installed
2023-10-24 10:42:54,211:INFO:             uvicorn: Not installed
2023-10-24 10:42:54,211:INFO:              m2cgen: Not installed
2023-10-24 10:42:54,211:INFO:           evidently: Not installed
2023-10-24 10:42:54,211:INFO:               fugue: Not installed
2023-10-24 10:42:54,211:INFO:           streamlit: Not installed
2023-10-24 10:42:54,211:INFO:             prophet: Not installed
2023-10-24 10:42:54,211:INFO:None
2023-10-24 10:42:54,211:INFO:Set up data.
2023-10-24 10:42:54,241:INFO:Set up folding strategy.
2023-10-24 10:42:54,241:INFO:Set up train/test split.
2023-10-24 10:42:54,260:INFO:Set up index.
2023-10-24 10:42:54,260:INFO:Assigning column types.
2023-10-24 10:42:54,278:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 10:42:54,278:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 10:42:54,284:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 10:42:54,289:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 10:42:54,366:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:42:54,416:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:42:54,417:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:42:54,417:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:42:54,418:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 10:42:54,423:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 10:42:54,428:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 10:42:54,504:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:42:54,549:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:42:54,549:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:42:54,549:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:42:54,549:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 10:42:54,549:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 10:42:54,564:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 10:42:54,642:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:42:54,692:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:42:54,692:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:42:54,692:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:42:54,698:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 10:42:54,703:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 10:42:54,780:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:42:54,829:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:42:54,830:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:42:54,830:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:42:54,830:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 10:42:54,840:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 10:42:54,916:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:42:54,966:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:42:54,967:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:42:54,967:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:42:54,979:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 10:42:55,054:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:42:55,104:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:42:55,105:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:42:55,105:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:42:55,106:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 10:42:55,193:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:42:55,243:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:42:55,244:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:42:55,244:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:42:55,336:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:42:55,386:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:42:55,386:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:42:55,386:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:42:55,387:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 10:42:55,473:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:42:55,521:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:42:55,521:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:42:55,596:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:42:55,659:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:42:55,659:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:42:55,659:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 10:42:55,794:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:42:55,795:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:42:55,936:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:42:55,936:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:42:55,936:INFO:Preparing preprocessing pipeline...
2023-10-24 10:42:55,936:INFO:Set up date feature engineering.
2023-10-24 10:42:55,936:INFO:Set up simple imputation.
2023-10-24 10:42:55,936:INFO:Set up encoding of ordinal features.
2023-10-24 10:42:55,951:INFO:Set up encoding of categorical features.
2023-10-24 10:42:55,951:INFO:Set up column name cleaning.
2023-10-24 10:42:56,199:INFO:Finished creating preprocessing pipeline.
2023-10-24 10:42:56,253:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 10:42:56,253:INFO:Creating final display dataframe.
2023-10-24 10:42:56,885:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (32819, 48)
4        Transformed data shape  (32819, 52)
5   Transformed train set shape  (22973, 52)
6    Transformed test set shape   (9846, 52)
7              Ordinal features            2
8              Numeric features           43
9                 Date features            1
10         Categorical features            3
11     Rows with missing values        95.9%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18               Fold Generator        KFold
19                  Fold Number           10
20                     CPU Jobs           -1
21                      Use GPU        False
22               Log Experiment        False
23              Experiment Name        exp_B
24                          USI         e054
2023-10-24 10:42:57,033:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:42:57,033:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:42:57,172:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:42:57,172:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:42:57,172:INFO:setup() successfully completed in 2.98s...............
2023-10-24 10:42:57,172:INFO:Initializing compare_models()
2023-10-24 10:42:57,172:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CCA4F880>, include=['catboost', 'lightgbm'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000166CCA4F880>, 'include': ['catboost', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-10-24 10:42:57,172:INFO:Checking exceptions
2023-10-24 10:42:57,184:INFO:Preparing display monitor
2023-10-24 10:42:57,188:INFO:Initializing CatBoost Regressor
2023-10-24 10:42:57,188:INFO:Total runtime is 0.0 minutes
2023-10-24 10:42:57,188:INFO:SubProcess create_model() called ==================================
2023-10-24 10:42:57,190:INFO:Initializing create_model()
2023-10-24 10:42:57,190:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CCA4F880>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166D0D942B0>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 10:42:57,190:INFO:Checking exceptions
2023-10-24 10:42:57,190:INFO:Importing libraries
2023-10-24 10:42:57,190:INFO:Copying training dataset
2023-10-24 10:42:57,213:INFO:Defining folds
2023-10-24 10:42:57,213:INFO:Declaring metric variables
2023-10-24 10:42:57,213:INFO:Importing untrained model
2023-10-24 10:42:57,213:INFO:CatBoost Regressor Imported successfully
2023-10-24 10:42:57,213:INFO:Starting cross validation
2023-10-24 10:42:57,215:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 10:43:24,348:INFO:Calculating mean and std
2023-10-24 10:43:24,348:INFO:Creating metrics dataframe
2023-10-24 10:43:24,348:INFO:Uploading results into container
2023-10-24 10:43:24,348:INFO:Uploading model into container now
2023-10-24 10:43:24,348:INFO:_master_model_container: 1
2023-10-24 10:43:24,348:INFO:_display_container: 2
2023-10-24 10:43:24,348:INFO:<catboost.core.CatBoostRegressor object at 0x00000166CD2A1370>
2023-10-24 10:43:24,348:INFO:create_model() successfully completed......................................
2023-10-24 10:43:24,477:INFO:SubProcess create_model() end ==================================
2023-10-24 10:43:24,477:INFO:Creating metrics dataframe
2023-10-24 10:43:24,494:INFO:Initializing Light Gradient Boosting Machine
2023-10-24 10:43:24,494:INFO:Total runtime is 0.45509251753489177 minutes
2023-10-24 10:43:24,494:INFO:SubProcess create_model() called ==================================
2023-10-24 10:43:24,494:INFO:Initializing create_model()
2023-10-24 10:43:24,494:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CCA4F880>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166D0D942B0>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 10:43:24,494:INFO:Checking exceptions
2023-10-24 10:43:24,494:INFO:Importing libraries
2023-10-24 10:43:24,494:INFO:Copying training dataset
2023-10-24 10:43:24,511:INFO:Defining folds
2023-10-24 10:43:24,511:INFO:Declaring metric variables
2023-10-24 10:43:24,511:INFO:Importing untrained model
2023-10-24 10:43:24,511:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 10:43:24,511:INFO:Starting cross validation
2023-10-24 10:43:24,511:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 10:43:27,145:INFO:Calculating mean and std
2023-10-24 10:43:27,148:INFO:Creating metrics dataframe
2023-10-24 10:43:27,150:INFO:Uploading results into container
2023-10-24 10:43:27,150:INFO:Uploading model into container now
2023-10-24 10:43:27,150:INFO:_master_model_container: 2
2023-10-24 10:43:27,150:INFO:_display_container: 2
2023-10-24 10:43:27,156:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 10:43:27,156:INFO:create_model() successfully completed......................................
2023-10-24 10:43:27,386:INFO:SubProcess create_model() end ==================================
2023-10-24 10:43:27,386:INFO:Creating metrics dataframe
2023-10-24 10:43:27,401:INFO:Initializing create_model()
2023-10-24 10:43:27,401:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CCA4F880>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 10:43:27,401:INFO:Checking exceptions
2023-10-24 10:43:27,401:INFO:Importing libraries
2023-10-24 10:43:27,401:INFO:Copying training dataset
2023-10-24 10:43:27,447:INFO:Defining folds
2023-10-24 10:43:27,447:INFO:Declaring metric variables
2023-10-24 10:43:27,447:INFO:Importing untrained model
2023-10-24 10:43:27,447:INFO:Declaring custom model
2023-10-24 10:43:27,450:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 10:43:27,454:INFO:Cross validation set to False
2023-10-24 10:43:27,454:INFO:Fitting Model
2023-10-24 10:43:27,756:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005227 seconds.
2023-10-24 10:43:27,757:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:43:27,757:INFO:[LightGBM] [Info] Total Bins 6444
2023-10-24 10:43:27,758:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 46
2023-10-24 10:43:27,759:INFO:[LightGBM] [Info] Start training from score 117.072182
2023-10-24 10:43:27,940:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 10:43:27,940:INFO:create_model() successfully completed......................................
2023-10-24 10:43:28,110:INFO:_master_model_container: 2
2023-10-24 10:43:28,110:INFO:_display_container: 2
2023-10-24 10:43:28,111:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 10:43:28,111:INFO:compare_models() successfully completed......................................
2023-10-24 10:43:28,111:INFO:Initializing finalize_model()
2023-10-24 10:43:28,111:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CCA4F880>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-24 10:43:28,111:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 10:43:28,125:INFO:Initializing create_model()
2023-10-24 10:43:28,125:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CCA4F880>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-24 10:43:28,126:INFO:Checking exceptions
2023-10-24 10:43:28,126:INFO:Importing libraries
2023-10-24 10:43:28,127:INFO:Copying training dataset
2023-10-24 10:43:28,128:INFO:Defining folds
2023-10-24 10:43:28,128:INFO:Declaring metric variables
2023-10-24 10:43:28,128:INFO:Importing untrained model
2023-10-24 10:43:28,128:INFO:Declaring custom model
2023-10-24 10:43:28,129:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 10:43:28,129:INFO:Cross validation set to False
2023-10-24 10:43:28,129:INFO:Fitting Model
2023-10-24 10:43:28,446:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006388 seconds.
2023-10-24 10:43:28,446:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:43:28,446:INFO:[LightGBM] [Info] Total Bins 6781
2023-10-24 10:43:28,446:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 47
2023-10-24 10:43:28,446:INFO:[LightGBM] [Info] Start training from score 96.893335
2023-10-24 10:43:28,739:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 10:43:28,739:INFO:create_model() successfully completed......................................
2023-10-24 10:43:28,885:INFO:_master_model_container: 2
2023-10-24 10:43:28,885:INFO:_display_container: 2
2023-10-24 10:43:28,940:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 10:43:28,940:INFO:finalize_model() successfully completed......................................
2023-10-24 10:43:29,190:INFO:Initializing save_model()
2023-10-24 10:43:29,190:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_B, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-24 10:43:29,190:INFO:Adding model into prep_pipe
2023-10-24 10:43:29,190:WARNING:Only Model saved as it was a pipeline.
2023-10-24 10:43:29,206:INFO:final_model_for_location_B.pkl saved in current working directory
2023-10-24 10:43:29,292:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 10:43:29,292:INFO:save_model() successfully completed......................................
2023-10-24 10:43:29,461:INFO:PyCaret RegressionExperiment
2023-10-24 10:43:29,461:INFO:Logging name: exp_C
2023-10-24 10:43:29,461:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 10:43:29,461:INFO:version 3.1.0
2023-10-24 10:43:29,461:INFO:Initializing setup()
2023-10-24 10:43:29,461:INFO:self.USI: 0358
2023-10-24 10:43:29,461:INFO:self._variable_keys: {'seed', 'logging_param', 'html_param', 'USI', 'data', 'y_train', 'pipeline', '_ml_usecase', 'gpu_n_jobs_param', 'X_test', 'X_train', 'memory', 'X', 'y_test', 'fold_shuffle_param', 'n_jobs_param', 'exp_name_log', 'y', '_available_plots', 'target_param', 'exp_id', 'idx', 'transform_target_param', 'log_plots_param', 'fold_groups_param', 'gpu_param', 'fold_generator'}
2023-10-24 10:43:29,461:INFO:Checking environment
2023-10-24 10:43:29,461:INFO:python_version: 3.8.18
2023-10-24 10:43:29,461:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-24 10:43:29,461:INFO:machine: AMD64
2023-10-24 10:43:29,461:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-24 10:43:29,461:INFO:Memory: svmem(total=16505954304, available=4549951488, percent=72.4, used=11956002816, free=4549951488)
2023-10-24 10:43:29,461:INFO:Physical Core: 8
2023-10-24 10:43:29,461:INFO:Logical Core: 16
2023-10-24 10:43:29,461:INFO:Checking libraries
2023-10-24 10:43:29,461:INFO:System:
2023-10-24 10:43:29,461:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-24 10:43:29,461:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-24 10:43:29,461:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-24 10:43:29,461:INFO:PyCaret required dependencies:
2023-10-24 10:43:29,461:INFO:                 pip: 23.3
2023-10-24 10:43:29,461:INFO:          setuptools: 68.0.0
2023-10-24 10:43:29,461:INFO:             pycaret: 3.1.0
2023-10-24 10:43:29,461:INFO:             IPython: 8.12.0
2023-10-24 10:43:29,461:INFO:          ipywidgets: 8.1.1
2023-10-24 10:43:29,461:INFO:                tqdm: 4.66.1
2023-10-24 10:43:29,461:INFO:               numpy: 1.23.5
2023-10-24 10:43:29,461:INFO:              pandas: 1.5.3
2023-10-24 10:43:29,461:INFO:              jinja2: 3.1.2
2023-10-24 10:43:29,461:INFO:               scipy: 1.10.1
2023-10-24 10:43:29,461:INFO:              joblib: 1.3.2
2023-10-24 10:43:29,461:INFO:             sklearn: 1.2.2
2023-10-24 10:43:29,461:INFO:                pyod: 1.1.0
2023-10-24 10:43:29,461:INFO:            imblearn: 0.11.0
2023-10-24 10:43:29,461:INFO:   category_encoders: 2.6.2
2023-10-24 10:43:29,461:INFO:            lightgbm: 4.1.0
2023-10-24 10:43:29,461:INFO:               numba: 0.58.1
2023-10-24 10:43:29,461:INFO:            requests: 2.31.0
2023-10-24 10:43:29,461:INFO:          matplotlib: 3.7.3
2023-10-24 10:43:29,461:INFO:          scikitplot: 0.3.7
2023-10-24 10:43:29,461:INFO:         yellowbrick: 1.5
2023-10-24 10:43:29,461:INFO:              plotly: 5.17.0
2023-10-24 10:43:29,461:INFO:    plotly-resampler: Not installed
2023-10-24 10:43:29,461:INFO:             kaleido: 0.2.1
2023-10-24 10:43:29,461:INFO:           schemdraw: 0.15
2023-10-24 10:43:29,461:INFO:         statsmodels: 0.14.0
2023-10-24 10:43:29,461:INFO:              sktime: 0.21.1
2023-10-24 10:43:29,461:INFO:               tbats: 1.1.3
2023-10-24 10:43:29,461:INFO:            pmdarima: 2.0.3
2023-10-24 10:43:29,461:INFO:              psutil: 5.9.0
2023-10-24 10:43:29,461:INFO:          markupsafe: 2.1.3
2023-10-24 10:43:29,461:INFO:             pickle5: Not installed
2023-10-24 10:43:29,461:INFO:         cloudpickle: 2.2.1
2023-10-24 10:43:29,461:INFO:         deprecation: 2.1.0
2023-10-24 10:43:29,461:INFO:              xxhash: 3.4.1
2023-10-24 10:43:29,461:INFO:           wurlitzer: Not installed
2023-10-24 10:43:29,461:INFO:PyCaret optional dependencies:
2023-10-24 10:43:29,461:INFO:                shap: Not installed
2023-10-24 10:43:29,461:INFO:           interpret: Not installed
2023-10-24 10:43:29,461:INFO:                umap: Not installed
2023-10-24 10:43:29,461:INFO:     ydata_profiling: Not installed
2023-10-24 10:43:29,461:INFO:  explainerdashboard: Not installed
2023-10-24 10:43:29,461:INFO:             autoviz: Not installed
2023-10-24 10:43:29,461:INFO:           fairlearn: Not installed
2023-10-24 10:43:29,461:INFO:          deepchecks: Not installed
2023-10-24 10:43:29,461:INFO:             xgboost: Not installed
2023-10-24 10:43:29,461:INFO:            catboost: 1.2.2
2023-10-24 10:43:29,461:INFO:              kmodes: Not installed
2023-10-24 10:43:29,461:INFO:             mlxtend: Not installed
2023-10-24 10:43:29,461:INFO:       statsforecast: Not installed
2023-10-24 10:43:29,461:INFO:        tune_sklearn: Not installed
2023-10-24 10:43:29,461:INFO:                 ray: Not installed
2023-10-24 10:43:29,461:INFO:            hyperopt: Not installed
2023-10-24 10:43:29,461:INFO:              optuna: Not installed
2023-10-24 10:43:29,461:INFO:               skopt: Not installed
2023-10-24 10:43:29,461:INFO:              mlflow: 2.7.1
2023-10-24 10:43:29,461:INFO:              gradio: Not installed
2023-10-24 10:43:29,461:INFO:             fastapi: Not installed
2023-10-24 10:43:29,461:INFO:             uvicorn: Not installed
2023-10-24 10:43:29,461:INFO:              m2cgen: Not installed
2023-10-24 10:43:29,461:INFO:           evidently: Not installed
2023-10-24 10:43:29,461:INFO:               fugue: Not installed
2023-10-24 10:43:29,461:INFO:           streamlit: Not installed
2023-10-24 10:43:29,461:INFO:             prophet: Not installed
2023-10-24 10:43:29,461:INFO:None
2023-10-24 10:43:29,461:INFO:Set up data.
2023-10-24 10:43:29,493:INFO:Set up folding strategy.
2023-10-24 10:43:29,494:INFO:Set up train/test split.
2023-10-24 10:43:29,510:INFO:Set up index.
2023-10-24 10:43:29,511:INFO:Assigning column types.
2023-10-24 10:43:29,526:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 10:43:29,526:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 10:43:29,531:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 10:43:29,536:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 10:43:29,608:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:43:29,658:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:43:29,658:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:43:29,658:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:43:29,658:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 10:43:29,658:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 10:43:29,658:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 10:43:29,743:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:43:29,789:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:43:29,789:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:43:29,789:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:43:29,789:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 10:43:29,789:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 10:43:29,804:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 10:43:29,873:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:43:29,920:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:43:29,936:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:43:29,936:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:43:29,936:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 10:43:29,936:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 10:43:30,011:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:43:30,060:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:43:30,060:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:43:30,060:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:43:30,060:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 10:43:30,075:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 10:43:30,154:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:43:30,205:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:43:30,208:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:43:30,208:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:43:30,212:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 10:43:30,292:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:43:30,340:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:43:30,340:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:43:30,340:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:43:30,340:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 10:43:30,424:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:43:30,471:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:43:30,471:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:43:30,471:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:43:30,555:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:43:30,608:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:43:30,608:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:43:30,608:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:43:30,608:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 10:43:30,687:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:43:30,741:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:43:30,741:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:43:30,825:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:43:30,887:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:43:30,887:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:43:30,887:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 10:43:31,022:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:43:31,022:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:43:31,157:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:43:31,157:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:43:31,157:INFO:Preparing preprocessing pipeline...
2023-10-24 10:43:31,157:INFO:Set up date feature engineering.
2023-10-24 10:43:31,157:INFO:Set up simple imputation.
2023-10-24 10:43:31,172:INFO:Set up encoding of ordinal features.
2023-10-24 10:43:31,172:INFO:Set up encoding of categorical features.
2023-10-24 10:43:31,172:INFO:Set up column name cleaning.
2023-10-24 10:43:31,394:INFO:Finished creating preprocessing pipeline.
2023-10-24 10:43:31,442:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 10:43:31,442:INFO:Creating final display dataframe.
2023-10-24 10:43:31,952:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (26071, 48)
4        Transformed data shape  (26071, 52)
5   Transformed train set shape  (18249, 52)
6    Transformed test set shape   (7822, 52)
7              Ordinal features            2
8              Numeric features           43
9                 Date features            1
10         Categorical features            3
11     Rows with missing values        95.9%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18               Fold Generator        KFold
19                  Fold Number           10
20                     CPU Jobs           -1
21                      Use GPU        False
22               Log Experiment        False
23              Experiment Name        exp_C
24                          USI         0358
2023-10-24 10:43:32,091:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:43:32,091:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:43:32,227:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:43:32,227:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:43:32,227:INFO:setup() successfully completed in 2.79s...............
2023-10-24 10:43:32,227:INFO:Initializing compare_models()
2023-10-24 10:43:32,227:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CC20F9A0>, include=['catboost', 'lightgbm'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000166CC20F9A0>, 'include': ['catboost', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-10-24 10:43:32,227:INFO:Checking exceptions
2023-10-24 10:43:32,238:INFO:Preparing display monitor
2023-10-24 10:43:32,241:INFO:Initializing CatBoost Regressor
2023-10-24 10:43:32,241:INFO:Total runtime is 0.0 minutes
2023-10-24 10:43:32,241:INFO:SubProcess create_model() called ==================================
2023-10-24 10:43:32,242:INFO:Initializing create_model()
2023-10-24 10:43:32,242:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CC20F9A0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166CBBF6880>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 10:43:32,242:INFO:Checking exceptions
2023-10-24 10:43:32,242:INFO:Importing libraries
2023-10-24 10:43:32,242:INFO:Copying training dataset
2023-10-24 10:43:32,263:INFO:Defining folds
2023-10-24 10:43:32,263:INFO:Declaring metric variables
2023-10-24 10:43:32,263:INFO:Importing untrained model
2023-10-24 10:43:32,264:INFO:CatBoost Regressor Imported successfully
2023-10-24 10:43:32,264:INFO:Starting cross validation
2023-10-24 10:43:32,265:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 10:43:58,782:INFO:Calculating mean and std
2023-10-24 10:43:58,783:INFO:Creating metrics dataframe
2023-10-24 10:43:58,787:INFO:Uploading results into container
2023-10-24 10:43:58,787:INFO:Uploading model into container now
2023-10-24 10:43:58,787:INFO:_master_model_container: 1
2023-10-24 10:43:58,787:INFO:_display_container: 2
2023-10-24 10:43:58,787:INFO:<catboost.core.CatBoostRegressor object at 0x00000166D0B9A250>
2023-10-24 10:43:58,787:INFO:create_model() successfully completed......................................
2023-10-24 10:43:58,916:INFO:SubProcess create_model() end ==================================
2023-10-24 10:43:58,916:INFO:Creating metrics dataframe
2023-10-24 10:43:58,930:INFO:Initializing Light Gradient Boosting Machine
2023-10-24 10:43:58,930:INFO:Total runtime is 0.4448193430900574 minutes
2023-10-24 10:43:58,930:INFO:SubProcess create_model() called ==================================
2023-10-24 10:43:58,930:INFO:Initializing create_model()
2023-10-24 10:43:58,930:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CC20F9A0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166CBBF6880>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 10:43:58,930:INFO:Checking exceptions
2023-10-24 10:43:58,931:INFO:Importing libraries
2023-10-24 10:43:58,931:INFO:Copying training dataset
2023-10-24 10:43:58,948:INFO:Defining folds
2023-10-24 10:43:58,948:INFO:Declaring metric variables
2023-10-24 10:43:58,948:INFO:Importing untrained model
2023-10-24 10:43:58,948:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 10:43:58,948:INFO:Starting cross validation
2023-10-24 10:43:58,948:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 10:44:01,595:INFO:Calculating mean and std
2023-10-24 10:44:01,596:INFO:Creating metrics dataframe
2023-10-24 10:44:01,596:INFO:Uploading results into container
2023-10-24 10:44:01,596:INFO:Uploading model into container now
2023-10-24 10:44:01,596:INFO:_master_model_container: 2
2023-10-24 10:44:01,596:INFO:_display_container: 2
2023-10-24 10:44:01,596:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 10:44:01,596:INFO:create_model() successfully completed......................................
2023-10-24 10:44:01,734:INFO:SubProcess create_model() end ==================================
2023-10-24 10:44:01,734:INFO:Creating metrics dataframe
2023-10-24 10:44:01,746:INFO:Initializing create_model()
2023-10-24 10:44:01,746:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CC20F9A0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 10:44:01,746:INFO:Checking exceptions
2023-10-24 10:44:01,746:INFO:Importing libraries
2023-10-24 10:44:01,746:INFO:Copying training dataset
2023-10-24 10:44:01,768:INFO:Defining folds
2023-10-24 10:44:01,768:INFO:Declaring metric variables
2023-10-24 10:44:01,768:INFO:Importing untrained model
2023-10-24 10:44:01,768:INFO:Declaring custom model
2023-10-24 10:44:01,768:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 10:44:01,768:INFO:Cross validation set to False
2023-10-24 10:44:01,768:INFO:Fitting Model
2023-10-24 10:44:01,962:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004317 seconds.
2023-10-24 10:44:01,962:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:44:01,962:INFO:[LightGBM] [Info] Total Bins 6598
2023-10-24 10:44:01,962:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 47
2023-10-24 10:44:01,962:INFO:[LightGBM] [Info] Start training from score 96.094131
2023-10-24 10:44:02,129:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 10:44:02,129:INFO:create_model() successfully completed......................................
2023-10-24 10:44:02,294:INFO:_master_model_container: 2
2023-10-24 10:44:02,294:INFO:_display_container: 2
2023-10-24 10:44:02,295:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 10:44:02,295:INFO:compare_models() successfully completed......................................
2023-10-24 10:44:02,295:INFO:Initializing finalize_model()
2023-10-24 10:44:02,295:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CC20F9A0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-24 10:44:02,296:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 10:44:02,303:INFO:Initializing create_model()
2023-10-24 10:44:02,303:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CC20F9A0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-24 10:44:02,303:INFO:Checking exceptions
2023-10-24 10:44:02,303:INFO:Importing libraries
2023-10-24 10:44:02,303:INFO:Copying training dataset
2023-10-24 10:44:02,303:INFO:Defining folds
2023-10-24 10:44:02,303:INFO:Declaring metric variables
2023-10-24 10:44:02,303:INFO:Importing untrained model
2023-10-24 10:44:02,303:INFO:Declaring custom model
2023-10-24 10:44:02,311:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 10:44:02,313:INFO:Cross validation set to False
2023-10-24 10:44:02,313:INFO:Fitting Model
2023-10-24 10:44:02,586:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005866 seconds.
2023-10-24 10:44:02,586:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:44:02,587:INFO:[LightGBM] [Info] Total Bins 6987
2023-10-24 10:44:02,587:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 48
2023-10-24 10:44:02,588:INFO:[LightGBM] [Info] Start training from score 77.700043
2023-10-24 10:44:02,866:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 10:44:02,866:INFO:create_model() successfully completed......................................
2023-10-24 10:44:03,013:INFO:_master_model_container: 2
2023-10-24 10:44:03,013:INFO:_display_container: 2
2023-10-24 10:44:03,071:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 10:44:03,071:INFO:finalize_model() successfully completed......................................
2023-10-24 10:44:03,315:INFO:Initializing save_model()
2023-10-24 10:44:03,315:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_C, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-24 10:44:03,315:INFO:Adding model into prep_pipe
2023-10-24 10:44:03,315:WARNING:Only Model saved as it was a pipeline.
2023-10-24 10:44:03,330:INFO:final_model_for_location_C.pkl saved in current working directory
2023-10-24 10:44:03,414:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 10:44:03,414:INFO:save_model() successfully completed......................................
2023-10-24 10:45:05,002:INFO:Initializing load_model()
2023-10-24 10:45:05,002:INFO:load_model(model_name=final_model_for_location_A, platform=None, authentication=None, verbose=True)
2023-10-24 10:45:05,022:INFO:Initializing load_model()
2023-10-24 10:45:05,022:INFO:load_model(model_name=final_model_for_location_B, platform=None, authentication=None, verbose=True)
2023-10-24 10:45:05,049:INFO:Initializing load_model()
2023-10-24 10:45:05,049:INFO:load_model(model_name=final_model_for_location_C, platform=None, authentication=None, verbose=True)
2023-10-24 10:45:05,185:INFO:Initializing predict_model()
2023-10-24 10:45:05,185:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CC20F9A0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000166D0B15E50>)
2023-10-24 10:45:05,185:INFO:Checking exceptions
2023-10-24 10:45:05,185:INFO:Preloading libraries
2023-10-24 10:45:05,185:INFO:Set up data.
2023-10-24 10:45:05,194:INFO:Set up index.
2023-10-24 10:45:05,462:INFO:Initializing predict_model()
2023-10-24 10:45:05,462:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CC20F9A0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000166D0B15E50>)
2023-10-24 10:45:05,462:INFO:Checking exceptions
2023-10-24 10:45:05,462:INFO:Preloading libraries
2023-10-24 10:45:05,462:INFO:Set up data.
2023-10-24 10:45:05,482:INFO:Set up index.
2023-10-24 10:45:05,743:INFO:Initializing predict_model()
2023-10-24 10:45:05,744:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CC20F9A0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000166D0B15E50>)
2023-10-24 10:45:05,744:INFO:Checking exceptions
2023-10-24 10:45:05,744:INFO:Preloading libraries
2023-10-24 10:45:05,744:INFO:Set up data.
2023-10-24 10:45:05,750:INFO:Set up index.
2023-10-24 10:47:17,155:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_1136\1075571308.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  a = merged_data_a.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 10:47:17,193:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_1136\1075571308.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  b = merged_data_b.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 10:47:17,224:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_1136\1075571308.py:3: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  c = merged_data_c.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 10:47:17,254:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_1136\1075571308.py:21: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  X_test_a = X_test_estimated_a.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 10:47:17,254:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_1136\1075571308.py:22: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  X_test_b = X_test_estimated_b.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 10:47:17,270:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_1136\1075571308.py:23: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  X_test_c = X_test_estimated_c.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 10:47:17,329:INFO:PyCaret RegressionExperiment
2023-10-24 10:47:17,329:INFO:Logging name: exp_A
2023-10-24 10:47:17,329:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 10:47:17,329:INFO:version 3.1.0
2023-10-24 10:47:17,329:INFO:Initializing setup()
2023-10-24 10:47:17,329:INFO:self.USI: 9026
2023-10-24 10:47:17,329:INFO:self._variable_keys: {'seed', 'logging_param', 'html_param', 'USI', 'data', 'y_train', 'pipeline', '_ml_usecase', 'gpu_n_jobs_param', 'X_test', 'X_train', 'memory', 'X', 'y_test', 'fold_shuffle_param', 'n_jobs_param', 'exp_name_log', 'y', '_available_plots', 'target_param', 'exp_id', 'idx', 'transform_target_param', 'log_plots_param', 'fold_groups_param', 'gpu_param', 'fold_generator'}
2023-10-24 10:47:17,329:INFO:Checking environment
2023-10-24 10:47:17,329:INFO:python_version: 3.8.18
2023-10-24 10:47:17,329:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-24 10:47:17,329:INFO:machine: AMD64
2023-10-24 10:47:17,329:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-24 10:47:17,329:INFO:Memory: svmem(total=16505954304, available=4144271360, percent=74.9, used=12361682944, free=4144271360)
2023-10-24 10:47:17,329:INFO:Physical Core: 8
2023-10-24 10:47:17,329:INFO:Logical Core: 16
2023-10-24 10:47:17,329:INFO:Checking libraries
2023-10-24 10:47:17,329:INFO:System:
2023-10-24 10:47:17,329:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-24 10:47:17,329:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-24 10:47:17,329:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-24 10:47:17,329:INFO:PyCaret required dependencies:
2023-10-24 10:47:17,329:INFO:                 pip: 23.3
2023-10-24 10:47:17,329:INFO:          setuptools: 68.0.0
2023-10-24 10:47:17,333:INFO:             pycaret: 3.1.0
2023-10-24 10:47:17,333:INFO:             IPython: 8.12.0
2023-10-24 10:47:17,333:INFO:          ipywidgets: 8.1.1
2023-10-24 10:47:17,333:INFO:                tqdm: 4.66.1
2023-10-24 10:47:17,333:INFO:               numpy: 1.23.5
2023-10-24 10:47:17,333:INFO:              pandas: 1.5.3
2023-10-24 10:47:17,333:INFO:              jinja2: 3.1.2
2023-10-24 10:47:17,333:INFO:               scipy: 1.10.1
2023-10-24 10:47:17,333:INFO:              joblib: 1.3.2
2023-10-24 10:47:17,333:INFO:             sklearn: 1.2.2
2023-10-24 10:47:17,333:INFO:                pyod: 1.1.0
2023-10-24 10:47:17,333:INFO:            imblearn: 0.11.0
2023-10-24 10:47:17,333:INFO:   category_encoders: 2.6.2
2023-10-24 10:47:17,333:INFO:            lightgbm: 4.1.0
2023-10-24 10:47:17,333:INFO:               numba: 0.58.1
2023-10-24 10:47:17,335:INFO:            requests: 2.31.0
2023-10-24 10:47:17,335:INFO:          matplotlib: 3.7.3
2023-10-24 10:47:17,335:INFO:          scikitplot: 0.3.7
2023-10-24 10:47:17,335:INFO:         yellowbrick: 1.5
2023-10-24 10:47:17,335:INFO:              plotly: 5.17.0
2023-10-24 10:47:17,335:INFO:    plotly-resampler: Not installed
2023-10-24 10:47:17,335:INFO:             kaleido: 0.2.1
2023-10-24 10:47:17,335:INFO:           schemdraw: 0.15
2023-10-24 10:47:17,335:INFO:         statsmodels: 0.14.0
2023-10-24 10:47:17,335:INFO:              sktime: 0.21.1
2023-10-24 10:47:17,335:INFO:               tbats: 1.1.3
2023-10-24 10:47:17,335:INFO:            pmdarima: 2.0.3
2023-10-24 10:47:17,335:INFO:              psutil: 5.9.0
2023-10-24 10:47:17,336:INFO:          markupsafe: 2.1.3
2023-10-24 10:47:17,336:INFO:             pickle5: Not installed
2023-10-24 10:47:17,336:INFO:         cloudpickle: 2.2.1
2023-10-24 10:47:17,336:INFO:         deprecation: 2.1.0
2023-10-24 10:47:17,336:INFO:              xxhash: 3.4.1
2023-10-24 10:47:17,336:INFO:           wurlitzer: Not installed
2023-10-24 10:47:17,336:INFO:PyCaret optional dependencies:
2023-10-24 10:47:17,336:INFO:                shap: Not installed
2023-10-24 10:47:17,336:INFO:           interpret: Not installed
2023-10-24 10:47:17,336:INFO:                umap: Not installed
2023-10-24 10:47:17,336:INFO:     ydata_profiling: Not installed
2023-10-24 10:47:17,336:INFO:  explainerdashboard: Not installed
2023-10-24 10:47:17,336:INFO:             autoviz: Not installed
2023-10-24 10:47:17,337:INFO:           fairlearn: Not installed
2023-10-24 10:47:17,337:INFO:          deepchecks: Not installed
2023-10-24 10:47:17,337:INFO:             xgboost: Not installed
2023-10-24 10:47:17,337:INFO:            catboost: 1.2.2
2023-10-24 10:47:17,337:INFO:              kmodes: Not installed
2023-10-24 10:47:17,337:INFO:             mlxtend: Not installed
2023-10-24 10:47:17,337:INFO:       statsforecast: Not installed
2023-10-24 10:47:17,337:INFO:        tune_sklearn: Not installed
2023-10-24 10:47:17,337:INFO:                 ray: Not installed
2023-10-24 10:47:17,337:INFO:            hyperopt: Not installed
2023-10-24 10:47:17,337:INFO:              optuna: Not installed
2023-10-24 10:47:17,337:INFO:               skopt: Not installed
2023-10-24 10:47:17,337:INFO:              mlflow: 2.7.1
2023-10-24 10:47:17,337:INFO:              gradio: Not installed
2023-10-24 10:47:17,338:INFO:             fastapi: Not installed
2023-10-24 10:47:17,338:INFO:             uvicorn: Not installed
2023-10-24 10:47:17,338:INFO:              m2cgen: Not installed
2023-10-24 10:47:17,338:INFO:           evidently: Not installed
2023-10-24 10:47:17,338:INFO:               fugue: Not installed
2023-10-24 10:47:17,338:INFO:           streamlit: Not installed
2023-10-24 10:47:17,338:INFO:             prophet: Not installed
2023-10-24 10:47:17,338:INFO:None
2023-10-24 10:47:17,338:INFO:Set up data.
2023-10-24 10:47:17,368:INFO:Set up folding strategy.
2023-10-24 10:47:17,368:INFO:Set up train/test split.
2023-10-24 10:47:17,392:INFO:Set up index.
2023-10-24 10:47:17,392:INFO:Assigning column types.
2023-10-24 10:47:17,421:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 10:47:17,422:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 10:47:17,430:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 10:47:17,434:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 10:47:17,513:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:47:17,562:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:47:17,562:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:47:17,563:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:47:17,563:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 10:47:17,568:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 10:47:17,573:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 10:47:17,647:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:47:17,690:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:47:17,690:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:47:17,690:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:47:17,690:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 10:47:17,704:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 10:47:17,704:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 10:47:17,785:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:47:17,834:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:47:17,835:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:47:17,835:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:47:17,837:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 10:47:17,837:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 10:47:17,919:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:47:17,970:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:47:17,970:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:47:17,970:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:47:17,970:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 10:47:17,983:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 10:47:18,051:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:47:18,101:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:47:18,101:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:47:18,101:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:47:18,119:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 10:47:18,184:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:47:18,242:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:47:18,242:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:47:18,242:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:47:18,242:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 10:47:18,333:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:47:18,370:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:47:18,370:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:47:18,383:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:47:18,469:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:47:18,525:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:47:18,525:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:47:18,526:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:47:18,526:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 10:47:18,603:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:47:18,650:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:47:18,650:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:47:18,749:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:47:18,789:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:47:18,789:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:47:18,789:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 10:47:18,934:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:47:18,934:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:47:19,067:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:47:19,067:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:47:19,067:INFO:Preparing preprocessing pipeline...
2023-10-24 10:47:19,067:INFO:Set up date feature engineering.
2023-10-24 10:47:19,067:INFO:Set up simple imputation.
2023-10-24 10:47:19,067:INFO:Set up encoding of ordinal features.
2023-10-24 10:47:19,084:INFO:Set up encoding of categorical features.
2023-10-24 10:47:19,084:INFO:Set up column name cleaning.
2023-10-24 10:47:19,350:INFO:Finished creating preprocessing pipeline.
2023-10-24 10:47:19,404:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 10:47:19,404:INFO:Creating final display dataframe.
2023-10-24 10:47:19,549:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (34061, 48)
4        Transformed data shape  (34061, 52)
5   Transformed train set shape  (23842, 52)
6    Transformed test set shape  (10219, 52)
7              Ordinal features            2
8              Numeric features           43
9                 Date features            1
10         Categorical features            3
11     Rows with missing values        97.6%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18               Fold Generator        KFold
19                  Fold Number           10
20                     CPU Jobs           -1
21                      Use GPU        False
22               Log Experiment        False
23              Experiment Name        exp_A
24                          USI         9026
2023-10-24 10:47:19,688:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:47:19,688:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:47:19,832:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:47:19,832:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:47:19,833:INFO:setup() successfully completed in 2.51s...............
2023-10-24 10:47:19,833:INFO:Initializing compare_models()
2023-10-24 10:47:19,833:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CF42D670>, include=['lightgbm'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000166CF42D670>, 'include': ['lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-10-24 10:47:19,833:INFO:Checking exceptions
2023-10-24 10:47:19,842:INFO:Preparing display monitor
2023-10-24 10:47:19,846:INFO:Initializing Light Gradient Boosting Machine
2023-10-24 10:47:19,847:INFO:Total runtime is 1.701513926188151e-05 minutes
2023-10-24 10:47:19,847:INFO:SubProcess create_model() called ==================================
2023-10-24 10:47:19,847:INFO:Initializing create_model()
2023-10-24 10:47:19,847:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CF42D670>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166CD22D100>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 10:47:19,847:INFO:Checking exceptions
2023-10-24 10:47:19,847:INFO:Importing libraries
2023-10-24 10:47:19,847:INFO:Copying training dataset
2023-10-24 10:47:19,873:INFO:Defining folds
2023-10-24 10:47:19,873:INFO:Declaring metric variables
2023-10-24 10:47:19,874:INFO:Importing untrained model
2023-10-24 10:47:19,874:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 10:47:19,874:INFO:Starting cross validation
2023-10-24 10:47:19,876:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 10:47:23,314:INFO:Calculating mean and std
2023-10-24 10:47:23,314:INFO:Creating metrics dataframe
2023-10-24 10:47:23,314:INFO:Uploading results into container
2023-10-24 10:47:23,314:INFO:Uploading model into container now
2023-10-24 10:47:23,314:INFO:_master_model_container: 1
2023-10-24 10:47:23,314:INFO:_display_container: 2
2023-10-24 10:47:23,314:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 10:47:23,314:INFO:create_model() successfully completed......................................
2023-10-24 10:47:23,485:INFO:SubProcess create_model() end ==================================
2023-10-24 10:47:23,485:INFO:Creating metrics dataframe
2023-10-24 10:47:23,493:INFO:Initializing create_model()
2023-10-24 10:47:23,493:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CF42D670>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 10:47:23,493:INFO:Checking exceptions
2023-10-24 10:47:23,494:INFO:Importing libraries
2023-10-24 10:47:23,494:INFO:Copying training dataset
2023-10-24 10:47:23,519:INFO:Defining folds
2023-10-24 10:47:23,519:INFO:Declaring metric variables
2023-10-24 10:47:23,519:INFO:Importing untrained model
2023-10-24 10:47:23,519:INFO:Declaring custom model
2023-10-24 10:47:23,520:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 10:47:23,521:INFO:Cross validation set to False
2023-10-24 10:47:23,522:INFO:Fitting Model
2023-10-24 10:47:23,765:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004352 seconds.
2023-10-24 10:47:23,765:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:47:23,765:INFO:[LightGBM] [Info] Total Bins 6408
2023-10-24 10:47:23,765:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 10:47:23,778:INFO:[LightGBM] [Info] Start training from score 616.864890
2023-10-24 10:47:23,964:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 10:47:23,965:INFO:create_model() successfully completed......................................
2023-10-24 10:47:24,131:INFO:_master_model_container: 1
2023-10-24 10:47:24,131:INFO:_display_container: 2
2023-10-24 10:47:24,131:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 10:47:24,131:INFO:compare_models() successfully completed......................................
2023-10-24 10:47:24,132:INFO:Initializing tune_model()
2023-10-24 10:47:24,132:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CF42D670>)
2023-10-24 10:47:24,132:INFO:Checking exceptions
2023-10-24 10:47:24,133:INFO:Copying training dataset
2023-10-24 10:47:24,148:INFO:Checking base model
2023-10-24 10:47:24,148:INFO:Base model : Light Gradient Boosting Machine
2023-10-24 10:47:24,148:INFO:Declaring metric variables
2023-10-24 10:47:24,148:INFO:Defining Hyperparameters
2023-10-24 10:47:24,299:INFO:Tuning with n_jobs=-1
2023-10-24 10:47:24,299:INFO:Initializing RandomizedSearchCV
2023-10-24 10:48:05,428:INFO:best_params: {'actual_estimator__reg_lambda': 0.1, 'actual_estimator__reg_alpha': 0.0001, 'actual_estimator__num_leaves': 10, 'actual_estimator__n_estimators': 180, 'actual_estimator__min_split_gain': 0.7, 'actual_estimator__min_child_samples': 96, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__feature_fraction': 0.9, 'actual_estimator__bagging_freq': 4, 'actual_estimator__bagging_fraction': 0.6}
2023-10-24 10:48:05,428:INFO:Hyperparameter search completed
2023-10-24 10:48:05,428:INFO:SubProcess create_model() called ==================================
2023-10-24 10:48:05,428:INFO:Initializing create_model()
2023-10-24 10:48:05,428:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CF42D670>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166D07309A0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 0.1, 'reg_alpha': 0.0001, 'num_leaves': 10, 'n_estimators': 180, 'min_split_gain': 0.7, 'min_child_samples': 96, 'learning_rate': 0.05, 'feature_fraction': 0.9, 'bagging_freq': 4, 'bagging_fraction': 0.6})
2023-10-24 10:48:05,428:INFO:Checking exceptions
2023-10-24 10:48:05,428:INFO:Importing libraries
2023-10-24 10:48:05,428:INFO:Copying training dataset
2023-10-24 10:48:05,460:INFO:Defining folds
2023-10-24 10:48:05,460:INFO:Declaring metric variables
2023-10-24 10:48:05,460:INFO:Importing untrained model
2023-10-24 10:48:05,460:INFO:Declaring custom model
2023-10-24 10:48:05,460:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 10:48:05,460:INFO:Starting cross validation
2023-10-24 10:48:05,460:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 10:48:07,976:INFO:Calculating mean and std
2023-10-24 10:48:07,976:INFO:Creating metrics dataframe
2023-10-24 10:48:07,976:INFO:Finalizing model
2023-10-24 10:48:08,212:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:48:08,212:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:48:08,212:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:48:08,228:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:48:08,228:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:48:08,228:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:48:08,243:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004027 seconds.
2023-10-24 10:48:08,243:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:48:08,243:INFO:[LightGBM] [Info] Total Bins 6400
2023-10-24 10:48:08,243:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-24 10:48:08,243:INFO:[LightGBM] [Info] Start training from score 616.864890
2023-10-24 10:48:08,401:INFO:Uploading results into container
2023-10-24 10:48:08,401:INFO:Uploading model into container now
2023-10-24 10:48:08,408:INFO:_master_model_container: 2
2023-10-24 10:48:08,408:INFO:_display_container: 3
2023-10-24 10:48:08,408:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9,
              learning_rate=0.05, min_child_samples=96, min_split_gain=0.7,
              n_estimators=180, n_jobs=-1, num_leaves=10, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.1)
2023-10-24 10:48:08,408:INFO:create_model() successfully completed......................................
2023-10-24 10:48:08,558:INFO:SubProcess create_model() end ==================================
2023-10-24 10:48:08,558:INFO:choose_better activated
2023-10-24 10:48:08,558:INFO:SubProcess create_model() called ==================================
2023-10-24 10:48:08,558:INFO:Initializing create_model()
2023-10-24 10:48:08,558:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CF42D670>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 10:48:08,558:INFO:Checking exceptions
2023-10-24 10:48:08,558:INFO:Importing libraries
2023-10-24 10:48:08,558:INFO:Copying training dataset
2023-10-24 10:48:08,574:INFO:Defining folds
2023-10-24 10:48:08,574:INFO:Declaring metric variables
2023-10-24 10:48:08,574:INFO:Importing untrained model
2023-10-24 10:48:08,574:INFO:Declaring custom model
2023-10-24 10:48:08,574:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 10:48:08,574:INFO:Starting cross validation
2023-10-24 10:48:08,574:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 10:48:11,075:INFO:Calculating mean and std
2023-10-24 10:48:11,075:INFO:Creating metrics dataframe
2023-10-24 10:48:11,075:INFO:Finalizing model
2023-10-24 10:48:11,328:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004892 seconds.
2023-10-24 10:48:11,328:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:48:11,328:INFO:[LightGBM] [Info] Total Bins 6408
2023-10-24 10:48:11,328:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 10:48:11,328:INFO:[LightGBM] [Info] Start training from score 616.864890
2023-10-24 10:48:11,475:INFO:Uploading results into container
2023-10-24 10:48:11,475:INFO:Uploading model into container now
2023-10-24 10:48:11,475:INFO:_master_model_container: 3
2023-10-24 10:48:11,475:INFO:_display_container: 4
2023-10-24 10:48:11,475:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 10:48:11,475:INFO:create_model() successfully completed......................................
2023-10-24 10:48:11,632:INFO:SubProcess create_model() end ==================================
2023-10-24 10:48:11,632:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.7469
2023-10-24 10:48:11,632:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9,
              learning_rate=0.05, min_child_samples=96, min_split_gain=0.7,
              n_estimators=180, n_jobs=-1, num_leaves=10, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.1) result for R2 is 0.746
2023-10-24 10:48:11,632:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-24 10:48:11,632:INFO:choose_better completed
2023-10-24 10:48:11,632:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-24 10:48:11,648:INFO:_master_model_container: 3
2023-10-24 10:48:11,648:INFO:_display_container: 3
2023-10-24 10:48:11,648:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 10:48:11,648:INFO:tune_model() successfully completed......................................
2023-10-24 10:48:11,773:INFO:Initializing ensemble_model()
2023-10-24 10:48:11,773:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CF42D670>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=True, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-24 10:48:11,773:INFO:Checking exceptions
2023-10-24 10:48:11,789:INFO:Importing libraries
2023-10-24 10:48:11,789:INFO:Copying training dataset
2023-10-24 10:48:11,789:INFO:Checking base model
2023-10-24 10:48:11,789:INFO:Base model : Light Gradient Boosting Machine
2023-10-24 10:48:11,789:INFO:Importing untrained ensembler
2023-10-24 10:48:11,789:INFO:Ensemble method set to Bagging
2023-10-24 10:48:11,789:INFO:SubProcess create_model() called ==================================
2023-10-24 10:48:11,789:INFO:Initializing create_model()
2023-10-24 10:48:11,789:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CF42D670>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166D07309A0>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 10:48:11,789:INFO:Checking exceptions
2023-10-24 10:48:11,789:INFO:Importing libraries
2023-10-24 10:48:11,789:INFO:Copying training dataset
2023-10-24 10:48:11,814:INFO:Defining folds
2023-10-24 10:48:11,814:INFO:Declaring metric variables
2023-10-24 10:48:11,814:INFO:Importing untrained model
2023-10-24 10:48:11,814:INFO:Declaring custom model
2023-10-24 10:48:11,814:INFO:Bagging Regressor Imported successfully
2023-10-24 10:48:11,814:INFO:Starting cross validation
2023-10-24 10:48:11,814:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 10:48:29,922:INFO:Calculating mean and std
2023-10-24 10:48:29,922:INFO:Creating metrics dataframe
2023-10-24 10:48:29,928:INFO:Finalizing model
2023-10-24 10:48:30,174:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005623 seconds.
2023-10-24 10:48:30,174:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:48:30,174:INFO:[LightGBM] [Info] Total Bins 6408
2023-10-24 10:48:30,174:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 10:48:30,174:INFO:[LightGBM] [Info] Start training from score 616.125105
2023-10-24 10:48:30,493:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005947 seconds.
2023-10-24 10:48:30,493:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:48:30,493:INFO:[LightGBM] [Info] Total Bins 6408
2023-10-24 10:48:30,493:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 10:48:30,493:INFO:[LightGBM] [Info] Start training from score 613.258669
2023-10-24 10:48:30,760:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005325 seconds.
2023-10-24 10:48:30,760:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:48:30,760:INFO:[LightGBM] [Info] Total Bins 6408
2023-10-24 10:48:30,760:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 10:48:30,760:INFO:[LightGBM] [Info] Start training from score 617.032501
2023-10-24 10:48:31,011:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005441 seconds.
2023-10-24 10:48:31,011:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:48:31,011:INFO:[LightGBM] [Info] Total Bins 6408
2023-10-24 10:48:31,011:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 10:48:31,011:INFO:[LightGBM] [Info] Start training from score 617.633903
2023-10-24 10:48:31,310:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005317 seconds.
2023-10-24 10:48:31,310:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:48:31,310:INFO:[LightGBM] [Info] Total Bins 6408
2023-10-24 10:48:31,310:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 10:48:31,310:INFO:[LightGBM] [Info] Start training from score 624.020441
2023-10-24 10:48:31,553:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005242 seconds.
2023-10-24 10:48:31,553:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:48:31,553:INFO:[LightGBM] [Info] Total Bins 6408
2023-10-24 10:48:31,553:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 10:48:31,553:INFO:[LightGBM] [Info] Start training from score 618.752897
2023-10-24 10:48:31,853:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006666 seconds.
2023-10-24 10:48:31,853:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:48:31,853:INFO:[LightGBM] [Info] Total Bins 6408
2023-10-24 10:48:31,853:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 10:48:31,853:INFO:[LightGBM] [Info] Start training from score 611.671157
2023-10-24 10:48:32,100:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005706 seconds.
2023-10-24 10:48:32,100:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:48:32,100:INFO:[LightGBM] [Info] Total Bins 6408
2023-10-24 10:48:32,100:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 10:48:32,100:INFO:[LightGBM] [Info] Start training from score 617.400574
2023-10-24 10:48:32,354:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006697 seconds.
2023-10-24 10:48:32,354:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:48:32,354:INFO:[LightGBM] [Info] Total Bins 6408
2023-10-24 10:48:32,354:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 10:48:32,354:INFO:[LightGBM] [Info] Start training from score 613.053129
2023-10-24 10:48:32,603:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005755 seconds.
2023-10-24 10:48:32,603:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:48:32,603:INFO:[LightGBM] [Info] Total Bins 6408
2023-10-24 10:48:32,603:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 10:48:32,603:INFO:[LightGBM] [Info] Start training from score 614.380418
2023-10-24 10:48:32,807:INFO:Uploading results into container
2023-10-24 10:48:32,807:INFO:Uploading model into container now
2023-10-24 10:48:32,807:INFO:_master_model_container: 4
2023-10-24 10:48:32,807:INFO:_display_container: 4
2023-10-24 10:48:32,807:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-24 10:48:32,807:INFO:create_model() successfully completed......................................
2023-10-24 10:48:32,964:INFO:SubProcess create_model() end ==================================
2023-10-24 10:48:32,964:INFO:choose_better activated
2023-10-24 10:48:32,964:INFO:SubProcess create_model() called ==================================
2023-10-24 10:48:32,964:INFO:Initializing create_model()
2023-10-24 10:48:32,964:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CF42D670>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 10:48:32,964:INFO:Checking exceptions
2023-10-24 10:48:32,964:INFO:Importing libraries
2023-10-24 10:48:32,964:INFO:Copying training dataset
2023-10-24 10:48:32,995:INFO:Defining folds
2023-10-24 10:48:32,995:INFO:Declaring metric variables
2023-10-24 10:48:32,995:INFO:Importing untrained model
2023-10-24 10:48:32,995:INFO:Declaring custom model
2023-10-24 10:48:32,995:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 10:48:32,995:INFO:Starting cross validation
2023-10-24 10:48:32,995:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 10:48:35,569:INFO:Calculating mean and std
2023-10-24 10:48:35,569:INFO:Creating metrics dataframe
2023-10-24 10:48:35,569:INFO:Finalizing model
2023-10-24 10:48:35,806:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004053 seconds.
2023-10-24 10:48:35,806:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:48:35,806:INFO:[LightGBM] [Info] Total Bins 6408
2023-10-24 10:48:35,806:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 10:48:35,806:INFO:[LightGBM] [Info] Start training from score 616.864890
2023-10-24 10:48:35,967:INFO:Uploading results into container
2023-10-24 10:48:35,967:INFO:Uploading model into container now
2023-10-24 10:48:35,967:INFO:_master_model_container: 5
2023-10-24 10:48:35,967:INFO:_display_container: 5
2023-10-24 10:48:35,967:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 10:48:35,967:INFO:create_model() successfully completed......................................
2023-10-24 10:48:36,121:INFO:SubProcess create_model() end ==================================
2023-10-24 10:48:36,121:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.7469
2023-10-24 10:48:36,121:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123) result for R2 is 0.7576
2023-10-24 10:48:36,121:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123) is best model
2023-10-24 10:48:36,121:INFO:choose_better completed
2023-10-24 10:48:36,121:INFO:_master_model_container: 5
2023-10-24 10:48:36,136:INFO:_display_container: 4
2023-10-24 10:48:36,136:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-24 10:48:36,136:INFO:ensemble_model() successfully completed......................................
2023-10-24 10:48:36,263:INFO:Initializing finalize_model()
2023-10-24 10:48:36,263:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CF42D670>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-24 10:48:36,263:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 10:48:36,278:INFO:Initializing create_model()
2023-10-24 10:48:36,278:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CF42D670>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-24 10:48:36,278:INFO:Checking exceptions
2023-10-24 10:48:36,278:INFO:Importing libraries
2023-10-24 10:48:36,278:INFO:Copying training dataset
2023-10-24 10:48:36,278:INFO:Defining folds
2023-10-24 10:48:36,278:INFO:Declaring metric variables
2023-10-24 10:48:36,278:INFO:Importing untrained model
2023-10-24 10:48:36,278:INFO:Declaring custom model
2023-10-24 10:48:36,278:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 10:48:36,278:INFO:Cross validation set to False
2023-10-24 10:48:36,278:INFO:Fitting Model
2023-10-24 10:48:36,576:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006565 seconds.
2023-10-24 10:48:36,576:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:48:36,576:INFO:[LightGBM] [Info] Total Bins 6836
2023-10-24 10:48:36,576:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 47
2023-10-24 10:48:36,576:INFO:[LightGBM] [Info] Start training from score 631.011165
2023-10-24 10:48:36,843:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 10:48:36,843:INFO:create_model() successfully completed......................................
2023-10-24 10:48:36,984:INFO:_master_model_container: 5
2023-10-24 10:48:36,984:INFO:_display_container: 4
2023-10-24 10:48:37,031:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 10:48:37,031:INFO:finalize_model() successfully completed......................................
2023-10-24 10:48:37,267:INFO:Initializing save_model()
2023-10-24 10:48:37,267:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_A, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-24 10:48:37,267:INFO:Adding model into prep_pipe
2023-10-24 10:48:37,267:WARNING:Only Model saved as it was a pipeline.
2023-10-24 10:48:37,283:INFO:final_model_for_location_A.pkl saved in current working directory
2023-10-24 10:48:37,377:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 10:48:37,377:INFO:save_model() successfully completed......................................
2023-10-24 10:48:37,539:INFO:PyCaret RegressionExperiment
2023-10-24 10:48:37,539:INFO:Logging name: exp_B
2023-10-24 10:48:37,539:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 10:48:37,539:INFO:version 3.1.0
2023-10-24 10:48:37,539:INFO:Initializing setup()
2023-10-24 10:48:37,539:INFO:self.USI: cd44
2023-10-24 10:48:37,539:INFO:self._variable_keys: {'seed', 'logging_param', 'html_param', 'USI', 'data', 'y_train', 'pipeline', '_ml_usecase', 'gpu_n_jobs_param', 'X_test', 'X_train', 'memory', 'X', 'y_test', 'fold_shuffle_param', 'n_jobs_param', 'exp_name_log', 'y', '_available_plots', 'target_param', 'exp_id', 'idx', 'transform_target_param', 'log_plots_param', 'fold_groups_param', 'gpu_param', 'fold_generator'}
2023-10-24 10:48:37,539:INFO:Checking environment
2023-10-24 10:48:37,539:INFO:python_version: 3.8.18
2023-10-24 10:48:37,539:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-24 10:48:37,539:INFO:machine: AMD64
2023-10-24 10:48:37,539:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-24 10:48:37,539:INFO:Memory: svmem(total=16505954304, available=4154757120, percent=74.8, used=12351197184, free=4154757120)
2023-10-24 10:48:37,539:INFO:Physical Core: 8
2023-10-24 10:48:37,539:INFO:Logical Core: 16
2023-10-24 10:48:37,539:INFO:Checking libraries
2023-10-24 10:48:37,539:INFO:System:
2023-10-24 10:48:37,539:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-24 10:48:37,539:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-24 10:48:37,539:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-24 10:48:37,539:INFO:PyCaret required dependencies:
2023-10-24 10:48:37,539:INFO:                 pip: 23.3
2023-10-24 10:48:37,539:INFO:          setuptools: 68.0.0
2023-10-24 10:48:37,539:INFO:             pycaret: 3.1.0
2023-10-24 10:48:37,539:INFO:             IPython: 8.12.0
2023-10-24 10:48:37,539:INFO:          ipywidgets: 8.1.1
2023-10-24 10:48:37,539:INFO:                tqdm: 4.66.1
2023-10-24 10:48:37,539:INFO:               numpy: 1.23.5
2023-10-24 10:48:37,539:INFO:              pandas: 1.5.3
2023-10-24 10:48:37,539:INFO:              jinja2: 3.1.2
2023-10-24 10:48:37,539:INFO:               scipy: 1.10.1
2023-10-24 10:48:37,539:INFO:              joblib: 1.3.2
2023-10-24 10:48:37,539:INFO:             sklearn: 1.2.2
2023-10-24 10:48:37,539:INFO:                pyod: 1.1.0
2023-10-24 10:48:37,539:INFO:            imblearn: 0.11.0
2023-10-24 10:48:37,539:INFO:   category_encoders: 2.6.2
2023-10-24 10:48:37,539:INFO:            lightgbm: 4.1.0
2023-10-24 10:48:37,539:INFO:               numba: 0.58.1
2023-10-24 10:48:37,539:INFO:            requests: 2.31.0
2023-10-24 10:48:37,539:INFO:          matplotlib: 3.7.3
2023-10-24 10:48:37,539:INFO:          scikitplot: 0.3.7
2023-10-24 10:48:37,539:INFO:         yellowbrick: 1.5
2023-10-24 10:48:37,539:INFO:              plotly: 5.17.0
2023-10-24 10:48:37,539:INFO:    plotly-resampler: Not installed
2023-10-24 10:48:37,539:INFO:             kaleido: 0.2.1
2023-10-24 10:48:37,539:INFO:           schemdraw: 0.15
2023-10-24 10:48:37,539:INFO:         statsmodels: 0.14.0
2023-10-24 10:48:37,539:INFO:              sktime: 0.21.1
2023-10-24 10:48:37,539:INFO:               tbats: 1.1.3
2023-10-24 10:48:37,539:INFO:            pmdarima: 2.0.3
2023-10-24 10:48:37,539:INFO:              psutil: 5.9.0
2023-10-24 10:48:37,539:INFO:          markupsafe: 2.1.3
2023-10-24 10:48:37,539:INFO:             pickle5: Not installed
2023-10-24 10:48:37,539:INFO:         cloudpickle: 2.2.1
2023-10-24 10:48:37,539:INFO:         deprecation: 2.1.0
2023-10-24 10:48:37,539:INFO:              xxhash: 3.4.1
2023-10-24 10:48:37,539:INFO:           wurlitzer: Not installed
2023-10-24 10:48:37,539:INFO:PyCaret optional dependencies:
2023-10-24 10:48:37,539:INFO:                shap: Not installed
2023-10-24 10:48:37,539:INFO:           interpret: Not installed
2023-10-24 10:48:37,539:INFO:                umap: Not installed
2023-10-24 10:48:37,539:INFO:     ydata_profiling: Not installed
2023-10-24 10:48:37,539:INFO:  explainerdashboard: Not installed
2023-10-24 10:48:37,539:INFO:             autoviz: Not installed
2023-10-24 10:48:37,539:INFO:           fairlearn: Not installed
2023-10-24 10:48:37,539:INFO:          deepchecks: Not installed
2023-10-24 10:48:37,539:INFO:             xgboost: Not installed
2023-10-24 10:48:37,539:INFO:            catboost: 1.2.2
2023-10-24 10:48:37,539:INFO:              kmodes: Not installed
2023-10-24 10:48:37,539:INFO:             mlxtend: Not installed
2023-10-24 10:48:37,539:INFO:       statsforecast: Not installed
2023-10-24 10:48:37,539:INFO:        tune_sklearn: Not installed
2023-10-24 10:48:37,539:INFO:                 ray: Not installed
2023-10-24 10:48:37,539:INFO:            hyperopt: Not installed
2023-10-24 10:48:37,539:INFO:              optuna: Not installed
2023-10-24 10:48:37,539:INFO:               skopt: Not installed
2023-10-24 10:48:37,539:INFO:              mlflow: 2.7.1
2023-10-24 10:48:37,539:INFO:              gradio: Not installed
2023-10-24 10:48:37,539:INFO:             fastapi: Not installed
2023-10-24 10:48:37,539:INFO:             uvicorn: Not installed
2023-10-24 10:48:37,539:INFO:              m2cgen: Not installed
2023-10-24 10:48:37,539:INFO:           evidently: Not installed
2023-10-24 10:48:37,539:INFO:               fugue: Not installed
2023-10-24 10:48:37,539:INFO:           streamlit: Not installed
2023-10-24 10:48:37,539:INFO:             prophet: Not installed
2023-10-24 10:48:37,539:INFO:None
2023-10-24 10:48:37,539:INFO:Set up data.
2023-10-24 10:48:37,570:INFO:Set up folding strategy.
2023-10-24 10:48:37,570:INFO:Set up train/test split.
2023-10-24 10:48:37,586:INFO:Set up index.
2023-10-24 10:48:37,586:INFO:Assigning column types.
2023-10-24 10:48:37,602:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 10:48:37,602:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 10:48:37,617:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 10:48:37,617:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 10:48:37,696:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:48:37,743:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:48:37,743:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:48:37,743:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:48:37,743:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 10:48:37,743:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 10:48:37,758:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 10:48:37,821:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:48:37,884:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:48:37,884:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:48:37,884:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:48:37,884:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 10:48:37,884:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 10:48:37,884:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 10:48:37,963:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:48:38,010:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:48:38,010:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:48:38,010:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:48:38,025:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 10:48:38,025:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 10:48:38,104:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:48:38,151:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:48:38,151:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:48:38,151:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:48:38,151:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 10:48:38,167:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 10:48:38,230:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:48:38,293:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:48:38,293:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:48:38,293:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:48:38,293:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 10:48:38,371:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:48:38,419:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:48:38,419:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:48:38,419:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:48:38,419:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 10:48:38,513:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:48:38,565:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:48:38,565:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:48:38,565:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:48:38,655:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:48:38,703:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:48:38,703:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:48:38,703:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:48:38,703:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 10:48:38,781:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:48:38,843:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:48:38,843:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:48:38,922:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:48:38,969:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:48:38,969:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:48:38,969:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 10:48:39,122:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:48:39,122:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:48:39,267:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:48:39,267:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:48:39,267:INFO:Preparing preprocessing pipeline...
2023-10-24 10:48:39,267:INFO:Set up date feature engineering.
2023-10-24 10:48:39,267:INFO:Set up simple imputation.
2023-10-24 10:48:39,269:INFO:Set up encoding of ordinal features.
2023-10-24 10:48:39,285:INFO:Set up encoding of categorical features.
2023-10-24 10:48:39,285:INFO:Set up column name cleaning.
2023-10-24 10:48:39,525:INFO:Finished creating preprocessing pipeline.
2023-10-24 10:48:39,572:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 10:48:39,572:INFO:Creating final display dataframe.
2023-10-24 10:48:39,714:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (32819, 48)
4        Transformed data shape  (32819, 52)
5   Transformed train set shape  (22973, 52)
6    Transformed test set shape   (9846, 52)
7              Ordinal features            2
8              Numeric features           43
9                 Date features            1
10         Categorical features            3
11     Rows with missing values        95.9%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18               Fold Generator        KFold
19                  Fold Number           10
20                     CPU Jobs           -1
21                      Use GPU        False
22               Log Experiment        False
23              Experiment Name        exp_B
24                          USI         cd44
2023-10-24 10:48:39,902:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:48:39,902:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:48:40,107:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:48:40,107:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:48:40,107:INFO:setup() successfully completed in 2.58s...............
2023-10-24 10:48:40,107:INFO:Initializing compare_models()
2023-10-24 10:48:40,107:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CD64F3D0>, include=['lightgbm'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000166CD64F3D0>, 'include': ['lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-10-24 10:48:40,107:INFO:Checking exceptions
2023-10-24 10:48:40,107:INFO:Preparing display monitor
2023-10-24 10:48:40,123:INFO:Initializing Light Gradient Boosting Machine
2023-10-24 10:48:40,123:INFO:Total runtime is 0.0 minutes
2023-10-24 10:48:40,123:INFO:SubProcess create_model() called ==================================
2023-10-24 10:48:40,123:INFO:Initializing create_model()
2023-10-24 10:48:40,123:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CD64F3D0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166CF393B80>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 10:48:40,123:INFO:Checking exceptions
2023-10-24 10:48:40,123:INFO:Importing libraries
2023-10-24 10:48:40,123:INFO:Copying training dataset
2023-10-24 10:48:40,138:INFO:Defining folds
2023-10-24 10:48:40,138:INFO:Declaring metric variables
2023-10-24 10:48:40,138:INFO:Importing untrained model
2023-10-24 10:48:40,138:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 10:48:40,138:INFO:Starting cross validation
2023-10-24 10:48:40,138:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 10:48:42,733:INFO:Calculating mean and std
2023-10-24 10:48:42,733:INFO:Creating metrics dataframe
2023-10-24 10:48:42,733:INFO:Uploading results into container
2023-10-24 10:48:42,733:INFO:Uploading model into container now
2023-10-24 10:48:42,733:INFO:_master_model_container: 1
2023-10-24 10:48:42,733:INFO:_display_container: 2
2023-10-24 10:48:42,733:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 10:48:42,733:INFO:create_model() successfully completed......................................
2023-10-24 10:48:42,891:INFO:SubProcess create_model() end ==================================
2023-10-24 10:48:42,891:INFO:Creating metrics dataframe
2023-10-24 10:48:42,891:INFO:Initializing create_model()
2023-10-24 10:48:42,891:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CD64F3D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 10:48:42,891:INFO:Checking exceptions
2023-10-24 10:48:42,891:INFO:Importing libraries
2023-10-24 10:48:42,891:INFO:Copying training dataset
2023-10-24 10:48:42,907:INFO:Defining folds
2023-10-24 10:48:42,907:INFO:Declaring metric variables
2023-10-24 10:48:42,907:INFO:Importing untrained model
2023-10-24 10:48:42,923:INFO:Declaring custom model
2023-10-24 10:48:42,923:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 10:48:42,923:INFO:Cross validation set to False
2023-10-24 10:48:42,923:INFO:Fitting Model
2023-10-24 10:48:43,142:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005372 seconds.
2023-10-24 10:48:43,142:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:48:43,142:INFO:[LightGBM] [Info] Total Bins 6444
2023-10-24 10:48:43,142:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 46
2023-10-24 10:48:43,142:INFO:[LightGBM] [Info] Start training from score 117.072182
2023-10-24 10:48:43,300:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 10:48:43,300:INFO:create_model() successfully completed......................................
2023-10-24 10:48:43,462:INFO:_master_model_container: 1
2023-10-24 10:48:43,462:INFO:_display_container: 2
2023-10-24 10:48:43,462:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 10:48:43,462:INFO:compare_models() successfully completed......................................
2023-10-24 10:48:43,462:INFO:Initializing tune_model()
2023-10-24 10:48:43,462:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CD64F3D0>)
2023-10-24 10:48:43,462:INFO:Checking exceptions
2023-10-24 10:48:43,478:INFO:Copying training dataset
2023-10-24 10:48:43,494:INFO:Checking base model
2023-10-24 10:48:43,494:INFO:Base model : Light Gradient Boosting Machine
2023-10-24 10:48:43,494:INFO:Declaring metric variables
2023-10-24 10:48:43,494:INFO:Defining Hyperparameters
2023-10-24 10:48:43,620:INFO:Tuning with n_jobs=-1
2023-10-24 10:48:43,620:INFO:Initializing RandomizedSearchCV
2023-10-24 10:49:26,165:INFO:best_params: {'actual_estimator__reg_lambda': 0.1, 'actual_estimator__reg_alpha': 0.0001, 'actual_estimator__num_leaves': 10, 'actual_estimator__n_estimators': 180, 'actual_estimator__min_split_gain': 0.7, 'actual_estimator__min_child_samples': 96, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__feature_fraction': 0.9, 'actual_estimator__bagging_freq': 4, 'actual_estimator__bagging_fraction': 0.6}
2023-10-24 10:49:26,165:INFO:Hyperparameter search completed
2023-10-24 10:49:26,165:INFO:SubProcess create_model() called ==================================
2023-10-24 10:49:26,165:INFO:Initializing create_model()
2023-10-24 10:49:26,165:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CD64F3D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166D0B71FD0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 0.1, 'reg_alpha': 0.0001, 'num_leaves': 10, 'n_estimators': 180, 'min_split_gain': 0.7, 'min_child_samples': 96, 'learning_rate': 0.05, 'feature_fraction': 0.9, 'bagging_freq': 4, 'bagging_fraction': 0.6})
2023-10-24 10:49:26,165:INFO:Checking exceptions
2023-10-24 10:49:26,165:INFO:Importing libraries
2023-10-24 10:49:26,165:INFO:Copying training dataset
2023-10-24 10:49:26,197:INFO:Defining folds
2023-10-24 10:49:26,197:INFO:Declaring metric variables
2023-10-24 10:49:26,197:INFO:Importing untrained model
2023-10-24 10:49:26,197:INFO:Declaring custom model
2023-10-24 10:49:26,197:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 10:49:26,197:INFO:Starting cross validation
2023-10-24 10:49:26,197:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 10:49:28,321:INFO:Calculating mean and std
2023-10-24 10:49:28,321:INFO:Creating metrics dataframe
2023-10-24 10:49:28,321:INFO:Finalizing model
2023-10-24 10:49:28,510:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:49:28,510:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:49:28,510:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:49:28,542:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:49:28,542:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:49:28,542:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:49:28,557:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005775 seconds.
2023-10-24 10:49:28,557:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:49:28,557:INFO:[LightGBM] [Info] Total Bins 6442
2023-10-24 10:49:28,557:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-24 10:49:28,557:INFO:[LightGBM] [Info] Start training from score 117.072182
2023-10-24 10:49:28,714:INFO:Uploading results into container
2023-10-24 10:49:28,714:INFO:Uploading model into container now
2023-10-24 10:49:28,714:INFO:_master_model_container: 2
2023-10-24 10:49:28,714:INFO:_display_container: 3
2023-10-24 10:49:28,714:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9,
              learning_rate=0.05, min_child_samples=96, min_split_gain=0.7,
              n_estimators=180, n_jobs=-1, num_leaves=10, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.1)
2023-10-24 10:49:28,714:INFO:create_model() successfully completed......................................
2023-10-24 10:49:28,871:INFO:SubProcess create_model() end ==================================
2023-10-24 10:49:28,871:INFO:choose_better activated
2023-10-24 10:49:28,871:INFO:SubProcess create_model() called ==================================
2023-10-24 10:49:28,871:INFO:Initializing create_model()
2023-10-24 10:49:28,871:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CD64F3D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 10:49:28,871:INFO:Checking exceptions
2023-10-24 10:49:28,871:INFO:Importing libraries
2023-10-24 10:49:28,871:INFO:Copying training dataset
2023-10-24 10:49:28,888:INFO:Defining folds
2023-10-24 10:49:28,888:INFO:Declaring metric variables
2023-10-24 10:49:28,888:INFO:Importing untrained model
2023-10-24 10:49:28,888:INFO:Declaring custom model
2023-10-24 10:49:28,888:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 10:49:28,888:INFO:Starting cross validation
2023-10-24 10:49:28,888:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 10:49:31,356:INFO:Calculating mean and std
2023-10-24 10:49:31,356:INFO:Creating metrics dataframe
2023-10-24 10:49:31,356:INFO:Finalizing model
2023-10-24 10:49:31,628:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004026 seconds.
2023-10-24 10:49:31,628:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:49:31,628:INFO:[LightGBM] [Info] Total Bins 6444
2023-10-24 10:49:31,628:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 46
2023-10-24 10:49:31,628:INFO:[LightGBM] [Info] Start training from score 117.072182
2023-10-24 10:49:31,785:INFO:Uploading results into container
2023-10-24 10:49:31,785:INFO:Uploading model into container now
2023-10-24 10:49:31,785:INFO:_master_model_container: 3
2023-10-24 10:49:31,785:INFO:_display_container: 4
2023-10-24 10:49:31,785:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 10:49:31,785:INFO:create_model() successfully completed......................................
2023-10-24 10:49:31,942:INFO:SubProcess create_model() end ==================================
2023-10-24 10:49:31,942:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.5728
2023-10-24 10:49:31,942:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9,
              learning_rate=0.05, min_child_samples=96, min_split_gain=0.7,
              n_estimators=180, n_jobs=-1, num_leaves=10, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.1) result for R2 is 0.5804
2023-10-24 10:49:31,942:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9,
              learning_rate=0.05, min_child_samples=96, min_split_gain=0.7,
              n_estimators=180, n_jobs=-1, num_leaves=10, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.1) is best model
2023-10-24 10:49:31,942:INFO:choose_better completed
2023-10-24 10:49:31,942:INFO:_master_model_container: 3
2023-10-24 10:49:31,942:INFO:_display_container: 3
2023-10-24 10:49:31,942:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9,
              learning_rate=0.05, min_child_samples=96, min_split_gain=0.7,
              n_estimators=180, n_jobs=-1, num_leaves=10, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.1)
2023-10-24 10:49:31,942:INFO:tune_model() successfully completed......................................
2023-10-24 10:49:32,084:INFO:Initializing ensemble_model()
2023-10-24 10:49:32,084:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CD64F3D0>, estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9,
              learning_rate=0.05, min_child_samples=96, min_split_gain=0.7,
              n_estimators=180, n_jobs=-1, num_leaves=10, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.1), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=True, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-24 10:49:32,084:INFO:Checking exceptions
2023-10-24 10:49:32,084:INFO:Importing libraries
2023-10-24 10:49:32,084:INFO:Copying training dataset
2023-10-24 10:49:32,084:INFO:Checking base model
2023-10-24 10:49:32,084:INFO:Base model : Light Gradient Boosting Machine
2023-10-24 10:49:32,084:INFO:Importing untrained ensembler
2023-10-24 10:49:32,084:INFO:Ensemble method set to Bagging
2023-10-24 10:49:32,084:INFO:SubProcess create_model() called ==================================
2023-10-24 10:49:32,099:INFO:Initializing create_model()
2023-10-24 10:49:32,099:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CD64F3D0>, estimator=BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=4,
                                         feature_fraction=0.9,
                                         learning_rate=0.05,
                                         min_child_samples=96,
                                         min_split_gain=0.7, n_estimators=180,
                                         n_jobs=-1, num_leaves=10,
                                         random_state=123, reg_alpha=0.0001,
                                         reg_lambda=0.1),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166CD64F970>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 10:49:32,099:INFO:Checking exceptions
2023-10-24 10:49:32,099:INFO:Importing libraries
2023-10-24 10:49:32,099:INFO:Copying training dataset
2023-10-24 10:49:32,115:INFO:Defining folds
2023-10-24 10:49:32,115:INFO:Declaring metric variables
2023-10-24 10:49:32,115:INFO:Importing untrained model
2023-10-24 10:49:32,115:INFO:Declaring custom model
2023-10-24 10:49:32,115:INFO:Bagging Regressor Imported successfully
2023-10-24 10:49:32,115:INFO:Starting cross validation
2023-10-24 10:49:32,115:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 10:49:49,131:INFO:Calculating mean and std
2023-10-24 10:49:49,131:INFO:Creating metrics dataframe
2023-10-24 10:49:49,131:INFO:Finalizing model
2023-10-24 10:49:49,400:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:49:49,400:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:49:49,400:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:49:49,425:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:49:49,425:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:49:49,425:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:49:49,442:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004776 seconds.
2023-10-24 10:49:49,442:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:49:49,442:INFO:[LightGBM] [Info] Total Bins 6442
2023-10-24 10:49:49,442:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-24 10:49:49,442:INFO:[LightGBM] [Info] Start training from score 118.026402
2023-10-24 10:49:49,714:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:49:49,715:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:49:49,715:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:49:49,760:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:49:49,760:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:49:49,760:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:49:49,760:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006471 seconds.
2023-10-24 10:49:49,760:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:49:49,760:INFO:[LightGBM] [Info] Total Bins 6442
2023-10-24 10:49:49,760:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-24 10:49:49,760:INFO:[LightGBM] [Info] Start training from score 118.074872
2023-10-24 10:49:50,033:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:49:50,033:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:49:50,033:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:49:50,074:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:49:50,074:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:49:50,074:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:49:50,081:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005043 seconds.
2023-10-24 10:49:50,081:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:49:50,082:INFO:[LightGBM] [Info] Total Bins 6442
2023-10-24 10:49:50,082:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-24 10:49:50,083:INFO:[LightGBM] [Info] Start training from score 118.804616
2023-10-24 10:49:50,271:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:49:50,271:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:49:50,271:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:49:50,302:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:49:50,302:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:49:50,302:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:49:50,302:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005065 seconds.
2023-10-24 10:49:50,302:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:49:50,302:INFO:[LightGBM] [Info] Total Bins 6442
2023-10-24 10:49:50,302:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-24 10:49:50,302:INFO:[LightGBM] [Info] Start training from score 113.631456
2023-10-24 10:49:50,459:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:49:50,459:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:49:50,459:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:49:50,509:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:49:50,509:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:49:50,509:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:49:50,509:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005467 seconds.
2023-10-24 10:49:50,509:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:49:50,509:INFO:[LightGBM] [Info] Total Bins 6442
2023-10-24 10:49:50,509:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-24 10:49:50,509:INFO:[LightGBM] [Info] Start training from score 116.143830
2023-10-24 10:49:50,674:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:49:50,674:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:49:50,674:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:49:50,723:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:49:50,723:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:49:50,723:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:49:50,731:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005968 seconds.
2023-10-24 10:49:50,731:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:49:50,731:INFO:[LightGBM] [Info] Total Bins 6442
2023-10-24 10:49:50,732:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-24 10:49:50,733:INFO:[LightGBM] [Info] Start training from score 117.770840
2023-10-24 10:49:50,882:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:49:50,882:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:49:50,882:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:49:50,914:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:49:50,914:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:49:50,914:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:49:50,929:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006017 seconds.
2023-10-24 10:49:50,929:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:49:50,929:INFO:[LightGBM] [Info] Total Bins 6442
2023-10-24 10:49:50,929:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-24 10:49:50,929:INFO:[LightGBM] [Info] Start training from score 116.312891
2023-10-24 10:49:51,087:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:49:51,087:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:49:51,087:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:49:51,119:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:49:51,119:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:49:51,119:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:49:51,134:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006262 seconds.
2023-10-24 10:49:51,134:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:49:51,134:INFO:[LightGBM] [Info] Total Bins 6442
2023-10-24 10:49:51,134:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-24 10:49:51,140:INFO:[LightGBM] [Info] Start training from score 116.430179
2023-10-24 10:49:51,283:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:49:51,283:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:49:51,283:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:49:51,328:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:49:51,328:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:49:51,328:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:49:51,345:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005845 seconds.
2023-10-24 10:49:51,346:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:49:51,346:INFO:[LightGBM] [Info] Total Bins 6442
2023-10-24 10:49:51,346:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-24 10:49:51,348:INFO:[LightGBM] [Info] Start training from score 116.654317
2023-10-24 10:49:51,531:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:49:51,531:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:49:51,531:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:49:51,557:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:49:51,557:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:49:51,557:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:49:51,572:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005068 seconds.
2023-10-24 10:49:51,572:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:49:51,572:INFO:[LightGBM] [Info] Total Bins 6442
2023-10-24 10:49:51,572:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-24 10:49:51,572:INFO:[LightGBM] [Info] Start training from score 117.801701
2023-10-24 10:49:51,733:INFO:Uploading results into container
2023-10-24 10:49:51,733:INFO:Uploading model into container now
2023-10-24 10:49:51,733:INFO:_master_model_container: 4
2023-10-24 10:49:51,733:INFO:_display_container: 4
2023-10-24 10:49:51,733:INFO:BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=4,
                                         feature_fraction=0.9,
                                         learning_rate=0.05,
                                         min_child_samples=96,
                                         min_split_gain=0.7, n_estimators=180,
                                         n_jobs=-1, num_leaves=10,
                                         random_state=123, reg_alpha=0.0001,
                                         reg_lambda=0.1),
                 random_state=123)
2023-10-24 10:49:51,733:INFO:create_model() successfully completed......................................
2023-10-24 10:49:51,890:INFO:SubProcess create_model() end ==================================
2023-10-24 10:49:51,890:INFO:choose_better activated
2023-10-24 10:49:51,890:INFO:SubProcess create_model() called ==================================
2023-10-24 10:49:51,890:INFO:Initializing create_model()
2023-10-24 10:49:51,890:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CD64F3D0>, estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9,
              learning_rate=0.05, min_child_samples=96, min_split_gain=0.7,
              n_estimators=180, n_jobs=-1, num_leaves=10, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 10:49:51,890:INFO:Checking exceptions
2023-10-24 10:49:51,890:INFO:Importing libraries
2023-10-24 10:49:51,890:INFO:Copying training dataset
2023-10-24 10:49:51,906:INFO:Defining folds
2023-10-24 10:49:51,906:INFO:Declaring metric variables
2023-10-24 10:49:51,906:INFO:Importing untrained model
2023-10-24 10:49:51,906:INFO:Declaring custom model
2023-10-24 10:49:51,906:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 10:49:51,906:INFO:Starting cross validation
2023-10-24 10:49:51,906:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 10:49:54,788:INFO:Calculating mean and std
2023-10-24 10:49:54,789:INFO:Creating metrics dataframe
2023-10-24 10:49:54,792:INFO:Finalizing model
2023-10-24 10:49:55,046:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:49:55,047:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:49:55,047:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:49:55,081:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:49:55,081:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:49:55,081:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:49:55,088:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006091 seconds.
2023-10-24 10:49:55,088:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:49:55,089:INFO:[LightGBM] [Info] Total Bins 6442
2023-10-24 10:49:55,089:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-24 10:49:55,091:INFO:[LightGBM] [Info] Start training from score 117.072182
2023-10-24 10:49:55,289:INFO:Uploading results into container
2023-10-24 10:49:55,290:INFO:Uploading model into container now
2023-10-24 10:49:55,291:INFO:_master_model_container: 5
2023-10-24 10:49:55,291:INFO:_display_container: 5
2023-10-24 10:49:55,292:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9,
              learning_rate=0.05, min_child_samples=96, min_split_gain=0.7,
              n_estimators=180, n_jobs=-1, num_leaves=10, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.1)
2023-10-24 10:49:55,292:INFO:create_model() successfully completed......................................
2023-10-24 10:49:55,461:INFO:SubProcess create_model() end ==================================
2023-10-24 10:49:55,462:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9,
              learning_rate=0.05, min_child_samples=96, min_split_gain=0.7,
              n_estimators=180, n_jobs=-1, num_leaves=10, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.1) result for R2 is 0.5804
2023-10-24 10:49:55,465:INFO:BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=4,
                                         feature_fraction=0.9,
                                         learning_rate=0.05,
                                         min_child_samples=96,
                                         min_split_gain=0.7, n_estimators=180,
                                         n_jobs=-1, num_leaves=10,
                                         random_state=123, reg_alpha=0.0001,
                                         reg_lambda=0.1),
                 random_state=123) result for R2 is 0.5906
2023-10-24 10:49:55,468:INFO:BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=4,
                                         feature_fraction=0.9,
                                         learning_rate=0.05,
                                         min_child_samples=96,
                                         min_split_gain=0.7, n_estimators=180,
                                         n_jobs=-1, num_leaves=10,
                                         random_state=123, reg_alpha=0.0001,
                                         reg_lambda=0.1),
                 random_state=123) is best model
2023-10-24 10:49:55,468:INFO:choose_better completed
2023-10-24 10:49:55,474:INFO:_master_model_container: 5
2023-10-24 10:49:55,474:INFO:_display_container: 4
2023-10-24 10:49:55,474:INFO:BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=4,
                                         feature_fraction=0.9,
                                         learning_rate=0.05,
                                         min_child_samples=96,
                                         min_split_gain=0.7, n_estimators=180,
                                         n_jobs=-1, num_leaves=10,
                                         random_state=123, reg_alpha=0.0001,
                                         reg_lambda=0.1),
                 random_state=123)
2023-10-24 10:49:55,474:INFO:ensemble_model() successfully completed......................................
2023-10-24 10:49:55,605:INFO:Initializing finalize_model()
2023-10-24 10:49:55,605:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CD64F3D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-24 10:49:55,605:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 10:49:55,621:INFO:Initializing create_model()
2023-10-24 10:49:55,621:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CD64F3D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-24 10:49:55,621:INFO:Checking exceptions
2023-10-24 10:49:55,621:INFO:Importing libraries
2023-10-24 10:49:55,621:INFO:Copying training dataset
2023-10-24 10:49:55,621:INFO:Defining folds
2023-10-24 10:49:55,621:INFO:Declaring metric variables
2023-10-24 10:49:55,621:INFO:Importing untrained model
2023-10-24 10:49:55,621:INFO:Declaring custom model
2023-10-24 10:49:55,621:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 10:49:55,621:INFO:Cross validation set to False
2023-10-24 10:49:55,621:INFO:Fitting Model
2023-10-24 10:49:55,955:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006898 seconds.
2023-10-24 10:49:55,956:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:49:55,956:INFO:[LightGBM] [Info] Total Bins 6781
2023-10-24 10:49:55,957:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 47
2023-10-24 10:49:55,957:INFO:[LightGBM] [Info] Start training from score 96.893335
2023-10-24 10:49:56,306:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 10:49:56,306:INFO:create_model() successfully completed......................................
2023-10-24 10:49:56,453:INFO:_master_model_container: 5
2023-10-24 10:49:56,453:INFO:_display_container: 4
2023-10-24 10:49:56,514:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 10:49:56,514:INFO:finalize_model() successfully completed......................................
2023-10-24 10:49:56,780:INFO:Initializing save_model()
2023-10-24 10:49:56,780:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_B, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-24 10:49:56,780:INFO:Adding model into prep_pipe
2023-10-24 10:49:56,780:WARNING:Only Model saved as it was a pipeline.
2023-10-24 10:49:56,799:INFO:final_model_for_location_B.pkl saved in current working directory
2023-10-24 10:49:56,901:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 10:49:56,901:INFO:save_model() successfully completed......................................
2023-10-24 10:49:57,083:INFO:PyCaret RegressionExperiment
2023-10-24 10:49:57,083:INFO:Logging name: exp_C
2023-10-24 10:49:57,083:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 10:49:57,083:INFO:version 3.1.0
2023-10-24 10:49:57,083:INFO:Initializing setup()
2023-10-24 10:49:57,083:INFO:self.USI: 0e3a
2023-10-24 10:49:57,083:INFO:self._variable_keys: {'seed', 'logging_param', 'html_param', 'USI', 'data', 'y_train', 'pipeline', '_ml_usecase', 'gpu_n_jobs_param', 'X_test', 'X_train', 'memory', 'X', 'y_test', 'fold_shuffle_param', 'n_jobs_param', 'exp_name_log', 'y', '_available_plots', 'target_param', 'exp_id', 'idx', 'transform_target_param', 'log_plots_param', 'fold_groups_param', 'gpu_param', 'fold_generator'}
2023-10-24 10:49:57,083:INFO:Checking environment
2023-10-24 10:49:57,084:INFO:python_version: 3.8.18
2023-10-24 10:49:57,084:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-24 10:49:57,084:INFO:machine: AMD64
2023-10-24 10:49:57,084:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-24 10:49:57,084:INFO:Memory: svmem(total=16505954304, available=3399737344, percent=79.4, used=13106216960, free=3399737344)
2023-10-24 10:49:57,084:INFO:Physical Core: 8
2023-10-24 10:49:57,084:INFO:Logical Core: 16
2023-10-24 10:49:57,085:INFO:Checking libraries
2023-10-24 10:49:57,085:INFO:System:
2023-10-24 10:49:57,085:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-24 10:49:57,085:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-24 10:49:57,085:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-24 10:49:57,085:INFO:PyCaret required dependencies:
2023-10-24 10:49:57,085:INFO:                 pip: 23.3
2023-10-24 10:49:57,085:INFO:          setuptools: 68.0.0
2023-10-24 10:49:57,085:INFO:             pycaret: 3.1.0
2023-10-24 10:49:57,086:INFO:             IPython: 8.12.0
2023-10-24 10:49:57,086:INFO:          ipywidgets: 8.1.1
2023-10-24 10:49:57,086:INFO:                tqdm: 4.66.1
2023-10-24 10:49:57,086:INFO:               numpy: 1.23.5
2023-10-24 10:49:57,086:INFO:              pandas: 1.5.3
2023-10-24 10:49:57,086:INFO:              jinja2: 3.1.2
2023-10-24 10:49:57,086:INFO:               scipy: 1.10.1
2023-10-24 10:49:57,086:INFO:              joblib: 1.3.2
2023-10-24 10:49:57,086:INFO:             sklearn: 1.2.2
2023-10-24 10:49:57,087:INFO:                pyod: 1.1.0
2023-10-24 10:49:57,087:INFO:            imblearn: 0.11.0
2023-10-24 10:49:57,087:INFO:   category_encoders: 2.6.2
2023-10-24 10:49:57,087:INFO:            lightgbm: 4.1.0
2023-10-24 10:49:57,087:INFO:               numba: 0.58.1
2023-10-24 10:49:57,087:INFO:            requests: 2.31.0
2023-10-24 10:49:57,087:INFO:          matplotlib: 3.7.3
2023-10-24 10:49:57,088:INFO:          scikitplot: 0.3.7
2023-10-24 10:49:57,088:INFO:         yellowbrick: 1.5
2023-10-24 10:49:57,088:INFO:              plotly: 5.17.0
2023-10-24 10:49:57,088:INFO:    plotly-resampler: Not installed
2023-10-24 10:49:57,088:INFO:             kaleido: 0.2.1
2023-10-24 10:49:57,088:INFO:           schemdraw: 0.15
2023-10-24 10:49:57,088:INFO:         statsmodels: 0.14.0
2023-10-24 10:49:57,088:INFO:              sktime: 0.21.1
2023-10-24 10:49:57,088:INFO:               tbats: 1.1.3
2023-10-24 10:49:57,088:INFO:            pmdarima: 2.0.3
2023-10-24 10:49:57,088:INFO:              psutil: 5.9.0
2023-10-24 10:49:57,088:INFO:          markupsafe: 2.1.3
2023-10-24 10:49:57,089:INFO:             pickle5: Not installed
2023-10-24 10:49:57,089:INFO:         cloudpickle: 2.2.1
2023-10-24 10:49:57,089:INFO:         deprecation: 2.1.0
2023-10-24 10:49:57,089:INFO:              xxhash: 3.4.1
2023-10-24 10:49:57,089:INFO:           wurlitzer: Not installed
2023-10-24 10:49:57,089:INFO:PyCaret optional dependencies:
2023-10-24 10:49:57,089:INFO:                shap: Not installed
2023-10-24 10:49:57,089:INFO:           interpret: Not installed
2023-10-24 10:49:57,089:INFO:                umap: Not installed
2023-10-24 10:49:57,089:INFO:     ydata_profiling: Not installed
2023-10-24 10:49:57,089:INFO:  explainerdashboard: Not installed
2023-10-24 10:49:57,090:INFO:             autoviz: Not installed
2023-10-24 10:49:57,090:INFO:           fairlearn: Not installed
2023-10-24 10:49:57,090:INFO:          deepchecks: Not installed
2023-10-24 10:49:57,090:INFO:             xgboost: Not installed
2023-10-24 10:49:57,090:INFO:            catboost: 1.2.2
2023-10-24 10:49:57,091:INFO:              kmodes: Not installed
2023-10-24 10:49:57,091:INFO:             mlxtend: Not installed
2023-10-24 10:49:57,091:INFO:       statsforecast: Not installed
2023-10-24 10:49:57,091:INFO:        tune_sklearn: Not installed
2023-10-24 10:49:57,091:INFO:                 ray: Not installed
2023-10-24 10:49:57,091:INFO:            hyperopt: Not installed
2023-10-24 10:49:57,091:INFO:              optuna: Not installed
2023-10-24 10:49:57,092:INFO:               skopt: Not installed
2023-10-24 10:49:57,092:INFO:              mlflow: 2.7.1
2023-10-24 10:49:57,092:INFO:              gradio: Not installed
2023-10-24 10:49:57,092:INFO:             fastapi: Not installed
2023-10-24 10:49:57,092:INFO:             uvicorn: Not installed
2023-10-24 10:49:57,092:INFO:              m2cgen: Not installed
2023-10-24 10:49:57,093:INFO:           evidently: Not installed
2023-10-24 10:49:57,093:INFO:               fugue: Not installed
2023-10-24 10:49:57,093:INFO:           streamlit: Not installed
2023-10-24 10:49:57,093:INFO:             prophet: Not installed
2023-10-24 10:49:57,093:INFO:None
2023-10-24 10:49:57,093:INFO:Set up data.
2023-10-24 10:49:57,130:INFO:Set up folding strategy.
2023-10-24 10:49:57,131:INFO:Set up train/test split.
2023-10-24 10:49:57,148:INFO:Set up index.
2023-10-24 10:49:57,149:INFO:Assigning column types.
2023-10-24 10:49:57,166:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 10:49:57,166:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 10:49:57,171:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 10:49:57,177:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 10:49:57,252:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:49:57,324:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:49:57,325:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:49:57,325:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:49:57,326:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 10:49:57,334:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 10:49:57,340:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 10:49:57,437:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:49:57,505:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:49:57,506:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:49:57,507:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:49:57,507:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 10:49:57,514:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 10:49:57,521:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 10:49:57,614:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:49:57,674:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:49:57,675:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:49:57,675:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:49:57,683:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 10:49:57,691:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 10:49:57,799:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:49:57,854:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:49:57,854:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:49:57,855:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:49:57,855:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 10:49:57,867:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 10:49:57,955:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:49:58,009:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:49:58,010:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:49:58,011:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:49:58,022:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 10:49:58,114:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:49:58,162:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:49:58,162:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:49:58,162:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:49:58,162:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 10:49:58,255:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:49:58,301:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:49:58,301:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:49:58,301:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:49:58,394:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:49:58,451:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 10:49:58,451:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:49:58,451:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:49:58,451:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 10:49:58,546:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:49:58,597:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:49:58,597:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:49:58,685:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 10:49:58,739:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:49:58,739:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:49:58,739:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 10:49:58,882:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:49:58,882:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:49:59,026:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:49:59,026:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:49:59,027:INFO:Preparing preprocessing pipeline...
2023-10-24 10:49:59,028:INFO:Set up date feature engineering.
2023-10-24 10:49:59,028:INFO:Set up simple imputation.
2023-10-24 10:49:59,039:INFO:Set up encoding of ordinal features.
2023-10-24 10:49:59,052:INFO:Set up encoding of categorical features.
2023-10-24 10:49:59,056:INFO:Set up column name cleaning.
2023-10-24 10:49:59,350:INFO:Finished creating preprocessing pipeline.
2023-10-24 10:49:59,433:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 10:49:59,433:INFO:Creating final display dataframe.
2023-10-24 10:49:59,837:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (26071, 48)
4        Transformed data shape  (26071, 52)
5   Transformed train set shape  (18249, 52)
6    Transformed test set shape   (7822, 52)
7              Ordinal features            2
8              Numeric features           43
9                 Date features            1
10         Categorical features            3
11     Rows with missing values        95.9%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18               Fold Generator        KFold
19                  Fold Number           10
20                     CPU Jobs           -1
21                      Use GPU        False
22               Log Experiment        False
23              Experiment Name        exp_C
24                          USI         0e3a
2023-10-24 10:49:59,983:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:49:59,983:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:50:00,133:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 10:50:00,133:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 10:50:00,133:INFO:setup() successfully completed in 3.06s...............
2023-10-24 10:50:00,133:INFO:Initializing compare_models()
2023-10-24 10:50:00,133:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CD64F970>, include=['lightgbm'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000166CD64F970>, 'include': ['lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-10-24 10:50:00,133:INFO:Checking exceptions
2023-10-24 10:50:00,133:INFO:Preparing display monitor
2023-10-24 10:50:00,149:INFO:Initializing Light Gradient Boosting Machine
2023-10-24 10:50:00,149:INFO:Total runtime is 0.0 minutes
2023-10-24 10:50:00,149:INFO:SubProcess create_model() called ==================================
2023-10-24 10:50:00,149:INFO:Initializing create_model()
2023-10-24 10:50:00,149:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CD64F970>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166CCA4FE50>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 10:50:00,149:INFO:Checking exceptions
2023-10-24 10:50:00,149:INFO:Importing libraries
2023-10-24 10:50:00,149:INFO:Copying training dataset
2023-10-24 10:50:00,181:INFO:Defining folds
2023-10-24 10:50:00,181:INFO:Declaring metric variables
2023-10-24 10:50:00,181:INFO:Importing untrained model
2023-10-24 10:50:00,182:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 10:50:00,183:INFO:Starting cross validation
2023-10-24 10:50:00,183:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 10:50:03,379:INFO:Calculating mean and std
2023-10-24 10:50:03,380:INFO:Creating metrics dataframe
2023-10-24 10:50:03,380:INFO:Uploading results into container
2023-10-24 10:50:03,380:INFO:Uploading model into container now
2023-10-24 10:50:03,380:INFO:_master_model_container: 1
2023-10-24 10:50:03,380:INFO:_display_container: 2
2023-10-24 10:50:03,380:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 10:50:03,380:INFO:create_model() successfully completed......................................
2023-10-24 10:50:03,551:INFO:SubProcess create_model() end ==================================
2023-10-24 10:50:03,551:INFO:Creating metrics dataframe
2023-10-24 10:50:03,559:INFO:Initializing create_model()
2023-10-24 10:50:03,560:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CD64F970>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 10:50:03,560:INFO:Checking exceptions
2023-10-24 10:50:03,561:INFO:Importing libraries
2023-10-24 10:50:03,561:INFO:Copying training dataset
2023-10-24 10:50:03,581:INFO:Defining folds
2023-10-24 10:50:03,581:INFO:Declaring metric variables
2023-10-24 10:50:03,581:INFO:Importing untrained model
2023-10-24 10:50:03,581:INFO:Declaring custom model
2023-10-24 10:50:03,582:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 10:50:03,583:INFO:Cross validation set to False
2023-10-24 10:50:03,584:INFO:Fitting Model
2023-10-24 10:50:03,796:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004663 seconds.
2023-10-24 10:50:03,796:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:50:03,796:INFO:[LightGBM] [Info] Total Bins 6598
2023-10-24 10:50:03,796:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 47
2023-10-24 10:50:03,796:INFO:[LightGBM] [Info] Start training from score 96.094131
2023-10-24 10:50:03,946:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 10:50:03,946:INFO:create_model() successfully completed......................................
2023-10-24 10:50:04,112:INFO:_master_model_container: 1
2023-10-24 10:50:04,112:INFO:_display_container: 2
2023-10-24 10:50:04,112:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 10:50:04,112:INFO:compare_models() successfully completed......................................
2023-10-24 10:50:04,112:INFO:Initializing tune_model()
2023-10-24 10:50:04,112:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CD64F970>)
2023-10-24 10:50:04,112:INFO:Checking exceptions
2023-10-24 10:50:04,124:INFO:Copying training dataset
2023-10-24 10:50:04,124:INFO:Checking base model
2023-10-24 10:50:04,124:INFO:Base model : Light Gradient Boosting Machine
2023-10-24 10:50:04,124:INFO:Declaring metric variables
2023-10-24 10:50:04,124:INFO:Defining Hyperparameters
2023-10-24 10:50:04,266:INFO:Tuning with n_jobs=-1
2023-10-24 10:50:04,266:INFO:Initializing RandomizedSearchCV
2023-10-24 10:50:45,185:INFO:best_params: {'actual_estimator__reg_lambda': 0.1, 'actual_estimator__reg_alpha': 0.0001, 'actual_estimator__num_leaves': 10, 'actual_estimator__n_estimators': 180, 'actual_estimator__min_split_gain': 0.7, 'actual_estimator__min_child_samples': 96, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__feature_fraction': 0.9, 'actual_estimator__bagging_freq': 4, 'actual_estimator__bagging_fraction': 0.6}
2023-10-24 10:50:45,187:INFO:Hyperparameter search completed
2023-10-24 10:50:45,187:INFO:SubProcess create_model() called ==================================
2023-10-24 10:50:45,188:INFO:Initializing create_model()
2023-10-24 10:50:45,189:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CD64F970>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166CBCFC820>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 0.1, 'reg_alpha': 0.0001, 'num_leaves': 10, 'n_estimators': 180, 'min_split_gain': 0.7, 'min_child_samples': 96, 'learning_rate': 0.05, 'feature_fraction': 0.9, 'bagging_freq': 4, 'bagging_fraction': 0.6})
2023-10-24 10:50:45,189:INFO:Checking exceptions
2023-10-24 10:50:45,189:INFO:Importing libraries
2023-10-24 10:50:45,189:INFO:Copying training dataset
2023-10-24 10:50:45,218:INFO:Defining folds
2023-10-24 10:50:45,218:INFO:Declaring metric variables
2023-10-24 10:50:45,218:INFO:Importing untrained model
2023-10-24 10:50:45,218:INFO:Declaring custom model
2023-10-24 10:50:45,220:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 10:50:45,220:INFO:Starting cross validation
2023-10-24 10:50:45,223:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 10:50:47,278:INFO:Calculating mean and std
2023-10-24 10:50:47,280:INFO:Creating metrics dataframe
2023-10-24 10:50:47,284:INFO:Finalizing model
2023-10-24 10:50:47,478:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:50:47,478:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:50:47,478:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:50:47,510:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:50:47,510:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:50:47,510:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:50:47,510:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004643 seconds.
2023-10-24 10:50:47,510:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:50:47,510:INFO:[LightGBM] [Info] Total Bins 6598
2023-10-24 10:50:47,510:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 47
2023-10-24 10:50:47,525:INFO:[LightGBM] [Info] Start training from score 96.094131
2023-10-24 10:50:47,693:INFO:Uploading results into container
2023-10-24 10:50:47,693:INFO:Uploading model into container now
2023-10-24 10:50:47,693:INFO:_master_model_container: 2
2023-10-24 10:50:47,693:INFO:_display_container: 3
2023-10-24 10:50:47,693:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9,
              learning_rate=0.05, min_child_samples=96, min_split_gain=0.7,
              n_estimators=180, n_jobs=-1, num_leaves=10, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.1)
2023-10-24 10:50:47,693:INFO:create_model() successfully completed......................................
2023-10-24 10:50:47,867:INFO:SubProcess create_model() end ==================================
2023-10-24 10:50:47,867:INFO:choose_better activated
2023-10-24 10:50:47,867:INFO:SubProcess create_model() called ==================================
2023-10-24 10:50:47,867:INFO:Initializing create_model()
2023-10-24 10:50:47,867:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CD64F970>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 10:50:47,867:INFO:Checking exceptions
2023-10-24 10:50:47,867:INFO:Importing libraries
2023-10-24 10:50:47,867:INFO:Copying training dataset
2023-10-24 10:50:47,882:INFO:Defining folds
2023-10-24 10:50:47,882:INFO:Declaring metric variables
2023-10-24 10:50:47,882:INFO:Importing untrained model
2023-10-24 10:50:47,882:INFO:Declaring custom model
2023-10-24 10:50:47,882:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 10:50:47,882:INFO:Starting cross validation
2023-10-24 10:50:47,882:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 10:50:50,219:INFO:Calculating mean and std
2023-10-24 10:50:50,219:INFO:Creating metrics dataframe
2023-10-24 10:50:50,219:INFO:Finalizing model
2023-10-24 10:50:50,406:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003358 seconds.
2023-10-24 10:50:50,406:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:50:50,406:INFO:[LightGBM] [Info] Total Bins 6598
2023-10-24 10:50:50,406:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 47
2023-10-24 10:50:50,422:INFO:[LightGBM] [Info] Start training from score 96.094131
2023-10-24 10:50:50,551:INFO:Uploading results into container
2023-10-24 10:50:50,551:INFO:Uploading model into container now
2023-10-24 10:50:50,551:INFO:_master_model_container: 3
2023-10-24 10:50:50,551:INFO:_display_container: 4
2023-10-24 10:50:50,551:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 10:50:50,563:INFO:create_model() successfully completed......................................
2023-10-24 10:50:50,704:INFO:SubProcess create_model() end ==================================
2023-10-24 10:50:50,704:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.4151
2023-10-24 10:50:50,704:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9,
              learning_rate=0.05, min_child_samples=96, min_split_gain=0.7,
              n_estimators=180, n_jobs=-1, num_leaves=10, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.1) result for R2 is 0.5032
2023-10-24 10:50:50,704:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9,
              learning_rate=0.05, min_child_samples=96, min_split_gain=0.7,
              n_estimators=180, n_jobs=-1, num_leaves=10, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.1) is best model
2023-10-24 10:50:50,704:INFO:choose_better completed
2023-10-24 10:50:50,720:INFO:_master_model_container: 3
2023-10-24 10:50:50,720:INFO:_display_container: 3
2023-10-24 10:50:50,720:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9,
              learning_rate=0.05, min_child_samples=96, min_split_gain=0.7,
              n_estimators=180, n_jobs=-1, num_leaves=10, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.1)
2023-10-24 10:50:50,720:INFO:tune_model() successfully completed......................................
2023-10-24 10:50:50,854:INFO:Initializing ensemble_model()
2023-10-24 10:50:50,855:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CD64F970>, estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9,
              learning_rate=0.05, min_child_samples=96, min_split_gain=0.7,
              n_estimators=180, n_jobs=-1, num_leaves=10, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.1), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=True, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-24 10:50:50,855:INFO:Checking exceptions
2023-10-24 10:50:50,859:INFO:Importing libraries
2023-10-24 10:50:50,859:INFO:Copying training dataset
2023-10-24 10:50:50,859:INFO:Checking base model
2023-10-24 10:50:50,859:INFO:Base model : Light Gradient Boosting Machine
2023-10-24 10:50:50,859:INFO:Importing untrained ensembler
2023-10-24 10:50:50,859:INFO:Ensemble method set to Bagging
2023-10-24 10:50:50,859:INFO:SubProcess create_model() called ==================================
2023-10-24 10:50:50,859:INFO:Initializing create_model()
2023-10-24 10:50:50,859:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CD64F970>, estimator=BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=4,
                                         feature_fraction=0.9,
                                         learning_rate=0.05,
                                         min_child_samples=96,
                                         min_split_gain=0.7, n_estimators=180,
                                         n_jobs=-1, num_leaves=10,
                                         random_state=123, reg_alpha=0.0001,
                                         reg_lambda=0.1),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166CC494AC0>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 10:50:50,859:INFO:Checking exceptions
2023-10-24 10:50:50,859:INFO:Importing libraries
2023-10-24 10:50:50,859:INFO:Copying training dataset
2023-10-24 10:50:50,874:INFO:Defining folds
2023-10-24 10:50:50,874:INFO:Declaring metric variables
2023-10-24 10:50:50,874:INFO:Importing untrained model
2023-10-24 10:50:50,874:INFO:Declaring custom model
2023-10-24 10:50:50,874:INFO:Bagging Regressor Imported successfully
2023-10-24 10:50:50,874:INFO:Starting cross validation
2023-10-24 10:50:50,874:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 10:51:07,133:INFO:Calculating mean and std
2023-10-24 10:51:07,133:INFO:Creating metrics dataframe
2023-10-24 10:51:07,133:INFO:Finalizing model
2023-10-24 10:51:07,340:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:51:07,340:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:51:07,340:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:51:07,373:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:51:07,373:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:51:07,373:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:51:07,373:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004143 seconds.
2023-10-24 10:51:07,373:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:51:07,373:INFO:[LightGBM] [Info] Total Bins 6598
2023-10-24 10:51:07,373:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 47
2023-10-24 10:51:07,387:INFO:[LightGBM] [Info] Start training from score 98.024703
2023-10-24 10:51:07,593:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:51:07,593:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:51:07,593:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:51:07,628:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:51:07,628:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:51:07,628:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:51:07,629:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005147 seconds.
2023-10-24 10:51:07,629:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:51:07,629:INFO:[LightGBM] [Info] Total Bins 6598
2023-10-24 10:51:07,629:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 47
2023-10-24 10:51:07,629:INFO:[LightGBM] [Info] Start training from score 98.611661
2023-10-24 10:51:07,829:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:51:07,829:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:51:07,829:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:51:07,876:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:51:07,876:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:51:07,876:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:51:07,879:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006196 seconds.
2023-10-24 10:51:07,879:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:51:07,879:INFO:[LightGBM] [Info] Total Bins 6598
2023-10-24 10:51:07,879:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 47
2023-10-24 10:51:07,879:INFO:[LightGBM] [Info] Start training from score 96.858305
2023-10-24 10:51:08,078:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:51:08,078:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:51:08,078:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:51:08,111:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:51:08,111:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:51:08,111:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:51:08,111:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005045 seconds.
2023-10-24 10:51:08,111:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:51:08,126:INFO:[LightGBM] [Info] Total Bins 6598
2023-10-24 10:51:08,126:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 47
2023-10-24 10:51:08,128:INFO:[LightGBM] [Info] Start training from score 97.841580
2023-10-24 10:51:08,310:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:51:08,311:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:51:08,311:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:51:08,329:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:51:08,329:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:51:08,329:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:51:08,345:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004703 seconds.
2023-10-24 10:51:08,345:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:51:08,345:INFO:[LightGBM] [Info] Total Bins 6598
2023-10-24 10:51:08,345:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 47
2023-10-24 10:51:08,345:INFO:[LightGBM] [Info] Start training from score 92.212045
2023-10-24 10:51:08,506:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:51:08,506:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:51:08,506:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:51:08,536:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:51:08,536:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:51:08,536:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:51:08,542:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005073 seconds.
2023-10-24 10:51:08,543:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:51:08,543:INFO:[LightGBM] [Info] Total Bins 6598
2023-10-24 10:51:08,543:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 47
2023-10-24 10:51:08,544:INFO:[LightGBM] [Info] Start training from score 95.321903
2023-10-24 10:51:08,719:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:51:08,720:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:51:08,720:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:51:08,761:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:51:08,761:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:51:08,761:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:51:08,768:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005306 seconds.
2023-10-24 10:51:08,768:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:51:08,769:INFO:[LightGBM] [Info] Total Bins 6598
2023-10-24 10:51:08,769:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 47
2023-10-24 10:51:08,771:INFO:[LightGBM] [Info] Start training from score 95.132336
2023-10-24 10:51:09,042:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:51:09,042:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:51:09,042:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:51:09,075:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:51:09,075:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:51:09,075:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:51:09,089:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004063 seconds.
2023-10-24 10:51:09,089:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:51:09,089:INFO:[LightGBM] [Info] Total Bins 6598
2023-10-24 10:51:09,089:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 47
2023-10-24 10:51:09,089:INFO:[LightGBM] [Info] Start training from score 96.174684
2023-10-24 10:51:09,275:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:51:09,275:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:51:09,275:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:51:09,294:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:51:09,294:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:51:09,294:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:51:09,310:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004353 seconds.
2023-10-24 10:51:09,310:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:51:09,310:INFO:[LightGBM] [Info] Total Bins 6598
2023-10-24 10:51:09,310:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 47
2023-10-24 10:51:09,310:INFO:[LightGBM] [Info] Start training from score 94.903567
2023-10-24 10:51:09,510:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:51:09,510:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:51:09,510:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:51:09,553:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:51:09,553:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:51:09,553:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:51:09,561:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004703 seconds.
2023-10-24 10:51:09,562:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:51:09,562:INFO:[LightGBM] [Info] Total Bins 6598
2023-10-24 10:51:09,562:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 47
2023-10-24 10:51:09,563:INFO:[LightGBM] [Info] Start training from score 96.260069
2023-10-24 10:51:09,760:INFO:Uploading results into container
2023-10-24 10:51:09,761:INFO:Uploading model into container now
2023-10-24 10:51:09,762:INFO:_master_model_container: 4
2023-10-24 10:51:09,763:INFO:_display_container: 4
2023-10-24 10:51:09,767:INFO:BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=4,
                                         feature_fraction=0.9,
                                         learning_rate=0.05,
                                         min_child_samples=96,
                                         min_split_gain=0.7, n_estimators=180,
                                         n_jobs=-1, num_leaves=10,
                                         random_state=123, reg_alpha=0.0001,
                                         reg_lambda=0.1),
                 random_state=123)
2023-10-24 10:51:09,768:INFO:create_model() successfully completed......................................
2023-10-24 10:51:09,933:INFO:SubProcess create_model() end ==================================
2023-10-24 10:51:09,933:INFO:choose_better activated
2023-10-24 10:51:09,933:INFO:SubProcess create_model() called ==================================
2023-10-24 10:51:09,933:INFO:Initializing create_model()
2023-10-24 10:51:09,933:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CD64F970>, estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9,
              learning_rate=0.05, min_child_samples=96, min_split_gain=0.7,
              n_estimators=180, n_jobs=-1, num_leaves=10, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 10:51:09,933:INFO:Checking exceptions
2023-10-24 10:51:09,933:INFO:Importing libraries
2023-10-24 10:51:09,933:INFO:Copying training dataset
2023-10-24 10:51:09,958:INFO:Defining folds
2023-10-24 10:51:09,958:INFO:Declaring metric variables
2023-10-24 10:51:09,958:INFO:Importing untrained model
2023-10-24 10:51:09,959:INFO:Declaring custom model
2023-10-24 10:51:09,960:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 10:51:09,960:INFO:Starting cross validation
2023-10-24 10:51:09,962:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 10:51:12,940:INFO:Calculating mean and std
2023-10-24 10:51:12,940:INFO:Creating metrics dataframe
2023-10-24 10:51:12,940:INFO:Finalizing model
2023-10-24 10:51:13,106:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:51:13,106:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:51:13,106:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:51:13,165:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 10:51:13,165:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 10:51:13,165:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 10:51:13,165:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004381 seconds.
2023-10-24 10:51:13,165:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:51:13,165:INFO:[LightGBM] [Info] Total Bins 6598
2023-10-24 10:51:13,165:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 47
2023-10-24 10:51:13,178:INFO:[LightGBM] [Info] Start training from score 96.094131
2023-10-24 10:51:13,307:INFO:Uploading results into container
2023-10-24 10:51:13,307:INFO:Uploading model into container now
2023-10-24 10:51:13,307:INFO:_master_model_container: 5
2023-10-24 10:51:13,307:INFO:_display_container: 5
2023-10-24 10:51:13,307:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9,
              learning_rate=0.05, min_child_samples=96, min_split_gain=0.7,
              n_estimators=180, n_jobs=-1, num_leaves=10, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.1)
2023-10-24 10:51:13,307:INFO:create_model() successfully completed......................................
2023-10-24 10:51:13,469:INFO:SubProcess create_model() end ==================================
2023-10-24 10:51:13,469:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9,
              learning_rate=0.05, min_child_samples=96, min_split_gain=0.7,
              n_estimators=180, n_jobs=-1, num_leaves=10, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.1) result for R2 is 0.5032
2023-10-24 10:51:13,469:INFO:BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=4,
                                         feature_fraction=0.9,
                                         learning_rate=0.05,
                                         min_child_samples=96,
                                         min_split_gain=0.7, n_estimators=180,
                                         n_jobs=-1, num_leaves=10,
                                         random_state=123, reg_alpha=0.0001,
                                         reg_lambda=0.1),
                 random_state=123) result for R2 is 0.3804
2023-10-24 10:51:13,469:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9,
              learning_rate=0.05, min_child_samples=96, min_split_gain=0.7,
              n_estimators=180, n_jobs=-1, num_leaves=10, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.1) is best model
2023-10-24 10:51:13,469:INFO:choose_better completed
2023-10-24 10:51:13,469:INFO:Original model was better than the ensembled model, hence it will be returned. NOTE: The display metrics are for the ensembled model (not the original one).
2023-10-24 10:51:13,479:INFO:_master_model_container: 5
2023-10-24 10:51:13,479:INFO:_display_container: 4
2023-10-24 10:51:13,479:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9,
              learning_rate=0.05, min_child_samples=96, min_split_gain=0.7,
              n_estimators=180, n_jobs=-1, num_leaves=10, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.1)
2023-10-24 10:51:13,479:INFO:ensemble_model() successfully completed......................................
2023-10-24 10:51:13,610:INFO:Initializing finalize_model()
2023-10-24 10:51:13,610:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CD64F970>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-24 10:51:13,611:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 10:51:13,622:INFO:Initializing create_model()
2023-10-24 10:51:13,622:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CD64F970>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-24 10:51:13,622:INFO:Checking exceptions
2023-10-24 10:51:13,623:INFO:Importing libraries
2023-10-24 10:51:13,623:INFO:Copying training dataset
2023-10-24 10:51:13,624:INFO:Defining folds
2023-10-24 10:51:13,624:INFO:Declaring metric variables
2023-10-24 10:51:13,624:INFO:Importing untrained model
2023-10-24 10:51:13,624:INFO:Declaring custom model
2023-10-24 10:51:13,625:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 10:51:13,627:INFO:Cross validation set to False
2023-10-24 10:51:13,627:INFO:Fitting Model
2023-10-24 10:51:13,882:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005439 seconds.
2023-10-24 10:51:13,882:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 10:51:13,883:INFO:[LightGBM] [Info] Total Bins 6987
2023-10-24 10:51:13,884:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 48
2023-10-24 10:51:13,884:INFO:[LightGBM] [Info] Start training from score 77.700043
2023-10-24 10:51:14,152:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 10:51:14,152:INFO:create_model() successfully completed......................................
2023-10-24 10:51:14,279:INFO:_master_model_container: 5
2023-10-24 10:51:14,279:INFO:_display_container: 4
2023-10-24 10:51:14,341:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 10:51:14,341:INFO:finalize_model() successfully completed......................................
2023-10-24 10:51:14,582:INFO:Initializing save_model()
2023-10-24 10:51:14,582:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_C, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-24 10:51:14,582:INFO:Adding model into prep_pipe
2023-10-24 10:51:14,582:WARNING:Only Model saved as it was a pipeline.
2023-10-24 10:51:14,582:INFO:final_model_for_location_C.pkl saved in current working directory
2023-10-24 10:51:14,680:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 10:51:14,680:INFO:save_model() successfully completed......................................
2023-10-24 10:51:14,880:INFO:Initializing load_model()
2023-10-24 10:51:14,880:INFO:load_model(model_name=final_model_for_location_A, platform=None, authentication=None, verbose=True)
2023-10-24 10:51:14,893:INFO:Initializing load_model()
2023-10-24 10:51:14,893:INFO:load_model(model_name=final_model_for_location_B, platform=None, authentication=None, verbose=True)
2023-10-24 10:51:14,914:INFO:Initializing load_model()
2023-10-24 10:51:14,914:INFO:load_model(model_name=final_model_for_location_C, platform=None, authentication=None, verbose=True)
2023-10-24 10:51:15,040:INFO:Initializing predict_model()
2023-10-24 10:51:15,040:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CD64F970>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000166D0DA9940>)
2023-10-24 10:51:15,040:INFO:Checking exceptions
2023-10-24 10:51:15,040:INFO:Preloading libraries
2023-10-24 10:51:15,040:INFO:Set up data.
2023-10-24 10:51:15,055:INFO:Set up index.
2023-10-24 10:51:15,304:INFO:Initializing predict_model()
2023-10-24 10:51:15,304:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CD64F970>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000166D0DA9940>)
2023-10-24 10:51:15,304:INFO:Checking exceptions
2023-10-24 10:51:15,304:INFO:Preloading libraries
2023-10-24 10:51:15,304:INFO:Set up data.
2023-10-24 10:51:15,319:INFO:Set up index.
2023-10-24 10:51:15,569:INFO:Initializing predict_model()
2023-10-24 10:51:15,569:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CD64F970>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000166D0DA9940>)
2023-10-24 10:51:15,569:INFO:Checking exceptions
2023-10-24 10:51:15,569:INFO:Preloading libraries
2023-10-24 10:51:15,569:INFO:Set up data.
2023-10-24 10:51:15,581:INFO:Set up index.
2023-10-24 11:45:18,401:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_1136\1075571308.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  a = merged_data_a.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 11:45:18,444:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_1136\1075571308.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  b = merged_data_b.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 11:45:18,481:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_1136\1075571308.py:3: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  c = merged_data_c.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 11:45:18,514:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_1136\1075571308.py:21: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  X_test_a = X_test_estimated_a.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 11:45:18,529:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_1136\1075571308.py:22: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  X_test_b = X_test_estimated_b.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 11:45:18,530:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_1136\1075571308.py:23: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  X_test_c = X_test_estimated_c.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 11:45:18,614:INFO:PyCaret RegressionExperiment
2023-10-24 11:45:18,614:INFO:Logging name: exp_A
2023-10-24 11:45:18,614:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 11:45:18,615:INFO:version 3.1.0
2023-10-24 11:45:18,615:INFO:Initializing setup()
2023-10-24 11:45:18,615:INFO:self.USI: 19e1
2023-10-24 11:45:18,616:INFO:self._variable_keys: {'seed', 'logging_param', 'html_param', 'USI', 'data', 'y_train', 'pipeline', '_ml_usecase', 'gpu_n_jobs_param', 'X_test', 'X_train', 'memory', 'X', 'y_test', 'fold_shuffle_param', 'n_jobs_param', 'exp_name_log', 'y', '_available_plots', 'target_param', 'exp_id', 'idx', 'transform_target_param', 'log_plots_param', 'fold_groups_param', 'gpu_param', 'fold_generator'}
2023-10-24 11:45:18,617:INFO:Checking environment
2023-10-24 11:45:18,617:INFO:python_version: 3.8.18
2023-10-24 11:45:18,617:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-24 11:45:18,617:INFO:machine: AMD64
2023-10-24 11:45:18,617:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-24 11:45:18,618:INFO:Memory: svmem(total=16505954304, available=6157520896, percent=62.7, used=10348433408, free=6157520896)
2023-10-24 11:45:18,618:INFO:Physical Core: 8
2023-10-24 11:45:18,618:INFO:Logical Core: 16
2023-10-24 11:45:18,618:INFO:Checking libraries
2023-10-24 11:45:18,619:INFO:System:
2023-10-24 11:45:18,619:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-24 11:45:18,619:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-24 11:45:18,619:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-24 11:45:18,619:INFO:PyCaret required dependencies:
2023-10-24 11:45:18,619:INFO:                 pip: 23.3
2023-10-24 11:45:18,619:INFO:          setuptools: 68.0.0
2023-10-24 11:45:18,619:INFO:             pycaret: 3.1.0
2023-10-24 11:45:18,619:INFO:             IPython: 8.12.0
2023-10-24 11:45:18,619:INFO:          ipywidgets: 8.1.1
2023-10-24 11:45:18,619:INFO:                tqdm: 4.66.1
2023-10-24 11:45:18,619:INFO:               numpy: 1.23.5
2023-10-24 11:45:18,619:INFO:              pandas: 1.5.3
2023-10-24 11:45:18,619:INFO:              jinja2: 3.1.2
2023-10-24 11:45:18,619:INFO:               scipy: 1.10.1
2023-10-24 11:45:18,619:INFO:              joblib: 1.3.2
2023-10-24 11:45:18,619:INFO:             sklearn: 1.2.2
2023-10-24 11:45:18,619:INFO:                pyod: 1.1.0
2023-10-24 11:45:18,619:INFO:            imblearn: 0.11.0
2023-10-24 11:45:18,619:INFO:   category_encoders: 2.6.2
2023-10-24 11:45:18,619:INFO:            lightgbm: 4.1.0
2023-10-24 11:45:18,619:INFO:               numba: 0.58.1
2023-10-24 11:45:18,619:INFO:            requests: 2.31.0
2023-10-24 11:45:18,619:INFO:          matplotlib: 3.7.3
2023-10-24 11:45:18,619:INFO:          scikitplot: 0.3.7
2023-10-24 11:45:18,619:INFO:         yellowbrick: 1.5
2023-10-24 11:45:18,619:INFO:              plotly: 5.17.0
2023-10-24 11:45:18,619:INFO:    plotly-resampler: Not installed
2023-10-24 11:45:18,619:INFO:             kaleido: 0.2.1
2023-10-24 11:45:18,619:INFO:           schemdraw: 0.15
2023-10-24 11:45:18,619:INFO:         statsmodels: 0.14.0
2023-10-24 11:45:18,619:INFO:              sktime: 0.21.1
2023-10-24 11:45:18,619:INFO:               tbats: 1.1.3
2023-10-24 11:45:18,619:INFO:            pmdarima: 2.0.3
2023-10-24 11:45:18,619:INFO:              psutil: 5.9.0
2023-10-24 11:45:18,619:INFO:          markupsafe: 2.1.3
2023-10-24 11:45:18,619:INFO:             pickle5: Not installed
2023-10-24 11:45:18,619:INFO:         cloudpickle: 2.2.1
2023-10-24 11:45:18,619:INFO:         deprecation: 2.1.0
2023-10-24 11:45:18,619:INFO:              xxhash: 3.4.1
2023-10-24 11:45:18,619:INFO:           wurlitzer: Not installed
2023-10-24 11:45:18,619:INFO:PyCaret optional dependencies:
2023-10-24 11:45:18,619:INFO:                shap: Not installed
2023-10-24 11:45:18,619:INFO:           interpret: Not installed
2023-10-24 11:45:18,619:INFO:                umap: Not installed
2023-10-24 11:45:18,619:INFO:     ydata_profiling: Not installed
2023-10-24 11:45:18,619:INFO:  explainerdashboard: Not installed
2023-10-24 11:45:18,619:INFO:             autoviz: Not installed
2023-10-24 11:45:18,619:INFO:           fairlearn: Not installed
2023-10-24 11:45:18,619:INFO:          deepchecks: Not installed
2023-10-24 11:45:18,619:INFO:             xgboost: Not installed
2023-10-24 11:45:18,619:INFO:            catboost: 1.2.2
2023-10-24 11:45:18,619:INFO:              kmodes: Not installed
2023-10-24 11:45:18,619:INFO:             mlxtend: Not installed
2023-10-24 11:45:18,619:INFO:       statsforecast: Not installed
2023-10-24 11:45:18,619:INFO:        tune_sklearn: Not installed
2023-10-24 11:45:18,619:INFO:                 ray: Not installed
2023-10-24 11:45:18,619:INFO:            hyperopt: Not installed
2023-10-24 11:45:18,619:INFO:              optuna: Not installed
2023-10-24 11:45:18,619:INFO:               skopt: Not installed
2023-10-24 11:45:18,619:INFO:              mlflow: 2.7.1
2023-10-24 11:45:18,619:INFO:              gradio: Not installed
2023-10-24 11:45:18,619:INFO:             fastapi: Not installed
2023-10-24 11:45:18,619:INFO:             uvicorn: Not installed
2023-10-24 11:45:18,619:INFO:              m2cgen: Not installed
2023-10-24 11:45:18,619:INFO:           evidently: Not installed
2023-10-24 11:45:18,619:INFO:               fugue: Not installed
2023-10-24 11:45:18,619:INFO:           streamlit: Not installed
2023-10-24 11:45:18,619:INFO:             prophet: Not installed
2023-10-24 11:45:18,619:INFO:None
2023-10-24 11:45:18,619:INFO:Set up data.
2023-10-24 11:45:18,646:INFO:Set up folding strategy.
2023-10-24 11:45:18,646:INFO:Set up train/test split.
2023-10-24 11:45:18,661:INFO:Set up index.
2023-10-24 11:45:18,661:INFO:Assigning column types.
2023-10-24 11:45:18,697:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 11:45:18,697:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 11:45:18,701:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:45:18,701:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:45:18,786:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:45:18,845:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:45:18,846:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:45:18,847:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 11:45:18,848:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 11:45:18,853:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:45:18,859:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:45:18,939:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:45:18,988:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:45:18,989:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:45:18,989:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 11:45:18,990:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 11:45:18,995:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:45:19,001:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:45:19,079:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:45:19,128:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:45:19,128:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:45:19,129:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 11:45:19,135:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:45:19,140:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:45:19,211:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:45:19,264:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:45:19,264:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:45:19,264:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 11:45:19,264:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 11:45:19,277:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:45:19,349:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:45:19,396:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:45:19,396:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:45:19,396:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 11:45:19,414:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:45:19,490:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:45:19,527:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:45:19,527:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:45:19,527:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 11:45:19,527:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 11:45:19,615:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:45:19,675:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:45:19,676:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:45:19,676:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 11:45:19,761:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:45:19,817:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:45:19,817:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:45:19,817:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 11:45:19,817:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 11:45:19,911:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:45:19,962:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:45:19,962:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 11:45:20,048:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:45:20,098:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:45:20,098:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 11:45:20,098:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 11:45:20,233:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:45:20,233:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 11:45:20,375:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:45:20,376:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 11:45:20,379:INFO:Preparing preprocessing pipeline...
2023-10-24 11:45:20,379:INFO:Set up date feature engineering.
2023-10-24 11:45:20,379:INFO:Set up simple imputation.
2023-10-24 11:45:20,389:INFO:Set up encoding of ordinal features.
2023-10-24 11:45:20,397:INFO:Set up encoding of categorical features.
2023-10-24 11:45:20,397:INFO:Set up column name cleaning.
2023-10-24 11:45:20,665:INFO:Finished creating preprocessing pipeline.
2023-10-24 11:45:20,712:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 11:45:20,712:INFO:Creating final display dataframe.
2023-10-24 11:45:20,849:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (34061, 48)
4        Transformed data shape  (34061, 52)
5   Transformed train set shape  (23842, 52)
6    Transformed test set shape  (10219, 52)
7              Ordinal features            2
8              Numeric features           43
9                 Date features            1
10         Categorical features            3
11     Rows with missing values        97.6%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18               Fold Generator        KFold
19                  Fold Number           10
20                     CPU Jobs           -1
21                      Use GPU        False
22               Log Experiment        False
23              Experiment Name        exp_A
24                          USI         19e1
2023-10-24 11:45:20,998:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:45:20,998:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 11:45:21,128:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:45:21,128:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 11:45:21,128:INFO:setup() successfully completed in 2.53s...............
2023-10-24 11:45:21,128:INFO:Initializing compare_models()
2023-10-24 11:45:21,128:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CC490B80>, include=['lightgbm'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000166CC490B80>, 'include': ['lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-10-24 11:45:21,128:INFO:Checking exceptions
2023-10-24 11:45:21,144:INFO:Preparing display monitor
2023-10-24 11:45:21,150:INFO:Initializing Light Gradient Boosting Machine
2023-10-24 11:45:21,150:INFO:Total runtime is 0.0 minutes
2023-10-24 11:45:21,150:INFO:SubProcess create_model() called ==================================
2023-10-24 11:45:21,150:INFO:Initializing create_model()
2023-10-24 11:45:21,150:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CC490B80>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166CF42DCA0>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 11:45:21,150:INFO:Checking exceptions
2023-10-24 11:45:21,150:INFO:Importing libraries
2023-10-24 11:45:21,150:INFO:Copying training dataset
2023-10-24 11:45:21,179:INFO:Defining folds
2023-10-24 11:45:21,179:INFO:Declaring metric variables
2023-10-24 11:45:21,179:INFO:Importing untrained model
2023-10-24 11:45:21,180:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 11:45:21,180:INFO:Starting cross validation
2023-10-24 11:45:21,182:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 11:45:29,669:INFO:Calculating mean and std
2023-10-24 11:45:29,671:INFO:Creating metrics dataframe
2023-10-24 11:45:29,677:INFO:Uploading results into container
2023-10-24 11:45:29,678:INFO:Uploading model into container now
2023-10-24 11:45:29,678:INFO:_master_model_container: 1
2023-10-24 11:45:29,678:INFO:_display_container: 2
2023-10-24 11:45:29,678:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 11:45:29,679:INFO:create_model() successfully completed......................................
2023-10-24 11:45:29,857:INFO:SubProcess create_model() end ==================================
2023-10-24 11:45:29,857:INFO:Creating metrics dataframe
2023-10-24 11:45:29,864:INFO:Initializing create_model()
2023-10-24 11:45:29,865:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CC490B80>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 11:45:29,865:INFO:Checking exceptions
2023-10-24 11:45:29,866:INFO:Importing libraries
2023-10-24 11:45:29,866:INFO:Copying training dataset
2023-10-24 11:45:29,888:INFO:Defining folds
2023-10-24 11:45:29,888:INFO:Declaring metric variables
2023-10-24 11:45:29,888:INFO:Importing untrained model
2023-10-24 11:45:29,888:INFO:Declaring custom model
2023-10-24 11:45:29,889:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 11:45:29,890:INFO:Cross validation set to False
2023-10-24 11:45:29,890:INFO:Fitting Model
2023-10-24 11:45:30,126:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004543 seconds.
2023-10-24 11:45:30,127:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:45:30,127:INFO:[LightGBM] [Info] Total Bins 6408
2023-10-24 11:45:30,127:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 11:45:30,128:INFO:[LightGBM] [Info] Start training from score 616.864890
2023-10-24 11:45:30,278:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 11:45:30,278:INFO:create_model() successfully completed......................................
2023-10-24 11:45:30,438:INFO:_master_model_container: 1
2023-10-24 11:45:30,438:INFO:_display_container: 2
2023-10-24 11:45:30,438:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 11:45:30,438:INFO:compare_models() successfully completed......................................
2023-10-24 11:45:30,438:INFO:Initializing tune_model()
2023-10-24 11:45:30,438:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CC490B80>)
2023-10-24 11:45:30,438:INFO:Checking exceptions
2023-10-24 11:45:30,453:INFO:Copying training dataset
2023-10-24 11:45:30,468:INFO:Checking base model
2023-10-24 11:45:30,468:INFO:Base model : Light Gradient Boosting Machine
2023-10-24 11:45:30,469:INFO:Declaring metric variables
2023-10-24 11:45:30,469:INFO:Defining Hyperparameters
2023-10-24 11:45:30,623:INFO:Tuning with n_jobs=-1
2023-10-24 11:45:30,623:INFO:Initializing RandomizedSearchCV
2023-10-24 11:46:17,542:INFO:best_params: {'actual_estimator__reg_lambda': 0.1, 'actual_estimator__reg_alpha': 0.0001, 'actual_estimator__num_leaves': 10, 'actual_estimator__n_estimators': 180, 'actual_estimator__min_split_gain': 0.7, 'actual_estimator__min_child_samples': 96, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__feature_fraction': 0.9, 'actual_estimator__bagging_freq': 4, 'actual_estimator__bagging_fraction': 0.6}
2023-10-24 11:46:17,542:INFO:Hyperparameter search completed
2023-10-24 11:46:17,542:INFO:SubProcess create_model() called ==================================
2023-10-24 11:46:17,542:INFO:Initializing create_model()
2023-10-24 11:46:17,542:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CC490B80>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166CCDFAC40>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 0.1, 'reg_alpha': 0.0001, 'num_leaves': 10, 'n_estimators': 180, 'min_split_gain': 0.7, 'min_child_samples': 96, 'learning_rate': 0.05, 'feature_fraction': 0.9, 'bagging_freq': 4, 'bagging_fraction': 0.6})
2023-10-24 11:46:17,542:INFO:Checking exceptions
2023-10-24 11:46:17,542:INFO:Importing libraries
2023-10-24 11:46:17,542:INFO:Copying training dataset
2023-10-24 11:46:17,575:INFO:Defining folds
2023-10-24 11:46:17,575:INFO:Declaring metric variables
2023-10-24 11:46:17,575:INFO:Importing untrained model
2023-10-24 11:46:17,575:INFO:Declaring custom model
2023-10-24 11:46:17,575:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 11:46:17,575:INFO:Starting cross validation
2023-10-24 11:46:17,575:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 11:46:20,030:INFO:Calculating mean and std
2023-10-24 11:46:20,032:INFO:Creating metrics dataframe
2023-10-24 11:46:20,035:INFO:Finalizing model
2023-10-24 11:46:20,258:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:46:20,258:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:46:20,258:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:46:20,292:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:46:20,292:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:46:20,292:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:46:20,298:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004812 seconds.
2023-10-24 11:46:20,298:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:46:20,299:INFO:[LightGBM] [Info] Total Bins 6400
2023-10-24 11:46:20,299:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-24 11:46:20,300:INFO:[LightGBM] [Info] Start training from score 616.864890
2023-10-24 11:46:20,493:INFO:Uploading results into container
2023-10-24 11:46:20,493:INFO:Uploading model into container now
2023-10-24 11:46:20,493:INFO:_master_model_container: 2
2023-10-24 11:46:20,493:INFO:_display_container: 3
2023-10-24 11:46:20,493:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9,
              learning_rate=0.05, min_child_samples=96, min_split_gain=0.7,
              n_estimators=180, n_jobs=-1, num_leaves=10, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.1)
2023-10-24 11:46:20,493:INFO:create_model() successfully completed......................................
2023-10-24 11:46:20,665:INFO:SubProcess create_model() end ==================================
2023-10-24 11:46:20,665:INFO:choose_better activated
2023-10-24 11:46:20,665:INFO:SubProcess create_model() called ==================================
2023-10-24 11:46:20,665:INFO:Initializing create_model()
2023-10-24 11:46:20,665:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CC490B80>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 11:46:20,665:INFO:Checking exceptions
2023-10-24 11:46:20,665:INFO:Importing libraries
2023-10-24 11:46:20,665:INFO:Copying training dataset
2023-10-24 11:46:20,681:INFO:Defining folds
2023-10-24 11:46:20,681:INFO:Declaring metric variables
2023-10-24 11:46:20,681:INFO:Importing untrained model
2023-10-24 11:46:20,681:INFO:Declaring custom model
2023-10-24 11:46:20,681:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 11:46:20,681:INFO:Starting cross validation
2023-10-24 11:46:20,681:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 11:46:23,191:INFO:Calculating mean and std
2023-10-24 11:46:23,192:INFO:Creating metrics dataframe
2023-10-24 11:46:23,196:INFO:Finalizing model
2023-10-24 11:46:23,418:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004240 seconds.
2023-10-24 11:46:23,418:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:46:23,433:INFO:[LightGBM] [Info] Total Bins 6408
2023-10-24 11:46:23,433:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 11:46:23,433:INFO:[LightGBM] [Info] Start training from score 616.864890
2023-10-24 11:46:23,571:INFO:Uploading results into container
2023-10-24 11:46:23,583:INFO:Uploading model into container now
2023-10-24 11:46:23,583:INFO:_master_model_container: 3
2023-10-24 11:46:23,583:INFO:_display_container: 4
2023-10-24 11:46:23,583:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 11:46:23,583:INFO:create_model() successfully completed......................................
2023-10-24 11:46:23,725:INFO:SubProcess create_model() end ==================================
2023-10-24 11:46:23,725:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.7469
2023-10-24 11:46:23,725:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9,
              learning_rate=0.05, min_child_samples=96, min_split_gain=0.7,
              n_estimators=180, n_jobs=-1, num_leaves=10, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.1) result for R2 is 0.746
2023-10-24 11:46:23,741:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-24 11:46:23,741:INFO:choose_better completed
2023-10-24 11:46:23,741:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-24 11:46:23,741:INFO:_master_model_container: 3
2023-10-24 11:46:23,741:INFO:_display_container: 3
2023-10-24 11:46:23,741:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 11:46:23,741:INFO:tune_model() successfully completed......................................
2023-10-24 11:46:23,879:INFO:Initializing ensemble_model()
2023-10-24 11:46:23,880:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CC490B80>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=True, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-24 11:46:23,880:INFO:Checking exceptions
2023-10-24 11:46:23,891:INFO:Importing libraries
2023-10-24 11:46:23,891:INFO:Copying training dataset
2023-10-24 11:46:23,891:INFO:Checking base model
2023-10-24 11:46:23,892:INFO:Base model : Light Gradient Boosting Machine
2023-10-24 11:46:23,893:INFO:Importing untrained ensembler
2023-10-24 11:46:23,894:INFO:Ensemble method set to Bagging
2023-10-24 11:46:23,894:INFO:SubProcess create_model() called ==================================
2023-10-24 11:46:23,895:INFO:Initializing create_model()
2023-10-24 11:46:23,895:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CC490B80>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166CC3CCD60>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 11:46:23,895:INFO:Checking exceptions
2023-10-24 11:46:23,895:INFO:Importing libraries
2023-10-24 11:46:23,895:INFO:Copying training dataset
2023-10-24 11:46:23,919:INFO:Defining folds
2023-10-24 11:46:23,919:INFO:Declaring metric variables
2023-10-24 11:46:23,920:INFO:Importing untrained model
2023-10-24 11:46:23,920:INFO:Declaring custom model
2023-10-24 11:46:23,921:INFO:Bagging Regressor Imported successfully
2023-10-24 11:46:23,921:INFO:Starting cross validation
2023-10-24 11:46:23,923:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 11:46:43,038:INFO:Calculating mean and std
2023-10-24 11:46:43,040:INFO:Creating metrics dataframe
2023-10-24 11:46:43,044:INFO:Finalizing model
2023-10-24 11:46:43,344:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005042 seconds.
2023-10-24 11:46:43,344:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:46:43,344:INFO:[LightGBM] [Info] Total Bins 6408
2023-10-24 11:46:43,344:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 11:46:43,345:INFO:[LightGBM] [Info] Start training from score 616.125105
2023-10-24 11:46:43,625:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006933 seconds.
2023-10-24 11:46:43,625:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:46:43,626:INFO:[LightGBM] [Info] Total Bins 6408
2023-10-24 11:46:43,627:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 11:46:43,628:INFO:[LightGBM] [Info] Start training from score 613.258669
2023-10-24 11:46:43,875:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004696 seconds.
2023-10-24 11:46:43,875:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:46:43,890:INFO:[LightGBM] [Info] Total Bins 6408
2023-10-24 11:46:43,890:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 11:46:43,891:INFO:[LightGBM] [Info] Start training from score 617.032501
2023-10-24 11:46:44,100:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005278 seconds.
2023-10-24 11:46:44,101:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:46:44,101:INFO:[LightGBM] [Info] Total Bins 6408
2023-10-24 11:46:44,102:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 11:46:44,103:INFO:[LightGBM] [Info] Start training from score 617.633903
2023-10-24 11:46:44,315:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004779 seconds.
2023-10-24 11:46:44,315:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:46:44,316:INFO:[LightGBM] [Info] Total Bins 6408
2023-10-24 11:46:44,316:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 11:46:44,317:INFO:[LightGBM] [Info] Start training from score 624.020441
2023-10-24 11:46:44,526:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005597 seconds.
2023-10-24 11:46:44,526:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:46:44,527:INFO:[LightGBM] [Info] Total Bins 6408
2023-10-24 11:46:44,528:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 11:46:44,529:INFO:[LightGBM] [Info] Start training from score 618.752897
2023-10-24 11:46:44,744:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005024 seconds.
2023-10-24 11:46:44,745:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:46:44,745:INFO:[LightGBM] [Info] Total Bins 6408
2023-10-24 11:46:44,745:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 11:46:44,746:INFO:[LightGBM] [Info] Start training from score 611.671157
2023-10-24 11:46:44,954:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005454 seconds.
2023-10-24 11:46:44,954:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:46:44,954:INFO:[LightGBM] [Info] Total Bins 6408
2023-10-24 11:46:44,956:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 11:46:44,956:INFO:[LightGBM] [Info] Start training from score 617.400574
2023-10-24 11:46:45,195:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005846 seconds.
2023-10-24 11:46:45,195:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:46:45,195:INFO:[LightGBM] [Info] Total Bins 6408
2023-10-24 11:46:45,196:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 11:46:45,196:INFO:[LightGBM] [Info] Start training from score 613.053129
2023-10-24 11:46:45,410:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006380 seconds.
2023-10-24 11:46:45,410:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:46:45,410:INFO:[LightGBM] [Info] Total Bins 6408
2023-10-24 11:46:45,410:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 11:46:45,410:INFO:[LightGBM] [Info] Start training from score 614.380418
2023-10-24 11:46:45,572:INFO:Uploading results into container
2023-10-24 11:46:45,572:INFO:Uploading model into container now
2023-10-24 11:46:45,572:INFO:_master_model_container: 4
2023-10-24 11:46:45,572:INFO:_display_container: 4
2023-10-24 11:46:45,572:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-24 11:46:45,572:INFO:create_model() successfully completed......................................
2023-10-24 11:46:45,722:INFO:SubProcess create_model() end ==================================
2023-10-24 11:46:45,722:INFO:choose_better activated
2023-10-24 11:46:45,722:INFO:SubProcess create_model() called ==================================
2023-10-24 11:46:45,738:INFO:Initializing create_model()
2023-10-24 11:46:45,738:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CC490B80>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 11:46:45,738:INFO:Checking exceptions
2023-10-24 11:46:45,738:INFO:Importing libraries
2023-10-24 11:46:45,738:INFO:Copying training dataset
2023-10-24 11:46:45,754:INFO:Defining folds
2023-10-24 11:46:45,754:INFO:Declaring metric variables
2023-10-24 11:46:45,754:INFO:Importing untrained model
2023-10-24 11:46:45,754:INFO:Declaring custom model
2023-10-24 11:46:45,754:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 11:46:45,754:INFO:Starting cross validation
2023-10-24 11:46:45,754:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 11:46:48,568:INFO:Calculating mean and std
2023-10-24 11:46:48,568:INFO:Creating metrics dataframe
2023-10-24 11:46:48,571:INFO:Finalizing model
2023-10-24 11:46:48,784:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003756 seconds.
2023-10-24 11:46:48,799:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:46:48,799:INFO:[LightGBM] [Info] Total Bins 6408
2023-10-24 11:46:48,800:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 11:46:48,800:INFO:[LightGBM] [Info] Start training from score 616.864890
2023-10-24 11:46:48,962:INFO:Uploading results into container
2023-10-24 11:46:48,963:INFO:Uploading model into container now
2023-10-24 11:46:48,963:INFO:_master_model_container: 5
2023-10-24 11:46:48,963:INFO:_display_container: 5
2023-10-24 11:46:48,964:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 11:46:48,964:INFO:create_model() successfully completed......................................
2023-10-24 11:46:49,126:INFO:SubProcess create_model() end ==================================
2023-10-24 11:46:49,126:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.7469
2023-10-24 11:46:49,127:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123) result for R2 is 0.7576
2023-10-24 11:46:49,128:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123) is best model
2023-10-24 11:46:49,128:INFO:choose_better completed
2023-10-24 11:46:49,132:INFO:_master_model_container: 5
2023-10-24 11:46:49,132:INFO:_display_container: 4
2023-10-24 11:46:49,135:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-24 11:46:49,136:INFO:ensemble_model() successfully completed......................................
2023-10-24 11:46:49,271:INFO:Initializing finalize_model()
2023-10-24 11:46:49,271:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CC490B80>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-24 11:46:49,271:INFO:Finalizing BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-24 11:46:49,287:INFO:Initializing create_model()
2023-10-24 11:46:49,288:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166CC490B80>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-24 11:46:49,288:INFO:Checking exceptions
2023-10-24 11:46:49,288:INFO:Importing libraries
2023-10-24 11:46:49,289:INFO:Copying training dataset
2023-10-24 11:46:49,290:INFO:Defining folds
2023-10-24 11:46:49,290:INFO:Declaring metric variables
2023-10-24 11:46:49,290:INFO:Importing untrained model
2023-10-24 11:46:49,290:INFO:Declaring custom model
2023-10-24 11:46:49,291:INFO:Bagging Regressor Imported successfully
2023-10-24 11:46:49,293:INFO:Cross validation set to False
2023-10-24 11:46:49,293:INFO:Fitting Model
2023-10-24 11:46:49,624:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007168 seconds.
2023-10-24 11:46:49,624:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:46:49,625:INFO:[LightGBM] [Info] Total Bins 6836
2023-10-24 11:46:49,625:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 47
2023-10-24 11:46:49,626:INFO:[LightGBM] [Info] Start training from score 627.920236
2023-10-24 11:46:49,914:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006916 seconds.
2023-10-24 11:46:49,914:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:46:49,915:INFO:[LightGBM] [Info] Total Bins 6836
2023-10-24 11:46:49,915:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 47
2023-10-24 11:46:49,916:INFO:[LightGBM] [Info] Start training from score 634.755509
2023-10-24 11:46:50,145:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007848 seconds.
2023-10-24 11:46:50,145:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:46:50,145:INFO:[LightGBM] [Info] Total Bins 6836
2023-10-24 11:46:50,145:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 47
2023-10-24 11:46:50,145:INFO:[LightGBM] [Info] Start training from score 627.098393
2023-10-24 11:46:50,396:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006340 seconds.
2023-10-24 11:46:50,396:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:46:50,396:INFO:[LightGBM] [Info] Total Bins 6836
2023-10-24 11:46:50,396:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 47
2023-10-24 11:46:50,396:INFO:[LightGBM] [Info] Start training from score 630.777059
2023-10-24 11:46:50,658:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008336 seconds.
2023-10-24 11:46:50,658:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:46:50,659:INFO:[LightGBM] [Info] Total Bins 6836
2023-10-24 11:46:50,659:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 47
2023-10-24 11:46:50,660:INFO:[LightGBM] [Info] Start training from score 634.111214
2023-10-24 11:46:50,956:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005855 seconds.
2023-10-24 11:46:50,956:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:46:50,957:INFO:[LightGBM] [Info] Total Bins 6836
2023-10-24 11:46:50,958:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 47
2023-10-24 11:46:50,958:INFO:[LightGBM] [Info] Start training from score 619.898739
2023-10-24 11:46:51,215:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007466 seconds.
2023-10-24 11:46:51,215:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:46:51,215:INFO:[LightGBM] [Info] Total Bins 6836
2023-10-24 11:46:51,215:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 47
2023-10-24 11:46:51,215:INFO:[LightGBM] [Info] Start training from score 626.850229
2023-10-24 11:46:51,473:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006853 seconds.
2023-10-24 11:46:51,473:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:46:51,473:INFO:[LightGBM] [Info] Total Bins 6836
2023-10-24 11:46:51,474:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 47
2023-10-24 11:46:51,474:INFO:[LightGBM] [Info] Start training from score 632.505396
2023-10-24 11:46:51,729:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007130 seconds.
2023-10-24 11:46:51,729:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:46:51,730:INFO:[LightGBM] [Info] Total Bins 6836
2023-10-24 11:46:51,730:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 47
2023-10-24 11:46:51,731:INFO:[LightGBM] [Info] Start training from score 618.587660
2023-10-24 11:46:51,983:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008052 seconds.
2023-10-24 11:46:51,983:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:46:51,983:INFO:[LightGBM] [Info] Total Bins 6836
2023-10-24 11:46:51,983:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 47
2023-10-24 11:46:51,983:INFO:[LightGBM] [Info] Start training from score 630.173794
2023-10-24 11:46:52,282:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-24 11:46:52,282:INFO:create_model() successfully completed......................................
2023-10-24 11:46:52,418:INFO:_master_model_container: 5
2023-10-24 11:46:52,418:INFO:_display_container: 4
2023-10-24 11:46:52,478:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-24 11:46:52,478:INFO:finalize_model() successfully completed......................................
2023-10-24 11:46:52,720:INFO:Initializing save_model()
2023-10-24 11:46:52,720:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), model_name=final_model_for_location_A, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-24 11:46:52,720:INFO:Adding model into prep_pipe
2023-10-24 11:46:52,720:WARNING:Only Model saved as it was a pipeline.
2023-10-24 11:46:52,780:INFO:final_model_for_location_A.pkl saved in current working directory
2023-10-24 11:46:52,878:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-24 11:46:52,878:INFO:save_model() successfully completed......................................
2023-10-24 11:46:53,038:INFO:PyCaret RegressionExperiment
2023-10-24 11:46:53,038:INFO:Logging name: exp_B
2023-10-24 11:46:53,038:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 11:46:53,038:INFO:version 3.1.0
2023-10-24 11:46:53,038:INFO:Initializing setup()
2023-10-24 11:46:53,038:INFO:self.USI: 3500
2023-10-24 11:46:53,038:INFO:self._variable_keys: {'seed', 'logging_param', 'html_param', 'USI', 'data', 'y_train', 'pipeline', '_ml_usecase', 'gpu_n_jobs_param', 'X_test', 'X_train', 'memory', 'X', 'y_test', 'fold_shuffle_param', 'n_jobs_param', 'exp_name_log', 'y', '_available_plots', 'target_param', 'exp_id', 'idx', 'transform_target_param', 'log_plots_param', 'fold_groups_param', 'gpu_param', 'fold_generator'}
2023-10-24 11:46:53,038:INFO:Checking environment
2023-10-24 11:46:53,038:INFO:python_version: 3.8.18
2023-10-24 11:46:53,038:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-24 11:46:53,038:INFO:machine: AMD64
2023-10-24 11:46:53,038:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-24 11:46:53,038:INFO:Memory: svmem(total=16505954304, available=3892494336, percent=76.4, used=12613459968, free=3892494336)
2023-10-24 11:46:53,038:INFO:Physical Core: 8
2023-10-24 11:46:53,038:INFO:Logical Core: 16
2023-10-24 11:46:53,038:INFO:Checking libraries
2023-10-24 11:46:53,038:INFO:System:
2023-10-24 11:46:53,038:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-24 11:46:53,038:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-24 11:46:53,038:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-24 11:46:53,038:INFO:PyCaret required dependencies:
2023-10-24 11:46:53,038:INFO:                 pip: 23.3
2023-10-24 11:46:53,038:INFO:          setuptools: 68.0.0
2023-10-24 11:46:53,038:INFO:             pycaret: 3.1.0
2023-10-24 11:46:53,038:INFO:             IPython: 8.12.0
2023-10-24 11:46:53,038:INFO:          ipywidgets: 8.1.1
2023-10-24 11:46:53,038:INFO:                tqdm: 4.66.1
2023-10-24 11:46:53,038:INFO:               numpy: 1.23.5
2023-10-24 11:46:53,038:INFO:              pandas: 1.5.3
2023-10-24 11:46:53,038:INFO:              jinja2: 3.1.2
2023-10-24 11:46:53,038:INFO:               scipy: 1.10.1
2023-10-24 11:46:53,038:INFO:              joblib: 1.3.2
2023-10-24 11:46:53,038:INFO:             sklearn: 1.2.2
2023-10-24 11:46:53,038:INFO:                pyod: 1.1.0
2023-10-24 11:46:53,038:INFO:            imblearn: 0.11.0
2023-10-24 11:46:53,038:INFO:   category_encoders: 2.6.2
2023-10-24 11:46:53,038:INFO:            lightgbm: 4.1.0
2023-10-24 11:46:53,038:INFO:               numba: 0.58.1
2023-10-24 11:46:53,038:INFO:            requests: 2.31.0
2023-10-24 11:46:53,038:INFO:          matplotlib: 3.7.3
2023-10-24 11:46:53,038:INFO:          scikitplot: 0.3.7
2023-10-24 11:46:53,038:INFO:         yellowbrick: 1.5
2023-10-24 11:46:53,038:INFO:              plotly: 5.17.0
2023-10-24 11:46:53,038:INFO:    plotly-resampler: Not installed
2023-10-24 11:46:53,038:INFO:             kaleido: 0.2.1
2023-10-24 11:46:53,038:INFO:           schemdraw: 0.15
2023-10-24 11:46:53,038:INFO:         statsmodels: 0.14.0
2023-10-24 11:46:53,038:INFO:              sktime: 0.21.1
2023-10-24 11:46:53,038:INFO:               tbats: 1.1.3
2023-10-24 11:46:53,038:INFO:            pmdarima: 2.0.3
2023-10-24 11:46:53,038:INFO:              psutil: 5.9.0
2023-10-24 11:46:53,038:INFO:          markupsafe: 2.1.3
2023-10-24 11:46:53,038:INFO:             pickle5: Not installed
2023-10-24 11:46:53,038:INFO:         cloudpickle: 2.2.1
2023-10-24 11:46:53,038:INFO:         deprecation: 2.1.0
2023-10-24 11:46:53,038:INFO:              xxhash: 3.4.1
2023-10-24 11:46:53,038:INFO:           wurlitzer: Not installed
2023-10-24 11:46:53,038:INFO:PyCaret optional dependencies:
2023-10-24 11:46:53,038:INFO:                shap: Not installed
2023-10-24 11:46:53,038:INFO:           interpret: Not installed
2023-10-24 11:46:53,038:INFO:                umap: Not installed
2023-10-24 11:46:53,038:INFO:     ydata_profiling: Not installed
2023-10-24 11:46:53,038:INFO:  explainerdashboard: Not installed
2023-10-24 11:46:53,038:INFO:             autoviz: Not installed
2023-10-24 11:46:53,038:INFO:           fairlearn: Not installed
2023-10-24 11:46:53,038:INFO:          deepchecks: Not installed
2023-10-24 11:46:53,038:INFO:             xgboost: Not installed
2023-10-24 11:46:53,038:INFO:            catboost: 1.2.2
2023-10-24 11:46:53,038:INFO:              kmodes: Not installed
2023-10-24 11:46:53,038:INFO:             mlxtend: Not installed
2023-10-24 11:46:53,038:INFO:       statsforecast: Not installed
2023-10-24 11:46:53,038:INFO:        tune_sklearn: Not installed
2023-10-24 11:46:53,038:INFO:                 ray: Not installed
2023-10-24 11:46:53,038:INFO:            hyperopt: Not installed
2023-10-24 11:46:53,038:INFO:              optuna: Not installed
2023-10-24 11:46:53,038:INFO:               skopt: Not installed
2023-10-24 11:46:53,038:INFO:              mlflow: 2.7.1
2023-10-24 11:46:53,038:INFO:              gradio: Not installed
2023-10-24 11:46:53,038:INFO:             fastapi: Not installed
2023-10-24 11:46:53,038:INFO:             uvicorn: Not installed
2023-10-24 11:46:53,038:INFO:              m2cgen: Not installed
2023-10-24 11:46:53,038:INFO:           evidently: Not installed
2023-10-24 11:46:53,038:INFO:               fugue: Not installed
2023-10-24 11:46:53,038:INFO:           streamlit: Not installed
2023-10-24 11:46:53,038:INFO:             prophet: Not installed
2023-10-24 11:46:53,047:INFO:None
2023-10-24 11:46:53,047:INFO:Set up data.
2023-10-24 11:46:53,077:INFO:Set up folding strategy.
2023-10-24 11:46:53,077:INFO:Set up train/test split.
2023-10-24 11:46:53,083:INFO:Set up index.
2023-10-24 11:46:53,083:INFO:Assigning column types.
2023-10-24 11:46:53,102:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 11:46:53,102:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 11:46:53,120:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:46:53,126:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:46:53,199:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:46:53,250:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:46:53,250:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:46:53,250:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 11:46:53,250:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 11:46:53,250:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:46:53,267:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:46:53,344:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:46:53,394:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:46:53,395:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:46:53,395:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 11:46:53,396:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 11:46:53,401:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:46:53,406:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:46:53,484:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:46:53,533:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:46:53,534:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:46:53,534:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 11:46:53,540:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:46:53,545:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:46:53,618:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:46:53,671:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:46:53,672:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:46:53,672:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 11:46:53,673:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 11:46:53,683:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:46:53,759:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:46:53,809:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:46:53,810:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:46:53,810:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 11:46:53,820:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:46:53,898:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:46:53,948:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:46:53,949:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:46:53,949:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 11:46:53,950:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 11:46:54,031:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:46:54,078:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:46:54,078:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:46:54,078:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 11:46:54,173:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:46:54,218:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:46:54,218:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:46:54,218:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 11:46:54,218:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 11:46:54,310:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:46:54,360:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:46:54,360:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 11:46:54,445:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:46:54,483:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:46:54,483:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 11:46:54,483:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 11:46:54,632:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:46:54,632:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 11:46:54,779:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:46:54,779:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 11:46:54,781:INFO:Preparing preprocessing pipeline...
2023-10-24 11:46:54,781:INFO:Set up date feature engineering.
2023-10-24 11:46:54,781:INFO:Set up simple imputation.
2023-10-24 11:46:54,791:INFO:Set up encoding of ordinal features.
2023-10-24 11:46:54,803:INFO:Set up encoding of categorical features.
2023-10-24 11:46:54,805:INFO:Set up column name cleaning.
2023-10-24 11:46:55,032:INFO:Finished creating preprocessing pipeline.
2023-10-24 11:46:55,086:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 11:46:55,086:INFO:Creating final display dataframe.
2023-10-24 11:46:55,222:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (32819, 48)
4        Transformed data shape  (32819, 52)
5   Transformed train set shape  (22973, 52)
6    Transformed test set shape   (9846, 52)
7              Ordinal features            2
8              Numeric features           43
9                 Date features            1
10         Categorical features            3
11     Rows with missing values        95.9%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18               Fold Generator        KFold
19                  Fold Number           10
20                     CPU Jobs           -1
21                      Use GPU        False
22               Log Experiment        False
23              Experiment Name        exp_B
24                          USI         3500
2023-10-24 11:46:55,366:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:46:55,366:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 11:46:55,508:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:46:55,508:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 11:46:55,509:INFO:setup() successfully completed in 2.48s...............
2023-10-24 11:46:55,509:INFO:Initializing compare_models()
2023-10-24 11:46:55,509:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166BE4D3490>, include=['lightgbm'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000166BE4D3490>, 'include': ['lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-10-24 11:46:55,509:INFO:Checking exceptions
2023-10-24 11:46:55,518:INFO:Preparing display monitor
2023-10-24 11:46:55,522:INFO:Initializing Light Gradient Boosting Machine
2023-10-24 11:46:55,523:INFO:Total runtime is 1.666545867919922e-05 minutes
2023-10-24 11:46:55,523:INFO:SubProcess create_model() called ==================================
2023-10-24 11:46:55,523:INFO:Initializing create_model()
2023-10-24 11:46:55,523:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166BE4D3490>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166D0D207F0>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 11:46:55,523:INFO:Checking exceptions
2023-10-24 11:46:55,523:INFO:Importing libraries
2023-10-24 11:46:55,523:INFO:Copying training dataset
2023-10-24 11:46:55,546:INFO:Defining folds
2023-10-24 11:46:55,547:INFO:Declaring metric variables
2023-10-24 11:46:55,547:INFO:Importing untrained model
2023-10-24 11:46:55,547:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 11:46:55,548:INFO:Starting cross validation
2023-10-24 11:46:55,549:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 11:46:58,196:INFO:Calculating mean and std
2023-10-24 11:46:58,198:INFO:Creating metrics dataframe
2023-10-24 11:46:58,203:INFO:Uploading results into container
2023-10-24 11:46:58,204:INFO:Uploading model into container now
2023-10-24 11:46:58,204:INFO:_master_model_container: 1
2023-10-24 11:46:58,205:INFO:_display_container: 2
2023-10-24 11:46:58,205:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 11:46:58,206:INFO:create_model() successfully completed......................................
2023-10-24 11:46:58,369:INFO:SubProcess create_model() end ==================================
2023-10-24 11:46:58,369:INFO:Creating metrics dataframe
2023-10-24 11:46:58,376:INFO:Initializing create_model()
2023-10-24 11:46:58,377:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166BE4D3490>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 11:46:58,377:INFO:Checking exceptions
2023-10-24 11:46:58,379:INFO:Importing libraries
2023-10-24 11:46:58,379:INFO:Copying training dataset
2023-10-24 11:46:58,403:INFO:Defining folds
2023-10-24 11:46:58,404:INFO:Declaring metric variables
2023-10-24 11:46:58,404:INFO:Importing untrained model
2023-10-24 11:46:58,404:INFO:Declaring custom model
2023-10-24 11:46:58,405:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 11:46:58,406:INFO:Cross validation set to False
2023-10-24 11:46:58,406:INFO:Fitting Model
2023-10-24 11:46:58,671:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004538 seconds.
2023-10-24 11:46:58,671:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:46:58,671:INFO:[LightGBM] [Info] Total Bins 6444
2023-10-24 11:46:58,672:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 46
2023-10-24 11:46:58,673:INFO:[LightGBM] [Info] Start training from score 117.072182
2023-10-24 11:46:58,825:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 11:46:58,825:INFO:create_model() successfully completed......................................
2023-10-24 11:46:58,977:INFO:_master_model_container: 1
2023-10-24 11:46:58,990:INFO:_display_container: 2
2023-10-24 11:46:58,992:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 11:46:58,992:INFO:compare_models() successfully completed......................................
2023-10-24 11:46:58,992:INFO:Initializing tune_model()
2023-10-24 11:46:58,992:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166BE4D3490>)
2023-10-24 11:46:58,992:INFO:Checking exceptions
2023-10-24 11:46:59,003:INFO:Copying training dataset
2023-10-24 11:46:59,019:INFO:Checking base model
2023-10-24 11:46:59,019:INFO:Base model : Light Gradient Boosting Machine
2023-10-24 11:46:59,020:INFO:Declaring metric variables
2023-10-24 11:46:59,020:INFO:Defining Hyperparameters
2023-10-24 11:46:59,153:INFO:Tuning with n_jobs=-1
2023-10-24 11:46:59,154:INFO:Initializing RandomizedSearchCV
2023-10-24 11:47:46,574:INFO:best_params: {'actual_estimator__reg_lambda': 0.1, 'actual_estimator__reg_alpha': 0.0001, 'actual_estimator__num_leaves': 10, 'actual_estimator__n_estimators': 180, 'actual_estimator__min_split_gain': 0.7, 'actual_estimator__min_child_samples': 96, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__feature_fraction': 0.9, 'actual_estimator__bagging_freq': 4, 'actual_estimator__bagging_fraction': 0.6}
2023-10-24 11:47:46,575:INFO:Hyperparameter search completed
2023-10-24 11:47:46,575:INFO:SubProcess create_model() called ==================================
2023-10-24 11:47:46,575:INFO:Initializing create_model()
2023-10-24 11:47:46,575:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166BE4D3490>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166CF02F610>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 0.1, 'reg_alpha': 0.0001, 'num_leaves': 10, 'n_estimators': 180, 'min_split_gain': 0.7, 'min_child_samples': 96, 'learning_rate': 0.05, 'feature_fraction': 0.9, 'bagging_freq': 4, 'bagging_fraction': 0.6})
2023-10-24 11:47:46,575:INFO:Checking exceptions
2023-10-24 11:47:46,575:INFO:Importing libraries
2023-10-24 11:47:46,575:INFO:Copying training dataset
2023-10-24 11:47:46,593:INFO:Defining folds
2023-10-24 11:47:46,593:INFO:Declaring metric variables
2023-10-24 11:47:46,593:INFO:Importing untrained model
2023-10-24 11:47:46,593:INFO:Declaring custom model
2023-10-24 11:47:46,593:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 11:47:46,607:INFO:Starting cross validation
2023-10-24 11:47:46,609:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 11:47:49,464:INFO:Calculating mean and std
2023-10-24 11:47:49,466:INFO:Creating metrics dataframe
2023-10-24 11:47:49,468:INFO:Finalizing model
2023-10-24 11:47:49,684:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:47:49,684:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:47:49,685:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:47:49,717:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:47:49,717:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:47:49,717:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:47:49,723:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004697 seconds.
2023-10-24 11:47:49,724:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:47:49,724:INFO:[LightGBM] [Info] Total Bins 6442
2023-10-24 11:47:49,724:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-24 11:47:49,726:INFO:[LightGBM] [Info] Start training from score 117.072182
2023-10-24 11:47:49,936:INFO:Uploading results into container
2023-10-24 11:47:49,936:INFO:Uploading model into container now
2023-10-24 11:47:49,936:INFO:_master_model_container: 2
2023-10-24 11:47:49,936:INFO:_display_container: 3
2023-10-24 11:47:49,936:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9,
              learning_rate=0.05, min_child_samples=96, min_split_gain=0.7,
              n_estimators=180, n_jobs=-1, num_leaves=10, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.1)
2023-10-24 11:47:49,936:INFO:create_model() successfully completed......................................
2023-10-24 11:47:50,101:INFO:SubProcess create_model() end ==================================
2023-10-24 11:47:50,101:INFO:choose_better activated
2023-10-24 11:47:50,101:INFO:SubProcess create_model() called ==================================
2023-10-24 11:47:50,101:INFO:Initializing create_model()
2023-10-24 11:47:50,101:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166BE4D3490>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 11:47:50,101:INFO:Checking exceptions
2023-10-24 11:47:50,101:INFO:Importing libraries
2023-10-24 11:47:50,101:INFO:Copying training dataset
2023-10-24 11:47:50,116:INFO:Defining folds
2023-10-24 11:47:50,116:INFO:Declaring metric variables
2023-10-24 11:47:50,116:INFO:Importing untrained model
2023-10-24 11:47:50,116:INFO:Declaring custom model
2023-10-24 11:47:50,116:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 11:47:50,132:INFO:Starting cross validation
2023-10-24 11:47:50,132:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 11:47:53,368:INFO:Calculating mean and std
2023-10-24 11:47:53,368:INFO:Creating metrics dataframe
2023-10-24 11:47:53,368:INFO:Finalizing model
2023-10-24 11:47:53,615:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004823 seconds.
2023-10-24 11:47:53,615:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:47:53,615:INFO:[LightGBM] [Info] Total Bins 6444
2023-10-24 11:47:53,615:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 46
2023-10-24 11:47:53,615:INFO:[LightGBM] [Info] Start training from score 117.072182
2023-10-24 11:47:53,819:INFO:Uploading results into container
2023-10-24 11:47:53,819:INFO:Uploading model into container now
2023-10-24 11:47:53,819:INFO:_master_model_container: 3
2023-10-24 11:47:53,819:INFO:_display_container: 4
2023-10-24 11:47:53,819:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 11:47:53,819:INFO:create_model() successfully completed......................................
2023-10-24 11:47:53,992:INFO:SubProcess create_model() end ==================================
2023-10-24 11:47:53,992:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.5728
2023-10-24 11:47:53,992:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9,
              learning_rate=0.05, min_child_samples=96, min_split_gain=0.7,
              n_estimators=180, n_jobs=-1, num_leaves=10, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.1) result for R2 is 0.5804
2023-10-24 11:47:53,992:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9,
              learning_rate=0.05, min_child_samples=96, min_split_gain=0.7,
              n_estimators=180, n_jobs=-1, num_leaves=10, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.1) is best model
2023-10-24 11:47:53,992:INFO:choose_better completed
2023-10-24 11:47:53,992:INFO:_master_model_container: 3
2023-10-24 11:47:53,992:INFO:_display_container: 3
2023-10-24 11:47:53,992:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9,
              learning_rate=0.05, min_child_samples=96, min_split_gain=0.7,
              n_estimators=180, n_jobs=-1, num_leaves=10, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.1)
2023-10-24 11:47:53,992:INFO:tune_model() successfully completed......................................
2023-10-24 11:47:54,139:INFO:Initializing ensemble_model()
2023-10-24 11:47:54,139:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166BE4D3490>, estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9,
              learning_rate=0.05, min_child_samples=96, min_split_gain=0.7,
              n_estimators=180, n_jobs=-1, num_leaves=10, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.1), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=True, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-24 11:47:54,139:INFO:Checking exceptions
2023-10-24 11:47:54,150:INFO:Importing libraries
2023-10-24 11:47:54,150:INFO:Copying training dataset
2023-10-24 11:47:54,150:INFO:Checking base model
2023-10-24 11:47:54,150:INFO:Base model : Light Gradient Boosting Machine
2023-10-24 11:47:54,150:INFO:Importing untrained ensembler
2023-10-24 11:47:54,150:INFO:Ensemble method set to Bagging
2023-10-24 11:47:54,150:INFO:SubProcess create_model() called ==================================
2023-10-24 11:47:54,150:INFO:Initializing create_model()
2023-10-24 11:47:54,150:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166BE4D3490>, estimator=BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=4,
                                         feature_fraction=0.9,
                                         learning_rate=0.05,
                                         min_child_samples=96,
                                         min_split_gain=0.7, n_estimators=180,
                                         n_jobs=-1, num_leaves=10,
                                         random_state=123, reg_alpha=0.0001,
                                         reg_lambda=0.1),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166CD0E37F0>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 11:47:54,150:INFO:Checking exceptions
2023-10-24 11:47:54,150:INFO:Importing libraries
2023-10-24 11:47:54,150:INFO:Copying training dataset
2023-10-24 11:47:54,165:INFO:Defining folds
2023-10-24 11:47:54,165:INFO:Declaring metric variables
2023-10-24 11:47:54,165:INFO:Importing untrained model
2023-10-24 11:47:54,165:INFO:Declaring custom model
2023-10-24 11:47:54,165:INFO:Bagging Regressor Imported successfully
2023-10-24 11:47:54,165:INFO:Starting cross validation
2023-10-24 11:47:54,165:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 11:48:14,230:INFO:Calculating mean and std
2023-10-24 11:48:14,230:INFO:Creating metrics dataframe
2023-10-24 11:48:14,230:INFO:Finalizing model
2023-10-24 11:48:14,439:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:48:14,439:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:48:14,455:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:48:14,470:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:48:14,470:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:48:14,470:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:48:14,486:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005031 seconds.
2023-10-24 11:48:14,486:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:48:14,486:INFO:[LightGBM] [Info] Total Bins 6442
2023-10-24 11:48:14,486:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-24 11:48:14,486:INFO:[LightGBM] [Info] Start training from score 118.026402
2023-10-24 11:48:14,706:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:48:14,706:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:48:14,706:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:48:14,738:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:48:14,738:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:48:14,738:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:48:14,753:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005314 seconds.
2023-10-24 11:48:14,753:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:48:14,753:INFO:[LightGBM] [Info] Total Bins 6442
2023-10-24 11:48:14,753:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-24 11:48:14,753:INFO:[LightGBM] [Info] Start training from score 118.074872
2023-10-24 11:48:14,963:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:48:14,963:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:48:14,964:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:48:15,007:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:48:15,007:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:48:15,007:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:48:15,015:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005718 seconds.
2023-10-24 11:48:15,015:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:48:15,016:INFO:[LightGBM] [Info] Total Bins 6442
2023-10-24 11:48:15,016:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-24 11:48:15,017:INFO:[LightGBM] [Info] Start training from score 118.804616
2023-10-24 11:48:15,231:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:48:15,231:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:48:15,231:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:48:15,270:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:48:15,270:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:48:15,270:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:48:15,270:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004695 seconds.
2023-10-24 11:48:15,270:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:48:15,270:INFO:[LightGBM] [Info] Total Bins 6442
2023-10-24 11:48:15,270:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-24 11:48:15,281:INFO:[LightGBM] [Info] Start training from score 113.631456
2023-10-24 11:48:15,488:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:48:15,488:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:48:15,488:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:48:15,529:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:48:15,529:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:48:15,529:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:48:15,537:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005448 seconds.
2023-10-24 11:48:15,537:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:48:15,538:INFO:[LightGBM] [Info] Total Bins 6442
2023-10-24 11:48:15,538:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-24 11:48:15,538:INFO:[LightGBM] [Info] Start training from score 116.143830
2023-10-24 11:48:15,727:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:48:15,727:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:48:15,727:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:48:15,775:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:48:15,775:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:48:15,775:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:48:15,782:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004949 seconds.
2023-10-24 11:48:15,782:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:48:15,782:INFO:[LightGBM] [Info] Total Bins 6442
2023-10-24 11:48:15,782:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-24 11:48:15,782:INFO:[LightGBM] [Info] Start training from score 117.770840
2023-10-24 11:48:16,067:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:48:16,067:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:48:16,067:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:48:16,115:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:48:16,115:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:48:16,115:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:48:16,115:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005483 seconds.
2023-10-24 11:48:16,115:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:48:16,115:INFO:[LightGBM] [Info] Total Bins 6442
2023-10-24 11:48:16,115:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-24 11:48:16,115:INFO:[LightGBM] [Info] Start training from score 116.312891
2023-10-24 11:48:16,350:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:48:16,350:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:48:16,350:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:48:16,397:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:48:16,397:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:48:16,397:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:48:16,397:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005977 seconds.
2023-10-24 11:48:16,397:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:48:16,397:INFO:[LightGBM] [Info] Total Bins 6442
2023-10-24 11:48:16,397:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-24 11:48:16,397:INFO:[LightGBM] [Info] Start training from score 116.430179
2023-10-24 11:48:16,616:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:48:16,616:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:48:16,628:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:48:16,660:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:48:16,660:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:48:16,660:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:48:16,675:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005516 seconds.
2023-10-24 11:48:16,675:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:48:16,675:INFO:[LightGBM] [Info] Total Bins 6442
2023-10-24 11:48:16,675:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-24 11:48:16,675:INFO:[LightGBM] [Info] Start training from score 116.654317
2023-10-24 11:48:16,888:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:48:16,888:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:48:16,888:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:48:16,927:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:48:16,928:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:48:16,928:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:48:16,935:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005920 seconds.
2023-10-24 11:48:16,935:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:48:16,936:INFO:[LightGBM] [Info] Total Bins 6442
2023-10-24 11:48:16,936:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-24 11:48:16,938:INFO:[LightGBM] [Info] Start training from score 117.801701
2023-10-24 11:48:17,178:INFO:Uploading results into container
2023-10-24 11:48:17,178:INFO:Uploading model into container now
2023-10-24 11:48:17,178:INFO:_master_model_container: 4
2023-10-24 11:48:17,178:INFO:_display_container: 4
2023-10-24 11:48:17,178:INFO:BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=4,
                                         feature_fraction=0.9,
                                         learning_rate=0.05,
                                         min_child_samples=96,
                                         min_split_gain=0.7, n_estimators=180,
                                         n_jobs=-1, num_leaves=10,
                                         random_state=123, reg_alpha=0.0001,
                                         reg_lambda=0.1),
                 random_state=123)
2023-10-24 11:48:17,178:INFO:create_model() successfully completed......................................
2023-10-24 11:48:17,350:INFO:SubProcess create_model() end ==================================
2023-10-24 11:48:17,350:INFO:choose_better activated
2023-10-24 11:48:17,350:INFO:SubProcess create_model() called ==================================
2023-10-24 11:48:17,351:INFO:Initializing create_model()
2023-10-24 11:48:17,351:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166BE4D3490>, estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9,
              learning_rate=0.05, min_child_samples=96, min_split_gain=0.7,
              n_estimators=180, n_jobs=-1, num_leaves=10, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 11:48:17,351:INFO:Checking exceptions
2023-10-24 11:48:17,352:INFO:Importing libraries
2023-10-24 11:48:17,352:INFO:Copying training dataset
2023-10-24 11:48:17,372:INFO:Defining folds
2023-10-24 11:48:17,372:INFO:Declaring metric variables
2023-10-24 11:48:17,372:INFO:Importing untrained model
2023-10-24 11:48:17,372:INFO:Declaring custom model
2023-10-24 11:48:17,374:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 11:48:17,374:INFO:Starting cross validation
2023-10-24 11:48:17,376:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 11:48:20,021:INFO:Calculating mean and std
2023-10-24 11:48:20,021:INFO:Creating metrics dataframe
2023-10-24 11:48:20,021:INFO:Finalizing model
2023-10-24 11:48:20,263:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:48:20,263:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:48:20,263:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:48:20,296:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:48:20,296:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:48:20,296:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:48:20,296:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005142 seconds.
2023-10-24 11:48:20,296:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:48:20,296:INFO:[LightGBM] [Info] Total Bins 6442
2023-10-24 11:48:20,296:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-24 11:48:20,296:INFO:[LightGBM] [Info] Start training from score 117.072182
2023-10-24 11:48:20,546:INFO:Uploading results into container
2023-10-24 11:48:20,546:INFO:Uploading model into container now
2023-10-24 11:48:20,546:INFO:_master_model_container: 5
2023-10-24 11:48:20,546:INFO:_display_container: 5
2023-10-24 11:48:20,546:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9,
              learning_rate=0.05, min_child_samples=96, min_split_gain=0.7,
              n_estimators=180, n_jobs=-1, num_leaves=10, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.1)
2023-10-24 11:48:20,546:INFO:create_model() successfully completed......................................
2023-10-24 11:48:20,730:INFO:SubProcess create_model() end ==================================
2023-10-24 11:48:20,731:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9,
              learning_rate=0.05, min_child_samples=96, min_split_gain=0.7,
              n_estimators=180, n_jobs=-1, num_leaves=10, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.1) result for R2 is 0.5804
2023-10-24 11:48:20,732:INFO:BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=4,
                                         feature_fraction=0.9,
                                         learning_rate=0.05,
                                         min_child_samples=96,
                                         min_split_gain=0.7, n_estimators=180,
                                         n_jobs=-1, num_leaves=10,
                                         random_state=123, reg_alpha=0.0001,
                                         reg_lambda=0.1),
                 random_state=123) result for R2 is 0.5906
2023-10-24 11:48:20,732:INFO:BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=4,
                                         feature_fraction=0.9,
                                         learning_rate=0.05,
                                         min_child_samples=96,
                                         min_split_gain=0.7, n_estimators=180,
                                         n_jobs=-1, num_leaves=10,
                                         random_state=123, reg_alpha=0.0001,
                                         reg_lambda=0.1),
                 random_state=123) is best model
2023-10-24 11:48:20,732:INFO:choose_better completed
2023-10-24 11:48:20,732:INFO:_master_model_container: 5
2023-10-24 11:48:20,732:INFO:_display_container: 4
2023-10-24 11:48:20,732:INFO:BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=4,
                                         feature_fraction=0.9,
                                         learning_rate=0.05,
                                         min_child_samples=96,
                                         min_split_gain=0.7, n_estimators=180,
                                         n_jobs=-1, num_leaves=10,
                                         random_state=123, reg_alpha=0.0001,
                                         reg_lambda=0.1),
                 random_state=123)
2023-10-24 11:48:20,743:INFO:ensemble_model() successfully completed......................................
2023-10-24 11:48:20,871:INFO:Initializing finalize_model()
2023-10-24 11:48:20,871:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166BE4D3490>, estimator=BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=4,
                                         feature_fraction=0.9,
                                         learning_rate=0.05,
                                         min_child_samples=96,
                                         min_split_gain=0.7, n_estimators=180,
                                         n_jobs=-1, num_leaves=10,
                                         random_state=123, reg_alpha=0.0001,
                                         reg_lambda=0.1),
                 random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-24 11:48:20,871:INFO:Finalizing BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=4,
                                         feature_fraction=0.9,
                                         learning_rate=0.05,
                                         min_child_samples=96,
                                         min_split_gain=0.7, n_estimators=180,
                                         n_jobs=-1, num_leaves=10,
                                         random_state=123, reg_alpha=0.0001,
                                         reg_lambda=0.1),
                 random_state=123)
2023-10-24 11:48:20,887:INFO:Initializing create_model()
2023-10-24 11:48:20,887:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166BE4D3490>, estimator=BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=4,
                                         feature_fraction=0.9,
                                         learning_rate=0.05,
                                         min_child_samples=96,
                                         min_split_gain=0.7, n_estimators=180,
                                         n_jobs=-1, num_leaves=10,
                                         random_state=123, reg_alpha=0.0001,
                                         reg_lambda=0.1),
                 random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-24 11:48:20,887:INFO:Checking exceptions
2023-10-24 11:48:20,903:INFO:Importing libraries
2023-10-24 11:48:20,903:INFO:Copying training dataset
2023-10-24 11:48:20,903:INFO:Defining folds
2023-10-24 11:48:20,903:INFO:Declaring metric variables
2023-10-24 11:48:20,903:INFO:Importing untrained model
2023-10-24 11:48:20,903:INFO:Declaring custom model
2023-10-24 11:48:20,903:INFO:Bagging Regressor Imported successfully
2023-10-24 11:48:20,903:INFO:Cross validation set to False
2023-10-24 11:48:20,903:INFO:Fitting Model
2023-10-24 11:48:21,213:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:48:21,214:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:48:21,214:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:48:21,265:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:48:21,265:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:48:21,265:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:48:21,279:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009845 seconds.
2023-10-24 11:48:21,279:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:48:21,280:INFO:[LightGBM] [Info] Total Bins 6781
2023-10-24 11:48:21,280:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 47
2023-10-24 11:48:21,282:INFO:[LightGBM] [Info] Start training from score 98.434111
2023-10-24 11:48:21,580:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:48:21,580:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:48:21,580:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:48:21,646:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:48:21,646:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:48:21,646:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:48:21,661:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009110 seconds.
2023-10-24 11:48:21,661:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:48:21,662:INFO:[LightGBM] [Info] Total Bins 6781
2023-10-24 11:48:21,662:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 47
2023-10-24 11:48:21,663:INFO:[LightGBM] [Info] Start training from score 96.058010
2023-10-24 11:48:21,976:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:48:21,976:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:48:21,976:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:48:22,039:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:48:22,039:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:48:22,039:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:48:22,043:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008204 seconds.
2023-10-24 11:48:22,043:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:48:22,043:INFO:[LightGBM] [Info] Total Bins 6781
2023-10-24 11:48:22,043:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 47
2023-10-24 11:48:22,043:INFO:[LightGBM] [Info] Start training from score 97.429068
2023-10-24 11:48:22,371:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:48:22,371:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:48:22,371:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:48:22,420:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:48:22,420:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:48:22,420:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:48:22,434:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008608 seconds.
2023-10-24 11:48:22,434:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:48:22,434:INFO:[LightGBM] [Info] Total Bins 6781
2023-10-24 11:48:22,434:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 47
2023-10-24 11:48:22,434:INFO:[LightGBM] [Info] Start training from score 94.540512
2023-10-24 11:48:22,727:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:48:22,727:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:48:22,727:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:48:22,794:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:48:22,795:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:48:22,795:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:48:22,795:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009220 seconds.
2023-10-24 11:48:22,795:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:48:22,795:INFO:[LightGBM] [Info] Total Bins 6781
2023-10-24 11:48:22,795:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 47
2023-10-24 11:48:22,808:INFO:[LightGBM] [Info] Start training from score 95.981086
2023-10-24 11:48:23,060:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:48:23,060:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:48:23,060:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:48:23,121:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:48:23,121:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:48:23,121:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:48:23,127:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006415 seconds.
2023-10-24 11:48:23,127:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:48:23,127:INFO:[LightGBM] [Info] Total Bins 6781
2023-10-24 11:48:23,127:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 47
2023-10-24 11:48:23,127:INFO:[LightGBM] [Info] Start training from score 97.333888
2023-10-24 11:48:23,377:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:48:23,377:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:48:23,377:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:48:23,447:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:48:23,447:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:48:23,448:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:48:23,448:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006796 seconds.
2023-10-24 11:48:23,448:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:48:23,448:INFO:[LightGBM] [Info] Total Bins 6781
2023-10-24 11:48:23,448:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 47
2023-10-24 11:48:23,458:INFO:[LightGBM] [Info] Start training from score 97.045222
2023-10-24 11:48:23,702:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:48:23,702:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:48:23,702:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:48:23,769:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:48:23,769:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:48:23,769:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:48:23,778:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006752 seconds.
2023-10-24 11:48:23,778:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:48:23,779:INFO:[LightGBM] [Info] Total Bins 6781
2023-10-24 11:48:23,779:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 47
2023-10-24 11:48:23,781:INFO:[LightGBM] [Info] Start training from score 96.032791
2023-10-24 11:48:24,029:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:48:24,030:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:48:24,030:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:48:24,088:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:48:24,088:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:48:24,088:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:48:24,088:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009780 seconds.
2023-10-24 11:48:24,103:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:48:24,103:INFO:[LightGBM] [Info] Total Bins 6781
2023-10-24 11:48:24,103:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 47
2023-10-24 11:48:24,103:INFO:[LightGBM] [Info] Start training from score 98.349126
2023-10-24 11:48:24,352:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:48:24,352:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:48:24,352:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:48:24,405:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:48:24,405:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:48:24,405:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:48:24,420:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007370 seconds.
2023-10-24 11:48:24,420:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:48:24,422:INFO:[LightGBM] [Info] Total Bins 6781
2023-10-24 11:48:24,422:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 47
2023-10-24 11:48:24,422:INFO:[LightGBM] [Info] Start training from score 98.054848
2023-10-24 11:48:24,768:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6,
                                                          bagging_freq=4,
                                                          feature_fraction=0.9,
                                                          learning_rate=0.05,
                                                          min_child_samples=96,
                                                          min_split_gain=0.7,
                                                          n_estimators=180,
                                                          n_jobs=-1,
                                                          num_leaves=10,
                                                          random_state=123,
                                                          reg_alpha=0.0001,
                                                          reg_lambda=0.1),
                                  random_state=123))])
2023-10-24 11:48:24,768:INFO:create_model() successfully completed......................................
2023-10-24 11:48:24,915:INFO:_master_model_container: 5
2023-10-24 11:48:24,915:INFO:_display_container: 4
2023-10-24 11:48:24,972:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6,
                                                          bagging_freq=4,
                                                          feature_fraction=0.9,
                                                          learning_rate=0.05,
                                                          min_child_samples=96,
                                                          min_split_gain=0.7,
                                                          n_estimators=180,
                                                          n_jobs=-1,
                                                          num_leaves=10,
                                                          random_state=123,
                                                          reg_alpha=0.0001,
                                                          reg_lambda=0.1),
                                  random_state=123))])
2023-10-24 11:48:24,972:INFO:finalize_model() successfully completed......................................
2023-10-24 11:48:25,236:INFO:Initializing save_model()
2023-10-24 11:48:25,236:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6,
                                                          bagging_freq=4,
                                                          feature_fraction=0.9,
                                                          learning_rate=0.05,
                                                          min_child_samples=96,
                                                          min_split_gain=0.7,
                                                          n_estimators=180,
                                                          n_jobs=-1,
                                                          num_leaves=10,
                                                          random_state=123,
                                                          reg_alpha=0.0001,
                                                          reg_lambda=0.1),
                                  random_state=123))]), model_name=final_model_for_location_B, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-24 11:48:25,236:INFO:Adding model into prep_pipe
2023-10-24 11:48:25,236:WARNING:Only Model saved as it was a pipeline.
2023-10-24 11:48:25,305:INFO:final_model_for_location_B.pkl saved in current working directory
2023-10-24 11:48:25,428:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6,
                                                          bagging_freq=4,
                                                          feature_fraction=0.9,
                                                          learning_rate=0.05,
                                                          min_child_samples=96,
                                                          min_split_gain=0.7,
                                                          n_estimators=180,
                                                          n_jobs=-1,
                                                          num_leaves=10,
                                                          random_state=123,
                                                          reg_alpha=0.0001,
                                                          reg_lambda=0.1),
                                  random_state=123))])
2023-10-24 11:48:25,429:INFO:save_model() successfully completed......................................
2023-10-24 11:48:25,592:INFO:PyCaret RegressionExperiment
2023-10-24 11:48:25,592:INFO:Logging name: exp_C
2023-10-24 11:48:25,593:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 11:48:25,593:INFO:version 3.1.0
2023-10-24 11:48:25,593:INFO:Initializing setup()
2023-10-24 11:48:25,593:INFO:self.USI: 8a5d
2023-10-24 11:48:25,593:INFO:self._variable_keys: {'seed', 'logging_param', 'html_param', 'USI', 'data', 'y_train', 'pipeline', '_ml_usecase', 'gpu_n_jobs_param', 'X_test', 'X_train', 'memory', 'X', 'y_test', 'fold_shuffle_param', 'n_jobs_param', 'exp_name_log', 'y', '_available_plots', 'target_param', 'exp_id', 'idx', 'transform_target_param', 'log_plots_param', 'fold_groups_param', 'gpu_param', 'fold_generator'}
2023-10-24 11:48:25,593:INFO:Checking environment
2023-10-24 11:48:25,593:INFO:python_version: 3.8.18
2023-10-24 11:48:25,593:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-24 11:48:25,593:INFO:machine: AMD64
2023-10-24 11:48:25,594:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-24 11:48:25,594:INFO:Memory: svmem(total=16505954304, available=3878367232, percent=76.5, used=12627587072, free=3878367232)
2023-10-24 11:48:25,594:INFO:Physical Core: 8
2023-10-24 11:48:25,594:INFO:Logical Core: 16
2023-10-24 11:48:25,594:INFO:Checking libraries
2023-10-24 11:48:25,594:INFO:System:
2023-10-24 11:48:25,594:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-24 11:48:25,594:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-24 11:48:25,594:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-24 11:48:25,594:INFO:PyCaret required dependencies:
2023-10-24 11:48:25,594:INFO:                 pip: 23.3
2023-10-24 11:48:25,594:INFO:          setuptools: 68.0.0
2023-10-24 11:48:25,594:INFO:             pycaret: 3.1.0
2023-10-24 11:48:25,594:INFO:             IPython: 8.12.0
2023-10-24 11:48:25,595:INFO:          ipywidgets: 8.1.1
2023-10-24 11:48:25,595:INFO:                tqdm: 4.66.1
2023-10-24 11:48:25,595:INFO:               numpy: 1.23.5
2023-10-24 11:48:25,595:INFO:              pandas: 1.5.3
2023-10-24 11:48:25,595:INFO:              jinja2: 3.1.2
2023-10-24 11:48:25,595:INFO:               scipy: 1.10.1
2023-10-24 11:48:25,595:INFO:              joblib: 1.3.2
2023-10-24 11:48:25,595:INFO:             sklearn: 1.2.2
2023-10-24 11:48:25,595:INFO:                pyod: 1.1.0
2023-10-24 11:48:25,595:INFO:            imblearn: 0.11.0
2023-10-24 11:48:25,595:INFO:   category_encoders: 2.6.2
2023-10-24 11:48:25,595:INFO:            lightgbm: 4.1.0
2023-10-24 11:48:25,595:INFO:               numba: 0.58.1
2023-10-24 11:48:25,595:INFO:            requests: 2.31.0
2023-10-24 11:48:25,595:INFO:          matplotlib: 3.7.3
2023-10-24 11:48:25,595:INFO:          scikitplot: 0.3.7
2023-10-24 11:48:25,595:INFO:         yellowbrick: 1.5
2023-10-24 11:48:25,595:INFO:              plotly: 5.17.0
2023-10-24 11:48:25,596:INFO:    plotly-resampler: Not installed
2023-10-24 11:48:25,596:INFO:             kaleido: 0.2.1
2023-10-24 11:48:25,596:INFO:           schemdraw: 0.15
2023-10-24 11:48:25,596:INFO:         statsmodels: 0.14.0
2023-10-24 11:48:25,596:INFO:              sktime: 0.21.1
2023-10-24 11:48:25,596:INFO:               tbats: 1.1.3
2023-10-24 11:48:25,596:INFO:            pmdarima: 2.0.3
2023-10-24 11:48:25,596:INFO:              psutil: 5.9.0
2023-10-24 11:48:25,596:INFO:          markupsafe: 2.1.3
2023-10-24 11:48:25,596:INFO:             pickle5: Not installed
2023-10-24 11:48:25,596:INFO:         cloudpickle: 2.2.1
2023-10-24 11:48:25,596:INFO:         deprecation: 2.1.0
2023-10-24 11:48:25,596:INFO:              xxhash: 3.4.1
2023-10-24 11:48:25,596:INFO:           wurlitzer: Not installed
2023-10-24 11:48:25,596:INFO:PyCaret optional dependencies:
2023-10-24 11:48:25,596:INFO:                shap: Not installed
2023-10-24 11:48:25,596:INFO:           interpret: Not installed
2023-10-24 11:48:25,596:INFO:                umap: Not installed
2023-10-24 11:48:25,597:INFO:     ydata_profiling: Not installed
2023-10-24 11:48:25,597:INFO:  explainerdashboard: Not installed
2023-10-24 11:48:25,597:INFO:             autoviz: Not installed
2023-10-24 11:48:25,597:INFO:           fairlearn: Not installed
2023-10-24 11:48:25,597:INFO:          deepchecks: Not installed
2023-10-24 11:48:25,597:INFO:             xgboost: Not installed
2023-10-24 11:48:25,597:INFO:            catboost: 1.2.2
2023-10-24 11:48:25,597:INFO:              kmodes: Not installed
2023-10-24 11:48:25,597:INFO:             mlxtend: Not installed
2023-10-24 11:48:25,597:INFO:       statsforecast: Not installed
2023-10-24 11:48:25,597:INFO:        tune_sklearn: Not installed
2023-10-24 11:48:25,597:INFO:                 ray: Not installed
2023-10-24 11:48:25,597:INFO:            hyperopt: Not installed
2023-10-24 11:48:25,597:INFO:              optuna: Not installed
2023-10-24 11:48:25,597:INFO:               skopt: Not installed
2023-10-24 11:48:25,597:INFO:              mlflow: 2.7.1
2023-10-24 11:48:25,597:INFO:              gradio: Not installed
2023-10-24 11:48:25,598:INFO:             fastapi: Not installed
2023-10-24 11:48:25,598:INFO:             uvicorn: Not installed
2023-10-24 11:48:25,598:INFO:              m2cgen: Not installed
2023-10-24 11:48:25,598:INFO:           evidently: Not installed
2023-10-24 11:48:25,598:INFO:               fugue: Not installed
2023-10-24 11:48:25,598:INFO:           streamlit: Not installed
2023-10-24 11:48:25,598:INFO:             prophet: Not installed
2023-10-24 11:48:25,598:INFO:None
2023-10-24 11:48:25,598:INFO:Set up data.
2023-10-24 11:48:25,624:INFO:Set up folding strategy.
2023-10-24 11:48:25,624:INFO:Set up train/test split.
2023-10-24 11:48:25,639:INFO:Set up index.
2023-10-24 11:48:25,639:INFO:Assigning column types.
2023-10-24 11:48:25,654:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 11:48:25,654:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 11:48:25,654:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:48:25,654:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:48:25,733:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:48:25,796:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:48:25,796:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:48:25,796:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 11:48:25,796:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 11:48:25,796:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:48:25,796:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:48:25,874:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:48:25,937:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:48:25,937:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:48:25,937:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 11:48:25,937:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 11:48:25,937:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:48:25,937:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:48:26,025:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:48:26,074:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:48:26,074:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:48:26,074:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 11:48:26,074:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:48:26,074:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:48:26,158:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:48:26,209:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:48:26,209:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:48:26,209:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 11:48:26,209:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 11:48:26,225:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:48:26,305:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:48:26,352:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:48:26,352:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:48:26,352:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 11:48:26,367:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:48:26,430:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:48:26,496:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:48:26,497:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:48:26,497:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 11:48:26,498:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 11:48:26,585:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:48:26,636:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:48:26,636:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:48:26,636:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 11:48:26,721:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:48:26,772:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:48:26,772:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:48:26,772:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 11:48:26,772:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 11:48:26,852:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:48:26,915:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:48:26,915:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 11:48:27,002:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:48:27,049:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:48:27,049:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 11:48:27,049:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 11:48:27,190:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:48:27,190:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 11:48:27,340:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:48:27,340:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 11:48:27,340:INFO:Preparing preprocessing pipeline...
2023-10-24 11:48:27,340:INFO:Set up date feature engineering.
2023-10-24 11:48:27,340:INFO:Set up simple imputation.
2023-10-24 11:48:27,363:INFO:Set up encoding of ordinal features.
2023-10-24 11:48:27,374:INFO:Set up encoding of categorical features.
2023-10-24 11:48:27,374:INFO:Set up column name cleaning.
2023-10-24 11:48:27,619:INFO:Finished creating preprocessing pipeline.
2023-10-24 11:48:27,678:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 11:48:27,678:INFO:Creating final display dataframe.
2023-10-24 11:48:27,800:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (26071, 48)
4        Transformed data shape  (26071, 52)
5   Transformed train set shape  (18249, 52)
6    Transformed test set shape   (7822, 52)
7              Ordinal features            2
8              Numeric features           43
9                 Date features            1
10         Categorical features            3
11     Rows with missing values        95.9%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18               Fold Generator        KFold
19                  Fold Number           10
20                     CPU Jobs           -1
21                      Use GPU        False
22               Log Experiment        False
23              Experiment Name        exp_C
24                          USI         8a5d
2023-10-24 11:48:27,936:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:48:27,936:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 11:48:28,077:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:48:28,077:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 11:48:28,077:INFO:setup() successfully completed in 2.49s...............
2023-10-24 11:48:28,077:INFO:Initializing compare_models()
2023-10-24 11:48:28,077:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166D0DD5400>, include=['lightgbm'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000166D0DD5400>, 'include': ['lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-10-24 11:48:28,077:INFO:Checking exceptions
2023-10-24 11:48:28,092:INFO:Preparing display monitor
2023-10-24 11:48:28,092:INFO:Initializing Light Gradient Boosting Machine
2023-10-24 11:48:28,092:INFO:Total runtime is 0.0 minutes
2023-10-24 11:48:28,092:INFO:SubProcess create_model() called ==================================
2023-10-24 11:48:28,092:INFO:Initializing create_model()
2023-10-24 11:48:28,092:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166D0DD5400>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166CC63BCD0>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 11:48:28,092:INFO:Checking exceptions
2023-10-24 11:48:28,092:INFO:Importing libraries
2023-10-24 11:48:28,092:INFO:Copying training dataset
2023-10-24 11:48:28,108:INFO:Defining folds
2023-10-24 11:48:28,108:INFO:Declaring metric variables
2023-10-24 11:48:28,108:INFO:Importing untrained model
2023-10-24 11:48:28,108:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 11:48:28,108:INFO:Starting cross validation
2023-10-24 11:48:28,124:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 11:48:30,969:INFO:Calculating mean and std
2023-10-24 11:48:30,970:INFO:Creating metrics dataframe
2023-10-24 11:48:30,976:INFO:Uploading results into container
2023-10-24 11:48:30,976:INFO:Uploading model into container now
2023-10-24 11:48:30,977:INFO:_master_model_container: 1
2023-10-24 11:48:30,977:INFO:_display_container: 2
2023-10-24 11:48:30,978:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 11:48:30,979:INFO:create_model() successfully completed......................................
2023-10-24 11:48:31,132:INFO:SubProcess create_model() end ==================================
2023-10-24 11:48:31,133:INFO:Creating metrics dataframe
2023-10-24 11:48:31,141:INFO:Initializing create_model()
2023-10-24 11:48:31,141:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166D0DD5400>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 11:48:31,141:INFO:Checking exceptions
2023-10-24 11:48:31,142:INFO:Importing libraries
2023-10-24 11:48:31,142:INFO:Copying training dataset
2023-10-24 11:48:31,163:INFO:Defining folds
2023-10-24 11:48:31,163:INFO:Declaring metric variables
2023-10-24 11:48:31,163:INFO:Importing untrained model
2023-10-24 11:48:31,163:INFO:Declaring custom model
2023-10-24 11:48:31,164:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 11:48:31,166:INFO:Cross validation set to False
2023-10-24 11:48:31,166:INFO:Fitting Model
2023-10-24 11:48:31,382:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005423 seconds.
2023-10-24 11:48:31,382:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:48:31,382:INFO:[LightGBM] [Info] Total Bins 6598
2023-10-24 11:48:31,383:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 47
2023-10-24 11:48:31,383:INFO:[LightGBM] [Info] Start training from score 96.094131
2023-10-24 11:48:31,602:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 11:48:31,602:INFO:create_model() successfully completed......................................
2023-10-24 11:48:31,777:INFO:_master_model_container: 1
2023-10-24 11:48:31,777:INFO:_display_container: 2
2023-10-24 11:48:31,778:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 11:48:31,779:INFO:compare_models() successfully completed......................................
2023-10-24 11:48:31,779:INFO:Initializing tune_model()
2023-10-24 11:48:31,779:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166D0DD5400>)
2023-10-24 11:48:31,779:INFO:Checking exceptions
2023-10-24 11:48:31,790:INFO:Copying training dataset
2023-10-24 11:48:31,802:INFO:Checking base model
2023-10-24 11:48:31,802:INFO:Base model : Light Gradient Boosting Machine
2023-10-24 11:48:31,802:INFO:Declaring metric variables
2023-10-24 11:48:31,802:INFO:Defining Hyperparameters
2023-10-24 11:48:31,935:INFO:Tuning with n_jobs=-1
2023-10-24 11:48:31,935:INFO:Initializing RandomizedSearchCV
2023-10-24 11:49:21,902:INFO:best_params: {'actual_estimator__reg_lambda': 0.1, 'actual_estimator__reg_alpha': 0.0001, 'actual_estimator__num_leaves': 10, 'actual_estimator__n_estimators': 180, 'actual_estimator__min_split_gain': 0.7, 'actual_estimator__min_child_samples': 96, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__feature_fraction': 0.9, 'actual_estimator__bagging_freq': 4, 'actual_estimator__bagging_fraction': 0.6}
2023-10-24 11:49:21,902:INFO:Hyperparameter search completed
2023-10-24 11:49:21,902:INFO:SubProcess create_model() called ==================================
2023-10-24 11:49:21,902:INFO:Initializing create_model()
2023-10-24 11:49:21,902:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166D0DD5400>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166CF3992E0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 0.1, 'reg_alpha': 0.0001, 'num_leaves': 10, 'n_estimators': 180, 'min_split_gain': 0.7, 'min_child_samples': 96, 'learning_rate': 0.05, 'feature_fraction': 0.9, 'bagging_freq': 4, 'bagging_fraction': 0.6})
2023-10-24 11:49:21,902:INFO:Checking exceptions
2023-10-24 11:49:21,902:INFO:Importing libraries
2023-10-24 11:49:21,902:INFO:Copying training dataset
2023-10-24 11:49:21,934:INFO:Defining folds
2023-10-24 11:49:21,934:INFO:Declaring metric variables
2023-10-24 11:49:21,934:INFO:Importing untrained model
2023-10-24 11:49:21,934:INFO:Declaring custom model
2023-10-24 11:49:21,934:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 11:49:21,934:INFO:Starting cross validation
2023-10-24 11:49:21,934:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 11:49:24,174:INFO:Calculating mean and std
2023-10-24 11:49:24,174:INFO:Creating metrics dataframe
2023-10-24 11:49:24,178:INFO:Finalizing model
2023-10-24 11:49:24,348:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:49:24,348:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:49:24,348:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:49:24,364:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:49:24,379:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:49:24,379:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:49:24,380:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004212 seconds.
2023-10-24 11:49:24,380:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:49:24,380:INFO:[LightGBM] [Info] Total Bins 6598
2023-10-24 11:49:24,380:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 47
2023-10-24 11:49:24,380:INFO:[LightGBM] [Info] Start training from score 96.094131
2023-10-24 11:49:24,537:INFO:Uploading results into container
2023-10-24 11:49:24,553:INFO:Uploading model into container now
2023-10-24 11:49:24,553:INFO:_master_model_container: 2
2023-10-24 11:49:24,553:INFO:_display_container: 3
2023-10-24 11:49:24,553:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9,
              learning_rate=0.05, min_child_samples=96, min_split_gain=0.7,
              n_estimators=180, n_jobs=-1, num_leaves=10, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.1)
2023-10-24 11:49:24,553:INFO:create_model() successfully completed......................................
2023-10-24 11:49:24,706:INFO:SubProcess create_model() end ==================================
2023-10-24 11:49:24,706:INFO:choose_better activated
2023-10-24 11:49:24,706:INFO:SubProcess create_model() called ==================================
2023-10-24 11:49:24,706:INFO:Initializing create_model()
2023-10-24 11:49:24,706:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166D0DD5400>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 11:49:24,706:INFO:Checking exceptions
2023-10-24 11:49:24,706:INFO:Importing libraries
2023-10-24 11:49:24,706:INFO:Copying training dataset
2023-10-24 11:49:24,722:INFO:Defining folds
2023-10-24 11:49:24,722:INFO:Declaring metric variables
2023-10-24 11:49:24,722:INFO:Importing untrained model
2023-10-24 11:49:24,722:INFO:Declaring custom model
2023-10-24 11:49:24,722:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 11:49:24,722:INFO:Starting cross validation
2023-10-24 11:49:24,722:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 11:49:27,104:INFO:Calculating mean and std
2023-10-24 11:49:27,104:INFO:Creating metrics dataframe
2023-10-24 11:49:27,104:INFO:Finalizing model
2023-10-24 11:49:27,324:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004201 seconds.
2023-10-24 11:49:27,324:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:49:27,324:INFO:[LightGBM] [Info] Total Bins 6598
2023-10-24 11:49:27,325:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 47
2023-10-24 11:49:27,325:INFO:[LightGBM] [Info] Start training from score 96.094131
2023-10-24 11:49:27,454:INFO:Uploading results into container
2023-10-24 11:49:27,454:INFO:Uploading model into container now
2023-10-24 11:49:27,454:INFO:_master_model_container: 3
2023-10-24 11:49:27,454:INFO:_display_container: 4
2023-10-24 11:49:27,454:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 11:49:27,454:INFO:create_model() successfully completed......................................
2023-10-24 11:49:27,611:INFO:SubProcess create_model() end ==================================
2023-10-24 11:49:27,611:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.4151
2023-10-24 11:49:27,611:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9,
              learning_rate=0.05, min_child_samples=96, min_split_gain=0.7,
              n_estimators=180, n_jobs=-1, num_leaves=10, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.1) result for R2 is 0.5032
2023-10-24 11:49:27,611:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9,
              learning_rate=0.05, min_child_samples=96, min_split_gain=0.7,
              n_estimators=180, n_jobs=-1, num_leaves=10, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.1) is best model
2023-10-24 11:49:27,611:INFO:choose_better completed
2023-10-24 11:49:27,627:INFO:_master_model_container: 3
2023-10-24 11:49:27,627:INFO:_display_container: 3
2023-10-24 11:49:27,627:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9,
              learning_rate=0.05, min_child_samples=96, min_split_gain=0.7,
              n_estimators=180, n_jobs=-1, num_leaves=10, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.1)
2023-10-24 11:49:27,627:INFO:tune_model() successfully completed......................................
2023-10-24 11:49:27,753:INFO:Initializing ensemble_model()
2023-10-24 11:49:27,753:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166D0DD5400>, estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9,
              learning_rate=0.05, min_child_samples=96, min_split_gain=0.7,
              n_estimators=180, n_jobs=-1, num_leaves=10, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.1), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=True, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-24 11:49:27,753:INFO:Checking exceptions
2023-10-24 11:49:27,769:INFO:Importing libraries
2023-10-24 11:49:27,769:INFO:Copying training dataset
2023-10-24 11:49:27,769:INFO:Checking base model
2023-10-24 11:49:27,769:INFO:Base model : Light Gradient Boosting Machine
2023-10-24 11:49:27,769:INFO:Importing untrained ensembler
2023-10-24 11:49:27,769:INFO:Ensemble method set to Bagging
2023-10-24 11:49:27,769:INFO:SubProcess create_model() called ==================================
2023-10-24 11:49:27,769:INFO:Initializing create_model()
2023-10-24 11:49:27,769:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166D0DD5400>, estimator=BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=4,
                                         feature_fraction=0.9,
                                         learning_rate=0.05,
                                         min_child_samples=96,
                                         min_split_gain=0.7, n_estimators=180,
                                         n_jobs=-1, num_leaves=10,
                                         random_state=123, reg_alpha=0.0001,
                                         reg_lambda=0.1),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166FCA49340>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 11:49:27,769:INFO:Checking exceptions
2023-10-24 11:49:27,769:INFO:Importing libraries
2023-10-24 11:49:27,769:INFO:Copying training dataset
2023-10-24 11:49:27,784:INFO:Defining folds
2023-10-24 11:49:27,784:INFO:Declaring metric variables
2023-10-24 11:49:27,784:INFO:Importing untrained model
2023-10-24 11:49:27,784:INFO:Declaring custom model
2023-10-24 11:49:27,784:INFO:Bagging Regressor Imported successfully
2023-10-24 11:49:27,784:INFO:Starting cross validation
2023-10-24 11:49:27,784:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 11:49:42,177:INFO:Calculating mean and std
2023-10-24 11:49:42,177:INFO:Creating metrics dataframe
2023-10-24 11:49:42,177:INFO:Finalizing model
2023-10-24 11:49:42,381:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:49:42,381:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:49:42,381:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:49:42,413:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:49:42,413:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:49:42,413:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:49:42,413:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002588 seconds.
2023-10-24 11:49:42,413:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:49:42,413:INFO:[LightGBM] [Info] Total Bins 6598
2023-10-24 11:49:42,413:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 47
2023-10-24 11:49:42,413:INFO:[LightGBM] [Info] Start training from score 98.024703
2023-10-24 11:49:42,554:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:49:42,554:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:49:42,554:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:49:42,585:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:49:42,585:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:49:42,585:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:49:42,585:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003356 seconds.
2023-10-24 11:49:42,585:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:49:42,585:INFO:[LightGBM] [Info] Total Bins 6598
2023-10-24 11:49:42,585:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 47
2023-10-24 11:49:42,585:INFO:[LightGBM] [Info] Start training from score 98.611661
2023-10-24 11:49:42,726:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:49:42,726:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:49:42,726:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:49:42,757:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:49:42,757:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:49:42,757:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:49:42,757:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004260 seconds.
2023-10-24 11:49:42,757:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:49:42,757:INFO:[LightGBM] [Info] Total Bins 6598
2023-10-24 11:49:42,757:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 47
2023-10-24 11:49:42,773:INFO:[LightGBM] [Info] Start training from score 96.858305
2023-10-24 11:49:42,914:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:49:42,914:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:49:42,914:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:49:42,946:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:49:42,946:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:49:42,946:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:49:42,946:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003656 seconds.
2023-10-24 11:49:42,946:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:49:42,946:INFO:[LightGBM] [Info] Total Bins 6598
2023-10-24 11:49:42,946:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 47
2023-10-24 11:49:42,946:INFO:[LightGBM] [Info] Start training from score 97.841580
2023-10-24 11:49:43,087:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:49:43,087:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:49:43,087:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:49:43,119:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:49:43,119:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:49:43,119:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:49:43,119:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002997 seconds.
2023-10-24 11:49:43,119:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:49:43,119:INFO:[LightGBM] [Info] Total Bins 6598
2023-10-24 11:49:43,119:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 47
2023-10-24 11:49:43,119:INFO:[LightGBM] [Info] Start training from score 92.212045
2023-10-24 11:49:43,273:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:49:43,273:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:49:43,273:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:49:43,289:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:49:43,289:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:49:43,289:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:49:43,305:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003182 seconds.
2023-10-24 11:49:43,305:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:49:43,305:INFO:[LightGBM] [Info] Total Bins 6598
2023-10-24 11:49:43,305:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 47
2023-10-24 11:49:43,305:INFO:[LightGBM] [Info] Start training from score 95.321903
2023-10-24 11:49:43,451:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:49:43,451:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:49:43,451:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:49:43,483:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:49:43,483:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:49:43,483:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:49:43,483:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003049 seconds.
2023-10-24 11:49:43,483:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:49:43,483:INFO:[LightGBM] [Info] Total Bins 6598
2023-10-24 11:49:43,483:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 47
2023-10-24 11:49:43,483:INFO:[LightGBM] [Info] Start training from score 95.132336
2023-10-24 11:49:43,624:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:49:43,624:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:49:43,624:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:49:43,655:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:49:43,655:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:49:43,655:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:49:43,655:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004286 seconds.
2023-10-24 11:49:43,655:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:49:43,655:INFO:[LightGBM] [Info] Total Bins 6598
2023-10-24 11:49:43,655:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 47
2023-10-24 11:49:43,655:INFO:[LightGBM] [Info] Start training from score 96.174684
2023-10-24 11:49:43,813:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:49:43,813:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:49:43,813:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:49:43,837:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:49:43,837:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:49:43,837:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:49:43,837:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004313 seconds.
2023-10-24 11:49:43,837:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:49:43,837:INFO:[LightGBM] [Info] Total Bins 6598
2023-10-24 11:49:43,837:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 47
2023-10-24 11:49:43,837:INFO:[LightGBM] [Info] Start training from score 94.903567
2023-10-24 11:49:43,979:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:49:43,979:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:49:43,979:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:49:44,010:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:49:44,010:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:49:44,010:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:49:44,013:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004335 seconds.
2023-10-24 11:49:44,013:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:49:44,013:INFO:[LightGBM] [Info] Total Bins 6598
2023-10-24 11:49:44,013:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 47
2023-10-24 11:49:44,013:INFO:[LightGBM] [Info] Start training from score 96.260069
2023-10-24 11:49:44,152:INFO:Uploading results into container
2023-10-24 11:49:44,152:INFO:Uploading model into container now
2023-10-24 11:49:44,152:INFO:_master_model_container: 4
2023-10-24 11:49:44,152:INFO:_display_container: 4
2023-10-24 11:49:44,167:INFO:BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=4,
                                         feature_fraction=0.9,
                                         learning_rate=0.05,
                                         min_child_samples=96,
                                         min_split_gain=0.7, n_estimators=180,
                                         n_jobs=-1, num_leaves=10,
                                         random_state=123, reg_alpha=0.0001,
                                         reg_lambda=0.1),
                 random_state=123)
2023-10-24 11:49:44,167:INFO:create_model() successfully completed......................................
2023-10-24 11:49:44,324:INFO:SubProcess create_model() end ==================================
2023-10-24 11:49:44,324:INFO:choose_better activated
2023-10-24 11:49:44,324:INFO:SubProcess create_model() called ==================================
2023-10-24 11:49:44,324:INFO:Initializing create_model()
2023-10-24 11:49:44,324:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166D0DD5400>, estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9,
              learning_rate=0.05, min_child_samples=96, min_split_gain=0.7,
              n_estimators=180, n_jobs=-1, num_leaves=10, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 11:49:44,324:INFO:Checking exceptions
2023-10-24 11:49:44,324:INFO:Importing libraries
2023-10-24 11:49:44,324:INFO:Copying training dataset
2023-10-24 11:49:44,339:INFO:Defining folds
2023-10-24 11:49:44,339:INFO:Declaring metric variables
2023-10-24 11:49:44,339:INFO:Importing untrained model
2023-10-24 11:49:44,339:INFO:Declaring custom model
2023-10-24 11:49:44,339:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 11:49:44,339:INFO:Starting cross validation
2023-10-24 11:49:44,339:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 11:49:46,548:INFO:Calculating mean and std
2023-10-24 11:49:46,548:INFO:Creating metrics dataframe
2023-10-24 11:49:46,548:INFO:Finalizing model
2023-10-24 11:49:46,718:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:49:46,718:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:49:46,718:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:49:46,738:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:49:46,738:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:49:46,738:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:49:46,738:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003987 seconds.
2023-10-24 11:49:46,738:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:49:46,738:INFO:[LightGBM] [Info] Total Bins 6598
2023-10-24 11:49:46,738:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 47
2023-10-24 11:49:46,738:INFO:[LightGBM] [Info] Start training from score 96.094131
2023-10-24 11:49:46,879:INFO:Uploading results into container
2023-10-24 11:49:46,879:INFO:Uploading model into container now
2023-10-24 11:49:46,879:INFO:_master_model_container: 5
2023-10-24 11:49:46,879:INFO:_display_container: 5
2023-10-24 11:49:46,879:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9,
              learning_rate=0.05, min_child_samples=96, min_split_gain=0.7,
              n_estimators=180, n_jobs=-1, num_leaves=10, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.1)
2023-10-24 11:49:46,879:INFO:create_model() successfully completed......................................
2023-10-24 11:49:47,034:INFO:SubProcess create_model() end ==================================
2023-10-24 11:49:47,034:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9,
              learning_rate=0.05, min_child_samples=96, min_split_gain=0.7,
              n_estimators=180, n_jobs=-1, num_leaves=10, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.1) result for R2 is 0.5032
2023-10-24 11:49:47,050:INFO:BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=4,
                                         feature_fraction=0.9,
                                         learning_rate=0.05,
                                         min_child_samples=96,
                                         min_split_gain=0.7, n_estimators=180,
                                         n_jobs=-1, num_leaves=10,
                                         random_state=123, reg_alpha=0.0001,
                                         reg_lambda=0.1),
                 random_state=123) result for R2 is 0.3804
2023-10-24 11:49:47,050:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9,
              learning_rate=0.05, min_child_samples=96, min_split_gain=0.7,
              n_estimators=180, n_jobs=-1, num_leaves=10, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.1) is best model
2023-10-24 11:49:47,050:INFO:choose_better completed
2023-10-24 11:49:47,050:INFO:Original model was better than the ensembled model, hence it will be returned. NOTE: The display metrics are for the ensembled model (not the original one).
2023-10-24 11:49:47,050:INFO:_master_model_container: 5
2023-10-24 11:49:47,050:INFO:_display_container: 4
2023-10-24 11:49:47,050:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9,
              learning_rate=0.05, min_child_samples=96, min_split_gain=0.7,
              n_estimators=180, n_jobs=-1, num_leaves=10, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.1)
2023-10-24 11:49:47,050:INFO:ensemble_model() successfully completed......................................
2023-10-24 11:49:47,177:INFO:Initializing finalize_model()
2023-10-24 11:49:47,177:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166D0DD5400>, estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9,
              learning_rate=0.05, min_child_samples=96, min_split_gain=0.7,
              n_estimators=180, n_jobs=-1, num_leaves=10, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.1), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-24 11:49:47,177:INFO:Finalizing LGBMRegressor(bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9,
              learning_rate=0.05, min_child_samples=96, min_split_gain=0.7,
              n_estimators=180, n_jobs=-1, num_leaves=10, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.1)
2023-10-24 11:49:47,196:INFO:Initializing create_model()
2023-10-24 11:49:47,196:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166D0DD5400>, estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9,
              learning_rate=0.05, min_child_samples=96, min_split_gain=0.7,
              n_estimators=180, n_jobs=-1, num_leaves=10, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.1), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-24 11:49:47,196:INFO:Checking exceptions
2023-10-24 11:49:47,196:INFO:Importing libraries
2023-10-24 11:49:47,196:INFO:Copying training dataset
2023-10-24 11:49:47,196:INFO:Defining folds
2023-10-24 11:49:47,196:INFO:Declaring metric variables
2023-10-24 11:49:47,196:INFO:Importing untrained model
2023-10-24 11:49:47,196:INFO:Declaring custom model
2023-10-24 11:49:47,196:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 11:49:47,196:INFO:Cross validation set to False
2023-10-24 11:49:47,196:INFO:Fitting Model
2023-10-24 11:49:47,423:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:49:47,424:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:49:47,424:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:49:47,454:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-10-24 11:49:47,454:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 11:49:47,455:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-10-24 11:49:47,456:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004136 seconds.
2023-10-24 11:49:47,456:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:49:47,456:INFO:[LightGBM] [Info] Total Bins 6987
2023-10-24 11:49:47,456:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 48
2023-10-24 11:49:47,456:INFO:[LightGBM] [Info] Start training from score 77.700043
2023-10-24 11:49:47,691:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.6, bagging_freq=4,
                               feature_fraction=0.9, learning_rate=0.05,
                               min_child_samples=96, min_split_gain=0.7,
                               n_estimators=180, n_jobs=-1, num_leaves=10,
                               random_state=123, reg_alpha=0.0001,
                               reg_lambda=0.1))])
2023-10-24 11:49:47,691:INFO:create_model() successfully completed......................................
2023-10-24 11:49:47,833:INFO:_master_model_container: 5
2023-10-24 11:49:47,833:INFO:_display_container: 4
2023-10-24 11:49:47,880:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.6, bagging_freq=4,
                               feature_fraction=0.9, learning_rate=0.05,
                               min_child_samples=96, min_split_gain=0.7,
                               n_estimators=180, n_jobs=-1, num_leaves=10,
                               random_state=123, reg_alpha=0.0001,
                               reg_lambda=0.1))])
2023-10-24 11:49:47,880:INFO:finalize_model() successfully completed......................................
2023-10-24 11:49:48,121:INFO:Initializing save_model()
2023-10-24 11:49:48,121:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.6, bagging_freq=4,
                               feature_fraction=0.9, learning_rate=0.05,
                               min_child_samples=96, min_split_gain=0.7,
                               n_estimators=180, n_jobs=-1, num_leaves=10,
                               random_state=123, reg_alpha=0.0001,
                               reg_lambda=0.1))]), model_name=final_model_for_location_C, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-24 11:49:48,121:INFO:Adding model into prep_pipe
2023-10-24 11:49:48,121:WARNING:Only Model saved as it was a pipeline.
2023-10-24 11:49:48,132:INFO:final_model_for_location_C.pkl saved in current working directory
2023-10-24 11:49:48,226:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.6, bagging_freq=4,
                               feature_fraction=0.9, learning_rate=0.05,
                               min_child_samples=96, min_split_gain=0.7,
                               n_estimators=180, n_jobs=-1, num_leaves=10,
                               random_state=123, reg_alpha=0.0001,
                               reg_lambda=0.1))])
2023-10-24 11:49:48,226:INFO:save_model() successfully completed......................................
2023-10-24 11:49:48,428:INFO:Initializing load_model()
2023-10-24 11:49:48,428:INFO:load_model(model_name=final_model_for_location_A, platform=None, authentication=None, verbose=True)
2023-10-24 11:49:48,467:INFO:Initializing load_model()
2023-10-24 11:49:48,467:INFO:load_model(model_name=final_model_for_location_B, platform=None, authentication=None, verbose=True)
2023-10-24 11:49:48,521:INFO:Initializing load_model()
2023-10-24 11:49:48,521:INFO:load_model(model_name=final_model_for_location_C, platform=None, authentication=None, verbose=True)
2023-10-24 11:49:48,647:INFO:Initializing predict_model()
2023-10-24 11:49:48,647:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166D0DD5400>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000166CCAC4B80>)
2023-10-24 11:49:48,647:INFO:Checking exceptions
2023-10-24 11:49:48,647:INFO:Preloading libraries
2023-10-24 11:49:48,647:INFO:Set up data.
2023-10-24 11:49:48,663:INFO:Set up index.
2023-10-24 11:49:48,931:INFO:Initializing predict_model()
2023-10-24 11:49:48,931:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166D0DD5400>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6,
                                                          bagging_freq=4,
                                                          feature_fraction=0.9,
                                                          learning_rate=0.05,
                                                          min_child_samples=96,
                                                          min_split_gain=0.7,
                                                          n_estimators=180,
                                                          n_jobs=-1,
                                                          num_leaves=10,
                                                          random_state=123,
                                                          reg_alpha=0.0001,
                                                          reg_lambda=0.1),
                                  random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000166CCAC4B80>)
2023-10-24 11:49:48,931:INFO:Checking exceptions
2023-10-24 11:49:48,931:INFO:Preloading libraries
2023-10-24 11:49:48,931:INFO:Set up data.
2023-10-24 11:49:48,946:INFO:Set up index.
2023-10-24 11:49:49,213:INFO:Initializing predict_model()
2023-10-24 11:49:49,213:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166D0DD5400>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.6, bagging_freq=4,
                               feature_fraction=0.9, learning_rate=0.05,
                               min_child_samples=96, min_split_gain=0.7,
                               n_estimators=180, n_jobs=-1, num_leaves=10,
                               random_state=123, reg_alpha=0.0001,
                               reg_lambda=0.1))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000166CCAC4B80>)
2023-10-24 11:49:49,213:INFO:Checking exceptions
2023-10-24 11:49:49,213:INFO:Preloading libraries
2023-10-24 11:49:49,213:INFO:Set up data.
2023-10-24 11:49:49,229:INFO:Set up index.
2023-10-24 12:12:47,435:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_1136\1075571308.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  a = merged_data_a.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 12:12:47,466:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_1136\1075571308.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  b = merged_data_b.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 12:12:47,516:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_1136\1075571308.py:3: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  c = merged_data_c.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 12:12:47,532:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_1136\1075571308.py:21: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  X_test_a = X_test_estimated_a.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 12:12:47,548:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_1136\1075571308.py:22: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  X_test_b = X_test_estimated_b.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 12:12:47,548:WARNING:C:\Users\thoma\AppData\Local\Temp\ipykernel_1136\1075571308.py:23: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  X_test_c = X_test_estimated_c.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 12:12:47,630:INFO:PyCaret RegressionExperiment
2023-10-24 12:12:47,630:INFO:Logging name: exp_A
2023-10-24 12:12:47,631:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 12:12:47,631:INFO:version 3.1.0
2023-10-24 12:12:47,631:INFO:Initializing setup()
2023-10-24 12:12:47,631:INFO:self.USI: a8a0
2023-10-24 12:12:47,632:INFO:self._variable_keys: {'seed', 'logging_param', 'html_param', 'USI', 'data', 'y_train', 'pipeline', '_ml_usecase', 'gpu_n_jobs_param', 'X_test', 'X_train', 'memory', 'X', 'y_test', 'fold_shuffle_param', 'n_jobs_param', 'exp_name_log', 'y', '_available_plots', 'target_param', 'exp_id', 'idx', 'transform_target_param', 'log_plots_param', 'fold_groups_param', 'gpu_param', 'fold_generator'}
2023-10-24 12:12:47,632:INFO:Checking environment
2023-10-24 12:12:47,632:INFO:python_version: 3.8.18
2023-10-24 12:12:47,632:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-24 12:12:47,632:INFO:machine: AMD64
2023-10-24 12:12:47,632:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-24 12:12:47,632:INFO:Memory: svmem(total=16505954304, available=5643894784, percent=65.8, used=10862059520, free=5643894784)
2023-10-24 12:12:47,632:INFO:Physical Core: 8
2023-10-24 12:12:47,632:INFO:Logical Core: 16
2023-10-24 12:12:47,632:INFO:Checking libraries
2023-10-24 12:12:47,633:INFO:System:
2023-10-24 12:12:47,633:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-24 12:12:47,633:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-24 12:12:47,633:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-24 12:12:47,633:INFO:PyCaret required dependencies:
2023-10-24 12:12:47,633:INFO:                 pip: 23.3
2023-10-24 12:12:47,633:INFO:          setuptools: 68.0.0
2023-10-24 12:12:47,633:INFO:             pycaret: 3.1.0
2023-10-24 12:12:47,633:INFO:             IPython: 8.12.0
2023-10-24 12:12:47,633:INFO:          ipywidgets: 8.1.1
2023-10-24 12:12:47,633:INFO:                tqdm: 4.66.1
2023-10-24 12:12:47,633:INFO:               numpy: 1.23.5
2023-10-24 12:12:47,633:INFO:              pandas: 1.5.3
2023-10-24 12:12:47,633:INFO:              jinja2: 3.1.2
2023-10-24 12:12:47,633:INFO:               scipy: 1.10.1
2023-10-24 12:12:47,633:INFO:              joblib: 1.3.2
2023-10-24 12:12:47,633:INFO:             sklearn: 1.2.2
2023-10-24 12:12:47,633:INFO:                pyod: 1.1.0
2023-10-24 12:12:47,633:INFO:            imblearn: 0.11.0
2023-10-24 12:12:47,633:INFO:   category_encoders: 2.6.2
2023-10-24 12:12:47,634:INFO:            lightgbm: 4.1.0
2023-10-24 12:12:47,634:INFO:               numba: 0.58.1
2023-10-24 12:12:47,634:INFO:            requests: 2.31.0
2023-10-24 12:12:47,634:INFO:          matplotlib: 3.7.3
2023-10-24 12:12:47,634:INFO:          scikitplot: 0.3.7
2023-10-24 12:12:47,634:INFO:         yellowbrick: 1.5
2023-10-24 12:12:47,634:INFO:              plotly: 5.17.0
2023-10-24 12:12:47,634:INFO:    plotly-resampler: Not installed
2023-10-24 12:12:47,634:INFO:             kaleido: 0.2.1
2023-10-24 12:12:47,634:INFO:           schemdraw: 0.15
2023-10-24 12:12:47,634:INFO:         statsmodels: 0.14.0
2023-10-24 12:12:47,634:INFO:              sktime: 0.21.1
2023-10-24 12:12:47,634:INFO:               tbats: 1.1.3
2023-10-24 12:12:47,634:INFO:            pmdarima: 2.0.3
2023-10-24 12:12:47,634:INFO:              psutil: 5.9.0
2023-10-24 12:12:47,634:INFO:          markupsafe: 2.1.3
2023-10-24 12:12:47,634:INFO:             pickle5: Not installed
2023-10-24 12:12:47,634:INFO:         cloudpickle: 2.2.1
2023-10-24 12:12:47,634:INFO:         deprecation: 2.1.0
2023-10-24 12:12:47,634:INFO:              xxhash: 3.4.1
2023-10-24 12:12:47,634:INFO:           wurlitzer: Not installed
2023-10-24 12:12:47,635:INFO:PyCaret optional dependencies:
2023-10-24 12:12:47,635:INFO:                shap: Not installed
2023-10-24 12:12:47,635:INFO:           interpret: Not installed
2023-10-24 12:12:47,635:INFO:                umap: Not installed
2023-10-24 12:12:47,635:INFO:     ydata_profiling: Not installed
2023-10-24 12:12:47,635:INFO:  explainerdashboard: Not installed
2023-10-24 12:12:47,635:INFO:             autoviz: Not installed
2023-10-24 12:12:47,635:INFO:           fairlearn: Not installed
2023-10-24 12:12:47,635:INFO:          deepchecks: Not installed
2023-10-24 12:12:47,635:INFO:             xgboost: Not installed
2023-10-24 12:12:47,635:INFO:            catboost: 1.2.2
2023-10-24 12:12:47,635:INFO:              kmodes: Not installed
2023-10-24 12:12:47,635:INFO:             mlxtend: Not installed
2023-10-24 12:12:47,635:INFO:       statsforecast: Not installed
2023-10-24 12:12:47,635:INFO:        tune_sklearn: Not installed
2023-10-24 12:12:47,635:INFO:                 ray: Not installed
2023-10-24 12:12:47,635:INFO:            hyperopt: Not installed
2023-10-24 12:12:47,635:INFO:              optuna: Not installed
2023-10-24 12:12:47,636:INFO:               skopt: Not installed
2023-10-24 12:12:47,636:INFO:              mlflow: 2.7.1
2023-10-24 12:12:47,636:INFO:              gradio: Not installed
2023-10-24 12:12:47,636:INFO:             fastapi: Not installed
2023-10-24 12:12:47,636:INFO:             uvicorn: Not installed
2023-10-24 12:12:47,636:INFO:              m2cgen: Not installed
2023-10-24 12:12:47,636:INFO:           evidently: Not installed
2023-10-24 12:12:47,636:INFO:               fugue: Not installed
2023-10-24 12:12:47,636:INFO:           streamlit: Not installed
2023-10-24 12:12:47,636:INFO:             prophet: Not installed
2023-10-24 12:12:47,636:INFO:None
2023-10-24 12:12:47,636:INFO:Set up data.
2023-10-24 12:12:47,661:INFO:Set up folding strategy.
2023-10-24 12:12:47,661:INFO:Set up train/test split.
2023-10-24 12:12:47,693:INFO:Set up index.
2023-10-24 12:12:47,693:INFO:Assigning column types.
2023-10-24 12:12:47,713:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 12:12:47,713:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 12:12:47,725:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 12:12:47,725:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:12:47,815:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:12:47,867:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:12:47,867:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:12:47,867:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 12:12:47,867:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 12:12:47,880:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 12:12:47,885:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:12:47,951:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:12:48,015:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:12:48,015:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:12:48,015:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 12:12:48,016:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 12:12:48,021:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 12:12:48,026:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:12:48,097:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:12:48,147:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:12:48,147:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:12:48,147:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 12:12:48,165:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 12:12:48,165:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:12:48,245:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:12:48,304:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:12:48,305:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:12:48,305:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 12:12:48,306:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 12:12:48,316:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:12:48,396:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:12:48,447:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:12:48,448:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:12:48,448:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 12:12:48,451:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:12:48,535:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:12:48,582:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:12:48,582:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:12:48,582:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 12:12:48,582:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 12:12:48,682:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:12:48,729:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:12:48,729:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:12:48,729:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 12:12:48,831:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:12:48,882:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:12:48,883:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:12:48,884:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 12:12:48,885:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 12:12:48,985:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:12:49,038:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:12:49,039:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 12:12:49,133:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:12:49,184:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:12:49,185:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 12:12:49,185:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 12:12:49,317:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:12:49,317:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 12:12:49,464:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:12:49,464:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 12:12:49,467:INFO:Preparing preprocessing pipeline...
2023-10-24 12:12:49,467:INFO:Set up date feature engineering.
2023-10-24 12:12:49,467:INFO:Set up simple imputation.
2023-10-24 12:12:49,467:INFO:Set up encoding of ordinal features.
2023-10-24 12:12:49,487:INFO:Set up encoding of categorical features.
2023-10-24 12:12:49,487:INFO:Set up column name cleaning.
2023-10-24 12:12:49,750:INFO:Finished creating preprocessing pipeline.
2023-10-24 12:12:49,816:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sk...
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 12:12:49,816:INFO:Creating final display dataframe.
2023-10-24 12:12:49,984:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (34061, 48)
4        Transformed data shape  (34061, 52)
5   Transformed train set shape  (23842, 52)
6    Transformed test set shape  (10219, 52)
7              Ordinal features            2
8              Numeric features           43
9                 Date features            1
10         Categorical features            3
11     Rows with missing values        97.6%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18               Fold Generator        KFold
19                  Fold Number           10
20                     CPU Jobs           -1
21                      Use GPU        False
22               Log Experiment        False
23              Experiment Name        exp_A
24                          USI         a8a0
2023-10-24 12:12:50,130:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:12:50,130:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 12:12:50,268:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:12:50,268:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-24 12:12:50,268:INFO:setup() successfully completed in 2.65s...............
2023-10-24 12:12:50,268:INFO:Initializing compare_models()
2023-10-24 12:12:50,268:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166D0B713A0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000166D0B713A0>, 'include': None, 'exclude': ['ransac'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=['ransac'])
2023-10-24 12:12:50,268:INFO:Checking exceptions
2023-10-24 12:12:50,268:INFO:Preparing display monitor
2023-10-24 12:12:50,284:INFO:Initializing Linear Regression
2023-10-24 12:12:50,284:INFO:Total runtime is 0.0 minutes
2023-10-24 12:12:50,284:INFO:SubProcess create_model() called ==================================
2023-10-24 12:12:50,284:INFO:Initializing create_model()
2023-10-24 12:12:50,284:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166D0B713A0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166CD24D2E0>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 12:12:50,287:INFO:Checking exceptions
2023-10-24 12:12:50,287:INFO:Importing libraries
2023-10-24 12:12:50,287:INFO:Copying training dataset
2023-10-24 12:12:50,314:INFO:Defining folds
2023-10-24 12:12:50,314:INFO:Declaring metric variables
2023-10-24 12:12:50,314:INFO:Importing untrained model
2023-10-24 12:12:50,315:INFO:Linear Regression Imported successfully
2023-10-24 12:12:50,315:INFO:Starting cross validation
2023-10-24 12:12:50,317:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 12:12:57,472:INFO:Calculating mean and std
2023-10-24 12:12:57,472:INFO:Creating metrics dataframe
2023-10-24 12:12:57,472:INFO:Uploading results into container
2023-10-24 12:12:57,472:INFO:Uploading model into container now
2023-10-24 12:12:57,472:INFO:_master_model_container: 1
2023-10-24 12:12:57,472:INFO:_display_container: 2
2023-10-24 12:12:57,472:INFO:LinearRegression(n_jobs=-1)
2023-10-24 12:12:57,472:INFO:create_model() successfully completed......................................
2023-10-24 12:12:57,627:INFO:SubProcess create_model() end ==================================
2023-10-24 12:12:57,627:INFO:Creating metrics dataframe
2023-10-24 12:12:57,627:INFO:Initializing Lasso Regression
2023-10-24 12:12:57,627:INFO:Total runtime is 0.12238849401473999 minutes
2023-10-24 12:12:57,627:INFO:SubProcess create_model() called ==================================
2023-10-24 12:12:57,627:INFO:Initializing create_model()
2023-10-24 12:12:57,627:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166D0B713A0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166CD24D2E0>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 12:12:57,627:INFO:Checking exceptions
2023-10-24 12:12:57,627:INFO:Importing libraries
2023-10-24 12:12:57,627:INFO:Copying training dataset
2023-10-24 12:12:57,656:INFO:Defining folds
2023-10-24 12:12:57,656:INFO:Declaring metric variables
2023-10-24 12:12:57,656:INFO:Importing untrained model
2023-10-24 12:12:57,656:INFO:Lasso Regression Imported successfully
2023-10-24 12:12:57,656:INFO:Starting cross validation
2023-10-24 12:12:57,656:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 12:13:00,298:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.698e+09, tolerance: 3.088e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-24 12:13:00,304:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.471e+09, tolerance: 2.938e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-24 12:13:00,304:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.224e+09, tolerance: 2.396e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-24 12:13:00,304:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.505e+09, tolerance: 2.951e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-24 12:13:04,837:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.278e+09, tolerance: 2.592e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-24 12:13:04,888:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.333e+09, tolerance: 2.772e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-24 12:13:04,931:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.542e+09, tolerance: 3.013e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-24 12:13:05,058:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.183e+09, tolerance: 2.693e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-24 12:13:05,100:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.605e+09, tolerance: 3.058e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-24 12:13:05,117:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.662e+09, tolerance: 3.080e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-24 12:13:05,300:INFO:Calculating mean and std
2023-10-24 12:13:05,300:INFO:Creating metrics dataframe
2023-10-24 12:13:05,300:INFO:Uploading results into container
2023-10-24 12:13:05,300:INFO:Uploading model into container now
2023-10-24 12:13:05,300:INFO:_master_model_container: 2
2023-10-24 12:13:05,300:INFO:_display_container: 2
2023-10-24 12:13:05,300:INFO:Lasso(random_state=123)
2023-10-24 12:13:05,300:INFO:create_model() successfully completed......................................
2023-10-24 12:13:05,433:INFO:SubProcess create_model() end ==================================
2023-10-24 12:13:05,433:INFO:Creating metrics dataframe
2023-10-24 12:13:05,449:INFO:Initializing Ridge Regression
2023-10-24 12:13:05,449:INFO:Total runtime is 0.2527607242266337 minutes
2023-10-24 12:13:05,449:INFO:SubProcess create_model() called ==================================
2023-10-24 12:13:05,449:INFO:Initializing create_model()
2023-10-24 12:13:05,449:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166D0B713A0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166CD24D2E0>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 12:13:05,449:INFO:Checking exceptions
2023-10-24 12:13:05,449:INFO:Importing libraries
2023-10-24 12:13:05,449:INFO:Copying training dataset
2023-10-24 12:13:05,467:INFO:Defining folds
2023-10-24 12:13:05,467:INFO:Declaring metric variables
2023-10-24 12:13:05,467:INFO:Importing untrained model
2023-10-24 12:13:05,467:INFO:Ridge Regression Imported successfully
2023-10-24 12:13:05,467:INFO:Starting cross validation
2023-10-24 12:13:05,467:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 12:13:05,967:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.73127e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-24 12:13:05,967:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.43356e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-24 12:13:05,983:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.73317e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-24 12:13:06,016:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.4387e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-24 12:13:06,032:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.09881e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-24 12:13:06,033:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.7281e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-24 12:13:06,049:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.8029e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-24 12:13:06,066:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.66873e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-24 12:13:06,097:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.83456e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-24 12:13:06,099:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.73431e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-24 12:13:06,313:INFO:Calculating mean and std
2023-10-24 12:13:06,315:INFO:Creating metrics dataframe
2023-10-24 12:13:06,315:INFO:Uploading results into container
2023-10-24 12:13:06,315:INFO:Uploading model into container now
2023-10-24 12:13:06,315:INFO:_master_model_container: 3
2023-10-24 12:13:06,315:INFO:_display_container: 2
2023-10-24 12:13:06,315:INFO:Ridge(random_state=123)
2023-10-24 12:13:06,315:INFO:create_model() successfully completed......................................
2023-10-24 12:13:06,465:INFO:SubProcess create_model() end ==================================
2023-10-24 12:13:06,465:INFO:Creating metrics dataframe
2023-10-24 12:13:06,465:INFO:Initializing Elastic Net
2023-10-24 12:13:06,465:INFO:Total runtime is 0.269695516427358 minutes
2023-10-24 12:13:06,465:INFO:SubProcess create_model() called ==================================
2023-10-24 12:13:06,465:INFO:Initializing create_model()
2023-10-24 12:13:06,465:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166D0B713A0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166CD24D2E0>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 12:13:06,465:INFO:Checking exceptions
2023-10-24 12:13:06,465:INFO:Importing libraries
2023-10-24 12:13:06,465:INFO:Copying training dataset
2023-10-24 12:13:06,482:INFO:Defining folds
2023-10-24 12:13:06,482:INFO:Declaring metric variables
2023-10-24 12:13:06,482:INFO:Importing untrained model
2023-10-24 12:13:06,496:INFO:Elastic Net Imported successfully
2023-10-24 12:13:06,496:INFO:Starting cross validation
2023-10-24 12:13:06,498:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 12:13:10,400:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.198e+09, tolerance: 2.693e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-24 12:13:10,499:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.559e+09, tolerance: 3.013e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-24 12:13:10,658:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.522e+09, tolerance: 2.951e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-24 12:13:10,722:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.487e+09, tolerance: 2.938e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-24 12:13:10,725:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.242e+09, tolerance: 2.396e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-24 12:13:10,756:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.721e+09, tolerance: 3.088e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-24 12:13:10,772:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.623e+09, tolerance: 3.058e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-24 12:13:10,772:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.296e+09, tolerance: 2.592e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-24 12:13:10,819:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.349e+09, tolerance: 2.772e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-24 12:13:10,851:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.680e+09, tolerance: 3.080e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-24 12:13:11,043:INFO:Calculating mean and std
2023-10-24 12:13:11,046:INFO:Creating metrics dataframe
2023-10-24 12:13:11,051:INFO:Uploading results into container
2023-10-24 12:13:11,051:INFO:Uploading model into container now
2023-10-24 12:13:11,051:INFO:_master_model_container: 4
2023-10-24 12:13:11,051:INFO:_display_container: 2
2023-10-24 12:13:11,051:INFO:ElasticNet(random_state=123)
2023-10-24 12:13:11,051:INFO:create_model() successfully completed......................................
2023-10-24 12:13:11,197:INFO:SubProcess create_model() end ==================================
2023-10-24 12:13:11,197:INFO:Creating metrics dataframe
2023-10-24 12:13:11,197:INFO:Initializing Least Angle Regression
2023-10-24 12:13:11,197:INFO:Total runtime is 0.34855779012044275 minutes
2023-10-24 12:13:11,197:INFO:SubProcess create_model() called ==================================
2023-10-24 12:13:11,197:INFO:Initializing create_model()
2023-10-24 12:13:11,197:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166D0B713A0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166CD24D2E0>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 12:13:11,197:INFO:Checking exceptions
2023-10-24 12:13:11,197:INFO:Importing libraries
2023-10-24 12:13:11,197:INFO:Copying training dataset
2023-10-24 12:13:11,229:INFO:Defining folds
2023-10-24 12:13:11,229:INFO:Declaring metric variables
2023-10-24 12:13:11,229:INFO:Importing untrained model
2023-10-24 12:13:11,229:INFO:Least Angle Regression Imported successfully
2023-10-24 12:13:11,229:INFO:Starting cross validation
2023-10-24 12:13:11,229:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 12:13:12,093:INFO:Calculating mean and std
2023-10-24 12:13:12,095:INFO:Creating metrics dataframe
2023-10-24 12:13:12,099:INFO:Uploading results into container
2023-10-24 12:13:12,100:INFO:Uploading model into container now
2023-10-24 12:13:12,100:INFO:_master_model_container: 5
2023-10-24 12:13:12,100:INFO:_display_container: 2
2023-10-24 12:13:12,100:INFO:Lars(random_state=123)
2023-10-24 12:13:12,100:INFO:create_model() successfully completed......................................
2023-10-24 12:13:12,229:INFO:SubProcess create_model() end ==================================
2023-10-24 12:13:12,229:INFO:Creating metrics dataframe
2023-10-24 12:13:12,240:INFO:Initializing Lasso Least Angle Regression
2023-10-24 12:13:12,240:INFO:Total runtime is 0.36594041188557946 minutes
2023-10-24 12:13:12,240:INFO:SubProcess create_model() called ==================================
2023-10-24 12:13:12,240:INFO:Initializing create_model()
2023-10-24 12:13:12,240:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166D0B713A0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166CD24D2E0>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 12:13:12,240:INFO:Checking exceptions
2023-10-24 12:13:12,240:INFO:Importing libraries
2023-10-24 12:13:12,240:INFO:Copying training dataset
2023-10-24 12:13:12,261:INFO:Defining folds
2023-10-24 12:13:12,261:INFO:Declaring metric variables
2023-10-24 12:13:12,261:INFO:Importing untrained model
2023-10-24 12:13:12,261:INFO:Lasso Least Angle Regression Imported successfully
2023-10-24 12:13:12,261:INFO:Starting cross validation
2023-10-24 12:13:12,261:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 12:13:13,065:INFO:Calculating mean and std
2023-10-24 12:13:13,065:INFO:Creating metrics dataframe
2023-10-24 12:13:13,065:INFO:Uploading results into container
2023-10-24 12:13:13,065:INFO:Uploading model into container now
2023-10-24 12:13:13,065:INFO:_master_model_container: 6
2023-10-24 12:13:13,065:INFO:_display_container: 2
2023-10-24 12:13:13,065:INFO:LassoLars(random_state=123)
2023-10-24 12:13:13,065:INFO:create_model() successfully completed......................................
2023-10-24 12:13:13,194:INFO:SubProcess create_model() end ==================================
2023-10-24 12:13:13,194:INFO:Creating metrics dataframe
2023-10-24 12:13:13,210:INFO:Initializing Orthogonal Matching Pursuit
2023-10-24 12:13:13,210:INFO:Total runtime is 0.3820975303649903 minutes
2023-10-24 12:13:13,210:INFO:SubProcess create_model() called ==================================
2023-10-24 12:13:13,210:INFO:Initializing create_model()
2023-10-24 12:13:13,210:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166D0B713A0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166CD24D2E0>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 12:13:13,210:INFO:Checking exceptions
2023-10-24 12:13:13,210:INFO:Importing libraries
2023-10-24 12:13:13,210:INFO:Copying training dataset
2023-10-24 12:13:13,230:INFO:Defining folds
2023-10-24 12:13:13,230:INFO:Declaring metric variables
2023-10-24 12:13:13,230:INFO:Importing untrained model
2023-10-24 12:13:13,230:INFO:Orthogonal Matching Pursuit Imported successfully
2023-10-24 12:13:13,230:INFO:Starting cross validation
2023-10-24 12:13:13,230:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 12:13:14,026:INFO:Calculating mean and std
2023-10-24 12:13:14,026:INFO:Creating metrics dataframe
2023-10-24 12:13:14,026:INFO:Uploading results into container
2023-10-24 12:13:14,026:INFO:Uploading model into container now
2023-10-24 12:13:14,026:INFO:_master_model_container: 7
2023-10-24 12:13:14,026:INFO:_display_container: 2
2023-10-24 12:13:14,026:INFO:OrthogonalMatchingPursuit()
2023-10-24 12:13:14,026:INFO:create_model() successfully completed......................................
2023-10-24 12:13:14,169:INFO:SubProcess create_model() end ==================================
2023-10-24 12:13:14,169:INFO:Creating metrics dataframe
2023-10-24 12:13:14,174:INFO:Initializing Bayesian Ridge
2023-10-24 12:13:14,174:INFO:Total runtime is 0.3981645266215007 minutes
2023-10-24 12:13:14,174:INFO:SubProcess create_model() called ==================================
2023-10-24 12:13:14,174:INFO:Initializing create_model()
2023-10-24 12:13:14,174:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166D0B713A0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166CD24D2E0>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 12:13:14,175:INFO:Checking exceptions
2023-10-24 12:13:14,175:INFO:Importing libraries
2023-10-24 12:13:14,175:INFO:Copying training dataset
2023-10-24 12:13:14,192:INFO:Defining folds
2023-10-24 12:13:14,192:INFO:Declaring metric variables
2023-10-24 12:13:14,192:INFO:Importing untrained model
2023-10-24 12:13:14,192:INFO:Bayesian Ridge Imported successfully
2023-10-24 12:13:14,192:INFO:Starting cross validation
2023-10-24 12:13:14,192:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 12:13:15,674:INFO:Calculating mean and std
2023-10-24 12:13:15,674:INFO:Creating metrics dataframe
2023-10-24 12:13:15,674:INFO:Uploading results into container
2023-10-24 12:13:15,674:INFO:Uploading model into container now
2023-10-24 12:13:15,674:INFO:_master_model_container: 8
2023-10-24 12:13:15,674:INFO:_display_container: 2
2023-10-24 12:13:15,674:INFO:BayesianRidge()
2023-10-24 12:13:15,674:INFO:create_model() successfully completed......................................
2023-10-24 12:13:15,812:INFO:SubProcess create_model() end ==================================
2023-10-24 12:13:15,812:INFO:Creating metrics dataframe
2023-10-24 12:13:15,822:INFO:Initializing Passive Aggressive Regressor
2023-10-24 12:13:15,822:INFO:Total runtime is 0.4256418943405152 minutes
2023-10-24 12:13:15,822:INFO:SubProcess create_model() called ==================================
2023-10-24 12:13:15,823:INFO:Initializing create_model()
2023-10-24 12:13:15,823:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166D0B713A0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166CD24D2E0>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 12:13:15,823:INFO:Checking exceptions
2023-10-24 12:13:15,823:INFO:Importing libraries
2023-10-24 12:13:15,823:INFO:Copying training dataset
2023-10-24 12:13:15,845:INFO:Defining folds
2023-10-24 12:13:15,845:INFO:Declaring metric variables
2023-10-24 12:13:15,845:INFO:Importing untrained model
2023-10-24 12:13:15,845:INFO:Passive Aggressive Regressor Imported successfully
2023-10-24 12:13:15,845:INFO:Starting cross validation
2023-10-24 12:13:15,845:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 12:13:16,806:INFO:Calculating mean and std
2023-10-24 12:13:16,806:INFO:Creating metrics dataframe
2023-10-24 12:13:16,806:INFO:Uploading results into container
2023-10-24 12:13:16,806:INFO:Uploading model into container now
2023-10-24 12:13:16,806:INFO:_master_model_container: 9
2023-10-24 12:13:16,806:INFO:_display_container: 2
2023-10-24 12:13:16,806:INFO:PassiveAggressiveRegressor(random_state=123)
2023-10-24 12:13:16,806:INFO:create_model() successfully completed......................................
2023-10-24 12:13:16,946:INFO:SubProcess create_model() end ==================================
2023-10-24 12:13:16,946:INFO:Creating metrics dataframe
2023-10-24 12:13:16,959:INFO:Initializing Huber Regressor
2023-10-24 12:13:16,959:INFO:Total runtime is 0.4445910771687826 minutes
2023-10-24 12:13:16,959:INFO:SubProcess create_model() called ==================================
2023-10-24 12:13:16,960:INFO:Initializing create_model()
2023-10-24 12:13:16,960:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166D0B713A0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166CD24D2E0>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 12:13:16,960:INFO:Checking exceptions
2023-10-24 12:13:16,960:INFO:Importing libraries
2023-10-24 12:13:16,960:INFO:Copying training dataset
2023-10-24 12:13:16,978:INFO:Defining folds
2023-10-24 12:13:16,978:INFO:Declaring metric variables
2023-10-24 12:13:16,978:INFO:Importing untrained model
2023-10-24 12:13:16,978:INFO:Huber Regressor Imported successfully
2023-10-24 12:13:16,978:INFO:Starting cross validation
2023-10-24 12:13:16,978:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 12:13:20,788:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-24 12:13:20,811:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-24 12:13:20,818:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-24 12:13:20,902:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-24 12:13:20,921:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-24 12:13:20,936:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-24 12:13:20,953:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-24 12:13:20,970:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-24 12:13:20,986:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-24 12:13:21,048:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-24 12:13:21,202:INFO:Calculating mean and std
2023-10-24 12:13:21,203:INFO:Creating metrics dataframe
2023-10-24 12:13:21,203:INFO:Uploading results into container
2023-10-24 12:13:21,203:INFO:Uploading model into container now
2023-10-24 12:13:21,203:INFO:_master_model_container: 10
2023-10-24 12:13:21,203:INFO:_display_container: 2
2023-10-24 12:13:21,203:INFO:HuberRegressor()
2023-10-24 12:13:21,203:INFO:create_model() successfully completed......................................
2023-10-24 12:13:21,341:INFO:SubProcess create_model() end ==================================
2023-10-24 12:13:21,341:INFO:Creating metrics dataframe
2023-10-24 12:13:21,341:INFO:Initializing K Neighbors Regressor
2023-10-24 12:13:21,341:INFO:Total runtime is 0.5176175634066265 minutes
2023-10-24 12:13:21,341:INFO:SubProcess create_model() called ==================================
2023-10-24 12:13:21,341:INFO:Initializing create_model()
2023-10-24 12:13:21,341:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166D0B713A0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166CD24D2E0>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 12:13:21,341:INFO:Checking exceptions
2023-10-24 12:13:21,341:INFO:Importing libraries
2023-10-24 12:13:21,341:INFO:Copying training dataset
2023-10-24 12:13:21,369:INFO:Defining folds
2023-10-24 12:13:21,369:INFO:Declaring metric variables
2023-10-24 12:13:21,369:INFO:Importing untrained model
2023-10-24 12:13:21,369:INFO:K Neighbors Regressor Imported successfully
2023-10-24 12:13:21,369:INFO:Starting cross validation
2023-10-24 12:13:21,369:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 12:13:22,885:INFO:Calculating mean and std
2023-10-24 12:13:22,885:INFO:Creating metrics dataframe
2023-10-24 12:13:22,885:INFO:Uploading results into container
2023-10-24 12:13:22,885:INFO:Uploading model into container now
2023-10-24 12:13:22,885:INFO:_master_model_container: 11
2023-10-24 12:13:22,885:INFO:_display_container: 2
2023-10-24 12:13:22,885:INFO:KNeighborsRegressor(n_jobs=-1)
2023-10-24 12:13:22,885:INFO:create_model() successfully completed......................................
2023-10-24 12:13:23,034:INFO:SubProcess create_model() end ==================================
2023-10-24 12:13:23,034:INFO:Creating metrics dataframe
2023-10-24 12:13:23,034:INFO:Initializing Decision Tree Regressor
2023-10-24 12:13:23,034:INFO:Total runtime is 0.5458447416623434 minutes
2023-10-24 12:13:23,034:INFO:SubProcess create_model() called ==================================
2023-10-24 12:13:23,034:INFO:Initializing create_model()
2023-10-24 12:13:23,034:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166D0B713A0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166CD24D2E0>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 12:13:23,034:INFO:Checking exceptions
2023-10-24 12:13:23,034:INFO:Importing libraries
2023-10-24 12:13:23,034:INFO:Copying training dataset
2023-10-24 12:13:23,058:INFO:Defining folds
2023-10-24 12:13:23,058:INFO:Declaring metric variables
2023-10-24 12:13:23,058:INFO:Importing untrained model
2023-10-24 12:13:23,058:INFO:Decision Tree Regressor Imported successfully
2023-10-24 12:13:23,066:INFO:Starting cross validation
2023-10-24 12:13:23,067:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 12:13:24,640:INFO:Calculating mean and std
2023-10-24 12:13:24,640:INFO:Creating metrics dataframe
2023-10-24 12:13:24,640:INFO:Uploading results into container
2023-10-24 12:13:24,640:INFO:Uploading model into container now
2023-10-24 12:13:24,640:INFO:_master_model_container: 12
2023-10-24 12:13:24,640:INFO:_display_container: 2
2023-10-24 12:13:24,640:INFO:DecisionTreeRegressor(random_state=123)
2023-10-24 12:13:24,640:INFO:create_model() successfully completed......................................
2023-10-24 12:13:24,772:INFO:SubProcess create_model() end ==================================
2023-10-24 12:13:24,772:INFO:Creating metrics dataframe
2023-10-24 12:13:24,788:INFO:Initializing Random Forest Regressor
2023-10-24 12:13:24,788:INFO:Total runtime is 0.5750693082809449 minutes
2023-10-24 12:13:24,788:INFO:SubProcess create_model() called ==================================
2023-10-24 12:13:24,788:INFO:Initializing create_model()
2023-10-24 12:13:24,788:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166D0B713A0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166CD24D2E0>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 12:13:24,788:INFO:Checking exceptions
2023-10-24 12:13:24,788:INFO:Importing libraries
2023-10-24 12:13:24,788:INFO:Copying training dataset
2023-10-24 12:13:24,804:INFO:Defining folds
2023-10-24 12:13:24,804:INFO:Declaring metric variables
2023-10-24 12:13:24,804:INFO:Importing untrained model
2023-10-24 12:13:24,804:INFO:Random Forest Regressor Imported successfully
2023-10-24 12:13:24,804:INFO:Starting cross validation
2023-10-24 12:13:24,804:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 12:14:19,937:INFO:Calculating mean and std
2023-10-24 12:14:19,939:INFO:Creating metrics dataframe
2023-10-24 12:14:19,943:INFO:Uploading results into container
2023-10-24 12:14:19,944:INFO:Uploading model into container now
2023-10-24 12:14:19,944:INFO:_master_model_container: 13
2023-10-24 12:14:19,945:INFO:_display_container: 2
2023-10-24 12:14:19,945:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-10-24 12:14:19,945:INFO:create_model() successfully completed......................................
2023-10-24 12:14:20,085:INFO:SubProcess create_model() end ==================================
2023-10-24 12:14:20,085:INFO:Creating metrics dataframe
2023-10-24 12:14:20,092:INFO:Initializing Extra Trees Regressor
2023-10-24 12:14:20,093:INFO:Total runtime is 1.4968133568763733 minutes
2023-10-24 12:14:20,093:INFO:SubProcess create_model() called ==================================
2023-10-24 12:14:20,093:INFO:Initializing create_model()
2023-10-24 12:14:20,093:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166D0B713A0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166CD24D2E0>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 12:14:20,093:INFO:Checking exceptions
2023-10-24 12:14:20,094:INFO:Importing libraries
2023-10-24 12:14:20,094:INFO:Copying training dataset
2023-10-24 12:14:20,117:INFO:Defining folds
2023-10-24 12:14:20,118:INFO:Declaring metric variables
2023-10-24 12:14:20,118:INFO:Importing untrained model
2023-10-24 12:14:20,119:INFO:Extra Trees Regressor Imported successfully
2023-10-24 12:14:20,121:INFO:Starting cross validation
2023-10-24 12:14:20,123:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 12:14:37,206:INFO:Calculating mean and std
2023-10-24 12:14:37,209:INFO:Creating metrics dataframe
2023-10-24 12:14:37,210:INFO:Uploading results into container
2023-10-24 12:14:37,210:INFO:Uploading model into container now
2023-10-24 12:14:37,210:INFO:_master_model_container: 14
2023-10-24 12:14:37,210:INFO:_display_container: 2
2023-10-24 12:14:37,210:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-10-24 12:14:37,210:INFO:create_model() successfully completed......................................
2023-10-24 12:14:37,389:INFO:SubProcess create_model() end ==================================
2023-10-24 12:14:37,389:INFO:Creating metrics dataframe
2023-10-24 12:14:37,394:INFO:Initializing AdaBoost Regressor
2023-10-24 12:14:37,394:INFO:Total runtime is 1.7851696769396463 minutes
2023-10-24 12:14:37,394:INFO:SubProcess create_model() called ==================================
2023-10-24 12:14:37,395:INFO:Initializing create_model()
2023-10-24 12:14:37,395:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166D0B713A0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166CD24D2E0>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 12:14:37,395:INFO:Checking exceptions
2023-10-24 12:14:37,395:INFO:Importing libraries
2023-10-24 12:14:37,395:INFO:Copying training dataset
2023-10-24 12:14:37,419:INFO:Defining folds
2023-10-24 12:14:37,419:INFO:Declaring metric variables
2023-10-24 12:14:37,419:INFO:Importing untrained model
2023-10-24 12:14:37,420:INFO:AdaBoost Regressor Imported successfully
2023-10-24 12:14:37,421:INFO:Starting cross validation
2023-10-24 12:14:37,423:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 12:14:46,233:INFO:Calculating mean and std
2023-10-24 12:14:46,233:INFO:Creating metrics dataframe
2023-10-24 12:14:46,233:INFO:Uploading results into container
2023-10-24 12:14:46,233:INFO:Uploading model into container now
2023-10-24 12:14:46,233:INFO:_master_model_container: 15
2023-10-24 12:14:46,233:INFO:_display_container: 2
2023-10-24 12:14:46,233:INFO:AdaBoostRegressor(random_state=123)
2023-10-24 12:14:46,233:INFO:create_model() successfully completed......................................
2023-10-24 12:14:46,391:INFO:SubProcess create_model() end ==================================
2023-10-24 12:14:46,391:INFO:Creating metrics dataframe
2023-10-24 12:14:46,396:INFO:Initializing Gradient Boosting Regressor
2023-10-24 12:14:46,396:INFO:Total runtime is 1.935212536652883 minutes
2023-10-24 12:14:46,396:INFO:SubProcess create_model() called ==================================
2023-10-24 12:14:46,396:INFO:Initializing create_model()
2023-10-24 12:14:46,397:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166D0B713A0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166CD24D2E0>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 12:14:46,397:INFO:Checking exceptions
2023-10-24 12:14:46,397:INFO:Importing libraries
2023-10-24 12:14:46,397:INFO:Copying training dataset
2023-10-24 12:14:46,420:INFO:Defining folds
2023-10-24 12:14:46,421:INFO:Declaring metric variables
2023-10-24 12:14:46,421:INFO:Importing untrained model
2023-10-24 12:14:46,422:INFO:Gradient Boosting Regressor Imported successfully
2023-10-24 12:14:46,424:INFO:Starting cross validation
2023-10-24 12:14:46,426:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 12:15:05,586:INFO:Calculating mean and std
2023-10-24 12:15:05,587:INFO:Creating metrics dataframe
2023-10-24 12:15:05,590:INFO:Uploading results into container
2023-10-24 12:15:05,591:INFO:Uploading model into container now
2023-10-24 12:15:05,591:INFO:_master_model_container: 16
2023-10-24 12:15:05,591:INFO:_display_container: 2
2023-10-24 12:15:05,592:INFO:GradientBoostingRegressor(random_state=123)
2023-10-24 12:15:05,592:INFO:create_model() successfully completed......................................
2023-10-24 12:15:05,733:INFO:SubProcess create_model() end ==================================
2023-10-24 12:15:05,733:INFO:Creating metrics dataframe
2023-10-24 12:15:05,739:INFO:Initializing Light Gradient Boosting Machine
2023-10-24 12:15:05,739:INFO:Total runtime is 2.2575880765914915 minutes
2023-10-24 12:15:05,739:INFO:SubProcess create_model() called ==================================
2023-10-24 12:15:05,740:INFO:Initializing create_model()
2023-10-24 12:15:05,740:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166D0B713A0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166CD24D2E0>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 12:15:05,740:INFO:Checking exceptions
2023-10-24 12:15:05,740:INFO:Importing libraries
2023-10-24 12:15:05,740:INFO:Copying training dataset
2023-10-24 12:15:05,763:INFO:Defining folds
2023-10-24 12:15:05,763:INFO:Declaring metric variables
2023-10-24 12:15:05,764:INFO:Importing untrained model
2023-10-24 12:15:05,765:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 12:15:05,766:INFO:Starting cross validation
2023-10-24 12:15:05,768:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 12:15:08,630:INFO:Calculating mean and std
2023-10-24 12:15:08,630:INFO:Creating metrics dataframe
2023-10-24 12:15:08,630:INFO:Uploading results into container
2023-10-24 12:15:08,630:INFO:Uploading model into container now
2023-10-24 12:15:08,630:INFO:_master_model_container: 17
2023-10-24 12:15:08,630:INFO:_display_container: 2
2023-10-24 12:15:08,630:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 12:15:08,630:INFO:create_model() successfully completed......................................
2023-10-24 12:15:08,781:INFO:SubProcess create_model() end ==================================
2023-10-24 12:15:08,781:INFO:Creating metrics dataframe
2023-10-24 12:15:08,786:INFO:Initializing CatBoost Regressor
2023-10-24 12:15:08,786:INFO:Total runtime is 2.3083724856376646 minutes
2023-10-24 12:15:08,786:INFO:SubProcess create_model() called ==================================
2023-10-24 12:15:08,786:INFO:Initializing create_model()
2023-10-24 12:15:08,786:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166D0B713A0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166CD24D2E0>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 12:15:08,786:INFO:Checking exceptions
2023-10-24 12:15:08,786:INFO:Importing libraries
2023-10-24 12:15:08,786:INFO:Copying training dataset
2023-10-24 12:15:08,814:INFO:Defining folds
2023-10-24 12:15:08,814:INFO:Declaring metric variables
2023-10-24 12:15:08,814:INFO:Importing untrained model
2023-10-24 12:15:08,814:INFO:CatBoost Regressor Imported successfully
2023-10-24 12:15:08,814:INFO:Starting cross validation
2023-10-24 12:15:08,814:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 12:15:42,077:INFO:Calculating mean and std
2023-10-24 12:15:42,078:INFO:Creating metrics dataframe
2023-10-24 12:15:42,084:INFO:Uploading results into container
2023-10-24 12:15:42,084:INFO:Uploading model into container now
2023-10-24 12:15:42,085:INFO:_master_model_container: 18
2023-10-24 12:15:42,085:INFO:_display_container: 2
2023-10-24 12:15:42,085:INFO:<catboost.core.CatBoostRegressor object at 0x00000166CCB36C70>
2023-10-24 12:15:42,085:INFO:create_model() successfully completed......................................
2023-10-24 12:15:42,235:INFO:SubProcess create_model() end ==================================
2023-10-24 12:15:42,235:INFO:Creating metrics dataframe
2023-10-24 12:15:42,240:INFO:Initializing Dummy Regressor
2023-10-24 12:15:42,240:INFO:Total runtime is 2.865938774744669 minutes
2023-10-24 12:15:42,240:INFO:SubProcess create_model() called ==================================
2023-10-24 12:15:42,241:INFO:Initializing create_model()
2023-10-24 12:15:42,241:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166D0B713A0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166CD24D2E0>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 12:15:42,241:INFO:Checking exceptions
2023-10-24 12:15:42,241:INFO:Importing libraries
2023-10-24 12:15:42,241:INFO:Copying training dataset
2023-10-24 12:15:42,265:INFO:Defining folds
2023-10-24 12:15:42,265:INFO:Declaring metric variables
2023-10-24 12:15:42,266:INFO:Importing untrained model
2023-10-24 12:15:42,267:INFO:Dummy Regressor Imported successfully
2023-10-24 12:15:42,268:INFO:Starting cross validation
2023-10-24 12:15:42,270:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 12:15:43,052:INFO:Calculating mean and std
2023-10-24 12:15:43,052:INFO:Creating metrics dataframe
2023-10-24 12:15:43,059:INFO:Uploading results into container
2023-10-24 12:15:43,059:INFO:Uploading model into container now
2023-10-24 12:15:43,059:INFO:_master_model_container: 19
2023-10-24 12:15:43,059:INFO:_display_container: 2
2023-10-24 12:15:43,059:INFO:DummyRegressor()
2023-10-24 12:15:43,059:INFO:create_model() successfully completed......................................
2023-10-24 12:15:43,203:INFO:SubProcess create_model() end ==================================
2023-10-24 12:15:43,203:INFO:Creating metrics dataframe
2023-10-24 12:15:43,211:INFO:Initializing create_model()
2023-10-24 12:15:43,211:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166D0B713A0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 12:15:43,211:INFO:Checking exceptions
2023-10-24 12:15:43,212:INFO:Importing libraries
2023-10-24 12:15:43,212:INFO:Copying training dataset
2023-10-24 12:15:43,234:INFO:Defining folds
2023-10-24 12:15:43,235:INFO:Declaring metric variables
2023-10-24 12:15:43,235:INFO:Importing untrained model
2023-10-24 12:15:43,235:INFO:Declaring custom model
2023-10-24 12:15:43,236:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 12:15:43,238:INFO:Cross validation set to False
2023-10-24 12:15:43,238:INFO:Fitting Model
2023-10-24 12:15:43,484:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004531 seconds.
2023-10-24 12:15:43,484:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:15:43,484:INFO:[LightGBM] [Info] Total Bins 6408
2023-10-24 12:15:43,484:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 12:15:43,484:INFO:[LightGBM] [Info] Start training from score 616.864890
2023-10-24 12:15:43,684:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 12:15:43,684:INFO:create_model() successfully completed......................................
2023-10-24 12:15:43,866:INFO:_master_model_container: 19
2023-10-24 12:15:43,866:INFO:_display_container: 2
2023-10-24 12:15:43,868:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 12:15:43,868:INFO:compare_models() successfully completed......................................
2023-10-24 12:15:43,869:INFO:Initializing ensemble_model()
2023-10-24 12:15:43,869:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166D0B713A0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), method=Boosting, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-24 12:15:43,869:INFO:Checking exceptions
2023-10-24 12:15:44,014:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004689 seconds.
2023-10-24 12:15:44,014:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:15:44,015:INFO:[LightGBM] [Info] Total Bins 6357
2023-10-24 12:15:44,015:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 12:15:44,016:INFO:[LightGBM] [Info] Start training from score 614.999628
2023-10-24 12:15:44,342:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005879 seconds.
2023-10-24 12:15:44,342:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:15:44,342:INFO:[LightGBM] [Info] Total Bins 6331
2023-10-24 12:15:44,343:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 12:15:44,343:INFO:[LightGBM] [Info] Start training from score 839.907874
2023-10-24 12:15:44,648:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005176 seconds.
2023-10-24 12:15:44,649:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:15:44,649:INFO:[LightGBM] [Info] Total Bins 6306
2023-10-24 12:15:44,651:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 12:15:44,651:INFO:[LightGBM] [Info] Start training from score 1119.305129
2023-10-24 12:15:44,970:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005487 seconds.
2023-10-24 12:15:44,970:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:15:44,971:INFO:[LightGBM] [Info] Total Bins 6264
2023-10-24 12:15:44,971:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 12:15:44,972:INFO:[LightGBM] [Info] Start training from score 1352.870927
2023-10-24 12:15:45,336:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005892 seconds.
2023-10-24 12:15:45,336:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:15:45,336:INFO:[LightGBM] [Info] Total Bins 6247
2023-10-24 12:15:45,336:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 12:15:45,336:INFO:[LightGBM] [Info] Start training from score 1545.286806
2023-10-24 12:15:45,666:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005960 seconds.
2023-10-24 12:15:45,666:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:15:45,667:INFO:[LightGBM] [Info] Total Bins 6189
2023-10-24 12:15:45,667:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 12:15:45,667:INFO:[LightGBM] [Info] Start training from score 1677.193032
2023-10-24 12:15:45,982:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006596 seconds.
2023-10-24 12:15:45,982:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:15:45,982:INFO:[LightGBM] [Info] Total Bins 6140
2023-10-24 12:15:45,982:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-24 12:15:45,982:INFO:[LightGBM] [Info] Start training from score 1831.167878
2023-10-24 12:15:46,268:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005053 seconds.
2023-10-24 12:15:46,268:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:15:46,269:INFO:[LightGBM] [Info] Total Bins 6122
2023-10-24 12:15:46,269:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-24 12:15:46,270:INFO:[LightGBM] [Info] Start training from score 1881.531403
2023-10-24 12:15:46,564:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005005 seconds.
2023-10-24 12:15:46,564:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:15:46,564:INFO:[LightGBM] [Info] Total Bins 6099
2023-10-24 12:15:46,564:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-24 12:15:46,564:INFO:[LightGBM] [Info] Start training from score 1939.434551
2023-10-24 12:15:46,856:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005151 seconds.
2023-10-24 12:15:46,857:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:15:46,857:INFO:[LightGBM] [Info] Total Bins 6058
2023-10-24 12:15:46,857:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 44
2023-10-24 12:15:46,858:INFO:[LightGBM] [Info] Start training from score 2010.189257
2023-10-24 12:15:47,105:INFO:Importing libraries
2023-10-24 12:15:47,105:INFO:Copying training dataset
2023-10-24 12:15:47,105:INFO:Checking base model
2023-10-24 12:15:47,105:INFO:Base model : Light Gradient Boosting Machine
2023-10-24 12:15:47,105:INFO:Importing untrained ensembler
2023-10-24 12:15:47,105:INFO:Ensemble method set to Boosting
2023-10-24 12:15:47,105:INFO:SubProcess create_model() called ==================================
2023-10-24 12:15:47,105:INFO:Initializing create_model()
2023-10-24 12:15:47,105:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166D0B713A0>, estimator=AdaBoostRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                  n_estimators=10, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166CCAA4AF0>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 12:15:47,105:INFO:Checking exceptions
2023-10-24 12:15:47,105:INFO:Importing libraries
2023-10-24 12:15:47,105:INFO:Copying training dataset
2023-10-24 12:15:47,141:INFO:Defining folds
2023-10-24 12:15:47,141:INFO:Declaring metric variables
2023-10-24 12:15:47,141:INFO:Importing untrained model
2023-10-24 12:15:47,141:INFO:Declaring custom model
2023-10-24 12:15:47,147:INFO:AdaBoost Regressor Imported successfully
2023-10-24 12:15:47,147:INFO:Starting cross validation
2023-10-24 12:15:47,150:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 12:16:12,411:INFO:Calculating mean and std
2023-10-24 12:16:12,411:INFO:Creating metrics dataframe
2023-10-24 12:16:12,411:INFO:Finalizing model
2023-10-24 12:16:12,710:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004986 seconds.
2023-10-24 12:16:12,726:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:16:12,726:INFO:[LightGBM] [Info] Total Bins 6357
2023-10-24 12:16:12,727:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 12:16:12,727:INFO:[LightGBM] [Info] Start training from score 614.999628
2023-10-24 12:16:13,044:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005502 seconds.
2023-10-24 12:16:13,044:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:16:13,044:INFO:[LightGBM] [Info] Total Bins 6331
2023-10-24 12:16:13,044:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 12:16:13,044:INFO:[LightGBM] [Info] Start training from score 839.907874
2023-10-24 12:16:13,380:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005143 seconds.
2023-10-24 12:16:13,380:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:16:13,380:INFO:[LightGBM] [Info] Total Bins 6306
2023-10-24 12:16:13,380:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 12:16:13,380:INFO:[LightGBM] [Info] Start training from score 1119.305129
2023-10-24 12:16:13,743:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005213 seconds.
2023-10-24 12:16:13,743:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:16:13,743:INFO:[LightGBM] [Info] Total Bins 6264
2023-10-24 12:16:13,743:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 12:16:13,743:INFO:[LightGBM] [Info] Start training from score 1352.870927
2023-10-24 12:16:14,082:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006221 seconds.
2023-10-24 12:16:14,082:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:16:14,092:INFO:[LightGBM] [Info] Total Bins 6247
2023-10-24 12:16:14,092:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 12:16:14,093:INFO:[LightGBM] [Info] Start training from score 1545.286806
2023-10-24 12:16:14,409:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004989 seconds.
2023-10-24 12:16:14,409:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:16:14,409:INFO:[LightGBM] [Info] Total Bins 6189
2023-10-24 12:16:14,409:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 12:16:14,409:INFO:[LightGBM] [Info] Start training from score 1677.193032
2023-10-24 12:16:14,676:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005119 seconds.
2023-10-24 12:16:14,676:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:16:14,676:INFO:[LightGBM] [Info] Total Bins 6140
2023-10-24 12:16:14,676:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-24 12:16:14,676:INFO:[LightGBM] [Info] Start training from score 1831.167878
2023-10-24 12:16:14,942:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006247 seconds.
2023-10-24 12:16:14,942:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:16:14,942:INFO:[LightGBM] [Info] Total Bins 6122
2023-10-24 12:16:14,942:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-24 12:16:14,942:INFO:[LightGBM] [Info] Start training from score 1881.531403
2023-10-24 12:16:15,208:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004158 seconds.
2023-10-24 12:16:15,208:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:16:15,208:INFO:[LightGBM] [Info] Total Bins 6099
2023-10-24 12:16:15,208:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-24 12:16:15,208:INFO:[LightGBM] [Info] Start training from score 1939.434551
2023-10-24 12:16:15,475:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005115 seconds.
2023-10-24 12:16:15,475:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:16:15,475:INFO:[LightGBM] [Info] Total Bins 6058
2023-10-24 12:16:15,475:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 44
2023-10-24 12:16:15,475:INFO:[LightGBM] [Info] Start training from score 2010.189257
2023-10-24 12:16:15,691:INFO:Uploading results into container
2023-10-24 12:16:15,691:INFO:Uploading model into container now
2023-10-24 12:16:15,691:INFO:_master_model_container: 20
2023-10-24 12:16:15,691:INFO:_display_container: 3
2023-10-24 12:16:15,691:INFO:AdaBoostRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                  n_estimators=10, random_state=123)
2023-10-24 12:16:15,691:INFO:create_model() successfully completed......................................
2023-10-24 12:16:15,857:INFO:SubProcess create_model() end ==================================
2023-10-24 12:16:15,861:INFO:_master_model_container: 20
2023-10-24 12:16:15,862:INFO:_display_container: 3
2023-10-24 12:16:15,864:INFO:AdaBoostRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                  n_estimators=10, random_state=123)
2023-10-24 12:16:15,864:INFO:ensemble_model() successfully completed......................................
2023-10-24 12:16:15,996:INFO:Initializing tune_model()
2023-10-24 12:16:15,996:INFO:tune_model(estimator=AdaBoostRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                  n_estimators=10, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166D0B713A0>)
2023-10-24 12:16:15,996:INFO:Checking exceptions
2023-10-24 12:16:16,008:INFO:Copying training dataset
2023-10-24 12:16:16,031:INFO:Checking base model
2023-10-24 12:16:16,031:INFO:Base model : AdaBoost Regressor
2023-10-24 12:16:16,031:INFO:Declaring metric variables
2023-10-24 12:16:16,031:INFO:Defining Hyperparameters
2023-10-24 12:16:16,177:INFO:Tuning with n_jobs=-1
2023-10-24 12:16:16,177:INFO:Initializing RandomizedSearchCV
2023-10-24 13:18:40,916:INFO:best_params: {'actual_estimator__n_estimators': 180, 'actual_estimator__loss': 'square', 'actual_estimator__learning_rate': 1e-07}
2023-10-24 13:18:40,920:INFO:Hyperparameter search completed
2023-10-24 13:18:40,920:INFO:SubProcess create_model() called ==================================
2023-10-24 13:18:40,923:INFO:Initializing create_model()
2023-10-24 13:18:40,924:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166D0B713A0>, estimator=AdaBoostRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                  n_estimators=10, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166D0B82730>, model_only=True, return_train_score=False, kwargs={'n_estimators': 180, 'loss': 'square', 'learning_rate': 1e-07})
2023-10-24 13:18:40,924:INFO:Checking exceptions
2023-10-24 13:18:40,925:INFO:Importing libraries
2023-10-24 13:18:40,925:INFO:Copying training dataset
2023-10-24 13:18:40,967:INFO:Defining folds
2023-10-24 13:18:40,968:INFO:Declaring metric variables
2023-10-24 13:18:40,969:INFO:Importing untrained model
2023-10-24 13:18:40,969:INFO:Declaring custom model
2023-10-24 13:18:40,971:INFO:AdaBoost Regressor Imported successfully
2023-10-24 13:18:40,971:INFO:Starting cross validation
2023-10-24 13:18:40,974:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 13:26:23,788:INFO:Calculating mean and std
2023-10-24 13:26:23,788:INFO:Creating metrics dataframe
2023-10-24 13:26:23,788:INFO:Finalizing model
2023-10-24 13:26:24,156:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004900 seconds.
2023-10-24 13:26:24,156:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:24,156:INFO:[LightGBM] [Info] Total Bins 6357
2023-10-24 13:26:24,156:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:24,156:INFO:[LightGBM] [Info] Start training from score 614.999628
2023-10-24 13:26:24,543:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006904 seconds.
2023-10-24 13:26:24,543:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:24,543:INFO:[LightGBM] [Info] Total Bins 6356
2023-10-24 13:26:24,543:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:24,543:INFO:[LightGBM] [Info] Start training from score 612.568620
2023-10-24 13:26:24,906:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006010 seconds.
2023-10-24 13:26:24,906:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:24,906:INFO:[LightGBM] [Info] Total Bins 6374
2023-10-24 13:26:24,906:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:24,906:INFO:[LightGBM] [Info] Start training from score 613.592360
2023-10-24 13:26:25,277:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004994 seconds.
2023-10-24 13:26:25,277:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:25,277:INFO:[LightGBM] [Info] Total Bins 6346
2023-10-24 13:26:25,277:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:25,277:INFO:[LightGBM] [Info] Start training from score 625.522543
2023-10-24 13:26:25,643:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005653 seconds.
2023-10-24 13:26:25,643:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:25,643:INFO:[LightGBM] [Info] Total Bins 6379
2023-10-24 13:26:25,643:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:25,643:INFO:[LightGBM] [Info] Start training from score 612.782871
2023-10-24 13:26:25,998:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005372 seconds.
2023-10-24 13:26:25,998:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:25,998:INFO:[LightGBM] [Info] Total Bins 6366
2023-10-24 13:26:25,998:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:25,998:INFO:[LightGBM] [Info] Start training from score 614.206731
2023-10-24 13:26:26,378:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005877 seconds.
2023-10-24 13:26:26,378:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:26,379:INFO:[LightGBM] [Info] Total Bins 6367
2023-10-24 13:26:26,380:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:26,381:INFO:[LightGBM] [Info] Start training from score 635.800351
2023-10-24 13:26:26,708:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005692 seconds.
2023-10-24 13:26:26,709:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:26,710:INFO:[LightGBM] [Info] Total Bins 6366
2023-10-24 13:26:26,710:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:26,711:INFO:[LightGBM] [Info] Start training from score 623.950806
2023-10-24 13:26:27,044:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005869 seconds.
2023-10-24 13:26:27,044:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:27,045:INFO:[LightGBM] [Info] Total Bins 6357
2023-10-24 13:26:27,045:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:27,047:INFO:[LightGBM] [Info] Start training from score 601.477592
2023-10-24 13:26:27,360:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005105 seconds.
2023-10-24 13:26:27,360:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:27,360:INFO:[LightGBM] [Info] Total Bins 6365
2023-10-24 13:26:27,360:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:27,360:INFO:[LightGBM] [Info] Start training from score 615.211315
2023-10-24 13:26:27,680:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005403 seconds.
2023-10-24 13:26:27,680:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:27,680:INFO:[LightGBM] [Info] Total Bins 6364
2023-10-24 13:26:27,680:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:27,680:INFO:[LightGBM] [Info] Start training from score 628.052017
2023-10-24 13:26:28,019:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005041 seconds.
2023-10-24 13:26:28,019:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:28,019:INFO:[LightGBM] [Info] Total Bins 6362
2023-10-24 13:26:28,019:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:28,019:INFO:[LightGBM] [Info] Start training from score 607.850583
2023-10-24 13:26:28,364:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006471 seconds.
2023-10-24 13:26:28,364:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:28,364:INFO:[LightGBM] [Info] Total Bins 6378
2023-10-24 13:26:28,364:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:28,364:INFO:[LightGBM] [Info] Start training from score 621.368265
2023-10-24 13:26:28,678:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004230 seconds.
2023-10-24 13:26:28,678:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:28,678:INFO:[LightGBM] [Info] Total Bins 6366
2023-10-24 13:26:28,678:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:28,678:INFO:[LightGBM] [Info] Start training from score 613.297849
2023-10-24 13:26:29,022:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005274 seconds.
2023-10-24 13:26:29,022:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:29,022:INFO:[LightGBM] [Info] Total Bins 6356
2023-10-24 13:26:29,022:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:29,022:INFO:[LightGBM] [Info] Start training from score 620.248772
2023-10-24 13:26:29,388:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004731 seconds.
2023-10-24 13:26:29,388:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:29,388:INFO:[LightGBM] [Info] Total Bins 6357
2023-10-24 13:26:29,388:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:29,388:INFO:[LightGBM] [Info] Start training from score 625.739254
2023-10-24 13:26:29,743:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006454 seconds.
2023-10-24 13:26:29,743:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:29,743:INFO:[LightGBM] [Info] Total Bins 6378
2023-10-24 13:26:29,743:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:29,743:INFO:[LightGBM] [Info] Start training from score 626.098648
2023-10-24 13:26:30,075:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006012 seconds.
2023-10-24 13:26:30,075:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:30,075:INFO:[LightGBM] [Info] Total Bins 6362
2023-10-24 13:26:30,075:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:30,075:INFO:[LightGBM] [Info] Start training from score 630.744553
2023-10-24 13:26:30,409:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006445 seconds.
2023-10-24 13:26:30,409:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:30,409:INFO:[LightGBM] [Info] Total Bins 6358
2023-10-24 13:26:30,409:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:30,409:INFO:[LightGBM] [Info] Start training from score 612.992749
2023-10-24 13:26:30,716:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005085 seconds.
2023-10-24 13:26:30,716:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:30,716:INFO:[LightGBM] [Info] Total Bins 6358
2023-10-24 13:26:30,716:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:30,716:INFO:[LightGBM] [Info] Start training from score 631.277450
2023-10-24 13:26:31,046:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006798 seconds.
2023-10-24 13:26:31,046:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:31,046:INFO:[LightGBM] [Info] Total Bins 6368
2023-10-24 13:26:31,046:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:31,046:INFO:[LightGBM] [Info] Start training from score 621.891436
2023-10-24 13:26:31,375:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005383 seconds.
2023-10-24 13:26:31,375:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:31,375:INFO:[LightGBM] [Info] Total Bins 6375
2023-10-24 13:26:31,375:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:31,375:INFO:[LightGBM] [Info] Start training from score 611.950674
2023-10-24 13:26:31,703:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006501 seconds.
2023-10-24 13:26:31,703:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:31,703:INFO:[LightGBM] [Info] Total Bins 6361
2023-10-24 13:26:31,703:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:31,703:INFO:[LightGBM] [Info] Start training from score 616.714718
2023-10-24 13:26:32,050:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005845 seconds.
2023-10-24 13:26:32,050:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:32,050:INFO:[LightGBM] [Info] Total Bins 6366
2023-10-24 13:26:32,050:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:32,050:INFO:[LightGBM] [Info] Start training from score 630.499473
2023-10-24 13:26:32,378:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006971 seconds.
2023-10-24 13:26:32,378:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:32,378:INFO:[LightGBM] [Info] Total Bins 6363
2023-10-24 13:26:32,378:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:32,378:INFO:[LightGBM] [Info] Start training from score 609.094448
2023-10-24 13:26:32,735:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005370 seconds.
2023-10-24 13:26:32,735:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:32,735:INFO:[LightGBM] [Info] Total Bins 6367
2023-10-24 13:26:32,735:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:32,735:INFO:[LightGBM] [Info] Start training from score 620.757152
2023-10-24 13:26:33,049:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005086 seconds.
2023-10-24 13:26:33,049:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:33,049:INFO:[LightGBM] [Info] Total Bins 6367
2023-10-24 13:26:33,065:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:33,065:INFO:[LightGBM] [Info] Start training from score 624.914051
2023-10-24 13:26:33,415:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007180 seconds.
2023-10-24 13:26:33,415:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:33,415:INFO:[LightGBM] [Info] Total Bins 6384
2023-10-24 13:26:33,415:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:33,415:INFO:[LightGBM] [Info] Start training from score 617.841635
2023-10-24 13:26:33,785:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005293 seconds.
2023-10-24 13:26:33,785:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:33,785:INFO:[LightGBM] [Info] Total Bins 6348
2023-10-24 13:26:33,785:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:33,785:INFO:[LightGBM] [Info] Start training from score 614.141890
2023-10-24 13:26:34,114:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005589 seconds.
2023-10-24 13:26:34,114:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:34,114:INFO:[LightGBM] [Info] Total Bins 6371
2023-10-24 13:26:34,114:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:34,114:INFO:[LightGBM] [Info] Start training from score 604.073572
2023-10-24 13:26:34,453:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005496 seconds.
2023-10-24 13:26:34,453:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:34,453:INFO:[LightGBM] [Info] Total Bins 6352
2023-10-24 13:26:34,453:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:34,453:INFO:[LightGBM] [Info] Start training from score 617.826608
2023-10-24 13:26:34,824:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004846 seconds.
2023-10-24 13:26:34,824:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:34,824:INFO:[LightGBM] [Info] Total Bins 6366
2023-10-24 13:26:34,824:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:34,824:INFO:[LightGBM] [Info] Start training from score 612.987651
2023-10-24 13:26:35,169:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006763 seconds.
2023-10-24 13:26:35,169:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:35,169:INFO:[LightGBM] [Info] Total Bins 6353
2023-10-24 13:26:35,169:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:35,169:INFO:[LightGBM] [Info] Start training from score 613.604748
2023-10-24 13:26:35,499:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005858 seconds.
2023-10-24 13:26:35,499:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:35,499:INFO:[LightGBM] [Info] Total Bins 6375
2023-10-24 13:26:35,499:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:35,499:INFO:[LightGBM] [Info] Start training from score 611.447978
2023-10-24 13:26:35,837:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005026 seconds.
2023-10-24 13:26:35,837:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:35,837:INFO:[LightGBM] [Info] Total Bins 6358
2023-10-24 13:26:35,853:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:35,853:INFO:[LightGBM] [Info] Start training from score 611.510836
2023-10-24 13:26:36,073:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004059 seconds.
2023-10-24 13:26:36,073:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:36,073:INFO:[LightGBM] [Info] Total Bins 6357
2023-10-24 13:26:36,073:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:36,088:INFO:[LightGBM] [Info] Start training from score 622.540464
2023-10-24 13:26:36,333:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004992 seconds.
2023-10-24 13:26:36,334:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:36,334:INFO:[LightGBM] [Info] Total Bins 6366
2023-10-24 13:26:36,334:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:36,335:INFO:[LightGBM] [Info] Start training from score 618.396558
2023-10-24 13:26:36,578:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005029 seconds.
2023-10-24 13:26:36,578:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:36,578:INFO:[LightGBM] [Info] Total Bins 6352
2023-10-24 13:26:36,578:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:36,578:INFO:[LightGBM] [Info] Start training from score 619.736000
2023-10-24 13:26:36,830:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005086 seconds.
2023-10-24 13:26:36,830:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:36,830:INFO:[LightGBM] [Info] Total Bins 6363
2023-10-24 13:26:36,830:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:36,831:INFO:[LightGBM] [Info] Start training from score 606.762865
2023-10-24 13:26:37,060:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004902 seconds.
2023-10-24 13:26:37,060:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:37,060:INFO:[LightGBM] [Info] Total Bins 6373
2023-10-24 13:26:37,060:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:37,060:INFO:[LightGBM] [Info] Start training from score 616.769414
2023-10-24 13:26:37,311:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004012 seconds.
2023-10-24 13:26:37,311:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:37,311:INFO:[LightGBM] [Info] Total Bins 6374
2023-10-24 13:26:37,311:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:37,311:INFO:[LightGBM] [Info] Start training from score 615.002212
2023-10-24 13:26:37,550:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005048 seconds.
2023-10-24 13:26:37,550:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:37,550:INFO:[LightGBM] [Info] Total Bins 6360
2023-10-24 13:26:37,550:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:37,550:INFO:[LightGBM] [Info] Start training from score 610.255829
2023-10-24 13:26:37,802:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005076 seconds.
2023-10-24 13:26:37,802:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:37,802:INFO:[LightGBM] [Info] Total Bins 6349
2023-10-24 13:26:37,802:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:37,802:INFO:[LightGBM] [Info] Start training from score 623.469357
2023-10-24 13:26:38,047:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006014 seconds.
2023-10-24 13:26:38,047:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:38,047:INFO:[LightGBM] [Info] Total Bins 6369
2023-10-24 13:26:38,047:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:38,047:INFO:[LightGBM] [Info] Start training from score 618.527716
2023-10-24 13:26:38,286:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004922 seconds.
2023-10-24 13:26:38,286:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:38,286:INFO:[LightGBM] [Info] Total Bins 6363
2023-10-24 13:26:38,286:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:38,286:INFO:[LightGBM] [Info] Start training from score 626.642161
2023-10-24 13:26:38,531:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004907 seconds.
2023-10-24 13:26:38,531:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:38,531:INFO:[LightGBM] [Info] Total Bins 6363
2023-10-24 13:26:38,531:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:38,531:INFO:[LightGBM] [Info] Start training from score 606.407914
2023-10-24 13:26:38,783:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004226 seconds.
2023-10-24 13:26:38,783:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:38,783:INFO:[LightGBM] [Info] Total Bins 6359
2023-10-24 13:26:38,783:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:38,783:INFO:[LightGBM] [Info] Start training from score 611.262724
2023-10-24 13:26:39,018:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005070 seconds.
2023-10-24 13:26:39,018:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:39,018:INFO:[LightGBM] [Info] Total Bins 6374
2023-10-24 13:26:39,018:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:39,018:INFO:[LightGBM] [Info] Start training from score 611.403724
2023-10-24 13:26:39,269:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004291 seconds.
2023-10-24 13:26:39,269:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:39,274:INFO:[LightGBM] [Info] Total Bins 6358
2023-10-24 13:26:39,274:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:39,274:INFO:[LightGBM] [Info] Start training from score 625.569737
2023-10-24 13:26:39,504:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004019 seconds.
2023-10-24 13:26:39,504:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:39,504:INFO:[LightGBM] [Info] Total Bins 6372
2023-10-24 13:26:39,504:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:39,504:INFO:[LightGBM] [Info] Start training from score 611.835599
2023-10-24 13:26:39,802:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007026 seconds.
2023-10-24 13:26:39,802:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:39,802:INFO:[LightGBM] [Info] Total Bins 6363
2023-10-24 13:26:39,802:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:39,802:INFO:[LightGBM] [Info] Start training from score 612.541408
2023-10-24 13:26:40,075:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004896 seconds.
2023-10-24 13:26:40,075:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:40,075:INFO:[LightGBM] [Info] Total Bins 6351
2023-10-24 13:26:40,075:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:40,075:INFO:[LightGBM] [Info] Start training from score 610.539051
2023-10-24 13:26:40,323:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005291 seconds.
2023-10-24 13:26:40,323:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:40,323:INFO:[LightGBM] [Info] Total Bins 6368
2023-10-24 13:26:40,323:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:40,325:INFO:[LightGBM] [Info] Start training from score 602.782855
2023-10-24 13:26:40,554:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005023 seconds.
2023-10-24 13:26:40,554:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:40,554:INFO:[LightGBM] [Info] Total Bins 6347
2023-10-24 13:26:40,554:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:40,569:INFO:[LightGBM] [Info] Start training from score 625.485034
2023-10-24 13:26:40,805:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004228 seconds.
2023-10-24 13:26:40,805:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:40,805:INFO:[LightGBM] [Info] Total Bins 6374
2023-10-24 13:26:40,805:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:40,805:INFO:[LightGBM] [Info] Start training from score 629.368373
2023-10-24 13:26:41,040:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005034 seconds.
2023-10-24 13:26:41,040:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:41,040:INFO:[LightGBM] [Info] Total Bins 6364
2023-10-24 13:26:41,040:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:41,040:INFO:[LightGBM] [Info] Start training from score 609.914456
2023-10-24 13:26:41,277:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004113 seconds.
2023-10-24 13:26:41,277:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:41,291:INFO:[LightGBM] [Info] Total Bins 6366
2023-10-24 13:26:41,291:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:41,291:INFO:[LightGBM] [Info] Start training from score 612.838097
2023-10-24 13:26:41,580:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005090 seconds.
2023-10-24 13:26:41,580:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:41,580:INFO:[LightGBM] [Info] Total Bins 6378
2023-10-24 13:26:41,580:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:41,580:INFO:[LightGBM] [Info] Start training from score 605.667640
2023-10-24 13:26:41,838:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005910 seconds.
2023-10-24 13:26:41,838:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:41,838:INFO:[LightGBM] [Info] Total Bins 6377
2023-10-24 13:26:41,838:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:41,838:INFO:[LightGBM] [Info] Start training from score 619.813261
2023-10-24 13:26:42,089:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005264 seconds.
2023-10-24 13:26:42,089:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:42,089:INFO:[LightGBM] [Info] Total Bins 6367
2023-10-24 13:26:42,089:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:42,089:INFO:[LightGBM] [Info] Start training from score 609.690936
2023-10-24 13:26:42,369:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005174 seconds.
2023-10-24 13:26:42,369:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:42,369:INFO:[LightGBM] [Info] Total Bins 6353
2023-10-24 13:26:42,369:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:42,369:INFO:[LightGBM] [Info] Start training from score 627.125382
2023-10-24 13:26:42,604:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005091 seconds.
2023-10-24 13:26:42,604:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:42,604:INFO:[LightGBM] [Info] Total Bins 6363
2023-10-24 13:26:42,604:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:42,604:INFO:[LightGBM] [Info] Start training from score 612.282814
2023-10-24 13:26:42,860:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005988 seconds.
2023-10-24 13:26:42,860:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:42,860:INFO:[LightGBM] [Info] Total Bins 6368
2023-10-24 13:26:42,860:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:42,860:INFO:[LightGBM] [Info] Start training from score 611.240966
2023-10-24 13:26:43,096:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005951 seconds.
2023-10-24 13:26:43,096:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:43,096:INFO:[LightGBM] [Info] Total Bins 6360
2023-10-24 13:26:43,096:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:43,096:INFO:[LightGBM] [Info] Start training from score 611.404268
2023-10-24 13:26:43,342:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004021 seconds.
2023-10-24 13:26:43,342:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:43,342:INFO:[LightGBM] [Info] Total Bins 6360
2023-10-24 13:26:43,342:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:43,342:INFO:[LightGBM] [Info] Start training from score 599.648746
2023-10-24 13:26:43,583:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005003 seconds.
2023-10-24 13:26:43,583:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:43,583:INFO:[LightGBM] [Info] Total Bins 6373
2023-10-24 13:26:43,583:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:43,583:INFO:[LightGBM] [Info] Start training from score 612.417812
2023-10-24 13:26:43,828:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005141 seconds.
2023-10-24 13:26:43,828:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:43,828:INFO:[LightGBM] [Info] Total Bins 6366
2023-10-24 13:26:43,828:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:43,828:INFO:[LightGBM] [Info] Start training from score 619.373450
2023-10-24 13:26:44,064:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005040 seconds.
2023-10-24 13:26:44,064:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:44,064:INFO:[LightGBM] [Info] Total Bins 6369
2023-10-24 13:26:44,064:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:44,064:INFO:[LightGBM] [Info] Start training from score 614.854504
2023-10-24 13:26:44,313:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004981 seconds.
2023-10-24 13:26:44,313:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:44,313:INFO:[LightGBM] [Info] Total Bins 6365
2023-10-24 13:26:44,313:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:44,313:INFO:[LightGBM] [Info] Start training from score 623.499128
2023-10-24 13:26:44,549:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005938 seconds.
2023-10-24 13:26:44,549:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:44,549:INFO:[LightGBM] [Info] Total Bins 6360
2023-10-24 13:26:44,549:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:44,549:INFO:[LightGBM] [Info] Start training from score 624.692842
2023-10-24 13:26:44,817:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005893 seconds.
2023-10-24 13:26:44,817:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:44,817:INFO:[LightGBM] [Info] Total Bins 6372
2023-10-24 13:26:44,817:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:44,817:INFO:[LightGBM] [Info] Start training from score 615.687601
2023-10-24 13:26:45,099:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005026 seconds.
2023-10-24 13:26:45,099:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:45,099:INFO:[LightGBM] [Info] Total Bins 6380
2023-10-24 13:26:45,099:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:45,115:INFO:[LightGBM] [Info] Start training from score 618.789904
2023-10-24 13:26:45,348:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005985 seconds.
2023-10-24 13:26:45,348:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:45,348:INFO:[LightGBM] [Info] Total Bins 6367
2023-10-24 13:26:45,348:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:45,348:INFO:[LightGBM] [Info] Start training from score 617.374451
2023-10-24 13:26:45,589:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004140 seconds.
2023-10-24 13:26:45,589:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:45,589:INFO:[LightGBM] [Info] Total Bins 6348
2023-10-24 13:26:45,589:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:45,589:INFO:[LightGBM] [Info] Start training from score 616.942834
2023-10-24 13:26:45,845:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004914 seconds.
2023-10-24 13:26:45,845:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:45,846:INFO:[LightGBM] [Info] Total Bins 6358
2023-10-24 13:26:45,846:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:45,847:INFO:[LightGBM] [Info] Start training from score 606.422821
2023-10-24 13:26:46,085:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004950 seconds.
2023-10-24 13:26:46,085:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:46,085:INFO:[LightGBM] [Info] Total Bins 6365
2023-10-24 13:26:46,085:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:46,085:INFO:[LightGBM] [Info] Start training from score 619.677078
2023-10-24 13:26:46,337:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004958 seconds.
2023-10-24 13:26:46,337:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:46,337:INFO:[LightGBM] [Info] Total Bins 6363
2023-10-24 13:26:46,338:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:46,338:INFO:[LightGBM] [Info] Start training from score 623.113487
2023-10-24 13:26:46,582:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006865 seconds.
2023-10-24 13:26:46,582:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:46,584:INFO:[LightGBM] [Info] Total Bins 6363
2023-10-24 13:26:46,584:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:46,584:INFO:[LightGBM] [Info] Start training from score 622.628550
2023-10-24 13:26:46,863:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004965 seconds.
2023-10-24 13:26:46,864:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:46,864:INFO:[LightGBM] [Info] Total Bins 6362
2023-10-24 13:26:46,864:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:46,865:INFO:[LightGBM] [Info] Start training from score 611.105683
2023-10-24 13:26:47,133:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005275 seconds.
2023-10-24 13:26:47,134:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:47,134:INFO:[LightGBM] [Info] Total Bins 6365
2023-10-24 13:26:47,134:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:47,135:INFO:[LightGBM] [Info] Start training from score 626.123599
2023-10-24 13:26:47,395:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005983 seconds.
2023-10-24 13:26:47,395:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:47,396:INFO:[LightGBM] [Info] Total Bins 6361
2023-10-24 13:26:47,396:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:47,396:INFO:[LightGBM] [Info] Start training from score 619.062795
2023-10-24 13:26:47,623:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004925 seconds.
2023-10-24 13:26:47,623:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:47,623:INFO:[LightGBM] [Info] Total Bins 6384
2023-10-24 13:26:47,623:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:47,638:INFO:[LightGBM] [Info] Start training from score 618.869749
2023-10-24 13:26:47,873:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005135 seconds.
2023-10-24 13:26:47,873:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:47,873:INFO:[LightGBM] [Info] Total Bins 6358
2023-10-24 13:26:47,873:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:47,873:INFO:[LightGBM] [Info] Start training from score 616.185830
2023-10-24 13:26:48,107:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004170 seconds.
2023-10-24 13:26:48,107:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:48,107:INFO:[LightGBM] [Info] Total Bins 6370
2023-10-24 13:26:48,107:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:48,107:INFO:[LightGBM] [Info] Start training from score 623.323069
2023-10-24 13:26:48,348:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004862 seconds.
2023-10-24 13:26:48,348:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:48,348:INFO:[LightGBM] [Info] Total Bins 6361
2023-10-24 13:26:48,348:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:48,348:INFO:[LightGBM] [Info] Start training from score 609.818984
2023-10-24 13:26:48,592:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004901 seconds.
2023-10-24 13:26:48,592:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:48,592:INFO:[LightGBM] [Info] Total Bins 6355
2023-10-24 13:26:48,592:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:48,592:INFO:[LightGBM] [Info] Start training from score 605.841402
2023-10-24 13:26:48,827:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004099 seconds.
2023-10-24 13:26:48,827:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:48,827:INFO:[LightGBM] [Info] Total Bins 6376
2023-10-24 13:26:48,827:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:48,827:INFO:[LightGBM] [Info] Start training from score 619.227528
2023-10-24 13:26:49,061:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005950 seconds.
2023-10-24 13:26:49,061:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:49,061:INFO:[LightGBM] [Info] Total Bins 6347
2023-10-24 13:26:49,061:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:49,061:INFO:[LightGBM] [Info] Start training from score 604.762911
2023-10-24 13:26:49,298:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005053 seconds.
2023-10-24 13:26:49,298:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:49,298:INFO:[LightGBM] [Info] Total Bins 6368
2023-10-24 13:26:49,298:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:49,298:INFO:[LightGBM] [Info] Start training from score 610.283756
2023-10-24 13:26:49,547:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005556 seconds.
2023-10-24 13:26:49,547:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:49,547:INFO:[LightGBM] [Info] Total Bins 6358
2023-10-24 13:26:49,548:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:49,548:INFO:[LightGBM] [Info] Start training from score 621.337003
2023-10-24 13:26:49,788:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005254 seconds.
2023-10-24 13:26:49,788:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:49,788:INFO:[LightGBM] [Info] Total Bins 6363
2023-10-24 13:26:49,788:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:49,788:INFO:[LightGBM] [Info] Start training from score 618.531084
2023-10-24 13:26:50,065:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004174 seconds.
2023-10-24 13:26:50,065:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:50,065:INFO:[LightGBM] [Info] Total Bins 6373
2023-10-24 13:26:50,065:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:50,065:INFO:[LightGBM] [Info] Start training from score 609.652757
2023-10-24 13:26:50,362:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005915 seconds.
2023-10-24 13:26:50,362:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:50,362:INFO:[LightGBM] [Info] Total Bins 6379
2023-10-24 13:26:50,362:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:50,362:INFO:[LightGBM] [Info] Start training from score 614.284993
2023-10-24 13:26:50,599:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005008 seconds.
2023-10-24 13:26:50,599:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:50,599:INFO:[LightGBM] [Info] Total Bins 6370
2023-10-24 13:26:50,599:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:50,599:INFO:[LightGBM] [Info] Start training from score 617.183300
2023-10-24 13:26:50,849:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004970 seconds.
2023-10-24 13:26:50,849:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:50,849:INFO:[LightGBM] [Info] Total Bins 6358
2023-10-24 13:26:50,849:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:50,849:INFO:[LightGBM] [Info] Start training from score 612.927903
2023-10-24 13:26:51,085:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005026 seconds.
2023-10-24 13:26:51,085:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:51,085:INFO:[LightGBM] [Info] Total Bins 6369
2023-10-24 13:26:51,085:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:51,085:INFO:[LightGBM] [Info] Start training from score 624.429547
2023-10-24 13:26:51,334:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004193 seconds.
2023-10-24 13:26:51,334:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:51,334:INFO:[LightGBM] [Info] Total Bins 6372
2023-10-24 13:26:51,334:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:51,334:INFO:[LightGBM] [Info] Start training from score 618.382080
2023-10-24 13:26:51,574:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004989 seconds.
2023-10-24 13:26:51,574:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:51,574:INFO:[LightGBM] [Info] Total Bins 6365
2023-10-24 13:26:51,574:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:51,574:INFO:[LightGBM] [Info] Start training from score 624.972548
2023-10-24 13:26:51,819:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004894 seconds.
2023-10-24 13:26:51,819:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:51,819:INFO:[LightGBM] [Info] Total Bins 6367
2023-10-24 13:26:51,819:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:51,819:INFO:[LightGBM] [Info] Start training from score 615.255989
2023-10-24 13:26:52,054:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004076 seconds.
2023-10-24 13:26:52,054:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:52,054:INFO:[LightGBM] [Info] Total Bins 6364
2023-10-24 13:26:52,054:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:52,054:INFO:[LightGBM] [Info] Start training from score 615.477457
2023-10-24 13:26:52,305:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004112 seconds.
2023-10-24 13:26:52,305:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:52,305:INFO:[LightGBM] [Info] Total Bins 6365
2023-10-24 13:26:52,305:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:52,305:INFO:[LightGBM] [Info] Start training from score 626.976544
2023-10-24 13:26:52,540:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005898 seconds.
2023-10-24 13:26:52,540:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:52,540:INFO:[LightGBM] [Info] Total Bins 6339
2023-10-24 13:26:52,540:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:52,540:INFO:[LightGBM] [Info] Start training from score 627.835196
2023-10-24 13:26:52,775:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004100 seconds.
2023-10-24 13:26:52,775:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:52,775:INFO:[LightGBM] [Info] Total Bins 6376
2023-10-24 13:26:52,775:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:52,790:INFO:[LightGBM] [Info] Start training from score 629.598010
2023-10-24 13:26:53,026:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006042 seconds.
2023-10-24 13:26:53,026:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:53,026:INFO:[LightGBM] [Info] Total Bins 6377
2023-10-24 13:26:53,026:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:53,026:INFO:[LightGBM] [Info] Start training from score 614.886168
2023-10-24 13:26:53,273:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004988 seconds.
2023-10-24 13:26:53,273:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:53,273:INFO:[LightGBM] [Info] Total Bins 6352
2023-10-24 13:26:53,274:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:53,274:INFO:[LightGBM] [Info] Start training from score 610.543779
2023-10-24 13:26:53,517:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005042 seconds.
2023-10-24 13:26:53,517:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:53,517:INFO:[LightGBM] [Info] Total Bins 6351
2023-10-24 13:26:53,517:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:53,517:INFO:[LightGBM] [Info] Start training from score 618.581591
2023-10-24 13:26:53,752:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006024 seconds.
2023-10-24 13:26:53,752:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:53,752:INFO:[LightGBM] [Info] Total Bins 6360
2023-10-24 13:26:53,752:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:53,752:INFO:[LightGBM] [Info] Start training from score 627.375002
2023-10-24 13:26:53,997:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005118 seconds.
2023-10-24 13:26:53,997:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:53,997:INFO:[LightGBM] [Info] Total Bins 6381
2023-10-24 13:26:53,997:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:53,997:INFO:[LightGBM] [Info] Start training from score 623.999813
2023-10-24 13:26:54,250:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005086 seconds.
2023-10-24 13:26:54,251:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:54,251:INFO:[LightGBM] [Info] Total Bins 6367
2023-10-24 13:26:54,251:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:54,253:INFO:[LightGBM] [Info] Start training from score 612.020336
2023-10-24 13:26:54,498:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005025 seconds.
2023-10-24 13:26:54,498:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:54,498:INFO:[LightGBM] [Info] Total Bins 6378
2023-10-24 13:26:54,499:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:54,499:INFO:[LightGBM] [Info] Start training from score 621.458661
2023-10-24 13:26:54,734:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005026 seconds.
2023-10-24 13:26:54,734:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:54,735:INFO:[LightGBM] [Info] Total Bins 6361
2023-10-24 13:26:54,735:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:54,736:INFO:[LightGBM] [Info] Start training from score 623.111462
2023-10-24 13:26:54,968:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004287 seconds.
2023-10-24 13:26:54,968:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:54,968:INFO:[LightGBM] [Info] Total Bins 6350
2023-10-24 13:26:54,968:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:54,968:INFO:[LightGBM] [Info] Start training from score 620.202482
2023-10-24 13:26:55,266:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005737 seconds.
2023-10-24 13:26:55,266:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:55,266:INFO:[LightGBM] [Info] Total Bins 6361
2023-10-24 13:26:55,266:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:55,266:INFO:[LightGBM] [Info] Start training from score 619.569929
2023-10-24 13:26:55,549:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004180 seconds.
2023-10-24 13:26:55,549:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:55,549:INFO:[LightGBM] [Info] Total Bins 6361
2023-10-24 13:26:55,549:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:55,549:INFO:[LightGBM] [Info] Start training from score 613.973286
2023-10-24 13:26:55,796:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005000 seconds.
2023-10-24 13:26:55,796:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:55,796:INFO:[LightGBM] [Info] Total Bins 6368
2023-10-24 13:26:55,796:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:55,800:INFO:[LightGBM] [Info] Start training from score 613.379396
2023-10-24 13:26:56,050:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005012 seconds.
2023-10-24 13:26:56,050:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:56,050:INFO:[LightGBM] [Info] Total Bins 6363
2023-10-24 13:26:56,050:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:56,050:INFO:[LightGBM] [Info] Start training from score 619.726094
2023-10-24 13:26:56,290:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005054 seconds.
2023-10-24 13:26:56,290:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:56,291:INFO:[LightGBM] [Info] Total Bins 6364
2023-10-24 13:26:56,291:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:56,291:INFO:[LightGBM] [Info] Start training from score 606.812712
2023-10-24 13:26:56,534:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004977 seconds.
2023-10-24 13:26:56,534:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:56,535:INFO:[LightGBM] [Info] Total Bins 6352
2023-10-24 13:26:56,535:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:56,536:INFO:[LightGBM] [Info] Start training from score 626.539879
2023-10-24 13:26:56,826:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005147 seconds.
2023-10-24 13:26:56,826:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:56,826:INFO:[LightGBM] [Info] Total Bins 6368
2023-10-24 13:26:56,826:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:56,827:INFO:[LightGBM] [Info] Start training from score 612.029582
2023-10-24 13:26:57,066:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006044 seconds.
2023-10-24 13:26:57,066:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:57,066:INFO:[LightGBM] [Info] Total Bins 6361
2023-10-24 13:26:57,066:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:57,066:INFO:[LightGBM] [Info] Start training from score 613.889534
2023-10-24 13:26:57,311:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005179 seconds.
2023-10-24 13:26:57,311:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:57,311:INFO:[LightGBM] [Info] Total Bins 6371
2023-10-24 13:26:57,311:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:57,311:INFO:[LightGBM] [Info] Start training from score 614.913818
2023-10-24 13:26:57,601:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004160 seconds.
2023-10-24 13:26:57,601:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:57,601:INFO:[LightGBM] [Info] Total Bins 6358
2023-10-24 13:26:57,601:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:57,601:INFO:[LightGBM] [Info] Start training from score 621.757135
2023-10-24 13:26:57,836:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005095 seconds.
2023-10-24 13:26:57,836:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:57,836:INFO:[LightGBM] [Info] Total Bins 6350
2023-10-24 13:26:57,836:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:57,836:INFO:[LightGBM] [Info] Start training from score 614.583947
2023-10-24 13:26:58,070:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005002 seconds.
2023-10-24 13:26:58,070:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:58,070:INFO:[LightGBM] [Info] Total Bins 6360
2023-10-24 13:26:58,070:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:58,070:INFO:[LightGBM] [Info] Start training from score 622.659655
2023-10-24 13:26:58,323:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005290 seconds.
2023-10-24 13:26:58,324:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:58,324:INFO:[LightGBM] [Info] Total Bins 6363
2023-10-24 13:26:58,324:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:58,325:INFO:[LightGBM] [Info] Start training from score 621.006426
2023-10-24 13:26:58,563:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004136 seconds.
2023-10-24 13:26:58,563:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:58,563:INFO:[LightGBM] [Info] Total Bins 6365
2023-10-24 13:26:58,563:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:58,564:INFO:[LightGBM] [Info] Start training from score 617.773629
2023-10-24 13:26:58,808:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004228 seconds.
2023-10-24 13:26:58,808:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:58,808:INFO:[LightGBM] [Info] Total Bins 6354
2023-10-24 13:26:58,808:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:58,808:INFO:[LightGBM] [Info] Start training from score 601.020834
2023-10-24 13:26:59,043:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006036 seconds.
2023-10-24 13:26:59,043:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:59,043:INFO:[LightGBM] [Info] Total Bins 6372
2023-10-24 13:26:59,043:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:59,043:INFO:[LightGBM] [Info] Start training from score 612.406273
2023-10-24 13:26:59,298:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005922 seconds.
2023-10-24 13:26:59,298:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:59,298:INFO:[LightGBM] [Info] Total Bins 6365
2023-10-24 13:26:59,298:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:59,298:INFO:[LightGBM] [Info] Start training from score 619.045078
2023-10-24 13:26:59,534:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005124 seconds.
2023-10-24 13:26:59,534:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:59,534:INFO:[LightGBM] [Info] Total Bins 6349
2023-10-24 13:26:59,534:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:59,534:INFO:[LightGBM] [Info] Start training from score 607.263955
2023-10-24 13:26:59,779:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004179 seconds.
2023-10-24 13:26:59,779:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:26:59,779:INFO:[LightGBM] [Info] Total Bins 6362
2023-10-24 13:26:59,779:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:26:59,779:INFO:[LightGBM] [Info] Start training from score 618.611483
2023-10-24 13:27:00,014:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005576 seconds.
2023-10-24 13:27:00,014:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:00,014:INFO:[LightGBM] [Info] Total Bins 6368
2023-10-24 13:27:00,014:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:00,014:INFO:[LightGBM] [Info] Start training from score 619.835157
2023-10-24 13:27:00,277:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005285 seconds.
2023-10-24 13:27:00,277:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:00,278:INFO:[LightGBM] [Info] Total Bins 6362
2023-10-24 13:27:00,278:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:00,279:INFO:[LightGBM] [Info] Start training from score 621.309491
2023-10-24 13:27:00,580:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005674 seconds.
2023-10-24 13:27:00,580:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:00,581:INFO:[LightGBM] [Info] Total Bins 6367
2023-10-24 13:27:00,581:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:00,582:INFO:[LightGBM] [Info] Start training from score 622.359547
2023-10-24 13:27:00,830:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004084 seconds.
2023-10-24 13:27:00,831:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:00,831:INFO:[LightGBM] [Info] Total Bins 6368
2023-10-24 13:27:00,831:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:00,832:INFO:[LightGBM] [Info] Start training from score 626.130491
2023-10-24 13:27:01,078:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004922 seconds.
2023-10-24 13:27:01,079:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:01,079:INFO:[LightGBM] [Info] Total Bins 6371
2023-10-24 13:27:01,079:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:01,080:INFO:[LightGBM] [Info] Start training from score 623.049942
2023-10-24 13:27:01,314:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004141 seconds.
2023-10-24 13:27:01,314:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:01,314:INFO:[LightGBM] [Info] Total Bins 6379
2023-10-24 13:27:01,314:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:01,314:INFO:[LightGBM] [Info] Start training from score 610.129344
2023-10-24 13:27:01,554:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005073 seconds.
2023-10-24 13:27:01,554:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:01,554:INFO:[LightGBM] [Info] Total Bins 6368
2023-10-24 13:27:01,554:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:01,554:INFO:[LightGBM] [Info] Start training from score 618.706783
2023-10-24 13:27:01,804:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005148 seconds.
2023-10-24 13:27:01,804:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:01,804:INFO:[LightGBM] [Info] Total Bins 6356
2023-10-24 13:27:01,804:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:01,804:INFO:[LightGBM] [Info] Start training from score 620.166708
2023-10-24 13:27:02,040:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005995 seconds.
2023-10-24 13:27:02,040:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:02,040:INFO:[LightGBM] [Info] Total Bins 6368
2023-10-24 13:27:02,040:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:02,040:INFO:[LightGBM] [Info] Start training from score 612.193659
2023-10-24 13:27:02,286:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004976 seconds.
2023-10-24 13:27:02,286:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:02,286:INFO:[LightGBM] [Info] Total Bins 6363
2023-10-24 13:27:02,286:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:02,286:INFO:[LightGBM] [Info] Start training from score 620.558407
2023-10-24 13:27:02,538:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004935 seconds.
2023-10-24 13:27:02,538:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:02,538:INFO:[LightGBM] [Info] Total Bins 6362
2023-10-24 13:27:02,538:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:02,538:INFO:[LightGBM] [Info] Start training from score 620.245086
2023-10-24 13:27:02,790:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005176 seconds.
2023-10-24 13:27:02,790:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:02,790:INFO:[LightGBM] [Info] Total Bins 6368
2023-10-24 13:27:02,790:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:02,790:INFO:[LightGBM] [Info] Start training from score 619.217212
2023-10-24 13:27:03,085:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004140 seconds.
2023-10-24 13:27:03,085:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:03,085:INFO:[LightGBM] [Info] Total Bins 6357
2023-10-24 13:27:03,085:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:03,085:INFO:[LightGBM] [Info] Start training from score 626.651061
2023-10-24 13:27:03,339:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006095 seconds.
2023-10-24 13:27:03,339:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:03,340:INFO:[LightGBM] [Info] Total Bins 6353
2023-10-24 13:27:03,340:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:03,341:INFO:[LightGBM] [Info] Start training from score 618.072006
2023-10-24 13:27:03,576:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004072 seconds.
2023-10-24 13:27:03,576:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:03,576:INFO:[LightGBM] [Info] Total Bins 6351
2023-10-24 13:27:03,576:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:03,576:INFO:[LightGBM] [Info] Start training from score 608.496673
2023-10-24 13:27:03,812:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004179 seconds.
2023-10-24 13:27:03,812:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:03,812:INFO:[LightGBM] [Info] Total Bins 6359
2023-10-24 13:27:03,812:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:03,812:INFO:[LightGBM] [Info] Start training from score 611.508192
2023-10-24 13:27:04,056:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004104 seconds.
2023-10-24 13:27:04,056:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:04,056:INFO:[LightGBM] [Info] Total Bins 6364
2023-10-24 13:27:04,056:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:04,056:INFO:[LightGBM] [Info] Start training from score 615.302066
2023-10-24 13:27:04,291:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005045 seconds.
2023-10-24 13:27:04,291:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:04,291:INFO:[LightGBM] [Info] Total Bins 6368
2023-10-24 13:27:04,305:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:04,305:INFO:[LightGBM] [Info] Start training from score 617.575124
2023-10-24 13:27:04,544:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006040 seconds.
2023-10-24 13:27:04,544:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:04,544:INFO:[LightGBM] [Info] Total Bins 6365
2023-10-24 13:27:04,544:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:04,544:INFO:[LightGBM] [Info] Start training from score 622.017002
2023-10-24 13:27:04,795:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004955 seconds.
2023-10-24 13:27:04,795:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:04,795:INFO:[LightGBM] [Info] Total Bins 6354
2023-10-24 13:27:04,795:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:04,795:INFO:[LightGBM] [Info] Start training from score 618.316431
2023-10-24 13:27:05,043:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006074 seconds.
2023-10-24 13:27:05,043:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:05,043:INFO:[LightGBM] [Info] Total Bins 6373
2023-10-24 13:27:05,043:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:05,043:INFO:[LightGBM] [Info] Start training from score 617.605294
2023-10-24 13:27:05,278:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005966 seconds.
2023-10-24 13:27:05,278:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:05,278:INFO:[LightGBM] [Info] Total Bins 6355
2023-10-24 13:27:05,278:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:05,278:INFO:[LightGBM] [Info] Start training from score 616.845909
2023-10-24 13:27:05,560:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006703 seconds.
2023-10-24 13:27:05,560:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:05,560:INFO:[LightGBM] [Info] Total Bins 6355
2023-10-24 13:27:05,560:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:05,560:INFO:[LightGBM] [Info] Start training from score 621.143023
2023-10-24 13:27:05,843:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004182 seconds.
2023-10-24 13:27:05,843:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:05,843:INFO:[LightGBM] [Info] Total Bins 6362
2023-10-24 13:27:05,843:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:05,843:INFO:[LightGBM] [Info] Start training from score 623.245444
2023-10-24 13:27:06,077:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004242 seconds.
2023-10-24 13:27:06,077:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:06,077:INFO:[LightGBM] [Info] Total Bins 6362
2023-10-24 13:27:06,077:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:06,093:INFO:[LightGBM] [Info] Start training from score 605.039853
2023-10-24 13:27:06,334:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006110 seconds.
2023-10-24 13:27:06,334:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:06,335:INFO:[LightGBM] [Info] Total Bins 6368
2023-10-24 13:27:06,335:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:06,336:INFO:[LightGBM] [Info] Start training from score 608.210143
2023-10-24 13:27:06,579:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005921 seconds.
2023-10-24 13:27:06,579:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:06,579:INFO:[LightGBM] [Info] Total Bins 6383
2023-10-24 13:27:06,579:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:06,579:INFO:[LightGBM] [Info] Start training from score 621.280055
2023-10-24 13:27:06,814:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005014 seconds.
2023-10-24 13:27:06,814:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:06,814:INFO:[LightGBM] [Info] Total Bins 6363
2023-10-24 13:27:06,814:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:06,814:INFO:[LightGBM] [Info] Start training from score 619.169751
2023-10-24 13:27:07,064:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005945 seconds.
2023-10-24 13:27:07,064:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:07,064:INFO:[LightGBM] [Info] Total Bins 6364
2023-10-24 13:27:07,064:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:07,064:INFO:[LightGBM] [Info] Start training from score 614.252987
2023-10-24 13:27:07,308:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005147 seconds.
2023-10-24 13:27:07,308:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:07,308:INFO:[LightGBM] [Info] Total Bins 6352
2023-10-24 13:27:07,308:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:07,308:INFO:[LightGBM] [Info] Start training from score 608.474343
2023-10-24 13:27:07,540:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004966 seconds.
2023-10-24 13:27:07,540:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:07,540:INFO:[LightGBM] [Info] Total Bins 6355
2023-10-24 13:27:07,540:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:07,540:INFO:[LightGBM] [Info] Start training from score 614.949320
2023-10-24 13:27:07,785:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005264 seconds.
2023-10-24 13:27:07,785:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:07,785:INFO:[LightGBM] [Info] Total Bins 6365
2023-10-24 13:27:07,785:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:07,785:INFO:[LightGBM] [Info] Start training from score 626.692741
2023-10-24 13:27:08,021:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004998 seconds.
2023-10-24 13:27:08,021:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:08,021:INFO:[LightGBM] [Info] Total Bins 6367
2023-10-24 13:27:08,021:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:08,021:INFO:[LightGBM] [Info] Start training from score 620.596567
2023-10-24 13:27:08,272:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006002 seconds.
2023-10-24 13:27:08,272:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:08,272:INFO:[LightGBM] [Info] Total Bins 6363
2023-10-24 13:27:08,272:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:08,272:INFO:[LightGBM] [Info] Start training from score 612.241702
2023-10-24 13:27:08,522:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005025 seconds.
2023-10-24 13:27:08,522:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:08,522:INFO:[LightGBM] [Info] Total Bins 6351
2023-10-24 13:27:08,522:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:08,522:INFO:[LightGBM] [Info] Start training from score 608.773758
2023-10-24 13:27:08,775:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006030 seconds.
2023-10-24 13:27:08,775:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:08,775:INFO:[LightGBM] [Info] Total Bins 6380
2023-10-24 13:27:08,775:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:08,791:INFO:[LightGBM] [Info] Start training from score 613.407964
2023-10-24 13:27:09,026:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006254 seconds.
2023-10-24 13:27:09,026:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:09,026:INFO:[LightGBM] [Info] Total Bins 6356
2023-10-24 13:27:09,026:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:09,026:INFO:[LightGBM] [Info] Start training from score 612.803901
2023-10-24 13:27:09,260:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005992 seconds.
2023-10-24 13:27:09,260:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:09,260:INFO:[LightGBM] [Info] Total Bins 6381
2023-10-24 13:27:09,260:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:09,260:INFO:[LightGBM] [Info] Start training from score 608.494527
2023-10-24 13:27:09,501:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004166 seconds.
2023-10-24 13:27:09,501:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:09,511:INFO:[LightGBM] [Info] Total Bins 6362
2023-10-24 13:27:09,511:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:09,511:INFO:[LightGBM] [Info] Start training from score 613.449746
2023-10-24 13:27:09,744:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004990 seconds.
2023-10-24 13:27:09,744:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:09,744:INFO:[LightGBM] [Info] Total Bins 6354
2023-10-24 13:27:09,744:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:09,744:INFO:[LightGBM] [Info] Start training from score 616.128796
2023-10-24 13:27:09,980:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004279 seconds.
2023-10-24 13:27:09,980:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:09,980:INFO:[LightGBM] [Info] Total Bins 6352
2023-10-24 13:27:09,980:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:09,980:INFO:[LightGBM] [Info] Start training from score 614.215017
2023-10-24 13:27:10,230:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006017 seconds.
2023-10-24 13:27:10,230:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:10,230:INFO:[LightGBM] [Info] Total Bins 6382
2023-10-24 13:27:10,230:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:10,230:INFO:[LightGBM] [Info] Start training from score 607.528722
2023-10-24 13:27:10,472:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006215 seconds.
2023-10-24 13:27:10,472:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:10,472:INFO:[LightGBM] [Info] Total Bins 6373
2023-10-24 13:27:10,472:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:10,472:INFO:[LightGBM] [Info] Start training from score 619.904003
2023-10-24 13:27:10,756:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005151 seconds.
2023-10-24 13:27:10,756:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:10,757:INFO:[LightGBM] [Info] Total Bins 6368
2023-10-24 13:27:10,757:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:10,758:INFO:[LightGBM] [Info] Start training from score 608.210868
2023-10-24 13:27:11,044:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005112 seconds.
2023-10-24 13:27:11,044:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:11,044:INFO:[LightGBM] [Info] Total Bins 6367
2023-10-24 13:27:11,044:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:11,044:INFO:[LightGBM] [Info] Start training from score 622.627345
2023-10-24 13:27:11,304:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005385 seconds.
2023-10-24 13:27:11,304:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:11,304:INFO:[LightGBM] [Info] Total Bins 6368
2023-10-24 13:27:11,305:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:11,305:INFO:[LightGBM] [Info] Start training from score 615.185385
2023-10-24 13:27:11,538:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004993 seconds.
2023-10-24 13:27:11,538:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:11,538:INFO:[LightGBM] [Info] Total Bins 6364
2023-10-24 13:27:11,538:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:11,538:INFO:[LightGBM] [Info] Start training from score 618.889675
2023-10-24 13:27:11,814:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006109 seconds.
2023-10-24 13:27:11,814:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:11,814:INFO:[LightGBM] [Info] Total Bins 6362
2023-10-24 13:27:11,814:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:11,814:INFO:[LightGBM] [Info] Start training from score 610.429715
2023-10-24 13:27:12,079:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006564 seconds.
2023-10-24 13:27:12,079:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:12,079:INFO:[LightGBM] [Info] Total Bins 6356
2023-10-24 13:27:12,079:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:12,079:INFO:[LightGBM] [Info] Start training from score 611.993383
2023-10-24 13:27:12,262:INFO:Uploading results into container
2023-10-24 13:27:12,262:INFO:Uploading model into container now
2023-10-24 13:27:12,279:INFO:_master_model_container: 21
2023-10-24 13:27:12,279:INFO:_display_container: 4
2023-10-24 13:27:12,279:INFO:AdaBoostRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                  learning_rate=1e-07, loss='square', n_estimators=180,
                  random_state=123)
2023-10-24 13:27:12,279:INFO:create_model() successfully completed......................................
2023-10-24 13:27:12,492:INFO:SubProcess create_model() end ==================================
2023-10-24 13:27:12,492:INFO:choose_better activated
2023-10-24 13:27:12,492:INFO:SubProcess create_model() called ==================================
2023-10-24 13:27:12,492:INFO:Initializing create_model()
2023-10-24 13:27:12,492:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166D0B713A0>, estimator=AdaBoostRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                  n_estimators=10, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 13:27:12,492:INFO:Checking exceptions
2023-10-24 13:27:12,492:INFO:Importing libraries
2023-10-24 13:27:12,492:INFO:Copying training dataset
2023-10-24 13:27:12,513:INFO:Defining folds
2023-10-24 13:27:12,513:INFO:Declaring metric variables
2023-10-24 13:27:12,513:INFO:Importing untrained model
2023-10-24 13:27:12,513:INFO:Declaring custom model
2023-10-24 13:27:12,513:INFO:AdaBoost Regressor Imported successfully
2023-10-24 13:27:12,513:INFO:Starting cross validation
2023-10-24 13:27:12,523:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 13:27:39,751:INFO:Calculating mean and std
2023-10-24 13:27:39,751:INFO:Creating metrics dataframe
2023-10-24 13:27:39,751:INFO:Finalizing model
2023-10-24 13:27:40,000:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004473 seconds.
2023-10-24 13:27:40,000:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:40,000:INFO:[LightGBM] [Info] Total Bins 6357
2023-10-24 13:27:40,000:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:40,000:INFO:[LightGBM] [Info] Start training from score 614.999628
2023-10-24 13:27:40,299:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005150 seconds.
2023-10-24 13:27:40,299:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:40,314:INFO:[LightGBM] [Info] Total Bins 6331
2023-10-24 13:27:40,314:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:40,314:INFO:[LightGBM] [Info] Start training from score 839.907874
2023-10-24 13:27:40,579:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006166 seconds.
2023-10-24 13:27:40,579:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:40,579:INFO:[LightGBM] [Info] Total Bins 6306
2023-10-24 13:27:40,579:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:40,579:INFO:[LightGBM] [Info] Start training from score 1119.305129
2023-10-24 13:27:40,830:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006128 seconds.
2023-10-24 13:27:40,830:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:40,830:INFO:[LightGBM] [Info] Total Bins 6264
2023-10-24 13:27:40,830:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:40,830:INFO:[LightGBM] [Info] Start training from score 1352.870927
2023-10-24 13:27:41,081:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006232 seconds.
2023-10-24 13:27:41,081:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:41,081:INFO:[LightGBM] [Info] Total Bins 6247
2023-10-24 13:27:41,081:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:41,081:INFO:[LightGBM] [Info] Start training from score 1545.286806
2023-10-24 13:27:41,343:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005260 seconds.
2023-10-24 13:27:41,343:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:41,343:INFO:[LightGBM] [Info] Total Bins 6189
2023-10-24 13:27:41,344:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 46
2023-10-24 13:27:41,344:INFO:[LightGBM] [Info] Start training from score 1677.193032
2023-10-24 13:27:41,597:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005128 seconds.
2023-10-24 13:27:41,597:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:41,597:INFO:[LightGBM] [Info] Total Bins 6140
2023-10-24 13:27:41,597:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-24 13:27:41,597:INFO:[LightGBM] [Info] Start training from score 1831.167878
2023-10-24 13:27:41,848:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005170 seconds.
2023-10-24 13:27:41,848:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:41,848:INFO:[LightGBM] [Info] Total Bins 6122
2023-10-24 13:27:41,848:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-24 13:27:41,848:INFO:[LightGBM] [Info] Start training from score 1881.531403
2023-10-24 13:27:42,152:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005516 seconds.
2023-10-24 13:27:42,152:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:42,153:INFO:[LightGBM] [Info] Total Bins 6099
2023-10-24 13:27:42,153:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-24 13:27:42,154:INFO:[LightGBM] [Info] Start training from score 1939.434551
2023-10-24 13:27:42,447:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006115 seconds.
2023-10-24 13:27:42,447:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:27:42,448:INFO:[LightGBM] [Info] Total Bins 6058
2023-10-24 13:27:42,448:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 44
2023-10-24 13:27:42,449:INFO:[LightGBM] [Info] Start training from score 2010.189257
2023-10-24 13:27:42,665:INFO:Uploading results into container
2023-10-24 13:27:42,666:INFO:Uploading model into container now
2023-10-24 13:27:42,667:INFO:_master_model_container: 22
2023-10-24 13:27:42,667:INFO:_display_container: 5
2023-10-24 13:27:42,668:INFO:AdaBoostRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                  n_estimators=10, random_state=123)
2023-10-24 13:27:42,669:INFO:create_model() successfully completed......................................
2023-10-24 13:27:42,832:INFO:SubProcess create_model() end ==================================
2023-10-24 13:27:42,833:INFO:AdaBoostRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                  n_estimators=10, random_state=123) result for R2 is 0.7153
2023-10-24 13:27:42,834:INFO:AdaBoostRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                  learning_rate=1e-07, loss='square', n_estimators=180,
                  random_state=123) result for R2 is 0.7579
2023-10-24 13:27:42,835:INFO:AdaBoostRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                  learning_rate=1e-07, loss='square', n_estimators=180,
                  random_state=123) is best model
2023-10-24 13:27:42,835:INFO:choose_better completed
2023-10-24 13:27:42,838:INFO:_master_model_container: 22
2023-10-24 13:27:42,839:INFO:_display_container: 4
2023-10-24 13:27:42,840:INFO:AdaBoostRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                  learning_rate=1e-07, loss='square', n_estimators=180,
                  random_state=123)
2023-10-24 13:27:42,840:INFO:tune_model() successfully completed......................................
2023-10-24 13:27:42,972:INFO:Initializing ensemble_model()
2023-10-24 13:27:42,972:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166D0B713A0>, estimator=AdaBoostRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                  learning_rate=1e-07, loss='square', n_estimators=180,
                  random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=True, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-24 13:27:42,972:INFO:Checking exceptions
2023-10-24 13:27:42,985:INFO:Importing libraries
2023-10-24 13:27:42,985:INFO:Copying training dataset
2023-10-24 13:27:42,985:INFO:Checking base model
2023-10-24 13:27:42,986:INFO:Base model : AdaBoost Regressor
2023-10-24 13:27:42,986:INFO:Importing untrained ensembler
2023-10-24 13:27:42,986:INFO:Ensemble method set to Bagging
2023-10-24 13:27:42,986:INFO:SubProcess create_model() called ==================================
2023-10-24 13:27:42,989:INFO:Initializing create_model()
2023-10-24 13:27:42,989:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000166D0B713A0>, estimator=BaggingRegressor(estimator=AdaBoostRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                                     random_state=123),
                                             learning_rate=1e-07, loss='square',
                                             n_estimators=180,
                                             random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000166D0C45580>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 13:27:42,990:INFO:Checking exceptions
2023-10-24 13:27:42,990:INFO:Importing libraries
2023-10-24 13:27:42,990:INFO:Copying training dataset
2023-10-24 13:27:43,012:INFO:Defining folds
2023-10-24 13:27:43,012:INFO:Declaring metric variables
2023-10-24 13:27:43,012:INFO:Importing untrained model
2023-10-24 13:27:43,012:INFO:Declaring custom model
2023-10-24 13:27:43,014:INFO:Bagging Regressor Imported successfully
2023-10-24 13:27:43,014:INFO:Starting cross validation
2023-10-24 13:27:43,016:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
