2023-10-20 23:15:29,306:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-20 23:15:29,306:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-20 23:15:29,306:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-20 23:15:29,306:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-20 23:20:46,999:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-20 23:20:46,999:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-20 23:20:46,999:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-20 23:20:46,999:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-20 23:20:47,186:INFO:PyCaret RegressionExperiment
2023-10-20 23:20:47,186:INFO:Logging name: exp_A
2023-10-20 23:20:47,186:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-20 23:20:47,186:INFO:version 3.1.0
2023-10-20 23:20:47,186:INFO:Initializing setup()
2023-10-20 23:20:47,186:INFO:self.USI: 2be0
2023-10-20 23:20:47,186:INFO:self._variable_keys: {'transform_target_param', 'exp_name_log', 'y_train', 'logging_param', 'n_jobs_param', 'X_train', 'target_param', 'USI', 'gpu_n_jobs_param', 'fold_groups_param', '_ml_usecase', 'seed', 'fold_generator', 'idx', 'html_param', 'log_plots_param', 'y', 'gpu_param', 'X_test', 'memory', 'y_test', 'data', 'X', 'exp_id', '_available_plots', 'fold_shuffle_param', 'pipeline'}
2023-10-20 23:20:47,186:INFO:Checking environment
2023-10-20 23:20:47,186:INFO:python_version: 3.8.18
2023-10-20 23:20:47,186:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-20 23:20:47,186:INFO:machine: AMD64
2023-10-20 23:20:47,186:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-20 23:20:47,186:INFO:Memory: svmem(total=16505954304, available=3563368448, percent=78.4, used=12942585856, free=3563368448)
2023-10-20 23:20:47,186:INFO:Physical Core: 8
2023-10-20 23:20:47,186:INFO:Logical Core: 16
2023-10-20 23:20:47,186:INFO:Checking libraries
2023-10-20 23:20:47,186:INFO:System:
2023-10-20 23:20:47,186:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-20 23:20:47,186:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-20 23:20:47,186:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-20 23:20:47,186:INFO:PyCaret required dependencies:
2023-10-20 23:20:47,253:INFO:                 pip: 23.3
2023-10-20 23:20:47,254:INFO:          setuptools: 68.0.0
2023-10-20 23:20:47,254:INFO:             pycaret: 3.1.0
2023-10-20 23:20:47,254:INFO:             IPython: 8.12.0
2023-10-20 23:20:47,254:INFO:          ipywidgets: 8.1.1
2023-10-20 23:20:47,254:INFO:                tqdm: 4.66.1
2023-10-20 23:20:47,254:INFO:               numpy: 1.23.5
2023-10-20 23:20:47,254:INFO:              pandas: 1.5.3
2023-10-20 23:20:47,254:INFO:              jinja2: 3.1.2
2023-10-20 23:20:47,254:INFO:               scipy: 1.10.1
2023-10-20 23:20:47,254:INFO:              joblib: 1.3.2
2023-10-20 23:20:47,254:INFO:             sklearn: 1.2.2
2023-10-20 23:20:47,254:INFO:                pyod: 1.1.0
2023-10-20 23:20:47,254:INFO:            imblearn: 0.11.0
2023-10-20 23:20:47,254:INFO:   category_encoders: 2.6.2
2023-10-20 23:20:47,254:INFO:            lightgbm: 4.1.0
2023-10-20 23:20:47,254:INFO:               numba: 0.58.1
2023-10-20 23:20:47,254:INFO:            requests: 2.31.0
2023-10-20 23:20:47,254:INFO:          matplotlib: 3.7.3
2023-10-20 23:20:47,254:INFO:          scikitplot: 0.3.7
2023-10-20 23:20:47,254:INFO:         yellowbrick: 1.5
2023-10-20 23:20:47,255:INFO:              plotly: 5.17.0
2023-10-20 23:20:47,255:INFO:    plotly-resampler: Not installed
2023-10-20 23:20:47,255:INFO:             kaleido: 0.2.1
2023-10-20 23:20:47,255:INFO:           schemdraw: 0.15
2023-10-20 23:20:47,255:INFO:         statsmodels: 0.14.0
2023-10-20 23:20:47,255:INFO:              sktime: 0.21.1
2023-10-20 23:20:47,255:INFO:               tbats: 1.1.3
2023-10-20 23:20:47,255:INFO:            pmdarima: 2.0.3
2023-10-20 23:20:47,255:INFO:              psutil: 5.9.0
2023-10-20 23:20:47,255:INFO:          markupsafe: 2.1.3
2023-10-20 23:20:47,255:INFO:             pickle5: Not installed
2023-10-20 23:20:47,255:INFO:         cloudpickle: 2.2.1
2023-10-20 23:20:47,255:INFO:         deprecation: 2.1.0
2023-10-20 23:20:47,255:INFO:              xxhash: 3.4.1
2023-10-20 23:20:47,255:INFO:           wurlitzer: Not installed
2023-10-20 23:20:47,255:INFO:PyCaret optional dependencies:
2023-10-20 23:20:47,270:INFO:                shap: Not installed
2023-10-20 23:20:47,270:INFO:           interpret: Not installed
2023-10-20 23:20:47,270:INFO:                umap: Not installed
2023-10-20 23:20:47,271:INFO:     ydata_profiling: Not installed
2023-10-20 23:20:47,271:INFO:  explainerdashboard: Not installed
2023-10-20 23:20:47,271:INFO:             autoviz: Not installed
2023-10-20 23:20:47,271:INFO:           fairlearn: Not installed
2023-10-20 23:20:47,271:INFO:          deepchecks: Not installed
2023-10-20 23:20:47,271:INFO:             xgboost: Not installed
2023-10-20 23:20:47,271:INFO:            catboost: 1.2.2
2023-10-20 23:20:47,271:INFO:              kmodes: Not installed
2023-10-20 23:20:47,271:INFO:             mlxtend: Not installed
2023-10-20 23:20:47,271:INFO:       statsforecast: Not installed
2023-10-20 23:20:47,271:INFO:        tune_sklearn: Not installed
2023-10-20 23:20:47,271:INFO:                 ray: Not installed
2023-10-20 23:20:47,271:INFO:            hyperopt: Not installed
2023-10-20 23:20:47,271:INFO:              optuna: Not installed
2023-10-20 23:20:47,271:INFO:               skopt: Not installed
2023-10-20 23:20:47,271:INFO:              mlflow: 2.7.1
2023-10-20 23:20:47,271:INFO:              gradio: Not installed
2023-10-20 23:20:47,271:INFO:             fastapi: Not installed
2023-10-20 23:20:47,271:INFO:             uvicorn: Not installed
2023-10-20 23:20:47,271:INFO:              m2cgen: Not installed
2023-10-20 23:20:47,271:INFO:           evidently: Not installed
2023-10-20 23:20:47,272:INFO:               fugue: Not installed
2023-10-20 23:20:47,272:INFO:           streamlit: Not installed
2023-10-20 23:20:47,272:INFO:             prophet: Not installed
2023-10-20 23:20:47,272:INFO:None
2023-10-20 23:20:47,272:INFO:Set up data.
2023-10-20 23:20:47,303:INFO:Set up folding strategy.
2023-10-20 23:20:47,303:INFO:Set up train/test split.
2023-10-20 23:20:47,324:INFO:Set up index.
2023-10-20 23:20:47,324:INFO:Assigning column types.
2023-10-20 23:20:47,355:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-20 23:20:47,355:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,357:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,369:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,461:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,515:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,517:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:20:47,517:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:20:47,518:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,520:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,520:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,605:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,653:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,653:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:20:47,653:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:20:47,653:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-20 23:20:47,668:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,668:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,759:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,818:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,819:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:20:47,819:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:20:47,819:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,833:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,921:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,970:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,970:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:20:47,970:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:20:47,970:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-20 23:20:47,990:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-20 23:20:48,067:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:20:48,133:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:20:48,133:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:20:48,134:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:20:48,145:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-20 23:20:48,217:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:20:48,267:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:20:48,267:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:20:48,267:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:20:48,267:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-20 23:20:48,371:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:20:48,422:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:20:48,422:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:20:48,422:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:20:48,525:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:20:48,585:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:20:48,586:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:20:48,586:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:20:48,587:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-20 23:20:48,688:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:20:48,744:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:20:48,744:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:20:48,841:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:20:48,900:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:20:48,900:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:20:48,901:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-20 23:20:49,053:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:20:49,053:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:20:49,203:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:20:49,203:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:20:49,219:INFO:Preparing preprocessing pipeline...
2023-10-20 23:20:49,219:INFO:Set up simple imputation.
2023-10-20 23:20:49,219:INFO:Set up column name cleaning.
2023-10-20 23:20:49,286:INFO:Finished creating preprocessing pipeline.
2023-10-20 23:20:49,286:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-20 23:20:49,286:INFO:Creating final display dataframe.
2023-10-20 23:20:49,501:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (34061, 39)
4        Transformed data shape   (34061, 39)
5   Transformed train set shape   (23842, 39)
6    Transformed test set shape   (10219, 39)
7              Numeric features            38
8      Rows with missing values         23.1%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_A
19                          USI          2be0
2023-10-20 23:20:49,668:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:20:49,669:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:20:49,824:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:20:49,824:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:20:49,824:INFO:Logging experiment in loggers
2023-10-20 23:20:50,167:INFO:SubProcess save_model() called ==================================
2023-10-20 23:20:50,167:INFO:Initializing save_model()
2023-10-20 23:20:50,167:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmp4rp_n54e\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-20 23:20:50,167:INFO:Adding model into prep_pipe
2023-10-20 23:20:50,167:WARNING:Only Model saved as it was a pipeline.
2023-10-20 23:20:50,183:INFO:C:\Users\thoma\AppData\Local\Temp\tmp4rp_n54e\Transformation Pipeline.pkl saved in current working directory
2023-10-20 23:20:50,183:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-20 23:20:50,183:INFO:save_model() successfully completed......................................
2023-10-20 23:20:50,283:INFO:SubProcess save_model() end ==================================
2023-10-20 23:20:50,381:INFO:setup() successfully completed in 2.64s...............
2023-10-20 23:20:50,381:INFO:Initializing compare_models()
2023-10-20 23:20:50,381:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, 'include': None, 'exclude': ['ransac'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=['ransac'])
2023-10-20 23:20:50,381:INFO:Checking exceptions
2023-10-20 23:20:50,397:INFO:Preparing display monitor
2023-10-20 23:20:50,397:INFO:Initializing Linear Regression
2023-10-20 23:20:50,397:INFO:Total runtime is 0.0 minutes
2023-10-20 23:20:50,397:INFO:SubProcess create_model() called ==================================
2023-10-20 23:20:50,397:INFO:Initializing create_model()
2023-10-20 23:20:50,397:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:20:50,397:INFO:Checking exceptions
2023-10-20 23:20:50,397:INFO:Importing libraries
2023-10-20 23:20:50,397:INFO:Copying training dataset
2023-10-20 23:20:50,431:INFO:Defining folds
2023-10-20 23:20:50,433:INFO:Declaring metric variables
2023-10-20 23:20:50,433:INFO:Importing untrained model
2023-10-20 23:20:50,433:INFO:Linear Regression Imported successfully
2023-10-20 23:20:50,434:INFO:Starting cross validation
2023-10-20 23:20:50,437:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:20:57,263:INFO:Calculating mean and std
2023-10-20 23:20:57,266:INFO:Creating metrics dataframe
2023-10-20 23:20:57,266:INFO:Uploading results into container
2023-10-20 23:20:57,266:INFO:Uploading model into container now
2023-10-20 23:20:57,266:INFO:_master_model_container: 1
2023-10-20 23:20:57,266:INFO:_display_container: 2
2023-10-20 23:20:57,266:INFO:LinearRegression(n_jobs=-1)
2023-10-20 23:20:57,266:INFO:create_model() successfully completed......................................
2023-10-20 23:20:57,391:INFO:SubProcess create_model() end ==================================
2023-10-20 23:20:57,391:INFO:Creating metrics dataframe
2023-10-20 23:20:57,391:INFO:Initializing Lasso Regression
2023-10-20 23:20:57,391:INFO:Total runtime is 0.11657266219456991 minutes
2023-10-20 23:20:57,391:INFO:SubProcess create_model() called ==================================
2023-10-20 23:20:57,391:INFO:Initializing create_model()
2023-10-20 23:20:57,391:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:20:57,391:INFO:Checking exceptions
2023-10-20 23:20:57,407:INFO:Importing libraries
2023-10-20 23:20:57,407:INFO:Copying training dataset
2023-10-20 23:20:57,430:INFO:Defining folds
2023-10-20 23:20:57,430:INFO:Declaring metric variables
2023-10-20 23:20:57,430:INFO:Importing untrained model
2023-10-20 23:20:57,430:INFO:Lasso Regression Imported successfully
2023-10-20 23:20:57,430:INFO:Starting cross validation
2023-10-20 23:20:57,430:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:20:58,289:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.464e+09, tolerance: 2.904e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:20:58,304:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.457e+09, tolerance: 2.881e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:20:58,336:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.410e+09, tolerance: 2.856e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:20:58,352:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.470e+09, tolerance: 2.933e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:02,475:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.448e+09, tolerance: 2.871e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:02,551:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.427e+09, tolerance: 2.896e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:02,558:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.463e+09, tolerance: 2.927e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:02,573:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.450e+09, tolerance: 2.898e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:02,573:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.456e+09, tolerance: 2.898e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:02,656:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.460e+09, tolerance: 2.900e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:02,804:INFO:Calculating mean and std
2023-10-20 23:21:02,805:INFO:Creating metrics dataframe
2023-10-20 23:21:02,805:INFO:Uploading results into container
2023-10-20 23:21:02,805:INFO:Uploading model into container now
2023-10-20 23:21:02,805:INFO:_master_model_container: 2
2023-10-20 23:21:02,805:INFO:_display_container: 2
2023-10-20 23:21:02,805:INFO:Lasso(random_state=123)
2023-10-20 23:21:02,805:INFO:create_model() successfully completed......................................
2023-10-20 23:21:02,922:INFO:SubProcess create_model() end ==================================
2023-10-20 23:21:02,922:INFO:Creating metrics dataframe
2023-10-20 23:21:02,922:INFO:Initializing Ridge Regression
2023-10-20 23:21:02,922:INFO:Total runtime is 0.20875295797983806 minutes
2023-10-20 23:21:02,922:INFO:SubProcess create_model() called ==================================
2023-10-20 23:21:02,922:INFO:Initializing create_model()
2023-10-20 23:21:02,922:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:21:02,922:INFO:Checking exceptions
2023-10-20 23:21:02,922:INFO:Importing libraries
2023-10-20 23:21:02,922:INFO:Copying training dataset
2023-10-20 23:21:02,955:INFO:Defining folds
2023-10-20 23:21:02,955:INFO:Declaring metric variables
2023-10-20 23:21:02,958:INFO:Importing untrained model
2023-10-20 23:21:02,958:INFO:Ridge Regression Imported successfully
2023-10-20 23:21:02,958:INFO:Starting cross validation
2023-10-20 23:21:02,958:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:21:03,095:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.09042e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:21:03,095:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.08204e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:21:03,096:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.07861e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:21:03,103:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.06296e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:21:03,106:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.05293e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:21:03,122:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.07372e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:21:03,122:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.06625e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:21:03,139:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.06293e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:21:03,156:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.1254e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:21:03,162:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.05971e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:21:03,294:INFO:Calculating mean and std
2023-10-20 23:21:03,296:INFO:Creating metrics dataframe
2023-10-20 23:21:03,300:INFO:Uploading results into container
2023-10-20 23:21:03,301:INFO:Uploading model into container now
2023-10-20 23:21:03,301:INFO:_master_model_container: 3
2023-10-20 23:21:03,302:INFO:_display_container: 2
2023-10-20 23:21:03,302:INFO:Ridge(random_state=123)
2023-10-20 23:21:03,302:INFO:create_model() successfully completed......................................
2023-10-20 23:21:03,402:INFO:SubProcess create_model() end ==================================
2023-10-20 23:21:03,402:INFO:Creating metrics dataframe
2023-10-20 23:21:03,405:INFO:Initializing Elastic Net
2023-10-20 23:21:03,405:INFO:Total runtime is 0.21679709752400717 minutes
2023-10-20 23:21:03,405:INFO:SubProcess create_model() called ==================================
2023-10-20 23:21:03,405:INFO:Initializing create_model()
2023-10-20 23:21:03,405:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:21:03,405:INFO:Checking exceptions
2023-10-20 23:21:03,405:INFO:Importing libraries
2023-10-20 23:21:03,405:INFO:Copying training dataset
2023-10-20 23:21:03,426:INFO:Defining folds
2023-10-20 23:21:03,426:INFO:Declaring metric variables
2023-10-20 23:21:03,426:INFO:Importing untrained model
2023-10-20 23:21:03,426:INFO:Elastic Net Imported successfully
2023-10-20 23:21:03,426:INFO:Starting cross validation
2023-10-20 23:21:03,426:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:21:04,795:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.468e+09, tolerance: 2.871e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:04,795:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.476e+09, tolerance: 2.898e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:04,810:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.448e+09, tolerance: 2.896e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:04,827:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.481e+09, tolerance: 2.900e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:04,880:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.482e+09, tolerance: 2.927e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:04,891:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.470e+09, tolerance: 2.898e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:04,891:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.484e+09, tolerance: 2.904e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:04,907:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.477e+09, tolerance: 2.881e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:04,907:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.431e+09, tolerance: 2.856e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:04,922:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.490e+09, tolerance: 2.933e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:05,068:INFO:Calculating mean and std
2023-10-20 23:21:05,070:INFO:Creating metrics dataframe
2023-10-20 23:21:05,074:INFO:Uploading results into container
2023-10-20 23:21:05,074:INFO:Uploading model into container now
2023-10-20 23:21:05,074:INFO:_master_model_container: 4
2023-10-20 23:21:05,074:INFO:_display_container: 2
2023-10-20 23:21:05,074:INFO:ElasticNet(random_state=123)
2023-10-20 23:21:05,074:INFO:create_model() successfully completed......................................
2023-10-20 23:21:05,168:INFO:SubProcess create_model() end ==================================
2023-10-20 23:21:05,168:INFO:Creating metrics dataframe
2023-10-20 23:21:05,168:INFO:Initializing Least Angle Regression
2023-10-20 23:21:05,168:INFO:Total runtime is 0.24618028004964193 minutes
2023-10-20 23:21:05,168:INFO:SubProcess create_model() called ==================================
2023-10-20 23:21:05,168:INFO:Initializing create_model()
2023-10-20 23:21:05,168:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:21:05,168:INFO:Checking exceptions
2023-10-20 23:21:05,168:INFO:Importing libraries
2023-10-20 23:21:05,168:INFO:Copying training dataset
2023-10-20 23:21:05,192:INFO:Defining folds
2023-10-20 23:21:05,192:INFO:Declaring metric variables
2023-10-20 23:21:05,192:INFO:Importing untrained model
2023-10-20 23:21:05,192:INFO:Least Angle Regression Imported successfully
2023-10-20 23:21:05,192:INFO:Starting cross validation
2023-10-20 23:21:05,207:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:21:05,538:INFO:Calculating mean and std
2023-10-20 23:21:05,538:INFO:Creating metrics dataframe
2023-10-20 23:21:05,538:INFO:Uploading results into container
2023-10-20 23:21:05,538:INFO:Uploading model into container now
2023-10-20 23:21:05,538:INFO:_master_model_container: 5
2023-10-20 23:21:05,538:INFO:_display_container: 2
2023-10-20 23:21:05,538:INFO:Lars(random_state=123)
2023-10-20 23:21:05,538:INFO:create_model() successfully completed......................................
2023-10-20 23:21:05,655:INFO:SubProcess create_model() end ==================================
2023-10-20 23:21:05,661:INFO:Creating metrics dataframe
2023-10-20 23:21:05,661:INFO:Initializing Lasso Least Angle Regression
2023-10-20 23:21:05,661:INFO:Total runtime is 0.25440373420715334 minutes
2023-10-20 23:21:05,661:INFO:SubProcess create_model() called ==================================
2023-10-20 23:21:05,661:INFO:Initializing create_model()
2023-10-20 23:21:05,661:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:21:05,661:INFO:Checking exceptions
2023-10-20 23:21:05,661:INFO:Importing libraries
2023-10-20 23:21:05,661:INFO:Copying training dataset
2023-10-20 23:21:05,690:INFO:Defining folds
2023-10-20 23:21:05,690:INFO:Declaring metric variables
2023-10-20 23:21:05,690:INFO:Importing untrained model
2023-10-20 23:21:05,690:INFO:Lasso Least Angle Regression Imported successfully
2023-10-20 23:21:05,690:INFO:Starting cross validation
2023-10-20 23:21:05,690:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:21:05,833:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=1.588e+02, previous alpha=1.437e+02, with an active set of 14 regressors.
  warnings.warn(

2023-10-20 23:21:05,833:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 26 iterations, alpha=3.480e+01, previous alpha=3.271e+01, with an active set of 17 regressors.
  warnings.warn(

2023-10-20 23:21:05,848:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 26 iterations, alpha=3.393e+01, previous alpha=3.161e+01, with an active set of 17 regressors.
  warnings.warn(

2023-10-20 23:21:05,864:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 35 iterations, alpha=8.305e+00, previous alpha=6.087e+00, with an active set of 26 regressors.
  warnings.warn(

2023-10-20 23:21:05,880:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 29 iterations, alpha=1.570e+01, previous alpha=1.483e+01, with an active set of 20 regressors.
  warnings.warn(

2023-10-20 23:21:05,880:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 31 iterations, alpha=2.233e+01, previous alpha=2.086e+01, with an active set of 18 regressors.
  warnings.warn(

2023-10-20 23:21:05,895:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 26 iterations, alpha=3.158e+01, previous alpha=2.937e+01, with an active set of 17 regressors.
  warnings.warn(

2023-10-20 23:21:05,895:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 32 iterations, alpha=1.675e+01, previous alpha=1.367e+01, with an active set of 23 regressors.
  warnings.warn(

2023-10-20 23:21:05,911:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 31 iterations, alpha=7.665e+00, previous alpha=7.128e+00, with an active set of 22 regressors.
  warnings.warn(

2023-10-20 23:21:06,041:INFO:Calculating mean and std
2023-10-20 23:21:06,041:INFO:Creating metrics dataframe
2023-10-20 23:21:06,041:INFO:Uploading results into container
2023-10-20 23:21:06,041:INFO:Uploading model into container now
2023-10-20 23:21:06,041:INFO:_master_model_container: 6
2023-10-20 23:21:06,041:INFO:_display_container: 2
2023-10-20 23:21:06,041:INFO:LassoLars(random_state=123)
2023-10-20 23:21:06,041:INFO:create_model() successfully completed......................................
2023-10-20 23:21:06,139:INFO:SubProcess create_model() end ==================================
2023-10-20 23:21:06,139:INFO:Creating metrics dataframe
2023-10-20 23:21:06,139:INFO:Initializing Orthogonal Matching Pursuit
2023-10-20 23:21:06,139:INFO:Total runtime is 0.26237805287043253 minutes
2023-10-20 23:21:06,139:INFO:SubProcess create_model() called ==================================
2023-10-20 23:21:06,139:INFO:Initializing create_model()
2023-10-20 23:21:06,139:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:21:06,139:INFO:Checking exceptions
2023-10-20 23:21:06,139:INFO:Importing libraries
2023-10-20 23:21:06,139:INFO:Copying training dataset
2023-10-20 23:21:06,171:INFO:Defining folds
2023-10-20 23:21:06,171:INFO:Declaring metric variables
2023-10-20 23:21:06,171:INFO:Importing untrained model
2023-10-20 23:21:06,171:INFO:Orthogonal Matching Pursuit Imported successfully
2023-10-20 23:21:06,171:INFO:Starting cross validation
2023-10-20 23:21:06,171:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:21:06,467:INFO:Calculating mean and std
2023-10-20 23:21:06,469:INFO:Creating metrics dataframe
2023-10-20 23:21:06,473:INFO:Uploading results into container
2023-10-20 23:21:06,473:INFO:Uploading model into container now
2023-10-20 23:21:06,473:INFO:_master_model_container: 7
2023-10-20 23:21:06,473:INFO:_display_container: 2
2023-10-20 23:21:06,473:INFO:OrthogonalMatchingPursuit()
2023-10-20 23:21:06,473:INFO:create_model() successfully completed......................................
2023-10-20 23:21:06,566:INFO:SubProcess create_model() end ==================================
2023-10-20 23:21:06,566:INFO:Creating metrics dataframe
2023-10-20 23:21:06,573:INFO:Initializing Bayesian Ridge
2023-10-20 23:21:06,573:INFO:Total runtime is 0.26961002747217816 minutes
2023-10-20 23:21:06,573:INFO:SubProcess create_model() called ==================================
2023-10-20 23:21:06,573:INFO:Initializing create_model()
2023-10-20 23:21:06,573:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:21:06,573:INFO:Checking exceptions
2023-10-20 23:21:06,573:INFO:Importing libraries
2023-10-20 23:21:06,573:INFO:Copying training dataset
2023-10-20 23:21:06,589:INFO:Defining folds
2023-10-20 23:21:06,589:INFO:Declaring metric variables
2023-10-20 23:21:06,589:INFO:Importing untrained model
2023-10-20 23:21:06,589:INFO:Bayesian Ridge Imported successfully
2023-10-20 23:21:06,589:INFO:Starting cross validation
2023-10-20 23:21:06,589:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:21:07,152:INFO:Calculating mean and std
2023-10-20 23:21:07,152:INFO:Creating metrics dataframe
2023-10-20 23:21:07,152:INFO:Uploading results into container
2023-10-20 23:21:07,152:INFO:Uploading model into container now
2023-10-20 23:21:07,152:INFO:_master_model_container: 8
2023-10-20 23:21:07,152:INFO:_display_container: 2
2023-10-20 23:21:07,152:INFO:BayesianRidge()
2023-10-20 23:21:07,152:INFO:create_model() successfully completed......................................
2023-10-20 23:21:07,250:INFO:SubProcess create_model() end ==================================
2023-10-20 23:21:07,250:INFO:Creating metrics dataframe
2023-10-20 23:21:07,265:INFO:Initializing Passive Aggressive Regressor
2023-10-20 23:21:07,265:INFO:Total runtime is 0.28113539616266886 minutes
2023-10-20 23:21:07,265:INFO:SubProcess create_model() called ==================================
2023-10-20 23:21:07,265:INFO:Initializing create_model()
2023-10-20 23:21:07,266:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:21:07,266:INFO:Checking exceptions
2023-10-20 23:21:07,266:INFO:Importing libraries
2023-10-20 23:21:07,266:INFO:Copying training dataset
2023-10-20 23:21:07,282:INFO:Defining folds
2023-10-20 23:21:07,282:INFO:Declaring metric variables
2023-10-20 23:21:07,282:INFO:Importing untrained model
2023-10-20 23:21:07,282:INFO:Passive Aggressive Regressor Imported successfully
2023-10-20 23:21:07,282:INFO:Starting cross validation
2023-10-20 23:21:07,282:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:21:07,717:INFO:Calculating mean and std
2023-10-20 23:21:07,717:INFO:Creating metrics dataframe
2023-10-20 23:21:07,717:INFO:Uploading results into container
2023-10-20 23:21:07,717:INFO:Uploading model into container now
2023-10-20 23:21:07,717:INFO:_master_model_container: 9
2023-10-20 23:21:07,717:INFO:_display_container: 2
2023-10-20 23:21:07,717:INFO:PassiveAggressiveRegressor(random_state=123)
2023-10-20 23:21:07,717:INFO:create_model() successfully completed......................................
2023-10-20 23:21:07,816:INFO:SubProcess create_model() end ==================================
2023-10-20 23:21:07,816:INFO:Creating metrics dataframe
2023-10-20 23:21:07,816:INFO:Initializing Huber Regressor
2023-10-20 23:21:07,816:INFO:Total runtime is 0.2903209328651428 minutes
2023-10-20 23:21:07,816:INFO:SubProcess create_model() called ==================================
2023-10-20 23:21:07,816:INFO:Initializing create_model()
2023-10-20 23:21:07,816:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:21:07,816:INFO:Checking exceptions
2023-10-20 23:21:07,816:INFO:Importing libraries
2023-10-20 23:21:07,816:INFO:Copying training dataset
2023-10-20 23:21:07,839:INFO:Defining folds
2023-10-20 23:21:07,839:INFO:Declaring metric variables
2023-10-20 23:21:07,839:INFO:Importing untrained model
2023-10-20 23:21:07,839:INFO:Huber Regressor Imported successfully
2023-10-20 23:21:07,839:INFO:Starting cross validation
2023-10-20 23:21:07,839:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:21:12,211:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:21:12,232:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:21:12,270:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:21:12,270:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:21:12,331:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:21:12,331:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:21:12,358:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:21:12,370:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:21:12,381:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:21:12,448:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:21:12,581:INFO:Calculating mean and std
2023-10-20 23:21:12,581:INFO:Creating metrics dataframe
2023-10-20 23:21:12,581:INFO:Uploading results into container
2023-10-20 23:21:12,581:INFO:Uploading model into container now
2023-10-20 23:21:12,581:INFO:_master_model_container: 10
2023-10-20 23:21:12,581:INFO:_display_container: 2
2023-10-20 23:21:12,581:INFO:HuberRegressor()
2023-10-20 23:21:12,581:INFO:create_model() successfully completed......................................
2023-10-20 23:21:12,681:INFO:SubProcess create_model() end ==================================
2023-10-20 23:21:12,681:INFO:Creating metrics dataframe
2023-10-20 23:21:12,681:INFO:Initializing K Neighbors Regressor
2023-10-20 23:21:12,681:INFO:Total runtime is 0.371399708588918 minutes
2023-10-20 23:21:12,681:INFO:SubProcess create_model() called ==================================
2023-10-20 23:21:12,681:INFO:Initializing create_model()
2023-10-20 23:21:12,681:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:21:12,681:INFO:Checking exceptions
2023-10-20 23:21:12,681:INFO:Importing libraries
2023-10-20 23:21:12,681:INFO:Copying training dataset
2023-10-20 23:21:12,714:INFO:Defining folds
2023-10-20 23:21:12,714:INFO:Declaring metric variables
2023-10-20 23:21:12,714:INFO:Importing untrained model
2023-10-20 23:21:12,714:INFO:K Neighbors Regressor Imported successfully
2023-10-20 23:21:12,714:INFO:Starting cross validation
2023-10-20 23:21:12,714:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:21:13,880:INFO:Calculating mean and std
2023-10-20 23:21:13,880:INFO:Creating metrics dataframe
2023-10-20 23:21:13,880:INFO:Uploading results into container
2023-10-20 23:21:13,880:INFO:Uploading model into container now
2023-10-20 23:21:13,880:INFO:_master_model_container: 11
2023-10-20 23:21:13,880:INFO:_display_container: 2
2023-10-20 23:21:13,880:INFO:KNeighborsRegressor(n_jobs=-1)
2023-10-20 23:21:13,880:INFO:create_model() successfully completed......................................
2023-10-20 23:21:13,996:INFO:SubProcess create_model() end ==================================
2023-10-20 23:21:13,996:INFO:Creating metrics dataframe
2023-10-20 23:21:13,996:INFO:Initializing Decision Tree Regressor
2023-10-20 23:21:14,012:INFO:Total runtime is 0.3933236400286356 minutes
2023-10-20 23:21:14,012:INFO:SubProcess create_model() called ==================================
2023-10-20 23:21:14,012:INFO:Initializing create_model()
2023-10-20 23:21:14,012:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:21:14,012:INFO:Checking exceptions
2023-10-20 23:21:14,012:INFO:Importing libraries
2023-10-20 23:21:14,012:INFO:Copying training dataset
2023-10-20 23:21:14,030:INFO:Defining folds
2023-10-20 23:21:14,030:INFO:Declaring metric variables
2023-10-20 23:21:14,030:INFO:Importing untrained model
2023-10-20 23:21:14,030:INFO:Decision Tree Regressor Imported successfully
2023-10-20 23:21:14,030:INFO:Starting cross validation
2023-10-20 23:21:14,030:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:21:15,273:INFO:Calculating mean and std
2023-10-20 23:21:15,273:INFO:Creating metrics dataframe
2023-10-20 23:21:15,279:INFO:Uploading results into container
2023-10-20 23:21:15,280:INFO:Uploading model into container now
2023-10-20 23:21:15,280:INFO:_master_model_container: 12
2023-10-20 23:21:15,280:INFO:_display_container: 2
2023-10-20 23:21:15,281:INFO:DecisionTreeRegressor(random_state=123)
2023-10-20 23:21:15,281:INFO:create_model() successfully completed......................................
2023-10-20 23:21:15,394:INFO:SubProcess create_model() end ==================================
2023-10-20 23:21:15,394:INFO:Creating metrics dataframe
2023-10-20 23:21:15,400:INFO:Initializing Random Forest Regressor
2023-10-20 23:21:15,400:INFO:Total runtime is 0.416713277498881 minutes
2023-10-20 23:21:15,400:INFO:SubProcess create_model() called ==================================
2023-10-20 23:21:15,400:INFO:Initializing create_model()
2023-10-20 23:21:15,400:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:21:15,400:INFO:Checking exceptions
2023-10-20 23:21:15,400:INFO:Importing libraries
2023-10-20 23:21:15,400:INFO:Copying training dataset
2023-10-20 23:21:15,412:INFO:Defining folds
2023-10-20 23:21:15,412:INFO:Declaring metric variables
2023-10-20 23:21:15,412:INFO:Importing untrained model
2023-10-20 23:21:15,412:INFO:Random Forest Regressor Imported successfully
2023-10-20 23:21:15,412:INFO:Starting cross validation
2023-10-20 23:21:15,428:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:22:07,988:INFO:Calculating mean and std
2023-10-20 23:22:07,988:INFO:Creating metrics dataframe
2023-10-20 23:22:07,988:INFO:Uploading results into container
2023-10-20 23:22:07,988:INFO:Uploading model into container now
2023-10-20 23:22:07,988:INFO:_master_model_container: 13
2023-10-20 23:22:07,988:INFO:_display_container: 2
2023-10-20 23:22:07,988:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-10-20 23:22:07,988:INFO:create_model() successfully completed......................................
2023-10-20 23:22:08,099:INFO:SubProcess create_model() end ==================================
2023-10-20 23:22:08,099:INFO:Creating metrics dataframe
2023-10-20 23:22:08,117:INFO:Initializing Extra Trees Regressor
2023-10-20 23:22:08,117:INFO:Total runtime is 1.295339612166087 minutes
2023-10-20 23:22:08,118:INFO:SubProcess create_model() called ==================================
2023-10-20 23:22:08,118:INFO:Initializing create_model()
2023-10-20 23:22:08,118:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:22:08,118:INFO:Checking exceptions
2023-10-20 23:22:08,118:INFO:Importing libraries
2023-10-20 23:22:08,118:INFO:Copying training dataset
2023-10-20 23:22:08,138:INFO:Defining folds
2023-10-20 23:22:08,138:INFO:Declaring metric variables
2023-10-20 23:22:08,138:INFO:Importing untrained model
2023-10-20 23:22:08,138:INFO:Extra Trees Regressor Imported successfully
2023-10-20 23:22:08,138:INFO:Starting cross validation
2023-10-20 23:22:08,138:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:22:24,238:INFO:Calculating mean and std
2023-10-20 23:22:24,238:INFO:Creating metrics dataframe
2023-10-20 23:22:24,238:INFO:Uploading results into container
2023-10-20 23:22:24,238:INFO:Uploading model into container now
2023-10-20 23:22:24,238:INFO:_master_model_container: 14
2023-10-20 23:22:24,238:INFO:_display_container: 2
2023-10-20 23:22:24,238:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-10-20 23:22:24,238:INFO:create_model() successfully completed......................................
2023-10-20 23:22:24,410:INFO:SubProcess create_model() end ==================================
2023-10-20 23:22:24,410:INFO:Creating metrics dataframe
2023-10-20 23:22:24,421:INFO:Initializing AdaBoost Regressor
2023-10-20 23:22:24,421:INFO:Total runtime is 1.5670756936073305 minutes
2023-10-20 23:22:24,421:INFO:SubProcess create_model() called ==================================
2023-10-20 23:22:24,421:INFO:Initializing create_model()
2023-10-20 23:22:24,421:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:22:24,421:INFO:Checking exceptions
2023-10-20 23:22:24,421:INFO:Importing libraries
2023-10-20 23:22:24,421:INFO:Copying training dataset
2023-10-20 23:22:24,438:INFO:Defining folds
2023-10-20 23:22:24,438:INFO:Declaring metric variables
2023-10-20 23:22:24,438:INFO:Importing untrained model
2023-10-20 23:22:24,438:INFO:AdaBoost Regressor Imported successfully
2023-10-20 23:22:24,438:INFO:Starting cross validation
2023-10-20 23:22:24,453:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:22:31,199:INFO:Calculating mean and std
2023-10-20 23:22:31,199:INFO:Creating metrics dataframe
2023-10-20 23:22:31,199:INFO:Uploading results into container
2023-10-20 23:22:31,199:INFO:Uploading model into container now
2023-10-20 23:22:31,199:INFO:_master_model_container: 15
2023-10-20 23:22:31,199:INFO:_display_container: 2
2023-10-20 23:22:31,199:INFO:AdaBoostRegressor(random_state=123)
2023-10-20 23:22:31,199:INFO:create_model() successfully completed......................................
2023-10-20 23:22:31,299:INFO:SubProcess create_model() end ==================================
2023-10-20 23:22:31,299:INFO:Creating metrics dataframe
2023-10-20 23:22:31,299:INFO:Initializing Gradient Boosting Regressor
2023-10-20 23:22:31,299:INFO:Total runtime is 1.6817017118136088 minutes
2023-10-20 23:22:31,299:INFO:SubProcess create_model() called ==================================
2023-10-20 23:22:31,299:INFO:Initializing create_model()
2023-10-20 23:22:31,299:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:22:31,299:INFO:Checking exceptions
2023-10-20 23:22:31,299:INFO:Importing libraries
2023-10-20 23:22:31,299:INFO:Copying training dataset
2023-10-20 23:22:31,333:INFO:Defining folds
2023-10-20 23:22:31,333:INFO:Declaring metric variables
2023-10-20 23:22:31,333:INFO:Importing untrained model
2023-10-20 23:22:31,333:INFO:Gradient Boosting Regressor Imported successfully
2023-10-20 23:22:31,333:INFO:Starting cross validation
2023-10-20 23:22:31,333:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:22:52,132:INFO:Calculating mean and std
2023-10-20 23:22:52,133:INFO:Creating metrics dataframe
2023-10-20 23:22:52,133:INFO:Uploading results into container
2023-10-20 23:22:52,133:INFO:Uploading model into container now
2023-10-20 23:22:52,133:INFO:_master_model_container: 16
2023-10-20 23:22:52,133:INFO:_display_container: 2
2023-10-20 23:22:52,133:INFO:GradientBoostingRegressor(random_state=123)
2023-10-20 23:22:52,133:INFO:create_model() successfully completed......................................
2023-10-20 23:22:52,232:INFO:SubProcess create_model() end ==================================
2023-10-20 23:22:52,232:INFO:Creating metrics dataframe
2023-10-20 23:22:52,232:INFO:Initializing Light Gradient Boosting Machine
2023-10-20 23:22:52,232:INFO:Total runtime is 2.0305909077326456 minutes
2023-10-20 23:22:52,232:INFO:SubProcess create_model() called ==================================
2023-10-20 23:22:52,232:INFO:Initializing create_model()
2023-10-20 23:22:52,232:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:22:52,232:INFO:Checking exceptions
2023-10-20 23:22:52,232:INFO:Importing libraries
2023-10-20 23:22:52,232:INFO:Copying training dataset
2023-10-20 23:22:52,253:INFO:Defining folds
2023-10-20 23:22:52,253:INFO:Declaring metric variables
2023-10-20 23:22:52,253:INFO:Importing untrained model
2023-10-20 23:22:52,253:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-20 23:22:52,253:INFO:Starting cross validation
2023-10-20 23:22:52,253:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:22:54,847:INFO:Calculating mean and std
2023-10-20 23:22:54,850:INFO:Creating metrics dataframe
2023-10-20 23:22:54,851:INFO:Uploading results into container
2023-10-20 23:22:54,851:INFO:Uploading model into container now
2023-10-20 23:22:54,851:INFO:_master_model_container: 17
2023-10-20 23:22:54,851:INFO:_display_container: 2
2023-10-20 23:22:54,851:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-20 23:22:54,851:INFO:create_model() successfully completed......................................
2023-10-20 23:22:54,953:INFO:SubProcess create_model() end ==================================
2023-10-20 23:22:54,953:INFO:Creating metrics dataframe
2023-10-20 23:22:54,962:INFO:Initializing CatBoost Regressor
2023-10-20 23:22:54,962:INFO:Total runtime is 2.076080063978831 minutes
2023-10-20 23:22:54,962:INFO:SubProcess create_model() called ==================================
2023-10-20 23:22:54,963:INFO:Initializing create_model()
2023-10-20 23:22:54,963:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:22:54,963:INFO:Checking exceptions
2023-10-20 23:22:54,963:INFO:Importing libraries
2023-10-20 23:22:54,963:INFO:Copying training dataset
2023-10-20 23:22:54,979:INFO:Defining folds
2023-10-20 23:22:54,979:INFO:Declaring metric variables
2023-10-20 23:22:54,979:INFO:Importing untrained model
2023-10-20 23:22:54,979:INFO:CatBoost Regressor Imported successfully
2023-10-20 23:22:54,979:INFO:Starting cross validation
2023-10-20 23:22:54,979:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:23:28,367:INFO:Calculating mean and std
2023-10-20 23:23:28,368:INFO:Creating metrics dataframe
2023-10-20 23:23:28,368:INFO:Uploading results into container
2023-10-20 23:23:28,368:INFO:Uploading model into container now
2023-10-20 23:23:28,368:INFO:_master_model_container: 18
2023-10-20 23:23:28,368:INFO:_display_container: 2
2023-10-20 23:23:28,368:INFO:<catboost.core.CatBoostRegressor object at 0x00000209E3906F40>
2023-10-20 23:23:28,368:INFO:create_model() successfully completed......................................
2023-10-20 23:23:28,485:INFO:SubProcess create_model() end ==================================
2023-10-20 23:23:28,485:INFO:Creating metrics dataframe
2023-10-20 23:23:28,502:INFO:Initializing Dummy Regressor
2023-10-20 23:23:28,502:INFO:Total runtime is 2.6350830396016436 minutes
2023-10-20 23:23:28,502:INFO:SubProcess create_model() called ==================================
2023-10-20 23:23:28,502:INFO:Initializing create_model()
2023-10-20 23:23:28,502:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:23:28,502:INFO:Checking exceptions
2023-10-20 23:23:28,502:INFO:Importing libraries
2023-10-20 23:23:28,502:INFO:Copying training dataset
2023-10-20 23:23:28,519:INFO:Defining folds
2023-10-20 23:23:28,519:INFO:Declaring metric variables
2023-10-20 23:23:28,519:INFO:Importing untrained model
2023-10-20 23:23:28,534:INFO:Dummy Regressor Imported successfully
2023-10-20 23:23:28,535:INFO:Starting cross validation
2023-10-20 23:23:28,535:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:23:28,834:INFO:Calculating mean and std
2023-10-20 23:23:28,834:INFO:Creating metrics dataframe
2023-10-20 23:23:28,834:INFO:Uploading results into container
2023-10-20 23:23:28,834:INFO:Uploading model into container now
2023-10-20 23:23:28,834:INFO:_master_model_container: 19
2023-10-20 23:23:28,834:INFO:_display_container: 2
2023-10-20 23:23:28,834:INFO:DummyRegressor()
2023-10-20 23:23:28,834:INFO:create_model() successfully completed......................................
2023-10-20 23:23:28,951:INFO:SubProcess create_model() end ==================================
2023-10-20 23:23:28,951:INFO:Creating metrics dataframe
2023-10-20 23:23:28,951:INFO:Initializing create_model()
2023-10-20 23:23:28,951:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=<catboost.core.CatBoostRegressor object at 0x00000209E3906F40>, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:23:28,951:INFO:Checking exceptions
2023-10-20 23:23:28,968:INFO:Importing libraries
2023-10-20 23:23:28,968:INFO:Copying training dataset
2023-10-20 23:23:28,985:INFO:Defining folds
2023-10-20 23:23:28,985:INFO:Declaring metric variables
2023-10-20 23:23:28,985:INFO:Importing untrained model
2023-10-20 23:23:28,985:INFO:Declaring custom model
2023-10-20 23:23:28,985:INFO:CatBoost Regressor Imported successfully
2023-10-20 23:23:28,985:INFO:Cross validation set to False
2023-10-20 23:23:28,985:INFO:Fitting Model
2023-10-20 23:23:35,896:INFO:<catboost.core.CatBoostRegressor object at 0x00000209E3BDBC70>
2023-10-20 23:23:35,896:INFO:create_model() successfully completed......................................
2023-10-20 23:23:35,996:INFO:Creating Dashboard logs
2023-10-20 23:23:35,996:INFO:Model: CatBoost Regressor
2023-10-20 23:23:36,062:INFO:Logged params: {'nan_mode': 'Min', 'eval_metric': 'RMSE', 'iterations': 1000, 'sampling_frequency': 'PerTree', 'leaf_estimation_method': 'Newton', 'random_score_type': 'NormalWithModelSizeDecrease', 'grow_policy': 'SymmetricTree', 'penalties_coefficient': 1, 'boosting_type': 'Plain', 'model_shrink_mode': 'Constant', 'feature_border_type': 'GreedyLogSum', 'bayesian_matrix_reg': 0.10000000149011612, 'eval_fraction': 0, 'force_unit_auto_pair_weights': False, 'l2_leaf_reg': 3, 'random_strength': 1, 'rsm': 1, 'boost_from_average': True, 'model_size_reg': 0.5, 'pool_metainfo_options': {'tags': {}}, 'subsample': 0.800000011920929, 'use_best_model': False, 'random_seed': 123, 'depth': 6, 'posterior_sampling': False, 'border_count': 254, 'classes_count': 0, 'auto_class_weights': 'None', 'sparse_features_conflict_fraction': 0, 'leaf_estimation_backtracking': 'AnyImprovement', 'best_model_min_trees': 1, 'model_shrink_rate': 0, 'min_data_in_leaf': 1, 'loss_function': 'RMSE', 'learning_rate': 0.06757699698209763, 'score_function': 'Cosine', 'task_type': 'CPU', 'leaf_estimation_iterations': 1, 'bootstrap_type': 'MVS', 'max_leaves': 64}
2023-10-20 23:23:36,362:INFO:Initializing predict_model()
2023-10-20 23:23:36,362:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=<catboost.core.CatBoostRegressor object at 0x00000209E3BDBC70>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209E3CC7820>)
2023-10-20 23:23:36,362:INFO:Checking exceptions
2023-10-20 23:23:36,362:INFO:Preloading libraries
2023-10-20 23:23:36,595:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\_distutils_hack\__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2023-10-20 23:23:36,779:INFO:Creating Dashboard logs
2023-10-20 23:23:36,779:INFO:Model: Light Gradient Boosting Machine
2023-10-20 23:23:36,851:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-20 23:23:37,194:INFO:Creating Dashboard logs
2023-10-20 23:23:37,194:INFO:Model: Extra Trees Regressor
2023-10-20 23:23:37,244:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-20 23:23:37,582:INFO:Creating Dashboard logs
2023-10-20 23:23:37,582:INFO:Model: Random Forest Regressor
2023-10-20 23:23:37,645:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-20 23:23:37,960:INFO:Creating Dashboard logs
2023-10-20 23:23:37,960:INFO:Model: Gradient Boosting Regressor
2023-10-20 23:23:38,027:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 123, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-10-20 23:23:38,377:INFO:Creating Dashboard logs
2023-10-20 23:23:38,377:INFO:Model: Ridge Regression
2023-10-20 23:23:38,448:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 123, 'solver': 'auto', 'tol': 0.0001}
2023-10-20 23:23:38,727:INFO:Creating Dashboard logs
2023-10-20 23:23:38,727:INFO:Model: Lasso Regression
2023-10-20 23:23:38,793:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 123, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-10-20 23:23:39,084:INFO:Creating Dashboard logs
2023-10-20 23:23:39,084:INFO:Model: Elastic Net
2023-10-20 23:23:39,143:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 123, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-10-20 23:23:39,426:INFO:Creating Dashboard logs
2023-10-20 23:23:39,426:INFO:Model: Lasso Least Angle Regression
2023-10-20 23:23:39,477:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'max_iter': 500, 'normalize': 'deprecated', 'positive': False, 'precompute': 'auto', 'random_state': 123, 'verbose': False}
2023-10-20 23:23:39,776:INFO:Creating Dashboard logs
2023-10-20 23:23:39,776:INFO:Model: Linear Regression
2023-10-20 23:23:39,842:INFO:Logged params: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'positive': False}
2023-10-20 23:23:40,125:INFO:Creating Dashboard logs
2023-10-20 23:23:40,125:INFO:Model: AdaBoost Regressor
2023-10-20 23:23:40,192:INFO:Logged params: {'base_estimator': 'deprecated', 'estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': 123}
2023-10-20 23:23:40,492:INFO:Creating Dashboard logs
2023-10-20 23:23:40,492:INFO:Model: Orthogonal Matching Pursuit
2023-10-20 23:23:40,542:INFO:Logged params: {'fit_intercept': True, 'n_nonzero_coefs': None, 'normalize': 'deprecated', 'precompute': 'auto', 'tol': None}
2023-10-20 23:23:40,809:INFO:Creating Dashboard logs
2023-10-20 23:23:40,809:INFO:Model: Huber Regressor
2023-10-20 23:23:40,875:INFO:Logged params: {'alpha': 0.0001, 'epsilon': 1.35, 'fit_intercept': True, 'max_iter': 100, 'tol': 1e-05, 'warm_start': False}
2023-10-20 23:23:41,158:INFO:Creating Dashboard logs
2023-10-20 23:23:41,158:INFO:Model: Decision Tree Regressor
2023-10-20 23:23:41,226:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 123, 'splitter': 'best'}
2023-10-20 23:23:41,507:INFO:Creating Dashboard logs
2023-10-20 23:23:41,507:INFO:Model: K Neighbors Regressor
2023-10-20 23:23:41,574:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2023-10-20 23:23:41,858:INFO:Creating Dashboard logs
2023-10-20 23:23:41,858:INFO:Model: Dummy Regressor
2023-10-20 23:23:41,924:INFO:Logged params: {'constant': None, 'quantile': None, 'strategy': 'mean'}
2023-10-20 23:23:42,224:INFO:Creating Dashboard logs
2023-10-20 23:23:42,224:INFO:Model: Passive Aggressive Regressor
2023-10-20 23:23:42,274:INFO:Logged params: {'C': 1.0, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'fit_intercept': True, 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 5, 'random_state': 123, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-10-20 23:23:42,557:INFO:Creating Dashboard logs
2023-10-20 23:23:42,557:INFO:Model: Bayesian Ridge
2023-10-20 23:23:42,623:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'tol': 0.001, 'verbose': False}
2023-10-20 23:23:42,906:INFO:Creating Dashboard logs
2023-10-20 23:23:42,906:INFO:Model: Least Angle Regression
2023-10-20 23:23:42,973:INFO:Logged params: {'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'n_nonzero_coefs': 500, 'normalize': 'deprecated', 'precompute': 'auto', 'random_state': 123, 'verbose': False}
2023-10-20 23:23:43,272:INFO:_master_model_container: 19
2023-10-20 23:23:43,272:INFO:_display_container: 2
2023-10-20 23:23:43,273:INFO:<catboost.core.CatBoostRegressor object at 0x00000209E3BDBC70>
2023-10-20 23:23:43,273:INFO:compare_models() successfully completed......................................
2023-10-20 23:29:24,017:INFO:PyCaret RegressionExperiment
2023-10-20 23:29:24,019:INFO:Logging name: exp_A
2023-10-20 23:29:24,019:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-20 23:29:24,020:INFO:version 3.1.0
2023-10-20 23:29:24,020:INFO:Initializing setup()
2023-10-20 23:29:24,020:INFO:self.USI: f486
2023-10-20 23:29:24,020:INFO:self._variable_keys: {'transform_target_param', 'exp_name_log', 'y_train', 'logging_param', 'n_jobs_param', 'X_train', 'target_param', 'USI', 'gpu_n_jobs_param', 'fold_groups_param', '_ml_usecase', 'seed', 'fold_generator', 'idx', 'html_param', 'log_plots_param', 'y', 'gpu_param', 'X_test', 'memory', 'y_test', 'data', 'X', 'exp_id', '_available_plots', 'fold_shuffle_param', 'pipeline'}
2023-10-20 23:29:24,020:INFO:Checking environment
2023-10-20 23:29:24,021:INFO:python_version: 3.8.18
2023-10-20 23:29:24,021:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-20 23:29:24,021:INFO:machine: AMD64
2023-10-20 23:29:24,022:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-20 23:29:24,022:INFO:Memory: svmem(total=16505954304, available=2596114432, percent=84.3, used=13909839872, free=2596114432)
2023-10-20 23:29:24,022:INFO:Physical Core: 8
2023-10-20 23:29:24,022:INFO:Logical Core: 16
2023-10-20 23:29:24,023:INFO:Checking libraries
2023-10-20 23:29:24,023:INFO:System:
2023-10-20 23:29:24,023:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-20 23:29:24,023:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-20 23:29:24,023:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-20 23:29:24,023:INFO:PyCaret required dependencies:
2023-10-20 23:29:24,023:INFO:                 pip: 23.3
2023-10-20 23:29:24,023:INFO:          setuptools: 68.0.0
2023-10-20 23:29:24,023:INFO:             pycaret: 3.1.0
2023-10-20 23:29:24,023:INFO:             IPython: 8.12.0
2023-10-20 23:29:24,023:INFO:          ipywidgets: 8.1.1
2023-10-20 23:29:24,023:INFO:                tqdm: 4.66.1
2023-10-20 23:29:24,024:INFO:               numpy: 1.23.5
2023-10-20 23:29:24,024:INFO:              pandas: 1.5.3
2023-10-20 23:29:24,024:INFO:              jinja2: 3.1.2
2023-10-20 23:29:24,024:INFO:               scipy: 1.10.1
2023-10-20 23:29:24,024:INFO:              joblib: 1.3.2
2023-10-20 23:29:24,024:INFO:             sklearn: 1.2.2
2023-10-20 23:29:24,024:INFO:                pyod: 1.1.0
2023-10-20 23:29:24,024:INFO:            imblearn: 0.11.0
2023-10-20 23:29:24,024:INFO:   category_encoders: 2.6.2
2023-10-20 23:29:24,024:INFO:            lightgbm: 4.1.0
2023-10-20 23:29:24,024:INFO:               numba: 0.58.1
2023-10-20 23:29:24,024:INFO:            requests: 2.31.0
2023-10-20 23:29:24,024:INFO:          matplotlib: 3.7.3
2023-10-20 23:29:24,024:INFO:          scikitplot: 0.3.7
2023-10-20 23:29:24,024:INFO:         yellowbrick: 1.5
2023-10-20 23:29:24,024:INFO:              plotly: 5.17.0
2023-10-20 23:29:24,024:INFO:    plotly-resampler: Not installed
2023-10-20 23:29:24,025:INFO:             kaleido: 0.2.1
2023-10-20 23:29:24,025:INFO:           schemdraw: 0.15
2023-10-20 23:29:24,025:INFO:         statsmodels: 0.14.0
2023-10-20 23:29:24,025:INFO:              sktime: 0.21.1
2023-10-20 23:29:24,025:INFO:               tbats: 1.1.3
2023-10-20 23:29:24,025:INFO:            pmdarima: 2.0.3
2023-10-20 23:29:24,025:INFO:              psutil: 5.9.0
2023-10-20 23:29:24,025:INFO:          markupsafe: 2.1.3
2023-10-20 23:29:24,025:INFO:             pickle5: Not installed
2023-10-20 23:29:24,025:INFO:         cloudpickle: 2.2.1
2023-10-20 23:29:24,025:INFO:         deprecation: 2.1.0
2023-10-20 23:29:24,025:INFO:              xxhash: 3.4.1
2023-10-20 23:29:24,025:INFO:           wurlitzer: Not installed
2023-10-20 23:29:24,025:INFO:PyCaret optional dependencies:
2023-10-20 23:29:24,025:INFO:                shap: Not installed
2023-10-20 23:29:24,026:INFO:           interpret: Not installed
2023-10-20 23:29:24,026:INFO:                umap: Not installed
2023-10-20 23:29:24,026:INFO:     ydata_profiling: Not installed
2023-10-20 23:29:24,026:INFO:  explainerdashboard: Not installed
2023-10-20 23:29:24,026:INFO:             autoviz: Not installed
2023-10-20 23:29:24,026:INFO:           fairlearn: Not installed
2023-10-20 23:29:24,026:INFO:          deepchecks: Not installed
2023-10-20 23:29:24,026:INFO:             xgboost: Not installed
2023-10-20 23:29:24,026:INFO:            catboost: 1.2.2
2023-10-20 23:29:24,026:INFO:              kmodes: Not installed
2023-10-20 23:29:24,026:INFO:             mlxtend: Not installed
2023-10-20 23:29:24,026:INFO:       statsforecast: Not installed
2023-10-20 23:29:24,026:INFO:        tune_sklearn: Not installed
2023-10-20 23:29:24,026:INFO:                 ray: Not installed
2023-10-20 23:29:24,026:INFO:            hyperopt: Not installed
2023-10-20 23:29:24,026:INFO:              optuna: Not installed
2023-10-20 23:29:24,027:INFO:               skopt: Not installed
2023-10-20 23:29:24,027:INFO:              mlflow: 2.7.1
2023-10-20 23:29:24,027:INFO:              gradio: Not installed
2023-10-20 23:29:24,027:INFO:             fastapi: Not installed
2023-10-20 23:29:24,027:INFO:             uvicorn: Not installed
2023-10-20 23:29:24,027:INFO:              m2cgen: Not installed
2023-10-20 23:29:24,027:INFO:           evidently: Not installed
2023-10-20 23:29:24,027:INFO:               fugue: Not installed
2023-10-20 23:29:24,027:INFO:           streamlit: Not installed
2023-10-20 23:29:24,027:INFO:             prophet: Not installed
2023-10-20 23:29:24,027:INFO:None
2023-10-20 23:29:24,027:INFO:Set up data.
2023-10-20 23:29:24,057:INFO:Set up folding strategy.
2023-10-20 23:29:24,057:INFO:Set up train/test split.
2023-10-20 23:29:24,081:INFO:Set up index.
2023-10-20 23:29:24,082:INFO:Assigning column types.
2023-10-20 23:29:24,100:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-20 23:29:24,100:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,107:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,107:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,190:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,241:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,242:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:29:24,242:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:29:24,243:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,248:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,253:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,325:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,383:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,385:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:29:24,385:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:29:24,385:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-20 23:29:24,391:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,396:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,475:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,529:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,529:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:29:24,529:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:29:24,535:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,541:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,626:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,676:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,677:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:29:24,677:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:29:24,678:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-20 23:29:24,680:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,772:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,824:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,824:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:29:24,824:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:29:24,824:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,919:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,962:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,962:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:29:24,962:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:29:24,962:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-20 23:29:25,079:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:29:25,126:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:29:25,126:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:29:25,126:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:29:25,213:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:29:25,257:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:29:25,257:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:29:25,257:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:29:25,257:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-20 23:29:25,341:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:29:25,400:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:29:25,400:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:29:25,474:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:29:25,527:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:29:25,527:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:29:25,527:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-20 23:29:25,656:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:29:25,656:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:29:25,806:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:29:25,806:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:29:25,806:INFO:Preparing preprocessing pipeline...
2023-10-20 23:29:25,806:INFO:Set up simple imputation.
2023-10-20 23:29:25,806:INFO:Set up column name cleaning.
2023-10-20 23:29:25,859:INFO:Finished creating preprocessing pipeline.
2023-10-20 23:29:25,875:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-20 23:29:25,875:INFO:Creating final display dataframe.
2023-10-20 23:29:26,062:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (34061, 39)
4        Transformed data shape   (34061, 39)
5   Transformed train set shape   (23842, 39)
6    Transformed test set shape   (10219, 39)
7              Numeric features            38
8      Rows with missing values         23.1%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_A
19                          USI          f486
2023-10-20 23:29:26,191:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:29:26,191:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:29:26,340:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:29:26,340:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:29:26,341:INFO:Logging experiment in loggers
2023-10-20 23:29:26,442:INFO:SubProcess save_model() called ==================================
2023-10-20 23:29:26,445:INFO:Initializing save_model()
2023-10-20 23:29:26,445:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmplzngiykf\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-20 23:29:26,445:INFO:Adding model into prep_pipe
2023-10-20 23:29:26,445:WARNING:Only Model saved as it was a pipeline.
2023-10-20 23:29:26,445:INFO:C:\Users\thoma\AppData\Local\Temp\tmplzngiykf\Transformation Pipeline.pkl saved in current working directory
2023-10-20 23:29:26,460:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-20 23:29:26,460:INFO:save_model() successfully completed......................................
2023-10-20 23:29:26,572:INFO:SubProcess save_model() end ==================================
2023-10-20 23:29:26,612:INFO:setup() successfully completed in 2.33s...............
2023-10-20 23:29:26,612:INFO:Initializing compare_models()
2023-10-20 23:29:26,612:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, 'include': None, 'exclude': ['ransac'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=['ransac'])
2023-10-20 23:29:26,612:INFO:Checking exceptions
2023-10-20 23:29:26,630:INFO:Preparing display monitor
2023-10-20 23:29:26,634:INFO:Initializing Linear Regression
2023-10-20 23:29:26,634:INFO:Total runtime is 0.0 minutes
2023-10-20 23:29:26,635:INFO:SubProcess create_model() called ==================================
2023-10-20 23:29:26,635:INFO:Initializing create_model()
2023-10-20 23:29:26,635:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:29:26,635:INFO:Checking exceptions
2023-10-20 23:29:26,635:INFO:Importing libraries
2023-10-20 23:29:26,635:INFO:Copying training dataset
2023-10-20 23:29:26,657:INFO:Defining folds
2023-10-20 23:29:26,657:INFO:Declaring metric variables
2023-10-20 23:29:26,657:INFO:Importing untrained model
2023-10-20 23:29:26,658:INFO:Linear Regression Imported successfully
2023-10-20 23:29:26,658:INFO:Starting cross validation
2023-10-20 23:29:26,659:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:29:28,951:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\joblib\externals\loky\process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(

2023-10-20 23:29:31,883:INFO:Calculating mean and std
2023-10-20 23:29:31,883:INFO:Creating metrics dataframe
2023-10-20 23:29:31,883:INFO:Uploading results into container
2023-10-20 23:29:31,883:INFO:Uploading model into container now
2023-10-20 23:29:31,883:INFO:_master_model_container: 1
2023-10-20 23:29:31,883:INFO:_display_container: 2
2023-10-20 23:29:31,883:INFO:LinearRegression(n_jobs=-1)
2023-10-20 23:29:31,883:INFO:create_model() successfully completed......................................
2023-10-20 23:29:31,985:INFO:SubProcess create_model() end ==================================
2023-10-20 23:29:31,985:INFO:Creating metrics dataframe
2023-10-20 23:29:31,985:INFO:Initializing Lasso Regression
2023-10-20 23:29:31,985:INFO:Total runtime is 0.08918093045552572 minutes
2023-10-20 23:29:32,000:INFO:SubProcess create_model() called ==================================
2023-10-20 23:29:32,000:INFO:Initializing create_model()
2023-10-20 23:29:32,000:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:29:32,000:INFO:Checking exceptions
2023-10-20 23:29:32,000:INFO:Importing libraries
2023-10-20 23:29:32,000:INFO:Copying training dataset
2023-10-20 23:29:32,022:INFO:Defining folds
2023-10-20 23:29:32,022:INFO:Declaring metric variables
2023-10-20 23:29:32,022:INFO:Importing untrained model
2023-10-20 23:29:32,022:INFO:Lasso Regression Imported successfully
2023-10-20 23:29:32,022:INFO:Starting cross validation
2023-10-20 23:29:32,022:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:29:32,688:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.427e+09, tolerance: 2.896e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:37,881:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.463e+09, tolerance: 2.927e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:37,894:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.464e+09, tolerance: 2.904e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:37,997:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.457e+09, tolerance: 2.881e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:38,014:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.460e+09, tolerance: 2.900e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:38,014:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.450e+09, tolerance: 2.898e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:38,030:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.448e+09, tolerance: 2.871e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:38,030:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.410e+09, tolerance: 2.856e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:38,046:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.470e+09, tolerance: 2.933e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:38,046:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.456e+09, tolerance: 2.898e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:38,180:INFO:Calculating mean and std
2023-10-20 23:29:38,181:INFO:Creating metrics dataframe
2023-10-20 23:29:38,183:INFO:Uploading results into container
2023-10-20 23:29:38,183:INFO:Uploading model into container now
2023-10-20 23:29:38,183:INFO:_master_model_container: 2
2023-10-20 23:29:38,183:INFO:_display_container: 2
2023-10-20 23:29:38,183:INFO:Lasso(random_state=123)
2023-10-20 23:29:38,183:INFO:create_model() successfully completed......................................
2023-10-20 23:29:38,284:INFO:SubProcess create_model() end ==================================
2023-10-20 23:29:38,284:INFO:Creating metrics dataframe
2023-10-20 23:29:38,296:INFO:Initializing Ridge Regression
2023-10-20 23:29:38,296:INFO:Total runtime is 0.19436156749725342 minutes
2023-10-20 23:29:38,296:INFO:SubProcess create_model() called ==================================
2023-10-20 23:29:38,297:INFO:Initializing create_model()
2023-10-20 23:29:38,297:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:29:38,297:INFO:Checking exceptions
2023-10-20 23:29:38,297:INFO:Importing libraries
2023-10-20 23:29:38,297:INFO:Copying training dataset
2023-10-20 23:29:38,315:INFO:Defining folds
2023-10-20 23:29:38,315:INFO:Declaring metric variables
2023-10-20 23:29:38,315:INFO:Importing untrained model
2023-10-20 23:29:38,315:INFO:Ridge Regression Imported successfully
2023-10-20 23:29:38,315:INFO:Starting cross validation
2023-10-20 23:29:38,315:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:29:38,454:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.06625e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:29:38,470:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.06293e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:29:38,470:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.1254e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:29:38,470:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.05971e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:29:41,802:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.06296e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:29:41,821:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.07861e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:29:41,826:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.09042e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:29:41,827:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.05293e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:29:41,831:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.07372e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:29:41,834:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.08204e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:29:41,977:INFO:Calculating mean and std
2023-10-20 23:29:41,977:INFO:Creating metrics dataframe
2023-10-20 23:29:41,977:INFO:Uploading results into container
2023-10-20 23:29:41,977:INFO:Uploading model into container now
2023-10-20 23:29:41,977:INFO:_master_model_container: 3
2023-10-20 23:29:41,977:INFO:_display_container: 2
2023-10-20 23:29:41,977:INFO:Ridge(random_state=123)
2023-10-20 23:29:41,977:INFO:create_model() successfully completed......................................
2023-10-20 23:29:42,093:INFO:SubProcess create_model() end ==================================
2023-10-20 23:29:42,093:INFO:Creating metrics dataframe
2023-10-20 23:29:42,096:INFO:Initializing Elastic Net
2023-10-20 23:29:42,096:INFO:Total runtime is 0.257698396841685 minutes
2023-10-20 23:29:42,096:INFO:SubProcess create_model() called ==================================
2023-10-20 23:29:42,096:INFO:Initializing create_model()
2023-10-20 23:29:42,096:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:29:42,096:INFO:Checking exceptions
2023-10-20 23:29:42,096:INFO:Importing libraries
2023-10-20 23:29:42,096:INFO:Copying training dataset
2023-10-20 23:29:42,117:INFO:Defining folds
2023-10-20 23:29:42,117:INFO:Declaring metric variables
2023-10-20 23:29:42,117:INFO:Importing untrained model
2023-10-20 23:29:42,117:INFO:Elastic Net Imported successfully
2023-10-20 23:29:42,117:INFO:Starting cross validation
2023-10-20 23:29:42,117:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:29:43,444:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.468e+09, tolerance: 2.871e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:43,544:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.484e+09, tolerance: 2.904e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:43,560:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.448e+09, tolerance: 2.896e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:43,560:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.477e+09, tolerance: 2.881e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:43,585:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.470e+09, tolerance: 2.898e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:43,593:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.482e+09, tolerance: 2.927e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:43,593:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.476e+09, tolerance: 2.898e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:43,593:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.481e+09, tolerance: 2.900e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:43,613:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.490e+09, tolerance: 2.933e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:43,631:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.431e+09, tolerance: 2.856e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:43,758:INFO:Calculating mean and std
2023-10-20 23:29:43,758:INFO:Creating metrics dataframe
2023-10-20 23:29:43,758:INFO:Uploading results into container
2023-10-20 23:29:43,758:INFO:Uploading model into container now
2023-10-20 23:29:43,758:INFO:_master_model_container: 4
2023-10-20 23:29:43,758:INFO:_display_container: 2
2023-10-20 23:29:43,758:INFO:ElasticNet(random_state=123)
2023-10-20 23:29:43,758:INFO:create_model() successfully completed......................................
2023-10-20 23:29:43,858:INFO:SubProcess create_model() end ==================================
2023-10-20 23:29:43,858:INFO:Creating metrics dataframe
2023-10-20 23:29:43,875:INFO:Initializing Least Angle Regression
2023-10-20 23:29:43,875:INFO:Total runtime is 0.2873404979705811 minutes
2023-10-20 23:29:43,875:INFO:SubProcess create_model() called ==================================
2023-10-20 23:29:43,875:INFO:Initializing create_model()
2023-10-20 23:29:43,875:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:29:43,875:INFO:Checking exceptions
2023-10-20 23:29:43,875:INFO:Importing libraries
2023-10-20 23:29:43,875:INFO:Copying training dataset
2023-10-20 23:29:43,891:INFO:Defining folds
2023-10-20 23:29:43,891:INFO:Declaring metric variables
2023-10-20 23:29:43,891:INFO:Importing untrained model
2023-10-20 23:29:43,891:INFO:Least Angle Regression Imported successfully
2023-10-20 23:29:43,891:INFO:Starting cross validation
2023-10-20 23:29:43,891:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:29:44,227:INFO:Calculating mean and std
2023-10-20 23:29:44,227:INFO:Creating metrics dataframe
2023-10-20 23:29:44,227:INFO:Uploading results into container
2023-10-20 23:29:44,227:INFO:Uploading model into container now
2023-10-20 23:29:44,227:INFO:_master_model_container: 5
2023-10-20 23:29:44,227:INFO:_display_container: 2
2023-10-20 23:29:44,227:INFO:Lars(random_state=123)
2023-10-20 23:29:44,227:INFO:create_model() successfully completed......................................
2023-10-20 23:29:44,341:INFO:SubProcess create_model() end ==================================
2023-10-20 23:29:44,341:INFO:Creating metrics dataframe
2023-10-20 23:29:44,341:INFO:Initializing Lasso Least Angle Regression
2023-10-20 23:29:44,341:INFO:Total runtime is 0.2951181729634603 minutes
2023-10-20 23:29:44,341:INFO:SubProcess create_model() called ==================================
2023-10-20 23:29:44,341:INFO:Initializing create_model()
2023-10-20 23:29:44,341:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:29:44,341:INFO:Checking exceptions
2023-10-20 23:29:44,341:INFO:Importing libraries
2023-10-20 23:29:44,341:INFO:Copying training dataset
2023-10-20 23:29:44,358:INFO:Defining folds
2023-10-20 23:29:44,358:INFO:Declaring metric variables
2023-10-20 23:29:44,358:INFO:Importing untrained model
2023-10-20 23:29:44,358:INFO:Lasso Least Angle Regression Imported successfully
2023-10-20 23:29:44,358:INFO:Starting cross validation
2023-10-20 23:29:44,374:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:29:44,491:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=1.588e+02, previous alpha=1.437e+02, with an active set of 14 regressors.
  warnings.warn(

2023-10-20 23:29:44,491:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 26 iterations, alpha=3.480e+01, previous alpha=3.271e+01, with an active set of 17 regressors.
  warnings.warn(

2023-10-20 23:29:44,507:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 35 iterations, alpha=8.305e+00, previous alpha=6.087e+00, with an active set of 26 regressors.
  warnings.warn(

2023-10-20 23:29:44,508:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 26 iterations, alpha=3.393e+01, previous alpha=3.161e+01, with an active set of 17 regressors.
  warnings.warn(

2023-10-20 23:29:44,508:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 29 iterations, alpha=1.570e+01, previous alpha=1.483e+01, with an active set of 20 regressors.
  warnings.warn(

2023-10-20 23:29:44,525:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 31 iterations, alpha=2.233e+01, previous alpha=2.086e+01, with an active set of 18 regressors.
  warnings.warn(

2023-10-20 23:29:44,541:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 26 iterations, alpha=3.158e+01, previous alpha=2.937e+01, with an active set of 17 regressors.
  warnings.warn(

2023-10-20 23:29:44,547:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 32 iterations, alpha=1.675e+01, previous alpha=1.367e+01, with an active set of 23 regressors.
  warnings.warn(

2023-10-20 23:29:44,557:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 31 iterations, alpha=7.665e+00, previous alpha=7.128e+00, with an active set of 22 regressors.
  warnings.warn(

2023-10-20 23:29:44,690:INFO:Calculating mean and std
2023-10-20 23:29:44,690:INFO:Creating metrics dataframe
2023-10-20 23:29:44,690:INFO:Uploading results into container
2023-10-20 23:29:44,690:INFO:Uploading model into container now
2023-10-20 23:29:44,690:INFO:_master_model_container: 6
2023-10-20 23:29:44,690:INFO:_display_container: 2
2023-10-20 23:29:44,690:INFO:LassoLars(random_state=123)
2023-10-20 23:29:44,690:INFO:create_model() successfully completed......................................
2023-10-20 23:29:44,807:INFO:SubProcess create_model() end ==================================
2023-10-20 23:29:44,807:INFO:Creating metrics dataframe
2023-10-20 23:29:44,807:INFO:Initializing Orthogonal Matching Pursuit
2023-10-20 23:29:44,807:INFO:Total runtime is 0.3028773665428162 minutes
2023-10-20 23:29:44,807:INFO:SubProcess create_model() called ==================================
2023-10-20 23:29:44,807:INFO:Initializing create_model()
2023-10-20 23:29:44,807:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:29:44,807:INFO:Checking exceptions
2023-10-20 23:29:44,807:INFO:Importing libraries
2023-10-20 23:29:44,807:INFO:Copying training dataset
2023-10-20 23:29:44,824:INFO:Defining folds
2023-10-20 23:29:44,824:INFO:Declaring metric variables
2023-10-20 23:29:44,824:INFO:Importing untrained model
2023-10-20 23:29:44,824:INFO:Orthogonal Matching Pursuit Imported successfully
2023-10-20 23:29:44,839:INFO:Starting cross validation
2023-10-20 23:29:44,840:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:29:45,157:INFO:Calculating mean and std
2023-10-20 23:29:45,157:INFO:Creating metrics dataframe
2023-10-20 23:29:45,157:INFO:Uploading results into container
2023-10-20 23:29:45,157:INFO:Uploading model into container now
2023-10-20 23:29:45,157:INFO:_master_model_container: 7
2023-10-20 23:29:45,157:INFO:_display_container: 2
2023-10-20 23:29:45,157:INFO:OrthogonalMatchingPursuit()
2023-10-20 23:29:45,157:INFO:create_model() successfully completed......................................
2023-10-20 23:29:45,258:INFO:SubProcess create_model() end ==================================
2023-10-20 23:29:45,258:INFO:Creating metrics dataframe
2023-10-20 23:29:45,258:INFO:Initializing Bayesian Ridge
2023-10-20 23:29:45,258:INFO:Total runtime is 0.3103906472524008 minutes
2023-10-20 23:29:45,258:INFO:SubProcess create_model() called ==================================
2023-10-20 23:29:45,258:INFO:Initializing create_model()
2023-10-20 23:29:45,258:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:29:45,258:INFO:Checking exceptions
2023-10-20 23:29:45,258:INFO:Importing libraries
2023-10-20 23:29:45,258:INFO:Copying training dataset
2023-10-20 23:29:45,288:INFO:Defining folds
2023-10-20 23:29:45,288:INFO:Declaring metric variables
2023-10-20 23:29:45,288:INFO:Importing untrained model
2023-10-20 23:29:45,290:INFO:Bayesian Ridge Imported successfully
2023-10-20 23:29:45,290:INFO:Starting cross validation
2023-10-20 23:29:45,290:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:29:45,840:INFO:Calculating mean and std
2023-10-20 23:29:45,840:INFO:Creating metrics dataframe
2023-10-20 23:29:45,840:INFO:Uploading results into container
2023-10-20 23:29:45,840:INFO:Uploading model into container now
2023-10-20 23:29:45,840:INFO:_master_model_container: 8
2023-10-20 23:29:45,840:INFO:_display_container: 2
2023-10-20 23:29:45,840:INFO:BayesianRidge()
2023-10-20 23:29:45,840:INFO:create_model() successfully completed......................................
2023-10-20 23:29:45,943:INFO:SubProcess create_model() end ==================================
2023-10-20 23:29:45,943:INFO:Creating metrics dataframe
2023-10-20 23:29:45,943:INFO:Initializing Passive Aggressive Regressor
2023-10-20 23:29:45,943:INFO:Total runtime is 0.32181796630223597 minutes
2023-10-20 23:29:45,943:INFO:SubProcess create_model() called ==================================
2023-10-20 23:29:45,943:INFO:Initializing create_model()
2023-10-20 23:29:45,943:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:29:45,943:INFO:Checking exceptions
2023-10-20 23:29:45,943:INFO:Importing libraries
2023-10-20 23:29:45,943:INFO:Copying training dataset
2023-10-20 23:29:45,974:INFO:Defining folds
2023-10-20 23:29:45,974:INFO:Declaring metric variables
2023-10-20 23:29:45,974:INFO:Importing untrained model
2023-10-20 23:29:45,974:INFO:Passive Aggressive Regressor Imported successfully
2023-10-20 23:29:45,974:INFO:Starting cross validation
2023-10-20 23:29:45,974:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:29:46,406:INFO:Calculating mean and std
2023-10-20 23:29:46,407:INFO:Creating metrics dataframe
2023-10-20 23:29:46,407:INFO:Uploading results into container
2023-10-20 23:29:46,407:INFO:Uploading model into container now
2023-10-20 23:29:46,407:INFO:_master_model_container: 9
2023-10-20 23:29:46,407:INFO:_display_container: 2
2023-10-20 23:29:46,407:INFO:PassiveAggressiveRegressor(random_state=123)
2023-10-20 23:29:46,407:INFO:create_model() successfully completed......................................
2023-10-20 23:29:46,517:INFO:SubProcess create_model() end ==================================
2023-10-20 23:29:46,517:INFO:Creating metrics dataframe
2023-10-20 23:29:46,523:INFO:Initializing Huber Regressor
2023-10-20 23:29:46,523:INFO:Total runtime is 0.33148535887400316 minutes
2023-10-20 23:29:46,523:INFO:SubProcess create_model() called ==================================
2023-10-20 23:29:46,523:INFO:Initializing create_model()
2023-10-20 23:29:46,523:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:29:46,523:INFO:Checking exceptions
2023-10-20 23:29:46,523:INFO:Importing libraries
2023-10-20 23:29:46,524:INFO:Copying training dataset
2023-10-20 23:29:46,539:INFO:Defining folds
2023-10-20 23:29:46,539:INFO:Declaring metric variables
2023-10-20 23:29:46,539:INFO:Importing untrained model
2023-10-20 23:29:46,539:INFO:Huber Regressor Imported successfully
2023-10-20 23:29:46,539:INFO:Starting cross validation
2023-10-20 23:29:46,539:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:29:50,652:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:29:50,706:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:29:50,706:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:29:50,729:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:29:50,736:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:29:50,754:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:29:50,803:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:29:50,819:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:29:50,836:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:29:50,929:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:29:51,053:INFO:Calculating mean and std
2023-10-20 23:29:51,053:INFO:Creating metrics dataframe
2023-10-20 23:29:51,053:INFO:Uploading results into container
2023-10-20 23:29:51,053:INFO:Uploading model into container now
2023-10-20 23:29:51,053:INFO:_master_model_container: 10
2023-10-20 23:29:51,053:INFO:_display_container: 2
2023-10-20 23:29:51,053:INFO:HuberRegressor()
2023-10-20 23:29:51,053:INFO:create_model() successfully completed......................................
2023-10-20 23:29:51,168:INFO:SubProcess create_model() end ==================================
2023-10-20 23:29:51,168:INFO:Creating metrics dataframe
2023-10-20 23:29:51,168:INFO:Initializing K Neighbors Regressor
2023-10-20 23:29:51,168:INFO:Total runtime is 0.4089048584302267 minutes
2023-10-20 23:29:51,168:INFO:SubProcess create_model() called ==================================
2023-10-20 23:29:51,168:INFO:Initializing create_model()
2023-10-20 23:29:51,168:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:29:51,168:INFO:Checking exceptions
2023-10-20 23:29:51,168:INFO:Importing libraries
2023-10-20 23:29:51,168:INFO:Copying training dataset
2023-10-20 23:29:51,186:INFO:Defining folds
2023-10-20 23:29:51,186:INFO:Declaring metric variables
2023-10-20 23:29:51,186:INFO:Importing untrained model
2023-10-20 23:29:51,186:INFO:K Neighbors Regressor Imported successfully
2023-10-20 23:29:51,186:INFO:Starting cross validation
2023-10-20 23:29:51,186:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:29:52,272:INFO:Calculating mean and std
2023-10-20 23:29:52,272:INFO:Creating metrics dataframe
2023-10-20 23:29:52,272:INFO:Uploading results into container
2023-10-20 23:29:52,272:INFO:Uploading model into container now
2023-10-20 23:29:52,283:INFO:_master_model_container: 11
2023-10-20 23:29:52,284:INFO:_display_container: 2
2023-10-20 23:29:52,284:INFO:KNeighborsRegressor(n_jobs=-1)
2023-10-20 23:29:52,284:INFO:create_model() successfully completed......................................
2023-10-20 23:29:52,400:INFO:SubProcess create_model() end ==================================
2023-10-20 23:29:52,400:INFO:Creating metrics dataframe
2023-10-20 23:29:52,417:INFO:Initializing Decision Tree Regressor
2023-10-20 23:29:52,417:INFO:Total runtime is 0.4297126571337383 minutes
2023-10-20 23:29:52,417:INFO:SubProcess create_model() called ==================================
2023-10-20 23:29:52,417:INFO:Initializing create_model()
2023-10-20 23:29:52,417:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:29:52,417:INFO:Checking exceptions
2023-10-20 23:29:52,417:INFO:Importing libraries
2023-10-20 23:29:52,417:INFO:Copying training dataset
2023-10-20 23:29:52,437:INFO:Defining folds
2023-10-20 23:29:52,437:INFO:Declaring metric variables
2023-10-20 23:29:52,437:INFO:Importing untrained model
2023-10-20 23:29:52,437:INFO:Decision Tree Regressor Imported successfully
2023-10-20 23:29:52,437:INFO:Starting cross validation
2023-10-20 23:29:52,437:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:29:53,583:INFO:Calculating mean and std
2023-10-20 23:29:53,583:INFO:Creating metrics dataframe
2023-10-20 23:29:53,583:INFO:Uploading results into container
2023-10-20 23:29:53,583:INFO:Uploading model into container now
2023-10-20 23:29:53,583:INFO:_master_model_container: 12
2023-10-20 23:29:53,583:INFO:_display_container: 2
2023-10-20 23:29:53,583:INFO:DecisionTreeRegressor(random_state=123)
2023-10-20 23:29:53,583:INFO:create_model() successfully completed......................................
2023-10-20 23:29:53,700:INFO:SubProcess create_model() end ==================================
2023-10-20 23:29:53,700:INFO:Creating metrics dataframe
2023-10-20 23:29:53,700:INFO:Initializing Random Forest Regressor
2023-10-20 23:29:53,700:INFO:Total runtime is 0.45109365781148286 minutes
2023-10-20 23:29:53,700:INFO:SubProcess create_model() called ==================================
2023-10-20 23:29:53,700:INFO:Initializing create_model()
2023-10-20 23:29:53,700:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:29:53,700:INFO:Checking exceptions
2023-10-20 23:29:53,700:INFO:Importing libraries
2023-10-20 23:29:53,700:INFO:Copying training dataset
2023-10-20 23:29:53,716:INFO:Defining folds
2023-10-20 23:29:53,716:INFO:Declaring metric variables
2023-10-20 23:29:53,716:INFO:Importing untrained model
2023-10-20 23:29:53,731:INFO:Random Forest Regressor Imported successfully
2023-10-20 23:29:53,732:INFO:Starting cross validation
2023-10-20 23:29:53,733:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:30:46,477:INFO:Calculating mean and std
2023-10-20 23:30:46,477:INFO:Creating metrics dataframe
2023-10-20 23:30:46,477:INFO:Uploading results into container
2023-10-20 23:30:46,477:INFO:Uploading model into container now
2023-10-20 23:30:46,477:INFO:_master_model_container: 13
2023-10-20 23:30:46,477:INFO:_display_container: 2
2023-10-20 23:30:46,477:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-10-20 23:30:46,477:INFO:create_model() successfully completed......................................
2023-10-20 23:30:46,606:INFO:SubProcess create_model() end ==================================
2023-10-20 23:30:46,606:INFO:Creating metrics dataframe
2023-10-20 23:30:46,621:INFO:Initializing Extra Trees Regressor
2023-10-20 23:30:46,621:INFO:Total runtime is 1.333108727137248 minutes
2023-10-20 23:30:46,621:INFO:SubProcess create_model() called ==================================
2023-10-20 23:30:46,621:INFO:Initializing create_model()
2023-10-20 23:30:46,621:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:30:46,621:INFO:Checking exceptions
2023-10-20 23:30:46,621:INFO:Importing libraries
2023-10-20 23:30:46,621:INFO:Copying training dataset
2023-10-20 23:30:46,639:INFO:Defining folds
2023-10-20 23:30:46,639:INFO:Declaring metric variables
2023-10-20 23:30:46,639:INFO:Importing untrained model
2023-10-20 23:30:46,639:INFO:Extra Trees Regressor Imported successfully
2023-10-20 23:30:46,639:INFO:Starting cross validation
2023-10-20 23:30:46,639:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:31:02,598:INFO:Calculating mean and std
2023-10-20 23:31:02,598:INFO:Creating metrics dataframe
2023-10-20 23:31:02,613:INFO:Uploading results into container
2023-10-20 23:31:02,613:INFO:Uploading model into container now
2023-10-20 23:31:02,613:INFO:_master_model_container: 14
2023-10-20 23:31:02,613:INFO:_display_container: 2
2023-10-20 23:31:02,618:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-10-20 23:31:02,619:INFO:create_model() successfully completed......................................
2023-10-20 23:31:02,852:INFO:SubProcess create_model() end ==================================
2023-10-20 23:31:02,852:INFO:Creating metrics dataframe
2023-10-20 23:31:02,868:INFO:Initializing AdaBoost Regressor
2023-10-20 23:31:02,868:INFO:Total runtime is 1.603890113035838 minutes
2023-10-20 23:31:02,868:INFO:SubProcess create_model() called ==================================
2023-10-20 23:31:02,868:INFO:Initializing create_model()
2023-10-20 23:31:02,868:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:31:02,868:INFO:Checking exceptions
2023-10-20 23:31:02,868:INFO:Importing libraries
2023-10-20 23:31:02,868:INFO:Copying training dataset
2023-10-20 23:31:02,914:INFO:Defining folds
2023-10-20 23:31:02,914:INFO:Declaring metric variables
2023-10-20 23:31:02,914:INFO:Importing untrained model
2023-10-20 23:31:02,914:INFO:AdaBoost Regressor Imported successfully
2023-10-20 23:31:02,914:INFO:Starting cross validation
2023-10-20 23:31:02,930:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:31:10,552:INFO:Calculating mean and std
2023-10-20 23:31:10,553:INFO:Creating metrics dataframe
2023-10-20 23:31:10,553:INFO:Uploading results into container
2023-10-20 23:31:10,553:INFO:Uploading model into container now
2023-10-20 23:31:10,553:INFO:_master_model_container: 15
2023-10-20 23:31:10,553:INFO:_display_container: 2
2023-10-20 23:31:10,553:INFO:AdaBoostRegressor(random_state=123)
2023-10-20 23:31:10,553:INFO:create_model() successfully completed......................................
2023-10-20 23:31:10,653:INFO:SubProcess create_model() end ==================================
2023-10-20 23:31:10,653:INFO:Creating metrics dataframe
2023-10-20 23:31:10,669:INFO:Initializing Gradient Boosting Regressor
2023-10-20 23:31:10,669:INFO:Total runtime is 1.7339226762453717 minutes
2023-10-20 23:31:10,669:INFO:SubProcess create_model() called ==================================
2023-10-20 23:31:10,669:INFO:Initializing create_model()
2023-10-20 23:31:10,669:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:31:10,669:INFO:Checking exceptions
2023-10-20 23:31:10,669:INFO:Importing libraries
2023-10-20 23:31:10,669:INFO:Copying training dataset
2023-10-20 23:31:10,691:INFO:Defining folds
2023-10-20 23:31:10,691:INFO:Declaring metric variables
2023-10-20 23:31:10,691:INFO:Importing untrained model
2023-10-20 23:31:10,691:INFO:Gradient Boosting Regressor Imported successfully
2023-10-20 23:31:10,691:INFO:Starting cross validation
2023-10-20 23:31:10,691:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:31:31,253:INFO:Calculating mean and std
2023-10-20 23:31:31,253:INFO:Creating metrics dataframe
2023-10-20 23:31:31,253:INFO:Uploading results into container
2023-10-20 23:31:31,253:INFO:Uploading model into container now
2023-10-20 23:31:31,253:INFO:_master_model_container: 16
2023-10-20 23:31:31,253:INFO:_display_container: 2
2023-10-20 23:31:31,253:INFO:GradientBoostingRegressor(random_state=123)
2023-10-20 23:31:31,253:INFO:create_model() successfully completed......................................
2023-10-20 23:31:31,352:INFO:SubProcess create_model() end ==================================
2023-10-20 23:31:31,352:INFO:Creating metrics dataframe
2023-10-20 23:31:31,352:INFO:Initializing Light Gradient Boosting Machine
2023-10-20 23:31:31,352:INFO:Total runtime is 2.0786349614461264 minutes
2023-10-20 23:31:31,352:INFO:SubProcess create_model() called ==================================
2023-10-20 23:31:31,352:INFO:Initializing create_model()
2023-10-20 23:31:31,352:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:31:31,352:INFO:Checking exceptions
2023-10-20 23:31:31,352:INFO:Importing libraries
2023-10-20 23:31:31,352:INFO:Copying training dataset
2023-10-20 23:31:31,386:INFO:Defining folds
2023-10-20 23:31:31,386:INFO:Declaring metric variables
2023-10-20 23:31:31,386:INFO:Importing untrained model
2023-10-20 23:31:31,386:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-20 23:31:31,386:INFO:Starting cross validation
2023-10-20 23:31:31,386:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:31:34,148:INFO:Calculating mean and std
2023-10-20 23:31:34,150:INFO:Creating metrics dataframe
2023-10-20 23:31:34,150:INFO:Uploading results into container
2023-10-20 23:31:34,150:INFO:Uploading model into container now
2023-10-20 23:31:34,150:INFO:_master_model_container: 17
2023-10-20 23:31:34,150:INFO:_display_container: 2
2023-10-20 23:31:34,150:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-20 23:31:34,150:INFO:create_model() successfully completed......................................
2023-10-20 23:31:34,266:INFO:SubProcess create_model() end ==================================
2023-10-20 23:31:34,266:INFO:Creating metrics dataframe
2023-10-20 23:31:34,283:INFO:Initializing CatBoost Regressor
2023-10-20 23:31:34,283:INFO:Total runtime is 2.127480455239614 minutes
2023-10-20 23:31:34,283:INFO:SubProcess create_model() called ==================================
2023-10-20 23:31:34,283:INFO:Initializing create_model()
2023-10-20 23:31:34,283:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:31:34,283:INFO:Checking exceptions
2023-10-20 23:31:34,283:INFO:Importing libraries
2023-10-20 23:31:34,283:INFO:Copying training dataset
2023-10-20 23:31:34,311:INFO:Defining folds
2023-10-20 23:31:34,312:INFO:Declaring metric variables
2023-10-20 23:31:34,313:INFO:Importing untrained model
2023-10-20 23:31:34,313:INFO:CatBoost Regressor Imported successfully
2023-10-20 23:31:34,313:INFO:Starting cross validation
2023-10-20 23:31:34,316:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:32:07,875:INFO:Calculating mean and std
2023-10-20 23:32:07,875:INFO:Creating metrics dataframe
2023-10-20 23:32:07,875:INFO:Uploading results into container
2023-10-20 23:32:07,875:INFO:Uploading model into container now
2023-10-20 23:32:07,875:INFO:_master_model_container: 18
2023-10-20 23:32:07,875:INFO:_display_container: 2
2023-10-20 23:32:07,875:INFO:<catboost.core.CatBoostRegressor object at 0x00000209D5A82340>
2023-10-20 23:32:07,875:INFO:create_model() successfully completed......................................
2023-10-20 23:32:08,002:INFO:SubProcess create_model() end ==================================
2023-10-20 23:32:08,002:INFO:Creating metrics dataframe
2023-10-20 23:32:08,002:INFO:Initializing Dummy Regressor
2023-10-20 23:32:08,002:INFO:Total runtime is 2.689457360903422 minutes
2023-10-20 23:32:08,002:INFO:SubProcess create_model() called ==================================
2023-10-20 23:32:08,002:INFO:Initializing create_model()
2023-10-20 23:32:08,002:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:32:08,002:INFO:Checking exceptions
2023-10-20 23:32:08,002:INFO:Importing libraries
2023-10-20 23:32:08,002:INFO:Copying training dataset
2023-10-20 23:32:08,040:INFO:Defining folds
2023-10-20 23:32:08,040:INFO:Declaring metric variables
2023-10-20 23:32:08,040:INFO:Importing untrained model
2023-10-20 23:32:08,041:INFO:Dummy Regressor Imported successfully
2023-10-20 23:32:08,041:INFO:Starting cross validation
2023-10-20 23:32:08,043:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:32:08,354:INFO:Calculating mean and std
2023-10-20 23:32:08,354:INFO:Creating metrics dataframe
2023-10-20 23:32:08,354:INFO:Uploading results into container
2023-10-20 23:32:08,354:INFO:Uploading model into container now
2023-10-20 23:32:08,354:INFO:_master_model_container: 19
2023-10-20 23:32:08,354:INFO:_display_container: 2
2023-10-20 23:32:08,354:INFO:DummyRegressor()
2023-10-20 23:32:08,354:INFO:create_model() successfully completed......................................
2023-10-20 23:32:08,476:INFO:SubProcess create_model() end ==================================
2023-10-20 23:32:08,476:INFO:Creating metrics dataframe
2023-10-20 23:32:08,476:INFO:Initializing create_model()
2023-10-20 23:32:08,476:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=<catboost.core.CatBoostRegressor object at 0x00000209D5A82340>, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:32:08,476:INFO:Checking exceptions
2023-10-20 23:32:08,476:INFO:Importing libraries
2023-10-20 23:32:08,476:INFO:Copying training dataset
2023-10-20 23:32:08,507:INFO:Defining folds
2023-10-20 23:32:08,507:INFO:Declaring metric variables
2023-10-20 23:32:08,507:INFO:Importing untrained model
2023-10-20 23:32:08,507:INFO:Declaring custom model
2023-10-20 23:32:08,507:INFO:CatBoost Regressor Imported successfully
2023-10-20 23:32:08,507:INFO:Cross validation set to False
2023-10-20 23:32:08,507:INFO:Fitting Model
2023-10-20 23:32:15,516:INFO:<catboost.core.CatBoostRegressor object at 0x00000209E4212880>
2023-10-20 23:32:15,516:INFO:create_model() successfully completed......................................
2023-10-20 23:32:15,616:INFO:Creating Dashboard logs
2023-10-20 23:32:15,616:INFO:Model: CatBoost Regressor
2023-10-20 23:32:15,685:INFO:Logged params: {'nan_mode': 'Min', 'eval_metric': 'RMSE', 'iterations': 1000, 'sampling_frequency': 'PerTree', 'leaf_estimation_method': 'Newton', 'random_score_type': 'NormalWithModelSizeDecrease', 'grow_policy': 'SymmetricTree', 'penalties_coefficient': 1, 'boosting_type': 'Plain', 'model_shrink_mode': 'Constant', 'feature_border_type': 'GreedyLogSum', 'bayesian_matrix_reg': 0.10000000149011612, 'eval_fraction': 0, 'force_unit_auto_pair_weights': False, 'l2_leaf_reg': 3, 'random_strength': 1, 'rsm': 1, 'boost_from_average': True, 'model_size_reg': 0.5, 'pool_metainfo_options': {'tags': {}}, 'subsample': 0.800000011920929, 'use_best_model': False, 'random_seed': 123, 'depth': 6, 'posterior_sampling': False, 'border_count': 254, 'classes_count': 0, 'auto_class_weights': 'None', 'sparse_features_conflict_fraction': 0, 'leaf_estimation_backtracking': 'AnyImprovement', 'best_model_min_trees': 1, 'model_shrink_rate': 0, 'min_data_in_leaf': 1, 'loss_function': 'RMSE', 'learning_rate': 0.06757699698209763, 'score_function': 'Cosine', 'task_type': 'CPU', 'leaf_estimation_iterations': 1, 'bootstrap_type': 'MVS', 'max_leaves': 64}
2023-10-20 23:32:15,939:INFO:Initializing predict_model()
2023-10-20 23:32:15,947:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=<catboost.core.CatBoostRegressor object at 0x00000209E4212880>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DA9FBF70>)
2023-10-20 23:32:15,947:INFO:Checking exceptions
2023-10-20 23:32:15,947:INFO:Preloading libraries
2023-10-20 23:32:16,353:INFO:Creating Dashboard logs
2023-10-20 23:32:16,354:INFO:Model: Light Gradient Boosting Machine
2023-10-20 23:32:16,416:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-20 23:32:16,740:INFO:Creating Dashboard logs
2023-10-20 23:32:16,740:INFO:Model: Extra Trees Regressor
2023-10-20 23:32:16,802:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-20 23:32:17,117:INFO:Creating Dashboard logs
2023-10-20 23:32:17,117:INFO:Model: Random Forest Regressor
2023-10-20 23:32:17,180:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-20 23:32:17,520:INFO:Creating Dashboard logs
2023-10-20 23:32:17,520:INFO:Model: Gradient Boosting Regressor
2023-10-20 23:32:17,585:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 123, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-10-20 23:32:17,904:INFO:Creating Dashboard logs
2023-10-20 23:32:17,904:INFO:Model: Ridge Regression
2023-10-20 23:32:17,951:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 123, 'solver': 'auto', 'tol': 0.0001}
2023-10-20 23:32:18,231:INFO:Creating Dashboard logs
2023-10-20 23:32:18,242:INFO:Model: Lasso Regression
2023-10-20 23:32:18,303:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 123, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-10-20 23:32:18,634:INFO:Creating Dashboard logs
2023-10-20 23:32:18,634:INFO:Model: Elastic Net
2023-10-20 23:32:18,688:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 123, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-10-20 23:32:18,992:INFO:Creating Dashboard logs
2023-10-20 23:32:18,992:INFO:Model: Lasso Least Angle Regression
2023-10-20 23:32:19,048:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'max_iter': 500, 'normalize': 'deprecated', 'positive': False, 'precompute': 'auto', 'random_state': 123, 'verbose': False}
2023-10-20 23:32:19,360:INFO:Creating Dashboard logs
2023-10-20 23:32:19,360:INFO:Model: Linear Regression
2023-10-20 23:32:19,419:INFO:Logged params: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'positive': False}
2023-10-20 23:32:19,712:INFO:Creating Dashboard logs
2023-10-20 23:32:19,712:INFO:Model: AdaBoost Regressor
2023-10-20 23:32:19,768:INFO:Logged params: {'base_estimator': 'deprecated', 'estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': 123}
2023-10-20 23:32:20,078:INFO:Creating Dashboard logs
2023-10-20 23:32:20,080:INFO:Model: Orthogonal Matching Pursuit
2023-10-20 23:32:20,130:INFO:Logged params: {'fit_intercept': True, 'n_nonzero_coefs': None, 'normalize': 'deprecated', 'precompute': 'auto', 'tol': None}
2023-10-20 23:32:20,416:INFO:Creating Dashboard logs
2023-10-20 23:32:20,416:INFO:Model: Huber Regressor
2023-10-20 23:32:20,485:INFO:Logged params: {'alpha': 0.0001, 'epsilon': 1.35, 'fit_intercept': True, 'max_iter': 100, 'tol': 1e-05, 'warm_start': False}
2023-10-20 23:32:20,762:INFO:Creating Dashboard logs
2023-10-20 23:32:20,762:INFO:Model: Decision Tree Regressor
2023-10-20 23:32:20,817:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 123, 'splitter': 'best'}
2023-10-20 23:32:21,106:INFO:Creating Dashboard logs
2023-10-20 23:32:21,106:INFO:Model: K Neighbors Regressor
2023-10-20 23:32:21,164:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2023-10-20 23:32:21,462:INFO:Creating Dashboard logs
2023-10-20 23:32:21,462:INFO:Model: Dummy Regressor
2023-10-20 23:32:21,509:INFO:Logged params: {'constant': None, 'quantile': None, 'strategy': 'mean'}
2023-10-20 23:32:21,795:INFO:Creating Dashboard logs
2023-10-20 23:32:21,795:INFO:Model: Passive Aggressive Regressor
2023-10-20 23:32:21,848:INFO:Logged params: {'C': 1.0, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'fit_intercept': True, 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 5, 'random_state': 123, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-10-20 23:32:22,165:INFO:Creating Dashboard logs
2023-10-20 23:32:22,165:INFO:Model: Bayesian Ridge
2023-10-20 23:32:22,227:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'tol': 0.001, 'verbose': False}
2023-10-20 23:32:22,546:INFO:Creating Dashboard logs
2023-10-20 23:32:22,546:INFO:Model: Least Angle Regression
2023-10-20 23:32:22,613:INFO:Logged params: {'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'n_nonzero_coefs': 500, 'normalize': 'deprecated', 'precompute': 'auto', 'random_state': 123, 'verbose': False}
2023-10-20 23:32:22,909:INFO:_master_model_container: 19
2023-10-20 23:32:22,909:INFO:_display_container: 2
2023-10-20 23:32:22,909:INFO:<catboost.core.CatBoostRegressor object at 0x00000209E4212880>
2023-10-20 23:32:22,911:INFO:compare_models() successfully completed......................................
2023-10-20 23:32:22,911:INFO:Initializing ensemble_model()
2023-10-20 23:32:22,911:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=<catboost.core.CatBoostRegressor object at 0x00000209E4212880>, method=Boosting, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-20 23:32:22,911:INFO:Checking exceptions
2023-10-20 23:33:31,120:INFO:Importing libraries
2023-10-20 23:33:31,120:INFO:Copying training dataset
2023-10-20 23:33:31,120:INFO:Checking base model
2023-10-20 23:33:31,120:INFO:Base model : CatBoost Regressor
2023-10-20 23:33:31,120:INFO:Importing untrained ensembler
2023-10-20 23:33:31,120:INFO:Ensemble method set to Boosting
2023-10-20 23:33:31,120:INFO:SubProcess create_model() called ==================================
2023-10-20 23:33:31,135:INFO:Initializing create_model()
2023-10-20 23:33:31,135:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=AdaBoostRegressor(estimator=<catboost.core.CatBoostRegressor object at 0x00000209E4212880>,
                  n_estimators=10, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3CA4430>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:33:31,135:INFO:Checking exceptions
2023-10-20 23:33:31,135:INFO:Importing libraries
2023-10-20 23:33:31,135:INFO:Copying training dataset
2023-10-20 23:33:31,156:INFO:Defining folds
2023-10-20 23:33:31,157:INFO:Declaring metric variables
2023-10-20 23:33:31,157:INFO:Importing untrained model
2023-10-20 23:33:31,157:INFO:Declaring custom model
2023-10-20 23:33:31,159:INFO:AdaBoost Regressor Imported successfully
2023-10-20 23:33:31,159:INFO:Starting cross validation
2023-10-20 23:33:31,159:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:39:41,850:INFO:Calculating mean and std
2023-10-20 23:39:41,851:INFO:Creating metrics dataframe
2023-10-20 23:39:41,851:INFO:Finalizing model
2023-10-20 23:40:50,507:INFO:Uploading results into container
2023-10-20 23:40:50,507:INFO:Uploading model into container now
2023-10-20 23:40:50,507:INFO:_master_model_container: 20
2023-10-20 23:40:50,507:INFO:_display_container: 3
2023-10-20 23:40:50,507:INFO:AdaBoostRegressor(estimator=<catboost.core.CatBoostRegressor object at 0x00000209E421A670>,
                  n_estimators=10, random_state=123)
2023-10-20 23:40:50,507:INFO:create_model() successfully completed......................................
2023-10-20 23:40:50,607:INFO:SubProcess create_model() end ==================================
2023-10-20 23:40:50,623:INFO:Creating Dashboard logs
2023-10-20 23:40:50,624:INFO:Model: AdaBoost Regressor
2023-10-20 23:40:50,681:INFO:Logged params: {'base_estimator': 'deprecated', 'estimator__loss_function': 'RMSE', 'estimator__border_count': 254, 'estimator__verbose': False, 'estimator__task_type': 'CPU', 'estimator__random_state': 123, 'estimator': <catboost.core.CatBoostRegressor object at 0x00000209E421A670>, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 10, 'random_state': 123}
2023-10-20 23:40:50,840:INFO:Initializing predict_model()
2023-10-20 23:40:50,840:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=AdaBoostRegressor(estimator=<catboost.core.CatBoostRegressor object at 0x00000209E421A670>,
                  n_estimators=10, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DC9DE1F0>)
2023-10-20 23:40:50,840:INFO:Checking exceptions
2023-10-20 23:40:50,840:INFO:Preloading libraries
2023-10-20 23:40:51,323:INFO:_master_model_container: 20
2023-10-20 23:40:51,323:INFO:_display_container: 3
2023-10-20 23:40:51,323:INFO:AdaBoostRegressor(estimator=<catboost.core.CatBoostRegressor object at 0x00000209E421A670>,
                  n_estimators=10, random_state=123)
2023-10-20 23:40:51,323:INFO:ensemble_model() successfully completed......................................
2023-10-20 23:40:51,425:INFO:Initializing tune_model()
2023-10-20 23:40:51,425:INFO:tune_model(estimator=AdaBoostRegressor(estimator=<catboost.core.CatBoostRegressor object at 0x00000209E421A670>,
                  n_estimators=10, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>)
2023-10-20 23:40:51,425:INFO:Checking exceptions
2023-10-20 23:40:51,441:INFO:Copying training dataset
2023-10-20 23:40:51,457:INFO:Checking base model
2023-10-20 23:40:51,457:INFO:Base model : AdaBoost Regressor
2023-10-20 23:40:51,457:INFO:Declaring metric variables
2023-10-20 23:40:51,457:INFO:Defining Hyperparameters
2023-10-20 23:40:51,574:INFO:Tuning with n_jobs=-1
2023-10-20 23:40:51,574:INFO:Initializing RandomizedSearchCV
2023-10-21 08:53:05,939:INFO:PyCaret RegressionExperiment
2023-10-21 08:53:05,940:INFO:Logging name: exp_A
2023-10-21 08:53:05,940:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-21 08:53:05,941:INFO:version 3.1.0
2023-10-21 08:53:05,941:INFO:Initializing setup()
2023-10-21 08:53:05,941:INFO:self.USI: 0c8f
2023-10-21 08:53:05,941:INFO:self._variable_keys: {'transform_target_param', 'exp_name_log', 'y_train', 'logging_param', 'n_jobs_param', 'X_train', 'target_param', 'USI', 'gpu_n_jobs_param', 'fold_groups_param', '_ml_usecase', 'seed', 'fold_generator', 'idx', 'html_param', 'log_plots_param', 'y', 'gpu_param', 'X_test', 'memory', 'y_test', 'data', 'X', 'exp_id', '_available_plots', 'fold_shuffle_param', 'pipeline'}
2023-10-21 08:53:05,942:INFO:Checking environment
2023-10-21 08:53:05,942:INFO:python_version: 3.8.18
2023-10-21 08:53:05,942:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-21 08:53:05,942:INFO:machine: AMD64
2023-10-21 08:53:05,943:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-21 08:53:05,943:INFO:Memory: svmem(total=16505954304, available=5360242688, percent=67.5, used=11145711616, free=5360242688)
2023-10-21 08:53:05,943:INFO:Physical Core: 8
2023-10-21 08:53:05,943:INFO:Logical Core: 16
2023-10-21 08:53:05,943:INFO:Checking libraries
2023-10-21 08:53:05,944:INFO:System:
2023-10-21 08:53:05,944:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-21 08:53:05,944:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-21 08:53:05,944:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-21 08:53:05,944:INFO:PyCaret required dependencies:
2023-10-21 08:53:05,944:INFO:                 pip: 23.3
2023-10-21 08:53:05,944:INFO:          setuptools: 68.0.0
2023-10-21 08:53:05,944:INFO:             pycaret: 3.1.0
2023-10-21 08:53:05,944:INFO:             IPython: 8.12.0
2023-10-21 08:53:05,944:INFO:          ipywidgets: 8.1.1
2023-10-21 08:53:05,945:INFO:                tqdm: 4.66.1
2023-10-21 08:53:05,945:INFO:               numpy: 1.23.5
2023-10-21 08:53:05,945:INFO:              pandas: 1.5.3
2023-10-21 08:53:05,945:INFO:              jinja2: 3.1.2
2023-10-21 08:53:05,945:INFO:               scipy: 1.10.1
2023-10-21 08:53:05,945:INFO:              joblib: 1.3.2
2023-10-21 08:53:05,945:INFO:             sklearn: 1.2.2
2023-10-21 08:53:05,945:INFO:                pyod: 1.1.0
2023-10-21 08:53:05,945:INFO:            imblearn: 0.11.0
2023-10-21 08:53:05,945:INFO:   category_encoders: 2.6.2
2023-10-21 08:53:05,945:INFO:            lightgbm: 4.1.0
2023-10-21 08:53:05,945:INFO:               numba: 0.58.1
2023-10-21 08:53:05,945:INFO:            requests: 2.31.0
2023-10-21 08:53:05,945:INFO:          matplotlib: 3.7.3
2023-10-21 08:53:05,945:INFO:          scikitplot: 0.3.7
2023-10-21 08:53:05,946:INFO:         yellowbrick: 1.5
2023-10-21 08:53:05,946:INFO:              plotly: 5.17.0
2023-10-21 08:53:05,946:INFO:    plotly-resampler: Not installed
2023-10-21 08:53:05,946:INFO:             kaleido: 0.2.1
2023-10-21 08:53:05,946:INFO:           schemdraw: 0.15
2023-10-21 08:53:05,946:INFO:         statsmodels: 0.14.0
2023-10-21 08:53:05,946:INFO:              sktime: 0.21.1
2023-10-21 08:53:05,946:INFO:               tbats: 1.1.3
2023-10-21 08:53:05,946:INFO:            pmdarima: 2.0.3
2023-10-21 08:53:05,946:INFO:              psutil: 5.9.0
2023-10-21 08:53:05,946:INFO:          markupsafe: 2.1.3
2023-10-21 08:53:05,946:INFO:             pickle5: Not installed
2023-10-21 08:53:05,946:INFO:         cloudpickle: 2.2.1
2023-10-21 08:53:05,946:INFO:         deprecation: 2.1.0
2023-10-21 08:53:05,946:INFO:              xxhash: 3.4.1
2023-10-21 08:53:05,946:INFO:           wurlitzer: Not installed
2023-10-21 08:53:05,946:INFO:PyCaret optional dependencies:
2023-10-21 08:53:05,946:INFO:                shap: Not installed
2023-10-21 08:53:05,947:INFO:           interpret: Not installed
2023-10-21 08:53:05,947:INFO:                umap: Not installed
2023-10-21 08:53:05,947:INFO:     ydata_profiling: Not installed
2023-10-21 08:53:05,947:INFO:  explainerdashboard: Not installed
2023-10-21 08:53:05,947:INFO:             autoviz: Not installed
2023-10-21 08:53:05,947:INFO:           fairlearn: Not installed
2023-10-21 08:53:05,947:INFO:          deepchecks: Not installed
2023-10-21 08:53:05,947:INFO:             xgboost: Not installed
2023-10-21 08:53:05,947:INFO:            catboost: 1.2.2
2023-10-21 08:53:05,947:INFO:              kmodes: Not installed
2023-10-21 08:53:05,947:INFO:             mlxtend: Not installed
2023-10-21 08:53:05,947:INFO:       statsforecast: Not installed
2023-10-21 08:53:05,947:INFO:        tune_sklearn: Not installed
2023-10-21 08:53:05,947:INFO:                 ray: Not installed
2023-10-21 08:53:05,947:INFO:            hyperopt: Not installed
2023-10-21 08:53:05,947:INFO:              optuna: Not installed
2023-10-21 08:53:05,947:INFO:               skopt: Not installed
2023-10-21 08:53:05,947:INFO:              mlflow: 2.7.1
2023-10-21 08:53:05,947:INFO:              gradio: Not installed
2023-10-21 08:53:05,948:INFO:             fastapi: Not installed
2023-10-21 08:53:05,948:INFO:             uvicorn: Not installed
2023-10-21 08:53:05,948:INFO:              m2cgen: Not installed
2023-10-21 08:53:05,948:INFO:           evidently: Not installed
2023-10-21 08:53:05,948:INFO:               fugue: Not installed
2023-10-21 08:53:05,948:INFO:           streamlit: Not installed
2023-10-21 08:53:05,948:INFO:             prophet: Not installed
2023-10-21 08:53:05,948:INFO:None
2023-10-21 08:53:05,948:INFO:Set up data.
2023-10-21 08:53:05,970:INFO:Set up folding strategy.
2023-10-21 08:53:05,970:INFO:Set up train/test split.
2023-10-21 08:53:06,004:INFO:Set up index.
2023-10-21 08:53:06,005:INFO:Assigning column types.
2023-10-21 08:53:06,027:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-21 08:53:06,028:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,034:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,039:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,124:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,179:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,180:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:53:06,180:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:53:06,181:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,184:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,192:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,278:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,334:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,334:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:53:06,335:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:53:06,336:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-21 08:53:06,341:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,347:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,430:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,487:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,488:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:53:06,488:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:53:06,494:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,500:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,586:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,651:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,651:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:53:06,651:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:53:06,660:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-21 08:53:06,671:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,738:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,792:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,792:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:53:06,792:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:53:06,808:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,871:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,923:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,923:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:53:06,923:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:53:06,923:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-21 08:53:07,008:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:53:07,060:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:53:07,060:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:53:07,060:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:53:07,140:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:53:07,203:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:53:07,204:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:53:07,204:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:53:07,205:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-21 08:53:07,291:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:53:07,341:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:53:07,341:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:53:07,426:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:53:07,472:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:53:07,472:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:53:07,472:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-21 08:53:07,612:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:53:07,612:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:53:07,739:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:53:07,739:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:53:07,739:INFO:Preparing preprocessing pipeline...
2023-10-21 08:53:07,739:INFO:Set up simple imputation.
2023-10-21 08:53:07,739:INFO:Set up column name cleaning.
2023-10-21 08:53:07,802:INFO:Finished creating preprocessing pipeline.
2023-10-21 08:53:07,802:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 08:53:07,802:INFO:Creating final display dataframe.
2023-10-21 08:53:07,973:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (34061, 39)
4        Transformed data shape   (34061, 39)
5   Transformed train set shape   (23842, 39)
6    Transformed test set shape   (10219, 39)
7              Numeric features            38
8      Rows with missing values         23.1%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_A
19                          USI          0c8f
2023-10-21 08:53:08,108:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:53:08,108:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:53:08,235:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:53:08,235:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:53:08,252:INFO:Logging experiment in loggers
2023-10-21 08:53:08,357:INFO:SubProcess save_model() called ==================================
2023-10-21 08:53:08,372:INFO:Initializing save_model()
2023-10-21 08:53:08,372:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmpid5n4mr7\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 08:53:08,372:INFO:Adding model into prep_pipe
2023-10-21 08:53:08,372:WARNING:Only Model saved as it was a pipeline.
2023-10-21 08:53:08,372:INFO:C:\Users\thoma\AppData\Local\Temp\tmpid5n4mr7\Transformation Pipeline.pkl saved in current working directory
2023-10-21 08:53:08,372:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 08:53:08,372:INFO:save_model() successfully completed......................................
2023-10-21 08:53:08,507:INFO:SubProcess save_model() end ==================================
2023-10-21 08:53:08,564:INFO:setup() successfully completed in 2.31s...............
2023-10-21 08:53:08,564:INFO:Initializing create_model()
2023-10-21 08:53:08,564:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6BB93A0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 08:53:08,564:INFO:Checking exceptions
2023-10-21 08:53:08,570:INFO:Importing libraries
2023-10-21 08:53:08,570:INFO:Copying training dataset
2023-10-21 08:53:08,590:INFO:Defining folds
2023-10-21 08:53:08,590:INFO:Declaring metric variables
2023-10-21 08:53:08,590:INFO:Importing untrained model
2023-10-21 08:53:08,590:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 08:53:08,590:INFO:Starting cross validation
2023-10-21 08:53:08,590:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 08:53:18,947:INFO:Calculating mean and std
2023-10-21 08:53:18,950:INFO:Creating metrics dataframe
2023-10-21 08:53:18,950:INFO:Finalizing model
2023-10-21 08:53:19,081:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005763 seconds.
2023-10-21 08:53:19,081:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 08:53:19,082:INFO:[LightGBM] [Info] Total Bins 6173
2023-10-21 08:53:19,082:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 37
2023-10-21 08:53:19,084:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-21 08:53:19,327:INFO:Creating Dashboard logs
2023-10-21 08:53:19,327:INFO:Model: Light Gradient Boosting Machine
2023-10-21 08:53:19,410:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 08:53:19,610:INFO:Initializing predict_model()
2023-10-21 08:53:19,610:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6BB93A0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DCC6AA60>)
2023-10-21 08:53:19,610:INFO:Checking exceptions
2023-10-21 08:53:19,610:INFO:Preloading libraries
2023-10-21 08:53:20,160:INFO:Uploading results into container
2023-10-21 08:53:20,172:INFO:Uploading model into container now
2023-10-21 08:53:20,176:INFO:_master_model_container: 1
2023-10-21 08:53:20,176:INFO:_display_container: 2
2023-10-21 08:53:20,176:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 08:53:20,176:INFO:create_model() successfully completed......................................
2023-10-21 08:53:20,310:INFO:Initializing tune_model()
2023-10-21 08:53:20,310:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6BB93A0>)
2023-10-21 08:53:20,310:INFO:Checking exceptions
2023-10-21 08:53:20,327:INFO:Copying training dataset
2023-10-21 08:53:20,350:INFO:Checking base model
2023-10-21 08:53:20,350:INFO:Base model : Light Gradient Boosting Machine
2023-10-21 08:53:20,350:INFO:Declaring metric variables
2023-10-21 08:53:20,350:INFO:Defining Hyperparameters
2023-10-21 08:53:20,509:INFO:Tuning with n_jobs=-1
2023-10-21 08:53:20,509:INFO:Initializing RandomizedSearchCV
2023-10-21 08:54:14,998:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-21 08:54:14,998:INFO:Hyperparameter search completed
2023-10-21 08:54:14,998:INFO:SubProcess create_model() called ==================================
2023-10-21 08:54:14,998:INFO:Initializing create_model()
2023-10-21 08:54:14,998:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6BB93A0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209DAADED30>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-21 08:54:14,998:INFO:Checking exceptions
2023-10-21 08:54:14,998:INFO:Importing libraries
2023-10-21 08:54:14,998:INFO:Copying training dataset
2023-10-21 08:54:15,032:INFO:Defining folds
2023-10-21 08:54:15,032:INFO:Declaring metric variables
2023-10-21 08:54:15,032:INFO:Importing untrained model
2023-10-21 08:54:15,032:INFO:Declaring custom model
2023-10-21 08:54:15,032:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 08:54:15,032:INFO:Starting cross validation
2023-10-21 08:54:15,032:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 08:54:24,628:INFO:Calculating mean and std
2023-10-21 08:54:24,628:INFO:Creating metrics dataframe
2023-10-21 08:54:24,628:INFO:Finalizing model
2023-10-21 08:54:24,693:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 08:54:24,693:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 08:54:24,694:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 08:54:24,729:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 08:54:24,729:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 08:54:24,729:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 08:54:24,729:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005286 seconds.
2023-10-21 08:54:24,729:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 08:54:24,739:INFO:[LightGBM] [Info] Total Bins 6173
2023-10-21 08:54:24,739:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 37
2023-10-21 08:54:24,741:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-21 08:54:25,845:INFO:Uploading results into container
2023-10-21 08:54:25,845:INFO:Uploading model into container now
2023-10-21 08:54:25,845:INFO:_master_model_container: 2
2023-10-21 08:54:25,845:INFO:_display_container: 3
2023-10-21 08:54:25,845:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-21 08:54:25,845:INFO:create_model() successfully completed......................................
2023-10-21 08:54:26,009:INFO:SubProcess create_model() end ==================================
2023-10-21 08:54:26,009:INFO:choose_better activated
2023-10-21 08:54:26,009:INFO:SubProcess create_model() called ==================================
2023-10-21 08:54:26,009:INFO:Initializing create_model()
2023-10-21 08:54:26,009:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6BB93A0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 08:54:26,009:INFO:Checking exceptions
2023-10-21 08:54:26,009:INFO:Importing libraries
2023-10-21 08:54:26,009:INFO:Copying training dataset
2023-10-21 08:54:26,024:INFO:Defining folds
2023-10-21 08:54:26,024:INFO:Declaring metric variables
2023-10-21 08:54:26,024:INFO:Importing untrained model
2023-10-21 08:54:26,024:INFO:Declaring custom model
2023-10-21 08:54:26,024:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 08:54:26,024:INFO:Starting cross validation
2023-10-21 08:54:26,024:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 08:54:28,843:INFO:Calculating mean and std
2023-10-21 08:54:28,843:INFO:Creating metrics dataframe
2023-10-21 08:54:28,843:INFO:Finalizing model
2023-10-21 08:54:28,903:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004530 seconds.
2023-10-21 08:54:28,903:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 08:54:28,903:INFO:[LightGBM] [Info] Total Bins 6173
2023-10-21 08:54:28,903:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 37
2023-10-21 08:54:28,903:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-21 08:54:29,140:INFO:Uploading results into container
2023-10-21 08:54:29,140:INFO:Uploading model into container now
2023-10-21 08:54:29,140:INFO:_master_model_container: 3
2023-10-21 08:54:29,140:INFO:_display_container: 4
2023-10-21 08:54:29,140:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 08:54:29,140:INFO:create_model() successfully completed......................................
2023-10-21 08:54:29,302:INFO:SubProcess create_model() end ==================================
2023-10-21 08:54:29,302:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8702
2023-10-21 08:54:29,302:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.867
2023-10-21 08:54:29,302:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-21 08:54:29,302:INFO:choose_better completed
2023-10-21 08:54:29,302:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-21 08:54:29,302:INFO:Creating Dashboard logs
2023-10-21 08:54:29,302:INFO:Model: Light Gradient Boosting Machine
2023-10-21 08:54:29,365:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 08:54:29,535:INFO:Initializing predict_model()
2023-10-21 08:54:29,535:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6BB93A0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DCC6A670>)
2023-10-21 08:54:29,535:INFO:Checking exceptions
2023-10-21 08:54:29,535:INFO:Preloading libraries
2023-10-21 08:54:30,089:INFO:_master_model_container: 3
2023-10-21 08:54:30,089:INFO:_display_container: 3
2023-10-21 08:54:30,090:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 08:54:30,090:INFO:tune_model() successfully completed......................................
2023-10-21 08:54:30,220:INFO:Initializing finalize_model()
2023-10-21 08:54:30,220:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6BB93A0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-21 08:54:30,220:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 08:54:30,236:INFO:Initializing create_model()
2023-10-21 08:54:30,236:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6BB93A0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-21 08:54:30,236:INFO:Checking exceptions
2023-10-21 08:54:30,236:INFO:Importing libraries
2023-10-21 08:54:30,236:INFO:Copying training dataset
2023-10-21 08:54:30,236:INFO:Defining folds
2023-10-21 08:54:30,236:INFO:Declaring metric variables
2023-10-21 08:54:30,236:INFO:Importing untrained model
2023-10-21 08:54:30,236:INFO:Declaring custom model
2023-10-21 08:54:30,236:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 08:54:30,236:INFO:Cross validation set to False
2023-10-21 08:54:30,236:INFO:Fitting Model
2023-10-21 08:54:30,341:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010197 seconds.
2023-10-21 08:54:30,341:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 08:54:30,341:INFO:[LightGBM] [Info] Total Bins 6208
2023-10-21 08:54:30,356:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 37
2023-10-21 08:54:30,356:INFO:[LightGBM] [Info] Start training from score 631.011165
2023-10-21 08:54:30,654:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-21 08:54:30,654:INFO:create_model() successfully completed......................................
2023-10-21 08:54:30,799:INFO:Creating Dashboard logs
2023-10-21 08:54:30,799:INFO:Model: Light Gradient Boosting Machine
2023-10-21 08:54:30,869:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 08:54:31,217:INFO:_master_model_container: 3
2023-10-21 08:54:31,217:INFO:_display_container: 3
2023-10-21 08:54:31,221:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-21 08:54:31,221:INFO:finalize_model() successfully completed......................................
2023-10-21 08:54:31,375:INFO:Initializing save_model()
2023-10-21 08:54:31,375:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_A, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 08:54:31,375:INFO:Adding model into prep_pipe
2023-10-21 08:54:31,375:WARNING:Only Model saved as it was a pipeline.
2023-10-21 08:54:31,386:INFO:final_model_for_location_A.pkl saved in current working directory
2023-10-21 08:54:31,386:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-21 08:54:31,386:INFO:save_model() successfully completed......................................
2023-10-21 08:54:31,555:INFO:PyCaret RegressionExperiment
2023-10-21 08:54:31,555:INFO:Logging name: exp_B
2023-10-21 08:54:31,555:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-21 08:54:31,555:INFO:version 3.1.0
2023-10-21 08:54:31,555:INFO:Initializing setup()
2023-10-21 08:54:31,555:INFO:self.USI: 024c
2023-10-21 08:54:31,555:INFO:self._variable_keys: {'transform_target_param', 'exp_name_log', 'y_train', 'logging_param', 'n_jobs_param', 'X_train', 'target_param', 'USI', 'gpu_n_jobs_param', 'fold_groups_param', '_ml_usecase', 'seed', 'fold_generator', 'idx', 'html_param', 'log_plots_param', 'y', 'gpu_param', 'X_test', 'memory', 'y_test', 'data', 'X', 'exp_id', '_available_plots', 'fold_shuffle_param', 'pipeline'}
2023-10-21 08:54:31,555:INFO:Checking environment
2023-10-21 08:54:31,555:INFO:python_version: 3.8.18
2023-10-21 08:54:31,555:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-21 08:54:31,555:INFO:machine: AMD64
2023-10-21 08:54:31,555:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-21 08:54:31,555:INFO:Memory: svmem(total=16505954304, available=3512782848, percent=78.7, used=12993171456, free=3512782848)
2023-10-21 08:54:31,555:INFO:Physical Core: 8
2023-10-21 08:54:31,555:INFO:Logical Core: 16
2023-10-21 08:54:31,555:INFO:Checking libraries
2023-10-21 08:54:31,555:INFO:System:
2023-10-21 08:54:31,555:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-21 08:54:31,555:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-21 08:54:31,555:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-21 08:54:31,555:INFO:PyCaret required dependencies:
2023-10-21 08:54:31,555:INFO:                 pip: 23.3
2023-10-21 08:54:31,555:INFO:          setuptools: 68.0.0
2023-10-21 08:54:31,555:INFO:             pycaret: 3.1.0
2023-10-21 08:54:31,555:INFO:             IPython: 8.12.0
2023-10-21 08:54:31,555:INFO:          ipywidgets: 8.1.1
2023-10-21 08:54:31,555:INFO:                tqdm: 4.66.1
2023-10-21 08:54:31,555:INFO:               numpy: 1.23.5
2023-10-21 08:54:31,555:INFO:              pandas: 1.5.3
2023-10-21 08:54:31,555:INFO:              jinja2: 3.1.2
2023-10-21 08:54:31,555:INFO:               scipy: 1.10.1
2023-10-21 08:54:31,555:INFO:              joblib: 1.3.2
2023-10-21 08:54:31,555:INFO:             sklearn: 1.2.2
2023-10-21 08:54:31,555:INFO:                pyod: 1.1.0
2023-10-21 08:54:31,555:INFO:            imblearn: 0.11.0
2023-10-21 08:54:31,555:INFO:   category_encoders: 2.6.2
2023-10-21 08:54:31,555:INFO:            lightgbm: 4.1.0
2023-10-21 08:54:31,555:INFO:               numba: 0.58.1
2023-10-21 08:54:31,555:INFO:            requests: 2.31.0
2023-10-21 08:54:31,555:INFO:          matplotlib: 3.7.3
2023-10-21 08:54:31,555:INFO:          scikitplot: 0.3.7
2023-10-21 08:54:31,555:INFO:         yellowbrick: 1.5
2023-10-21 08:54:31,555:INFO:              plotly: 5.17.0
2023-10-21 08:54:31,555:INFO:    plotly-resampler: Not installed
2023-10-21 08:54:31,555:INFO:             kaleido: 0.2.1
2023-10-21 08:54:31,555:INFO:           schemdraw: 0.15
2023-10-21 08:54:31,555:INFO:         statsmodels: 0.14.0
2023-10-21 08:54:31,555:INFO:              sktime: 0.21.1
2023-10-21 08:54:31,555:INFO:               tbats: 1.1.3
2023-10-21 08:54:31,555:INFO:            pmdarima: 2.0.3
2023-10-21 08:54:31,555:INFO:              psutil: 5.9.0
2023-10-21 08:54:31,555:INFO:          markupsafe: 2.1.3
2023-10-21 08:54:31,555:INFO:             pickle5: Not installed
2023-10-21 08:54:31,555:INFO:         cloudpickle: 2.2.1
2023-10-21 08:54:31,555:INFO:         deprecation: 2.1.0
2023-10-21 08:54:31,555:INFO:              xxhash: 3.4.1
2023-10-21 08:54:31,555:INFO:           wurlitzer: Not installed
2023-10-21 08:54:31,555:INFO:PyCaret optional dependencies:
2023-10-21 08:54:31,555:INFO:                shap: Not installed
2023-10-21 08:54:31,555:INFO:           interpret: Not installed
2023-10-21 08:54:31,555:INFO:                umap: Not installed
2023-10-21 08:54:31,555:INFO:     ydata_profiling: Not installed
2023-10-21 08:54:31,555:INFO:  explainerdashboard: Not installed
2023-10-21 08:54:31,555:INFO:             autoviz: Not installed
2023-10-21 08:54:31,555:INFO:           fairlearn: Not installed
2023-10-21 08:54:31,555:INFO:          deepchecks: Not installed
2023-10-21 08:54:31,555:INFO:             xgboost: Not installed
2023-10-21 08:54:31,555:INFO:            catboost: 1.2.2
2023-10-21 08:54:31,555:INFO:              kmodes: Not installed
2023-10-21 08:54:31,555:INFO:             mlxtend: Not installed
2023-10-21 08:54:31,555:INFO:       statsforecast: Not installed
2023-10-21 08:54:31,555:INFO:        tune_sklearn: Not installed
2023-10-21 08:54:31,555:INFO:                 ray: Not installed
2023-10-21 08:54:31,571:INFO:            hyperopt: Not installed
2023-10-21 08:54:31,571:INFO:              optuna: Not installed
2023-10-21 08:54:31,571:INFO:               skopt: Not installed
2023-10-21 08:54:31,571:INFO:              mlflow: 2.7.1
2023-10-21 08:54:31,571:INFO:              gradio: Not installed
2023-10-21 08:54:31,571:INFO:             fastapi: Not installed
2023-10-21 08:54:31,571:INFO:             uvicorn: Not installed
2023-10-21 08:54:31,571:INFO:              m2cgen: Not installed
2023-10-21 08:54:31,571:INFO:           evidently: Not installed
2023-10-21 08:54:31,571:INFO:               fugue: Not installed
2023-10-21 08:54:31,571:INFO:           streamlit: Not installed
2023-10-21 08:54:31,571:INFO:             prophet: Not installed
2023-10-21 08:54:31,571:INFO:None
2023-10-21 08:54:31,571:INFO:Set up data.
2023-10-21 08:54:31,589:INFO:Set up folding strategy.
2023-10-21 08:54:31,589:INFO:Set up train/test split.
2023-10-21 08:54:31,621:INFO:Set up index.
2023-10-21 08:54:31,621:INFO:Assigning column types.
2023-10-21 08:54:31,637:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-21 08:54:31,637:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 08:54:31,637:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 08:54:31,653:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:54:31,721:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:54:31,787:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:54:31,787:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:54:31,787:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:54:31,787:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 08:54:31,787:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 08:54:31,787:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:54:31,884:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:54:31,924:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:54:31,924:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:54:31,924:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:54:31,924:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-21 08:54:31,939:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 08:54:31,939:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,021:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,087:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,087:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:54:32,088:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:54:32,093:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,100:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,186:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,235:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,235:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:54:32,235:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:54:32,235:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-21 08:54:32,251:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,336:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,383:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,383:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:54:32,383:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:54:32,399:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,483:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,537:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,537:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:54:32,537:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:54:32,537:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-21 08:54:32,637:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,722:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,731:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:54:32,731:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:54:32,822:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,883:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,884:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:54:32,884:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:54:32,885:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-21 08:54:32,969:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:54:33,022:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:54:33,022:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:54:33,122:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:54:33,170:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:54:33,170:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:54:33,170:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-21 08:54:33,323:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:54:33,323:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:54:33,469:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:54:33,469:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:54:33,469:INFO:Preparing preprocessing pipeline...
2023-10-21 08:54:33,469:INFO:Set up simple imputation.
2023-10-21 08:54:33,485:INFO:Set up column name cleaning.
2023-10-21 08:54:33,532:INFO:Finished creating preprocessing pipeline.
2023-10-21 08:54:33,532:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 08:54:33,532:INFO:Creating final display dataframe.
2023-10-21 08:54:33,702:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (32819, 39)
4        Transformed data shape   (32819, 39)
5   Transformed train set shape   (22973, 39)
6    Transformed test set shape    (9846, 39)
7              Numeric features            38
8      Rows with missing values         19.9%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_B
19                          USI          024c
2023-10-21 08:54:33,901:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:54:33,901:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:54:34,103:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:54:34,103:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:54:34,103:INFO:Logging experiment in loggers
2023-10-21 08:54:34,225:INFO:SubProcess save_model() called ==================================
2023-10-21 08:54:34,234:INFO:Initializing save_model()
2023-10-21 08:54:34,234:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmpov9bwx63\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 08:54:34,234:INFO:Adding model into prep_pipe
2023-10-21 08:54:34,234:WARNING:Only Model saved as it was a pipeline.
2023-10-21 08:54:34,234:INFO:C:\Users\thoma\AppData\Local\Temp\tmpov9bwx63\Transformation Pipeline.pkl saved in current working directory
2023-10-21 08:54:34,249:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 08:54:34,249:INFO:save_model() successfully completed......................................
2023-10-21 08:54:34,370:INFO:SubProcess save_model() end ==================================
2023-10-21 08:54:34,433:INFO:setup() successfully completed in 2.55s...............
2023-10-21 08:54:34,433:INFO:Initializing create_model()
2023-10-21 08:54:34,433:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E3690730>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 08:54:34,433:INFO:Checking exceptions
2023-10-21 08:54:34,433:INFO:Importing libraries
2023-10-21 08:54:34,433:INFO:Copying training dataset
2023-10-21 08:54:34,448:INFO:Defining folds
2023-10-21 08:54:34,448:INFO:Declaring metric variables
2023-10-21 08:54:34,448:INFO:Importing untrained model
2023-10-21 08:54:34,448:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 08:54:34,448:INFO:Starting cross validation
2023-10-21 08:54:34,448:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 08:54:37,332:INFO:Calculating mean and std
2023-10-21 08:54:37,332:INFO:Creating metrics dataframe
2023-10-21 08:54:37,332:INFO:Finalizing model
2023-10-21 08:54:37,398:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003893 seconds.
2023-10-21 08:54:37,398:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 08:54:37,398:INFO:[LightGBM] [Info] Total Bins 6163
2023-10-21 08:54:37,398:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 37
2023-10-21 08:54:37,398:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-21 08:54:37,602:INFO:Creating Dashboard logs
2023-10-21 08:54:37,618:INFO:Model: Light Gradient Boosting Machine
2023-10-21 08:54:37,702:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 08:54:37,879:INFO:Initializing predict_model()
2023-10-21 08:54:37,879:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E3690730>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209D70B8160>)
2023-10-21 08:54:37,879:INFO:Checking exceptions
2023-10-21 08:54:37,879:INFO:Preloading libraries
2023-10-21 08:54:38,375:INFO:Uploading results into container
2023-10-21 08:54:38,376:INFO:Uploading model into container now
2023-10-21 08:54:38,378:INFO:_master_model_container: 1
2023-10-21 08:54:38,378:INFO:_display_container: 2
2023-10-21 08:54:38,378:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 08:54:38,378:INFO:create_model() successfully completed......................................
2023-10-21 08:54:38,511:INFO:Initializing tune_model()
2023-10-21 08:54:38,511:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E3690730>)
2023-10-21 08:54:38,511:INFO:Checking exceptions
2023-10-21 08:54:38,526:INFO:Copying training dataset
2023-10-21 08:54:38,536:INFO:Checking base model
2023-10-21 08:54:38,536:INFO:Base model : Light Gradient Boosting Machine
2023-10-21 08:54:38,536:INFO:Declaring metric variables
2023-10-21 08:54:38,536:INFO:Defining Hyperparameters
2023-10-21 08:54:38,677:INFO:Tuning with n_jobs=-1
2023-10-21 08:54:38,677:INFO:Initializing RandomizedSearchCV
2023-10-21 08:55:25,730:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-21 08:55:25,730:INFO:Hyperparameter search completed
2023-10-21 08:55:25,730:INFO:SubProcess create_model() called ==================================
2023-10-21 08:55:25,730:INFO:Initializing create_model()
2023-10-21 08:55:25,730:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E3690730>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E373BC10>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-21 08:55:25,730:INFO:Checking exceptions
2023-10-21 08:55:25,730:INFO:Importing libraries
2023-10-21 08:55:25,730:INFO:Copying training dataset
2023-10-21 08:55:25,761:INFO:Defining folds
2023-10-21 08:55:25,761:INFO:Declaring metric variables
2023-10-21 08:55:25,761:INFO:Importing untrained model
2023-10-21 08:55:25,761:INFO:Declaring custom model
2023-10-21 08:55:25,761:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 08:55:25,761:INFO:Starting cross validation
2023-10-21 08:55:25,761:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 08:55:35,480:INFO:Calculating mean and std
2023-10-21 08:55:35,484:INFO:Creating metrics dataframe
2023-10-21 08:55:35,486:INFO:Finalizing model
2023-10-21 08:55:35,519:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 08:55:35,519:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 08:55:35,519:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 08:55:35,553:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 08:55:35,553:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 08:55:35,553:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 08:55:35,553:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001322 seconds.
2023-10-21 08:55:35,553:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-21 08:55:35,553:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-21 08:55:35,553:INFO:[LightGBM] [Info] Total Bins 6163
2023-10-21 08:55:35,553:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 37
2023-10-21 08:55:35,565:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-21 08:55:36,930:INFO:Uploading results into container
2023-10-21 08:55:36,930:INFO:Uploading model into container now
2023-10-21 08:55:36,930:INFO:_master_model_container: 2
2023-10-21 08:55:36,930:INFO:_display_container: 3
2023-10-21 08:55:36,930:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-21 08:55:36,930:INFO:create_model() successfully completed......................................
2023-10-21 08:55:37,084:INFO:SubProcess create_model() end ==================================
2023-10-21 08:55:37,084:INFO:choose_better activated
2023-10-21 08:55:37,084:INFO:SubProcess create_model() called ==================================
2023-10-21 08:55:37,084:INFO:Initializing create_model()
2023-10-21 08:55:37,084:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E3690730>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 08:55:37,084:INFO:Checking exceptions
2023-10-21 08:55:37,096:INFO:Importing libraries
2023-10-21 08:55:37,097:INFO:Copying training dataset
2023-10-21 08:55:37,114:INFO:Defining folds
2023-10-21 08:55:37,114:INFO:Declaring metric variables
2023-10-21 08:55:37,114:INFO:Importing untrained model
2023-10-21 08:55:37,114:INFO:Declaring custom model
2023-10-21 08:55:37,114:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 08:55:37,114:INFO:Starting cross validation
2023-10-21 08:55:37,114:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 08:55:40,094:INFO:Calculating mean and std
2023-10-21 08:55:40,094:INFO:Creating metrics dataframe
2023-10-21 08:55:40,094:INFO:Finalizing model
2023-10-21 08:55:40,173:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005807 seconds.
2023-10-21 08:55:40,174:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 08:55:40,174:INFO:[LightGBM] [Info] Total Bins 6163
2023-10-21 08:55:40,175:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 37
2023-10-21 08:55:40,175:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-21 08:55:40,418:INFO:Uploading results into container
2023-10-21 08:55:40,418:INFO:Uploading model into container now
2023-10-21 08:55:40,418:INFO:_master_model_container: 3
2023-10-21 08:55:40,418:INFO:_display_container: 4
2023-10-21 08:55:40,418:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 08:55:40,418:INFO:create_model() successfully completed......................................
2023-10-21 08:55:40,577:INFO:SubProcess create_model() end ==================================
2023-10-21 08:55:40,578:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.836
2023-10-21 08:55:40,579:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8394
2023-10-21 08:55:40,579:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) is best model
2023-10-21 08:55:40,579:INFO:choose_better completed
2023-10-21 08:55:40,580:INFO:Creating Dashboard logs
2023-10-21 08:55:40,580:INFO:Model: Light Gradient Boosting Machine
2023-10-21 08:55:40,631:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 41, 'min_child_weight': 0.001, 'min_split_gain': 0.9, 'n_estimators': 260, 'n_jobs': -1, 'num_leaves': 70, 'objective': None, 'random_state': 123, 'reg_alpha': 2, 'reg_lambda': 3, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6}
2023-10-21 08:55:40,810:INFO:Initializing predict_model()
2023-10-21 08:55:40,810:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E3690730>, estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DCE7EAF0>)
2023-10-21 08:55:40,810:INFO:Checking exceptions
2023-10-21 08:55:40,810:INFO:Preloading libraries
2023-10-21 08:55:41,393:INFO:_master_model_container: 3
2023-10-21 08:55:41,393:INFO:_display_container: 3
2023-10-21 08:55:41,393:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-21 08:55:41,393:INFO:tune_model() successfully completed......................................
2023-10-21 08:55:41,515:INFO:Initializing finalize_model()
2023-10-21 08:55:41,515:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E3690730>, estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-21 08:55:41,515:INFO:Finalizing LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-21 08:55:41,527:INFO:Initializing create_model()
2023-10-21 08:55:41,527:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E3690730>, estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-21 08:55:41,527:INFO:Checking exceptions
2023-10-21 08:55:41,527:INFO:Importing libraries
2023-10-21 08:55:41,527:INFO:Copying training dataset
2023-10-21 08:55:41,527:INFO:Defining folds
2023-10-21 08:55:41,527:INFO:Declaring metric variables
2023-10-21 08:55:41,527:INFO:Importing untrained model
2023-10-21 08:55:41,527:INFO:Declaring custom model
2023-10-21 08:55:41,527:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 08:55:41,527:INFO:Cross validation set to False
2023-10-21 08:55:41,527:INFO:Fitting Model
2023-10-21 08:55:41,576:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 08:55:41,576:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 08:55:41,576:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 08:55:41,609:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 08:55:41,609:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 08:55:41,609:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 08:55:41,629:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006571 seconds.
2023-10-21 08:55:41,629:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 08:55:41,629:INFO:[LightGBM] [Info] Total Bins 6208
2023-10-21 08:55:41,631:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 37
2023-10-21 08:55:41,632:INFO:[LightGBM] [Info] Start training from score 96.893335
2023-10-21 08:55:42,825:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                               feature_fraction=0.4, min_child_samples=41,
                               min_split_gain=0.9, n_estimators=260, n_jobs=-1,
                               num_leaves=70, random_state=123, reg_alpha=2,
                               reg_lambda=3))])
2023-10-21 08:55:42,825:INFO:create_model() successfully completed......................................
2023-10-21 08:55:42,978:INFO:Creating Dashboard logs
2023-10-21 08:55:42,978:INFO:Model: Light Gradient Boosting Machine
2023-10-21 08:55:43,042:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 41, 'min_child_weight': 0.001, 'min_split_gain': 0.9, 'n_estimators': 260, 'n_jobs': -1, 'num_leaves': 70, 'objective': None, 'random_state': 123, 'reg_alpha': 2, 'reg_lambda': 3, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6}
2023-10-21 08:55:43,426:INFO:_master_model_container: 3
2023-10-21 08:55:43,426:INFO:_display_container: 3
2023-10-21 08:55:43,430:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                               feature_fraction=0.4, min_child_samples=41,
                               min_split_gain=0.9, n_estimators=260, n_jobs=-1,
                               num_leaves=70, random_state=123, reg_alpha=2,
                               reg_lambda=3))])
2023-10-21 08:55:43,430:INFO:finalize_model() successfully completed......................................
2023-10-21 08:55:43,560:INFO:Initializing save_model()
2023-10-21 08:55:43,560:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                               feature_fraction=0.4, min_child_samples=41,
                               min_split_gain=0.9, n_estimators=260, n_jobs=-1,
                               num_leaves=70, random_state=123, reg_alpha=2,
                               reg_lambda=3))]), model_name=final_model_for_location_B, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 08:55:43,560:INFO:Adding model into prep_pipe
2023-10-21 08:55:43,560:WARNING:Only Model saved as it was a pipeline.
2023-10-21 08:55:43,608:INFO:final_model_for_location_B.pkl saved in current working directory
2023-10-21 08:55:43,627:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                               feature_fraction=0.4, min_child_samples=41,
                               min_split_gain=0.9, n_estimators=260, n_jobs=-1,
                               num_leaves=70, random_state=123, reg_alpha=2,
                               reg_lambda=3))])
2023-10-21 08:55:43,627:INFO:save_model() successfully completed......................................
2023-10-21 08:55:43,791:INFO:PyCaret RegressionExperiment
2023-10-21 08:55:43,791:INFO:Logging name: exp_C
2023-10-21 08:55:43,791:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-21 08:55:43,791:INFO:version 3.1.0
2023-10-21 08:55:43,791:INFO:Initializing setup()
2023-10-21 08:55:43,791:INFO:self.USI: f8e8
2023-10-21 08:55:43,792:INFO:self._variable_keys: {'transform_target_param', 'exp_name_log', 'y_train', 'logging_param', 'n_jobs_param', 'X_train', 'target_param', 'USI', 'gpu_n_jobs_param', 'fold_groups_param', '_ml_usecase', 'seed', 'fold_generator', 'idx', 'html_param', 'log_plots_param', 'y', 'gpu_param', 'X_test', 'memory', 'y_test', 'data', 'X', 'exp_id', '_available_plots', 'fold_shuffle_param', 'pipeline'}
2023-10-21 08:55:43,792:INFO:Checking environment
2023-10-21 08:55:43,792:INFO:python_version: 3.8.18
2023-10-21 08:55:43,792:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-21 08:55:43,792:INFO:machine: AMD64
2023-10-21 08:55:43,792:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-21 08:55:43,792:INFO:Memory: svmem(total=16505954304, available=3406655488, percent=79.4, used=13099298816, free=3406655488)
2023-10-21 08:55:43,792:INFO:Physical Core: 8
2023-10-21 08:55:43,792:INFO:Logical Core: 16
2023-10-21 08:55:43,792:INFO:Checking libraries
2023-10-21 08:55:43,792:INFO:System:
2023-10-21 08:55:43,792:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-21 08:55:43,792:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-21 08:55:43,792:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-21 08:55:43,792:INFO:PyCaret required dependencies:
2023-10-21 08:55:43,792:INFO:                 pip: 23.3
2023-10-21 08:55:43,792:INFO:          setuptools: 68.0.0
2023-10-21 08:55:43,792:INFO:             pycaret: 3.1.0
2023-10-21 08:55:43,792:INFO:             IPython: 8.12.0
2023-10-21 08:55:43,792:INFO:          ipywidgets: 8.1.1
2023-10-21 08:55:43,792:INFO:                tqdm: 4.66.1
2023-10-21 08:55:43,792:INFO:               numpy: 1.23.5
2023-10-21 08:55:43,792:INFO:              pandas: 1.5.3
2023-10-21 08:55:43,792:INFO:              jinja2: 3.1.2
2023-10-21 08:55:43,792:INFO:               scipy: 1.10.1
2023-10-21 08:55:43,792:INFO:              joblib: 1.3.2
2023-10-21 08:55:43,792:INFO:             sklearn: 1.2.2
2023-10-21 08:55:43,792:INFO:                pyod: 1.1.0
2023-10-21 08:55:43,792:INFO:            imblearn: 0.11.0
2023-10-21 08:55:43,792:INFO:   category_encoders: 2.6.2
2023-10-21 08:55:43,792:INFO:            lightgbm: 4.1.0
2023-10-21 08:55:43,792:INFO:               numba: 0.58.1
2023-10-21 08:55:43,792:INFO:            requests: 2.31.0
2023-10-21 08:55:43,792:INFO:          matplotlib: 3.7.3
2023-10-21 08:55:43,792:INFO:          scikitplot: 0.3.7
2023-10-21 08:55:43,792:INFO:         yellowbrick: 1.5
2023-10-21 08:55:43,792:INFO:              plotly: 5.17.0
2023-10-21 08:55:43,792:INFO:    plotly-resampler: Not installed
2023-10-21 08:55:43,792:INFO:             kaleido: 0.2.1
2023-10-21 08:55:43,792:INFO:           schemdraw: 0.15
2023-10-21 08:55:43,792:INFO:         statsmodels: 0.14.0
2023-10-21 08:55:43,792:INFO:              sktime: 0.21.1
2023-10-21 08:55:43,792:INFO:               tbats: 1.1.3
2023-10-21 08:55:43,792:INFO:            pmdarima: 2.0.3
2023-10-21 08:55:43,792:INFO:              psutil: 5.9.0
2023-10-21 08:55:43,792:INFO:          markupsafe: 2.1.3
2023-10-21 08:55:43,792:INFO:             pickle5: Not installed
2023-10-21 08:55:43,792:INFO:         cloudpickle: 2.2.1
2023-10-21 08:55:43,792:INFO:         deprecation: 2.1.0
2023-10-21 08:55:43,792:INFO:              xxhash: 3.4.1
2023-10-21 08:55:43,792:INFO:           wurlitzer: Not installed
2023-10-21 08:55:43,792:INFO:PyCaret optional dependencies:
2023-10-21 08:55:43,792:INFO:                shap: Not installed
2023-10-21 08:55:43,792:INFO:           interpret: Not installed
2023-10-21 08:55:43,792:INFO:                umap: Not installed
2023-10-21 08:55:43,792:INFO:     ydata_profiling: Not installed
2023-10-21 08:55:43,792:INFO:  explainerdashboard: Not installed
2023-10-21 08:55:43,792:INFO:             autoviz: Not installed
2023-10-21 08:55:43,792:INFO:           fairlearn: Not installed
2023-10-21 08:55:43,792:INFO:          deepchecks: Not installed
2023-10-21 08:55:43,792:INFO:             xgboost: Not installed
2023-10-21 08:55:43,792:INFO:            catboost: 1.2.2
2023-10-21 08:55:43,792:INFO:              kmodes: Not installed
2023-10-21 08:55:43,792:INFO:             mlxtend: Not installed
2023-10-21 08:55:43,792:INFO:       statsforecast: Not installed
2023-10-21 08:55:43,792:INFO:        tune_sklearn: Not installed
2023-10-21 08:55:43,792:INFO:                 ray: Not installed
2023-10-21 08:55:43,792:INFO:            hyperopt: Not installed
2023-10-21 08:55:43,792:INFO:              optuna: Not installed
2023-10-21 08:55:43,792:INFO:               skopt: Not installed
2023-10-21 08:55:43,792:INFO:              mlflow: 2.7.1
2023-10-21 08:55:43,792:INFO:              gradio: Not installed
2023-10-21 08:55:43,792:INFO:             fastapi: Not installed
2023-10-21 08:55:43,792:INFO:             uvicorn: Not installed
2023-10-21 08:55:43,792:INFO:              m2cgen: Not installed
2023-10-21 08:55:43,792:INFO:           evidently: Not installed
2023-10-21 08:55:43,792:INFO:               fugue: Not installed
2023-10-21 08:55:43,792:INFO:           streamlit: Not installed
2023-10-21 08:55:43,792:INFO:             prophet: Not installed
2023-10-21 08:55:43,792:INFO:None
2023-10-21 08:55:43,792:INFO:Set up data.
2023-10-21 08:55:43,825:INFO:Set up folding strategy.
2023-10-21 08:55:43,825:INFO:Set up train/test split.
2023-10-21 08:55:43,847:INFO:Set up index.
2023-10-21 08:55:43,847:INFO:Assigning column types.
2023-10-21 08:55:43,860:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-21 08:55:43,860:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 08:55:43,873:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 08:55:43,875:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:55:43,945:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:55:43,991:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,007:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:55:44,007:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:55:44,008:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,008:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,008:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,091:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,140:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,141:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:55:44,142:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:55:44,142:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-21 08:55:44,142:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,142:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,224:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,274:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,274:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:55:44,274:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:55:44,274:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,290:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,363:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,425:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,426:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:55:44,426:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:55:44,427:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-21 08:55:44,428:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,508:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,560:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,560:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:55:44,560:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:55:44,576:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,641:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,694:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,694:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:55:44,694:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:55:44,694:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-21 08:55:44,797:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,856:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,857:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:55:44,857:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:55:44,947:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:55:45,007:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:55:45,008:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:55:45,009:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:55:45,009:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-21 08:55:45,095:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:55:45,149:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:55:45,149:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:55:45,235:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:55:45,273:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:55:45,273:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:55:45,273:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-21 08:55:45,430:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:55:45,431:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:55:45,581:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:55:45,581:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:55:45,581:INFO:Preparing preprocessing pipeline...
2023-10-21 08:55:45,581:INFO:Set up simple imputation.
2023-10-21 08:55:45,590:INFO:Set up column name cleaning.
2023-10-21 08:55:45,644:INFO:Finished creating preprocessing pipeline.
2023-10-21 08:55:45,649:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 08:55:45,649:INFO:Creating final display dataframe.
2023-10-21 08:55:45,828:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (26071, 39)
4        Transformed data shape   (26071, 39)
5   Transformed train set shape   (18249, 39)
6    Transformed test set shape    (7822, 39)
7              Numeric features            38
8      Rows with missing values         25.0%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_C
19                          USI          f8e8
2023-10-21 08:55:45,974:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:55:45,974:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:55:46,106:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:55:46,106:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:55:46,106:INFO:Logging experiment in loggers
2023-10-21 08:55:46,263:INFO:SubProcess save_model() called ==================================
2023-10-21 08:55:46,278:INFO:Initializing save_model()
2023-10-21 08:55:46,278:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmp20uec8o6\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 08:55:46,278:INFO:Adding model into prep_pipe
2023-10-21 08:55:46,278:WARNING:Only Model saved as it was a pipeline.
2023-10-21 08:55:46,280:INFO:C:\Users\thoma\AppData\Local\Temp\tmp20uec8o6\Transformation Pipeline.pkl saved in current working directory
2023-10-21 08:55:46,291:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 08:55:46,291:INFO:save_model() successfully completed......................................
2023-10-21 08:55:46,439:INFO:SubProcess save_model() end ==================================
2023-10-21 08:55:46,520:INFO:setup() successfully completed in 2.33s...............
2023-10-21 08:55:46,520:INFO:Initializing create_model()
2023-10-21 08:55:46,520:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 08:55:46,520:INFO:Checking exceptions
2023-10-21 08:55:46,526:INFO:Importing libraries
2023-10-21 08:55:46,526:INFO:Copying training dataset
2023-10-21 08:55:46,545:INFO:Defining folds
2023-10-21 08:55:46,546:INFO:Declaring metric variables
2023-10-21 08:55:46,546:INFO:Importing untrained model
2023-10-21 08:55:46,546:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 08:55:46,547:INFO:Starting cross validation
2023-10-21 08:55:46,548:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 08:55:49,622:INFO:Calculating mean and std
2023-10-21 08:55:49,622:INFO:Creating metrics dataframe
2023-10-21 08:55:49,622:INFO:Finalizing model
2023-10-21 08:55:49,728:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004660 seconds.
2023-10-21 08:55:49,728:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 08:55:49,728:INFO:[LightGBM] [Info] Total Bins 6153
2023-10-21 08:55:49,728:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 37
2023-10-21 08:55:49,728:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-21 08:55:50,025:INFO:Creating Dashboard logs
2023-10-21 08:55:50,027:INFO:Model: Light Gradient Boosting Machine
2023-10-21 08:55:50,137:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 08:55:50,336:INFO:Initializing predict_model()
2023-10-21 08:55:50,336:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209D6F36CA0>)
2023-10-21 08:55:50,337:INFO:Checking exceptions
2023-10-21 08:55:50,337:INFO:Preloading libraries
2023-10-21 08:55:50,887:INFO:Uploading results into container
2023-10-21 08:55:50,887:INFO:Uploading model into container now
2023-10-21 08:55:50,887:INFO:_master_model_container: 1
2023-10-21 08:55:50,903:INFO:_display_container: 2
2023-10-21 08:55:50,903:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 08:55:50,903:INFO:create_model() successfully completed......................................
2023-10-21 08:55:51,043:INFO:Initializing tune_model()
2023-10-21 08:55:51,043:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>)
2023-10-21 08:55:51,043:INFO:Checking exceptions
2023-10-21 08:55:51,055:INFO:Copying training dataset
2023-10-21 08:55:51,068:INFO:Checking base model
2023-10-21 08:55:51,068:INFO:Base model : Light Gradient Boosting Machine
2023-10-21 08:55:51,069:INFO:Declaring metric variables
2023-10-21 08:55:51,070:INFO:Defining Hyperparameters
2023-10-21 08:55:51,224:INFO:Tuning with n_jobs=-1
2023-10-21 08:55:51,225:INFO:Initializing RandomizedSearchCV
2023-10-21 08:56:36,065:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-21 08:56:36,068:INFO:Hyperparameter search completed
2023-10-21 08:56:36,068:INFO:SubProcess create_model() called ==================================
2023-10-21 08:56:36,069:INFO:Initializing create_model()
2023-10-21 08:56:36,069:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E421AF10>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-21 08:56:36,069:INFO:Checking exceptions
2023-10-21 08:56:36,070:INFO:Importing libraries
2023-10-21 08:56:36,070:INFO:Copying training dataset
2023-10-21 08:56:36,094:INFO:Defining folds
2023-10-21 08:56:36,094:INFO:Declaring metric variables
2023-10-21 08:56:36,094:INFO:Importing untrained model
2023-10-21 08:56:36,094:INFO:Declaring custom model
2023-10-21 08:56:36,094:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 08:56:36,097:INFO:Starting cross validation
2023-10-21 08:56:36,099:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 08:56:45,640:INFO:Calculating mean and std
2023-10-21 08:56:45,640:INFO:Creating metrics dataframe
2023-10-21 08:56:45,640:INFO:Finalizing model
2023-10-21 08:56:45,679:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 08:56:45,679:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 08:56:45,679:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 08:56:45,696:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 08:56:45,696:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 08:56:45,696:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 08:56:45,696:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002809 seconds.
2023-10-21 08:56:45,696:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 08:56:45,696:INFO:[LightGBM] [Info] Total Bins 6153
2023-10-21 08:56:45,706:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 37
2023-10-21 08:56:45,707:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-21 08:56:45,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 08:56:45,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 08:56:45,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 08:56:45,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 08:56:46,706:INFO:Uploading results into container
2023-10-21 08:56:46,706:INFO:Uploading model into container now
2023-10-21 08:56:46,706:INFO:_master_model_container: 2
2023-10-21 08:56:46,706:INFO:_display_container: 3
2023-10-21 08:56:46,706:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-21 08:56:46,706:INFO:create_model() successfully completed......................................
2023-10-21 08:56:46,873:INFO:SubProcess create_model() end ==================================
2023-10-21 08:56:46,873:INFO:choose_better activated
2023-10-21 08:56:46,873:INFO:SubProcess create_model() called ==================================
2023-10-21 08:56:46,873:INFO:Initializing create_model()
2023-10-21 08:56:46,873:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 08:56:46,873:INFO:Checking exceptions
2023-10-21 08:56:46,873:INFO:Importing libraries
2023-10-21 08:56:46,873:INFO:Copying training dataset
2023-10-21 08:56:46,896:INFO:Defining folds
2023-10-21 08:56:46,896:INFO:Declaring metric variables
2023-10-21 08:56:46,896:INFO:Importing untrained model
2023-10-21 08:56:46,896:INFO:Declaring custom model
2023-10-21 08:56:46,896:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 08:56:46,896:INFO:Starting cross validation
2023-10-21 08:56:46,896:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 08:56:49,187:INFO:Calculating mean and std
2023-10-21 08:56:49,187:INFO:Creating metrics dataframe
2023-10-21 08:56:49,187:INFO:Finalizing model
2023-10-21 08:56:49,254:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003392 seconds.
2023-10-21 08:56:49,254:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 08:56:49,254:INFO:[LightGBM] [Info] Total Bins 6153
2023-10-21 08:56:49,254:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 37
2023-10-21 08:56:49,254:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-21 08:56:49,487:INFO:Uploading results into container
2023-10-21 08:56:49,487:INFO:Uploading model into container now
2023-10-21 08:56:49,487:INFO:_master_model_container: 3
2023-10-21 08:56:49,487:INFO:_display_container: 4
2023-10-21 08:56:49,487:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 08:56:49,487:INFO:create_model() successfully completed......................................
2023-10-21 08:56:49,635:INFO:SubProcess create_model() end ==================================
2023-10-21 08:56:49,636:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.9008
2023-10-21 08:56:49,637:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8936
2023-10-21 08:56:49,637:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-21 08:56:49,637:INFO:choose_better completed
2023-10-21 08:56:49,637:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-21 08:56:49,637:INFO:Creating Dashboard logs
2023-10-21 08:56:49,637:INFO:Model: Light Gradient Boosting Machine
2023-10-21 08:56:49,698:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 08:56:49,871:INFO:Initializing predict_model()
2023-10-21 08:56:49,871:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209D6F36310>)
2023-10-21 08:56:49,871:INFO:Checking exceptions
2023-10-21 08:56:49,871:INFO:Preloading libraries
2023-10-21 08:56:50,355:INFO:_master_model_container: 3
2023-10-21 08:56:50,369:INFO:_display_container: 3
2023-10-21 08:56:50,369:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 08:56:50,369:INFO:tune_model() successfully completed......................................
2023-10-21 08:56:50,490:INFO:Initializing finalize_model()
2023-10-21 08:56:50,490:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-21 08:56:50,490:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 08:56:50,500:INFO:Initializing create_model()
2023-10-21 08:56:50,506:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-21 08:56:50,506:INFO:Checking exceptions
2023-10-21 08:56:50,506:INFO:Importing libraries
2023-10-21 08:56:50,506:INFO:Copying training dataset
2023-10-21 08:56:50,506:INFO:Defining folds
2023-10-21 08:56:50,506:INFO:Declaring metric variables
2023-10-21 08:56:50,506:INFO:Importing untrained model
2023-10-21 08:56:50,506:INFO:Declaring custom model
2023-10-21 08:56:50,506:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 08:56:50,506:INFO:Cross validation set to False
2023-10-21 08:56:50,506:INFO:Fitting Model
2023-10-21 08:56:50,579:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004880 seconds.
2023-10-21 08:56:50,579:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 08:56:50,579:INFO:[LightGBM] [Info] Total Bins 6199
2023-10-21 08:56:50,579:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 37
2023-10-21 08:56:50,579:INFO:[LightGBM] [Info] Start training from score 77.700043
2023-10-21 08:56:50,820:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-21 08:56:50,820:INFO:create_model() successfully completed......................................
2023-10-21 08:56:50,973:INFO:Creating Dashboard logs
2023-10-21 08:56:50,973:INFO:Model: Light Gradient Boosting Machine
2023-10-21 08:56:51,035:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 08:56:51,351:INFO:_master_model_container: 3
2023-10-21 08:56:51,351:INFO:_display_container: 3
2023-10-21 08:56:51,351:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-21 08:56:51,351:INFO:finalize_model() successfully completed......................................
2023-10-21 08:56:51,489:INFO:Initializing save_model()
2023-10-21 08:56:51,489:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_C, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 08:56:51,489:INFO:Adding model into prep_pipe
2023-10-21 08:56:51,489:WARNING:Only Model saved as it was a pipeline.
2023-10-21 08:56:51,504:INFO:final_model_for_location_C.pkl saved in current working directory
2023-10-21 08:56:51,520:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-21 08:56:51,520:INFO:save_model() successfully completed......................................
2023-10-21 08:56:52,850:INFO:Initializing load_model()
2023-10-21 08:56:52,851:INFO:load_model(model_name=final_model_for_location_A, platform=None, authentication=None, verbose=True)
2023-10-21 08:56:52,866:INFO:Initializing load_model()
2023-10-21 08:56:52,866:INFO:load_model(model_name=final_model_for_location_B, platform=None, authentication=None, verbose=True)
2023-10-21 08:56:52,897:INFO:Initializing load_model()
2023-10-21 08:56:52,898:INFO:load_model(model_name=final_model_for_location_C, platform=None, authentication=None, verbose=True)
2023-10-21 08:56:52,933:INFO:Initializing predict_model()
2023-10-21 08:56:52,934:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DCC6AF70>)
2023-10-21 08:56:52,934:INFO:Checking exceptions
2023-10-21 08:56:52,934:INFO:Preloading libraries
2023-10-21 08:56:52,935:INFO:Set up data.
2023-10-21 08:56:52,959:INFO:Set up index.
2023-10-21 08:56:53,157:INFO:Initializing predict_model()
2023-10-21 08:56:53,157:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                               feature_fraction=0.4, min_child_samples=41,
                               min_split_gain=0.9, n_estimators=260, n_jobs=-1,
                               num_leaves=70, random_state=123, reg_alpha=2,
                               reg_lambda=3))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209D98B08B0>)
2023-10-21 08:56:53,157:INFO:Checking exceptions
2023-10-21 08:56:53,157:INFO:Preloading libraries
2023-10-21 08:56:53,157:INFO:Set up data.
2023-10-21 08:56:53,170:INFO:Set up index.
2023-10-21 08:56:53,398:INFO:Initializing predict_model()
2023-10-21 08:56:53,398:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209D98B08B0>)
2023-10-21 08:56:53,398:INFO:Checking exceptions
2023-10-21 08:56:53,398:INFO:Preloading libraries
2023-10-21 08:56:53,399:INFO:Set up data.
2023-10-21 08:56:53,412:INFO:Set up index.
2023-10-21 08:59:42,011:INFO:Initializing load_model()
2023-10-21 08:59:42,012:INFO:load_model(model_name=final_model_for_location_A, platform=None, authentication=None, verbose=True)
2023-10-21 08:59:42,013:INFO:Initializing load_model()
2023-10-21 08:59:42,013:INFO:load_model(model_name=final_model_for_location_B, platform=None, authentication=None, verbose=True)
2023-10-21 08:59:42,040:INFO:Initializing load_model()
2023-10-21 08:59:42,041:INFO:load_model(model_name=final_model_for_location_C, platform=None, authentication=None, verbose=True)
2023-10-21 08:59:42,063:INFO:Initializing predict_model()
2023-10-21 08:59:42,063:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209D5905EE0>)
2023-10-21 08:59:42,064:INFO:Checking exceptions
2023-10-21 08:59:42,064:INFO:Preloading libraries
2023-10-21 08:59:42,064:INFO:Set up data.
2023-10-21 08:59:42,078:INFO:Set up index.
2023-10-21 08:59:42,293:INFO:Initializing predict_model()
2023-10-21 08:59:42,293:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                               feature_fraction=0.4, min_child_samples=41,
                               min_split_gain=0.9, n_estimators=260, n_jobs=-1,
                               num_leaves=70, random_state=123, reg_alpha=2,
                               reg_lambda=3))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209D5905EE0>)
2023-10-21 08:59:42,293:INFO:Checking exceptions
2023-10-21 08:59:42,293:INFO:Preloading libraries
2023-10-21 08:59:42,294:INFO:Set up data.
2023-10-21 08:59:42,297:INFO:Set up index.
2023-10-21 08:59:42,516:INFO:Initializing predict_model()
2023-10-21 08:59:42,516:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209D5905EE0>)
2023-10-21 08:59:42,516:INFO:Checking exceptions
2023-10-21 08:59:42,516:INFO:Preloading libraries
2023-10-21 08:59:42,516:INFO:Set up data.
2023-10-21 08:59:42,533:INFO:Set up index.
2023-10-21 09:00:42,577:INFO:Initializing load_model()
2023-10-21 09:00:42,577:INFO:load_model(model_name=final_model_for_location_A, platform=None, authentication=None, verbose=True)
2023-10-21 09:00:42,589:INFO:Initializing load_model()
2023-10-21 09:00:42,589:INFO:load_model(model_name=final_model_for_location_B, platform=None, authentication=None, verbose=True)
2023-10-21 09:00:42,611:INFO:Initializing load_model()
2023-10-21 09:00:42,611:INFO:load_model(model_name=final_model_for_location_C, platform=None, authentication=None, verbose=True)
2023-10-21 09:00:42,635:INFO:Initializing predict_model()
2023-10-21 09:00:42,635:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DACFEA60>)
2023-10-21 09:00:42,635:INFO:Checking exceptions
2023-10-21 09:00:42,635:INFO:Preloading libraries
2023-10-21 09:00:42,636:INFO:Set up data.
2023-10-21 09:00:42,653:INFO:Set up index.
2023-10-21 09:00:42,860:INFO:Initializing predict_model()
2023-10-21 09:00:42,861:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                               feature_fraction=0.4, min_child_samples=41,
                               min_split_gain=0.9, n_estimators=260, n_jobs=-1,
                               num_leaves=70, random_state=123, reg_alpha=2,
                               reg_lambda=3))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209E36DEE50>)
2023-10-21 09:00:42,862:INFO:Checking exceptions
2023-10-21 09:00:42,862:INFO:Preloading libraries
2023-10-21 09:00:42,862:INFO:Set up data.
2023-10-21 09:00:42,862:INFO:Set up index.
2023-10-21 09:00:43,079:INFO:Initializing predict_model()
2023-10-21 09:00:43,079:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209E36DEE50>)
2023-10-21 09:00:43,079:INFO:Checking exceptions
2023-10-21 09:00:43,079:INFO:Preloading libraries
2023-10-21 09:00:43,079:INFO:Set up data.
2023-10-21 09:00:43,096:INFO:Set up index.
2023-10-21 13:11:47,221:INFO:PyCaret RegressionExperiment
2023-10-21 13:11:47,221:INFO:Logging name: exp_A
2023-10-21 13:11:47,221:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-21 13:11:47,221:INFO:version 3.1.0
2023-10-21 13:11:47,221:INFO:Initializing setup()
2023-10-21 13:11:47,221:INFO:self.USI: 1fbb
2023-10-21 13:11:47,221:INFO:self._variable_keys: {'transform_target_param', 'exp_name_log', 'y_train', 'logging_param', 'n_jobs_param', 'X_train', 'target_param', 'USI', 'gpu_n_jobs_param', 'fold_groups_param', '_ml_usecase', 'seed', 'fold_generator', 'idx', 'html_param', 'log_plots_param', 'y', 'gpu_param', 'X_test', 'memory', 'y_test', 'data', 'X', 'exp_id', '_available_plots', 'fold_shuffle_param', 'pipeline'}
2023-10-21 13:11:47,221:INFO:Checking environment
2023-10-21 13:11:47,221:INFO:python_version: 3.8.18
2023-10-21 13:11:47,221:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-21 13:11:47,221:INFO:machine: AMD64
2023-10-21 13:11:47,221:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-21 13:11:47,221:INFO:Memory: svmem(total=16505954304, available=4054556672, percent=75.4, used=12451397632, free=4054556672)
2023-10-21 13:11:47,221:INFO:Physical Core: 8
2023-10-21 13:11:47,221:INFO:Logical Core: 16
2023-10-21 13:11:47,221:INFO:Checking libraries
2023-10-21 13:11:47,221:INFO:System:
2023-10-21 13:11:47,221:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-21 13:11:47,221:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-21 13:11:47,221:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-21 13:11:47,221:INFO:PyCaret required dependencies:
2023-10-21 13:11:47,221:INFO:                 pip: 23.3
2023-10-21 13:11:47,221:INFO:          setuptools: 68.0.0
2023-10-21 13:11:47,221:INFO:             pycaret: 3.1.0
2023-10-21 13:11:47,221:INFO:             IPython: 8.12.0
2023-10-21 13:11:47,221:INFO:          ipywidgets: 8.1.1
2023-10-21 13:11:47,221:INFO:                tqdm: 4.66.1
2023-10-21 13:11:47,221:INFO:               numpy: 1.23.5
2023-10-21 13:11:47,221:INFO:              pandas: 1.5.3
2023-10-21 13:11:47,221:INFO:              jinja2: 3.1.2
2023-10-21 13:11:47,221:INFO:               scipy: 1.10.1
2023-10-21 13:11:47,221:INFO:              joblib: 1.3.2
2023-10-21 13:11:47,221:INFO:             sklearn: 1.2.2
2023-10-21 13:11:47,221:INFO:                pyod: 1.1.0
2023-10-21 13:11:47,221:INFO:            imblearn: 0.11.0
2023-10-21 13:11:47,221:INFO:   category_encoders: 2.6.2
2023-10-21 13:11:47,221:INFO:            lightgbm: 4.1.0
2023-10-21 13:11:47,221:INFO:               numba: 0.58.1
2023-10-21 13:11:47,221:INFO:            requests: 2.31.0
2023-10-21 13:11:47,221:INFO:          matplotlib: 3.7.3
2023-10-21 13:11:47,221:INFO:          scikitplot: 0.3.7
2023-10-21 13:11:47,221:INFO:         yellowbrick: 1.5
2023-10-21 13:11:47,221:INFO:              plotly: 5.17.0
2023-10-21 13:11:47,221:INFO:    plotly-resampler: Not installed
2023-10-21 13:11:47,221:INFO:             kaleido: 0.2.1
2023-10-21 13:11:47,221:INFO:           schemdraw: 0.15
2023-10-21 13:11:47,221:INFO:         statsmodels: 0.14.0
2023-10-21 13:11:47,221:INFO:              sktime: 0.21.1
2023-10-21 13:11:47,221:INFO:               tbats: 1.1.3
2023-10-21 13:11:47,221:INFO:            pmdarima: 2.0.3
2023-10-21 13:11:47,221:INFO:              psutil: 5.9.0
2023-10-21 13:11:47,221:INFO:          markupsafe: 2.1.3
2023-10-21 13:11:47,221:INFO:             pickle5: Not installed
2023-10-21 13:11:47,221:INFO:         cloudpickle: 2.2.1
2023-10-21 13:11:47,221:INFO:         deprecation: 2.1.0
2023-10-21 13:11:47,221:INFO:              xxhash: 3.4.1
2023-10-21 13:11:47,221:INFO:           wurlitzer: Not installed
2023-10-21 13:11:47,221:INFO:PyCaret optional dependencies:
2023-10-21 13:11:47,221:INFO:                shap: Not installed
2023-10-21 13:11:47,221:INFO:           interpret: Not installed
2023-10-21 13:11:47,221:INFO:                umap: Not installed
2023-10-21 13:11:47,221:INFO:     ydata_profiling: Not installed
2023-10-21 13:11:47,221:INFO:  explainerdashboard: Not installed
2023-10-21 13:11:47,221:INFO:             autoviz: Not installed
2023-10-21 13:11:47,221:INFO:           fairlearn: Not installed
2023-10-21 13:11:47,221:INFO:          deepchecks: Not installed
2023-10-21 13:11:47,221:INFO:             xgboost: Not installed
2023-10-21 13:11:47,221:INFO:            catboost: 1.2.2
2023-10-21 13:11:47,221:INFO:              kmodes: Not installed
2023-10-21 13:11:47,221:INFO:             mlxtend: Not installed
2023-10-21 13:11:47,221:INFO:       statsforecast: Not installed
2023-10-21 13:11:47,221:INFO:        tune_sklearn: Not installed
2023-10-21 13:11:47,221:INFO:                 ray: Not installed
2023-10-21 13:11:47,221:INFO:            hyperopt: Not installed
2023-10-21 13:11:47,221:INFO:              optuna: Not installed
2023-10-21 13:11:47,221:INFO:               skopt: Not installed
2023-10-21 13:11:47,221:INFO:              mlflow: 2.7.1
2023-10-21 13:11:47,221:INFO:              gradio: Not installed
2023-10-21 13:11:47,221:INFO:             fastapi: Not installed
2023-10-21 13:11:47,221:INFO:             uvicorn: Not installed
2023-10-21 13:11:47,221:INFO:              m2cgen: Not installed
2023-10-21 13:11:47,221:INFO:           evidently: Not installed
2023-10-21 13:11:47,221:INFO:               fugue: Not installed
2023-10-21 13:11:47,221:INFO:           streamlit: Not installed
2023-10-21 13:11:47,221:INFO:             prophet: Not installed
2023-10-21 13:11:47,221:INFO:None
2023-10-21 13:11:47,221:INFO:Set up data.
2023-10-21 13:11:47,268:INFO:Set up folding strategy.
2023-10-21 13:11:47,268:INFO:Set up train/test split.
2023-10-21 13:11:47,312:INFO:Set up index.
2023-10-21 13:11:47,315:INFO:Assigning column types.
2023-10-21 13:11:47,347:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-21 13:11:47,347:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,347:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,347:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,442:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,512:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,512:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:11:47,512:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:11:47,512:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,521:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,521:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,616:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,679:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,679:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:11:47,679:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:11:47,679:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-21 13:11:47,695:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,695:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,790:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,838:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,838:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:11:47,838:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:11:47,854:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,854:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,949:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:11:48,013:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:11:48,028:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:11:48,028:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:11:48,028:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-21 13:11:48,044:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:11:48,145:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:11:48,194:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:11:48,195:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:11:48,195:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:11:48,206:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:11:48,279:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:11:48,329:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:11:48,329:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:11:48,329:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:11:48,329:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-21 13:11:48,428:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:11:48,487:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:11:48,487:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:11:48,488:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:11:48,578:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:11:48,629:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:11:48,629:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:11:48,629:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:11:48,629:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-21 13:11:48,730:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:11:48,787:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:11:48,787:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:11:48,884:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:11:48,942:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:11:48,942:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:11:48,943:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-21 13:11:49,113:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:11:49,114:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:11:49,283:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:11:49,283:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:11:49,283:INFO:Preparing preprocessing pipeline...
2023-10-21 13:11:49,283:INFO:Set up simple imputation.
2023-10-21 13:11:49,298:INFO:Set up column name cleaning.
2023-10-21 13:11:49,377:INFO:Finished creating preprocessing pipeline.
2023-10-21 13:11:49,393:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 13:11:49,393:INFO:Creating final display dataframe.
2023-10-21 13:11:49,720:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (34061, 50)
4        Transformed data shape   (34061, 50)
5   Transformed train set shape   (23842, 50)
6    Transformed test set shape   (10219, 50)
7              Numeric features            49
8      Rows with missing values         97.6%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_A
19                          USI          1fbb
2023-10-21 13:11:49,914:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:11:49,914:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:11:50,077:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:11:50,077:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:11:50,077:INFO:Logging experiment in loggers
2023-10-21 13:11:50,244:INFO:SubProcess save_model() called ==================================
2023-10-21 13:11:50,249:INFO:Initializing save_model()
2023-10-21 13:11:50,249:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmphuo33fa3\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 13:11:50,249:INFO:Adding model into prep_pipe
2023-10-21 13:11:50,249:WARNING:Only Model saved as it was a pipeline.
2023-10-21 13:11:50,262:INFO:C:\Users\thoma\AppData\Local\Temp\tmphuo33fa3\Transformation Pipeline.pkl saved in current working directory
2023-10-21 13:11:50,265:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 13:11:50,265:INFO:save_model() successfully completed......................................
2023-10-21 13:11:50,469:INFO:SubProcess save_model() end ==================================
2023-10-21 13:11:50,562:INFO:setup() successfully completed in 2.87s...............
2023-10-21 13:11:50,562:INFO:Initializing create_model()
2023-10-21 13:11:50,562:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6CC2520>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 13:11:50,562:INFO:Checking exceptions
2023-10-21 13:11:50,562:INFO:Importing libraries
2023-10-21 13:11:50,562:INFO:Copying training dataset
2023-10-21 13:11:50,593:INFO:Defining folds
2023-10-21 13:11:50,593:INFO:Declaring metric variables
2023-10-21 13:11:50,593:INFO:Importing untrained model
2023-10-21 13:11:50,595:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 13:11:50,595:INFO:Starting cross validation
2023-10-21 13:11:50,595:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 13:12:00,954:INFO:Calculating mean and std
2023-10-21 13:12:00,954:INFO:Creating metrics dataframe
2023-10-21 13:12:00,954:INFO:Finalizing model
2023-10-21 13:12:01,052:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006269 seconds.
2023-10-21 13:12:01,052:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 13:12:01,052:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 13:12:01,052:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 13:12:01,052:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-21 13:12:01,286:INFO:Creating Dashboard logs
2023-10-21 13:12:01,286:INFO:Model: Light Gradient Boosting Machine
2023-10-21 13:12:01,386:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 13:12:01,586:INFO:Initializing predict_model()
2023-10-21 13:12:01,586:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6CC2520>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DA6C63A0>)
2023-10-21 13:12:01,586:INFO:Checking exceptions
2023-10-21 13:12:01,586:INFO:Preloading libraries
2023-10-21 13:12:02,250:INFO:Uploading results into container
2023-10-21 13:12:02,250:INFO:Uploading model into container now
2023-10-21 13:12:02,250:INFO:_master_model_container: 1
2023-10-21 13:12:02,250:INFO:_display_container: 2
2023-10-21 13:12:02,250:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 13:12:02,250:INFO:create_model() successfully completed......................................
2023-10-21 13:12:02,433:INFO:Initializing tune_model()
2023-10-21 13:12:02,433:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6CC2520>)
2023-10-21 13:12:02,433:INFO:Checking exceptions
2023-10-21 13:12:02,434:INFO:Copying training dataset
2023-10-21 13:12:02,460:INFO:Checking base model
2023-10-21 13:12:02,461:INFO:Base model : Light Gradient Boosting Machine
2023-10-21 13:12:02,461:INFO:Declaring metric variables
2023-10-21 13:12:02,461:INFO:Defining Hyperparameters
2023-10-21 13:12:02,666:INFO:Tuning with n_jobs=-1
2023-10-21 13:12:02,667:INFO:Initializing RandomizedSearchCV
2023-10-21 13:13:00,964:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-21 13:13:00,964:INFO:Hyperparameter search completed
2023-10-21 13:13:00,964:INFO:SubProcess create_model() called ==================================
2023-10-21 13:13:00,967:INFO:Initializing create_model()
2023-10-21 13:13:00,968:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6CC2520>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209DAB65AF0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-21 13:13:00,968:INFO:Checking exceptions
2023-10-21 13:13:00,968:INFO:Importing libraries
2023-10-21 13:13:00,968:INFO:Copying training dataset
2023-10-21 13:13:01,003:INFO:Defining folds
2023-10-21 13:13:01,004:INFO:Declaring metric variables
2023-10-21 13:13:01,004:INFO:Importing untrained model
2023-10-21 13:13:01,004:INFO:Declaring custom model
2023-10-21 13:13:01,006:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 13:13:01,006:INFO:Starting cross validation
2023-10-21 13:13:01,008:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 13:13:10,401:INFO:Calculating mean and std
2023-10-21 13:13:10,401:INFO:Creating metrics dataframe
2023-10-21 13:13:10,401:INFO:Finalizing model
2023-10-21 13:13:10,476:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 13:13:10,476:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 13:13:10,476:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 13:13:10,514:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 13:13:10,514:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 13:13:10,514:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 13:13:10,529:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007281 seconds.
2023-10-21 13:13:10,529:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 13:13:10,529:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 13:13:10,529:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 13:13:10,529:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-21 13:13:11,809:INFO:Uploading results into container
2023-10-21 13:13:11,809:INFO:Uploading model into container now
2023-10-21 13:13:11,809:INFO:_master_model_container: 2
2023-10-21 13:13:11,809:INFO:_display_container: 3
2023-10-21 13:13:11,809:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-21 13:13:11,809:INFO:create_model() successfully completed......................................
2023-10-21 13:13:12,024:INFO:SubProcess create_model() end ==================================
2023-10-21 13:13:12,024:INFO:choose_better activated
2023-10-21 13:13:12,025:INFO:SubProcess create_model() called ==================================
2023-10-21 13:13:12,026:INFO:Initializing create_model()
2023-10-21 13:13:12,026:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6CC2520>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 13:13:12,026:INFO:Checking exceptions
2023-10-21 13:13:12,026:INFO:Importing libraries
2023-10-21 13:13:12,026:INFO:Copying training dataset
2023-10-21 13:13:12,046:INFO:Defining folds
2023-10-21 13:13:12,046:INFO:Declaring metric variables
2023-10-21 13:13:12,046:INFO:Importing untrained model
2023-10-21 13:13:12,046:INFO:Declaring custom model
2023-10-21 13:13:12,046:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 13:13:12,046:INFO:Starting cross validation
2023-10-21 13:13:12,046:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 13:13:15,290:INFO:Calculating mean and std
2023-10-21 13:13:15,290:INFO:Creating metrics dataframe
2023-10-21 13:13:15,290:INFO:Finalizing model
2023-10-21 13:13:15,389:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006151 seconds.
2023-10-21 13:13:15,389:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 13:13:15,389:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 13:13:15,389:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 13:13:15,389:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-21 13:13:15,641:INFO:Uploading results into container
2023-10-21 13:13:15,642:INFO:Uploading model into container now
2023-10-21 13:13:15,643:INFO:_master_model_container: 3
2023-10-21 13:13:15,643:INFO:_display_container: 4
2023-10-21 13:13:15,644:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 13:13:15,644:INFO:create_model() successfully completed......................................
2023-10-21 13:13:15,847:INFO:SubProcess create_model() end ==================================
2023-10-21 13:13:15,848:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8716
2023-10-21 13:13:15,848:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8712
2023-10-21 13:13:15,849:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-21 13:13:15,849:INFO:choose_better completed
2023-10-21 13:13:15,849:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-21 13:13:15,849:INFO:Creating Dashboard logs
2023-10-21 13:13:15,850:INFO:Model: Light Gradient Boosting Machine
2023-10-21 13:13:15,909:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 13:13:16,081:INFO:Initializing predict_model()
2023-10-21 13:13:16,081:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6CC2520>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DA6C6550>)
2023-10-21 13:13:16,081:INFO:Checking exceptions
2023-10-21 13:13:16,081:INFO:Preloading libraries
2023-10-21 13:13:16,704:INFO:_master_model_container: 3
2023-10-21 13:13:16,704:INFO:_display_container: 3
2023-10-21 13:13:16,704:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 13:13:16,704:INFO:tune_model() successfully completed......................................
2023-10-21 13:13:16,888:INFO:Initializing finalize_model()
2023-10-21 13:13:16,888:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6CC2520>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-21 13:13:16,888:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 13:13:16,888:INFO:Initializing create_model()
2023-10-21 13:13:16,888:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6CC2520>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-21 13:13:16,888:INFO:Checking exceptions
2023-10-21 13:13:16,904:INFO:Importing libraries
2023-10-21 13:13:16,904:INFO:Copying training dataset
2023-10-21 13:13:16,904:INFO:Defining folds
2023-10-21 13:13:16,904:INFO:Declaring metric variables
2023-10-21 13:13:16,904:INFO:Importing untrained model
2023-10-21 13:13:16,904:INFO:Declaring custom model
2023-10-21 13:13:16,904:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 13:13:16,904:INFO:Cross validation set to False
2023-10-21 13:13:16,904:INFO:Fitting Model
2023-10-21 13:13:17,020:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007974 seconds.
2023-10-21 13:13:17,020:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 13:13:17,020:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-21 13:13:17,020:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-21 13:13:17,020:INFO:[LightGBM] [Info] Start training from score 631.011165
2023-10-21 13:13:17,376:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-21 13:13:17,376:INFO:create_model() successfully completed......................................
2023-10-21 13:13:17,574:INFO:Creating Dashboard logs
2023-10-21 13:13:17,574:INFO:Model: Light Gradient Boosting Machine
2023-10-21 13:13:17,622:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 13:13:17,990:INFO:_master_model_container: 3
2023-10-21 13:13:17,990:INFO:_display_container: 3
2023-10-21 13:13:18,006:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-21 13:13:18,006:INFO:finalize_model() successfully completed......................................
2023-10-21 13:13:18,186:INFO:Initializing save_model()
2023-10-21 13:13:18,186:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_A, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 13:13:18,186:INFO:Adding model into prep_pipe
2023-10-21 13:13:18,186:WARNING:Only Model saved as it was a pipeline.
2023-10-21 13:13:18,210:INFO:final_model_for_location_A.pkl saved in current working directory
2023-10-21 13:13:18,225:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-21 13:13:18,225:INFO:save_model() successfully completed......................................
2023-10-21 13:13:18,439:INFO:PyCaret RegressionExperiment
2023-10-21 13:13:18,439:INFO:Logging name: exp_B
2023-10-21 13:13:18,439:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-21 13:13:18,439:INFO:version 3.1.0
2023-10-21 13:13:18,439:INFO:Initializing setup()
2023-10-21 13:13:18,439:INFO:self.USI: 9f74
2023-10-21 13:13:18,439:INFO:self._variable_keys: {'transform_target_param', 'exp_name_log', 'y_train', 'logging_param', 'n_jobs_param', 'X_train', 'target_param', 'USI', 'gpu_n_jobs_param', 'fold_groups_param', '_ml_usecase', 'seed', 'fold_generator', 'idx', 'html_param', 'log_plots_param', 'y', 'gpu_param', 'X_test', 'memory', 'y_test', 'data', 'X', 'exp_id', '_available_plots', 'fold_shuffle_param', 'pipeline'}
2023-10-21 13:13:18,439:INFO:Checking environment
2023-10-21 13:13:18,439:INFO:python_version: 3.8.18
2023-10-21 13:13:18,439:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-21 13:13:18,439:INFO:machine: AMD64
2023-10-21 13:13:18,439:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-21 13:13:18,439:INFO:Memory: svmem(total=16505954304, available=3044720640, percent=81.6, used=13461233664, free=3044720640)
2023-10-21 13:13:18,439:INFO:Physical Core: 8
2023-10-21 13:13:18,439:INFO:Logical Core: 16
2023-10-21 13:13:18,439:INFO:Checking libraries
2023-10-21 13:13:18,439:INFO:System:
2023-10-21 13:13:18,439:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-21 13:13:18,439:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-21 13:13:18,439:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-21 13:13:18,439:INFO:PyCaret required dependencies:
2023-10-21 13:13:18,439:INFO:                 pip: 23.3
2023-10-21 13:13:18,439:INFO:          setuptools: 68.0.0
2023-10-21 13:13:18,439:INFO:             pycaret: 3.1.0
2023-10-21 13:13:18,439:INFO:             IPython: 8.12.0
2023-10-21 13:13:18,439:INFO:          ipywidgets: 8.1.1
2023-10-21 13:13:18,439:INFO:                tqdm: 4.66.1
2023-10-21 13:13:18,439:INFO:               numpy: 1.23.5
2023-10-21 13:13:18,439:INFO:              pandas: 1.5.3
2023-10-21 13:13:18,439:INFO:              jinja2: 3.1.2
2023-10-21 13:13:18,439:INFO:               scipy: 1.10.1
2023-10-21 13:13:18,439:INFO:              joblib: 1.3.2
2023-10-21 13:13:18,439:INFO:             sklearn: 1.2.2
2023-10-21 13:13:18,439:INFO:                pyod: 1.1.0
2023-10-21 13:13:18,439:INFO:            imblearn: 0.11.0
2023-10-21 13:13:18,439:INFO:   category_encoders: 2.6.2
2023-10-21 13:13:18,439:INFO:            lightgbm: 4.1.0
2023-10-21 13:13:18,439:INFO:               numba: 0.58.1
2023-10-21 13:13:18,439:INFO:            requests: 2.31.0
2023-10-21 13:13:18,439:INFO:          matplotlib: 3.7.3
2023-10-21 13:13:18,439:INFO:          scikitplot: 0.3.7
2023-10-21 13:13:18,439:INFO:         yellowbrick: 1.5
2023-10-21 13:13:18,439:INFO:              plotly: 5.17.0
2023-10-21 13:13:18,439:INFO:    plotly-resampler: Not installed
2023-10-21 13:13:18,439:INFO:             kaleido: 0.2.1
2023-10-21 13:13:18,439:INFO:           schemdraw: 0.15
2023-10-21 13:13:18,439:INFO:         statsmodels: 0.14.0
2023-10-21 13:13:18,439:INFO:              sktime: 0.21.1
2023-10-21 13:13:18,439:INFO:               tbats: 1.1.3
2023-10-21 13:13:18,439:INFO:            pmdarima: 2.0.3
2023-10-21 13:13:18,439:INFO:              psutil: 5.9.0
2023-10-21 13:13:18,439:INFO:          markupsafe: 2.1.3
2023-10-21 13:13:18,439:INFO:             pickle5: Not installed
2023-10-21 13:13:18,439:INFO:         cloudpickle: 2.2.1
2023-10-21 13:13:18,439:INFO:         deprecation: 2.1.0
2023-10-21 13:13:18,439:INFO:              xxhash: 3.4.1
2023-10-21 13:13:18,439:INFO:           wurlitzer: Not installed
2023-10-21 13:13:18,439:INFO:PyCaret optional dependencies:
2023-10-21 13:13:18,439:INFO:                shap: Not installed
2023-10-21 13:13:18,439:INFO:           interpret: Not installed
2023-10-21 13:13:18,439:INFO:                umap: Not installed
2023-10-21 13:13:18,439:INFO:     ydata_profiling: Not installed
2023-10-21 13:13:18,439:INFO:  explainerdashboard: Not installed
2023-10-21 13:13:18,439:INFO:             autoviz: Not installed
2023-10-21 13:13:18,439:INFO:           fairlearn: Not installed
2023-10-21 13:13:18,439:INFO:          deepchecks: Not installed
2023-10-21 13:13:18,439:INFO:             xgboost: Not installed
2023-10-21 13:13:18,439:INFO:            catboost: 1.2.2
2023-10-21 13:13:18,439:INFO:              kmodes: Not installed
2023-10-21 13:13:18,439:INFO:             mlxtend: Not installed
2023-10-21 13:13:18,439:INFO:       statsforecast: Not installed
2023-10-21 13:13:18,439:INFO:        tune_sklearn: Not installed
2023-10-21 13:13:18,439:INFO:                 ray: Not installed
2023-10-21 13:13:18,439:INFO:            hyperopt: Not installed
2023-10-21 13:13:18,439:INFO:              optuna: Not installed
2023-10-21 13:13:18,439:INFO:               skopt: Not installed
2023-10-21 13:13:18,439:INFO:              mlflow: 2.7.1
2023-10-21 13:13:18,439:INFO:              gradio: Not installed
2023-10-21 13:13:18,439:INFO:             fastapi: Not installed
2023-10-21 13:13:18,439:INFO:             uvicorn: Not installed
2023-10-21 13:13:18,439:INFO:              m2cgen: Not installed
2023-10-21 13:13:18,439:INFO:           evidently: Not installed
2023-10-21 13:13:18,439:INFO:               fugue: Not installed
2023-10-21 13:13:18,439:INFO:           streamlit: Not installed
2023-10-21 13:13:18,439:INFO:             prophet: Not installed
2023-10-21 13:13:18,439:INFO:None
2023-10-21 13:13:18,439:INFO:Set up data.
2023-10-21 13:13:18,479:INFO:Set up folding strategy.
2023-10-21 13:13:18,479:INFO:Set up train/test split.
2023-10-21 13:13:18,507:INFO:Set up index.
2023-10-21 13:13:18,509:INFO:Assigning column types.
2023-10-21 13:13:18,533:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-21 13:13:18,533:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 13:13:18,539:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 13:13:18,545:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:13:18,627:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:13:18,679:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:13:18,680:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:13:18,680:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:13:18,681:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 13:13:18,686:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 13:13:18,692:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:13:18,772:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:13:18,819:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:13:18,819:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:13:18,819:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:13:18,819:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-21 13:13:18,819:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 13:13:18,835:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:13:18,902:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:13:18,955:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:13:18,955:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:13:18,955:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:13:18,955:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 13:13:18,971:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:13:19,053:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:13:19,106:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:13:19,107:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:13:19,107:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:13:19,108:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-21 13:13:19,119:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:13:19,191:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:13:19,256:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:13:19,257:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:13:19,257:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:13:19,269:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:13:19,350:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:13:19,392:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:13:19,392:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:13:19,392:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:13:19,392:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-21 13:13:19,495:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:13:19,561:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:13:19,562:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:13:19,562:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:13:19,666:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:13:19,719:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:13:19,719:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:13:19,720:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:13:19,720:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-21 13:13:19,804:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:13:19,870:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:13:19,870:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:13:19,975:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:13:20,035:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:13:20,036:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:13:20,036:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-21 13:13:20,190:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:13:20,190:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:13:20,336:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:13:20,336:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:13:20,350:INFO:Preparing preprocessing pipeline...
2023-10-21 13:13:20,351:INFO:Set up simple imputation.
2023-10-21 13:13:20,355:INFO:Set up column name cleaning.
2023-10-21 13:13:20,419:INFO:Finished creating preprocessing pipeline.
2023-10-21 13:13:20,423:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 13:13:20,423:INFO:Creating final display dataframe.
2023-10-21 13:13:20,619:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (32819, 50)
4        Transformed data shape   (32819, 50)
5   Transformed train set shape   (22973, 50)
6    Transformed test set shape    (9846, 50)
7              Numeric features            49
8      Rows with missing values         95.9%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_B
19                          USI          9f74
2023-10-21 13:13:20,771:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:13:20,771:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:13:20,917:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:13:20,917:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:13:20,917:INFO:Logging experiment in loggers
2023-10-21 13:13:21,032:INFO:SubProcess save_model() called ==================================
2023-10-21 13:13:21,032:INFO:Initializing save_model()
2023-10-21 13:13:21,032:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmpiturykv6\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 13:13:21,032:INFO:Adding model into prep_pipe
2023-10-21 13:13:21,032:WARNING:Only Model saved as it was a pipeline.
2023-10-21 13:13:21,047:INFO:C:\Users\thoma\AppData\Local\Temp\tmpiturykv6\Transformation Pipeline.pkl saved in current working directory
2023-10-21 13:13:21,047:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 13:13:21,047:INFO:save_model() successfully completed......................................
2023-10-21 13:13:21,235:INFO:SubProcess save_model() end ==================================
2023-10-21 13:13:21,287:INFO:setup() successfully completed in 2.48s...............
2023-10-21 13:13:21,287:INFO:Initializing create_model()
2023-10-21 13:13:21,287:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAB65940>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 13:13:21,287:INFO:Checking exceptions
2023-10-21 13:13:21,303:INFO:Importing libraries
2023-10-21 13:13:21,303:INFO:Copying training dataset
2023-10-21 13:13:21,327:INFO:Defining folds
2023-10-21 13:13:21,327:INFO:Declaring metric variables
2023-10-21 13:13:21,327:INFO:Importing untrained model
2023-10-21 13:13:21,327:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 13:13:21,327:INFO:Starting cross validation
2023-10-21 13:13:21,327:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 13:13:24,373:INFO:Calculating mean and std
2023-10-21 13:13:24,373:INFO:Creating metrics dataframe
2023-10-21 13:13:24,373:INFO:Finalizing model
2023-10-21 13:13:24,472:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005085 seconds.
2023-10-21 13:13:24,472:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 13:13:24,473:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 13:13:24,473:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 13:13:24,474:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-21 13:13:24,733:INFO:Creating Dashboard logs
2023-10-21 13:13:24,733:INFO:Model: Light Gradient Boosting Machine
2023-10-21 13:13:24,831:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 13:13:25,049:INFO:Initializing predict_model()
2023-10-21 13:13:25,049:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAB65940>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209D98B01F0>)
2023-10-21 13:13:25,049:INFO:Checking exceptions
2023-10-21 13:13:25,049:INFO:Preloading libraries
2023-10-21 13:13:25,816:INFO:Uploading results into container
2023-10-21 13:13:25,816:INFO:Uploading model into container now
2023-10-21 13:13:25,816:INFO:_master_model_container: 1
2023-10-21 13:13:25,816:INFO:_display_container: 2
2023-10-21 13:13:25,816:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 13:13:25,816:INFO:create_model() successfully completed......................................
2023-10-21 13:13:26,033:INFO:Initializing tune_model()
2023-10-21 13:13:26,033:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAB65940>)
2023-10-21 13:13:26,033:INFO:Checking exceptions
2023-10-21 13:13:26,048:INFO:Copying training dataset
2023-10-21 13:13:26,065:INFO:Checking base model
2023-10-21 13:13:26,065:INFO:Base model : Light Gradient Boosting Machine
2023-10-21 13:13:26,065:INFO:Declaring metric variables
2023-10-21 13:13:26,065:INFO:Defining Hyperparameters
2023-10-21 13:13:26,271:INFO:Tuning with n_jobs=-1
2023-10-21 13:13:26,271:INFO:Initializing RandomizedSearchCV
2023-10-21 13:14:17,771:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-21 13:14:17,771:INFO:Hyperparameter search completed
2023-10-21 13:14:17,771:INFO:SubProcess create_model() called ==================================
2023-10-21 13:14:17,771:INFO:Initializing create_model()
2023-10-21 13:14:17,771:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAB65940>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209DCBE0D90>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-21 13:14:17,771:INFO:Checking exceptions
2023-10-21 13:14:17,771:INFO:Importing libraries
2023-10-21 13:14:17,771:INFO:Copying training dataset
2023-10-21 13:14:17,788:INFO:Defining folds
2023-10-21 13:14:17,788:INFO:Declaring metric variables
2023-10-21 13:14:17,788:INFO:Importing untrained model
2023-10-21 13:14:17,788:INFO:Declaring custom model
2023-10-21 13:14:17,803:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 13:14:17,803:INFO:Starting cross validation
2023-10-21 13:14:17,804:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 13:14:27,280:INFO:Calculating mean and std
2023-10-21 13:14:27,280:INFO:Creating metrics dataframe
2023-10-21 13:14:27,280:INFO:Finalizing model
2023-10-21 13:14:27,346:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 13:14:27,346:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 13:14:27,346:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 13:14:27,380:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 13:14:27,380:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 13:14:27,380:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 13:14:27,397:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005985 seconds.
2023-10-21 13:14:27,397:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 13:14:27,397:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 13:14:27,397:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 13:14:27,397:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-21 13:14:28,840:INFO:Uploading results into container
2023-10-21 13:14:28,840:INFO:Uploading model into container now
2023-10-21 13:14:28,840:INFO:_master_model_container: 2
2023-10-21 13:14:28,840:INFO:_display_container: 3
2023-10-21 13:14:28,840:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-21 13:14:28,840:INFO:create_model() successfully completed......................................
2023-10-21 13:14:29,060:INFO:SubProcess create_model() end ==================================
2023-10-21 13:14:29,060:INFO:choose_better activated
2023-10-21 13:14:29,060:INFO:SubProcess create_model() called ==================================
2023-10-21 13:14:29,060:INFO:Initializing create_model()
2023-10-21 13:14:29,060:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAB65940>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 13:14:29,060:INFO:Checking exceptions
2023-10-21 13:14:29,060:INFO:Importing libraries
2023-10-21 13:14:29,060:INFO:Copying training dataset
2023-10-21 13:14:29,091:INFO:Defining folds
2023-10-21 13:14:29,091:INFO:Declaring metric variables
2023-10-21 13:14:29,091:INFO:Importing untrained model
2023-10-21 13:14:29,091:INFO:Declaring custom model
2023-10-21 13:14:29,091:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 13:14:29,091:INFO:Starting cross validation
2023-10-21 13:14:29,091:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 13:14:31,610:INFO:Calculating mean and std
2023-10-21 13:14:31,610:INFO:Creating metrics dataframe
2023-10-21 13:14:31,610:INFO:Finalizing model
2023-10-21 13:14:31,693:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004877 seconds.
2023-10-21 13:14:31,693:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 13:14:31,693:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 13:14:31,693:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 13:14:31,693:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-21 13:14:31,926:INFO:Uploading results into container
2023-10-21 13:14:31,926:INFO:Uploading model into container now
2023-10-21 13:14:31,936:INFO:_master_model_container: 3
2023-10-21 13:14:31,936:INFO:_display_container: 4
2023-10-21 13:14:31,936:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 13:14:31,936:INFO:create_model() successfully completed......................................
2023-10-21 13:14:32,126:INFO:SubProcess create_model() end ==================================
2023-10-21 13:14:32,137:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8523
2023-10-21 13:14:32,137:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8523
2023-10-21 13:14:32,137:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-21 13:14:32,137:INFO:choose_better completed
2023-10-21 13:14:32,137:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-21 13:14:32,137:INFO:Creating Dashboard logs
2023-10-21 13:14:32,137:INFO:Model: Light Gradient Boosting Machine
2023-10-21 13:14:32,195:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 13:14:32,392:INFO:Initializing predict_model()
2023-10-21 13:14:32,392:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAB65940>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209D98B0AF0>)
2023-10-21 13:14:32,392:INFO:Checking exceptions
2023-10-21 13:14:32,392:INFO:Preloading libraries
2023-10-21 13:14:33,041:INFO:_master_model_container: 3
2023-10-21 13:14:33,041:INFO:_display_container: 3
2023-10-21 13:14:33,041:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 13:14:33,041:INFO:tune_model() successfully completed......................................
2023-10-21 13:14:33,208:INFO:Initializing finalize_model()
2023-10-21 13:14:33,208:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAB65940>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-21 13:14:33,208:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 13:14:33,225:INFO:Initializing create_model()
2023-10-21 13:14:33,225:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAB65940>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-21 13:14:33,225:INFO:Checking exceptions
2023-10-21 13:14:33,225:INFO:Importing libraries
2023-10-21 13:14:33,225:INFO:Copying training dataset
2023-10-21 13:14:33,238:INFO:Defining folds
2023-10-21 13:14:33,238:INFO:Declaring metric variables
2023-10-21 13:14:33,238:INFO:Importing untrained model
2023-10-21 13:14:33,238:INFO:Declaring custom model
2023-10-21 13:14:33,238:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 13:14:33,240:INFO:Cross validation set to False
2023-10-21 13:14:33,240:INFO:Fitting Model
2023-10-21 13:14:33,366:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009484 seconds.
2023-10-21 13:14:33,366:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 13:14:33,367:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-21 13:14:33,368:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-21 13:14:33,369:INFO:[LightGBM] [Info] Start training from score 96.893335
2023-10-21 13:14:33,658:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-21 13:14:33,658:INFO:create_model() successfully completed......................................
2023-10-21 13:14:33,874:INFO:Creating Dashboard logs
2023-10-21 13:14:33,874:INFO:Model: Light Gradient Boosting Machine
2023-10-21 13:14:33,942:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 13:14:34,358:INFO:_master_model_container: 3
2023-10-21 13:14:34,358:INFO:_display_container: 3
2023-10-21 13:14:34,373:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-21 13:14:34,373:INFO:finalize_model() successfully completed......................................
2023-10-21 13:14:34,557:INFO:Initializing save_model()
2023-10-21 13:14:34,557:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_B, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 13:14:34,557:INFO:Adding model into prep_pipe
2023-10-21 13:14:34,557:WARNING:Only Model saved as it was a pipeline.
2023-10-21 13:14:34,557:INFO:final_model_for_location_B.pkl saved in current working directory
2023-10-21 13:14:34,574:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-21 13:14:34,574:INFO:save_model() successfully completed......................................
2023-10-21 13:14:34,790:INFO:PyCaret RegressionExperiment
2023-10-21 13:14:34,790:INFO:Logging name: exp_C
2023-10-21 13:14:34,790:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-21 13:14:34,790:INFO:version 3.1.0
2023-10-21 13:14:34,790:INFO:Initializing setup()
2023-10-21 13:14:34,790:INFO:self.USI: f13b
2023-10-21 13:14:34,790:INFO:self._variable_keys: {'transform_target_param', 'exp_name_log', 'y_train', 'logging_param', 'n_jobs_param', 'X_train', 'target_param', 'USI', 'gpu_n_jobs_param', 'fold_groups_param', '_ml_usecase', 'seed', 'fold_generator', 'idx', 'html_param', 'log_plots_param', 'y', 'gpu_param', 'X_test', 'memory', 'y_test', 'data', 'X', 'exp_id', '_available_plots', 'fold_shuffle_param', 'pipeline'}
2023-10-21 13:14:34,790:INFO:Checking environment
2023-10-21 13:14:34,790:INFO:python_version: 3.8.18
2023-10-21 13:14:34,790:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-21 13:14:34,790:INFO:machine: AMD64
2023-10-21 13:14:34,790:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-21 13:14:34,790:INFO:Memory: svmem(total=16505954304, available=3200471040, percent=80.6, used=13305483264, free=3200471040)
2023-10-21 13:14:34,790:INFO:Physical Core: 8
2023-10-21 13:14:34,790:INFO:Logical Core: 16
2023-10-21 13:14:34,790:INFO:Checking libraries
2023-10-21 13:14:34,790:INFO:System:
2023-10-21 13:14:34,790:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-21 13:14:34,790:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-21 13:14:34,790:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-21 13:14:34,790:INFO:PyCaret required dependencies:
2023-10-21 13:14:34,790:INFO:                 pip: 23.3
2023-10-21 13:14:34,790:INFO:          setuptools: 68.0.0
2023-10-21 13:14:34,790:INFO:             pycaret: 3.1.0
2023-10-21 13:14:34,790:INFO:             IPython: 8.12.0
2023-10-21 13:14:34,790:INFO:          ipywidgets: 8.1.1
2023-10-21 13:14:34,790:INFO:                tqdm: 4.66.1
2023-10-21 13:14:34,790:INFO:               numpy: 1.23.5
2023-10-21 13:14:34,790:INFO:              pandas: 1.5.3
2023-10-21 13:14:34,790:INFO:              jinja2: 3.1.2
2023-10-21 13:14:34,790:INFO:               scipy: 1.10.1
2023-10-21 13:14:34,790:INFO:              joblib: 1.3.2
2023-10-21 13:14:34,790:INFO:             sklearn: 1.2.2
2023-10-21 13:14:34,790:INFO:                pyod: 1.1.0
2023-10-21 13:14:34,790:INFO:            imblearn: 0.11.0
2023-10-21 13:14:34,790:INFO:   category_encoders: 2.6.2
2023-10-21 13:14:34,790:INFO:            lightgbm: 4.1.0
2023-10-21 13:14:34,790:INFO:               numba: 0.58.1
2023-10-21 13:14:34,790:INFO:            requests: 2.31.0
2023-10-21 13:14:34,790:INFO:          matplotlib: 3.7.3
2023-10-21 13:14:34,790:INFO:          scikitplot: 0.3.7
2023-10-21 13:14:34,790:INFO:         yellowbrick: 1.5
2023-10-21 13:14:34,790:INFO:              plotly: 5.17.0
2023-10-21 13:14:34,790:INFO:    plotly-resampler: Not installed
2023-10-21 13:14:34,790:INFO:             kaleido: 0.2.1
2023-10-21 13:14:34,790:INFO:           schemdraw: 0.15
2023-10-21 13:14:34,790:INFO:         statsmodels: 0.14.0
2023-10-21 13:14:34,790:INFO:              sktime: 0.21.1
2023-10-21 13:14:34,790:INFO:               tbats: 1.1.3
2023-10-21 13:14:34,790:INFO:            pmdarima: 2.0.3
2023-10-21 13:14:34,790:INFO:              psutil: 5.9.0
2023-10-21 13:14:34,790:INFO:          markupsafe: 2.1.3
2023-10-21 13:14:34,790:INFO:             pickle5: Not installed
2023-10-21 13:14:34,790:INFO:         cloudpickle: 2.2.1
2023-10-21 13:14:34,790:INFO:         deprecation: 2.1.0
2023-10-21 13:14:34,790:INFO:              xxhash: 3.4.1
2023-10-21 13:14:34,790:INFO:           wurlitzer: Not installed
2023-10-21 13:14:34,790:INFO:PyCaret optional dependencies:
2023-10-21 13:14:34,790:INFO:                shap: Not installed
2023-10-21 13:14:34,790:INFO:           interpret: Not installed
2023-10-21 13:14:34,790:INFO:                umap: Not installed
2023-10-21 13:14:34,790:INFO:     ydata_profiling: Not installed
2023-10-21 13:14:34,790:INFO:  explainerdashboard: Not installed
2023-10-21 13:14:34,790:INFO:             autoviz: Not installed
2023-10-21 13:14:34,790:INFO:           fairlearn: Not installed
2023-10-21 13:14:34,790:INFO:          deepchecks: Not installed
2023-10-21 13:14:34,790:INFO:             xgboost: Not installed
2023-10-21 13:14:34,790:INFO:            catboost: 1.2.2
2023-10-21 13:14:34,790:INFO:              kmodes: Not installed
2023-10-21 13:14:34,790:INFO:             mlxtend: Not installed
2023-10-21 13:14:34,790:INFO:       statsforecast: Not installed
2023-10-21 13:14:34,790:INFO:        tune_sklearn: Not installed
2023-10-21 13:14:34,790:INFO:                 ray: Not installed
2023-10-21 13:14:34,790:INFO:            hyperopt: Not installed
2023-10-21 13:14:34,790:INFO:              optuna: Not installed
2023-10-21 13:14:34,790:INFO:               skopt: Not installed
2023-10-21 13:14:34,790:INFO:              mlflow: 2.7.1
2023-10-21 13:14:34,790:INFO:              gradio: Not installed
2023-10-21 13:14:34,790:INFO:             fastapi: Not installed
2023-10-21 13:14:34,790:INFO:             uvicorn: Not installed
2023-10-21 13:14:34,790:INFO:              m2cgen: Not installed
2023-10-21 13:14:34,790:INFO:           evidently: Not installed
2023-10-21 13:14:34,790:INFO:               fugue: Not installed
2023-10-21 13:14:34,790:INFO:           streamlit: Not installed
2023-10-21 13:14:34,790:INFO:             prophet: Not installed
2023-10-21 13:14:34,790:INFO:None
2023-10-21 13:14:34,790:INFO:Set up data.
2023-10-21 13:14:34,824:INFO:Set up folding strategy.
2023-10-21 13:14:34,824:INFO:Set up train/test split.
2023-10-21 13:14:34,852:INFO:Set up index.
2023-10-21 13:14:34,853:INFO:Assigning column types.
2023-10-21 13:14:34,857:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-21 13:14:34,857:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 13:14:34,873:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 13:14:34,873:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:14:34,956:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,007:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,007:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:14:35,007:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:14:35,007:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,007:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,007:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,090:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,147:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,148:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:14:35,148:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:14:35,148:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-21 13:14:35,154:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,156:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,223:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,273:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,287:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:14:35,287:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:14:35,290:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,290:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,373:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,423:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,423:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:14:35,423:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:14:35,423:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-21 13:14:35,445:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,506:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,556:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,572:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:14:35,573:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:14:35,573:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,656:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,706:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,706:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:14:35,706:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:14:35,706:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-21 13:14:35,790:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,847:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,848:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:14:35,848:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:14:35,923:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,988:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,988:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:14:35,989:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:14:35,989:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-21 13:14:36,072:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:14:36,123:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:14:36,123:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:14:36,206:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:14:36,255:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:14:36,255:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:14:36,255:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-21 13:14:36,406:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:14:36,406:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:14:36,551:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:14:36,552:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:14:36,553:INFO:Preparing preprocessing pipeline...
2023-10-21 13:14:36,553:INFO:Set up simple imputation.
2023-10-21 13:14:36,556:INFO:Set up column name cleaning.
2023-10-21 13:14:36,606:INFO:Finished creating preprocessing pipeline.
2023-10-21 13:14:36,606:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 13:14:36,606:INFO:Creating final display dataframe.
2023-10-21 13:14:36,789:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (26071, 50)
4        Transformed data shape   (26071, 50)
5   Transformed train set shape   (18249, 50)
6    Transformed test set shape    (7822, 50)
7              Numeric features            49
8      Rows with missing values         95.9%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_C
19                          USI          f13b
2023-10-21 13:14:36,941:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:14:36,941:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:14:37,088:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:14:37,088:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:14:37,088:INFO:Logging experiment in loggers
2023-10-21 13:14:37,205:INFO:SubProcess save_model() called ==================================
2023-10-21 13:14:37,205:INFO:Initializing save_model()
2023-10-21 13:14:37,205:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmpokoacz1e\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 13:14:37,205:INFO:Adding model into prep_pipe
2023-10-21 13:14:37,205:WARNING:Only Model saved as it was a pipeline.
2023-10-21 13:14:37,221:INFO:C:\Users\thoma\AppData\Local\Temp\tmpokoacz1e\Transformation Pipeline.pkl saved in current working directory
2023-10-21 13:14:37,221:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 13:14:37,221:INFO:save_model() successfully completed......................................
2023-10-21 13:14:37,404:INFO:SubProcess save_model() end ==================================
2023-10-21 13:14:37,455:INFO:setup() successfully completed in 2.3s...............
2023-10-21 13:14:37,455:INFO:Initializing create_model()
2023-10-21 13:14:37,455:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCD99880>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 13:14:37,455:INFO:Checking exceptions
2023-10-21 13:14:37,455:INFO:Importing libraries
2023-10-21 13:14:37,455:INFO:Copying training dataset
2023-10-21 13:14:37,471:INFO:Defining folds
2023-10-21 13:14:37,471:INFO:Declaring metric variables
2023-10-21 13:14:37,471:INFO:Importing untrained model
2023-10-21 13:14:37,471:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 13:14:37,471:INFO:Starting cross validation
2023-10-21 13:14:37,471:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 13:14:40,103:INFO:Calculating mean and std
2023-10-21 13:14:40,103:INFO:Creating metrics dataframe
2023-10-21 13:14:40,103:INFO:Finalizing model
2023-10-21 13:14:40,186:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004403 seconds.
2023-10-21 13:14:40,186:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 13:14:40,186:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-21 13:14:40,186:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-21 13:14:40,186:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-21 13:14:40,436:INFO:Creating Dashboard logs
2023-10-21 13:14:40,436:INFO:Model: Light Gradient Boosting Machine
2023-10-21 13:14:40,534:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 13:14:40,702:INFO:Initializing predict_model()
2023-10-21 13:14:40,702:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCD99880>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DB43D670>)
2023-10-21 13:14:40,702:INFO:Checking exceptions
2023-10-21 13:14:40,702:INFO:Preloading libraries
2023-10-21 13:14:41,285:INFO:Uploading results into container
2023-10-21 13:14:41,285:INFO:Uploading model into container now
2023-10-21 13:14:41,285:INFO:_master_model_container: 1
2023-10-21 13:14:41,285:INFO:_display_container: 2
2023-10-21 13:14:41,285:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 13:14:41,285:INFO:create_model() successfully completed......................................
2023-10-21 13:14:41,469:INFO:Initializing tune_model()
2023-10-21 13:14:41,469:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCD99880>)
2023-10-21 13:14:41,469:INFO:Checking exceptions
2023-10-21 13:14:41,485:INFO:Copying training dataset
2023-10-21 13:14:41,502:INFO:Checking base model
2023-10-21 13:14:41,502:INFO:Base model : Light Gradient Boosting Machine
2023-10-21 13:14:41,502:INFO:Declaring metric variables
2023-10-21 13:14:41,502:INFO:Defining Hyperparameters
2023-10-21 13:14:41,668:INFO:Tuning with n_jobs=-1
2023-10-21 13:14:41,668:INFO:Initializing RandomizedSearchCV
2023-10-21 13:15:23,268:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-21 13:15:23,268:INFO:Hyperparameter search completed
2023-10-21 13:15:23,268:INFO:SubProcess create_model() called ==================================
2023-10-21 13:15:23,268:INFO:Initializing create_model()
2023-10-21 13:15:23,268:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCD99880>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3955D00>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-21 13:15:23,268:INFO:Checking exceptions
2023-10-21 13:15:23,268:INFO:Importing libraries
2023-10-21 13:15:23,268:INFO:Copying training dataset
2023-10-21 13:15:23,306:INFO:Defining folds
2023-10-21 13:15:23,306:INFO:Declaring metric variables
2023-10-21 13:15:23,307:INFO:Importing untrained model
2023-10-21 13:15:23,307:INFO:Declaring custom model
2023-10-21 13:15:23,308:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 13:15:23,309:INFO:Starting cross validation
2023-10-21 13:15:23,310:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 13:15:32,027:INFO:Calculating mean and std
2023-10-21 13:15:32,027:INFO:Creating metrics dataframe
2023-10-21 13:15:32,027:INFO:Finalizing model
2023-10-21 13:15:32,074:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 13:15:32,074:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 13:15:32,074:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 13:15:32,093:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 13:15:32,093:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 13:15:32,093:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 13:15:32,110:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004872 seconds.
2023-10-21 13:15:32,110:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 13:15:32,110:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-21 13:15:32,110:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-21 13:15:32,110:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-21 13:15:32,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 13:15:32,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 13:15:32,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 13:15:32,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 13:15:32,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 13:15:32,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 13:15:32,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 13:15:32,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 13:15:33,242:INFO:Uploading results into container
2023-10-21 13:15:33,242:INFO:Uploading model into container now
2023-10-21 13:15:33,242:INFO:_master_model_container: 2
2023-10-21 13:15:33,242:INFO:_display_container: 3
2023-10-21 13:15:33,242:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-21 13:15:33,242:INFO:create_model() successfully completed......................................
2023-10-21 13:15:33,474:INFO:SubProcess create_model() end ==================================
2023-10-21 13:15:33,475:INFO:choose_better activated
2023-10-21 13:15:33,475:INFO:SubProcess create_model() called ==================================
2023-10-21 13:15:33,475:INFO:Initializing create_model()
2023-10-21 13:15:33,475:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCD99880>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 13:15:33,475:INFO:Checking exceptions
2023-10-21 13:15:33,475:INFO:Importing libraries
2023-10-21 13:15:33,475:INFO:Copying training dataset
2023-10-21 13:15:33,492:INFO:Defining folds
2023-10-21 13:15:33,492:INFO:Declaring metric variables
2023-10-21 13:15:33,492:INFO:Importing untrained model
2023-10-21 13:15:33,492:INFO:Declaring custom model
2023-10-21 13:15:33,492:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 13:15:33,492:INFO:Starting cross validation
2023-10-21 13:15:33,492:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 13:15:36,256:INFO:Calculating mean and std
2023-10-21 13:15:36,256:INFO:Creating metrics dataframe
2023-10-21 13:15:36,256:INFO:Finalizing model
2023-10-21 13:15:36,338:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005240 seconds.
2023-10-21 13:15:36,338:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 13:15:36,339:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-21 13:15:36,339:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-21 13:15:36,340:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-21 13:15:36,648:INFO:Uploading results into container
2023-10-21 13:15:36,649:INFO:Uploading model into container now
2023-10-21 13:15:36,650:INFO:_master_model_container: 3
2023-10-21 13:15:36,650:INFO:_display_container: 4
2023-10-21 13:15:36,651:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 13:15:36,651:INFO:create_model() successfully completed......................................
2023-10-21 13:15:36,856:INFO:SubProcess create_model() end ==================================
2023-10-21 13:15:36,856:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.905
2023-10-21 13:15:36,856:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8993
2023-10-21 13:15:36,856:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-21 13:15:36,856:INFO:choose_better completed
2023-10-21 13:15:36,856:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-21 13:15:36,856:INFO:Creating Dashboard logs
2023-10-21 13:15:36,856:INFO:Model: Light Gradient Boosting Machine
2023-10-21 13:15:36,922:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 13:15:37,122:INFO:Initializing predict_model()
2023-10-21 13:15:37,122:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCD99880>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DB43D040>)
2023-10-21 13:15:37,122:INFO:Checking exceptions
2023-10-21 13:15:37,122:INFO:Preloading libraries
2023-10-21 13:15:37,752:INFO:_master_model_container: 3
2023-10-21 13:15:37,753:INFO:_display_container: 3
2023-10-21 13:15:37,754:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 13:15:37,754:INFO:tune_model() successfully completed......................................
2023-10-21 13:15:37,943:INFO:Initializing finalize_model()
2023-10-21 13:15:37,943:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCD99880>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-21 13:15:37,943:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 13:15:37,955:INFO:Initializing create_model()
2023-10-21 13:15:37,955:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCD99880>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-21 13:15:37,955:INFO:Checking exceptions
2023-10-21 13:15:37,955:INFO:Importing libraries
2023-10-21 13:15:37,955:INFO:Copying training dataset
2023-10-21 13:15:37,955:INFO:Defining folds
2023-10-21 13:15:37,955:INFO:Declaring metric variables
2023-10-21 13:15:37,955:INFO:Importing untrained model
2023-10-21 13:15:37,955:INFO:Declaring custom model
2023-10-21 13:15:37,955:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 13:15:37,955:INFO:Cross validation set to False
2023-10-21 13:15:37,955:INFO:Fitting Model
2023-10-21 13:15:38,055:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005569 seconds.
2023-10-21 13:15:38,055:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 13:15:38,055:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-21 13:15:38,055:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-21 13:15:38,055:INFO:[LightGBM] [Info] Start training from score 77.700043
2023-10-21 13:15:38,336:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-21 13:15:38,336:INFO:create_model() successfully completed......................................
2023-10-21 13:15:38,522:INFO:Creating Dashboard logs
2023-10-21 13:15:38,522:INFO:Model: Light Gradient Boosting Machine
2023-10-21 13:15:38,587:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 13:15:38,955:INFO:_master_model_container: 3
2023-10-21 13:15:38,955:INFO:_display_container: 3
2023-10-21 13:15:38,972:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-21 13:15:38,972:INFO:finalize_model() successfully completed......................................
2023-10-21 13:15:39,172:INFO:Initializing save_model()
2023-10-21 13:15:39,172:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_C, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 13:15:39,172:INFO:Adding model into prep_pipe
2023-10-21 13:15:39,172:WARNING:Only Model saved as it was a pipeline.
2023-10-21 13:15:39,187:INFO:final_model_for_location_C.pkl saved in current working directory
2023-10-21 13:15:39,187:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-21 13:15:39,187:INFO:save_model() successfully completed......................................
2023-10-21 13:47:22,068:INFO:Initializing predict_model()
2023-10-21 13:47:22,068:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCD99880>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209D9514EE0>)
2023-10-21 13:47:22,068:INFO:Checking exceptions
2023-10-21 13:47:22,068:INFO:Preloading libraries
2023-10-21 13:47:22,068:INFO:Set up data.
2023-10-21 13:47:22,102:INFO:Set up index.
2023-10-21 14:11:14,187:INFO:Initializing predict_model()
2023-10-21 14:11:14,187:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCD99880>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209D95198B0>)
2023-10-21 14:11:14,187:INFO:Checking exceptions
2023-10-21 14:11:14,187:INFO:Preloading libraries
2023-10-21 14:11:14,196:INFO:Set up data.
2023-10-21 14:11:14,225:INFO:Set up index.
2023-10-21 14:24:13,932:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\base\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals
  warnings.warn("Maximum Likelihood optimization failed to "

2023-10-21 14:27:19,293:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.
  self._init_dates(dates, freq)

2023-10-21 14:27:19,294:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.
  self._init_dates(dates, freq)

2023-10-21 14:27:19,295:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.
  self._init_dates(dates, freq)

2023-10-21 14:31:24,554:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.
  self._init_dates(dates, freq)

2023-10-21 14:31:24,554:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.
  self._init_dates(dates, freq)

2023-10-21 14:31:24,554:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.
  self._init_dates(dates, freq)

2023-10-21 15:42:01,872:INFO:Initializing predict_model()
2023-10-21 15:42:01,872:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCD99880>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209D9519310>)
2023-10-21 15:42:01,872:INFO:Checking exceptions
2023-10-21 15:42:01,874:INFO:Preloading libraries
2023-10-21 15:42:01,877:INFO:Set up data.
2023-10-21 15:42:01,912:INFO:Set up index.
2023-10-21 15:42:45,886:INFO:PyCaret RegressionExperiment
2023-10-21 15:42:45,886:INFO:Logging name: exp_A
2023-10-21 15:42:45,886:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-21 15:42:45,886:INFO:version 3.1.0
2023-10-21 15:42:45,886:INFO:Initializing setup()
2023-10-21 15:42:45,886:INFO:self.USI: af10
2023-10-21 15:42:45,887:INFO:self._variable_keys: {'transform_target_param', 'exp_name_log', 'y_train', 'logging_param', 'n_jobs_param', 'X_train', 'target_param', 'USI', 'gpu_n_jobs_param', 'fold_groups_param', '_ml_usecase', 'seed', 'fold_generator', 'idx', 'html_param', 'log_plots_param', 'y', 'gpu_param', 'X_test', 'memory', 'y_test', 'data', 'X', 'exp_id', '_available_plots', 'fold_shuffle_param', 'pipeline'}
2023-10-21 15:42:45,887:INFO:Checking environment
2023-10-21 15:42:45,887:INFO:python_version: 3.8.18
2023-10-21 15:42:45,887:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-21 15:42:45,887:INFO:machine: AMD64
2023-10-21 15:42:45,887:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-21 15:42:45,887:INFO:Memory: svmem(total=16505954304, available=4074913792, percent=75.3, used=12431040512, free=4074913792)
2023-10-21 15:42:45,887:INFO:Physical Core: 8
2023-10-21 15:42:45,887:INFO:Logical Core: 16
2023-10-21 15:42:45,887:INFO:Checking libraries
2023-10-21 15:42:45,888:INFO:System:
2023-10-21 15:42:45,888:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-21 15:42:45,888:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-21 15:42:45,888:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-21 15:42:45,888:INFO:PyCaret required dependencies:
2023-10-21 15:42:45,888:INFO:                 pip: 23.3
2023-10-21 15:42:45,888:INFO:          setuptools: 68.0.0
2023-10-21 15:42:45,888:INFO:             pycaret: 3.1.0
2023-10-21 15:42:45,888:INFO:             IPython: 8.12.0
2023-10-21 15:42:45,888:INFO:          ipywidgets: 8.1.1
2023-10-21 15:42:45,888:INFO:                tqdm: 4.66.1
2023-10-21 15:42:45,888:INFO:               numpy: 1.23.5
2023-10-21 15:42:45,888:INFO:              pandas: 1.5.3
2023-10-21 15:42:45,888:INFO:              jinja2: 3.1.2
2023-10-21 15:42:45,888:INFO:               scipy: 1.10.1
2023-10-21 15:42:45,889:INFO:              joblib: 1.3.2
2023-10-21 15:42:45,889:INFO:             sklearn: 1.2.2
2023-10-21 15:42:45,889:INFO:                pyod: 1.1.0
2023-10-21 15:42:45,889:INFO:            imblearn: 0.11.0
2023-10-21 15:42:45,889:INFO:   category_encoders: 2.6.2
2023-10-21 15:42:45,889:INFO:            lightgbm: 4.1.0
2023-10-21 15:42:45,889:INFO:               numba: 0.58.1
2023-10-21 15:42:45,889:INFO:            requests: 2.31.0
2023-10-21 15:42:45,889:INFO:          matplotlib: 3.7.3
2023-10-21 15:42:45,889:INFO:          scikitplot: 0.3.7
2023-10-21 15:42:45,889:INFO:         yellowbrick: 1.5
2023-10-21 15:42:45,889:INFO:              plotly: 5.17.0
2023-10-21 15:42:45,889:INFO:    plotly-resampler: Not installed
2023-10-21 15:42:45,889:INFO:             kaleido: 0.2.1
2023-10-21 15:42:45,889:INFO:           schemdraw: 0.15
2023-10-21 15:42:45,890:INFO:         statsmodels: 0.14.0
2023-10-21 15:42:45,890:INFO:              sktime: 0.21.1
2023-10-21 15:42:45,890:INFO:               tbats: 1.1.3
2023-10-21 15:42:45,890:INFO:            pmdarima: 2.0.3
2023-10-21 15:42:45,890:INFO:              psutil: 5.9.0
2023-10-21 15:42:45,890:INFO:          markupsafe: 2.1.3
2023-10-21 15:42:45,890:INFO:             pickle5: Not installed
2023-10-21 15:42:45,890:INFO:         cloudpickle: 2.2.1
2023-10-21 15:42:45,890:INFO:         deprecation: 2.1.0
2023-10-21 15:42:45,890:INFO:              xxhash: 3.4.1
2023-10-21 15:42:45,890:INFO:           wurlitzer: Not installed
2023-10-21 15:42:45,890:INFO:PyCaret optional dependencies:
2023-10-21 15:42:45,890:INFO:                shap: Not installed
2023-10-21 15:42:45,890:INFO:           interpret: Not installed
2023-10-21 15:42:45,890:INFO:                umap: Not installed
2023-10-21 15:42:45,890:INFO:     ydata_profiling: Not installed
2023-10-21 15:42:45,890:INFO:  explainerdashboard: Not installed
2023-10-21 15:42:45,890:INFO:             autoviz: Not installed
2023-10-21 15:42:45,890:INFO:           fairlearn: Not installed
2023-10-21 15:42:45,892:INFO:          deepchecks: Not installed
2023-10-21 15:42:45,892:INFO:             xgboost: Not installed
2023-10-21 15:42:45,892:INFO:            catboost: 1.2.2
2023-10-21 15:42:45,892:INFO:              kmodes: Not installed
2023-10-21 15:42:45,892:INFO:             mlxtend: Not installed
2023-10-21 15:42:45,892:INFO:       statsforecast: Not installed
2023-10-21 15:42:45,892:INFO:        tune_sklearn: Not installed
2023-10-21 15:42:45,892:INFO:                 ray: Not installed
2023-10-21 15:42:45,892:INFO:            hyperopt: Not installed
2023-10-21 15:42:45,892:INFO:              optuna: Not installed
2023-10-21 15:42:45,892:INFO:               skopt: Not installed
2023-10-21 15:42:45,892:INFO:              mlflow: 2.7.1
2023-10-21 15:42:45,892:INFO:              gradio: Not installed
2023-10-21 15:42:45,892:INFO:             fastapi: Not installed
2023-10-21 15:42:45,892:INFO:             uvicorn: Not installed
2023-10-21 15:42:45,892:INFO:              m2cgen: Not installed
2023-10-21 15:42:45,892:INFO:           evidently: Not installed
2023-10-21 15:42:45,892:INFO:               fugue: Not installed
2023-10-21 15:42:45,893:INFO:           streamlit: Not installed
2023-10-21 15:42:45,893:INFO:             prophet: Not installed
2023-10-21 15:42:45,893:INFO:None
2023-10-21 15:42:45,893:INFO:Set up data.
2023-10-21 15:42:45,932:INFO:Set up folding strategy.
2023-10-21 15:42:45,932:INFO:Set up train/test split.
2023-10-21 15:42:45,960:INFO:Set up index.
2023-10-21 15:42:45,963:INFO:Assigning column types.
2023-10-21 15:42:45,989:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-21 15:42:45,990:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 15:42:45,995:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,001:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,100:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,148:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,149:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:42:46,150:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:42:46,150:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,156:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,161:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,240:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,288:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,288:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:42:46,288:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:42:46,289:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-21 15:42:46,295:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,300:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,378:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,426:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,426:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:42:46,427:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:42:46,433:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,438:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,527:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,579:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,579:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:42:46,580:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:42:46,580:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-21 15:42:46,584:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,662:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,710:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,710:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:42:46,710:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:42:46,725:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,804:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,852:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,852:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:42:46,852:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:42:46,852:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-21 15:42:46,936:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,987:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,988:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:42:46,988:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:42:47,067:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:42:47,115:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:42:47,115:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:42:47,115:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:42:47,115:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-21 15:42:47,210:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:42:47,257:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:42:47,257:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:42:47,337:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:42:47,402:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:42:47,402:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:42:47,402:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-21 15:42:47,531:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:42:47,531:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:42:47,670:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:42:47,670:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:42:47,670:INFO:Preparing preprocessing pipeline...
2023-10-21 15:42:47,670:INFO:Set up simple imputation.
2023-10-21 15:42:47,670:INFO:Set up column name cleaning.
2023-10-21 15:42:47,732:INFO:Finished creating preprocessing pipeline.
2023-10-21 15:42:47,732:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 15:42:47,732:INFO:Creating final display dataframe.
2023-10-21 15:42:47,952:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (34061, 50)
4        Transformed data shape   (34061, 50)
5   Transformed train set shape   (23842, 50)
6    Transformed test set shape   (10219, 50)
7              Numeric features            49
8      Rows with missing values         97.6%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_A
19                          USI          af10
2023-10-21 15:42:48,101:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:42:48,101:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:42:48,231:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:42:48,231:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:42:48,231:INFO:Logging experiment in loggers
2023-10-21 15:42:48,346:INFO:SubProcess save_model() called ==================================
2023-10-21 15:42:48,346:INFO:Initializing save_model()
2023-10-21 15:42:48,346:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmp1lfcq50a\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 15:42:48,346:INFO:Adding model into prep_pipe
2023-10-21 15:42:48,346:WARNING:Only Model saved as it was a pipeline.
2023-10-21 15:42:48,362:INFO:C:\Users\thoma\AppData\Local\Temp\tmp1lfcq50a\Transformation Pipeline.pkl saved in current working directory
2023-10-21 15:42:48,368:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 15:42:48,369:INFO:save_model() successfully completed......................................
2023-10-21 15:42:48,618:INFO:SubProcess save_model() end ==================================
2023-10-21 15:42:48,702:INFO:setup() successfully completed in 2.35s...............
2023-10-21 15:42:48,702:INFO:Initializing create_model()
2023-10-21 15:42:48,702:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D936C850>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 15:42:48,702:INFO:Checking exceptions
2023-10-21 15:42:48,702:INFO:Importing libraries
2023-10-21 15:42:48,702:INFO:Copying training dataset
2023-10-21 15:42:48,734:INFO:Defining folds
2023-10-21 15:42:48,734:INFO:Declaring metric variables
2023-10-21 15:42:48,734:INFO:Importing untrained model
2023-10-21 15:42:48,736:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 15:42:48,736:INFO:Starting cross validation
2023-10-21 15:42:48,736:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 15:42:58,941:INFO:Calculating mean and std
2023-10-21 15:42:58,941:INFO:Creating metrics dataframe
2023-10-21 15:42:58,941:INFO:Finalizing model
2023-10-21 15:42:59,042:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005359 seconds.
2023-10-21 15:42:59,042:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:42:59,042:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 15:42:59,042:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 15:42:59,042:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-21 15:42:59,307:INFO:Creating Dashboard logs
2023-10-21 15:42:59,307:INFO:Model: Light Gradient Boosting Machine
2023-10-21 15:42:59,390:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 15:42:59,575:INFO:Initializing predict_model()
2023-10-21 15:42:59,575:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D936C850>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DB02D9D0>)
2023-10-21 15:42:59,575:INFO:Checking exceptions
2023-10-21 15:42:59,575:INFO:Preloading libraries
2023-10-21 15:43:00,271:INFO:Uploading results into container
2023-10-21 15:43:00,273:INFO:Uploading model into container now
2023-10-21 15:43:00,273:INFO:_master_model_container: 1
2023-10-21 15:43:00,273:INFO:_display_container: 2
2023-10-21 15:43:00,273:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 15:43:00,273:INFO:create_model() successfully completed......................................
2023-10-21 15:43:00,538:INFO:Initializing tune_model()
2023-10-21 15:43:00,538:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D936C850>)
2023-10-21 15:43:00,539:INFO:Checking exceptions
2023-10-21 15:43:00,540:INFO:Copying training dataset
2023-10-21 15:43:00,569:INFO:Checking base model
2023-10-21 15:43:00,569:INFO:Base model : Light Gradient Boosting Machine
2023-10-21 15:43:00,569:INFO:Declaring metric variables
2023-10-21 15:43:00,570:INFO:Defining Hyperparameters
2023-10-21 15:43:00,790:INFO:Tuning with n_jobs=-1
2023-10-21 15:43:00,790:INFO:Initializing RandomizedSearchCV
2023-10-21 15:43:50,349:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-21 15:43:50,349:INFO:Hyperparameter search completed
2023-10-21 15:43:50,349:INFO:SubProcess create_model() called ==================================
2023-10-21 15:43:50,349:INFO:Initializing create_model()
2023-10-21 15:43:50,349:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D936C850>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209DB287A60>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-21 15:43:50,349:INFO:Checking exceptions
2023-10-21 15:43:50,349:INFO:Importing libraries
2023-10-21 15:43:50,349:INFO:Copying training dataset
2023-10-21 15:43:50,382:INFO:Defining folds
2023-10-21 15:43:50,383:INFO:Declaring metric variables
2023-10-21 15:43:50,383:INFO:Importing untrained model
2023-10-21 15:43:50,383:INFO:Declaring custom model
2023-10-21 15:43:50,384:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 15:43:50,385:INFO:Starting cross validation
2023-10-21 15:43:50,386:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 15:43:58,073:INFO:Calculating mean and std
2023-10-21 15:43:58,075:INFO:Creating metrics dataframe
2023-10-21 15:43:58,075:INFO:Finalizing model
2023-10-21 15:43:58,137:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 15:43:58,137:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 15:43:58,137:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 15:43:58,175:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 15:43:58,175:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 15:43:58,175:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 15:43:58,175:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005496 seconds.
2023-10-21 15:43:58,175:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:43:58,175:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 15:43:58,175:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 15:43:58,191:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-21 15:43:59,341:INFO:Uploading results into container
2023-10-21 15:43:59,341:INFO:Uploading model into container now
2023-10-21 15:43:59,356:INFO:_master_model_container: 2
2023-10-21 15:43:59,357:INFO:_display_container: 3
2023-10-21 15:43:59,358:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-21 15:43:59,359:INFO:create_model() successfully completed......................................
2023-10-21 15:43:59,624:INFO:SubProcess create_model() end ==================================
2023-10-21 15:43:59,624:INFO:choose_better activated
2023-10-21 15:43:59,624:INFO:SubProcess create_model() called ==================================
2023-10-21 15:43:59,624:INFO:Initializing create_model()
2023-10-21 15:43:59,624:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D936C850>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 15:43:59,624:INFO:Checking exceptions
2023-10-21 15:43:59,624:INFO:Importing libraries
2023-10-21 15:43:59,624:INFO:Copying training dataset
2023-10-21 15:43:59,660:INFO:Defining folds
2023-10-21 15:43:59,660:INFO:Declaring metric variables
2023-10-21 15:43:59,660:INFO:Importing untrained model
2023-10-21 15:43:59,660:INFO:Declaring custom model
2023-10-21 15:43:59,661:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 15:43:59,662:INFO:Starting cross validation
2023-10-21 15:43:59,663:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 15:44:02,905:INFO:Calculating mean and std
2023-10-21 15:44:02,905:INFO:Creating metrics dataframe
2023-10-21 15:44:02,905:INFO:Finalizing model
2023-10-21 15:44:03,005:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006647 seconds.
2023-10-21 15:44:03,005:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:03,005:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 15:44:03,005:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 15:44:03,005:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-21 15:44:03,288:INFO:Uploading results into container
2023-10-21 15:44:03,304:INFO:Uploading model into container now
2023-10-21 15:44:03,304:INFO:_master_model_container: 3
2023-10-21 15:44:03,304:INFO:_display_container: 4
2023-10-21 15:44:03,304:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 15:44:03,304:INFO:create_model() successfully completed......................................
2023-10-21 15:44:03,588:INFO:SubProcess create_model() end ==================================
2023-10-21 15:44:03,588:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8716
2023-10-21 15:44:03,588:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8712
2023-10-21 15:44:03,588:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-21 15:44:03,588:INFO:choose_better completed
2023-10-21 15:44:03,588:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-21 15:44:03,588:INFO:Creating Dashboard logs
2023-10-21 15:44:03,588:INFO:Model: Light Gradient Boosting Machine
2023-10-21 15:44:03,654:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 15:44:03,842:INFO:Initializing predict_model()
2023-10-21 15:44:03,842:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D936C850>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DB02D310>)
2023-10-21 15:44:03,842:INFO:Checking exceptions
2023-10-21 15:44:03,842:INFO:Preloading libraries
2023-10-21 15:44:04,503:INFO:_master_model_container: 3
2023-10-21 15:44:04,503:INFO:_display_container: 3
2023-10-21 15:44:04,503:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 15:44:04,503:INFO:tune_model() successfully completed......................................
2023-10-21 15:44:04,720:INFO:Initializing ensemble_model()
2023-10-21 15:44:04,720:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D936C850>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-21 15:44:04,720:INFO:Checking exceptions
2023-10-21 15:44:04,744:INFO:Importing libraries
2023-10-21 15:44:04,744:INFO:Copying training dataset
2023-10-21 15:44:04,744:INFO:Checking base model
2023-10-21 15:44:04,744:INFO:Base model : Light Gradient Boosting Machine
2023-10-21 15:44:04,744:INFO:Importing untrained ensembler
2023-10-21 15:44:04,744:INFO:Ensemble method set to Bagging
2023-10-21 15:44:04,744:INFO:SubProcess create_model() called ==================================
2023-10-21 15:44:04,744:INFO:Initializing create_model()
2023-10-21 15:44:04,744:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D936C850>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209DB287A60>, model_only=True, return_train_score=False, kwargs={})
2023-10-21 15:44:04,744:INFO:Checking exceptions
2023-10-21 15:44:04,744:INFO:Importing libraries
2023-10-21 15:44:04,744:INFO:Copying training dataset
2023-10-21 15:44:04,771:INFO:Defining folds
2023-10-21 15:44:04,771:INFO:Declaring metric variables
2023-10-21 15:44:04,771:INFO:Importing untrained model
2023-10-21 15:44:04,771:INFO:Declaring custom model
2023-10-21 15:44:04,771:INFO:Bagging Regressor Imported successfully
2023-10-21 15:44:04,771:INFO:Starting cross validation
2023-10-21 15:44:04,775:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 15:44:28,750:INFO:Calculating mean and std
2023-10-21 15:44:28,750:INFO:Creating metrics dataframe
2023-10-21 15:44:28,750:INFO:Finalizing model
2023-10-21 15:44:28,833:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004075 seconds.
2023-10-21 15:44:28,833:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:28,833:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 15:44:28,833:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 15:44:28,833:INFO:[LightGBM] [Info] Start training from score 626.831517
2023-10-21 15:44:29,083:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005246 seconds.
2023-10-21 15:44:29,083:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:29,083:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 15:44:29,083:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 15:44:29,083:INFO:[LightGBM] [Info] Start training from score 640.013980
2023-10-21 15:44:29,333:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005388 seconds.
2023-10-21 15:44:29,333:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:29,333:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 15:44:29,333:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 15:44:29,333:INFO:[LightGBM] [Info] Start training from score 623.946930
2023-10-21 15:44:29,583:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005223 seconds.
2023-10-21 15:44:29,583:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:29,583:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 15:44:29,583:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 15:44:29,583:INFO:[LightGBM] [Info] Start training from score 632.335152
2023-10-21 15:44:29,832:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004364 seconds.
2023-10-21 15:44:29,832:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:29,832:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 15:44:29,832:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 15:44:29,848:INFO:[LightGBM] [Info] Start training from score 620.070240
2023-10-21 15:44:30,165:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005504 seconds.
2023-10-21 15:44:30,165:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:30,165:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 15:44:30,165:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 15:44:30,165:INFO:[LightGBM] [Info] Start training from score 635.137343
2023-10-21 15:44:30,465:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006071 seconds.
2023-10-21 15:44:30,465:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:30,465:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 15:44:30,465:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 15:44:30,465:INFO:[LightGBM] [Info] Start training from score 620.066941
2023-10-21 15:44:30,765:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006645 seconds.
2023-10-21 15:44:30,765:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:30,765:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 15:44:30,765:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 15:44:30,765:INFO:[LightGBM] [Info] Start training from score 623.069874
2023-10-21 15:44:31,031:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004510 seconds.
2023-10-21 15:44:31,031:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:31,047:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 15:44:31,047:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 15:44:31,048:INFO:[LightGBM] [Info] Start training from score 633.817057
2023-10-21 15:44:31,315:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005548 seconds.
2023-10-21 15:44:31,315:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:31,315:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 15:44:31,315:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 15:44:31,315:INFO:[LightGBM] [Info] Start training from score 641.113408
2023-10-21 15:44:31,564:INFO:Uploading results into container
2023-10-21 15:44:31,564:INFO:Uploading model into container now
2023-10-21 15:44:31,564:INFO:_master_model_container: 4
2023-10-21 15:44:31,564:INFO:_display_container: 4
2023-10-21 15:44:31,564:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-21 15:44:31,564:INFO:create_model() successfully completed......................................
2023-10-21 15:44:31,815:INFO:SubProcess create_model() end ==================================
2023-10-21 15:44:31,815:INFO:Creating Dashboard logs
2023-10-21 15:44:31,815:INFO:Model: Bagging Regressor
2023-10-21 15:44:31,897:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-21 15:44:32,114:INFO:Initializing predict_model()
2023-10-21 15:44:32,114:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D936C850>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020986AFBCA0>)
2023-10-21 15:44:32,114:INFO:Checking exceptions
2023-10-21 15:44:32,114:INFO:Preloading libraries
2023-10-21 15:44:32,963:INFO:_master_model_container: 4
2023-10-21 15:44:32,963:INFO:_display_container: 4
2023-10-21 15:44:32,963:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-21 15:44:32,963:INFO:ensemble_model() successfully completed......................................
2023-10-21 15:44:33,180:INFO:Initializing finalize_model()
2023-10-21 15:44:33,180:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D936C850>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-21 15:44:33,180:INFO:Finalizing BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-21 15:44:33,196:INFO:Initializing create_model()
2023-10-21 15:44:33,196:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D936C850>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-21 15:44:33,196:INFO:Checking exceptions
2023-10-21 15:44:33,196:INFO:Importing libraries
2023-10-21 15:44:33,196:INFO:Copying training dataset
2023-10-21 15:44:33,196:INFO:Defining folds
2023-10-21 15:44:33,196:INFO:Declaring metric variables
2023-10-21 15:44:33,196:INFO:Importing untrained model
2023-10-21 15:44:33,196:INFO:Declaring custom model
2023-10-21 15:44:33,196:INFO:Bagging Regressor Imported successfully
2023-10-21 15:44:33,196:INFO:Cross validation set to False
2023-10-21 15:44:33,196:INFO:Fitting Model
2023-10-21 15:44:33,313:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008017 seconds.
2023-10-21 15:44:33,313:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:33,313:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-21 15:44:33,313:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-21 15:44:33,313:INFO:[LightGBM] [Info] Start training from score 634.491655
2023-10-21 15:44:33,713:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006599 seconds.
2023-10-21 15:44:33,713:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:33,713:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-21 15:44:33,713:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-21 15:44:33,728:INFO:[LightGBM] [Info] Start training from score 635.470959
2023-10-21 15:44:34,096:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007300 seconds.
2023-10-21 15:44:34,096:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:34,096:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-21 15:44:34,096:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-21 15:44:34,096:INFO:[LightGBM] [Info] Start training from score 634.053589
2023-10-21 15:44:34,528:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008366 seconds.
2023-10-21 15:44:34,528:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:34,528:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-21 15:44:34,528:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-21 15:44:34,528:INFO:[LightGBM] [Info] Start training from score 635.251785
2023-10-21 15:44:34,962:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006308 seconds.
2023-10-21 15:44:34,962:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:34,962:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-21 15:44:34,962:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-21 15:44:34,962:INFO:[LightGBM] [Info] Start training from score 627.555784
2023-10-21 15:44:35,261:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008473 seconds.
2023-10-21 15:44:35,261:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:35,262:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-21 15:44:35,262:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-21 15:44:35,262:INFO:[LightGBM] [Info] Start training from score 638.162596
2023-10-21 15:44:35,578:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008136 seconds.
2023-10-21 15:44:35,578:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:35,578:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-21 15:44:35,578:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-21 15:44:35,578:INFO:[LightGBM] [Info] Start training from score 633.181363
2023-10-21 15:44:35,861:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006286 seconds.
2023-10-21 15:44:35,861:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:35,861:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-21 15:44:35,861:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-21 15:44:35,861:INFO:[LightGBM] [Info] Start training from score 611.992287
2023-10-21 15:44:36,161:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008329 seconds.
2023-10-21 15:44:36,161:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:36,161:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-21 15:44:36,161:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-21 15:44:36,161:INFO:[LightGBM] [Info] Start training from score 638.181417
2023-10-21 15:44:36,477:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008043 seconds.
2023-10-21 15:44:36,477:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:36,477:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-21 15:44:36,477:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-21 15:44:36,477:INFO:[LightGBM] [Info] Start training from score 639.502137
2023-10-21 15:44:36,710:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-21 15:44:36,710:INFO:create_model() successfully completed......................................
2023-10-21 15:44:36,944:INFO:Creating Dashboard logs
2023-10-21 15:44:36,944:INFO:Model: Bagging Regressor
2023-10-21 15:44:37,010:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-21 15:44:37,477:INFO:_master_model_container: 4
2023-10-21 15:44:37,477:INFO:_display_container: 4
2023-10-21 15:44:37,477:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-21 15:44:37,477:INFO:finalize_model() successfully completed......................................
2023-10-21 15:44:37,693:INFO:Initializing save_model()
2023-10-21 15:44:37,693:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), model_name=final_model_for_location_A, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 15:44:37,693:INFO:Adding model into prep_pipe
2023-10-21 15:44:37,693:WARNING:Only Model saved as it was a pipeline.
2023-10-21 15:44:37,776:INFO:final_model_for_location_A.pkl saved in current working directory
2023-10-21 15:44:37,791:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-21 15:44:37,791:INFO:save_model() successfully completed......................................
2023-10-21 15:44:38,026:INFO:PyCaret RegressionExperiment
2023-10-21 15:44:38,026:INFO:Logging name: exp_B
2023-10-21 15:44:38,026:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-21 15:44:38,026:INFO:version 3.1.0
2023-10-21 15:44:38,026:INFO:Initializing setup()
2023-10-21 15:44:38,026:INFO:self.USI: e04f
2023-10-21 15:44:38,026:INFO:self._variable_keys: {'transform_target_param', 'exp_name_log', 'y_train', 'logging_param', 'n_jobs_param', 'X_train', 'target_param', 'USI', 'gpu_n_jobs_param', 'fold_groups_param', '_ml_usecase', 'seed', 'fold_generator', 'idx', 'html_param', 'log_plots_param', 'y', 'gpu_param', 'X_test', 'memory', 'y_test', 'data', 'X', 'exp_id', '_available_plots', 'fold_shuffle_param', 'pipeline'}
2023-10-21 15:44:38,026:INFO:Checking environment
2023-10-21 15:44:38,026:INFO:python_version: 3.8.18
2023-10-21 15:44:38,026:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-21 15:44:38,026:INFO:machine: AMD64
2023-10-21 15:44:38,026:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-21 15:44:38,026:INFO:Memory: svmem(total=16505954304, available=2976317440, percent=82.0, used=13529636864, free=2976317440)
2023-10-21 15:44:38,026:INFO:Physical Core: 8
2023-10-21 15:44:38,026:INFO:Logical Core: 16
2023-10-21 15:44:38,026:INFO:Checking libraries
2023-10-21 15:44:38,026:INFO:System:
2023-10-21 15:44:38,026:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-21 15:44:38,026:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-21 15:44:38,026:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-21 15:44:38,026:INFO:PyCaret required dependencies:
2023-10-21 15:44:38,026:INFO:                 pip: 23.3
2023-10-21 15:44:38,026:INFO:          setuptools: 68.0.0
2023-10-21 15:44:38,026:INFO:             pycaret: 3.1.0
2023-10-21 15:44:38,026:INFO:             IPython: 8.12.0
2023-10-21 15:44:38,026:INFO:          ipywidgets: 8.1.1
2023-10-21 15:44:38,026:INFO:                tqdm: 4.66.1
2023-10-21 15:44:38,026:INFO:               numpy: 1.23.5
2023-10-21 15:44:38,026:INFO:              pandas: 1.5.3
2023-10-21 15:44:38,026:INFO:              jinja2: 3.1.2
2023-10-21 15:44:38,026:INFO:               scipy: 1.10.1
2023-10-21 15:44:38,026:INFO:              joblib: 1.3.2
2023-10-21 15:44:38,026:INFO:             sklearn: 1.2.2
2023-10-21 15:44:38,026:INFO:                pyod: 1.1.0
2023-10-21 15:44:38,026:INFO:            imblearn: 0.11.0
2023-10-21 15:44:38,026:INFO:   category_encoders: 2.6.2
2023-10-21 15:44:38,026:INFO:            lightgbm: 4.1.0
2023-10-21 15:44:38,026:INFO:               numba: 0.58.1
2023-10-21 15:44:38,026:INFO:            requests: 2.31.0
2023-10-21 15:44:38,026:INFO:          matplotlib: 3.7.3
2023-10-21 15:44:38,026:INFO:          scikitplot: 0.3.7
2023-10-21 15:44:38,026:INFO:         yellowbrick: 1.5
2023-10-21 15:44:38,026:INFO:              plotly: 5.17.0
2023-10-21 15:44:38,026:INFO:    plotly-resampler: Not installed
2023-10-21 15:44:38,026:INFO:             kaleido: 0.2.1
2023-10-21 15:44:38,026:INFO:           schemdraw: 0.15
2023-10-21 15:44:38,026:INFO:         statsmodels: 0.14.0
2023-10-21 15:44:38,041:INFO:              sktime: 0.21.1
2023-10-21 15:44:38,041:INFO:               tbats: 1.1.3
2023-10-21 15:44:38,041:INFO:            pmdarima: 2.0.3
2023-10-21 15:44:38,041:INFO:              psutil: 5.9.0
2023-10-21 15:44:38,041:INFO:          markupsafe: 2.1.3
2023-10-21 15:44:38,041:INFO:             pickle5: Not installed
2023-10-21 15:44:38,041:INFO:         cloudpickle: 2.2.1
2023-10-21 15:44:38,041:INFO:         deprecation: 2.1.0
2023-10-21 15:44:38,041:INFO:              xxhash: 3.4.1
2023-10-21 15:44:38,041:INFO:           wurlitzer: Not installed
2023-10-21 15:44:38,041:INFO:PyCaret optional dependencies:
2023-10-21 15:44:38,041:INFO:                shap: Not installed
2023-10-21 15:44:38,041:INFO:           interpret: Not installed
2023-10-21 15:44:38,042:INFO:                umap: Not installed
2023-10-21 15:44:38,042:INFO:     ydata_profiling: Not installed
2023-10-21 15:44:38,042:INFO:  explainerdashboard: Not installed
2023-10-21 15:44:38,042:INFO:             autoviz: Not installed
2023-10-21 15:44:38,042:INFO:           fairlearn: Not installed
2023-10-21 15:44:38,042:INFO:          deepchecks: Not installed
2023-10-21 15:44:38,042:INFO:             xgboost: Not installed
2023-10-21 15:44:38,042:INFO:            catboost: 1.2.2
2023-10-21 15:44:38,042:INFO:              kmodes: Not installed
2023-10-21 15:44:38,042:INFO:             mlxtend: Not installed
2023-10-21 15:44:38,042:INFO:       statsforecast: Not installed
2023-10-21 15:44:38,042:INFO:        tune_sklearn: Not installed
2023-10-21 15:44:38,042:INFO:                 ray: Not installed
2023-10-21 15:44:38,042:INFO:            hyperopt: Not installed
2023-10-21 15:44:38,042:INFO:              optuna: Not installed
2023-10-21 15:44:38,042:INFO:               skopt: Not installed
2023-10-21 15:44:38,042:INFO:              mlflow: 2.7.1
2023-10-21 15:44:38,042:INFO:              gradio: Not installed
2023-10-21 15:44:38,042:INFO:             fastapi: Not installed
2023-10-21 15:44:38,042:INFO:             uvicorn: Not installed
2023-10-21 15:44:38,042:INFO:              m2cgen: Not installed
2023-10-21 15:44:38,042:INFO:           evidently: Not installed
2023-10-21 15:44:38,042:INFO:               fugue: Not installed
2023-10-21 15:44:38,042:INFO:           streamlit: Not installed
2023-10-21 15:44:38,042:INFO:             prophet: Not installed
2023-10-21 15:44:38,042:INFO:None
2023-10-21 15:44:38,042:INFO:Set up data.
2023-10-21 15:44:38,060:INFO:Set up folding strategy.
2023-10-21 15:44:38,060:INFO:Set up train/test split.
2023-10-21 15:44:38,093:INFO:Set up index.
2023-10-21 15:44:38,093:INFO:Assigning column types.
2023-10-21 15:44:38,110:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-21 15:44:38,110:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,124:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,126:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,209:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,260:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,260:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:44:38,260:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:44:38,260:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,274:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,276:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,358:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,409:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,409:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:44:38,409:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:44:38,409:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-21 15:44:38,409:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,409:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,492:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,558:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,559:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:44:38,559:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:44:38,561:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,561:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,642:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,693:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,693:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:44:38,707:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:44:38,707:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-21 15:44:38,708:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,792:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,842:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,857:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:44:38,857:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:44:38,869:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,942:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,991:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,991:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:44:38,991:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:44:38,991:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-21 15:44:39,092:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:44:39,142:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:44:39,142:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:44:39,142:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:44:39,241:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:44:39,291:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:44:39,291:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:44:39,291:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:44:39,291:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-21 15:44:39,378:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:44:39,425:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:44:39,425:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:44:39,525:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:44:39,574:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:44:39,574:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:44:39,574:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-21 15:44:39,724:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:44:39,724:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:44:39,881:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:44:39,881:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:44:39,883:INFO:Preparing preprocessing pipeline...
2023-10-21 15:44:39,883:INFO:Set up simple imputation.
2023-10-21 15:44:39,883:INFO:Set up column name cleaning.
2023-10-21 15:44:39,941:INFO:Finished creating preprocessing pipeline.
2023-10-21 15:44:39,956:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 15:44:39,956:INFO:Creating final display dataframe.
2023-10-21 15:44:40,166:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (32819, 50)
4        Transformed data shape   (32819, 50)
5   Transformed train set shape   (22973, 50)
6    Transformed test set shape    (9846, 50)
7              Numeric features            49
8      Rows with missing values         95.9%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_B
19                          USI          e04f
2023-10-21 15:44:40,307:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:44:40,307:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:44:40,440:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:44:40,440:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:44:40,440:INFO:Logging experiment in loggers
2023-10-21 15:44:40,567:INFO:SubProcess save_model() called ==================================
2023-10-21 15:44:40,573:INFO:Initializing save_model()
2023-10-21 15:44:40,573:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmpc91y37zv\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 15:44:40,573:INFO:Adding model into prep_pipe
2023-10-21 15:44:40,573:WARNING:Only Model saved as it was a pipeline.
2023-10-21 15:44:40,573:INFO:C:\Users\thoma\AppData\Local\Temp\tmpc91y37zv\Transformation Pipeline.pkl saved in current working directory
2023-10-21 15:44:40,590:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 15:44:40,590:INFO:save_model() successfully completed......................................
2023-10-21 15:44:40,790:INFO:SubProcess save_model() end ==================================
2023-10-21 15:44:40,841:INFO:setup() successfully completed in 2.41s...............
2023-10-21 15:44:40,841:INFO:Initializing create_model()
2023-10-21 15:44:40,841:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCAFE9D0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 15:44:40,841:INFO:Checking exceptions
2023-10-21 15:44:40,841:INFO:Importing libraries
2023-10-21 15:44:40,841:INFO:Copying training dataset
2023-10-21 15:44:40,868:INFO:Defining folds
2023-10-21 15:44:40,868:INFO:Declaring metric variables
2023-10-21 15:44:40,868:INFO:Importing untrained model
2023-10-21 15:44:40,869:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 15:44:40,869:INFO:Starting cross validation
2023-10-21 15:44:40,870:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 15:44:43,655:INFO:Calculating mean and std
2023-10-21 15:44:43,655:INFO:Creating metrics dataframe
2023-10-21 15:44:43,655:INFO:Finalizing model
2023-10-21 15:44:43,738:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004451 seconds.
2023-10-21 15:44:43,738:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:43,738:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 15:44:43,738:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 15:44:43,753:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-21 15:44:43,989:INFO:Creating Dashboard logs
2023-10-21 15:44:43,989:INFO:Model: Light Gradient Boosting Machine
2023-10-21 15:44:44,087:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 15:44:44,271:INFO:Initializing predict_model()
2023-10-21 15:44:44,271:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCAFE9D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002098123F550>)
2023-10-21 15:44:44,271:INFO:Checking exceptions
2023-10-21 15:44:44,271:INFO:Preloading libraries
2023-10-21 15:44:44,966:INFO:Uploading results into container
2023-10-21 15:44:44,966:INFO:Uploading model into container now
2023-10-21 15:44:44,970:INFO:_master_model_container: 1
2023-10-21 15:44:44,970:INFO:_display_container: 2
2023-10-21 15:44:44,970:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 15:44:44,970:INFO:create_model() successfully completed......................................
2023-10-21 15:44:45,170:INFO:Initializing tune_model()
2023-10-21 15:44:45,170:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCAFE9D0>)
2023-10-21 15:44:45,170:INFO:Checking exceptions
2023-10-21 15:44:45,187:INFO:Copying training dataset
2023-10-21 15:44:45,205:INFO:Checking base model
2023-10-21 15:44:45,205:INFO:Base model : Light Gradient Boosting Machine
2023-10-21 15:44:45,205:INFO:Declaring metric variables
2023-10-21 15:44:45,205:INFO:Defining Hyperparameters
2023-10-21 15:44:45,404:INFO:Tuning with n_jobs=-1
2023-10-21 15:44:45,404:INFO:Initializing RandomizedSearchCV
2023-10-21 15:45:31,981:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-21 15:45:31,981:INFO:Hyperparameter search completed
2023-10-21 15:45:31,981:INFO:SubProcess create_model() called ==================================
2023-10-21 15:45:31,981:INFO:Initializing create_model()
2023-10-21 15:45:31,981:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCAFE9D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209DAC11A60>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-21 15:45:31,981:INFO:Checking exceptions
2023-10-21 15:45:31,981:INFO:Importing libraries
2023-10-21 15:45:31,981:INFO:Copying training dataset
2023-10-21 15:45:32,017:INFO:Defining folds
2023-10-21 15:45:32,017:INFO:Declaring metric variables
2023-10-21 15:45:32,017:INFO:Importing untrained model
2023-10-21 15:45:32,017:INFO:Declaring custom model
2023-10-21 15:45:32,017:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 15:45:32,017:INFO:Starting cross validation
2023-10-21 15:45:32,017:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 15:45:43,372:INFO:Calculating mean and std
2023-10-21 15:45:43,372:INFO:Creating metrics dataframe
2023-10-21 15:45:43,372:INFO:Finalizing model
2023-10-21 15:45:43,422:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 15:45:43,422:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 15:45:43,422:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 15:45:43,455:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 15:45:43,455:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 15:45:43,455:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 15:45:43,472:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005311 seconds.
2023-10-21 15:45:43,472:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:45:43,472:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 15:45:43,472:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 15:45:43,472:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-21 15:45:44,654:INFO:Uploading results into container
2023-10-21 15:45:44,654:INFO:Uploading model into container now
2023-10-21 15:45:44,654:INFO:_master_model_container: 2
2023-10-21 15:45:44,654:INFO:_display_container: 3
2023-10-21 15:45:44,654:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-21 15:45:44,654:INFO:create_model() successfully completed......................................
2023-10-21 15:45:44,904:INFO:SubProcess create_model() end ==================================
2023-10-21 15:45:44,904:INFO:choose_better activated
2023-10-21 15:45:44,904:INFO:SubProcess create_model() called ==================================
2023-10-21 15:45:44,904:INFO:Initializing create_model()
2023-10-21 15:45:44,904:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCAFE9D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 15:45:44,904:INFO:Checking exceptions
2023-10-21 15:45:44,904:INFO:Importing libraries
2023-10-21 15:45:44,904:INFO:Copying training dataset
2023-10-21 15:45:44,921:INFO:Defining folds
2023-10-21 15:45:44,921:INFO:Declaring metric variables
2023-10-21 15:45:44,921:INFO:Importing untrained model
2023-10-21 15:45:44,921:INFO:Declaring custom model
2023-10-21 15:45:44,921:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 15:45:44,921:INFO:Starting cross validation
2023-10-21 15:45:44,921:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 15:45:47,485:INFO:Calculating mean and std
2023-10-21 15:45:47,485:INFO:Creating metrics dataframe
2023-10-21 15:45:47,485:INFO:Finalizing model
2023-10-21 15:45:47,568:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005051 seconds.
2023-10-21 15:45:47,568:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:45:47,568:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 15:45:47,584:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 15:45:47,585:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-21 15:45:47,852:INFO:Uploading results into container
2023-10-21 15:45:47,852:INFO:Uploading model into container now
2023-10-21 15:45:47,852:INFO:_master_model_container: 3
2023-10-21 15:45:47,852:INFO:_display_container: 4
2023-10-21 15:45:47,852:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 15:45:47,852:INFO:create_model() successfully completed......................................
2023-10-21 15:45:48,085:INFO:SubProcess create_model() end ==================================
2023-10-21 15:45:48,085:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8523
2023-10-21 15:45:48,085:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8523
2023-10-21 15:45:48,085:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-21 15:45:48,085:INFO:choose_better completed
2023-10-21 15:45:48,085:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-21 15:45:48,085:INFO:Creating Dashboard logs
2023-10-21 15:45:48,085:INFO:Model: Light Gradient Boosting Machine
2023-10-21 15:45:48,151:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 15:45:48,335:INFO:Initializing predict_model()
2023-10-21 15:45:48,335:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCAFE9D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209D83A4F70>)
2023-10-21 15:45:48,335:INFO:Checking exceptions
2023-10-21 15:45:48,335:INFO:Preloading libraries
2023-10-21 15:45:49,018:INFO:_master_model_container: 3
2023-10-21 15:45:49,018:INFO:_display_container: 3
2023-10-21 15:45:49,018:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 15:45:49,018:INFO:tune_model() successfully completed......................................
2023-10-21 15:45:49,227:INFO:Initializing ensemble_model()
2023-10-21 15:45:49,228:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCAFE9D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-21 15:45:49,228:INFO:Checking exceptions
2023-10-21 15:45:49,234:INFO:Importing libraries
2023-10-21 15:45:49,234:INFO:Copying training dataset
2023-10-21 15:45:49,234:INFO:Checking base model
2023-10-21 15:45:49,234:INFO:Base model : Light Gradient Boosting Machine
2023-10-21 15:45:49,234:INFO:Importing untrained ensembler
2023-10-21 15:45:49,234:INFO:Ensemble method set to Bagging
2023-10-21 15:45:49,234:INFO:SubProcess create_model() called ==================================
2023-10-21 15:45:49,234:INFO:Initializing create_model()
2023-10-21 15:45:49,234:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCAFE9D0>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209DCD99490>, model_only=True, return_train_score=False, kwargs={})
2023-10-21 15:45:49,234:INFO:Checking exceptions
2023-10-21 15:45:49,234:INFO:Importing libraries
2023-10-21 15:45:49,234:INFO:Copying training dataset
2023-10-21 15:45:49,250:INFO:Defining folds
2023-10-21 15:45:49,250:INFO:Declaring metric variables
2023-10-21 15:45:49,250:INFO:Importing untrained model
2023-10-21 15:45:49,250:INFO:Declaring custom model
2023-10-21 15:45:49,266:INFO:Bagging Regressor Imported successfully
2023-10-21 15:45:49,266:INFO:Starting cross validation
2023-10-21 15:45:49,267:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 15:46:17,913:INFO:Calculating mean and std
2023-10-21 15:46:17,913:INFO:Creating metrics dataframe
2023-10-21 15:46:17,913:INFO:Finalizing model
2023-10-21 15:46:18,008:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005190 seconds.
2023-10-21 15:46:18,008:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:18,008:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 15:46:18,008:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 15:46:18,008:INFO:[LightGBM] [Info] Start training from score 99.624795
2023-10-21 15:46:18,307:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005292 seconds.
2023-10-21 15:46:18,307:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:18,307:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 15:46:18,307:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 15:46:18,307:INFO:[LightGBM] [Info] Start training from score 96.229614
2023-10-21 15:46:18,587:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004625 seconds.
2023-10-21 15:46:18,587:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:18,587:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 15:46:18,587:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 15:46:18,587:INFO:[LightGBM] [Info] Start training from score 95.360987
2023-10-21 15:46:18,860:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005025 seconds.
2023-10-21 15:46:18,860:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:18,860:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 15:46:18,860:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 15:46:18,860:INFO:[LightGBM] [Info] Start training from score 94.348528
2023-10-21 15:46:19,148:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005167 seconds.
2023-10-21 15:46:19,148:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:19,148:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 15:46:19,148:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 15:46:19,148:INFO:[LightGBM] [Info] Start training from score 95.509684
2023-10-21 15:46:19,475:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005509 seconds.
2023-10-21 15:46:19,475:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:19,475:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 15:46:19,475:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 15:46:19,491:INFO:[LightGBM] [Info] Start training from score 96.036959
2023-10-21 15:46:19,775:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006716 seconds.
2023-10-21 15:46:19,775:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:19,775:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 15:46:19,775:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 15:46:19,775:INFO:[LightGBM] [Info] Start training from score 97.844637
2023-10-21 15:46:20,059:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004742 seconds.
2023-10-21 15:46:20,059:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:20,059:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 15:46:20,059:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 15:46:20,060:INFO:[LightGBM] [Info] Start training from score 96.245614
2023-10-21 15:46:20,325:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005188 seconds.
2023-10-21 15:46:20,325:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:20,325:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 15:46:20,325:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 15:46:20,325:INFO:[LightGBM] [Info] Start training from score 97.594984
2023-10-21 15:46:20,591:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006478 seconds.
2023-10-21 15:46:20,591:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:20,606:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 15:46:20,606:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 15:46:20,607:INFO:[LightGBM] [Info] Start training from score 96.370407
2023-10-21 15:46:20,841:INFO:Uploading results into container
2023-10-21 15:46:20,841:INFO:Uploading model into container now
2023-10-21 15:46:20,841:INFO:_master_model_container: 4
2023-10-21 15:46:20,841:INFO:_display_container: 4
2023-10-21 15:46:20,841:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-21 15:46:20,841:INFO:create_model() successfully completed......................................
2023-10-21 15:46:21,089:INFO:SubProcess create_model() end ==================================
2023-10-21 15:46:21,090:INFO:Creating Dashboard logs
2023-10-21 15:46:21,090:INFO:Model: Bagging Regressor
2023-10-21 15:46:21,140:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-21 15:46:21,363:INFO:Initializing predict_model()
2023-10-21 15:46:21,363:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCAFE9D0>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DCE93550>)
2023-10-21 15:46:21,363:INFO:Checking exceptions
2023-10-21 15:46:21,363:INFO:Preloading libraries
2023-10-21 15:46:22,189:INFO:_master_model_container: 4
2023-10-21 15:46:22,189:INFO:_display_container: 4
2023-10-21 15:46:22,189:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-21 15:46:22,189:INFO:ensemble_model() successfully completed......................................
2023-10-21 15:46:22,406:INFO:Initializing finalize_model()
2023-10-21 15:46:22,406:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCAFE9D0>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-21 15:46:22,406:INFO:Finalizing BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-21 15:46:22,423:INFO:Initializing create_model()
2023-10-21 15:46:22,423:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCAFE9D0>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-21 15:46:22,423:INFO:Checking exceptions
2023-10-21 15:46:22,423:INFO:Importing libraries
2023-10-21 15:46:22,423:INFO:Copying training dataset
2023-10-21 15:46:22,423:INFO:Defining folds
2023-10-21 15:46:22,423:INFO:Declaring metric variables
2023-10-21 15:46:22,423:INFO:Importing untrained model
2023-10-21 15:46:22,423:INFO:Declaring custom model
2023-10-21 15:46:22,423:INFO:Bagging Regressor Imported successfully
2023-10-21 15:46:22,423:INFO:Cross validation set to False
2023-10-21 15:46:22,423:INFO:Fitting Model
2023-10-21 15:46:22,570:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007404 seconds.
2023-10-21 15:46:22,571:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:22,571:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-21 15:46:22,572:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-21 15:46:22,573:INFO:[LightGBM] [Info] Start training from score 96.465021
2023-10-21 15:46:22,955:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007477 seconds.
2023-10-21 15:46:22,955:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:22,956:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-21 15:46:22,956:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-21 15:46:22,958:INFO:[LightGBM] [Info] Start training from score 97.264361
2023-10-21 15:46:23,356:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007300 seconds.
2023-10-21 15:46:23,356:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:23,356:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-21 15:46:23,356:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-21 15:46:23,356:INFO:[LightGBM] [Info] Start training from score 95.842370
2023-10-21 15:46:23,772:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007613 seconds.
2023-10-21 15:46:23,772:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:23,772:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-21 15:46:23,772:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-21 15:46:23,772:INFO:[LightGBM] [Info] Start training from score 95.431515
2023-10-21 15:46:24,213:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006845 seconds.
2023-10-21 15:46:24,213:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:24,213:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-21 15:46:24,213:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-21 15:46:24,213:INFO:[LightGBM] [Info] Start training from score 97.222213
2023-10-21 15:46:24,571:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008044 seconds.
2023-10-21 15:46:24,571:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:24,571:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-21 15:46:24,571:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-21 15:46:24,571:INFO:[LightGBM] [Info] Start training from score 97.332701
2023-10-21 15:46:25,004:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007975 seconds.
2023-10-21 15:46:25,004:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:25,004:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-21 15:46:25,004:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-21 15:46:25,004:INFO:[LightGBM] [Info] Start training from score 96.452612
2023-10-21 15:46:25,377:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007679 seconds.
2023-10-21 15:46:25,377:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:25,377:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-21 15:46:25,377:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-21 15:46:25,377:INFO:[LightGBM] [Info] Start training from score 97.322509
2023-10-21 15:46:25,737:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007850 seconds.
2023-10-21 15:46:25,737:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:25,737:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-21 15:46:25,737:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-21 15:46:25,737:INFO:[LightGBM] [Info] Start training from score 96.419103
2023-10-21 15:46:26,103:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007504 seconds.
2023-10-21 15:46:26,103:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:26,103:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-21 15:46:26,103:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-21 15:46:26,103:INFO:[LightGBM] [Info] Start training from score 95.095963
2023-10-21 15:46:26,403:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-21 15:46:26,403:INFO:create_model() successfully completed......................................
2023-10-21 15:46:26,670:INFO:Creating Dashboard logs
2023-10-21 15:46:26,670:INFO:Model: Bagging Regressor
2023-10-21 15:46:26,736:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-21 15:46:27,253:INFO:_master_model_container: 4
2023-10-21 15:46:27,268:INFO:_display_container: 4
2023-10-21 15:46:27,269:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-21 15:46:27,269:INFO:finalize_model() successfully completed......................................
2023-10-21 15:46:27,485:INFO:Initializing save_model()
2023-10-21 15:46:27,485:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), model_name=final_model_for_location_B, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 15:46:27,485:INFO:Adding model into prep_pipe
2023-10-21 15:46:27,485:WARNING:Only Model saved as it was a pipeline.
2023-10-21 15:46:27,552:INFO:final_model_for_location_B.pkl saved in current working directory
2023-10-21 15:46:27,569:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-21 15:46:27,569:INFO:save_model() successfully completed......................................
2023-10-21 15:46:27,819:INFO:PyCaret RegressionExperiment
2023-10-21 15:46:27,819:INFO:Logging name: exp_C
2023-10-21 15:46:27,819:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-21 15:46:27,819:INFO:version 3.1.0
2023-10-21 15:46:27,819:INFO:Initializing setup()
2023-10-21 15:46:27,819:INFO:self.USI: 54c7
2023-10-21 15:46:27,819:INFO:self._variable_keys: {'transform_target_param', 'exp_name_log', 'y_train', 'logging_param', 'n_jobs_param', 'X_train', 'target_param', 'USI', 'gpu_n_jobs_param', 'fold_groups_param', '_ml_usecase', 'seed', 'fold_generator', 'idx', 'html_param', 'log_plots_param', 'y', 'gpu_param', 'X_test', 'memory', 'y_test', 'data', 'X', 'exp_id', '_available_plots', 'fold_shuffle_param', 'pipeline'}
2023-10-21 15:46:27,819:INFO:Checking environment
2023-10-21 15:46:27,819:INFO:python_version: 3.8.18
2023-10-21 15:46:27,819:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-21 15:46:27,819:INFO:machine: AMD64
2023-10-21 15:46:27,819:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-21 15:46:27,819:INFO:Memory: svmem(total=16505954304, available=2961993728, percent=82.1, used=13543960576, free=2961993728)
2023-10-21 15:46:27,819:INFO:Physical Core: 8
2023-10-21 15:46:27,819:INFO:Logical Core: 16
2023-10-21 15:46:27,819:INFO:Checking libraries
2023-10-21 15:46:27,819:INFO:System:
2023-10-21 15:46:27,819:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-21 15:46:27,819:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-21 15:46:27,819:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-21 15:46:27,819:INFO:PyCaret required dependencies:
2023-10-21 15:46:27,819:INFO:                 pip: 23.3
2023-10-21 15:46:27,819:INFO:          setuptools: 68.0.0
2023-10-21 15:46:27,819:INFO:             pycaret: 3.1.0
2023-10-21 15:46:27,819:INFO:             IPython: 8.12.0
2023-10-21 15:46:27,819:INFO:          ipywidgets: 8.1.1
2023-10-21 15:46:27,819:INFO:                tqdm: 4.66.1
2023-10-21 15:46:27,819:INFO:               numpy: 1.23.5
2023-10-21 15:46:27,819:INFO:              pandas: 1.5.3
2023-10-21 15:46:27,819:INFO:              jinja2: 3.1.2
2023-10-21 15:46:27,819:INFO:               scipy: 1.10.1
2023-10-21 15:46:27,819:INFO:              joblib: 1.3.2
2023-10-21 15:46:27,819:INFO:             sklearn: 1.2.2
2023-10-21 15:46:27,819:INFO:                pyod: 1.1.0
2023-10-21 15:46:27,819:INFO:            imblearn: 0.11.0
2023-10-21 15:46:27,819:INFO:   category_encoders: 2.6.2
2023-10-21 15:46:27,819:INFO:            lightgbm: 4.1.0
2023-10-21 15:46:27,819:INFO:               numba: 0.58.1
2023-10-21 15:46:27,819:INFO:            requests: 2.31.0
2023-10-21 15:46:27,819:INFO:          matplotlib: 3.7.3
2023-10-21 15:46:27,819:INFO:          scikitplot: 0.3.7
2023-10-21 15:46:27,819:INFO:         yellowbrick: 1.5
2023-10-21 15:46:27,819:INFO:              plotly: 5.17.0
2023-10-21 15:46:27,819:INFO:    plotly-resampler: Not installed
2023-10-21 15:46:27,819:INFO:             kaleido: 0.2.1
2023-10-21 15:46:27,819:INFO:           schemdraw: 0.15
2023-10-21 15:46:27,819:INFO:         statsmodels: 0.14.0
2023-10-21 15:46:27,819:INFO:              sktime: 0.21.1
2023-10-21 15:46:27,819:INFO:               tbats: 1.1.3
2023-10-21 15:46:27,819:INFO:            pmdarima: 2.0.3
2023-10-21 15:46:27,819:INFO:              psutil: 5.9.0
2023-10-21 15:46:27,819:INFO:          markupsafe: 2.1.3
2023-10-21 15:46:27,819:INFO:             pickle5: Not installed
2023-10-21 15:46:27,819:INFO:         cloudpickle: 2.2.1
2023-10-21 15:46:27,819:INFO:         deprecation: 2.1.0
2023-10-21 15:46:27,819:INFO:              xxhash: 3.4.1
2023-10-21 15:46:27,819:INFO:           wurlitzer: Not installed
2023-10-21 15:46:27,819:INFO:PyCaret optional dependencies:
2023-10-21 15:46:27,819:INFO:                shap: Not installed
2023-10-21 15:46:27,819:INFO:           interpret: Not installed
2023-10-21 15:46:27,819:INFO:                umap: Not installed
2023-10-21 15:46:27,819:INFO:     ydata_profiling: Not installed
2023-10-21 15:46:27,819:INFO:  explainerdashboard: Not installed
2023-10-21 15:46:27,819:INFO:             autoviz: Not installed
2023-10-21 15:46:27,819:INFO:           fairlearn: Not installed
2023-10-21 15:46:27,819:INFO:          deepchecks: Not installed
2023-10-21 15:46:27,819:INFO:             xgboost: Not installed
2023-10-21 15:46:27,819:INFO:            catboost: 1.2.2
2023-10-21 15:46:27,819:INFO:              kmodes: Not installed
2023-10-21 15:46:27,819:INFO:             mlxtend: Not installed
2023-10-21 15:46:27,819:INFO:       statsforecast: Not installed
2023-10-21 15:46:27,819:INFO:        tune_sklearn: Not installed
2023-10-21 15:46:27,819:INFO:                 ray: Not installed
2023-10-21 15:46:27,819:INFO:            hyperopt: Not installed
2023-10-21 15:46:27,819:INFO:              optuna: Not installed
2023-10-21 15:46:27,819:INFO:               skopt: Not installed
2023-10-21 15:46:27,819:INFO:              mlflow: 2.7.1
2023-10-21 15:46:27,819:INFO:              gradio: Not installed
2023-10-21 15:46:27,819:INFO:             fastapi: Not installed
2023-10-21 15:46:27,819:INFO:             uvicorn: Not installed
2023-10-21 15:46:27,819:INFO:              m2cgen: Not installed
2023-10-21 15:46:27,819:INFO:           evidently: Not installed
2023-10-21 15:46:27,834:INFO:               fugue: Not installed
2023-10-21 15:46:27,834:INFO:           streamlit: Not installed
2023-10-21 15:46:27,834:INFO:             prophet: Not installed
2023-10-21 15:46:27,834:INFO:None
2023-10-21 15:46:27,834:INFO:Set up data.
2023-10-21 15:46:27,852:INFO:Set up folding strategy.
2023-10-21 15:46:27,852:INFO:Set up train/test split.
2023-10-21 15:46:27,873:INFO:Set up index.
2023-10-21 15:46:27,873:INFO:Assigning column types.
2023-10-21 15:46:27,885:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-21 15:46:27,885:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 15:46:27,902:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 15:46:27,902:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:46:27,985:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,035:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,035:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:46:28,035:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:46:28,035:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,035:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,050:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,119:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,169:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,169:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:46:28,169:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:46:28,169:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-21 15:46:28,185:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,185:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,268:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,318:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,318:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:46:28,318:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:46:28,318:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,318:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,402:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,451:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,451:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:46:28,451:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:46:28,451:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-21 15:46:28,467:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,536:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,585:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,585:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:46:28,585:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:46:28,602:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,668:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,736:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,736:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:46:28,736:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:46:28,736:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-21 15:46:28,818:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,872:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,872:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:46:28,872:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:46:28,966:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:46:29,018:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:46:29,018:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:46:29,018:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:46:29,018:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-21 15:46:29,101:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:46:29,151:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:46:29,151:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:46:29,236:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:46:29,284:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:46:29,284:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:46:29,299:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-21 15:46:29,436:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:46:29,436:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:46:29,584:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:46:29,584:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:46:29,584:INFO:Preparing preprocessing pipeline...
2023-10-21 15:46:29,584:INFO:Set up simple imputation.
2023-10-21 15:46:29,584:INFO:Set up column name cleaning.
2023-10-21 15:46:29,637:INFO:Finished creating preprocessing pipeline.
2023-10-21 15:46:29,650:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 15:46:29,650:INFO:Creating final display dataframe.
2023-10-21 15:46:29,837:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (26071, 50)
4        Transformed data shape   (26071, 50)
5   Transformed train set shape   (18249, 50)
6    Transformed test set shape    (7822, 50)
7              Numeric features            49
8      Rows with missing values         95.9%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_C
19                          USI          54c7
2023-10-21 15:46:30,000:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:46:30,000:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:46:30,137:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:46:30,148:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:46:30,150:INFO:Logging experiment in loggers
2023-10-21 15:46:30,250:INFO:SubProcess save_model() called ==================================
2023-10-21 15:46:30,267:INFO:Initializing save_model()
2023-10-21 15:46:30,267:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmpdslaeafk\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 15:46:30,267:INFO:Adding model into prep_pipe
2023-10-21 15:46:30,267:WARNING:Only Model saved as it was a pipeline.
2023-10-21 15:46:30,267:INFO:C:\Users\thoma\AppData\Local\Temp\tmpdslaeafk\Transformation Pipeline.pkl saved in current working directory
2023-10-21 15:46:30,267:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 15:46:30,267:INFO:save_model() successfully completed......................................
2023-10-21 15:46:30,483:INFO:SubProcess save_model() end ==================================
2023-10-21 15:46:30,517:INFO:setup() successfully completed in 2.33s...............
2023-10-21 15:46:30,517:INFO:Initializing create_model()
2023-10-21 15:46:30,517:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCBE0D90>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 15:46:30,517:INFO:Checking exceptions
2023-10-21 15:46:30,517:INFO:Importing libraries
2023-10-21 15:46:30,517:INFO:Copying training dataset
2023-10-21 15:46:30,538:INFO:Defining folds
2023-10-21 15:46:30,538:INFO:Declaring metric variables
2023-10-21 15:46:30,538:INFO:Importing untrained model
2023-10-21 15:46:30,538:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 15:46:30,538:INFO:Starting cross validation
2023-10-21 15:46:30,538:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 15:46:33,141:INFO:Calculating mean and std
2023-10-21 15:46:33,141:INFO:Creating metrics dataframe
2023-10-21 15:46:33,147:INFO:Finalizing model
2023-10-21 15:46:33,251:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005335 seconds.
2023-10-21 15:46:33,251:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:33,252:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-21 15:46:33,252:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-21 15:46:33,253:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-21 15:46:33,464:INFO:Creating Dashboard logs
2023-10-21 15:46:33,464:INFO:Model: Light Gradient Boosting Machine
2023-10-21 15:46:33,564:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 15:46:33,747:INFO:Initializing predict_model()
2023-10-21 15:46:33,747:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCBE0D90>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002098DAA5790>)
2023-10-21 15:46:33,747:INFO:Checking exceptions
2023-10-21 15:46:33,747:INFO:Preloading libraries
2023-10-21 15:46:34,430:INFO:Uploading results into container
2023-10-21 15:46:34,430:INFO:Uploading model into container now
2023-10-21 15:46:34,443:INFO:_master_model_container: 1
2023-10-21 15:46:34,445:INFO:_display_container: 2
2023-10-21 15:46:34,446:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 15:46:34,446:INFO:create_model() successfully completed......................................
2023-10-21 15:46:34,646:INFO:Initializing tune_model()
2023-10-21 15:46:34,646:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCBE0D90>)
2023-10-21 15:46:34,646:INFO:Checking exceptions
2023-10-21 15:46:34,663:INFO:Copying training dataset
2023-10-21 15:46:34,682:INFO:Checking base model
2023-10-21 15:46:34,682:INFO:Base model : Light Gradient Boosting Machine
2023-10-21 15:46:34,682:INFO:Declaring metric variables
2023-10-21 15:46:34,682:INFO:Defining Hyperparameters
2023-10-21 15:46:34,896:INFO:Tuning with n_jobs=-1
2023-10-21 15:46:34,896:INFO:Initializing RandomizedSearchCV
2023-10-21 15:47:21,125:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-21 15:47:21,125:INFO:Hyperparameter search completed
2023-10-21 15:47:21,125:INFO:SubProcess create_model() called ==================================
2023-10-21 15:47:21,125:INFO:Initializing create_model()
2023-10-21 15:47:21,125:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCBE0D90>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002098DA01E80>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-21 15:47:21,125:INFO:Checking exceptions
2023-10-21 15:47:21,125:INFO:Importing libraries
2023-10-21 15:47:21,125:INFO:Copying training dataset
2023-10-21 15:47:21,169:INFO:Defining folds
2023-10-21 15:47:21,169:INFO:Declaring metric variables
2023-10-21 15:47:21,171:INFO:Importing untrained model
2023-10-21 15:47:21,171:INFO:Declaring custom model
2023-10-21 15:47:21,172:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 15:47:21,173:INFO:Starting cross validation
2023-10-21 15:47:21,174:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 15:47:30,367:INFO:Calculating mean and std
2023-10-21 15:47:30,367:INFO:Creating metrics dataframe
2023-10-21 15:47:30,367:INFO:Finalizing model
2023-10-21 15:47:30,426:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 15:47:30,427:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 15:47:30,427:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 15:47:30,450:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 15:47:30,450:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 15:47:30,450:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 15:47:30,467:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005335 seconds.
2023-10-21 15:47:30,467:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:47:30,467:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-21 15:47:30,467:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-21 15:47:30,467:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-21 15:47:30,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 15:47:30,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 15:47:30,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 15:47:30,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 15:47:30,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 15:47:30,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 15:47:30,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 15:47:30,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 15:47:31,617:INFO:Uploading results into container
2023-10-21 15:47:31,619:INFO:Uploading model into container now
2023-10-21 15:47:31,621:INFO:_master_model_container: 2
2023-10-21 15:47:31,621:INFO:_display_container: 3
2023-10-21 15:47:31,623:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-21 15:47:31,623:INFO:create_model() successfully completed......................................
2023-10-21 15:47:31,870:INFO:SubProcess create_model() end ==================================
2023-10-21 15:47:31,870:INFO:choose_better activated
2023-10-21 15:47:31,870:INFO:SubProcess create_model() called ==================================
2023-10-21 15:47:31,876:INFO:Initializing create_model()
2023-10-21 15:47:31,876:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCBE0D90>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 15:47:31,876:INFO:Checking exceptions
2023-10-21 15:47:31,876:INFO:Importing libraries
2023-10-21 15:47:31,876:INFO:Copying training dataset
2023-10-21 15:47:31,899:INFO:Defining folds
2023-10-21 15:47:31,899:INFO:Declaring metric variables
2023-10-21 15:47:31,899:INFO:Importing untrained model
2023-10-21 15:47:31,899:INFO:Declaring custom model
2023-10-21 15:47:31,899:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 15:47:31,899:INFO:Starting cross validation
2023-10-21 15:47:31,899:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 15:47:34,496:INFO:Calculating mean and std
2023-10-21 15:47:34,497:INFO:Creating metrics dataframe
2023-10-21 15:47:34,497:INFO:Finalizing model
2023-10-21 15:47:34,563:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004016 seconds.
2023-10-21 15:47:34,563:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:47:34,563:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-21 15:47:34,563:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-21 15:47:34,563:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-21 15:47:34,797:INFO:Uploading results into container
2023-10-21 15:47:34,797:INFO:Uploading model into container now
2023-10-21 15:47:34,797:INFO:_master_model_container: 3
2023-10-21 15:47:34,797:INFO:_display_container: 4
2023-10-21 15:47:34,797:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 15:47:34,797:INFO:create_model() successfully completed......................................
2023-10-21 15:47:35,013:INFO:SubProcess create_model() end ==================================
2023-10-21 15:47:35,013:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.905
2023-10-21 15:47:35,028:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8993
2023-10-21 15:47:35,028:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-21 15:47:35,028:INFO:choose_better completed
2023-10-21 15:47:35,028:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-21 15:47:35,030:INFO:Creating Dashboard logs
2023-10-21 15:47:35,030:INFO:Model: Light Gradient Boosting Machine
2023-10-21 15:47:35,080:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 15:47:35,246:INFO:Initializing predict_model()
2023-10-21 15:47:35,246:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCBE0D90>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DBA03670>)
2023-10-21 15:47:35,246:INFO:Checking exceptions
2023-10-21 15:47:35,246:INFO:Preloading libraries
2023-10-21 15:47:35,929:INFO:_master_model_container: 3
2023-10-21 15:47:35,929:INFO:_display_container: 3
2023-10-21 15:47:35,929:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 15:47:35,929:INFO:tune_model() successfully completed......................................
2023-10-21 15:47:36,129:INFO:Initializing ensemble_model()
2023-10-21 15:47:36,129:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCBE0D90>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-21 15:47:36,129:INFO:Checking exceptions
2023-10-21 15:47:36,145:INFO:Importing libraries
2023-10-21 15:47:36,145:INFO:Copying training dataset
2023-10-21 15:47:36,145:INFO:Checking base model
2023-10-21 15:47:36,145:INFO:Base model : Light Gradient Boosting Machine
2023-10-21 15:47:36,145:INFO:Importing untrained ensembler
2023-10-21 15:47:36,145:INFO:Ensemble method set to Bagging
2023-10-21 15:47:36,145:INFO:SubProcess create_model() called ==================================
2023-10-21 15:47:36,145:INFO:Initializing create_model()
2023-10-21 15:47:36,145:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCBE0D90>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209D9BE5BB0>, model_only=True, return_train_score=False, kwargs={})
2023-10-21 15:47:36,145:INFO:Checking exceptions
2023-10-21 15:47:36,145:INFO:Importing libraries
2023-10-21 15:47:36,145:INFO:Copying training dataset
2023-10-21 15:47:36,162:INFO:Defining folds
2023-10-21 15:47:36,162:INFO:Declaring metric variables
2023-10-21 15:47:36,162:INFO:Importing untrained model
2023-10-21 15:47:36,162:INFO:Declaring custom model
2023-10-21 15:47:36,162:INFO:Bagging Regressor Imported successfully
2023-10-21 15:47:36,162:INFO:Starting cross validation
2023-10-21 15:47:36,162:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 06:00:12,211:INFO:Calculating mean and std
2023-10-22 06:00:12,213:INFO:Creating metrics dataframe
2023-10-22 06:00:12,213:INFO:Finalizing model
2023-10-22 06:00:12,427:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018408 seconds.
2023-10-22 06:00:12,427:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:12,429:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-22 06:00:12,429:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-22 06:00:12,429:INFO:[LightGBM] [Info] Start training from score 77.044367
2023-10-22 06:00:13,641:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013711 seconds.
2023-10-22 06:00:13,641:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:13,641:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-22 06:00:13,643:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-22 06:00:13,646:INFO:[LightGBM] [Info] Start training from score 76.520588
2023-10-22 06:00:14,362:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008493 seconds.
2023-10-22 06:00:14,362:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:14,362:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-22 06:00:14,362:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-22 06:00:14,362:INFO:[LightGBM] [Info] Start training from score 76.462170
2023-10-22 06:00:15,064:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005862 seconds.
2023-10-22 06:00:15,064:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:15,064:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-22 06:00:15,075:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-22 06:00:15,078:INFO:[LightGBM] [Info] Start training from score 77.386428
2023-10-22 06:00:15,693:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003786 seconds.
2023-10-22 06:00:15,693:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-22 06:00:15,693:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-22 06:00:15,693:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-22 06:00:15,693:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-22 06:00:15,700:INFO:[LightGBM] [Info] Start training from score 73.916304
2023-10-22 06:00:16,460:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009418 seconds.
2023-10-22 06:00:16,460:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:16,460:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-22 06:00:16,460:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-22 06:00:16,460:INFO:[LightGBM] [Info] Start training from score 75.879633
2023-10-22 06:00:17,177:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005668 seconds.
2023-10-22 06:00:17,177:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:17,177:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-22 06:00:17,177:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-22 06:00:17,177:INFO:[LightGBM] [Info] Start training from score 75.615395
2023-10-22 06:00:17,745:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005515 seconds.
2023-10-22 06:00:17,745:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:17,745:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-22 06:00:17,745:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-22 06:00:17,745:INFO:[LightGBM] [Info] Start training from score 79.544595
2023-10-22 06:00:18,259:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005585 seconds.
2023-10-22 06:00:18,259:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:18,259:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-22 06:00:18,273:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-22 06:00:18,274:INFO:[LightGBM] [Info] Start training from score 76.012052
2023-10-22 06:00:18,776:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004686 seconds.
2023-10-22 06:00:18,776:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:18,776:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-22 06:00:18,776:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-22 06:00:18,776:INFO:[LightGBM] [Info] Start training from score 78.124037
2023-10-22 06:00:19,141:INFO:Uploading results into container
2023-10-22 06:00:19,141:INFO:Uploading model into container now
2023-10-22 06:00:19,141:INFO:_master_model_container: 4
2023-10-22 06:00:19,141:INFO:_display_container: 4
2023-10-22 06:00:19,155:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-22 06:00:19,156:INFO:create_model() successfully completed......................................
2023-10-22 06:00:19,479:INFO:SubProcess create_model() end ==================================
2023-10-22 06:00:19,479:INFO:Creating Dashboard logs
2023-10-22 06:00:19,479:INFO:Model: Bagging Regressor
2023-10-22 06:00:19,641:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-22 06:00:20,026:INFO:Initializing predict_model()
2023-10-22 06:00:20,026:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCBE0D90>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209831F0DC0>)
2023-10-22 06:00:20,026:INFO:Checking exceptions
2023-10-22 06:00:20,026:INFO:Preloading libraries
2023-10-22 06:00:21,305:INFO:_master_model_container: 4
2023-10-22 06:00:21,305:INFO:_display_container: 4
2023-10-22 06:00:21,305:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-22 06:00:21,305:INFO:ensemble_model() successfully completed......................................
2023-10-22 06:00:21,688:INFO:Initializing finalize_model()
2023-10-22 06:00:21,688:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCBE0D90>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-22 06:00:21,688:INFO:Finalizing BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-22 06:00:21,710:INFO:Initializing create_model()
2023-10-22 06:00:21,710:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCBE0D90>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-22 06:00:21,710:INFO:Checking exceptions
2023-10-22 06:00:21,710:INFO:Importing libraries
2023-10-22 06:00:21,710:INFO:Copying training dataset
2023-10-22 06:00:21,710:INFO:Defining folds
2023-10-22 06:00:21,710:INFO:Declaring metric variables
2023-10-22 06:00:21,710:INFO:Importing untrained model
2023-10-22 06:00:21,710:INFO:Declaring custom model
2023-10-22 06:00:21,720:INFO:Bagging Regressor Imported successfully
2023-10-22 06:00:21,721:INFO:Cross validation set to False
2023-10-22 06:00:21,721:INFO:Fitting Model
2023-10-22 06:00:21,871:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007416 seconds.
2023-10-22 06:00:21,871:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:21,871:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-22 06:00:21,871:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-22 06:00:21,871:INFO:[LightGBM] [Info] Start training from score 77.360615
2023-10-22 06:00:22,287:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005908 seconds.
2023-10-22 06:00:22,287:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:22,287:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-22 06:00:22,296:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-22 06:00:22,296:INFO:[LightGBM] [Info] Start training from score 78.162759
2023-10-22 06:00:22,920:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007327 seconds.
2023-10-22 06:00:22,920:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:22,920:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-22 06:00:22,920:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-22 06:00:22,926:INFO:[LightGBM] [Info] Start training from score 77.185434
2023-10-22 06:00:23,379:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007738 seconds.
2023-10-22 06:00:23,379:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:23,379:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-22 06:00:23,379:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-22 06:00:23,379:INFO:[LightGBM] [Info] Start training from score 78.293126
2023-10-22 06:00:23,886:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008236 seconds.
2023-10-22 06:00:23,886:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:23,886:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-22 06:00:23,886:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-22 06:00:23,891:INFO:[LightGBM] [Info] Start training from score 75.493649
2023-10-22 06:00:24,329:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006544 seconds.
2023-10-22 06:00:24,329:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:24,329:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-22 06:00:24,329:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-22 06:00:24,334:INFO:[LightGBM] [Info] Start training from score 77.467219
2023-10-22 06:00:24,777:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006316 seconds.
2023-10-22 06:00:24,777:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:24,777:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-22 06:00:24,777:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-22 06:00:24,782:INFO:[LightGBM] [Info] Start training from score 77.083598
2023-10-22 06:00:25,278:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006562 seconds.
2023-10-22 06:00:25,278:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:25,278:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-22 06:00:25,278:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-22 06:00:25,278:INFO:[LightGBM] [Info] Start training from score 79.854607
2023-10-22 06:00:25,779:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007476 seconds.
2023-10-22 06:00:25,779:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:25,779:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-22 06:00:25,779:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-22 06:00:25,779:INFO:[LightGBM] [Info] Start training from score 76.153078
2023-10-22 06:00:26,203:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006755 seconds.
2023-10-22 06:00:26,203:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:26,211:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-22 06:00:26,211:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-22 06:00:26,211:INFO:[LightGBM] [Info] Start training from score 78.843978
2023-10-22 06:00:26,596:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-22 06:00:26,599:INFO:create_model() successfully completed......................................
2023-10-22 06:00:27,178:INFO:Creating Dashboard logs
2023-10-22 06:00:27,180:INFO:Model: Bagging Regressor
2023-10-22 06:00:27,309:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-22 06:00:28,283:INFO:_master_model_container: 4
2023-10-22 06:00:28,283:INFO:_display_container: 4
2023-10-22 06:00:28,304:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-22 06:00:28,304:INFO:finalize_model() successfully completed......................................
2023-10-22 06:00:28,746:INFO:Initializing save_model()
2023-10-22 06:00:28,746:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), model_name=final_model_for_location_C, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-22 06:00:28,746:INFO:Adding model into prep_pipe
2023-10-22 06:00:28,746:WARNING:Only Model saved as it was a pipeline.
2023-10-22 06:00:28,827:INFO:final_model_for_location_C.pkl saved in current working directory
2023-10-22 06:00:28,851:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-22 06:00:28,851:INFO:save_model() successfully completed......................................
2023-10-22 20:28:39,809:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\base\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals
  warnings.warn("Maximum Likelihood optimization failed to "

2023-10-23 09:36:55,148:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.
  self._init_dates(dates, freq)

2023-10-23 09:36:55,150:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.
  self._init_dates(dates, freq)

2023-10-23 09:36:55,152:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.
  self._init_dates(dates, freq)

2023-10-23 09:41:36,374:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.
  self._init_dates(dates, freq)

2023-10-23 09:41:36,374:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.
  self._init_dates(dates, freq)

2023-10-23 09:41:36,374:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.
  self._init_dates(dates, freq)

2023-10-23 09:41:45,324:INFO:Initializing predict_model()
2023-10-23 09:41:45,340:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCBE0D90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002098DAA5A60>)
2023-10-23 09:41:45,340:INFO:Checking exceptions
2023-10-23 09:41:45,340:INFO:Preloading libraries
2023-10-23 09:41:45,340:INFO:Set up data.
2023-10-23 09:41:45,402:INFO:Set up index.
2023-10-23 09:42:01,711:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\base\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals
  warnings.warn("Maximum Likelihood optimization failed to "

2023-10-23 09:42:03,101:INFO:Initializing predict_model()
2023-10-23 09:42:03,101:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCBE0D90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DA6BEA60>)
2023-10-23 09:42:03,101:INFO:Checking exceptions
2023-10-23 09:42:03,101:INFO:Preloading libraries
2023-10-23 09:42:03,102:INFO:Set up data.
2023-10-23 09:42:03,137:INFO:Set up index.
2023-10-23 09:42:03,786:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.
  self._init_dates(dates, freq)

2023-10-23 09:42:03,786:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.
  self._init_dates(dates, freq)

2023-10-23 09:42:03,787:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.
  self._init_dates(dates, freq)

2023-10-23 10:27:50,104:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-23 10:27:50,104:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-23 10:27:50,104:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-23 10:27:50,104:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-23 10:27:50,458:INFO:PyCaret RegressionExperiment
2023-10-23 10:27:50,458:INFO:Logging name: exp_A
2023-10-23 10:27:50,458:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 10:27:50,458:INFO:version 3.1.0
2023-10-23 10:27:50,458:INFO:Initializing setup()
2023-10-23 10:27:50,458:INFO:self.USI: eaad
2023-10-23 10:27:50,458:INFO:self._variable_keys: {'data', 'X_test', 'html_param', 'exp_id', 'exp_name_log', 'log_plots_param', '_available_plots', 'idx', 'pipeline', 'fold_generator', 'y', 'X', 'gpu_n_jobs_param', 'logging_param', 'memory', 'n_jobs_param', 'target_param', 'X_train', 'gpu_param', 'seed', 'USI', 'y_test', 'transform_target_param', 'y_train', 'fold_shuffle_param', 'fold_groups_param', '_ml_usecase'}
2023-10-23 10:27:50,458:INFO:Checking environment
2023-10-23 10:27:50,458:INFO:python_version: 3.8.18
2023-10-23 10:27:50,458:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 10:27:50,458:INFO:machine: AMD64
2023-10-23 10:27:50,472:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 10:27:50,472:INFO:Memory: svmem(total=16505954304, available=4717416448, percent=71.4, used=11788537856, free=4717416448)
2023-10-23 10:27:50,472:INFO:Physical Core: 8
2023-10-23 10:27:50,472:INFO:Logical Core: 16
2023-10-23 10:27:50,472:INFO:Checking libraries
2023-10-23 10:27:50,472:INFO:System:
2023-10-23 10:27:50,472:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 10:27:50,472:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 10:27:50,472:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 10:27:50,472:INFO:PyCaret required dependencies:
2023-10-23 10:27:50,596:INFO:                 pip: 23.3
2023-10-23 10:27:50,596:INFO:          setuptools: 68.0.0
2023-10-23 10:27:50,596:INFO:             pycaret: 3.1.0
2023-10-23 10:27:50,596:INFO:             IPython: 8.12.0
2023-10-23 10:27:50,596:INFO:          ipywidgets: 8.1.1
2023-10-23 10:27:50,596:INFO:                tqdm: 4.66.1
2023-10-23 10:27:50,596:INFO:               numpy: 1.23.5
2023-10-23 10:27:50,596:INFO:              pandas: 1.5.3
2023-10-23 10:27:50,596:INFO:              jinja2: 3.1.2
2023-10-23 10:27:50,596:INFO:               scipy: 1.10.1
2023-10-23 10:27:50,596:INFO:              joblib: 1.3.2
2023-10-23 10:27:50,596:INFO:             sklearn: 1.2.2
2023-10-23 10:27:50,596:INFO:                pyod: 1.1.0
2023-10-23 10:27:50,596:INFO:            imblearn: 0.11.0
2023-10-23 10:27:50,596:INFO:   category_encoders: 2.6.2
2023-10-23 10:27:50,596:INFO:            lightgbm: 4.1.0
2023-10-23 10:27:50,596:INFO:               numba: 0.58.1
2023-10-23 10:27:50,596:INFO:            requests: 2.31.0
2023-10-23 10:27:50,596:INFO:          matplotlib: 3.7.3
2023-10-23 10:27:50,596:INFO:          scikitplot: 0.3.7
2023-10-23 10:27:50,596:INFO:         yellowbrick: 1.5
2023-10-23 10:27:50,596:INFO:              plotly: 5.17.0
2023-10-23 10:27:50,596:INFO:    plotly-resampler: Not installed
2023-10-23 10:27:50,596:INFO:             kaleido: 0.2.1
2023-10-23 10:27:50,596:INFO:           schemdraw: 0.15
2023-10-23 10:27:50,596:INFO:         statsmodels: 0.14.0
2023-10-23 10:27:50,596:INFO:              sktime: 0.21.1
2023-10-23 10:27:50,596:INFO:               tbats: 1.1.3
2023-10-23 10:27:50,596:INFO:            pmdarima: 2.0.3
2023-10-23 10:27:50,596:INFO:              psutil: 5.9.0
2023-10-23 10:27:50,596:INFO:          markupsafe: 2.1.3
2023-10-23 10:27:50,596:INFO:             pickle5: Not installed
2023-10-23 10:27:50,596:INFO:         cloudpickle: 2.2.1
2023-10-23 10:27:50,596:INFO:         deprecation: 2.1.0
2023-10-23 10:27:50,596:INFO:              xxhash: 3.4.1
2023-10-23 10:27:50,596:INFO:           wurlitzer: Not installed
2023-10-23 10:27:50,596:INFO:PyCaret optional dependencies:
2023-10-23 10:27:50,638:INFO:                shap: Not installed
2023-10-23 10:27:50,638:INFO:           interpret: Not installed
2023-10-23 10:27:50,638:INFO:                umap: Not installed
2023-10-23 10:27:50,638:INFO:     ydata_profiling: Not installed
2023-10-23 10:27:50,638:INFO:  explainerdashboard: Not installed
2023-10-23 10:27:50,638:INFO:             autoviz: Not installed
2023-10-23 10:27:50,638:INFO:           fairlearn: Not installed
2023-10-23 10:27:50,638:INFO:          deepchecks: Not installed
2023-10-23 10:27:50,638:INFO:             xgboost: Not installed
2023-10-23 10:27:50,638:INFO:            catboost: 1.2.2
2023-10-23 10:27:50,638:INFO:              kmodes: Not installed
2023-10-23 10:27:50,638:INFO:             mlxtend: Not installed
2023-10-23 10:27:50,638:INFO:       statsforecast: Not installed
2023-10-23 10:27:50,638:INFO:        tune_sklearn: Not installed
2023-10-23 10:27:50,638:INFO:                 ray: Not installed
2023-10-23 10:27:50,638:INFO:            hyperopt: Not installed
2023-10-23 10:27:50,638:INFO:              optuna: Not installed
2023-10-23 10:27:50,638:INFO:               skopt: Not installed
2023-10-23 10:27:50,638:INFO:              mlflow: 2.7.1
2023-10-23 10:27:50,638:INFO:              gradio: Not installed
2023-10-23 10:27:50,638:INFO:             fastapi: Not installed
2023-10-23 10:27:50,638:INFO:             uvicorn: Not installed
2023-10-23 10:27:50,638:INFO:              m2cgen: Not installed
2023-10-23 10:27:50,638:INFO:           evidently: Not installed
2023-10-23 10:27:50,638:INFO:               fugue: Not installed
2023-10-23 10:27:50,638:INFO:           streamlit: Not installed
2023-10-23 10:27:50,638:INFO:             prophet: Not installed
2023-10-23 10:27:50,638:INFO:None
2023-10-23 10:27:50,638:INFO:Set up data.
2023-10-23 10:27:50,689:INFO:Set up folding strategy.
2023-10-23 10:27:50,689:INFO:Set up train/test split.
2023-10-23 10:27:50,728:INFO:Set up index.
2023-10-23 10:27:50,728:INFO:Assigning column types.
2023-10-23 10:27:50,768:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 10:27:50,768:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 10:27:50,774:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 10:27:50,789:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 10:27:50,916:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 10:27:50,990:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 10:27:50,990:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 10:27:50,990:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 10:27:50,990:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,002:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,002:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,136:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,214:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,214:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 10:27:51,214:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 10:27:51,214:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 10:27:51,230:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,230:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,348:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,434:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,434:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 10:27:51,434:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 10:27:51,450:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,450:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,568:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,653:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,653:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 10:27:51,653:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 10:27:51,653:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 10:27:51,669:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,800:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,878:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,878:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 10:27:51,878:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 10:27:51,894:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 10:27:52,022:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 10:27:52,115:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 10:27:52,115:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 10:27:52,115:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 10:27:52,115:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 10:27:52,270:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 10:27:52,353:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 10:27:52,356:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 10:27:52,356:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 10:27:52,513:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 10:27:52,596:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 10:27:52,596:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 10:27:52,596:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 10:27:52,596:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 10:27:52,747:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 10:27:52,831:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 10:27:52,831:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 10:27:52,994:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 10:27:53,079:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 10:27:53,079:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 10:27:53,081:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 10:27:53,338:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 10:27:53,338:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 10:27:53,612:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 10:27:53,612:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 10:27:53,612:INFO:Preparing preprocessing pipeline...
2023-10-23 10:27:53,612:INFO:Set up simple imputation.
2023-10-23 10:27:53,619:INFO:Set up column name cleaning.
2023-10-23 10:27:53,738:INFO:Finished creating preprocessing pipeline.
2023-10-23 10:27:53,754:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 10:27:53,754:INFO:Creating final display dataframe.
2023-10-23 10:27:54,124:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (34061, 50)
4        Transformed data shape   (34061, 50)
5   Transformed train set shape   (23842, 50)
6    Transformed test set shape   (10219, 50)
7              Numeric features            49
8      Rows with missing values         97.6%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_A
19                          USI          eaad
2023-10-23 10:27:54,316:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 10:27:54,316:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 10:27:54,521:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 10:27:54,521:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 10:27:54,521:INFO:Logging experiment in loggers
2023-10-23 10:27:55,047:INFO:SubProcess save_model() called ==================================
2023-10-23 10:27:55,060:INFO:Initializing save_model()
2023-10-23 10:27:55,060:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmps3mkt90d\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 10:27:55,060:INFO:Adding model into prep_pipe
2023-10-23 10:27:55,060:WARNING:Only Model saved as it was a pipeline.
2023-10-23 10:27:55,062:INFO:C:\Users\thoma\AppData\Local\Temp\tmps3mkt90d\Transformation Pipeline.pkl saved in current working directory
2023-10-23 10:27:55,068:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 10:27:55,068:INFO:save_model() successfully completed......................................
2023-10-23 10:27:55,164:INFO:SubProcess save_model() end ==================================
2023-10-23 10:27:55,252:INFO:setup() successfully completed in 4.06s...............
2023-10-23 10:27:55,252:INFO:Initializing create_model()
2023-10-23 10:27:55,252:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018BFA725310>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 10:27:55,252:INFO:Checking exceptions
2023-10-23 10:27:55,252:INFO:Importing libraries
2023-10-23 10:27:55,252:INFO:Copying training dataset
2023-10-23 10:27:55,277:INFO:Defining folds
2023-10-23 10:27:55,277:INFO:Declaring metric variables
2023-10-23 10:27:55,277:INFO:Importing untrained model
2023-10-23 10:27:55,277:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 10:27:55,277:INFO:Starting cross validation
2023-10-23 10:27:55,277:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 10:28:02,921:INFO:Calculating mean and std
2023-10-23 10:28:02,923:INFO:Creating metrics dataframe
2023-10-23 10:28:02,923:INFO:Finalizing model
2023-10-23 10:28:03,055:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006533 seconds.
2023-10-23 10:28:03,055:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 10:28:03,055:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 10:28:03,055:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 10:28:03,060:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-23 10:28:03,282:INFO:Creating Dashboard logs
2023-10-23 10:28:03,282:INFO:Model: Light Gradient Boosting Machine
2023-10-23 10:28:03,361:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 10:28:03,549:INFO:Initializing predict_model()
2023-10-23 10:28:03,549:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018BFA725310>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018B80298820>)
2023-10-23 10:28:03,549:INFO:Checking exceptions
2023-10-23 10:28:03,549:INFO:Preloading libraries
2023-10-23 10:28:03,817:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\_distutils_hack\__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2023-10-23 10:28:04,006:INFO:Uploading results into container
2023-10-23 10:28:04,006:INFO:Uploading model into container now
2023-10-23 10:28:04,014:INFO:_master_model_container: 1
2023-10-23 10:28:04,014:INFO:_display_container: 2
2023-10-23 10:28:04,014:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 10:28:04,014:INFO:create_model() successfully completed......................................
2023-10-23 10:28:04,118:INFO:Initializing tune_model()
2023-10-23 10:28:04,118:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018BFA725310>)
2023-10-23 10:28:04,118:INFO:Checking exceptions
2023-10-23 10:28:04,132:INFO:Copying training dataset
2023-10-23 10:28:04,143:INFO:Checking base model
2023-10-23 10:28:04,143:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 10:28:04,143:INFO:Declaring metric variables
2023-10-23 10:28:04,143:INFO:Defining Hyperparameters
2023-10-23 10:28:04,244:INFO:Tuning with n_jobs=-1
2023-10-23 10:28:04,244:INFO:Initializing RandomizedSearchCV
2023-10-23 14:31:20,238:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-23 14:31:20,238:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-23 14:31:20,238:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-23 14:31:20,238:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-23 14:31:20,480:INFO:PyCaret RegressionExperiment
2023-10-23 14:31:20,480:INFO:Logging name: exp_A
2023-10-23 14:31:20,480:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 14:31:20,480:INFO:version 3.1.0
2023-10-23 14:31:20,480:INFO:Initializing setup()
2023-10-23 14:31:20,480:INFO:self.USI: fafb
2023-10-23 14:31:20,480:INFO:self._variable_keys: {'gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', '_ml_usecase', 'gpu_param', 'exp_name_log', 'html_param', 'fold_generator', 'y', 'seed', 'y_train', 'transform_target_param', 'n_jobs_param', 'target_param', 'idx', '_available_plots', 'log_plots_param', 'memory', 'data', 'USI', 'X', 'logging_param', 'pipeline', 'exp_id', 'X_train', 'X_test', 'fold_groups_param'}
2023-10-23 14:31:20,480:INFO:Checking environment
2023-10-23 14:31:20,480:INFO:python_version: 3.8.18
2023-10-23 14:31:20,481:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 14:31:20,481:INFO:machine: AMD64
2023-10-23 14:31:20,481:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 14:31:20,481:INFO:Memory: svmem(total=16505954304, available=4661129216, percent=71.8, used=11844825088, free=4661129216)
2023-10-23 14:31:20,481:INFO:Physical Core: 8
2023-10-23 14:31:20,481:INFO:Logical Core: 16
2023-10-23 14:31:20,481:INFO:Checking libraries
2023-10-23 14:31:20,481:INFO:System:
2023-10-23 14:31:20,481:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 14:31:20,481:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 14:31:20,481:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 14:31:20,481:INFO:PyCaret required dependencies:
2023-10-23 14:31:20,573:INFO:                 pip: 23.3
2023-10-23 14:31:20,573:INFO:          setuptools: 68.0.0
2023-10-23 14:31:20,573:INFO:             pycaret: 3.1.0
2023-10-23 14:31:20,574:INFO:             IPython: 8.12.0
2023-10-23 14:31:20,574:INFO:          ipywidgets: 8.1.1
2023-10-23 14:31:20,574:INFO:                tqdm: 4.66.1
2023-10-23 14:31:20,574:INFO:               numpy: 1.23.5
2023-10-23 14:31:20,574:INFO:              pandas: 1.5.3
2023-10-23 14:31:20,574:INFO:              jinja2: 3.1.2
2023-10-23 14:31:20,574:INFO:               scipy: 1.10.1
2023-10-23 14:31:20,574:INFO:              joblib: 1.3.2
2023-10-23 14:31:20,574:INFO:             sklearn: 1.2.2
2023-10-23 14:31:20,574:INFO:                pyod: 1.1.0
2023-10-23 14:31:20,574:INFO:            imblearn: 0.11.0
2023-10-23 14:31:20,574:INFO:   category_encoders: 2.6.2
2023-10-23 14:31:20,574:INFO:            lightgbm: 4.1.0
2023-10-23 14:31:20,574:INFO:               numba: 0.58.1
2023-10-23 14:31:20,574:INFO:            requests: 2.31.0
2023-10-23 14:31:20,574:INFO:          matplotlib: 3.7.3
2023-10-23 14:31:20,574:INFO:          scikitplot: 0.3.7
2023-10-23 14:31:20,574:INFO:         yellowbrick: 1.5
2023-10-23 14:31:20,574:INFO:              plotly: 5.17.0
2023-10-23 14:31:20,574:INFO:    plotly-resampler: Not installed
2023-10-23 14:31:20,574:INFO:             kaleido: 0.2.1
2023-10-23 14:31:20,575:INFO:           schemdraw: 0.15
2023-10-23 14:31:20,575:INFO:         statsmodels: 0.14.0
2023-10-23 14:31:20,575:INFO:              sktime: 0.21.1
2023-10-23 14:31:20,575:INFO:               tbats: 1.1.3
2023-10-23 14:31:20,575:INFO:            pmdarima: 2.0.3
2023-10-23 14:31:20,575:INFO:              psutil: 5.9.0
2023-10-23 14:31:20,575:INFO:          markupsafe: 2.1.3
2023-10-23 14:31:20,575:INFO:             pickle5: Not installed
2023-10-23 14:31:20,575:INFO:         cloudpickle: 2.2.1
2023-10-23 14:31:20,575:INFO:         deprecation: 2.1.0
2023-10-23 14:31:20,575:INFO:              xxhash: 3.4.1
2023-10-23 14:31:20,575:INFO:           wurlitzer: Not installed
2023-10-23 14:31:20,575:INFO:PyCaret optional dependencies:
2023-10-23 14:31:20,591:INFO:                shap: Not installed
2023-10-23 14:31:20,591:INFO:           interpret: Not installed
2023-10-23 14:31:20,591:INFO:                umap: Not installed
2023-10-23 14:31:20,591:INFO:     ydata_profiling: Not installed
2023-10-23 14:31:20,592:INFO:  explainerdashboard: Not installed
2023-10-23 14:31:20,592:INFO:             autoviz: Not installed
2023-10-23 14:31:20,592:INFO:           fairlearn: Not installed
2023-10-23 14:31:20,592:INFO:          deepchecks: Not installed
2023-10-23 14:31:20,592:INFO:             xgboost: Not installed
2023-10-23 14:31:20,592:INFO:            catboost: 1.2.2
2023-10-23 14:31:20,592:INFO:              kmodes: Not installed
2023-10-23 14:31:20,592:INFO:             mlxtend: Not installed
2023-10-23 14:31:20,592:INFO:       statsforecast: Not installed
2023-10-23 14:31:20,592:INFO:        tune_sklearn: Not installed
2023-10-23 14:31:20,592:INFO:                 ray: Not installed
2023-10-23 14:31:20,592:INFO:            hyperopt: Not installed
2023-10-23 14:31:20,592:INFO:              optuna: Not installed
2023-10-23 14:31:20,592:INFO:               skopt: Not installed
2023-10-23 14:31:20,592:INFO:              mlflow: 2.7.1
2023-10-23 14:31:20,592:INFO:              gradio: Not installed
2023-10-23 14:31:20,593:INFO:             fastapi: Not installed
2023-10-23 14:31:20,593:INFO:             uvicorn: Not installed
2023-10-23 14:31:20,593:INFO:              m2cgen: Not installed
2023-10-23 14:31:20,593:INFO:           evidently: Not installed
2023-10-23 14:31:20,593:INFO:               fugue: Not installed
2023-10-23 14:31:20,593:INFO:           streamlit: Not installed
2023-10-23 14:31:20,593:INFO:             prophet: Not installed
2023-10-23 14:31:20,593:INFO:None
2023-10-23 14:31:20,593:INFO:Set up data.
2023-10-23 14:31:20,624:INFO:Set up folding strategy.
2023-10-23 14:31:20,624:INFO:Set up train/test split.
2023-10-23 14:31:20,660:INFO:Set up index.
2023-10-23 14:31:20,660:INFO:Assigning column types.
2023-10-23 14:31:20,691:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 14:31:20,691:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 14:31:20,700:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:31:20,700:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:31:20,791:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:31:20,838:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:31:20,838:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:31:20,838:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:31:20,838:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 14:31:20,838:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:31:20,854:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:31:20,934:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:31:20,991:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:31:20,991:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:31:20,992:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:31:20,992:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 14:31:20,998:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,003:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,082:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,119:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,119:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:31:21,119:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:31:21,138:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,143:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,225:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,276:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,276:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:31:21,276:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:31:21,276:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 14:31:21,295:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,381:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,435:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,436:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:31:21,436:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:31:21,436:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,535:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,586:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,591:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:31:21,591:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:31:21,591:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 14:31:21,684:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,736:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,737:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:31:21,737:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:31:21,837:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,891:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,891:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:31:21,891:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:31:21,891:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 14:31:22,006:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:31:22,065:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:31:22,066:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:31:22,153:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:31:22,210:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:31:22,210:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:31:22,211:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 14:31:22,351:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:31:22,352:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:31:22,517:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:31:22,517:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:31:22,518:INFO:Preparing preprocessing pipeline...
2023-10-23 14:31:22,518:INFO:Set up simple imputation.
2023-10-23 14:31:22,518:INFO:Set up column name cleaning.
2023-10-23 14:31:22,620:INFO:Finished creating preprocessing pipeline.
2023-10-23 14:31:22,626:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 14:31:22,626:INFO:Creating final display dataframe.
2023-10-23 14:31:22,894:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (34061, 50)
4        Transformed data shape   (34061, 50)
5   Transformed train set shape   (23842, 50)
6    Transformed test set shape   (10219, 50)
7              Numeric features            49
8      Rows with missing values         97.6%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_A
19                          USI          fafb
2023-10-23 14:31:23,033:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:31:23,033:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:31:23,176:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:31:23,176:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:31:23,176:INFO:Logging experiment in loggers
2023-10-23 14:31:23,521:INFO:SubProcess save_model() called ==================================
2023-10-23 14:31:23,540:INFO:Initializing save_model()
2023-10-23 14:31:23,540:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmp9ih1lsac\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 14:31:23,540:INFO:Adding model into prep_pipe
2023-10-23 14:31:23,540:WARNING:Only Model saved as it was a pipeline.
2023-10-23 14:31:23,552:INFO:C:\Users\thoma\AppData\Local\Temp\tmp9ih1lsac\Transformation Pipeline.pkl saved in current working directory
2023-10-23 14:31:23,553:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 14:31:23,553:INFO:save_model() successfully completed......................................
2023-10-23 14:31:23,666:INFO:SubProcess save_model() end ==================================
2023-10-23 14:31:23,750:INFO:setup() successfully completed in 2.7s...............
2023-10-23 14:31:23,750:INFO:Initializing create_model()
2023-10-23 14:31:23,750:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08C9C0F40>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:31:23,750:INFO:Checking exceptions
2023-10-23 14:31:23,754:INFO:Importing libraries
2023-10-23 14:31:23,754:INFO:Copying training dataset
2023-10-23 14:31:23,784:INFO:Defining folds
2023-10-23 14:31:23,784:INFO:Declaring metric variables
2023-10-23 14:31:23,784:INFO:Importing untrained model
2023-10-23 14:31:23,785:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:31:23,785:INFO:Starting cross validation
2023-10-23 14:31:23,794:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:31:33,183:INFO:Calculating mean and std
2023-10-23 14:31:33,186:INFO:Creating metrics dataframe
2023-10-23 14:31:33,189:INFO:Finalizing model
2023-10-23 14:31:33,309:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007339 seconds.
2023-10-23 14:31:33,309:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:31:33,310:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:31:33,311:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:31:33,312:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-23 14:31:33,643:INFO:Creating Dashboard logs
2023-10-23 14:31:33,643:INFO:Model: Light Gradient Boosting Machine
2023-10-23 14:31:33,772:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 14:31:34,007:INFO:Initializing predict_model()
2023-10-23 14:31:34,008:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08C9C0F40>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E0971B6EE0>)
2023-10-23 14:31:34,008:INFO:Checking exceptions
2023-10-23 14:31:34,008:INFO:Preloading libraries
2023-10-23 14:31:34,363:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\_distutils_hack\__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2023-10-23 14:31:34,627:INFO:Uploading results into container
2023-10-23 14:31:34,627:INFO:Uploading model into container now
2023-10-23 14:31:34,642:INFO:_master_model_container: 1
2023-10-23 14:31:34,642:INFO:_display_container: 2
2023-10-23 14:31:34,643:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:31:34,643:INFO:create_model() successfully completed......................................
2023-10-23 14:31:34,776:INFO:Initializing tune_model()
2023-10-23 14:31:34,776:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08C9C0F40>)
2023-10-23 14:31:34,776:INFO:Checking exceptions
2023-10-23 14:31:34,791:INFO:Copying training dataset
2023-10-23 14:31:34,810:INFO:Checking base model
2023-10-23 14:31:34,811:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 14:31:34,812:INFO:Declaring metric variables
2023-10-23 14:31:34,812:INFO:Defining Hyperparameters
2023-10-23 14:31:34,967:INFO:Tuning with n_jobs=-1
2023-10-23 14:31:34,968:INFO:Initializing RandomizedSearchCV
2023-10-23 14:32:26,101:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-23 14:32:26,102:INFO:Hyperparameter search completed
2023-10-23 14:32:26,103:INFO:SubProcess create_model() called ==================================
2023-10-23 14:32:26,104:INFO:Initializing create_model()
2023-10-23 14:32:26,104:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08C9C0F40>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E096F053A0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-23 14:32:26,104:INFO:Checking exceptions
2023-10-23 14:32:26,105:INFO:Importing libraries
2023-10-23 14:32:26,105:INFO:Copying training dataset
2023-10-23 14:32:26,137:INFO:Defining folds
2023-10-23 14:32:26,137:INFO:Declaring metric variables
2023-10-23 14:32:26,137:INFO:Importing untrained model
2023-10-23 14:32:26,138:INFO:Declaring custom model
2023-10-23 14:32:26,140:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:32:26,140:INFO:Starting cross validation
2023-10-23 14:32:26,142:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:32:34,733:INFO:Calculating mean and std
2023-10-23 14:32:34,734:INFO:Creating metrics dataframe
2023-10-23 14:32:34,738:INFO:Finalizing model
2023-10-23 14:32:34,801:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-23 14:32:34,801:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-23 14:32:34,801:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-23 14:32:34,842:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-23 14:32:34,842:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-23 14:32:34,842:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-23 14:32:34,851:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006217 seconds.
2023-10-23 14:32:34,851:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:32:34,852:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:32:34,853:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:32:34,855:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-23 14:32:36,016:INFO:Uploading results into container
2023-10-23 14:32:36,017:INFO:Uploading model into container now
2023-10-23 14:32:36,018:INFO:_master_model_container: 2
2023-10-23 14:32:36,018:INFO:_display_container: 3
2023-10-23 14:32:36,019:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-23 14:32:36,020:INFO:create_model() successfully completed......................................
2023-10-23 14:32:36,140:INFO:SubProcess create_model() end ==================================
2023-10-23 14:32:36,141:INFO:choose_better activated
2023-10-23 14:32:36,141:INFO:SubProcess create_model() called ==================================
2023-10-23 14:32:36,142:INFO:Initializing create_model()
2023-10-23 14:32:36,142:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08C9C0F40>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:32:36,142:INFO:Checking exceptions
2023-10-23 14:32:36,143:INFO:Importing libraries
2023-10-23 14:32:36,143:INFO:Copying training dataset
2023-10-23 14:32:36,165:INFO:Defining folds
2023-10-23 14:32:36,166:INFO:Declaring metric variables
2023-10-23 14:32:36,166:INFO:Importing untrained model
2023-10-23 14:32:36,166:INFO:Declaring custom model
2023-10-23 14:32:36,167:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:32:36,167:INFO:Starting cross validation
2023-10-23 14:32:36,168:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:32:38,715:INFO:Calculating mean and std
2023-10-23 14:32:38,715:INFO:Creating metrics dataframe
2023-10-23 14:32:38,718:INFO:Finalizing model
2023-10-23 14:32:38,816:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006205 seconds.
2023-10-23 14:32:38,816:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:32:38,817:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:32:38,817:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:32:38,819:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-23 14:32:39,027:INFO:Uploading results into container
2023-10-23 14:32:39,028:INFO:Uploading model into container now
2023-10-23 14:32:39,028:INFO:_master_model_container: 3
2023-10-23 14:32:39,028:INFO:_display_container: 4
2023-10-23 14:32:39,029:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:32:39,029:INFO:create_model() successfully completed......................................
2023-10-23 14:32:39,151:INFO:SubProcess create_model() end ==================================
2023-10-23 14:32:39,152:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8716
2023-10-23 14:32:39,153:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8712
2023-10-23 14:32:39,153:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-23 14:32:39,154:INFO:choose_better completed
2023-10-23 14:32:39,154:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-23 14:32:39,154:INFO:Creating Dashboard logs
2023-10-23 14:32:39,155:INFO:Model: Light Gradient Boosting Machine
2023-10-23 14:32:39,225:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 14:32:39,422:INFO:Initializing predict_model()
2023-10-23 14:32:39,422:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08C9C0F40>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E0970AACA0>)
2023-10-23 14:32:39,422:INFO:Checking exceptions
2023-10-23 14:32:39,422:INFO:Preloading libraries
2023-10-23 14:32:39,882:INFO:_master_model_container: 3
2023-10-23 14:32:39,883:INFO:_display_container: 3
2023-10-23 14:32:39,883:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:32:39,883:INFO:tune_model() successfully completed......................................
2023-10-23 14:32:39,991:INFO:Initializing ensemble_model()
2023-10-23 14:32:39,991:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08C9C0F40>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-23 14:32:39,991:INFO:Checking exceptions
2023-10-23 14:32:40,002:INFO:Importing libraries
2023-10-23 14:32:40,002:INFO:Copying training dataset
2023-10-23 14:32:40,003:INFO:Checking base model
2023-10-23 14:32:40,003:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 14:32:40,004:INFO:Importing untrained ensembler
2023-10-23 14:32:40,004:INFO:Ensemble method set to Bagging
2023-10-23 14:32:40,004:INFO:SubProcess create_model() called ==================================
2023-10-23 14:32:40,006:INFO:Initializing create_model()
2023-10-23 14:32:40,006:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08C9C0F40>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E096980A00>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:32:40,006:INFO:Checking exceptions
2023-10-23 14:32:40,006:INFO:Importing libraries
2023-10-23 14:32:40,006:INFO:Copying training dataset
2023-10-23 14:32:40,031:INFO:Defining folds
2023-10-23 14:32:40,031:INFO:Declaring metric variables
2023-10-23 14:32:40,032:INFO:Importing untrained model
2023-10-23 14:32:40,032:INFO:Declaring custom model
2023-10-23 14:32:40,033:INFO:Bagging Regressor Imported successfully
2023-10-23 14:32:40,034:INFO:Starting cross validation
2023-10-23 14:32:40,035:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:33:03,739:INFO:Calculating mean and std
2023-10-23 14:33:03,740:INFO:Creating metrics dataframe
2023-10-23 14:33:03,743:INFO:Finalizing model
2023-10-23 14:33:03,847:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005392 seconds.
2023-10-23 14:33:03,847:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:03,848:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:33:03,848:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:33:03,849:INFO:[LightGBM] [Info] Start training from score 626.831517
2023-10-23 14:33:04,126:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005093 seconds.
2023-10-23 14:33:04,126:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:04,126:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:33:04,127:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:33:04,127:INFO:[LightGBM] [Info] Start training from score 640.013980
2023-10-23 14:33:04,360:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005521 seconds.
2023-10-23 14:33:04,360:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:04,360:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:33:04,360:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:33:04,360:INFO:[LightGBM] [Info] Start training from score 623.946930
2023-10-23 14:33:04,628:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005296 seconds.
2023-10-23 14:33:04,628:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:04,629:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:33:04,629:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:33:04,629:INFO:[LightGBM] [Info] Start training from score 632.335152
2023-10-23 14:33:04,919:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006870 seconds.
2023-10-23 14:33:04,919:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:04,919:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:33:04,920:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:33:04,921:INFO:[LightGBM] [Info] Start training from score 620.070240
2023-10-23 14:33:05,194:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013481 seconds.
2023-10-23 14:33:05,195:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:05,195:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:33:05,196:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:33:05,202:INFO:[LightGBM] [Info] Start training from score 635.137343
2023-10-23 14:33:05,504:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005992 seconds.
2023-10-23 14:33:05,504:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:05,504:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:33:05,504:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:33:05,504:INFO:[LightGBM] [Info] Start training from score 620.066941
2023-10-23 14:33:05,783:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005717 seconds.
2023-10-23 14:33:05,783:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:05,783:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:33:05,783:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:33:05,783:INFO:[LightGBM] [Info] Start training from score 623.069874
2023-10-23 14:33:06,126:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007570 seconds.
2023-10-23 14:33:06,126:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:06,127:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:33:06,130:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:33:06,132:INFO:[LightGBM] [Info] Start training from score 633.817057
2023-10-23 14:33:06,447:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005651 seconds.
2023-10-23 14:33:06,447:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:06,447:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:33:06,448:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:33:06,448:INFO:[LightGBM] [Info] Start training from score 641.113408
2023-10-23 14:33:06,712:INFO:Uploading results into container
2023-10-23 14:33:06,713:INFO:Uploading model into container now
2023-10-23 14:33:06,714:INFO:_master_model_container: 4
2023-10-23 14:33:06,715:INFO:_display_container: 4
2023-10-23 14:33:06,717:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:33:06,717:INFO:create_model() successfully completed......................................
2023-10-23 14:33:06,840:INFO:SubProcess create_model() end ==================================
2023-10-23 14:33:06,840:INFO:Creating Dashboard logs
2023-10-23 14:33:06,841:INFO:Model: Bagging Regressor
2023-10-23 14:33:06,915:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-23 14:33:07,147:INFO:Initializing predict_model()
2023-10-23 14:33:07,147:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08C9C0F40>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E097086F70>)
2023-10-23 14:33:07,147:INFO:Checking exceptions
2023-10-23 14:33:07,147:INFO:Preloading libraries
2023-10-23 14:33:07,797:INFO:_master_model_container: 4
2023-10-23 14:33:07,797:INFO:_display_container: 4
2023-10-23 14:33:07,797:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:33:07,797:INFO:ensemble_model() successfully completed......................................
2023-10-23 14:33:07,914:INFO:Initializing finalize_model()
2023-10-23 14:33:07,914:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08C9C0F40>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-23 14:33:07,914:INFO:Finalizing BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:33:07,930:INFO:Initializing create_model()
2023-10-23 14:33:07,930:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08C9C0F40>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-23 14:33:07,930:INFO:Checking exceptions
2023-10-23 14:33:07,930:INFO:Importing libraries
2023-10-23 14:33:07,930:INFO:Copying training dataset
2023-10-23 14:33:07,930:INFO:Defining folds
2023-10-23 14:33:07,930:INFO:Declaring metric variables
2023-10-23 14:33:07,930:INFO:Importing untrained model
2023-10-23 14:33:07,930:INFO:Declaring custom model
2023-10-23 14:33:07,930:INFO:Bagging Regressor Imported successfully
2023-10-23 14:33:07,930:INFO:Cross validation set to False
2023-10-23 14:33:07,930:INFO:Fitting Model
2023-10-23 14:33:08,096:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009957 seconds.
2023-10-23 14:33:08,096:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:08,097:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:33:08,098:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:33:08,099:INFO:[LightGBM] [Info] Start training from score 634.491655
2023-10-23 14:33:08,482:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009853 seconds.
2023-10-23 14:33:08,482:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:08,482:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:33:08,483:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:33:08,485:INFO:[LightGBM] [Info] Start training from score 635.470959
2023-10-23 14:33:08,899:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009146 seconds.
2023-10-23 14:33:08,899:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:08,900:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:33:08,901:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:33:08,902:INFO:[LightGBM] [Info] Start training from score 634.053589
2023-10-23 14:33:09,365:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009197 seconds.
2023-10-23 14:33:09,365:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:09,365:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:33:09,365:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:33:09,365:INFO:[LightGBM] [Info] Start training from score 635.251785
2023-10-23 14:33:09,698:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008816 seconds.
2023-10-23 14:33:09,698:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:09,698:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:33:09,698:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:33:09,700:INFO:[LightGBM] [Info] Start training from score 627.555784
2023-10-23 14:33:10,053:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007364 seconds.
2023-10-23 14:33:10,053:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:10,054:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:33:10,054:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:33:10,056:INFO:[LightGBM] [Info] Start training from score 638.162596
2023-10-23 14:33:10,381:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007790 seconds.
2023-10-23 14:33:10,381:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:10,382:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:33:10,382:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:33:10,383:INFO:[LightGBM] [Info] Start training from score 633.181363
2023-10-23 14:33:10,722:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007785 seconds.
2023-10-23 14:33:10,722:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:10,723:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:33:10,723:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:33:10,724:INFO:[LightGBM] [Info] Start training from score 611.992287
2023-10-23 14:33:11,063:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007802 seconds.
2023-10-23 14:33:11,063:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:11,063:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:33:11,064:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:33:11,064:INFO:[LightGBM] [Info] Start training from score 638.181417
2023-10-23 14:33:11,383:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009670 seconds.
2023-10-23 14:33:11,383:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:11,383:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:33:11,383:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:33:11,383:INFO:[LightGBM] [Info] Start training from score 639.502137
2023-10-23 14:33:11,665:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:33:11,665:INFO:create_model() successfully completed......................................
2023-10-23 14:33:11,782:INFO:Creating Dashboard logs
2023-10-23 14:33:11,782:INFO:Model: Bagging Regressor
2023-10-23 14:33:11,860:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-23 14:33:12,279:INFO:_master_model_container: 4
2023-10-23 14:33:12,279:INFO:_display_container: 4
2023-10-23 14:33:12,290:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:33:12,290:INFO:finalize_model() successfully completed......................................
2023-10-23 14:33:12,404:INFO:Initializing save_model()
2023-10-23 14:33:12,404:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), model_name=final_model_for_location_A, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 14:33:12,404:INFO:Adding model into prep_pipe
2023-10-23 14:33:12,404:WARNING:Only Model saved as it was a pipeline.
2023-10-23 14:33:12,466:INFO:final_model_for_location_A.pkl saved in current working directory
2023-10-23 14:33:12,482:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:33:12,482:INFO:save_model() successfully completed......................................
2023-10-23 14:33:12,615:INFO:PyCaret RegressionExperiment
2023-10-23 14:33:12,615:INFO:Logging name: exp_B
2023-10-23 14:33:12,615:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 14:33:12,615:INFO:version 3.1.0
2023-10-23 14:33:12,615:INFO:Initializing setup()
2023-10-23 14:33:12,615:INFO:self.USI: 5eaa
2023-10-23 14:33:12,615:INFO:self._variable_keys: {'gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', '_ml_usecase', 'gpu_param', 'exp_name_log', 'html_param', 'fold_generator', 'y', 'seed', 'y_train', 'transform_target_param', 'n_jobs_param', 'target_param', 'idx', '_available_plots', 'log_plots_param', 'memory', 'data', 'USI', 'X', 'logging_param', 'pipeline', 'exp_id', 'X_train', 'X_test', 'fold_groups_param'}
2023-10-23 14:33:12,615:INFO:Checking environment
2023-10-23 14:33:12,615:INFO:python_version: 3.8.18
2023-10-23 14:33:12,615:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 14:33:12,615:INFO:machine: AMD64
2023-10-23 14:33:12,615:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 14:33:12,616:INFO:Memory: svmem(total=16505954304, available=2925641728, percent=82.3, used=13580312576, free=2925641728)
2023-10-23 14:33:12,616:INFO:Physical Core: 8
2023-10-23 14:33:12,616:INFO:Logical Core: 16
2023-10-23 14:33:12,616:INFO:Checking libraries
2023-10-23 14:33:12,616:INFO:System:
2023-10-23 14:33:12,616:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 14:33:12,616:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 14:33:12,616:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 14:33:12,616:INFO:PyCaret required dependencies:
2023-10-23 14:33:12,616:INFO:                 pip: 23.3
2023-10-23 14:33:12,617:INFO:          setuptools: 68.0.0
2023-10-23 14:33:12,617:INFO:             pycaret: 3.1.0
2023-10-23 14:33:12,617:INFO:             IPython: 8.12.0
2023-10-23 14:33:12,617:INFO:          ipywidgets: 8.1.1
2023-10-23 14:33:12,617:INFO:                tqdm: 4.66.1
2023-10-23 14:33:12,617:INFO:               numpy: 1.23.5
2023-10-23 14:33:12,617:INFO:              pandas: 1.5.3
2023-10-23 14:33:12,617:INFO:              jinja2: 3.1.2
2023-10-23 14:33:12,617:INFO:               scipy: 1.10.1
2023-10-23 14:33:12,617:INFO:              joblib: 1.3.2
2023-10-23 14:33:12,617:INFO:             sklearn: 1.2.2
2023-10-23 14:33:12,617:INFO:                pyod: 1.1.0
2023-10-23 14:33:12,617:INFO:            imblearn: 0.11.0
2023-10-23 14:33:12,617:INFO:   category_encoders: 2.6.2
2023-10-23 14:33:12,617:INFO:            lightgbm: 4.1.0
2023-10-23 14:33:12,618:INFO:               numba: 0.58.1
2023-10-23 14:33:12,618:INFO:            requests: 2.31.0
2023-10-23 14:33:12,618:INFO:          matplotlib: 3.7.3
2023-10-23 14:33:12,618:INFO:          scikitplot: 0.3.7
2023-10-23 14:33:12,618:INFO:         yellowbrick: 1.5
2023-10-23 14:33:12,618:INFO:              plotly: 5.17.0
2023-10-23 14:33:12,618:INFO:    plotly-resampler: Not installed
2023-10-23 14:33:12,618:INFO:             kaleido: 0.2.1
2023-10-23 14:33:12,618:INFO:           schemdraw: 0.15
2023-10-23 14:33:12,619:INFO:         statsmodels: 0.14.0
2023-10-23 14:33:12,619:INFO:              sktime: 0.21.1
2023-10-23 14:33:12,619:INFO:               tbats: 1.1.3
2023-10-23 14:33:12,619:INFO:            pmdarima: 2.0.3
2023-10-23 14:33:12,619:INFO:              psutil: 5.9.0
2023-10-23 14:33:12,619:INFO:          markupsafe: 2.1.3
2023-10-23 14:33:12,619:INFO:             pickle5: Not installed
2023-10-23 14:33:12,619:INFO:         cloudpickle: 2.2.1
2023-10-23 14:33:12,619:INFO:         deprecation: 2.1.0
2023-10-23 14:33:12,619:INFO:              xxhash: 3.4.1
2023-10-23 14:33:12,619:INFO:           wurlitzer: Not installed
2023-10-23 14:33:12,619:INFO:PyCaret optional dependencies:
2023-10-23 14:33:12,620:INFO:                shap: Not installed
2023-10-23 14:33:12,620:INFO:           interpret: Not installed
2023-10-23 14:33:12,620:INFO:                umap: Not installed
2023-10-23 14:33:12,620:INFO:     ydata_profiling: Not installed
2023-10-23 14:33:12,620:INFO:  explainerdashboard: Not installed
2023-10-23 14:33:12,620:INFO:             autoviz: Not installed
2023-10-23 14:33:12,620:INFO:           fairlearn: Not installed
2023-10-23 14:33:12,620:INFO:          deepchecks: Not installed
2023-10-23 14:33:12,620:INFO:             xgboost: Not installed
2023-10-23 14:33:12,620:INFO:            catboost: 1.2.2
2023-10-23 14:33:12,620:INFO:              kmodes: Not installed
2023-10-23 14:33:12,620:INFO:             mlxtend: Not installed
2023-10-23 14:33:12,620:INFO:       statsforecast: Not installed
2023-10-23 14:33:12,620:INFO:        tune_sklearn: Not installed
2023-10-23 14:33:12,621:INFO:                 ray: Not installed
2023-10-23 14:33:12,621:INFO:            hyperopt: Not installed
2023-10-23 14:33:12,621:INFO:              optuna: Not installed
2023-10-23 14:33:12,621:INFO:               skopt: Not installed
2023-10-23 14:33:12,621:INFO:              mlflow: 2.7.1
2023-10-23 14:33:12,621:INFO:              gradio: Not installed
2023-10-23 14:33:12,621:INFO:             fastapi: Not installed
2023-10-23 14:33:12,621:INFO:             uvicorn: Not installed
2023-10-23 14:33:12,621:INFO:              m2cgen: Not installed
2023-10-23 14:33:12,621:INFO:           evidently: Not installed
2023-10-23 14:33:12,621:INFO:               fugue: Not installed
2023-10-23 14:33:12,621:INFO:           streamlit: Not installed
2023-10-23 14:33:12,621:INFO:             prophet: Not installed
2023-10-23 14:33:12,622:INFO:None
2023-10-23 14:33:12,622:INFO:Set up data.
2023-10-23 14:33:12,660:INFO:Set up folding strategy.
2023-10-23 14:33:12,660:INFO:Set up train/test split.
2023-10-23 14:33:12,686:INFO:Set up index.
2023-10-23 14:33:12,688:INFO:Assigning column types.
2023-10-23 14:33:12,712:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 14:33:12,713:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 14:33:12,718:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:33:12,723:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:33:12,804:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:33:12,853:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:33:12,854:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:33:12,854:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:33:12,855:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 14:33:12,860:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:33:12,866:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:33:12,943:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:33:12,992:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:33:12,993:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:33:12,993:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:33:12,994:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 14:33:12,999:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,004:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,083:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,126:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,126:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:33:13,126:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:33:13,126:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,143:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,239:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,293:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,293:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:33:13,293:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:33:13,293:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 14:33:13,310:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,376:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,425:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,425:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:33:13,425:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:33:13,442:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,546:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,592:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,592:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:33:13,592:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:33:13,592:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 14:33:13,709:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,759:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,759:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:33:13,759:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:33:13,843:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,893:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,893:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:33:13,893:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:33:13,893:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 14:33:13,992:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:33:14,043:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:33:14,044:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:33:14,142:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:33:14,192:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:33:14,193:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:33:14,193:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 14:33:14,330:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:33:14,331:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:33:14,472:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:33:14,472:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:33:14,474:INFO:Preparing preprocessing pipeline...
2023-10-23 14:33:14,474:INFO:Set up simple imputation.
2023-10-23 14:33:14,477:INFO:Set up column name cleaning.
2023-10-23 14:33:14,547:INFO:Finished creating preprocessing pipeline.
2023-10-23 14:33:14,553:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 14:33:14,553:INFO:Creating final display dataframe.
2023-10-23 14:33:14,771:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (32819, 50)
4        Transformed data shape   (32819, 50)
5   Transformed train set shape   (22973, 50)
6    Transformed test set shape    (9846, 50)
7              Numeric features            49
8      Rows with missing values         95.9%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_B
19                          USI          5eaa
2023-10-23 14:33:14,933:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:33:14,934:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:33:15,078:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:33:15,078:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:33:15,079:INFO:Logging experiment in loggers
2023-10-23 14:33:15,206:INFO:SubProcess save_model() called ==================================
2023-10-23 14:33:15,210:INFO:Initializing save_model()
2023-10-23 14:33:15,210:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmplxeawuw9\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 14:33:15,210:INFO:Adding model into prep_pipe
2023-10-23 14:33:15,210:WARNING:Only Model saved as it was a pipeline.
2023-10-23 14:33:15,227:INFO:C:\Users\thoma\AppData\Local\Temp\tmplxeawuw9\Transformation Pipeline.pkl saved in current working directory
2023-10-23 14:33:15,229:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 14:33:15,229:INFO:save_model() successfully completed......................................
2023-10-23 14:33:15,343:INFO:SubProcess save_model() end ==================================
2023-10-23 14:33:15,406:INFO:setup() successfully completed in 2.47s...............
2023-10-23 14:33:15,406:INFO:Initializing create_model()
2023-10-23 14:33:15,406:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096DCF190>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:33:15,406:INFO:Checking exceptions
2023-10-23 14:33:15,410:INFO:Importing libraries
2023-10-23 14:33:15,410:INFO:Copying training dataset
2023-10-23 14:33:15,435:INFO:Defining folds
2023-10-23 14:33:15,435:INFO:Declaring metric variables
2023-10-23 14:33:15,435:INFO:Importing untrained model
2023-10-23 14:33:15,435:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:33:15,439:INFO:Starting cross validation
2023-10-23 14:33:15,440:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:33:17,998:INFO:Calculating mean and std
2023-10-23 14:33:18,000:INFO:Creating metrics dataframe
2023-10-23 14:33:18,002:INFO:Finalizing model
2023-10-23 14:33:18,101:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005265 seconds.
2023-10-23 14:33:18,101:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:18,101:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:33:18,102:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:33:18,103:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-23 14:33:18,346:INFO:Creating Dashboard logs
2023-10-23 14:33:18,347:INFO:Model: Light Gradient Boosting Machine
2023-10-23 14:33:18,448:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 14:33:18,669:INFO:Initializing predict_model()
2023-10-23 14:33:18,670:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096DCF190>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096789040>)
2023-10-23 14:33:18,670:INFO:Checking exceptions
2023-10-23 14:33:18,670:INFO:Preloading libraries
2023-10-23 14:33:19,177:INFO:Uploading results into container
2023-10-23 14:33:19,179:INFO:Uploading model into container now
2023-10-23 14:33:19,183:INFO:_master_model_container: 1
2023-10-23 14:33:19,183:INFO:_display_container: 2
2023-10-23 14:33:19,184:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:33:19,184:INFO:create_model() successfully completed......................................
2023-10-23 14:33:19,283:INFO:Initializing tune_model()
2023-10-23 14:33:19,283:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096DCF190>)
2023-10-23 14:33:19,283:INFO:Checking exceptions
2023-10-23 14:33:19,296:INFO:Copying training dataset
2023-10-23 14:33:19,311:INFO:Checking base model
2023-10-23 14:33:19,312:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 14:33:19,312:INFO:Declaring metric variables
2023-10-23 14:33:19,313:INFO:Defining Hyperparameters
2023-10-23 14:33:19,424:INFO:Tuning with n_jobs=-1
2023-10-23 14:33:19,424:INFO:Initializing RandomizedSearchCV
2023-10-23 14:34:01,842:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-23 14:34:01,844:INFO:Hyperparameter search completed
2023-10-23 14:34:01,844:INFO:SubProcess create_model() called ==================================
2023-10-23 14:34:01,845:INFO:Initializing create_model()
2023-10-23 14:34:01,846:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096DCF190>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E096AC0AC0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-23 14:34:01,846:INFO:Checking exceptions
2023-10-23 14:34:01,847:INFO:Importing libraries
2023-10-23 14:34:01,847:INFO:Copying training dataset
2023-10-23 14:34:01,879:INFO:Defining folds
2023-10-23 14:34:01,879:INFO:Declaring metric variables
2023-10-23 14:34:01,879:INFO:Importing untrained model
2023-10-23 14:34:01,879:INFO:Declaring custom model
2023-10-23 14:34:01,881:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:34:01,881:INFO:Starting cross validation
2023-10-23 14:34:01,883:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:34:10,558:INFO:Calculating mean and std
2023-10-23 14:34:10,558:INFO:Creating metrics dataframe
2023-10-23 14:34:10,563:INFO:Finalizing model
2023-10-23 14:34:10,612:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-23 14:34:10,612:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-23 14:34:10,612:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-23 14:34:10,658:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-23 14:34:10,658:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-23 14:34:10,658:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-23 14:34:10,658:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005687 seconds.
2023-10-23 14:34:10,658:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:10,658:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:34:10,673:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:34:10,673:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-23 14:34:11,591:INFO:Uploading results into container
2023-10-23 14:34:11,591:INFO:Uploading model into container now
2023-10-23 14:34:11,591:INFO:_master_model_container: 2
2023-10-23 14:34:11,591:INFO:_display_container: 3
2023-10-23 14:34:11,591:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-23 14:34:11,591:INFO:create_model() successfully completed......................................
2023-10-23 14:34:11,731:INFO:SubProcess create_model() end ==================================
2023-10-23 14:34:11,731:INFO:choose_better activated
2023-10-23 14:34:11,731:INFO:SubProcess create_model() called ==================================
2023-10-23 14:34:11,731:INFO:Initializing create_model()
2023-10-23 14:34:11,731:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096DCF190>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:34:11,731:INFO:Checking exceptions
2023-10-23 14:34:11,731:INFO:Importing libraries
2023-10-23 14:34:11,731:INFO:Copying training dataset
2023-10-23 14:34:11,749:INFO:Defining folds
2023-10-23 14:34:11,749:INFO:Declaring metric variables
2023-10-23 14:34:11,749:INFO:Importing untrained model
2023-10-23 14:34:11,749:INFO:Declaring custom model
2023-10-23 14:34:11,749:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:34:11,749:INFO:Starting cross validation
2023-10-23 14:34:11,749:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:34:14,239:INFO:Calculating mean and std
2023-10-23 14:34:14,239:INFO:Creating metrics dataframe
2023-10-23 14:34:14,239:INFO:Finalizing model
2023-10-23 14:34:14,344:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005003 seconds.
2023-10-23 14:34:14,344:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:14,344:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:34:14,344:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:34:14,344:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-23 14:34:14,560:INFO:Uploading results into container
2023-10-23 14:34:14,560:INFO:Uploading model into container now
2023-10-23 14:34:14,560:INFO:_master_model_container: 3
2023-10-23 14:34:14,560:INFO:_display_container: 4
2023-10-23 14:34:14,560:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:34:14,560:INFO:create_model() successfully completed......................................
2023-10-23 14:34:14,692:INFO:SubProcess create_model() end ==================================
2023-10-23 14:34:14,692:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8523
2023-10-23 14:34:14,692:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8523
2023-10-23 14:34:14,692:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-23 14:34:14,692:INFO:choose_better completed
2023-10-23 14:34:14,692:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-23 14:34:14,696:INFO:Creating Dashboard logs
2023-10-23 14:34:14,696:INFO:Model: Light Gradient Boosting Machine
2023-10-23 14:34:14,757:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 14:34:14,955:INFO:Initializing predict_model()
2023-10-23 14:34:14,956:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096DCF190>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096702B80>)
2023-10-23 14:34:14,956:INFO:Checking exceptions
2023-10-23 14:34:14,956:INFO:Preloading libraries
2023-10-23 14:34:15,442:INFO:_master_model_container: 3
2023-10-23 14:34:15,442:INFO:_display_container: 3
2023-10-23 14:34:15,442:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:34:15,442:INFO:tune_model() successfully completed......................................
2023-10-23 14:34:15,541:INFO:Initializing ensemble_model()
2023-10-23 14:34:15,541:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096DCF190>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-23 14:34:15,541:INFO:Checking exceptions
2023-10-23 14:34:15,541:INFO:Importing libraries
2023-10-23 14:34:15,557:INFO:Copying training dataset
2023-10-23 14:34:15,557:INFO:Checking base model
2023-10-23 14:34:15,557:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 14:34:15,557:INFO:Importing untrained ensembler
2023-10-23 14:34:15,557:INFO:Ensemble method set to Bagging
2023-10-23 14:34:15,557:INFO:SubProcess create_model() called ==================================
2023-10-23 14:34:15,557:INFO:Initializing create_model()
2023-10-23 14:34:15,557:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096DCF190>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E093358DC0>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:34:15,557:INFO:Checking exceptions
2023-10-23 14:34:15,557:INFO:Importing libraries
2023-10-23 14:34:15,557:INFO:Copying training dataset
2023-10-23 14:34:15,584:INFO:Defining folds
2023-10-23 14:34:15,584:INFO:Declaring metric variables
2023-10-23 14:34:15,584:INFO:Importing untrained model
2023-10-23 14:34:15,585:INFO:Declaring custom model
2023-10-23 14:34:15,586:INFO:Bagging Regressor Imported successfully
2023-10-23 14:34:15,586:INFO:Starting cross validation
2023-10-23 14:34:15,586:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:34:39,965:INFO:Calculating mean and std
2023-10-23 14:34:39,968:INFO:Creating metrics dataframe
2023-10-23 14:34:39,977:INFO:Finalizing model
2023-10-23 14:34:40,098:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005697 seconds.
2023-10-23 14:34:40,098:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:40,099:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:34:40,100:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:34:40,101:INFO:[LightGBM] [Info] Start training from score 99.624795
2023-10-23 14:34:40,488:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006397 seconds.
2023-10-23 14:34:40,488:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:40,488:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:34:40,488:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:34:40,488:INFO:[LightGBM] [Info] Start training from score 96.229614
2023-10-23 14:34:40,794:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007142 seconds.
2023-10-23 14:34:40,795:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:40,795:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:34:40,796:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:34:40,797:INFO:[LightGBM] [Info] Start training from score 95.360987
2023-10-23 14:34:41,165:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006056 seconds.
2023-10-23 14:34:41,165:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:41,166:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:34:41,167:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:34:41,168:INFO:[LightGBM] [Info] Start training from score 94.348528
2023-10-23 14:34:41,523:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006255 seconds.
2023-10-23 14:34:41,523:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:41,524:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:34:41,524:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:34:41,525:INFO:[LightGBM] [Info] Start training from score 95.509684
2023-10-23 14:34:41,805:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005180 seconds.
2023-10-23 14:34:41,805:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:41,805:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:34:41,806:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:34:41,807:INFO:[LightGBM] [Info] Start training from score 96.036959
2023-10-23 14:34:42,069:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005656 seconds.
2023-10-23 14:34:42,069:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:42,069:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:34:42,069:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:34:42,069:INFO:[LightGBM] [Info] Start training from score 97.844637
2023-10-23 14:34:42,339:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005494 seconds.
2023-10-23 14:34:42,339:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:42,339:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:34:42,339:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:34:42,339:INFO:[LightGBM] [Info] Start training from score 96.245614
2023-10-23 14:34:42,619:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007108 seconds.
2023-10-23 14:34:42,619:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:42,619:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:34:42,619:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:34:42,634:INFO:[LightGBM] [Info] Start training from score 97.594984
2023-10-23 14:34:42,901:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005595 seconds.
2023-10-23 14:34:42,901:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:42,917:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:34:42,918:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:34:42,918:INFO:[LightGBM] [Info] Start training from score 96.370407
2023-10-23 14:34:43,133:INFO:Uploading results into container
2023-10-23 14:34:43,134:INFO:Uploading model into container now
2023-10-23 14:34:43,136:INFO:_master_model_container: 4
2023-10-23 14:34:43,136:INFO:_display_container: 4
2023-10-23 14:34:43,138:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:34:43,138:INFO:create_model() successfully completed......................................
2023-10-23 14:34:43,255:INFO:SubProcess create_model() end ==================================
2023-10-23 14:34:43,255:INFO:Creating Dashboard logs
2023-10-23 14:34:43,255:INFO:Model: Bagging Regressor
2023-10-23 14:34:43,328:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-23 14:34:43,568:INFO:Initializing predict_model()
2023-10-23 14:34:43,568:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096DCF190>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096702DC0>)
2023-10-23 14:34:43,568:INFO:Checking exceptions
2023-10-23 14:34:43,568:INFO:Preloading libraries
2023-10-23 14:34:44,167:INFO:_master_model_container: 4
2023-10-23 14:34:44,167:INFO:_display_container: 4
2023-10-23 14:34:44,167:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:34:44,167:INFO:ensemble_model() successfully completed......................................
2023-10-23 14:34:44,272:INFO:Initializing finalize_model()
2023-10-23 14:34:44,272:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096DCF190>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-23 14:34:44,282:INFO:Finalizing BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:34:44,298:INFO:Initializing create_model()
2023-10-23 14:34:44,299:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096DCF190>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-23 14:34:44,299:INFO:Checking exceptions
2023-10-23 14:34:44,300:INFO:Importing libraries
2023-10-23 14:34:44,300:INFO:Copying training dataset
2023-10-23 14:34:44,301:INFO:Defining folds
2023-10-23 14:34:44,301:INFO:Declaring metric variables
2023-10-23 14:34:44,301:INFO:Importing untrained model
2023-10-23 14:34:44,301:INFO:Declaring custom model
2023-10-23 14:34:44,303:INFO:Bagging Regressor Imported successfully
2023-10-23 14:34:44,304:INFO:Cross validation set to False
2023-10-23 14:34:44,304:INFO:Fitting Model
2023-10-23 14:34:44,479:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017216 seconds.
2023-10-23 14:34:44,479:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:44,480:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:34:44,481:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:34:44,482:INFO:[LightGBM] [Info] Start training from score 96.465021
2023-10-23 14:34:44,857:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008815 seconds.
2023-10-23 14:34:44,868:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:44,868:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:34:44,868:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:34:44,868:INFO:[LightGBM] [Info] Start training from score 97.264361
2023-10-23 14:34:45,254:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008657 seconds.
2023-10-23 14:34:45,254:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:45,254:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:34:45,254:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:34:45,254:INFO:[LightGBM] [Info] Start training from score 95.842370
2023-10-23 14:34:45,684:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008002 seconds.
2023-10-23 14:34:45,684:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:45,684:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:34:45,684:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:34:45,684:INFO:[LightGBM] [Info] Start training from score 95.431515
2023-10-23 14:34:46,034:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008044 seconds.
2023-10-23 14:34:46,034:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:46,034:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:34:46,034:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:34:46,034:INFO:[LightGBM] [Info] Start training from score 97.222213
2023-10-23 14:34:46,383:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009419 seconds.
2023-10-23 14:34:46,383:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:46,383:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:34:46,383:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:34:46,383:INFO:[LightGBM] [Info] Start training from score 97.332701
2023-10-23 14:34:46,766:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007627 seconds.
2023-10-23 14:34:46,766:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:46,766:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:34:46,766:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:34:46,766:INFO:[LightGBM] [Info] Start training from score 96.452612
2023-10-23 14:34:47,167:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007072 seconds.
2023-10-23 14:34:47,167:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:47,168:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:34:47,168:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:34:47,168:INFO:[LightGBM] [Info] Start training from score 97.322509
2023-10-23 14:34:47,483:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007806 seconds.
2023-10-23 14:34:47,483:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:47,499:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:34:47,499:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:34:47,500:INFO:[LightGBM] [Info] Start training from score 96.419103
2023-10-23 14:34:47,840:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008775 seconds.
2023-10-23 14:34:47,840:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:47,840:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:34:47,840:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:34:47,840:INFO:[LightGBM] [Info] Start training from score 95.095963
2023-10-23 14:34:48,115:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:34:48,115:INFO:create_model() successfully completed......................................
2023-10-23 14:34:48,240:INFO:Creating Dashboard logs
2023-10-23 14:34:48,246:INFO:Model: Bagging Regressor
2023-10-23 14:34:48,316:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-23 14:34:48,729:INFO:_master_model_container: 4
2023-10-23 14:34:48,729:INFO:_display_container: 4
2023-10-23 14:34:48,740:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:34:48,740:INFO:finalize_model() successfully completed......................................
2023-10-23 14:34:48,849:INFO:Initializing save_model()
2023-10-23 14:34:48,849:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), model_name=final_model_for_location_B, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 14:34:48,849:INFO:Adding model into prep_pipe
2023-10-23 14:34:48,849:WARNING:Only Model saved as it was a pipeline.
2023-10-23 14:34:48,914:INFO:final_model_for_location_B.pkl saved in current working directory
2023-10-23 14:34:48,930:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:34:48,930:INFO:save_model() successfully completed......................................
2023-10-23 14:34:49,064:INFO:PyCaret RegressionExperiment
2023-10-23 14:34:49,064:INFO:Logging name: exp_C
2023-10-23 14:34:49,064:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 14:34:49,064:INFO:version 3.1.0
2023-10-23 14:34:49,065:INFO:Initializing setup()
2023-10-23 14:34:49,065:INFO:self.USI: cd30
2023-10-23 14:34:49,065:INFO:self._variable_keys: {'gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', '_ml_usecase', 'gpu_param', 'exp_name_log', 'html_param', 'fold_generator', 'y', 'seed', 'y_train', 'transform_target_param', 'n_jobs_param', 'target_param', 'idx', '_available_plots', 'log_plots_param', 'memory', 'data', 'USI', 'X', 'logging_param', 'pipeline', 'exp_id', 'X_train', 'X_test', 'fold_groups_param'}
2023-10-23 14:34:49,065:INFO:Checking environment
2023-10-23 14:34:49,065:INFO:python_version: 3.8.18
2023-10-23 14:34:49,065:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 14:34:49,065:INFO:machine: AMD64
2023-10-23 14:34:49,065:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 14:34:49,065:INFO:Memory: svmem(total=16505954304, available=2277785600, percent=86.2, used=14228168704, free=2277785600)
2023-10-23 14:34:49,065:INFO:Physical Core: 8
2023-10-23 14:34:49,065:INFO:Logical Core: 16
2023-10-23 14:34:49,065:INFO:Checking libraries
2023-10-23 14:34:49,065:INFO:System:
2023-10-23 14:34:49,065:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 14:34:49,065:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 14:34:49,065:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 14:34:49,065:INFO:PyCaret required dependencies:
2023-10-23 14:34:49,065:INFO:                 pip: 23.3
2023-10-23 14:34:49,065:INFO:          setuptools: 68.0.0
2023-10-23 14:34:49,065:INFO:             pycaret: 3.1.0
2023-10-23 14:34:49,065:INFO:             IPython: 8.12.0
2023-10-23 14:34:49,065:INFO:          ipywidgets: 8.1.1
2023-10-23 14:34:49,065:INFO:                tqdm: 4.66.1
2023-10-23 14:34:49,065:INFO:               numpy: 1.23.5
2023-10-23 14:34:49,065:INFO:              pandas: 1.5.3
2023-10-23 14:34:49,065:INFO:              jinja2: 3.1.2
2023-10-23 14:34:49,065:INFO:               scipy: 1.10.1
2023-10-23 14:34:49,065:INFO:              joblib: 1.3.2
2023-10-23 14:34:49,065:INFO:             sklearn: 1.2.2
2023-10-23 14:34:49,065:INFO:                pyod: 1.1.0
2023-10-23 14:34:49,065:INFO:            imblearn: 0.11.0
2023-10-23 14:34:49,065:INFO:   category_encoders: 2.6.2
2023-10-23 14:34:49,065:INFO:            lightgbm: 4.1.0
2023-10-23 14:34:49,065:INFO:               numba: 0.58.1
2023-10-23 14:34:49,065:INFO:            requests: 2.31.0
2023-10-23 14:34:49,065:INFO:          matplotlib: 3.7.3
2023-10-23 14:34:49,065:INFO:          scikitplot: 0.3.7
2023-10-23 14:34:49,065:INFO:         yellowbrick: 1.5
2023-10-23 14:34:49,065:INFO:              plotly: 5.17.0
2023-10-23 14:34:49,065:INFO:    plotly-resampler: Not installed
2023-10-23 14:34:49,065:INFO:             kaleido: 0.2.1
2023-10-23 14:34:49,065:INFO:           schemdraw: 0.15
2023-10-23 14:34:49,065:INFO:         statsmodels: 0.14.0
2023-10-23 14:34:49,065:INFO:              sktime: 0.21.1
2023-10-23 14:34:49,065:INFO:               tbats: 1.1.3
2023-10-23 14:34:49,065:INFO:            pmdarima: 2.0.3
2023-10-23 14:34:49,065:INFO:              psutil: 5.9.0
2023-10-23 14:34:49,065:INFO:          markupsafe: 2.1.3
2023-10-23 14:34:49,065:INFO:             pickle5: Not installed
2023-10-23 14:34:49,065:INFO:         cloudpickle: 2.2.1
2023-10-23 14:34:49,065:INFO:         deprecation: 2.1.0
2023-10-23 14:34:49,065:INFO:              xxhash: 3.4.1
2023-10-23 14:34:49,065:INFO:           wurlitzer: Not installed
2023-10-23 14:34:49,065:INFO:PyCaret optional dependencies:
2023-10-23 14:34:49,065:INFO:                shap: Not installed
2023-10-23 14:34:49,065:INFO:           interpret: Not installed
2023-10-23 14:34:49,065:INFO:                umap: Not installed
2023-10-23 14:34:49,065:INFO:     ydata_profiling: Not installed
2023-10-23 14:34:49,065:INFO:  explainerdashboard: Not installed
2023-10-23 14:34:49,065:INFO:             autoviz: Not installed
2023-10-23 14:34:49,065:INFO:           fairlearn: Not installed
2023-10-23 14:34:49,065:INFO:          deepchecks: Not installed
2023-10-23 14:34:49,065:INFO:             xgboost: Not installed
2023-10-23 14:34:49,065:INFO:            catboost: 1.2.2
2023-10-23 14:34:49,065:INFO:              kmodes: Not installed
2023-10-23 14:34:49,065:INFO:             mlxtend: Not installed
2023-10-23 14:34:49,065:INFO:       statsforecast: Not installed
2023-10-23 14:34:49,065:INFO:        tune_sklearn: Not installed
2023-10-23 14:34:49,065:INFO:                 ray: Not installed
2023-10-23 14:34:49,065:INFO:            hyperopt: Not installed
2023-10-23 14:34:49,065:INFO:              optuna: Not installed
2023-10-23 14:34:49,065:INFO:               skopt: Not installed
2023-10-23 14:34:49,065:INFO:              mlflow: 2.7.1
2023-10-23 14:34:49,065:INFO:              gradio: Not installed
2023-10-23 14:34:49,065:INFO:             fastapi: Not installed
2023-10-23 14:34:49,065:INFO:             uvicorn: Not installed
2023-10-23 14:34:49,065:INFO:              m2cgen: Not installed
2023-10-23 14:34:49,065:INFO:           evidently: Not installed
2023-10-23 14:34:49,065:INFO:               fugue: Not installed
2023-10-23 14:34:49,065:INFO:           streamlit: Not installed
2023-10-23 14:34:49,065:INFO:             prophet: Not installed
2023-10-23 14:34:49,065:INFO:None
2023-10-23 14:34:49,065:INFO:Set up data.
2023-10-23 14:34:49,098:INFO:Set up folding strategy.
2023-10-23 14:34:49,098:INFO:Set up train/test split.
2023-10-23 14:34:49,115:INFO:Set up index.
2023-10-23 14:34:49,115:INFO:Assigning column types.
2023-10-23 14:34:49,145:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 14:34:49,145:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,151:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,153:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,242:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,285:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,285:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:34:49,285:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:34:49,285:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,300:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,305:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,382:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,433:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,433:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:34:49,433:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:34:49,433:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 14:34:49,433:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,447:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,530:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,581:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,582:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:34:49,582:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:34:49,585:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,585:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,664:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,718:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,718:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:34:49,718:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:34:49,718:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 14:34:49,731:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,803:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,847:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,847:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:34:49,847:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:34:49,864:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,948:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,998:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,998:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:34:49,998:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:34:49,998:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 14:34:50,084:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:34:50,134:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:34:50,134:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:34:50,134:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:34:50,247:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:34:50,302:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:34:50,302:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:34:50,302:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:34:50,302:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 14:34:50,425:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:34:50,490:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:34:50,490:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:34:50,594:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:34:50,663:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:34:50,663:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:34:50,664:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 14:34:50,828:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:34:50,828:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:34:51,013:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:34:51,013:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:34:51,013:INFO:Preparing preprocessing pipeline...
2023-10-23 14:34:51,013:INFO:Set up simple imputation.
2023-10-23 14:34:51,028:INFO:Set up column name cleaning.
2023-10-23 14:34:51,096:INFO:Finished creating preprocessing pipeline.
2023-10-23 14:34:51,110:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 14:34:51,110:INFO:Creating final display dataframe.
2023-10-23 14:34:51,314:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (26071, 50)
4        Transformed data shape   (26071, 50)
5   Transformed train set shape   (18249, 50)
6    Transformed test set shape    (7822, 50)
7              Numeric features            49
8      Rows with missing values         95.9%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_C
19                          USI          cd30
2023-10-23 14:34:51,448:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:34:51,448:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:34:51,595:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:34:51,595:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:34:51,611:INFO:Logging experiment in loggers
2023-10-23 14:34:51,761:INFO:SubProcess save_model() called ==================================
2023-10-23 14:34:51,782:INFO:Initializing save_model()
2023-10-23 14:34:51,782:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmpmgj36nu5\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 14:34:51,782:INFO:Adding model into prep_pipe
2023-10-23 14:34:51,783:WARNING:Only Model saved as it was a pipeline.
2023-10-23 14:34:51,783:INFO:C:\Users\thoma\AppData\Local\Temp\tmpmgj36nu5\Transformation Pipeline.pkl saved in current working directory
2023-10-23 14:34:51,798:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 14:34:51,798:INFO:save_model() successfully completed......................................
2023-10-23 14:34:51,913:INFO:SubProcess save_model() end ==================================
2023-10-23 14:34:51,978:INFO:setup() successfully completed in 2.56s...............
2023-10-23 14:34:51,978:INFO:Initializing create_model()
2023-10-23 14:34:51,978:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84F40>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:34:51,978:INFO:Checking exceptions
2023-10-23 14:34:51,978:INFO:Importing libraries
2023-10-23 14:34:51,978:INFO:Copying training dataset
2023-10-23 14:34:51,996:INFO:Defining folds
2023-10-23 14:34:51,996:INFO:Declaring metric variables
2023-10-23 14:34:51,996:INFO:Importing untrained model
2023-10-23 14:34:52,010:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:34:52,010:INFO:Starting cross validation
2023-10-23 14:34:52,012:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:34:54,863:INFO:Calculating mean and std
2023-10-23 14:34:54,865:INFO:Creating metrics dataframe
2023-10-23 14:34:54,868:INFO:Finalizing model
2023-10-23 14:34:54,941:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004423 seconds.
2023-10-23 14:34:54,941:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:54,941:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:34:54,941:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:34:54,941:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-23 14:34:55,194:INFO:Creating Dashboard logs
2023-10-23 14:34:55,195:INFO:Model: Light Gradient Boosting Machine
2023-10-23 14:34:55,290:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 14:34:55,492:INFO:Initializing predict_model()
2023-10-23 14:34:55,492:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84F40>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096EA8EE0>)
2023-10-23 14:34:55,492:INFO:Checking exceptions
2023-10-23 14:34:55,492:INFO:Preloading libraries
2023-10-23 14:34:55,993:INFO:Uploading results into container
2023-10-23 14:34:55,993:INFO:Uploading model into container now
2023-10-23 14:34:55,993:INFO:_master_model_container: 1
2023-10-23 14:34:55,993:INFO:_display_container: 2
2023-10-23 14:34:55,993:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:34:55,993:INFO:create_model() successfully completed......................................
2023-10-23 14:34:56,110:INFO:Initializing tune_model()
2023-10-23 14:34:56,110:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84F40>)
2023-10-23 14:34:56,110:INFO:Checking exceptions
2023-10-23 14:34:56,125:INFO:Copying training dataset
2023-10-23 14:34:56,141:INFO:Checking base model
2023-10-23 14:34:56,141:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 14:34:56,145:INFO:Declaring metric variables
2023-10-23 14:34:56,145:INFO:Defining Hyperparameters
2023-10-23 14:34:56,264:INFO:Tuning with n_jobs=-1
2023-10-23 14:34:56,265:INFO:Initializing RandomizedSearchCV
2023-10-23 14:35:33,443:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-23 14:35:33,444:INFO:Hyperparameter search completed
2023-10-23 14:35:33,445:INFO:SubProcess create_model() called ==================================
2023-10-23 14:35:33,446:INFO:Initializing create_model()
2023-10-23 14:35:33,446:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84F40>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E096DBC580>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-23 14:35:33,446:INFO:Checking exceptions
2023-10-23 14:35:33,447:INFO:Importing libraries
2023-10-23 14:35:33,447:INFO:Copying training dataset
2023-10-23 14:35:33,469:INFO:Defining folds
2023-10-23 14:35:33,469:INFO:Declaring metric variables
2023-10-23 14:35:33,469:INFO:Importing untrained model
2023-10-23 14:35:33,475:INFO:Declaring custom model
2023-10-23 14:35:33,476:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:35:33,476:INFO:Starting cross validation
2023-10-23 14:35:33,478:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:35:42,059:INFO:Calculating mean and std
2023-10-23 14:35:42,059:INFO:Creating metrics dataframe
2023-10-23 14:35:42,059:INFO:Finalizing model
2023-10-23 14:35:42,117:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-23 14:35:42,117:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-23 14:35:42,117:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-23 14:35:42,135:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-23 14:35:42,135:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-23 14:35:42,135:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-23 14:35:42,151:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004649 seconds.
2023-10-23 14:35:42,151:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:35:42,151:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:35:42,151:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:35:42,151:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-23 14:35:42,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:35:42,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:35:42,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:35:42,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:35:42,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:35:42,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:35:42,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:35:42,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:35:43,388:INFO:Uploading results into container
2023-10-23 14:35:43,403:INFO:Uploading model into container now
2023-10-23 14:35:43,403:INFO:_master_model_container: 2
2023-10-23 14:35:43,403:INFO:_display_container: 3
2023-10-23 14:35:43,403:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-23 14:35:43,403:INFO:create_model() successfully completed......................................
2023-10-23 14:35:43,534:INFO:SubProcess create_model() end ==================================
2023-10-23 14:35:43,534:INFO:choose_better activated
2023-10-23 14:35:43,534:INFO:SubProcess create_model() called ==================================
2023-10-23 14:35:43,534:INFO:Initializing create_model()
2023-10-23 14:35:43,534:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84F40>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:35:43,534:INFO:Checking exceptions
2023-10-23 14:35:43,534:INFO:Importing libraries
2023-10-23 14:35:43,534:INFO:Copying training dataset
2023-10-23 14:35:43,557:INFO:Defining folds
2023-10-23 14:35:43,557:INFO:Declaring metric variables
2023-10-23 14:35:43,557:INFO:Importing untrained model
2023-10-23 14:35:43,557:INFO:Declaring custom model
2023-10-23 14:35:43,557:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:35:43,557:INFO:Starting cross validation
2023-10-23 14:35:43,557:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:35:45,883:INFO:Calculating mean and std
2023-10-23 14:35:45,883:INFO:Creating metrics dataframe
2023-10-23 14:35:45,883:INFO:Finalizing model
2023-10-23 14:35:45,966:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005855 seconds.
2023-10-23 14:35:45,966:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:35:45,966:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:35:45,966:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:35:45,966:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-23 14:35:46,183:INFO:Uploading results into container
2023-10-23 14:35:46,183:INFO:Uploading model into container now
2023-10-23 14:35:46,183:INFO:_master_model_container: 3
2023-10-23 14:35:46,183:INFO:_display_container: 4
2023-10-23 14:35:46,183:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:35:46,183:INFO:create_model() successfully completed......................................
2023-10-23 14:35:46,299:INFO:SubProcess create_model() end ==================================
2023-10-23 14:35:46,299:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.905
2023-10-23 14:35:46,299:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8993
2023-10-23 14:35:46,299:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-23 14:35:46,299:INFO:choose_better completed
2023-10-23 14:35:46,299:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-23 14:35:46,299:INFO:Creating Dashboard logs
2023-10-23 14:35:46,299:INFO:Model: Light Gradient Boosting Machine
2023-10-23 14:35:46,366:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 14:35:46,569:INFO:Initializing predict_model()
2023-10-23 14:35:46,569:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84F40>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096EA88B0>)
2023-10-23 14:35:46,569:INFO:Checking exceptions
2023-10-23 14:35:46,569:INFO:Preloading libraries
2023-10-23 14:35:47,018:INFO:_master_model_container: 3
2023-10-23 14:35:47,018:INFO:_display_container: 3
2023-10-23 14:35:47,018:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:35:47,018:INFO:tune_model() successfully completed......................................
2023-10-23 14:35:47,122:INFO:Initializing ensemble_model()
2023-10-23 14:35:47,122:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84F40>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-23 14:35:47,122:INFO:Checking exceptions
2023-10-23 14:35:47,138:INFO:Importing libraries
2023-10-23 14:35:47,138:INFO:Copying training dataset
2023-10-23 14:35:47,138:INFO:Checking base model
2023-10-23 14:35:47,138:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 14:35:47,138:INFO:Importing untrained ensembler
2023-10-23 14:35:47,138:INFO:Ensemble method set to Bagging
2023-10-23 14:35:47,138:INFO:SubProcess create_model() called ==================================
2023-10-23 14:35:47,138:INFO:Initializing create_model()
2023-10-23 14:35:47,138:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84F40>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E0971C0DF0>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:35:47,138:INFO:Checking exceptions
2023-10-23 14:35:47,138:INFO:Importing libraries
2023-10-23 14:35:47,138:INFO:Copying training dataset
2023-10-23 14:35:47,174:INFO:Defining folds
2023-10-23 14:35:47,174:INFO:Declaring metric variables
2023-10-23 14:35:47,174:INFO:Importing untrained model
2023-10-23 14:35:47,174:INFO:Declaring custom model
2023-10-23 14:35:47,176:INFO:Bagging Regressor Imported successfully
2023-10-23 14:35:47,177:INFO:Starting cross validation
2023-10-23 14:35:47,178:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:36:10,530:INFO:Calculating mean and std
2023-10-23 14:36:10,530:INFO:Creating metrics dataframe
2023-10-23 14:36:10,530:INFO:Finalizing model
2023-10-23 14:36:10,646:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005017 seconds.
2023-10-23 14:36:10,646:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:10,646:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:36:10,646:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:36:10,646:INFO:[LightGBM] [Info] Start training from score 77.044367
2023-10-23 14:36:10,912:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004618 seconds.
2023-10-23 14:36:10,912:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:10,912:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:36:10,912:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:36:10,912:INFO:[LightGBM] [Info] Start training from score 76.520588
2023-10-23 14:36:11,179:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005437 seconds.
2023-10-23 14:36:11,179:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:11,179:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:36:11,179:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:36:11,179:INFO:[LightGBM] [Info] Start training from score 76.462170
2023-10-23 14:36:11,446:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005279 seconds.
2023-10-23 14:36:11,446:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:11,446:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:36:11,446:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:36:11,446:INFO:[LightGBM] [Info] Start training from score 77.386428
2023-10-23 14:36:11,711:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005075 seconds.
2023-10-23 14:36:11,711:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:11,711:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:36:11,711:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:36:11,711:INFO:[LightGBM] [Info] Start training from score 73.916304
2023-10-23 14:36:11,961:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004452 seconds.
2023-10-23 14:36:11,961:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:11,961:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:36:11,961:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:36:11,977:INFO:[LightGBM] [Info] Start training from score 75.879633
2023-10-23 14:36:12,235:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004582 seconds.
2023-10-23 14:36:12,235:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:12,235:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:36:12,235:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:36:12,235:INFO:[LightGBM] [Info] Start training from score 75.615395
2023-10-23 14:36:12,494:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004239 seconds.
2023-10-23 14:36:12,494:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:12,494:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:36:12,494:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:36:12,494:INFO:[LightGBM] [Info] Start training from score 79.544595
2023-10-23 14:36:12,777:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005002 seconds.
2023-10-23 14:36:12,777:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:12,777:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:36:12,777:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:36:12,777:INFO:[LightGBM] [Info] Start training from score 76.012052
2023-10-23 14:36:13,094:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004560 seconds.
2023-10-23 14:36:13,094:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:13,094:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:36:13,094:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:36:13,094:INFO:[LightGBM] [Info] Start training from score 78.124037
2023-10-23 14:36:13,323:INFO:Uploading results into container
2023-10-23 14:36:13,325:INFO:Uploading model into container now
2023-10-23 14:36:13,326:INFO:_master_model_container: 4
2023-10-23 14:36:13,326:INFO:_display_container: 4
2023-10-23 14:36:13,327:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:36:13,327:INFO:create_model() successfully completed......................................
2023-10-23 14:36:13,443:INFO:SubProcess create_model() end ==================================
2023-10-23 14:36:13,443:INFO:Creating Dashboard logs
2023-10-23 14:36:13,443:INFO:Model: Bagging Regressor
2023-10-23 14:36:13,514:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-23 14:36:13,764:INFO:Initializing predict_model()
2023-10-23 14:36:13,764:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84F40>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096EA8670>)
2023-10-23 14:36:13,764:INFO:Checking exceptions
2023-10-23 14:36:13,764:INFO:Preloading libraries
2023-10-23 14:36:14,361:INFO:_master_model_container: 4
2023-10-23 14:36:14,361:INFO:_display_container: 4
2023-10-23 14:36:14,362:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:36:14,363:INFO:ensemble_model() successfully completed......................................
2023-10-23 14:36:14,458:INFO:Initializing finalize_model()
2023-10-23 14:36:14,458:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84F40>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-23 14:36:14,459:INFO:Finalizing BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:36:14,464:INFO:Initializing create_model()
2023-10-23 14:36:14,464:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84F40>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-23 14:36:14,464:INFO:Checking exceptions
2023-10-23 14:36:14,464:INFO:Importing libraries
2023-10-23 14:36:14,464:INFO:Copying training dataset
2023-10-23 14:36:14,464:INFO:Defining folds
2023-10-23 14:36:14,464:INFO:Declaring metric variables
2023-10-23 14:36:14,464:INFO:Importing untrained model
2023-10-23 14:36:14,464:INFO:Declaring custom model
2023-10-23 14:36:14,475:INFO:Bagging Regressor Imported successfully
2023-10-23 14:36:14,476:INFO:Cross validation set to False
2023-10-23 14:36:14,476:INFO:Fitting Model
2023-10-23 14:36:14,559:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008366 seconds.
2023-10-23 14:36:14,559:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:14,559:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:36:14,559:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:36:14,575:INFO:[LightGBM] [Info] Start training from score 77.360615
2023-10-23 14:36:14,929:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006046 seconds.
2023-10-23 14:36:14,929:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:14,945:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:36:14,945:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:36:14,945:INFO:[LightGBM] [Info] Start training from score 78.162759
2023-10-23 14:36:15,246:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006855 seconds.
2023-10-23 14:36:15,246:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:15,247:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:36:15,247:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:36:15,247:INFO:[LightGBM] [Info] Start training from score 77.185434
2023-10-23 14:36:15,545:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008025 seconds.
2023-10-23 14:36:15,545:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:15,545:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:36:15,545:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:36:15,545:INFO:[LightGBM] [Info] Start training from score 78.293126
2023-10-23 14:36:15,947:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007751 seconds.
2023-10-23 14:36:15,947:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:15,947:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:36:15,947:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:36:15,947:INFO:[LightGBM] [Info] Start training from score 75.493649
2023-10-23 14:36:16,251:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007603 seconds.
2023-10-23 14:36:16,251:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:16,251:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:36:16,252:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:36:16,252:INFO:[LightGBM] [Info] Start training from score 77.467219
2023-10-23 14:36:16,543:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005685 seconds.
2023-10-23 14:36:16,543:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:16,543:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:36:16,543:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:36:16,543:INFO:[LightGBM] [Info] Start training from score 77.083598
2023-10-23 14:36:16,849:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006492 seconds.
2023-10-23 14:36:16,849:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:16,849:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:36:16,849:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:36:16,849:INFO:[LightGBM] [Info] Start training from score 79.854607
2023-10-23 14:36:17,144:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006850 seconds.
2023-10-23 14:36:17,144:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:17,144:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:36:17,144:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:36:17,144:INFO:[LightGBM] [Info] Start training from score 76.153078
2023-10-23 14:36:17,461:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006621 seconds.
2023-10-23 14:36:17,461:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:17,461:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:36:17,461:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:36:17,461:INFO:[LightGBM] [Info] Start training from score 78.843978
2023-10-23 14:36:17,730:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:36:17,730:INFO:create_model() successfully completed......................................
2023-10-23 14:36:17,844:INFO:Creating Dashboard logs
2023-10-23 14:36:17,844:INFO:Model: Bagging Regressor
2023-10-23 14:36:17,923:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-23 14:36:18,341:INFO:_master_model_container: 4
2023-10-23 14:36:18,341:INFO:_display_container: 4
2023-10-23 14:36:18,357:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:36:18,357:INFO:finalize_model() successfully completed......................................
2023-10-23 14:36:18,477:INFO:Initializing save_model()
2023-10-23 14:36:18,477:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), model_name=final_model_for_location_C, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 14:36:18,477:INFO:Adding model into prep_pipe
2023-10-23 14:36:18,477:WARNING:Only Model saved as it was a pipeline.
2023-10-23 14:36:18,541:INFO:final_model_for_location_C.pkl saved in current working directory
2023-10-23 14:36:18,556:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:36:18,556:INFO:save_model() successfully completed......................................
2023-10-23 14:36:19,990:INFO:Initializing load_model()
2023-10-23 14:36:19,990:INFO:load_model(model_name=final_model_for_location_A, platform=None, authentication=None, verbose=True)
2023-10-23 14:36:20,024:INFO:Initializing load_model()
2023-10-23 14:36:20,024:INFO:load_model(model_name=final_model_for_location_B, platform=None, authentication=None, verbose=True)
2023-10-23 14:36:20,082:INFO:Initializing load_model()
2023-10-23 14:36:20,083:INFO:load_model(model_name=final_model_for_location_C, platform=None, authentication=None, verbose=True)
2023-10-23 14:36:20,152:INFO:Initializing predict_model()
2023-10-23 14:36:20,152:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84F40>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E0970AA5E0>)
2023-10-23 14:36:20,153:INFO:Checking exceptions
2023-10-23 14:36:20,153:INFO:Preloading libraries
2023-10-23 14:36:20,153:INFO:Set up data.
2023-10-23 14:36:20,183:INFO:Set up index.
2023-10-23 14:36:20,386:INFO:Initializing predict_model()
2023-10-23 14:36:20,386:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84F40>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E0970AA5E0>)
2023-10-23 14:36:20,386:INFO:Checking exceptions
2023-10-23 14:36:20,386:INFO:Preloading libraries
2023-10-23 14:36:20,386:INFO:Set up data.
2023-10-23 14:36:20,402:INFO:Set up index.
2023-10-23 14:36:20,593:INFO:Initializing predict_model()
2023-10-23 14:36:20,594:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84F40>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E0970AA5E0>)
2023-10-23 14:36:20,594:INFO:Checking exceptions
2023-10-23 14:36:20,594:INFO:Preloading libraries
2023-10-23 14:36:20,594:INFO:Set up data.
2023-10-23 14:36:20,611:INFO:Set up index.
2023-10-23 14:44:05,097:INFO:PyCaret RegressionExperiment
2023-10-23 14:44:05,097:INFO:Logging name: exp_A
2023-10-23 14:44:05,098:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 14:44:05,098:INFO:version 3.1.0
2023-10-23 14:44:05,098:INFO:Initializing setup()
2023-10-23 14:44:05,098:INFO:self.USI: 9317
2023-10-23 14:44:05,099:INFO:self._variable_keys: {'gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', '_ml_usecase', 'gpu_param', 'exp_name_log', 'html_param', 'fold_generator', 'y', 'seed', 'y_train', 'transform_target_param', 'n_jobs_param', 'target_param', 'idx', '_available_plots', 'log_plots_param', 'memory', 'data', 'USI', 'X', 'logging_param', 'pipeline', 'exp_id', 'X_train', 'X_test', 'fold_groups_param'}
2023-10-23 14:44:05,099:INFO:Checking environment
2023-10-23 14:44:05,099:INFO:python_version: 3.8.18
2023-10-23 14:44:05,099:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 14:44:05,099:INFO:machine: AMD64
2023-10-23 14:44:05,099:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 14:44:05,100:INFO:Memory: svmem(total=16505954304, available=4620279808, percent=72.0, used=11885674496, free=4620279808)
2023-10-23 14:44:05,100:INFO:Physical Core: 8
2023-10-23 14:44:05,100:INFO:Logical Core: 16
2023-10-23 14:44:05,100:INFO:Checking libraries
2023-10-23 14:44:05,100:INFO:System:
2023-10-23 14:44:05,101:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 14:44:05,101:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 14:44:05,101:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 14:44:05,101:INFO:PyCaret required dependencies:
2023-10-23 14:44:05,101:INFO:                 pip: 23.3
2023-10-23 14:44:05,101:INFO:          setuptools: 68.0.0
2023-10-23 14:44:05,101:INFO:             pycaret: 3.1.0
2023-10-23 14:44:05,101:INFO:             IPython: 8.12.0
2023-10-23 14:44:05,101:INFO:          ipywidgets: 8.1.1
2023-10-23 14:44:05,101:INFO:                tqdm: 4.66.1
2023-10-23 14:44:05,101:INFO:               numpy: 1.23.5
2023-10-23 14:44:05,101:INFO:              pandas: 1.5.3
2023-10-23 14:44:05,101:INFO:              jinja2: 3.1.2
2023-10-23 14:44:05,101:INFO:               scipy: 1.10.1
2023-10-23 14:44:05,101:INFO:              joblib: 1.3.2
2023-10-23 14:44:05,102:INFO:             sklearn: 1.2.2
2023-10-23 14:44:05,102:INFO:                pyod: 1.1.0
2023-10-23 14:44:05,102:INFO:            imblearn: 0.11.0
2023-10-23 14:44:05,102:INFO:   category_encoders: 2.6.2
2023-10-23 14:44:05,102:INFO:            lightgbm: 4.1.0
2023-10-23 14:44:05,102:INFO:               numba: 0.58.1
2023-10-23 14:44:05,102:INFO:            requests: 2.31.0
2023-10-23 14:44:05,102:INFO:          matplotlib: 3.7.3
2023-10-23 14:44:05,102:INFO:          scikitplot: 0.3.7
2023-10-23 14:44:05,102:INFO:         yellowbrick: 1.5
2023-10-23 14:44:05,102:INFO:              plotly: 5.17.0
2023-10-23 14:44:05,102:INFO:    plotly-resampler: Not installed
2023-10-23 14:44:05,102:INFO:             kaleido: 0.2.1
2023-10-23 14:44:05,102:INFO:           schemdraw: 0.15
2023-10-23 14:44:05,102:INFO:         statsmodels: 0.14.0
2023-10-23 14:44:05,102:INFO:              sktime: 0.21.1
2023-10-23 14:44:05,102:INFO:               tbats: 1.1.3
2023-10-23 14:44:05,102:INFO:            pmdarima: 2.0.3
2023-10-23 14:44:05,103:INFO:              psutil: 5.9.0
2023-10-23 14:44:05,103:INFO:          markupsafe: 2.1.3
2023-10-23 14:44:05,103:INFO:             pickle5: Not installed
2023-10-23 14:44:05,103:INFO:         cloudpickle: 2.2.1
2023-10-23 14:44:05,103:INFO:         deprecation: 2.1.0
2023-10-23 14:44:05,103:INFO:              xxhash: 3.4.1
2023-10-23 14:44:05,103:INFO:           wurlitzer: Not installed
2023-10-23 14:44:05,103:INFO:PyCaret optional dependencies:
2023-10-23 14:44:05,103:INFO:                shap: Not installed
2023-10-23 14:44:05,103:INFO:           interpret: Not installed
2023-10-23 14:44:05,103:INFO:                umap: Not installed
2023-10-23 14:44:05,103:INFO:     ydata_profiling: Not installed
2023-10-23 14:44:05,103:INFO:  explainerdashboard: Not installed
2023-10-23 14:44:05,103:INFO:             autoviz: Not installed
2023-10-23 14:44:05,104:INFO:           fairlearn: Not installed
2023-10-23 14:44:05,104:INFO:          deepchecks: Not installed
2023-10-23 14:44:05,104:INFO:             xgboost: Not installed
2023-10-23 14:44:05,104:INFO:            catboost: 1.2.2
2023-10-23 14:44:05,104:INFO:              kmodes: Not installed
2023-10-23 14:44:05,104:INFO:             mlxtend: Not installed
2023-10-23 14:44:05,104:INFO:       statsforecast: Not installed
2023-10-23 14:44:05,104:INFO:        tune_sklearn: Not installed
2023-10-23 14:44:05,104:INFO:                 ray: Not installed
2023-10-23 14:44:05,104:INFO:            hyperopt: Not installed
2023-10-23 14:44:05,104:INFO:              optuna: Not installed
2023-10-23 14:44:05,104:INFO:               skopt: Not installed
2023-10-23 14:44:05,104:INFO:              mlflow: 2.7.1
2023-10-23 14:44:05,104:INFO:              gradio: Not installed
2023-10-23 14:44:05,104:INFO:             fastapi: Not installed
2023-10-23 14:44:05,104:INFO:             uvicorn: Not installed
2023-10-23 14:44:05,105:INFO:              m2cgen: Not installed
2023-10-23 14:44:05,105:INFO:           evidently: Not installed
2023-10-23 14:44:05,105:INFO:               fugue: Not installed
2023-10-23 14:44:05,105:INFO:           streamlit: Not installed
2023-10-23 14:44:05,105:INFO:             prophet: Not installed
2023-10-23 14:44:05,106:INFO:None
2023-10-23 14:44:05,106:INFO:Set up data.
2023-10-23 14:44:05,140:INFO:Set up folding strategy.
2023-10-23 14:44:05,141:INFO:Set up train/test split.
2023-10-23 14:44:05,167:INFO:Set up index.
2023-10-23 14:44:05,169:INFO:Assigning column types.
2023-10-23 14:44:05,192:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 14:44:05,194:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,199:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,204:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,290:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,356:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,358:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:44:05,358:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:44:05,359:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,365:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,371:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,450:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,499:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,500:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:44:05,500:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:44:05,501:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 14:44:05,506:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,512:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,596:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,647:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,647:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:44:05,648:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:44:05,653:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,659:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,741:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,793:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,794:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:44:05,794:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:44:05,795:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 14:44:05,806:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,890:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,947:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,948:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:44:05,948:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:44:05,960:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:44:06,057:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:44:06,125:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:44:06,126:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:44:06,126:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:44:06,128:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 14:44:06,231:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:44:06,286:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:44:06,287:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:44:06,287:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:44:06,383:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:44:06,436:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:44:06,437:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:44:06,437:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:44:06,438:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 14:44:06,552:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:44:06,603:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:44:06,603:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:44:06,691:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:44:06,752:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:44:06,754:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:44:06,755:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 14:44:06,913:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:44:06,913:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:44:07,055:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:44:07,055:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:44:07,057:INFO:Preparing preprocessing pipeline...
2023-10-23 14:44:07,057:INFO:Set up simple imputation.
2023-10-23 14:44:07,060:INFO:Set up column name cleaning.
2023-10-23 14:44:07,130:INFO:Finished creating preprocessing pipeline.
2023-10-23 14:44:07,135:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 14:44:07,136:INFO:Creating final display dataframe.
2023-10-23 14:44:07,340:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (34061, 49)
4        Transformed data shape   (34061, 49)
5   Transformed train set shape   (23842, 49)
6    Transformed test set shape   (10219, 49)
7              Numeric features            48
8      Rows with missing values         23.1%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_A
19                          USI          9317
2023-10-23 14:44:07,479:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:44:07,479:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:44:07,621:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:44:07,621:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:44:07,622:INFO:Logging experiment in loggers
2023-10-23 14:44:07,745:INFO:SubProcess save_model() called ==================================
2023-10-23 14:44:07,760:INFO:Initializing save_model()
2023-10-23 14:44:07,760:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmpl_wn4l99\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 14:44:07,760:INFO:Adding model into prep_pipe
2023-10-23 14:44:07,760:WARNING:Only Model saved as it was a pipeline.
2023-10-23 14:44:07,765:INFO:C:\Users\thoma\AppData\Local\Temp\tmpl_wn4l99\Transformation Pipeline.pkl saved in current working directory
2023-10-23 14:44:07,772:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 14:44:07,772:INFO:save_model() successfully completed......................................
2023-10-23 14:44:07,904:INFO:SubProcess save_model() end ==================================
2023-10-23 14:44:07,962:INFO:setup() successfully completed in 2.53s...............
2023-10-23 14:44:07,963:INFO:Initializing create_model()
2023-10-23 14:44:07,963:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84FD0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:44:07,963:INFO:Checking exceptions
2023-10-23 14:44:07,967:INFO:Importing libraries
2023-10-23 14:44:07,968:INFO:Copying training dataset
2023-10-23 14:44:07,992:INFO:Defining folds
2023-10-23 14:44:07,992:INFO:Declaring metric variables
2023-10-23 14:44:07,993:INFO:Importing untrained model
2023-10-23 14:44:07,993:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:44:07,993:INFO:Starting cross validation
2023-10-23 14:44:07,995:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:44:16,927:INFO:Calculating mean and std
2023-10-23 14:44:16,928:INFO:Creating metrics dataframe
2023-10-23 14:44:16,931:INFO:Finalizing model
2023-10-23 14:44:17,012:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005245 seconds.
2023-10-23 14:44:17,012:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:44:17,012:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:44:17,013:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:44:17,014:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-23 14:44:17,241:INFO:Creating Dashboard logs
2023-10-23 14:44:17,242:INFO:Model: Light Gradient Boosting Machine
2023-10-23 14:44:17,335:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 14:44:17,526:INFO:Initializing predict_model()
2023-10-23 14:44:17,526:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84FD0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E08C7A5160>)
2023-10-23 14:44:17,526:INFO:Checking exceptions
2023-10-23 14:44:17,526:INFO:Preloading libraries
2023-10-23 14:44:18,009:INFO:Uploading results into container
2023-10-23 14:44:18,010:INFO:Uploading model into container now
2023-10-23 14:44:18,018:INFO:_master_model_container: 1
2023-10-23 14:44:18,019:INFO:_display_container: 2
2023-10-23 14:44:18,020:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:44:18,020:INFO:create_model() successfully completed......................................
2023-10-23 14:44:18,137:INFO:Initializing tune_model()
2023-10-23 14:44:18,137:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84FD0>)
2023-10-23 14:44:18,138:INFO:Checking exceptions
2023-10-23 14:44:18,150:INFO:Copying training dataset
2023-10-23 14:44:18,165:INFO:Checking base model
2023-10-23 14:44:18,166:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 14:44:18,166:INFO:Declaring metric variables
2023-10-23 14:44:18,166:INFO:Defining Hyperparameters
2023-10-23 14:44:18,278:INFO:Tuning with n_jobs=-1
2023-10-23 14:44:18,278:INFO:Initializing RandomizedSearchCV
2023-10-23 14:45:08,698:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-23 14:45:08,699:INFO:Hyperparameter search completed
2023-10-23 14:45:08,699:INFO:SubProcess create_model() called ==================================
2023-10-23 14:45:08,700:INFO:Initializing create_model()
2023-10-23 14:45:08,700:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84FD0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E0C7ECD820>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-23 14:45:08,700:INFO:Checking exceptions
2023-10-23 14:45:08,701:INFO:Importing libraries
2023-10-23 14:45:08,701:INFO:Copying training dataset
2023-10-23 14:45:08,726:INFO:Defining folds
2023-10-23 14:45:08,726:INFO:Declaring metric variables
2023-10-23 14:45:08,726:INFO:Importing untrained model
2023-10-23 14:45:08,726:INFO:Declaring custom model
2023-10-23 14:45:08,726:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:45:08,726:INFO:Starting cross validation
2023-10-23 14:45:08,733:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:45:17,878:INFO:Calculating mean and std
2023-10-23 14:45:17,878:INFO:Creating metrics dataframe
2023-10-23 14:45:17,878:INFO:Finalizing model
2023-10-23 14:45:17,939:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-23 14:45:17,943:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-23 14:45:17,943:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-23 14:45:17,981:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-23 14:45:17,981:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-23 14:45:17,981:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-23 14:45:17,990:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006455 seconds.
2023-10-23 14:45:17,990:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:17,990:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:45:17,990:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:45:17,993:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-23 14:45:19,086:INFO:Uploading results into container
2023-10-23 14:45:19,086:INFO:Uploading model into container now
2023-10-23 14:45:19,086:INFO:_master_model_container: 2
2023-10-23 14:45:19,086:INFO:_display_container: 3
2023-10-23 14:45:19,086:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-23 14:45:19,086:INFO:create_model() successfully completed......................................
2023-10-23 14:45:19,218:INFO:SubProcess create_model() end ==================================
2023-10-23 14:45:19,218:INFO:choose_better activated
2023-10-23 14:45:19,218:INFO:SubProcess create_model() called ==================================
2023-10-23 14:45:19,218:INFO:Initializing create_model()
2023-10-23 14:45:19,218:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84FD0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:45:19,218:INFO:Checking exceptions
2023-10-23 14:45:19,218:INFO:Importing libraries
2023-10-23 14:45:19,218:INFO:Copying training dataset
2023-10-23 14:45:19,253:INFO:Defining folds
2023-10-23 14:45:19,253:INFO:Declaring metric variables
2023-10-23 14:45:19,253:INFO:Importing untrained model
2023-10-23 14:45:19,253:INFO:Declaring custom model
2023-10-23 14:45:19,254:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:45:19,254:INFO:Starting cross validation
2023-10-23 14:45:19,254:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:45:22,115:INFO:Calculating mean and std
2023-10-23 14:45:22,115:INFO:Creating metrics dataframe
2023-10-23 14:45:22,115:INFO:Finalizing model
2023-10-23 14:45:22,199:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006830 seconds.
2023-10-23 14:45:22,199:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:22,199:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:45:22,199:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:45:22,199:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-23 14:45:22,451:INFO:Uploading results into container
2023-10-23 14:45:22,451:INFO:Uploading model into container now
2023-10-23 14:45:22,451:INFO:_master_model_container: 3
2023-10-23 14:45:22,451:INFO:_display_container: 4
2023-10-23 14:45:22,451:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:45:22,451:INFO:create_model() successfully completed......................................
2023-10-23 14:45:22,590:INFO:SubProcess create_model() end ==================================
2023-10-23 14:45:22,590:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8716
2023-10-23 14:45:22,590:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8712
2023-10-23 14:45:22,590:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-23 14:45:22,590:INFO:choose_better completed
2023-10-23 14:45:22,590:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-23 14:45:22,590:INFO:Creating Dashboard logs
2023-10-23 14:45:22,590:INFO:Model: Light Gradient Boosting Machine
2023-10-23 14:45:22,679:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 14:45:22,874:INFO:Initializing predict_model()
2023-10-23 14:45:22,874:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84FD0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E08C6C3AF0>)
2023-10-23 14:45:22,874:INFO:Checking exceptions
2023-10-23 14:45:22,874:INFO:Preloading libraries
2023-10-23 14:45:23,391:INFO:_master_model_container: 3
2023-10-23 14:45:23,391:INFO:_display_container: 3
2023-10-23 14:45:23,391:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:45:23,391:INFO:tune_model() successfully completed......................................
2023-10-23 14:45:23,507:INFO:Initializing ensemble_model()
2023-10-23 14:45:23,507:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84FD0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-23 14:45:23,507:INFO:Checking exceptions
2023-10-23 14:45:23,524:INFO:Importing libraries
2023-10-23 14:45:23,524:INFO:Copying training dataset
2023-10-23 14:45:23,524:INFO:Checking base model
2023-10-23 14:45:23,524:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 14:45:23,524:INFO:Importing untrained ensembler
2023-10-23 14:45:23,524:INFO:Ensemble method set to Bagging
2023-10-23 14:45:23,524:INFO:SubProcess create_model() called ==================================
2023-10-23 14:45:23,524:INFO:Initializing create_model()
2023-10-23 14:45:23,524:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84FD0>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E096CDC790>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:45:23,524:INFO:Checking exceptions
2023-10-23 14:45:23,524:INFO:Importing libraries
2023-10-23 14:45:23,524:INFO:Copying training dataset
2023-10-23 14:45:23,541:INFO:Defining folds
2023-10-23 14:45:23,541:INFO:Declaring metric variables
2023-10-23 14:45:23,541:INFO:Importing untrained model
2023-10-23 14:45:23,541:INFO:Declaring custom model
2023-10-23 14:45:23,541:INFO:Bagging Regressor Imported successfully
2023-10-23 14:45:23,541:INFO:Starting cross validation
2023-10-23 14:45:23,555:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:45:48,468:INFO:Calculating mean and std
2023-10-23 14:45:48,468:INFO:Creating metrics dataframe
2023-10-23 14:45:48,468:INFO:Finalizing model
2023-10-23 14:45:48,559:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005709 seconds.
2023-10-23 14:45:48,559:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:48,559:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:45:48,559:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:45:48,567:INFO:[LightGBM] [Info] Start training from score 626.831517
2023-10-23 14:45:48,856:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007452 seconds.
2023-10-23 14:45:48,856:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:48,857:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:45:48,857:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:45:48,858:INFO:[LightGBM] [Info] Start training from score 640.013980
2023-10-23 14:45:49,182:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005122 seconds.
2023-10-23 14:45:49,182:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:49,182:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:45:49,184:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:45:49,184:INFO:[LightGBM] [Info] Start training from score 623.946930
2023-10-23 14:45:49,440:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005796 seconds.
2023-10-23 14:45:49,440:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:49,440:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:45:49,455:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:45:49,455:INFO:[LightGBM] [Info] Start training from score 632.335152
2023-10-23 14:45:49,756:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007570 seconds.
2023-10-23 14:45:49,756:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:49,756:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:45:49,757:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:45:49,758:INFO:[LightGBM] [Info] Start training from score 620.070240
2023-10-23 14:45:50,021:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005001 seconds.
2023-10-23 14:45:50,021:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:50,021:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:45:50,021:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:45:50,021:INFO:[LightGBM] [Info] Start training from score 635.137343
2023-10-23 14:45:50,352:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005117 seconds.
2023-10-23 14:45:50,352:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:50,353:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:45:50,353:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:45:50,354:INFO:[LightGBM] [Info] Start training from score 620.066941
2023-10-23 14:45:50,672:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005249 seconds.
2023-10-23 14:45:50,672:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:50,673:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:45:50,673:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:45:50,674:INFO:[LightGBM] [Info] Start training from score 623.069874
2023-10-23 14:45:50,950:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005444 seconds.
2023-10-23 14:45:50,950:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:50,951:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:45:50,951:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:45:50,952:INFO:[LightGBM] [Info] Start training from score 633.817057
2023-10-23 14:45:51,237:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005689 seconds.
2023-10-23 14:45:51,237:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:51,237:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:45:51,237:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:45:51,237:INFO:[LightGBM] [Info] Start training from score 641.113408
2023-10-23 14:45:51,491:INFO:Uploading results into container
2023-10-23 14:45:51,491:INFO:Uploading model into container now
2023-10-23 14:45:51,491:INFO:_master_model_container: 4
2023-10-23 14:45:51,491:INFO:_display_container: 4
2023-10-23 14:45:51,499:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:45:51,499:INFO:create_model() successfully completed......................................
2023-10-23 14:45:51,632:INFO:SubProcess create_model() end ==================================
2023-10-23 14:45:51,632:INFO:Creating Dashboard logs
2023-10-23 14:45:51,632:INFO:Model: Bagging Regressor
2023-10-23 14:45:51,700:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-23 14:45:51,908:INFO:Initializing predict_model()
2023-10-23 14:45:51,908:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84FD0>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E08C6C3B80>)
2023-10-23 14:45:51,908:INFO:Checking exceptions
2023-10-23 14:45:51,908:INFO:Preloading libraries
2023-10-23 14:45:52,568:INFO:_master_model_container: 4
2023-10-23 14:45:52,568:INFO:_display_container: 4
2023-10-23 14:45:52,568:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:45:52,568:INFO:ensemble_model() successfully completed......................................
2023-10-23 14:45:52,684:INFO:Initializing finalize_model()
2023-10-23 14:45:52,684:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84FD0>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-23 14:45:52,684:INFO:Finalizing BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:45:52,701:INFO:Initializing create_model()
2023-10-23 14:45:52,701:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84FD0>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-23 14:45:52,701:INFO:Checking exceptions
2023-10-23 14:45:52,702:INFO:Importing libraries
2023-10-23 14:45:52,702:INFO:Copying training dataset
2023-10-23 14:45:52,702:INFO:Defining folds
2023-10-23 14:45:52,702:INFO:Declaring metric variables
2023-10-23 14:45:52,702:INFO:Importing untrained model
2023-10-23 14:45:52,702:INFO:Declaring custom model
2023-10-23 14:45:52,702:INFO:Bagging Regressor Imported successfully
2023-10-23 14:45:52,702:INFO:Cross validation set to False
2023-10-23 14:45:52,702:INFO:Fitting Model
2023-10-23 14:45:52,834:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008321 seconds.
2023-10-23 14:45:52,834:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:52,834:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:45:52,834:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:45:52,847:INFO:[LightGBM] [Info] Start training from score 634.491655
2023-10-23 14:45:53,204:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007528 seconds.
2023-10-23 14:45:53,204:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:53,204:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:45:53,204:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:45:53,204:INFO:[LightGBM] [Info] Start training from score 635.470959
2023-10-23 14:45:53,547:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006774 seconds.
2023-10-23 14:45:53,547:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:53,547:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:45:53,547:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:45:53,547:INFO:[LightGBM] [Info] Start training from score 634.053589
2023-10-23 14:45:53,980:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010125 seconds.
2023-10-23 14:45:53,980:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:53,981:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:45:53,981:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:45:53,982:INFO:[LightGBM] [Info] Start training from score 635.251785
2023-10-23 14:45:54,421:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008669 seconds.
2023-10-23 14:45:54,421:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:54,421:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:45:54,421:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:45:54,421:INFO:[LightGBM] [Info] Start training from score 627.555784
2023-10-23 14:45:54,780:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008666 seconds.
2023-10-23 14:45:54,780:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:54,780:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:45:54,780:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:45:54,780:INFO:[LightGBM] [Info] Start training from score 638.162596
2023-10-23 14:45:55,231:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007516 seconds.
2023-10-23 14:45:55,231:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:55,231:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:45:55,231:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:45:55,231:INFO:[LightGBM] [Info] Start training from score 633.181363
2023-10-23 14:45:55,595:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009193 seconds.
2023-10-23 14:45:55,595:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:55,596:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:45:55,597:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:45:55,598:INFO:[LightGBM] [Info] Start training from score 611.992287
2023-10-23 14:45:55,950:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007659 seconds.
2023-10-23 14:45:55,951:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:55,951:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:45:55,951:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:45:55,951:INFO:[LightGBM] [Info] Start training from score 638.181417
2023-10-23 14:45:56,282:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007908 seconds.
2023-10-23 14:45:56,283:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:56,283:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:45:56,284:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:45:56,285:INFO:[LightGBM] [Info] Start training from score 639.502137
2023-10-23 14:45:56,559:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:45:56,559:INFO:create_model() successfully completed......................................
2023-10-23 14:45:56,679:INFO:Creating Dashboard logs
2023-10-23 14:45:56,679:INFO:Model: Bagging Regressor
2023-10-23 14:45:56,749:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-23 14:45:57,134:INFO:_master_model_container: 4
2023-10-23 14:45:57,134:INFO:_display_container: 4
2023-10-23 14:45:57,149:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:45:57,149:INFO:finalize_model() successfully completed......................................
2023-10-23 14:45:57,266:INFO:Initializing save_model()
2023-10-23 14:45:57,266:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), model_name=final_model_for_location_A, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 14:45:57,266:INFO:Adding model into prep_pipe
2023-10-23 14:45:57,266:WARNING:Only Model saved as it was a pipeline.
2023-10-23 14:45:57,330:INFO:final_model_for_location_A.pkl saved in current working directory
2023-10-23 14:45:57,346:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:45:57,346:INFO:save_model() successfully completed......................................
2023-10-23 14:45:57,492:INFO:PyCaret RegressionExperiment
2023-10-23 14:45:57,492:INFO:Logging name: exp_B
2023-10-23 14:45:57,492:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 14:45:57,492:INFO:version 3.1.0
2023-10-23 14:45:57,492:INFO:Initializing setup()
2023-10-23 14:45:57,492:INFO:self.USI: b9ca
2023-10-23 14:45:57,492:INFO:self._variable_keys: {'gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', '_ml_usecase', 'gpu_param', 'exp_name_log', 'html_param', 'fold_generator', 'y', 'seed', 'y_train', 'transform_target_param', 'n_jobs_param', 'target_param', 'idx', '_available_plots', 'log_plots_param', 'memory', 'data', 'USI', 'X', 'logging_param', 'pipeline', 'exp_id', 'X_train', 'X_test', 'fold_groups_param'}
2023-10-23 14:45:57,492:INFO:Checking environment
2023-10-23 14:45:57,492:INFO:python_version: 3.8.18
2023-10-23 14:45:57,492:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 14:45:57,492:INFO:machine: AMD64
2023-10-23 14:45:57,492:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 14:45:57,492:INFO:Memory: svmem(total=16505954304, available=2717450240, percent=83.5, used=13788504064, free=2717450240)
2023-10-23 14:45:57,492:INFO:Physical Core: 8
2023-10-23 14:45:57,492:INFO:Logical Core: 16
2023-10-23 14:45:57,492:INFO:Checking libraries
2023-10-23 14:45:57,492:INFO:System:
2023-10-23 14:45:57,492:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 14:45:57,492:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 14:45:57,492:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 14:45:57,492:INFO:PyCaret required dependencies:
2023-10-23 14:45:57,492:INFO:                 pip: 23.3
2023-10-23 14:45:57,492:INFO:          setuptools: 68.0.0
2023-10-23 14:45:57,492:INFO:             pycaret: 3.1.0
2023-10-23 14:45:57,492:INFO:             IPython: 8.12.0
2023-10-23 14:45:57,492:INFO:          ipywidgets: 8.1.1
2023-10-23 14:45:57,492:INFO:                tqdm: 4.66.1
2023-10-23 14:45:57,492:INFO:               numpy: 1.23.5
2023-10-23 14:45:57,492:INFO:              pandas: 1.5.3
2023-10-23 14:45:57,492:INFO:              jinja2: 3.1.2
2023-10-23 14:45:57,492:INFO:               scipy: 1.10.1
2023-10-23 14:45:57,492:INFO:              joblib: 1.3.2
2023-10-23 14:45:57,492:INFO:             sklearn: 1.2.2
2023-10-23 14:45:57,492:INFO:                pyod: 1.1.0
2023-10-23 14:45:57,492:INFO:            imblearn: 0.11.0
2023-10-23 14:45:57,492:INFO:   category_encoders: 2.6.2
2023-10-23 14:45:57,492:INFO:            lightgbm: 4.1.0
2023-10-23 14:45:57,492:INFO:               numba: 0.58.1
2023-10-23 14:45:57,492:INFO:            requests: 2.31.0
2023-10-23 14:45:57,492:INFO:          matplotlib: 3.7.3
2023-10-23 14:45:57,492:INFO:          scikitplot: 0.3.7
2023-10-23 14:45:57,492:INFO:         yellowbrick: 1.5
2023-10-23 14:45:57,492:INFO:              plotly: 5.17.0
2023-10-23 14:45:57,492:INFO:    plotly-resampler: Not installed
2023-10-23 14:45:57,492:INFO:             kaleido: 0.2.1
2023-10-23 14:45:57,492:INFO:           schemdraw: 0.15
2023-10-23 14:45:57,492:INFO:         statsmodels: 0.14.0
2023-10-23 14:45:57,492:INFO:              sktime: 0.21.1
2023-10-23 14:45:57,492:INFO:               tbats: 1.1.3
2023-10-23 14:45:57,492:INFO:            pmdarima: 2.0.3
2023-10-23 14:45:57,492:INFO:              psutil: 5.9.0
2023-10-23 14:45:57,492:INFO:          markupsafe: 2.1.3
2023-10-23 14:45:57,492:INFO:             pickle5: Not installed
2023-10-23 14:45:57,492:INFO:         cloudpickle: 2.2.1
2023-10-23 14:45:57,492:INFO:         deprecation: 2.1.0
2023-10-23 14:45:57,492:INFO:              xxhash: 3.4.1
2023-10-23 14:45:57,492:INFO:           wurlitzer: Not installed
2023-10-23 14:45:57,492:INFO:PyCaret optional dependencies:
2023-10-23 14:45:57,492:INFO:                shap: Not installed
2023-10-23 14:45:57,492:INFO:           interpret: Not installed
2023-10-23 14:45:57,492:INFO:                umap: Not installed
2023-10-23 14:45:57,492:INFO:     ydata_profiling: Not installed
2023-10-23 14:45:57,492:INFO:  explainerdashboard: Not installed
2023-10-23 14:45:57,492:INFO:             autoviz: Not installed
2023-10-23 14:45:57,492:INFO:           fairlearn: Not installed
2023-10-23 14:45:57,492:INFO:          deepchecks: Not installed
2023-10-23 14:45:57,492:INFO:             xgboost: Not installed
2023-10-23 14:45:57,492:INFO:            catboost: 1.2.2
2023-10-23 14:45:57,492:INFO:              kmodes: Not installed
2023-10-23 14:45:57,492:INFO:             mlxtend: Not installed
2023-10-23 14:45:57,492:INFO:       statsforecast: Not installed
2023-10-23 14:45:57,492:INFO:        tune_sklearn: Not installed
2023-10-23 14:45:57,492:INFO:                 ray: Not installed
2023-10-23 14:45:57,492:INFO:            hyperopt: Not installed
2023-10-23 14:45:57,492:INFO:              optuna: Not installed
2023-10-23 14:45:57,492:INFO:               skopt: Not installed
2023-10-23 14:45:57,492:INFO:              mlflow: 2.7.1
2023-10-23 14:45:57,492:INFO:              gradio: Not installed
2023-10-23 14:45:57,492:INFO:             fastapi: Not installed
2023-10-23 14:45:57,492:INFO:             uvicorn: Not installed
2023-10-23 14:45:57,492:INFO:              m2cgen: Not installed
2023-10-23 14:45:57,492:INFO:           evidently: Not installed
2023-10-23 14:45:57,492:INFO:               fugue: Not installed
2023-10-23 14:45:57,492:INFO:           streamlit: Not installed
2023-10-23 14:45:57,492:INFO:             prophet: Not installed
2023-10-23 14:45:57,492:INFO:None
2023-10-23 14:45:57,492:INFO:Set up data.
2023-10-23 14:45:57,529:INFO:Set up folding strategy.
2023-10-23 14:45:57,530:INFO:Set up train/test split.
2023-10-23 14:45:57,545:INFO:Set up index.
2023-10-23 14:45:57,545:INFO:Assigning column types.
2023-10-23 14:45:57,561:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 14:45:57,561:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 14:45:57,581:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:45:57,581:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:45:57,662:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:45:57,712:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:45:57,712:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:45:57,712:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:45:57,712:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 14:45:57,712:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:45:57,712:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:45:57,802:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:45:57,846:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:45:57,846:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:45:57,846:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:45:57,846:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 14:45:57,846:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:45:57,863:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:45:57,929:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:45:57,979:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:45:57,993:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:45:57,993:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:45:57,996:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,002:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,080:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,127:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,127:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:45:58,127:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:45:58,127:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 14:45:58,127:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,212:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,265:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,266:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:45:58,266:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:45:58,266:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,342:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,389:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,389:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:45:58,389:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:45:58,389:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 14:45:58,479:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,528:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,528:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:45:58,528:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:45:58,632:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,677:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,677:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:45:58,677:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:45:58,677:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 14:45:58,764:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,816:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:45:58,816:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:45:58,905:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,956:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:45:58,957:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:45:58,957:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 14:45:59,095:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:45:59,095:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:45:59,243:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:45:59,243:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:45:59,245:INFO:Preparing preprocessing pipeline...
2023-10-23 14:45:59,245:INFO:Set up simple imputation.
2023-10-23 14:45:59,248:INFO:Set up column name cleaning.
2023-10-23 14:45:59,324:INFO:Finished creating preprocessing pipeline.
2023-10-23 14:45:59,324:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 14:45:59,324:INFO:Creating final display dataframe.
2023-10-23 14:45:59,565:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (32819, 49)
4        Transformed data shape   (32819, 49)
5   Transformed train set shape   (22973, 49)
6    Transformed test set shape    (9846, 49)
7              Numeric features            48
8      Rows with missing values         19.9%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_B
19                          USI          b9ca
2023-10-23 14:45:59,707:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:45:59,718:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:45:59,854:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:45:59,854:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:45:59,854:INFO:Logging experiment in loggers
2023-10-23 14:45:59,961:INFO:SubProcess save_model() called ==================================
2023-10-23 14:45:59,981:INFO:Initializing save_model()
2023-10-23 14:45:59,981:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmpe7u471_g\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 14:45:59,981:INFO:Adding model into prep_pipe
2023-10-23 14:45:59,982:WARNING:Only Model saved as it was a pipeline.
2023-10-23 14:45:59,986:INFO:C:\Users\thoma\AppData\Local\Temp\tmpe7u471_g\Transformation Pipeline.pkl saved in current working directory
2023-10-23 14:45:59,993:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 14:45:59,993:INFO:save_model() successfully completed......................................
2023-10-23 14:46:00,105:INFO:SubProcess save_model() end ==================================
2023-10-23 14:46:00,160:INFO:setup() successfully completed in 2.38s...............
2023-10-23 14:46:00,160:INFO:Initializing create_model()
2023-10-23 14:46:00,160:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E87DF0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:46:00,160:INFO:Checking exceptions
2023-10-23 14:46:00,160:INFO:Importing libraries
2023-10-23 14:46:00,160:INFO:Copying training dataset
2023-10-23 14:46:00,184:INFO:Defining folds
2023-10-23 14:46:00,184:INFO:Declaring metric variables
2023-10-23 14:46:00,184:INFO:Importing untrained model
2023-10-23 14:46:00,184:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:46:00,184:INFO:Starting cross validation
2023-10-23 14:46:00,191:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:46:03,398:INFO:Calculating mean and std
2023-10-23 14:46:03,398:INFO:Creating metrics dataframe
2023-10-23 14:46:03,398:INFO:Finalizing model
2023-10-23 14:46:03,498:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005603 seconds.
2023-10-23 14:46:03,498:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:46:03,499:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:46:03,499:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:46:03,500:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-23 14:46:03,727:INFO:Creating Dashboard logs
2023-10-23 14:46:03,727:INFO:Model: Light Gradient Boosting Machine
2023-10-23 14:46:03,815:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 14:46:03,992:INFO:Initializing predict_model()
2023-10-23 14:46:03,992:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E87DF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096364A60>)
2023-10-23 14:46:03,992:INFO:Checking exceptions
2023-10-23 14:46:03,992:INFO:Preloading libraries
2023-10-23 14:46:04,463:INFO:Uploading results into container
2023-10-23 14:46:04,463:INFO:Uploading model into container now
2023-10-23 14:46:04,463:INFO:_master_model_container: 1
2023-10-23 14:46:04,463:INFO:_display_container: 2
2023-10-23 14:46:04,463:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:46:04,463:INFO:create_model() successfully completed......................................
2023-10-23 14:46:04,604:INFO:Initializing tune_model()
2023-10-23 14:46:04,604:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E87DF0>)
2023-10-23 14:46:04,604:INFO:Checking exceptions
2023-10-23 14:46:04,611:INFO:Copying training dataset
2023-10-23 14:46:04,620:INFO:Checking base model
2023-10-23 14:46:04,620:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 14:46:04,620:INFO:Declaring metric variables
2023-10-23 14:46:04,620:INFO:Defining Hyperparameters
2023-10-23 14:46:04,727:INFO:Tuning with n_jobs=-1
2023-10-23 14:46:04,727:INFO:Initializing RandomizedSearchCV
2023-10-23 14:46:50,700:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-23 14:46:50,701:INFO:Hyperparameter search completed
2023-10-23 14:46:50,701:INFO:SubProcess create_model() called ==================================
2023-10-23 14:46:50,702:INFO:Initializing create_model()
2023-10-23 14:46:50,703:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E87DF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E0962FA850>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-23 14:46:50,703:INFO:Checking exceptions
2023-10-23 14:46:50,703:INFO:Importing libraries
2023-10-23 14:46:50,703:INFO:Copying training dataset
2023-10-23 14:46:50,737:INFO:Defining folds
2023-10-23 14:46:50,737:INFO:Declaring metric variables
2023-10-23 14:46:50,737:INFO:Importing untrained model
2023-10-23 14:46:50,737:INFO:Declaring custom model
2023-10-23 14:46:50,738:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:46:50,739:INFO:Starting cross validation
2023-10-23 14:46:50,740:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:47:00,304:INFO:Calculating mean and std
2023-10-23 14:47:00,306:INFO:Creating metrics dataframe
2023-10-23 14:47:00,309:INFO:Finalizing model
2023-10-23 14:47:00,360:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-23 14:47:00,360:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-23 14:47:00,361:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-23 14:47:00,394:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-23 14:47:00,394:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-23 14:47:00,394:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-23 14:47:00,395:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001608 seconds.
2023-10-23 14:47:00,395:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-23 14:47:00,395:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-23 14:47:00,395:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:47:00,395:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:47:00,395:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-23 14:47:01,750:INFO:Uploading results into container
2023-10-23 14:47:01,752:INFO:Uploading model into container now
2023-10-23 14:47:01,753:INFO:_master_model_container: 2
2023-10-23 14:47:01,753:INFO:_display_container: 3
2023-10-23 14:47:01,754:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-23 14:47:01,756:INFO:create_model() successfully completed......................................
2023-10-23 14:47:01,891:INFO:SubProcess create_model() end ==================================
2023-10-23 14:47:01,891:INFO:choose_better activated
2023-10-23 14:47:01,891:INFO:SubProcess create_model() called ==================================
2023-10-23 14:47:01,891:INFO:Initializing create_model()
2023-10-23 14:47:01,891:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E87DF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:47:01,891:INFO:Checking exceptions
2023-10-23 14:47:01,891:INFO:Importing libraries
2023-10-23 14:47:01,891:INFO:Copying training dataset
2023-10-23 14:47:01,908:INFO:Defining folds
2023-10-23 14:47:01,908:INFO:Declaring metric variables
2023-10-23 14:47:01,908:INFO:Importing untrained model
2023-10-23 14:47:01,908:INFO:Declaring custom model
2023-10-23 14:47:01,908:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:47:01,908:INFO:Starting cross validation
2023-10-23 14:47:01,908:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:47:04,461:INFO:Calculating mean and std
2023-10-23 14:47:04,461:INFO:Creating metrics dataframe
2023-10-23 14:47:04,461:INFO:Finalizing model
2023-10-23 14:47:04,544:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004684 seconds.
2023-10-23 14:47:04,544:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:04,544:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:47:04,545:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:47:04,545:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-23 14:47:04,822:INFO:Uploading results into container
2023-10-23 14:47:04,822:INFO:Uploading model into container now
2023-10-23 14:47:04,822:INFO:_master_model_container: 3
2023-10-23 14:47:04,822:INFO:_display_container: 4
2023-10-23 14:47:04,822:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:47:04,822:INFO:create_model() successfully completed......................................
2023-10-23 14:47:04,939:INFO:SubProcess create_model() end ==================================
2023-10-23 14:47:04,954:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8523
2023-10-23 14:47:04,955:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8523
2023-10-23 14:47:04,955:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-23 14:47:04,955:INFO:choose_better completed
2023-10-23 14:47:04,955:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-23 14:47:04,955:INFO:Creating Dashboard logs
2023-10-23 14:47:04,955:INFO:Model: Light Gradient Boosting Machine
2023-10-23 14:47:05,022:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 14:47:05,238:INFO:Initializing predict_model()
2023-10-23 14:47:05,238:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E87DF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E0970E9D30>)
2023-10-23 14:47:05,238:INFO:Checking exceptions
2023-10-23 14:47:05,238:INFO:Preloading libraries
2023-10-23 14:47:05,760:INFO:_master_model_container: 3
2023-10-23 14:47:05,760:INFO:_display_container: 3
2023-10-23 14:47:05,761:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:47:05,761:INFO:tune_model() successfully completed......................................
2023-10-23 14:47:05,860:INFO:Initializing ensemble_model()
2023-10-23 14:47:05,860:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E87DF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-23 14:47:05,860:INFO:Checking exceptions
2023-10-23 14:47:05,874:INFO:Importing libraries
2023-10-23 14:47:05,874:INFO:Copying training dataset
2023-10-23 14:47:05,874:INFO:Checking base model
2023-10-23 14:47:05,874:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 14:47:05,874:INFO:Importing untrained ensembler
2023-10-23 14:47:05,874:INFO:Ensemble method set to Bagging
2023-10-23 14:47:05,874:INFO:SubProcess create_model() called ==================================
2023-10-23 14:47:05,874:INFO:Initializing create_model()
2023-10-23 14:47:05,874:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E87DF0>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E096781040>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:47:05,874:INFO:Checking exceptions
2023-10-23 14:47:05,874:INFO:Importing libraries
2023-10-23 14:47:05,874:INFO:Copying training dataset
2023-10-23 14:47:05,905:INFO:Defining folds
2023-10-23 14:47:05,905:INFO:Declaring metric variables
2023-10-23 14:47:05,905:INFO:Importing untrained model
2023-10-23 14:47:05,905:INFO:Declaring custom model
2023-10-23 14:47:05,909:INFO:Bagging Regressor Imported successfully
2023-10-23 14:47:05,909:INFO:Starting cross validation
2023-10-23 14:47:05,910:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:47:29,635:INFO:Calculating mean and std
2023-10-23 14:47:29,637:INFO:Creating metrics dataframe
2023-10-23 14:47:29,639:INFO:Finalizing model
2023-10-23 14:47:29,724:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005547 seconds.
2023-10-23 14:47:29,724:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:29,724:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:47:29,734:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:47:29,735:INFO:[LightGBM] [Info] Start training from score 99.624795
2023-10-23 14:47:30,054:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005853 seconds.
2023-10-23 14:47:30,054:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:30,054:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:47:30,054:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:47:30,054:INFO:[LightGBM] [Info] Start training from score 96.229614
2023-10-23 14:47:30,338:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005411 seconds.
2023-10-23 14:47:30,338:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:30,338:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:47:30,338:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:47:30,338:INFO:[LightGBM] [Info] Start training from score 95.360987
2023-10-23 14:47:30,623:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007590 seconds.
2023-10-23 14:47:30,623:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:30,623:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:47:30,623:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:47:30,623:INFO:[LightGBM] [Info] Start training from score 94.348528
2023-10-23 14:47:30,976:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005415 seconds.
2023-10-23 14:47:30,976:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:30,976:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:47:30,976:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:47:30,976:INFO:[LightGBM] [Info] Start training from score 95.509684
2023-10-23 14:47:31,253:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005506 seconds.
2023-10-23 14:47:31,254:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:31,254:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:47:31,255:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:47:31,256:INFO:[LightGBM] [Info] Start training from score 96.036959
2023-10-23 14:47:31,558:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005650 seconds.
2023-10-23 14:47:31,558:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:31,558:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:47:31,565:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:47:31,566:INFO:[LightGBM] [Info] Start training from score 97.844637
2023-10-23 14:47:31,883:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007215 seconds.
2023-10-23 14:47:31,883:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:31,883:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:47:31,883:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:47:31,883:INFO:[LightGBM] [Info] Start training from score 96.245614
2023-10-23 14:47:32,193:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005736 seconds.
2023-10-23 14:47:32,194:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:32,194:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:47:32,194:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:47:32,195:INFO:[LightGBM] [Info] Start training from score 97.594984
2023-10-23 14:47:32,515:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005202 seconds.
2023-10-23 14:47:32,515:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:32,516:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:47:32,517:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:47:32,517:INFO:[LightGBM] [Info] Start training from score 96.370407
2023-10-23 14:47:32,767:INFO:Uploading results into container
2023-10-23 14:47:32,767:INFO:Uploading model into container now
2023-10-23 14:47:32,767:INFO:_master_model_container: 4
2023-10-23 14:47:32,767:INFO:_display_container: 4
2023-10-23 14:47:32,773:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:47:32,773:INFO:create_model() successfully completed......................................
2023-10-23 14:47:32,905:INFO:SubProcess create_model() end ==================================
2023-10-23 14:47:32,906:INFO:Creating Dashboard logs
2023-10-23 14:47:32,906:INFO:Model: Bagging Regressor
2023-10-23 14:47:32,968:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-23 14:47:33,173:INFO:Initializing predict_model()
2023-10-23 14:47:33,173:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E87DF0>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096B345E0>)
2023-10-23 14:47:33,173:INFO:Checking exceptions
2023-10-23 14:47:33,173:INFO:Preloading libraries
2023-10-23 14:47:33,827:INFO:_master_model_container: 4
2023-10-23 14:47:33,827:INFO:_display_container: 4
2023-10-23 14:47:33,830:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:47:33,830:INFO:ensemble_model() successfully completed......................................
2023-10-23 14:47:33,965:INFO:Initializing finalize_model()
2023-10-23 14:47:33,965:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E87DF0>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-23 14:47:33,965:INFO:Finalizing BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:47:33,982:INFO:Initializing create_model()
2023-10-23 14:47:33,982:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E87DF0>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-23 14:47:33,982:INFO:Checking exceptions
2023-10-23 14:47:33,982:INFO:Importing libraries
2023-10-23 14:47:33,982:INFO:Copying training dataset
2023-10-23 14:47:33,982:INFO:Defining folds
2023-10-23 14:47:33,982:INFO:Declaring metric variables
2023-10-23 14:47:33,982:INFO:Importing untrained model
2023-10-23 14:47:33,982:INFO:Declaring custom model
2023-10-23 14:47:33,982:INFO:Bagging Regressor Imported successfully
2023-10-23 14:47:33,982:INFO:Cross validation set to False
2023-10-23 14:47:33,982:INFO:Fitting Model
2023-10-23 14:47:34,142:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009669 seconds.
2023-10-23 14:47:34,142:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:34,143:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:47:34,143:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:47:34,145:INFO:[LightGBM] [Info] Start training from score 96.465021
2023-10-23 14:47:34,513:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006795 seconds.
2023-10-23 14:47:34,513:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:34,513:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:47:34,514:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:47:34,515:INFO:[LightGBM] [Info] Start training from score 97.264361
2023-10-23 14:47:34,883:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010233 seconds.
2023-10-23 14:47:34,883:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:34,883:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:47:34,883:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:47:34,883:INFO:[LightGBM] [Info] Start training from score 95.842370
2023-10-23 14:47:35,429:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009869 seconds.
2023-10-23 14:47:35,429:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:35,430:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:47:35,431:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:47:35,431:INFO:[LightGBM] [Info] Start training from score 95.431515
2023-10-23 14:47:35,829:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009113 seconds.
2023-10-23 14:47:35,829:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:35,829:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:47:35,829:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:47:35,829:INFO:[LightGBM] [Info] Start training from score 97.222213
2023-10-23 14:47:36,301:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013524 seconds.
2023-10-23 14:47:36,301:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:36,302:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:47:36,303:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:47:36,303:INFO:[LightGBM] [Info] Start training from score 97.332701
2023-10-23 14:47:36,665:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009251 seconds.
2023-10-23 14:47:36,666:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:36,666:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:47:36,667:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:47:36,668:INFO:[LightGBM] [Info] Start training from score 96.452612
2023-10-23 14:47:37,030:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008704 seconds.
2023-10-23 14:47:37,030:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:37,030:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:47:37,030:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:47:37,030:INFO:[LightGBM] [Info] Start training from score 97.322509
2023-10-23 14:47:37,373:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009085 seconds.
2023-10-23 14:47:37,373:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:37,374:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:47:37,374:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:47:37,376:INFO:[LightGBM] [Info] Start training from score 96.419103
2023-10-23 14:47:37,708:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007364 seconds.
2023-10-23 14:47:37,708:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:37,709:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:47:37,709:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:47:37,710:INFO:[LightGBM] [Info] Start training from score 95.095963
2023-10-23 14:47:37,973:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:47:37,973:INFO:create_model() successfully completed......................................
2023-10-23 14:47:38,102:INFO:Creating Dashboard logs
2023-10-23 14:47:38,103:INFO:Model: Bagging Regressor
2023-10-23 14:47:38,171:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-23 14:47:38,565:INFO:_master_model_container: 4
2023-10-23 14:47:38,565:INFO:_display_container: 4
2023-10-23 14:47:38,575:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:47:38,575:INFO:finalize_model() successfully completed......................................
2023-10-23 14:47:38,691:INFO:Initializing save_model()
2023-10-23 14:47:38,691:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), model_name=final_model_for_location_B, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 14:47:38,691:INFO:Adding model into prep_pipe
2023-10-23 14:47:38,691:WARNING:Only Model saved as it was a pipeline.
2023-10-23 14:47:38,751:INFO:final_model_for_location_B.pkl saved in current working directory
2023-10-23 14:47:38,771:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:47:38,771:INFO:save_model() successfully completed......................................
2023-10-23 14:47:38,912:INFO:PyCaret RegressionExperiment
2023-10-23 14:47:38,912:INFO:Logging name: exp_C
2023-10-23 14:47:38,912:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 14:47:38,912:INFO:version 3.1.0
2023-10-23 14:47:38,912:INFO:Initializing setup()
2023-10-23 14:47:38,912:INFO:self.USI: 349b
2023-10-23 14:47:38,912:INFO:self._variable_keys: {'gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', '_ml_usecase', 'gpu_param', 'exp_name_log', 'html_param', 'fold_generator', 'y', 'seed', 'y_train', 'transform_target_param', 'n_jobs_param', 'target_param', 'idx', '_available_plots', 'log_plots_param', 'memory', 'data', 'USI', 'X', 'logging_param', 'pipeline', 'exp_id', 'X_train', 'X_test', 'fold_groups_param'}
2023-10-23 14:47:38,912:INFO:Checking environment
2023-10-23 14:47:38,913:INFO:python_version: 3.8.18
2023-10-23 14:47:38,913:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 14:47:38,913:INFO:machine: AMD64
2023-10-23 14:47:38,913:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 14:47:38,913:INFO:Memory: svmem(total=16505954304, available=2728316928, percent=83.5, used=13777637376, free=2728316928)
2023-10-23 14:47:38,913:INFO:Physical Core: 8
2023-10-23 14:47:38,913:INFO:Logical Core: 16
2023-10-23 14:47:38,913:INFO:Checking libraries
2023-10-23 14:47:38,914:INFO:System:
2023-10-23 14:47:38,914:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 14:47:38,914:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 14:47:38,914:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 14:47:38,914:INFO:PyCaret required dependencies:
2023-10-23 14:47:38,914:INFO:                 pip: 23.3
2023-10-23 14:47:38,914:INFO:          setuptools: 68.0.0
2023-10-23 14:47:38,914:INFO:             pycaret: 3.1.0
2023-10-23 14:47:38,914:INFO:             IPython: 8.12.0
2023-10-23 14:47:38,914:INFO:          ipywidgets: 8.1.1
2023-10-23 14:47:38,914:INFO:                tqdm: 4.66.1
2023-10-23 14:47:38,914:INFO:               numpy: 1.23.5
2023-10-23 14:47:38,914:INFO:              pandas: 1.5.3
2023-10-23 14:47:38,914:INFO:              jinja2: 3.1.2
2023-10-23 14:47:38,914:INFO:               scipy: 1.10.1
2023-10-23 14:47:38,915:INFO:              joblib: 1.3.2
2023-10-23 14:47:38,915:INFO:             sklearn: 1.2.2
2023-10-23 14:47:38,915:INFO:                pyod: 1.1.0
2023-10-23 14:47:38,915:INFO:            imblearn: 0.11.0
2023-10-23 14:47:38,915:INFO:   category_encoders: 2.6.2
2023-10-23 14:47:38,915:INFO:            lightgbm: 4.1.0
2023-10-23 14:47:38,915:INFO:               numba: 0.58.1
2023-10-23 14:47:38,915:INFO:            requests: 2.31.0
2023-10-23 14:47:38,915:INFO:          matplotlib: 3.7.3
2023-10-23 14:47:38,915:INFO:          scikitplot: 0.3.7
2023-10-23 14:47:38,915:INFO:         yellowbrick: 1.5
2023-10-23 14:47:38,915:INFO:              plotly: 5.17.0
2023-10-23 14:47:38,916:INFO:    plotly-resampler: Not installed
2023-10-23 14:47:38,916:INFO:             kaleido: 0.2.1
2023-10-23 14:47:38,916:INFO:           schemdraw: 0.15
2023-10-23 14:47:38,916:INFO:         statsmodels: 0.14.0
2023-10-23 14:47:38,916:INFO:              sktime: 0.21.1
2023-10-23 14:47:38,916:INFO:               tbats: 1.1.3
2023-10-23 14:47:38,916:INFO:            pmdarima: 2.0.3
2023-10-23 14:47:38,916:INFO:              psutil: 5.9.0
2023-10-23 14:47:38,916:INFO:          markupsafe: 2.1.3
2023-10-23 14:47:38,916:INFO:             pickle5: Not installed
2023-10-23 14:47:38,916:INFO:         cloudpickle: 2.2.1
2023-10-23 14:47:38,916:INFO:         deprecation: 2.1.0
2023-10-23 14:47:38,916:INFO:              xxhash: 3.4.1
2023-10-23 14:47:38,916:INFO:           wurlitzer: Not installed
2023-10-23 14:47:38,916:INFO:PyCaret optional dependencies:
2023-10-23 14:47:38,917:INFO:                shap: Not installed
2023-10-23 14:47:38,917:INFO:           interpret: Not installed
2023-10-23 14:47:38,917:INFO:                umap: Not installed
2023-10-23 14:47:38,917:INFO:     ydata_profiling: Not installed
2023-10-23 14:47:38,917:INFO:  explainerdashboard: Not installed
2023-10-23 14:47:38,917:INFO:             autoviz: Not installed
2023-10-23 14:47:38,917:INFO:           fairlearn: Not installed
2023-10-23 14:47:38,917:INFO:          deepchecks: Not installed
2023-10-23 14:47:38,917:INFO:             xgboost: Not installed
2023-10-23 14:47:38,917:INFO:            catboost: 1.2.2
2023-10-23 14:47:38,917:INFO:              kmodes: Not installed
2023-10-23 14:47:38,917:INFO:             mlxtend: Not installed
2023-10-23 14:47:38,917:INFO:       statsforecast: Not installed
2023-10-23 14:47:38,917:INFO:        tune_sklearn: Not installed
2023-10-23 14:47:38,917:INFO:                 ray: Not installed
2023-10-23 14:47:38,917:INFO:            hyperopt: Not installed
2023-10-23 14:47:38,917:INFO:              optuna: Not installed
2023-10-23 14:47:38,917:INFO:               skopt: Not installed
2023-10-23 14:47:38,917:INFO:              mlflow: 2.7.1
2023-10-23 14:47:38,918:INFO:              gradio: Not installed
2023-10-23 14:47:38,918:INFO:             fastapi: Not installed
2023-10-23 14:47:38,918:INFO:             uvicorn: Not installed
2023-10-23 14:47:38,918:INFO:              m2cgen: Not installed
2023-10-23 14:47:38,918:INFO:           evidently: Not installed
2023-10-23 14:47:38,918:INFO:               fugue: Not installed
2023-10-23 14:47:38,918:INFO:           streamlit: Not installed
2023-10-23 14:47:38,918:INFO:             prophet: Not installed
2023-10-23 14:47:38,918:INFO:None
2023-10-23 14:47:38,918:INFO:Set up data.
2023-10-23 14:47:38,948:INFO:Set up folding strategy.
2023-10-23 14:47:38,948:INFO:Set up train/test split.
2023-10-23 14:47:38,969:INFO:Set up index.
2023-10-23 14:47:38,970:INFO:Assigning column types.
2023-10-23 14:47:38,989:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 14:47:38,990:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 14:47:38,995:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,000:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,078:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,140:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,140:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:47:39,141:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:47:39,141:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,147:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,153:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,233:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,282:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,283:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:47:39,283:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:47:39,283:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 14:47:39,289:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,294:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,369:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,417:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,418:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:47:39,418:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:47:39,425:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,430:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,503:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,552:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,553:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:47:39,553:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:47:39,554:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 14:47:39,565:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,639:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,688:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,689:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:47:39,689:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:47:39,700:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,773:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,821:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,822:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:47:39,822:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:47:39,823:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 14:47:39,908:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,957:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,958:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:47:39,958:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:47:40,051:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:47:40,089:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:47:40,089:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:47:40,089:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:47:40,089:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 14:47:40,178:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:47:40,232:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:47:40,232:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:47:40,310:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:47:40,362:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:47:40,362:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:47:40,362:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 14:47:40,501:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:47:40,501:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:47:40,655:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:47:40,656:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:47:40,657:INFO:Preparing preprocessing pipeline...
2023-10-23 14:47:40,657:INFO:Set up simple imputation.
2023-10-23 14:47:40,660:INFO:Set up column name cleaning.
2023-10-23 14:47:40,740:INFO:Finished creating preprocessing pipeline.
2023-10-23 14:47:40,740:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 14:47:40,740:INFO:Creating final display dataframe.
2023-10-23 14:47:40,979:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (26071, 49)
4        Transformed data shape   (26071, 49)
5   Transformed train set shape   (18249, 49)
6    Transformed test set shape    (7822, 49)
7              Numeric features            48
8      Rows with missing values         25.0%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_C
19                          USI          349b
2023-10-23 14:47:41,125:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:47:41,126:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:47:41,278:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:47:41,278:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:47:41,280:INFO:Logging experiment in loggers
2023-10-23 14:47:41,414:INFO:SubProcess save_model() called ==================================
2023-10-23 14:47:41,430:INFO:Initializing save_model()
2023-10-23 14:47:41,430:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmpy9t5z0ne\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 14:47:41,430:INFO:Adding model into prep_pipe
2023-10-23 14:47:41,430:WARNING:Only Model saved as it was a pipeline.
2023-10-23 14:47:41,434:INFO:C:\Users\thoma\AppData\Local\Temp\tmpy9t5z0ne\Transformation Pipeline.pkl saved in current working directory
2023-10-23 14:47:41,442:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 14:47:41,442:INFO:save_model() successfully completed......................................
2023-10-23 14:47:41,566:INFO:SubProcess save_model() end ==================================
2023-10-23 14:47:41,628:INFO:setup() successfully completed in 2.37s...............
2023-10-23 14:47:41,629:INFO:Initializing create_model()
2023-10-23 14:47:41,629:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E095E7AF70>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:47:41,629:INFO:Checking exceptions
2023-10-23 14:47:41,633:INFO:Importing libraries
2023-10-23 14:47:41,633:INFO:Copying training dataset
2023-10-23 14:47:41,656:INFO:Defining folds
2023-10-23 14:47:41,656:INFO:Declaring metric variables
2023-10-23 14:47:41,656:INFO:Importing untrained model
2023-10-23 14:47:41,657:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:47:41,657:INFO:Starting cross validation
2023-10-23 14:47:41,659:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:47:44,812:INFO:Calculating mean and std
2023-10-23 14:47:44,814:INFO:Creating metrics dataframe
2023-10-23 14:47:44,819:INFO:Finalizing model
2023-10-23 14:47:44,903:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003910 seconds.
2023-10-23 14:47:44,904:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:44,904:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:47:44,905:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:47:44,905:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-23 14:47:45,157:INFO:Creating Dashboard logs
2023-10-23 14:47:45,157:INFO:Model: Light Gradient Boosting Machine
2023-10-23 14:47:45,256:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 14:47:45,455:INFO:Initializing predict_model()
2023-10-23 14:47:45,455:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E095E7AF70>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096789310>)
2023-10-23 14:47:45,455:INFO:Checking exceptions
2023-10-23 14:47:45,455:INFO:Preloading libraries
2023-10-23 14:47:45,958:INFO:Uploading results into container
2023-10-23 14:47:45,958:INFO:Uploading model into container now
2023-10-23 14:47:45,958:INFO:_master_model_container: 1
2023-10-23 14:47:45,958:INFO:_display_container: 2
2023-10-23 14:47:45,958:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:47:45,958:INFO:create_model() successfully completed......................................
2023-10-23 14:47:46,069:INFO:Initializing tune_model()
2023-10-23 14:47:46,069:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E095E7AF70>)
2023-10-23 14:47:46,069:INFO:Checking exceptions
2023-10-23 14:47:46,082:INFO:Copying training dataset
2023-10-23 14:47:46,085:INFO:Checking base model
2023-10-23 14:47:46,085:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 14:47:46,085:INFO:Declaring metric variables
2023-10-23 14:47:46,085:INFO:Defining Hyperparameters
2023-10-23 14:47:46,232:INFO:Tuning with n_jobs=-1
2023-10-23 14:47:46,232:INFO:Initializing RandomizedSearchCV
2023-10-23 14:48:24,018:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-23 14:48:24,019:INFO:Hyperparameter search completed
2023-10-23 14:48:24,019:INFO:SubProcess create_model() called ==================================
2023-10-23 14:48:24,020:INFO:Initializing create_model()
2023-10-23 14:48:24,021:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E095E7AF70>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E096CD9760>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-23 14:48:24,021:INFO:Checking exceptions
2023-10-23 14:48:24,021:INFO:Importing libraries
2023-10-23 14:48:24,021:INFO:Copying training dataset
2023-10-23 14:48:24,050:INFO:Defining folds
2023-10-23 14:48:24,050:INFO:Declaring metric variables
2023-10-23 14:48:24,050:INFO:Importing untrained model
2023-10-23 14:48:24,051:INFO:Declaring custom model
2023-10-23 14:48:24,052:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:48:24,052:INFO:Starting cross validation
2023-10-23 14:48:24,054:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:48:34,839:INFO:Calculating mean and std
2023-10-23 14:48:34,840:INFO:Creating metrics dataframe
2023-10-23 14:48:34,844:INFO:Finalizing model
2023-10-23 14:48:34,890:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-23 14:48:34,890:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-23 14:48:34,890:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-23 14:48:34,916:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-23 14:48:34,916:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-23 14:48:34,916:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-23 14:48:34,922:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004448 seconds.
2023-10-23 14:48:34,922:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:48:34,923:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:48:34,923:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:48:34,925:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-23 14:48:34,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:48:34,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:48:34,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:48:34,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:48:34,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:48:34,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:48:34,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:48:34,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:48:36,170:INFO:Uploading results into container
2023-10-23 14:48:36,171:INFO:Uploading model into container now
2023-10-23 14:48:36,172:INFO:_master_model_container: 2
2023-10-23 14:48:36,172:INFO:_display_container: 3
2023-10-23 14:48:36,173:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-23 14:48:36,174:INFO:create_model() successfully completed......................................
2023-10-23 14:48:36,327:INFO:SubProcess create_model() end ==================================
2023-10-23 14:48:36,327:INFO:choose_better activated
2023-10-23 14:48:36,327:INFO:SubProcess create_model() called ==================================
2023-10-23 14:48:36,328:INFO:Initializing create_model()
2023-10-23 14:48:36,328:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E095E7AF70>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:48:36,329:INFO:Checking exceptions
2023-10-23 14:48:36,330:INFO:Importing libraries
2023-10-23 14:48:36,330:INFO:Copying training dataset
2023-10-23 14:48:36,354:INFO:Defining folds
2023-10-23 14:48:36,354:INFO:Declaring metric variables
2023-10-23 14:48:36,354:INFO:Importing untrained model
2023-10-23 14:48:36,354:INFO:Declaring custom model
2023-10-23 14:48:36,355:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:48:36,356:INFO:Starting cross validation
2023-10-23 14:48:36,357:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:48:39,155:INFO:Calculating mean and std
2023-10-23 14:48:39,155:INFO:Creating metrics dataframe
2023-10-23 14:48:39,155:INFO:Finalizing model
2023-10-23 14:48:39,233:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005192 seconds.
2023-10-23 14:48:39,233:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:48:39,233:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:48:39,233:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:48:39,233:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-23 14:48:39,479:INFO:Uploading results into container
2023-10-23 14:48:39,480:INFO:Uploading model into container now
2023-10-23 14:48:39,481:INFO:_master_model_container: 3
2023-10-23 14:48:39,481:INFO:_display_container: 4
2023-10-23 14:48:39,481:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:48:39,481:INFO:create_model() successfully completed......................................
2023-10-23 14:48:39,626:INFO:SubProcess create_model() end ==================================
2023-10-23 14:48:39,628:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.905
2023-10-23 14:48:39,629:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8993
2023-10-23 14:48:39,629:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-23 14:48:39,629:INFO:choose_better completed
2023-10-23 14:48:39,629:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-23 14:48:39,630:INFO:Creating Dashboard logs
2023-10-23 14:48:39,630:INFO:Model: Light Gradient Boosting Machine
2023-10-23 14:48:39,700:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 14:48:39,888:INFO:Initializing predict_model()
2023-10-23 14:48:39,889:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E095E7AF70>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096CAF550>)
2023-10-23 14:48:39,889:INFO:Checking exceptions
2023-10-23 14:48:39,889:INFO:Preloading libraries
2023-10-23 14:48:40,388:INFO:_master_model_container: 3
2023-10-23 14:48:40,389:INFO:_display_container: 3
2023-10-23 14:48:40,389:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:48:40,389:INFO:tune_model() successfully completed......................................
2023-10-23 14:48:40,504:INFO:Initializing ensemble_model()
2023-10-23 14:48:40,504:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E095E7AF70>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-23 14:48:40,504:INFO:Checking exceptions
2023-10-23 14:48:40,515:INFO:Importing libraries
2023-10-23 14:48:40,516:INFO:Copying training dataset
2023-10-23 14:48:40,516:INFO:Checking base model
2023-10-23 14:48:40,516:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 14:48:40,517:INFO:Importing untrained ensembler
2023-10-23 14:48:40,517:INFO:Ensemble method set to Bagging
2023-10-23 14:48:40,517:INFO:SubProcess create_model() called ==================================
2023-10-23 14:48:40,518:INFO:Initializing create_model()
2023-10-23 14:48:40,518:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E095E7AF70>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E096EFA970>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:48:40,518:INFO:Checking exceptions
2023-10-23 14:48:40,518:INFO:Importing libraries
2023-10-23 14:48:40,518:INFO:Copying training dataset
2023-10-23 14:48:40,540:INFO:Defining folds
2023-10-23 14:48:40,540:INFO:Declaring metric variables
2023-10-23 14:48:40,540:INFO:Importing untrained model
2023-10-23 14:48:40,540:INFO:Declaring custom model
2023-10-23 14:48:40,542:INFO:Bagging Regressor Imported successfully
2023-10-23 14:48:40,542:INFO:Starting cross validation
2023-10-23 14:48:40,544:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:49:08,614:INFO:Calculating mean and std
2023-10-23 14:49:08,616:INFO:Creating metrics dataframe
2023-10-23 14:49:08,620:INFO:Finalizing model
2023-10-23 14:49:08,715:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004583 seconds.
2023-10-23 14:49:08,716:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:08,716:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:49:08,717:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:49:08,717:INFO:[LightGBM] [Info] Start training from score 77.044367
2023-10-23 14:49:09,016:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005129 seconds.
2023-10-23 14:49:09,016:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:09,017:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:49:09,017:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:49:09,019:INFO:[LightGBM] [Info] Start training from score 76.520588
2023-10-23 14:49:09,297:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005449 seconds.
2023-10-23 14:49:09,297:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:09,298:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:49:09,298:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:49:09,299:INFO:[LightGBM] [Info] Start training from score 76.462170
2023-10-23 14:49:09,559:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004986 seconds.
2023-10-23 14:49:09,559:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:09,560:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:49:09,560:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:49:09,561:INFO:[LightGBM] [Info] Start training from score 77.386428
2023-10-23 14:49:09,830:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004397 seconds.
2023-10-23 14:49:09,831:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:09,831:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:49:09,832:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:49:09,832:INFO:[LightGBM] [Info] Start training from score 73.916304
2023-10-23 14:49:10,118:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004851 seconds.
2023-10-23 14:49:10,118:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:10,119:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:49:10,119:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:49:10,119:INFO:[LightGBM] [Info] Start training from score 75.879633
2023-10-23 14:49:10,391:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004740 seconds.
2023-10-23 14:49:10,391:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:10,391:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:49:10,391:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:49:10,392:INFO:[LightGBM] [Info] Start training from score 75.615395
2023-10-23 14:49:10,669:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005798 seconds.
2023-10-23 14:49:10,669:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:10,670:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:49:10,670:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:49:10,671:INFO:[LightGBM] [Info] Start training from score 79.544595
2023-10-23 14:49:10,955:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004772 seconds.
2023-10-23 14:49:10,955:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:10,955:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:49:10,956:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:49:10,956:INFO:[LightGBM] [Info] Start training from score 76.012052
2023-10-23 14:49:11,212:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005272 seconds.
2023-10-23 14:49:11,212:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:11,212:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:49:11,213:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:49:11,213:INFO:[LightGBM] [Info] Start training from score 78.124037
2023-10-23 14:49:11,439:INFO:Uploading results into container
2023-10-23 14:49:11,440:INFO:Uploading model into container now
2023-10-23 14:49:11,441:INFO:_master_model_container: 4
2023-10-23 14:49:11,442:INFO:_display_container: 4
2023-10-23 14:49:11,443:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:49:11,444:INFO:create_model() successfully completed......................................
2023-10-23 14:49:11,580:INFO:SubProcess create_model() end ==================================
2023-10-23 14:49:11,581:INFO:Creating Dashboard logs
2023-10-23 14:49:11,581:INFO:Model: Bagging Regressor
2023-10-23 14:49:11,655:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-23 14:49:11,884:INFO:Initializing predict_model()
2023-10-23 14:49:11,884:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E095E7AF70>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096CAF700>)
2023-10-23 14:49:11,884:INFO:Checking exceptions
2023-10-23 14:49:11,884:INFO:Preloading libraries
2023-10-23 14:49:12,495:INFO:_master_model_container: 4
2023-10-23 14:49:12,496:INFO:_display_container: 4
2023-10-23 14:49:12,497:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:49:12,497:INFO:ensemble_model() successfully completed......................................
2023-10-23 14:49:12,611:INFO:Initializing finalize_model()
2023-10-23 14:49:12,611:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E095E7AF70>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-23 14:49:12,611:INFO:Finalizing BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:49:12,624:INFO:Initializing create_model()
2023-10-23 14:49:12,624:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E095E7AF70>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-23 14:49:12,624:INFO:Checking exceptions
2023-10-23 14:49:12,625:INFO:Importing libraries
2023-10-23 14:49:12,625:INFO:Copying training dataset
2023-10-23 14:49:12,626:INFO:Defining folds
2023-10-23 14:49:12,626:INFO:Declaring metric variables
2023-10-23 14:49:12,626:INFO:Importing untrained model
2023-10-23 14:49:12,626:INFO:Declaring custom model
2023-10-23 14:49:12,627:INFO:Bagging Regressor Imported successfully
2023-10-23 14:49:12,627:INFO:Cross validation set to False
2023-10-23 14:49:12,627:INFO:Fitting Model
2023-10-23 14:49:12,725:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006446 seconds.
2023-10-23 14:49:12,725:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:12,725:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:49:12,725:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:49:12,729:INFO:[LightGBM] [Info] Start training from score 77.360615
2023-10-23 14:49:13,083:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006861 seconds.
2023-10-23 14:49:13,083:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:13,098:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:49:13,098:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:49:13,100:INFO:[LightGBM] [Info] Start training from score 78.162759
2023-10-23 14:49:13,369:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005830 seconds.
2023-10-23 14:49:13,369:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:13,370:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:49:13,370:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:49:13,371:INFO:[LightGBM] [Info] Start training from score 77.185434
2023-10-23 14:49:13,737:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006602 seconds.
2023-10-23 14:49:13,737:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:13,748:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:49:13,749:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:49:13,750:INFO:[LightGBM] [Info] Start training from score 78.293126
2023-10-23 14:49:14,101:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005662 seconds.
2023-10-23 14:49:14,101:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:14,101:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:49:14,101:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:49:14,101:INFO:[LightGBM] [Info] Start training from score 75.493649
2023-10-23 14:49:14,399:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006417 seconds.
2023-10-23 14:49:14,399:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:14,399:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:49:14,399:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:49:14,399:INFO:[LightGBM] [Info] Start training from score 77.467219
2023-10-23 14:49:14,765:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006263 seconds.
2023-10-23 14:49:14,765:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:14,765:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:49:14,765:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:49:14,765:INFO:[LightGBM] [Info] Start training from score 77.083598
2023-10-23 14:49:15,103:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005896 seconds.
2023-10-23 14:49:15,103:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:15,104:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:49:15,104:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:49:15,104:INFO:[LightGBM] [Info] Start training from score 79.854607
2023-10-23 14:49:15,383:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005470 seconds.
2023-10-23 14:49:15,383:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:15,383:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:49:15,383:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:49:15,383:INFO:[LightGBM] [Info] Start training from score 76.153078
2023-10-23 14:49:15,653:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005816 seconds.
2023-10-23 14:49:15,653:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:15,653:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:49:15,653:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:49:15,653:INFO:[LightGBM] [Info] Start training from score 78.843978
2023-10-23 14:49:15,884:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:49:15,884:INFO:create_model() successfully completed......................................
2023-10-23 14:49:16,015:INFO:Creating Dashboard logs
2023-10-23 14:49:16,015:INFO:Model: Bagging Regressor
2023-10-23 14:49:16,084:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-23 14:49:16,451:INFO:_master_model_container: 4
2023-10-23 14:49:16,451:INFO:_display_container: 4
2023-10-23 14:49:16,451:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:49:16,451:INFO:finalize_model() successfully completed......................................
2023-10-23 14:49:16,577:INFO:Initializing save_model()
2023-10-23 14:49:16,577:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), model_name=final_model_for_location_C, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 14:49:16,577:INFO:Adding model into prep_pipe
2023-10-23 14:49:16,577:WARNING:Only Model saved as it was a pipeline.
2023-10-23 14:49:16,632:INFO:final_model_for_location_C.pkl saved in current working directory
2023-10-23 14:49:16,648:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:49:16,648:INFO:save_model() successfully completed......................................
2023-10-23 14:49:17,818:INFO:Initializing load_model()
2023-10-23 14:49:17,818:INFO:load_model(model_name=final_model_for_location_A, platform=None, authentication=None, verbose=True)
2023-10-23 14:49:17,858:INFO:Initializing load_model()
2023-10-23 14:49:17,858:INFO:load_model(model_name=final_model_for_location_B, platform=None, authentication=None, verbose=True)
2023-10-23 14:49:17,900:INFO:Initializing load_model()
2023-10-23 14:49:17,900:INFO:load_model(model_name=final_model_for_location_C, platform=None, authentication=None, verbose=True)
2023-10-23 14:49:17,959:INFO:Initializing predict_model()
2023-10-23 14:49:17,959:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E095E7AF70>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096C5B160>)
2023-10-23 14:49:17,959:INFO:Checking exceptions
2023-10-23 14:49:17,960:INFO:Preloading libraries
2023-10-23 14:49:17,960:INFO:Set up data.
2023-10-23 14:49:17,993:INFO:Set up index.
2023-10-23 14:49:18,207:INFO:Initializing predict_model()
2023-10-23 14:49:18,207:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E095E7AF70>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096C5B160>)
2023-10-23 14:49:18,207:INFO:Checking exceptions
2023-10-23 14:49:18,207:INFO:Preloading libraries
2023-10-23 14:49:18,207:INFO:Set up data.
2023-10-23 14:49:18,207:INFO:Set up index.
2023-10-23 14:49:18,394:INFO:Initializing predict_model()
2023-10-23 14:49:18,394:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E095E7AF70>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096C5B160>)
2023-10-23 14:49:18,394:INFO:Checking exceptions
2023-10-23 14:49:18,394:INFO:Preloading libraries
2023-10-23 14:49:18,394:INFO:Set up data.
2023-10-23 14:49:18,409:INFO:Set up index.
2023-10-23 15:34:25,905:INFO:PyCaret RegressionExperiment
2023-10-23 15:34:25,905:INFO:Logging name: exp_A
2023-10-23 15:34:25,906:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 15:34:25,906:INFO:version 3.1.0
2023-10-23 15:34:25,907:INFO:Initializing setup()
2023-10-23 15:34:25,907:INFO:self.USI: 5315
2023-10-23 15:34:25,908:INFO:self._variable_keys: {'gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', '_ml_usecase', 'gpu_param', 'exp_name_log', 'html_param', 'fold_generator', 'y', 'seed', 'y_train', 'transform_target_param', 'n_jobs_param', 'target_param', 'idx', '_available_plots', 'log_plots_param', 'memory', 'data', 'USI', 'X', 'logging_param', 'pipeline', 'exp_id', 'X_train', 'X_test', 'fold_groups_param'}
2023-10-23 15:34:25,908:INFO:Checking environment
2023-10-23 15:34:25,909:INFO:python_version: 3.8.18
2023-10-23 15:34:25,909:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 15:34:25,910:INFO:machine: AMD64
2023-10-23 15:34:25,910:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 15:34:25,910:INFO:Memory: svmem(total=16505954304, available=4813242368, percent=70.8, used=11692711936, free=4813242368)
2023-10-23 15:34:25,911:INFO:Physical Core: 8
2023-10-23 15:34:25,911:INFO:Logical Core: 16
2023-10-23 15:34:25,912:INFO:Checking libraries
2023-10-23 15:34:25,912:INFO:System:
2023-10-23 15:34:25,912:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 15:34:25,912:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 15:34:25,912:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 15:34:25,913:INFO:PyCaret required dependencies:
2023-10-23 15:34:25,913:INFO:                 pip: 23.3
2023-10-23 15:34:25,913:INFO:          setuptools: 68.0.0
2023-10-23 15:34:25,914:INFO:             pycaret: 3.1.0
2023-10-23 15:34:25,914:INFO:             IPython: 8.12.0
2023-10-23 15:34:25,914:INFO:          ipywidgets: 8.1.1
2023-10-23 15:34:25,915:INFO:                tqdm: 4.66.1
2023-10-23 15:34:25,915:INFO:               numpy: 1.23.5
2023-10-23 15:34:25,915:INFO:              pandas: 1.5.3
2023-10-23 15:34:25,916:INFO:              jinja2: 3.1.2
2023-10-23 15:34:25,916:INFO:               scipy: 1.10.1
2023-10-23 15:34:25,917:INFO:              joblib: 1.3.2
2023-10-23 15:34:25,917:INFO:             sklearn: 1.2.2
2023-10-23 15:34:25,917:INFO:                pyod: 1.1.0
2023-10-23 15:34:25,918:INFO:            imblearn: 0.11.0
2023-10-23 15:34:25,918:INFO:   category_encoders: 2.6.2
2023-10-23 15:34:25,918:INFO:            lightgbm: 4.1.0
2023-10-23 15:34:25,918:INFO:               numba: 0.58.1
2023-10-23 15:34:25,919:INFO:            requests: 2.31.0
2023-10-23 15:34:25,919:INFO:          matplotlib: 3.7.3
2023-10-23 15:34:25,919:INFO:          scikitplot: 0.3.7
2023-10-23 15:34:25,919:INFO:         yellowbrick: 1.5
2023-10-23 15:34:25,919:INFO:              plotly: 5.17.0
2023-10-23 15:34:25,920:INFO:    plotly-resampler: Not installed
2023-10-23 15:34:25,920:INFO:             kaleido: 0.2.1
2023-10-23 15:34:25,920:INFO:           schemdraw: 0.15
2023-10-23 15:34:25,920:INFO:         statsmodels: 0.14.0
2023-10-23 15:34:25,921:INFO:              sktime: 0.21.1
2023-10-23 15:34:25,921:INFO:               tbats: 1.1.3
2023-10-23 15:34:25,921:INFO:            pmdarima: 2.0.3
2023-10-23 15:34:25,921:INFO:              psutil: 5.9.0
2023-10-23 15:34:25,922:INFO:          markupsafe: 2.1.3
2023-10-23 15:34:25,922:INFO:             pickle5: Not installed
2023-10-23 15:34:25,922:INFO:         cloudpickle: 2.2.1
2023-10-23 15:34:25,922:INFO:         deprecation: 2.1.0
2023-10-23 15:34:25,922:INFO:              xxhash: 3.4.1
2023-10-23 15:34:25,922:INFO:           wurlitzer: Not installed
2023-10-23 15:34:25,923:INFO:PyCaret optional dependencies:
2023-10-23 15:34:25,923:INFO:                shap: Not installed
2023-10-23 15:34:25,923:INFO:           interpret: Not installed
2023-10-23 15:34:25,923:INFO:                umap: Not installed
2023-10-23 15:34:25,923:INFO:     ydata_profiling: Not installed
2023-10-23 15:34:25,923:INFO:  explainerdashboard: Not installed
2023-10-23 15:34:25,923:INFO:             autoviz: Not installed
2023-10-23 15:34:25,924:INFO:           fairlearn: Not installed
2023-10-23 15:34:25,924:INFO:          deepchecks: Not installed
2023-10-23 15:34:25,924:INFO:             xgboost: Not installed
2023-10-23 15:34:25,924:INFO:            catboost: 1.2.2
2023-10-23 15:34:25,924:INFO:              kmodes: Not installed
2023-10-23 15:34:25,924:INFO:             mlxtend: Not installed
2023-10-23 15:34:25,924:INFO:       statsforecast: Not installed
2023-10-23 15:34:25,924:INFO:        tune_sklearn: Not installed
2023-10-23 15:34:25,924:INFO:                 ray: Not installed
2023-10-23 15:34:25,924:INFO:            hyperopt: Not installed
2023-10-23 15:34:25,924:INFO:              optuna: Not installed
2023-10-23 15:34:25,924:INFO:               skopt: Not installed
2023-10-23 15:34:25,925:INFO:              mlflow: 2.7.1
2023-10-23 15:34:25,925:INFO:              gradio: Not installed
2023-10-23 15:34:25,925:INFO:             fastapi: Not installed
2023-10-23 15:34:25,925:INFO:             uvicorn: Not installed
2023-10-23 15:34:25,925:INFO:              m2cgen: Not installed
2023-10-23 15:34:25,925:INFO:           evidently: Not installed
2023-10-23 15:34:25,925:INFO:               fugue: Not installed
2023-10-23 15:34:25,925:INFO:           streamlit: Not installed
2023-10-23 15:34:25,925:INFO:             prophet: Not installed
2023-10-23 15:34:25,925:INFO:None
2023-10-23 15:34:25,925:INFO:Set up data.
2023-10-23 15:34:25,966:INFO:Set up folding strategy.
2023-10-23 15:34:25,966:INFO:Set up train/test split.
2023-10-23 15:34:26,010:INFO:Set up index.
2023-10-23 15:34:26,012:INFO:Assigning column types.
2023-10-23 15:34:26,044:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 15:34:26,045:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,050:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,055:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,140:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,175:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,175:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 15:34:26,175:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 15:34:26,175:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,192:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,198:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,282:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,322:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,322:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 15:34:26,322:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 15:34:26,322:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 15:34:26,338:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,338:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,425:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,457:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,457:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 15:34:26,457:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 15:34:26,474:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,483:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,564:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,611:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,611:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 15:34:26,612:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 15:34:26,612:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 15:34:26,620:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,699:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,746:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,747:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 15:34:26,748:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 15:34:26,758:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,835:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,878:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,878:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 15:34:26,878:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 15:34:26,878:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 15:34:26,979:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 15:34:27,029:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 15:34:27,030:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 15:34:27,030:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 15:34:27,112:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 15:34:27,160:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 15:34:27,160:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 15:34:27,160:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 15:34:27,160:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 15:34:27,246:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 15:34:27,297:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 15:34:27,297:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 15:34:27,378:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 15:34:27,427:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 15:34:27,427:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 15:34:27,427:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 15:34:27,572:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 15:34:27,573:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 15:34:27,709:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 15:34:27,709:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 15:34:27,709:INFO:Preparing preprocessing pipeline...
2023-10-23 15:34:27,709:INFO:Set up date feature engineering.
2023-10-23 15:34:27,709:INFO:Set up simple imputation.
2023-10-23 15:34:27,727:INFO:Set up encoding of ordinal features.
2023-10-23 15:34:27,760:INFO:Set up encoding of categorical features.
2023-10-23 15:34:27,760:INFO:Set up polynomial features.
2023-10-23 15:34:27,760:INFO:Set up removing outliers.
2023-10-23 15:34:27,763:INFO:Set up column name cleaning.
2023-10-23 15:34:29,924:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:34:58,498:INFO:Finished creating preprocessing pipeline.
2023-10-23 15:34:58,597:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_ene...
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 15:34:58,597:INFO:Creating final display dataframe.
2023-10-23 15:34:59,551:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:35:31,806:INFO:Setup _display_container:                     Description          Value
0                    Session id            123
1                        Target         target
2                   Target type     Regression
3           Original data shape    (34061, 52)
4        Transformed data shape  (32868, 1540)
5   Transformed train set shape  (22649, 1540)
6    Transformed test set shape  (10219, 1540)
7              Ordinal features              4
8              Numeric features             44
9                 Date features              3
10         Categorical features              4
11     Rows with missing values          90.5%
12                   Preprocess           True
13              Imputation type         simple
14           Numeric imputation           mean
15       Categorical imputation           mode
16     Maximum one-hot encoding             25
17              Encoding method           None
18          Polynomial features           True
19            Polynomial degree              2
20              Remove outliers           True
21           Outliers threshold           0.05
22               Fold Generator          KFold
23                  Fold Number             10
24                     CPU Jobs             -1
25                      Use GPU          False
26               Log Experiment   MlflowLogger
27              Experiment Name          exp_A
28                          USI           5315
2023-10-23 15:35:31,941:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 15:35:31,941:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 15:35:32,091:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 15:35:32,091:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 15:35:32,091:INFO:Logging experiment in loggers
2023-10-23 15:35:32,220:INFO:SubProcess save_model() called ==================================
2023-10-23 15:35:32,455:INFO:Initializing save_model()
2023-10-23 15:35:32,455:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_ene...
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmptj34vz9k\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_ene...
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 15:35:32,456:INFO:Adding model into prep_pipe
2023-10-23 15:35:32,456:WARNING:Only Model saved as it was a pipeline.
2023-10-23 15:35:32,539:INFO:C:\Users\thoma\AppData\Local\Temp\tmptj34vz9k\Transformation Pipeline.pkl saved in current working directory
2023-10-23 15:35:32,686:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_ene...
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 15:35:32,686:INFO:save_model() successfully completed......................................
2023-10-23 15:35:32,819:INFO:SubProcess save_model() end ==================================
2023-10-23 15:35:32,908:INFO:setup() successfully completed in 66.19s...............
2023-10-23 15:35:32,908:INFO:Initializing create_model()
2023-10-23 15:35:32,908:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E99F10>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 15:35:32,908:INFO:Checking exceptions
2023-10-23 15:35:32,908:INFO:Importing libraries
2023-10-23 15:35:32,908:INFO:Copying training dataset
2023-10-23 15:35:32,937:INFO:Defining folds
2023-10-23 15:35:32,937:INFO:Declaring metric variables
2023-10-23 15:35:32,937:INFO:Importing untrained model
2023-10-23 15:35:32,937:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 15:35:32,938:INFO:Starting cross validation
2023-10-23 15:35:32,955:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 15:35:47,304:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:35:49,487:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:35:52,996:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:35:53,109:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:35:53,351:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:35:53,375:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:35:53,405:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:35:53,561:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:35:54,541:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:35:54,961:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:38:06,176:INFO:Calculating mean and std
2023-10-23 15:38:06,179:INFO:Creating metrics dataframe
2023-10-23 15:38:06,185:INFO:Finalizing model
2023-10-23 15:38:08,048:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:38:38,454:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-10-23 15:38:38,704:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.223384 seconds.
2023-10-23 15:38:38,704:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 15:38:38,713:INFO:[LightGBM] [Info] Total Bins 232794
2023-10-23 15:38:38,726:INFO:[LightGBM] [Info] Number of data points in the train set: 22649, number of used features: 1345
2023-10-23 15:38:38,733:INFO:[LightGBM] [Info] Start training from score 606.666216
2023-10-23 15:38:43,078:INFO:Creating Dashboard logs
2023-10-23 15:38:43,079:INFO:Model: Light Gradient Boosting Machine
2023-10-23 15:38:43,172:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 15:38:43,362:INFO:Initializing predict_model()
2023-10-23 15:38:43,362:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E99F10>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096917790>)
2023-10-23 15:38:43,362:INFO:Checking exceptions
2023-10-23 15:38:43,362:INFO:Preloading libraries
2023-10-23 15:38:44,406:INFO:Uploading results into container
2023-10-23 15:38:44,407:INFO:Uploading model into container now
2023-10-23 15:38:44,411:INFO:_master_model_container: 1
2023-10-23 15:38:44,411:INFO:_display_container: 2
2023-10-23 15:38:44,411:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 15:38:44,411:INFO:create_model() successfully completed......................................
2023-10-23 15:38:44,519:INFO:Initializing tune_model()
2023-10-23 15:38:44,519:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E99F10>)
2023-10-23 15:38:44,519:INFO:Checking exceptions
2023-10-23 15:38:44,531:INFO:Copying training dataset
2023-10-23 15:38:44,547:INFO:Checking base model
2023-10-23 15:38:44,547:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 15:38:44,548:INFO:Declaring metric variables
2023-10-23 15:38:44,548:INFO:Defining Hyperparameters
2023-10-23 15:38:44,680:INFO:Tuning with n_jobs=-1
2023-10-23 15:38:44,680:INFO:Initializing RandomizedSearchCV
2023-10-23 15:38:50,024:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:38:50,235:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:38:50,241:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:38:50,322:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:38:50,380:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:38:51,140:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:38:52,430:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:38:53,602:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:38:56,451:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:38:57,759:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:39:11,085:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:39:15,396:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:39:18,112:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:39:18,362:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:39:18,338:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:39:22,480:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:42:36,169:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:42:36,986:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:42:37,024:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:42:41,282:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:42:42,248:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:42:49,428:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:45:04,986:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:45:07,811:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:45:08,544:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:45:09,201:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:47:04,166:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:47:09,347:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:47:13,807:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:47:19,719:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:47:23,268:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:47:28,714:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:47:39,264:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:47:39,629:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:47:40,942:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:47:44,029:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:50:08,362:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:50:15,309:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:50:23,751:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:50:31,598:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:50:34,042:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:50:39,920:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:51:58,020:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:52:19,390:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:52:48,417:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:52:54,807:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:52:57,721:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:54:05,758:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:54:07,956:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:54:11,427:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:54:21,147:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:54:34,032:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:55:15,782:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:55:27,499:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:55:32,744:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:55:36,344:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:56:04,775:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:56:13,978:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:56:42,689:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:56:53,540:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

