2023-10-20 23:15:29,306:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-20 23:15:29,306:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-20 23:15:29,306:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-20 23:15:29,306:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-20 23:20:46,999:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-20 23:20:46,999:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-20 23:20:46,999:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-20 23:20:46,999:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-20 23:20:47,186:INFO:PyCaret RegressionExperiment
2023-10-20 23:20:47,186:INFO:Logging name: exp_A
2023-10-20 23:20:47,186:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-20 23:20:47,186:INFO:version 3.1.0
2023-10-20 23:20:47,186:INFO:Initializing setup()
2023-10-20 23:20:47,186:INFO:self.USI: 2be0
2023-10-20 23:20:47,186:INFO:self._variable_keys: {'transform_target_param', 'exp_name_log', 'y_train', 'logging_param', 'n_jobs_param', 'X_train', 'target_param', 'USI', 'gpu_n_jobs_param', 'fold_groups_param', '_ml_usecase', 'seed', 'fold_generator', 'idx', 'html_param', 'log_plots_param', 'y', 'gpu_param', 'X_test', 'memory', 'y_test', 'data', 'X', 'exp_id', '_available_plots', 'fold_shuffle_param', 'pipeline'}
2023-10-20 23:20:47,186:INFO:Checking environment
2023-10-20 23:20:47,186:INFO:python_version: 3.8.18
2023-10-20 23:20:47,186:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-20 23:20:47,186:INFO:machine: AMD64
2023-10-20 23:20:47,186:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-20 23:20:47,186:INFO:Memory: svmem(total=16505954304, available=3563368448, percent=78.4, used=12942585856, free=3563368448)
2023-10-20 23:20:47,186:INFO:Physical Core: 8
2023-10-20 23:20:47,186:INFO:Logical Core: 16
2023-10-20 23:20:47,186:INFO:Checking libraries
2023-10-20 23:20:47,186:INFO:System:
2023-10-20 23:20:47,186:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-20 23:20:47,186:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-20 23:20:47,186:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-20 23:20:47,186:INFO:PyCaret required dependencies:
2023-10-20 23:20:47,253:INFO:                 pip: 23.3
2023-10-20 23:20:47,254:INFO:          setuptools: 68.0.0
2023-10-20 23:20:47,254:INFO:             pycaret: 3.1.0
2023-10-20 23:20:47,254:INFO:             IPython: 8.12.0
2023-10-20 23:20:47,254:INFO:          ipywidgets: 8.1.1
2023-10-20 23:20:47,254:INFO:                tqdm: 4.66.1
2023-10-20 23:20:47,254:INFO:               numpy: 1.23.5
2023-10-20 23:20:47,254:INFO:              pandas: 1.5.3
2023-10-20 23:20:47,254:INFO:              jinja2: 3.1.2
2023-10-20 23:20:47,254:INFO:               scipy: 1.10.1
2023-10-20 23:20:47,254:INFO:              joblib: 1.3.2
2023-10-20 23:20:47,254:INFO:             sklearn: 1.2.2
2023-10-20 23:20:47,254:INFO:                pyod: 1.1.0
2023-10-20 23:20:47,254:INFO:            imblearn: 0.11.0
2023-10-20 23:20:47,254:INFO:   category_encoders: 2.6.2
2023-10-20 23:20:47,254:INFO:            lightgbm: 4.1.0
2023-10-20 23:20:47,254:INFO:               numba: 0.58.1
2023-10-20 23:20:47,254:INFO:            requests: 2.31.0
2023-10-20 23:20:47,254:INFO:          matplotlib: 3.7.3
2023-10-20 23:20:47,254:INFO:          scikitplot: 0.3.7
2023-10-20 23:20:47,254:INFO:         yellowbrick: 1.5
2023-10-20 23:20:47,255:INFO:              plotly: 5.17.0
2023-10-20 23:20:47,255:INFO:    plotly-resampler: Not installed
2023-10-20 23:20:47,255:INFO:             kaleido: 0.2.1
2023-10-20 23:20:47,255:INFO:           schemdraw: 0.15
2023-10-20 23:20:47,255:INFO:         statsmodels: 0.14.0
2023-10-20 23:20:47,255:INFO:              sktime: 0.21.1
2023-10-20 23:20:47,255:INFO:               tbats: 1.1.3
2023-10-20 23:20:47,255:INFO:            pmdarima: 2.0.3
2023-10-20 23:20:47,255:INFO:              psutil: 5.9.0
2023-10-20 23:20:47,255:INFO:          markupsafe: 2.1.3
2023-10-20 23:20:47,255:INFO:             pickle5: Not installed
2023-10-20 23:20:47,255:INFO:         cloudpickle: 2.2.1
2023-10-20 23:20:47,255:INFO:         deprecation: 2.1.0
2023-10-20 23:20:47,255:INFO:              xxhash: 3.4.1
2023-10-20 23:20:47,255:INFO:           wurlitzer: Not installed
2023-10-20 23:20:47,255:INFO:PyCaret optional dependencies:
2023-10-20 23:20:47,270:INFO:                shap: Not installed
2023-10-20 23:20:47,270:INFO:           interpret: Not installed
2023-10-20 23:20:47,270:INFO:                umap: Not installed
2023-10-20 23:20:47,271:INFO:     ydata_profiling: Not installed
2023-10-20 23:20:47,271:INFO:  explainerdashboard: Not installed
2023-10-20 23:20:47,271:INFO:             autoviz: Not installed
2023-10-20 23:20:47,271:INFO:           fairlearn: Not installed
2023-10-20 23:20:47,271:INFO:          deepchecks: Not installed
2023-10-20 23:20:47,271:INFO:             xgboost: Not installed
2023-10-20 23:20:47,271:INFO:            catboost: 1.2.2
2023-10-20 23:20:47,271:INFO:              kmodes: Not installed
2023-10-20 23:20:47,271:INFO:             mlxtend: Not installed
2023-10-20 23:20:47,271:INFO:       statsforecast: Not installed
2023-10-20 23:20:47,271:INFO:        tune_sklearn: Not installed
2023-10-20 23:20:47,271:INFO:                 ray: Not installed
2023-10-20 23:20:47,271:INFO:            hyperopt: Not installed
2023-10-20 23:20:47,271:INFO:              optuna: Not installed
2023-10-20 23:20:47,271:INFO:               skopt: Not installed
2023-10-20 23:20:47,271:INFO:              mlflow: 2.7.1
2023-10-20 23:20:47,271:INFO:              gradio: Not installed
2023-10-20 23:20:47,271:INFO:             fastapi: Not installed
2023-10-20 23:20:47,271:INFO:             uvicorn: Not installed
2023-10-20 23:20:47,271:INFO:              m2cgen: Not installed
2023-10-20 23:20:47,271:INFO:           evidently: Not installed
2023-10-20 23:20:47,272:INFO:               fugue: Not installed
2023-10-20 23:20:47,272:INFO:           streamlit: Not installed
2023-10-20 23:20:47,272:INFO:             prophet: Not installed
2023-10-20 23:20:47,272:INFO:None
2023-10-20 23:20:47,272:INFO:Set up data.
2023-10-20 23:20:47,303:INFO:Set up folding strategy.
2023-10-20 23:20:47,303:INFO:Set up train/test split.
2023-10-20 23:20:47,324:INFO:Set up index.
2023-10-20 23:20:47,324:INFO:Assigning column types.
2023-10-20 23:20:47,355:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-20 23:20:47,355:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,357:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,369:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,461:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,515:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,517:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:20:47,517:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:20:47,518:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,520:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,520:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,605:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,653:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,653:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:20:47,653:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:20:47,653:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-20 23:20:47,668:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,668:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,759:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,818:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,819:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:20:47,819:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:20:47,819:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,833:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,921:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,970:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:20:47,970:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:20:47,970:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:20:47,970:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-20 23:20:47,990:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-20 23:20:48,067:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:20:48,133:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:20:48,133:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:20:48,134:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:20:48,145:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-20 23:20:48,217:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:20:48,267:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:20:48,267:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:20:48,267:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:20:48,267:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-20 23:20:48,371:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:20:48,422:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:20:48,422:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:20:48,422:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:20:48,525:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:20:48,585:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:20:48,586:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:20:48,586:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:20:48,587:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-20 23:20:48,688:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:20:48,744:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:20:48,744:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:20:48,841:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:20:48,900:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:20:48,900:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:20:48,901:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-20 23:20:49,053:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:20:49,053:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:20:49,203:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:20:49,203:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:20:49,219:INFO:Preparing preprocessing pipeline...
2023-10-20 23:20:49,219:INFO:Set up simple imputation.
2023-10-20 23:20:49,219:INFO:Set up column name cleaning.
2023-10-20 23:20:49,286:INFO:Finished creating preprocessing pipeline.
2023-10-20 23:20:49,286:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-20 23:20:49,286:INFO:Creating final display dataframe.
2023-10-20 23:20:49,501:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (34061, 39)
4        Transformed data shape   (34061, 39)
5   Transformed train set shape   (23842, 39)
6    Transformed test set shape   (10219, 39)
7              Numeric features            38
8      Rows with missing values         23.1%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_A
19                          USI          2be0
2023-10-20 23:20:49,668:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:20:49,669:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:20:49,824:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:20:49,824:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:20:49,824:INFO:Logging experiment in loggers
2023-10-20 23:20:50,167:INFO:SubProcess save_model() called ==================================
2023-10-20 23:20:50,167:INFO:Initializing save_model()
2023-10-20 23:20:50,167:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmp4rp_n54e\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-20 23:20:50,167:INFO:Adding model into prep_pipe
2023-10-20 23:20:50,167:WARNING:Only Model saved as it was a pipeline.
2023-10-20 23:20:50,183:INFO:C:\Users\thoma\AppData\Local\Temp\tmp4rp_n54e\Transformation Pipeline.pkl saved in current working directory
2023-10-20 23:20:50,183:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-20 23:20:50,183:INFO:save_model() successfully completed......................................
2023-10-20 23:20:50,283:INFO:SubProcess save_model() end ==================================
2023-10-20 23:20:50,381:INFO:setup() successfully completed in 2.64s...............
2023-10-20 23:20:50,381:INFO:Initializing compare_models()
2023-10-20 23:20:50,381:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, 'include': None, 'exclude': ['ransac'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=['ransac'])
2023-10-20 23:20:50,381:INFO:Checking exceptions
2023-10-20 23:20:50,397:INFO:Preparing display monitor
2023-10-20 23:20:50,397:INFO:Initializing Linear Regression
2023-10-20 23:20:50,397:INFO:Total runtime is 0.0 minutes
2023-10-20 23:20:50,397:INFO:SubProcess create_model() called ==================================
2023-10-20 23:20:50,397:INFO:Initializing create_model()
2023-10-20 23:20:50,397:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:20:50,397:INFO:Checking exceptions
2023-10-20 23:20:50,397:INFO:Importing libraries
2023-10-20 23:20:50,397:INFO:Copying training dataset
2023-10-20 23:20:50,431:INFO:Defining folds
2023-10-20 23:20:50,433:INFO:Declaring metric variables
2023-10-20 23:20:50,433:INFO:Importing untrained model
2023-10-20 23:20:50,433:INFO:Linear Regression Imported successfully
2023-10-20 23:20:50,434:INFO:Starting cross validation
2023-10-20 23:20:50,437:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:20:57,263:INFO:Calculating mean and std
2023-10-20 23:20:57,266:INFO:Creating metrics dataframe
2023-10-20 23:20:57,266:INFO:Uploading results into container
2023-10-20 23:20:57,266:INFO:Uploading model into container now
2023-10-20 23:20:57,266:INFO:_master_model_container: 1
2023-10-20 23:20:57,266:INFO:_display_container: 2
2023-10-20 23:20:57,266:INFO:LinearRegression(n_jobs=-1)
2023-10-20 23:20:57,266:INFO:create_model() successfully completed......................................
2023-10-20 23:20:57,391:INFO:SubProcess create_model() end ==================================
2023-10-20 23:20:57,391:INFO:Creating metrics dataframe
2023-10-20 23:20:57,391:INFO:Initializing Lasso Regression
2023-10-20 23:20:57,391:INFO:Total runtime is 0.11657266219456991 minutes
2023-10-20 23:20:57,391:INFO:SubProcess create_model() called ==================================
2023-10-20 23:20:57,391:INFO:Initializing create_model()
2023-10-20 23:20:57,391:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:20:57,391:INFO:Checking exceptions
2023-10-20 23:20:57,407:INFO:Importing libraries
2023-10-20 23:20:57,407:INFO:Copying training dataset
2023-10-20 23:20:57,430:INFO:Defining folds
2023-10-20 23:20:57,430:INFO:Declaring metric variables
2023-10-20 23:20:57,430:INFO:Importing untrained model
2023-10-20 23:20:57,430:INFO:Lasso Regression Imported successfully
2023-10-20 23:20:57,430:INFO:Starting cross validation
2023-10-20 23:20:57,430:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:20:58,289:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.464e+09, tolerance: 2.904e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:20:58,304:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.457e+09, tolerance: 2.881e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:20:58,336:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.410e+09, tolerance: 2.856e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:20:58,352:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.470e+09, tolerance: 2.933e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:02,475:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.448e+09, tolerance: 2.871e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:02,551:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.427e+09, tolerance: 2.896e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:02,558:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.463e+09, tolerance: 2.927e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:02,573:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.450e+09, tolerance: 2.898e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:02,573:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.456e+09, tolerance: 2.898e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:02,656:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.460e+09, tolerance: 2.900e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:02,804:INFO:Calculating mean and std
2023-10-20 23:21:02,805:INFO:Creating metrics dataframe
2023-10-20 23:21:02,805:INFO:Uploading results into container
2023-10-20 23:21:02,805:INFO:Uploading model into container now
2023-10-20 23:21:02,805:INFO:_master_model_container: 2
2023-10-20 23:21:02,805:INFO:_display_container: 2
2023-10-20 23:21:02,805:INFO:Lasso(random_state=123)
2023-10-20 23:21:02,805:INFO:create_model() successfully completed......................................
2023-10-20 23:21:02,922:INFO:SubProcess create_model() end ==================================
2023-10-20 23:21:02,922:INFO:Creating metrics dataframe
2023-10-20 23:21:02,922:INFO:Initializing Ridge Regression
2023-10-20 23:21:02,922:INFO:Total runtime is 0.20875295797983806 minutes
2023-10-20 23:21:02,922:INFO:SubProcess create_model() called ==================================
2023-10-20 23:21:02,922:INFO:Initializing create_model()
2023-10-20 23:21:02,922:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:21:02,922:INFO:Checking exceptions
2023-10-20 23:21:02,922:INFO:Importing libraries
2023-10-20 23:21:02,922:INFO:Copying training dataset
2023-10-20 23:21:02,955:INFO:Defining folds
2023-10-20 23:21:02,955:INFO:Declaring metric variables
2023-10-20 23:21:02,958:INFO:Importing untrained model
2023-10-20 23:21:02,958:INFO:Ridge Regression Imported successfully
2023-10-20 23:21:02,958:INFO:Starting cross validation
2023-10-20 23:21:02,958:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:21:03,095:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.09042e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:21:03,095:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.08204e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:21:03,096:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.07861e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:21:03,103:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.06296e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:21:03,106:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.05293e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:21:03,122:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.07372e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:21:03,122:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.06625e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:21:03,139:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.06293e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:21:03,156:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.1254e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:21:03,162:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.05971e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:21:03,294:INFO:Calculating mean and std
2023-10-20 23:21:03,296:INFO:Creating metrics dataframe
2023-10-20 23:21:03,300:INFO:Uploading results into container
2023-10-20 23:21:03,301:INFO:Uploading model into container now
2023-10-20 23:21:03,301:INFO:_master_model_container: 3
2023-10-20 23:21:03,302:INFO:_display_container: 2
2023-10-20 23:21:03,302:INFO:Ridge(random_state=123)
2023-10-20 23:21:03,302:INFO:create_model() successfully completed......................................
2023-10-20 23:21:03,402:INFO:SubProcess create_model() end ==================================
2023-10-20 23:21:03,402:INFO:Creating metrics dataframe
2023-10-20 23:21:03,405:INFO:Initializing Elastic Net
2023-10-20 23:21:03,405:INFO:Total runtime is 0.21679709752400717 minutes
2023-10-20 23:21:03,405:INFO:SubProcess create_model() called ==================================
2023-10-20 23:21:03,405:INFO:Initializing create_model()
2023-10-20 23:21:03,405:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:21:03,405:INFO:Checking exceptions
2023-10-20 23:21:03,405:INFO:Importing libraries
2023-10-20 23:21:03,405:INFO:Copying training dataset
2023-10-20 23:21:03,426:INFO:Defining folds
2023-10-20 23:21:03,426:INFO:Declaring metric variables
2023-10-20 23:21:03,426:INFO:Importing untrained model
2023-10-20 23:21:03,426:INFO:Elastic Net Imported successfully
2023-10-20 23:21:03,426:INFO:Starting cross validation
2023-10-20 23:21:03,426:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:21:04,795:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.468e+09, tolerance: 2.871e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:04,795:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.476e+09, tolerance: 2.898e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:04,810:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.448e+09, tolerance: 2.896e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:04,827:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.481e+09, tolerance: 2.900e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:04,880:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.482e+09, tolerance: 2.927e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:04,891:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.470e+09, tolerance: 2.898e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:04,891:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.484e+09, tolerance: 2.904e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:04,907:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.477e+09, tolerance: 2.881e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:04,907:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.431e+09, tolerance: 2.856e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:04,922:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.490e+09, tolerance: 2.933e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:21:05,068:INFO:Calculating mean and std
2023-10-20 23:21:05,070:INFO:Creating metrics dataframe
2023-10-20 23:21:05,074:INFO:Uploading results into container
2023-10-20 23:21:05,074:INFO:Uploading model into container now
2023-10-20 23:21:05,074:INFO:_master_model_container: 4
2023-10-20 23:21:05,074:INFO:_display_container: 2
2023-10-20 23:21:05,074:INFO:ElasticNet(random_state=123)
2023-10-20 23:21:05,074:INFO:create_model() successfully completed......................................
2023-10-20 23:21:05,168:INFO:SubProcess create_model() end ==================================
2023-10-20 23:21:05,168:INFO:Creating metrics dataframe
2023-10-20 23:21:05,168:INFO:Initializing Least Angle Regression
2023-10-20 23:21:05,168:INFO:Total runtime is 0.24618028004964193 minutes
2023-10-20 23:21:05,168:INFO:SubProcess create_model() called ==================================
2023-10-20 23:21:05,168:INFO:Initializing create_model()
2023-10-20 23:21:05,168:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:21:05,168:INFO:Checking exceptions
2023-10-20 23:21:05,168:INFO:Importing libraries
2023-10-20 23:21:05,168:INFO:Copying training dataset
2023-10-20 23:21:05,192:INFO:Defining folds
2023-10-20 23:21:05,192:INFO:Declaring metric variables
2023-10-20 23:21:05,192:INFO:Importing untrained model
2023-10-20 23:21:05,192:INFO:Least Angle Regression Imported successfully
2023-10-20 23:21:05,192:INFO:Starting cross validation
2023-10-20 23:21:05,207:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:21:05,538:INFO:Calculating mean and std
2023-10-20 23:21:05,538:INFO:Creating metrics dataframe
2023-10-20 23:21:05,538:INFO:Uploading results into container
2023-10-20 23:21:05,538:INFO:Uploading model into container now
2023-10-20 23:21:05,538:INFO:_master_model_container: 5
2023-10-20 23:21:05,538:INFO:_display_container: 2
2023-10-20 23:21:05,538:INFO:Lars(random_state=123)
2023-10-20 23:21:05,538:INFO:create_model() successfully completed......................................
2023-10-20 23:21:05,655:INFO:SubProcess create_model() end ==================================
2023-10-20 23:21:05,661:INFO:Creating metrics dataframe
2023-10-20 23:21:05,661:INFO:Initializing Lasso Least Angle Regression
2023-10-20 23:21:05,661:INFO:Total runtime is 0.25440373420715334 minutes
2023-10-20 23:21:05,661:INFO:SubProcess create_model() called ==================================
2023-10-20 23:21:05,661:INFO:Initializing create_model()
2023-10-20 23:21:05,661:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:21:05,661:INFO:Checking exceptions
2023-10-20 23:21:05,661:INFO:Importing libraries
2023-10-20 23:21:05,661:INFO:Copying training dataset
2023-10-20 23:21:05,690:INFO:Defining folds
2023-10-20 23:21:05,690:INFO:Declaring metric variables
2023-10-20 23:21:05,690:INFO:Importing untrained model
2023-10-20 23:21:05,690:INFO:Lasso Least Angle Regression Imported successfully
2023-10-20 23:21:05,690:INFO:Starting cross validation
2023-10-20 23:21:05,690:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:21:05,833:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=1.588e+02, previous alpha=1.437e+02, with an active set of 14 regressors.
  warnings.warn(

2023-10-20 23:21:05,833:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 26 iterations, alpha=3.480e+01, previous alpha=3.271e+01, with an active set of 17 regressors.
  warnings.warn(

2023-10-20 23:21:05,848:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 26 iterations, alpha=3.393e+01, previous alpha=3.161e+01, with an active set of 17 regressors.
  warnings.warn(

2023-10-20 23:21:05,864:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 35 iterations, alpha=8.305e+00, previous alpha=6.087e+00, with an active set of 26 regressors.
  warnings.warn(

2023-10-20 23:21:05,880:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 29 iterations, alpha=1.570e+01, previous alpha=1.483e+01, with an active set of 20 regressors.
  warnings.warn(

2023-10-20 23:21:05,880:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 31 iterations, alpha=2.233e+01, previous alpha=2.086e+01, with an active set of 18 regressors.
  warnings.warn(

2023-10-20 23:21:05,895:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 26 iterations, alpha=3.158e+01, previous alpha=2.937e+01, with an active set of 17 regressors.
  warnings.warn(

2023-10-20 23:21:05,895:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 32 iterations, alpha=1.675e+01, previous alpha=1.367e+01, with an active set of 23 regressors.
  warnings.warn(

2023-10-20 23:21:05,911:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 31 iterations, alpha=7.665e+00, previous alpha=7.128e+00, with an active set of 22 regressors.
  warnings.warn(

2023-10-20 23:21:06,041:INFO:Calculating mean and std
2023-10-20 23:21:06,041:INFO:Creating metrics dataframe
2023-10-20 23:21:06,041:INFO:Uploading results into container
2023-10-20 23:21:06,041:INFO:Uploading model into container now
2023-10-20 23:21:06,041:INFO:_master_model_container: 6
2023-10-20 23:21:06,041:INFO:_display_container: 2
2023-10-20 23:21:06,041:INFO:LassoLars(random_state=123)
2023-10-20 23:21:06,041:INFO:create_model() successfully completed......................................
2023-10-20 23:21:06,139:INFO:SubProcess create_model() end ==================================
2023-10-20 23:21:06,139:INFO:Creating metrics dataframe
2023-10-20 23:21:06,139:INFO:Initializing Orthogonal Matching Pursuit
2023-10-20 23:21:06,139:INFO:Total runtime is 0.26237805287043253 minutes
2023-10-20 23:21:06,139:INFO:SubProcess create_model() called ==================================
2023-10-20 23:21:06,139:INFO:Initializing create_model()
2023-10-20 23:21:06,139:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:21:06,139:INFO:Checking exceptions
2023-10-20 23:21:06,139:INFO:Importing libraries
2023-10-20 23:21:06,139:INFO:Copying training dataset
2023-10-20 23:21:06,171:INFO:Defining folds
2023-10-20 23:21:06,171:INFO:Declaring metric variables
2023-10-20 23:21:06,171:INFO:Importing untrained model
2023-10-20 23:21:06,171:INFO:Orthogonal Matching Pursuit Imported successfully
2023-10-20 23:21:06,171:INFO:Starting cross validation
2023-10-20 23:21:06,171:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:21:06,467:INFO:Calculating mean and std
2023-10-20 23:21:06,469:INFO:Creating metrics dataframe
2023-10-20 23:21:06,473:INFO:Uploading results into container
2023-10-20 23:21:06,473:INFO:Uploading model into container now
2023-10-20 23:21:06,473:INFO:_master_model_container: 7
2023-10-20 23:21:06,473:INFO:_display_container: 2
2023-10-20 23:21:06,473:INFO:OrthogonalMatchingPursuit()
2023-10-20 23:21:06,473:INFO:create_model() successfully completed......................................
2023-10-20 23:21:06,566:INFO:SubProcess create_model() end ==================================
2023-10-20 23:21:06,566:INFO:Creating metrics dataframe
2023-10-20 23:21:06,573:INFO:Initializing Bayesian Ridge
2023-10-20 23:21:06,573:INFO:Total runtime is 0.26961002747217816 minutes
2023-10-20 23:21:06,573:INFO:SubProcess create_model() called ==================================
2023-10-20 23:21:06,573:INFO:Initializing create_model()
2023-10-20 23:21:06,573:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:21:06,573:INFO:Checking exceptions
2023-10-20 23:21:06,573:INFO:Importing libraries
2023-10-20 23:21:06,573:INFO:Copying training dataset
2023-10-20 23:21:06,589:INFO:Defining folds
2023-10-20 23:21:06,589:INFO:Declaring metric variables
2023-10-20 23:21:06,589:INFO:Importing untrained model
2023-10-20 23:21:06,589:INFO:Bayesian Ridge Imported successfully
2023-10-20 23:21:06,589:INFO:Starting cross validation
2023-10-20 23:21:06,589:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:21:07,152:INFO:Calculating mean and std
2023-10-20 23:21:07,152:INFO:Creating metrics dataframe
2023-10-20 23:21:07,152:INFO:Uploading results into container
2023-10-20 23:21:07,152:INFO:Uploading model into container now
2023-10-20 23:21:07,152:INFO:_master_model_container: 8
2023-10-20 23:21:07,152:INFO:_display_container: 2
2023-10-20 23:21:07,152:INFO:BayesianRidge()
2023-10-20 23:21:07,152:INFO:create_model() successfully completed......................................
2023-10-20 23:21:07,250:INFO:SubProcess create_model() end ==================================
2023-10-20 23:21:07,250:INFO:Creating metrics dataframe
2023-10-20 23:21:07,265:INFO:Initializing Passive Aggressive Regressor
2023-10-20 23:21:07,265:INFO:Total runtime is 0.28113539616266886 minutes
2023-10-20 23:21:07,265:INFO:SubProcess create_model() called ==================================
2023-10-20 23:21:07,265:INFO:Initializing create_model()
2023-10-20 23:21:07,266:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:21:07,266:INFO:Checking exceptions
2023-10-20 23:21:07,266:INFO:Importing libraries
2023-10-20 23:21:07,266:INFO:Copying training dataset
2023-10-20 23:21:07,282:INFO:Defining folds
2023-10-20 23:21:07,282:INFO:Declaring metric variables
2023-10-20 23:21:07,282:INFO:Importing untrained model
2023-10-20 23:21:07,282:INFO:Passive Aggressive Regressor Imported successfully
2023-10-20 23:21:07,282:INFO:Starting cross validation
2023-10-20 23:21:07,282:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:21:07,717:INFO:Calculating mean and std
2023-10-20 23:21:07,717:INFO:Creating metrics dataframe
2023-10-20 23:21:07,717:INFO:Uploading results into container
2023-10-20 23:21:07,717:INFO:Uploading model into container now
2023-10-20 23:21:07,717:INFO:_master_model_container: 9
2023-10-20 23:21:07,717:INFO:_display_container: 2
2023-10-20 23:21:07,717:INFO:PassiveAggressiveRegressor(random_state=123)
2023-10-20 23:21:07,717:INFO:create_model() successfully completed......................................
2023-10-20 23:21:07,816:INFO:SubProcess create_model() end ==================================
2023-10-20 23:21:07,816:INFO:Creating metrics dataframe
2023-10-20 23:21:07,816:INFO:Initializing Huber Regressor
2023-10-20 23:21:07,816:INFO:Total runtime is 0.2903209328651428 minutes
2023-10-20 23:21:07,816:INFO:SubProcess create_model() called ==================================
2023-10-20 23:21:07,816:INFO:Initializing create_model()
2023-10-20 23:21:07,816:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:21:07,816:INFO:Checking exceptions
2023-10-20 23:21:07,816:INFO:Importing libraries
2023-10-20 23:21:07,816:INFO:Copying training dataset
2023-10-20 23:21:07,839:INFO:Defining folds
2023-10-20 23:21:07,839:INFO:Declaring metric variables
2023-10-20 23:21:07,839:INFO:Importing untrained model
2023-10-20 23:21:07,839:INFO:Huber Regressor Imported successfully
2023-10-20 23:21:07,839:INFO:Starting cross validation
2023-10-20 23:21:07,839:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:21:12,211:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:21:12,232:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:21:12,270:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:21:12,270:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:21:12,331:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:21:12,331:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:21:12,358:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:21:12,370:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:21:12,381:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:21:12,448:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:21:12,581:INFO:Calculating mean and std
2023-10-20 23:21:12,581:INFO:Creating metrics dataframe
2023-10-20 23:21:12,581:INFO:Uploading results into container
2023-10-20 23:21:12,581:INFO:Uploading model into container now
2023-10-20 23:21:12,581:INFO:_master_model_container: 10
2023-10-20 23:21:12,581:INFO:_display_container: 2
2023-10-20 23:21:12,581:INFO:HuberRegressor()
2023-10-20 23:21:12,581:INFO:create_model() successfully completed......................................
2023-10-20 23:21:12,681:INFO:SubProcess create_model() end ==================================
2023-10-20 23:21:12,681:INFO:Creating metrics dataframe
2023-10-20 23:21:12,681:INFO:Initializing K Neighbors Regressor
2023-10-20 23:21:12,681:INFO:Total runtime is 0.371399708588918 minutes
2023-10-20 23:21:12,681:INFO:SubProcess create_model() called ==================================
2023-10-20 23:21:12,681:INFO:Initializing create_model()
2023-10-20 23:21:12,681:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:21:12,681:INFO:Checking exceptions
2023-10-20 23:21:12,681:INFO:Importing libraries
2023-10-20 23:21:12,681:INFO:Copying training dataset
2023-10-20 23:21:12,714:INFO:Defining folds
2023-10-20 23:21:12,714:INFO:Declaring metric variables
2023-10-20 23:21:12,714:INFO:Importing untrained model
2023-10-20 23:21:12,714:INFO:K Neighbors Regressor Imported successfully
2023-10-20 23:21:12,714:INFO:Starting cross validation
2023-10-20 23:21:12,714:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:21:13,880:INFO:Calculating mean and std
2023-10-20 23:21:13,880:INFO:Creating metrics dataframe
2023-10-20 23:21:13,880:INFO:Uploading results into container
2023-10-20 23:21:13,880:INFO:Uploading model into container now
2023-10-20 23:21:13,880:INFO:_master_model_container: 11
2023-10-20 23:21:13,880:INFO:_display_container: 2
2023-10-20 23:21:13,880:INFO:KNeighborsRegressor(n_jobs=-1)
2023-10-20 23:21:13,880:INFO:create_model() successfully completed......................................
2023-10-20 23:21:13,996:INFO:SubProcess create_model() end ==================================
2023-10-20 23:21:13,996:INFO:Creating metrics dataframe
2023-10-20 23:21:13,996:INFO:Initializing Decision Tree Regressor
2023-10-20 23:21:14,012:INFO:Total runtime is 0.3933236400286356 minutes
2023-10-20 23:21:14,012:INFO:SubProcess create_model() called ==================================
2023-10-20 23:21:14,012:INFO:Initializing create_model()
2023-10-20 23:21:14,012:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:21:14,012:INFO:Checking exceptions
2023-10-20 23:21:14,012:INFO:Importing libraries
2023-10-20 23:21:14,012:INFO:Copying training dataset
2023-10-20 23:21:14,030:INFO:Defining folds
2023-10-20 23:21:14,030:INFO:Declaring metric variables
2023-10-20 23:21:14,030:INFO:Importing untrained model
2023-10-20 23:21:14,030:INFO:Decision Tree Regressor Imported successfully
2023-10-20 23:21:14,030:INFO:Starting cross validation
2023-10-20 23:21:14,030:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:21:15,273:INFO:Calculating mean and std
2023-10-20 23:21:15,273:INFO:Creating metrics dataframe
2023-10-20 23:21:15,279:INFO:Uploading results into container
2023-10-20 23:21:15,280:INFO:Uploading model into container now
2023-10-20 23:21:15,280:INFO:_master_model_container: 12
2023-10-20 23:21:15,280:INFO:_display_container: 2
2023-10-20 23:21:15,281:INFO:DecisionTreeRegressor(random_state=123)
2023-10-20 23:21:15,281:INFO:create_model() successfully completed......................................
2023-10-20 23:21:15,394:INFO:SubProcess create_model() end ==================================
2023-10-20 23:21:15,394:INFO:Creating metrics dataframe
2023-10-20 23:21:15,400:INFO:Initializing Random Forest Regressor
2023-10-20 23:21:15,400:INFO:Total runtime is 0.416713277498881 minutes
2023-10-20 23:21:15,400:INFO:SubProcess create_model() called ==================================
2023-10-20 23:21:15,400:INFO:Initializing create_model()
2023-10-20 23:21:15,400:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:21:15,400:INFO:Checking exceptions
2023-10-20 23:21:15,400:INFO:Importing libraries
2023-10-20 23:21:15,400:INFO:Copying training dataset
2023-10-20 23:21:15,412:INFO:Defining folds
2023-10-20 23:21:15,412:INFO:Declaring metric variables
2023-10-20 23:21:15,412:INFO:Importing untrained model
2023-10-20 23:21:15,412:INFO:Random Forest Regressor Imported successfully
2023-10-20 23:21:15,412:INFO:Starting cross validation
2023-10-20 23:21:15,428:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:22:07,988:INFO:Calculating mean and std
2023-10-20 23:22:07,988:INFO:Creating metrics dataframe
2023-10-20 23:22:07,988:INFO:Uploading results into container
2023-10-20 23:22:07,988:INFO:Uploading model into container now
2023-10-20 23:22:07,988:INFO:_master_model_container: 13
2023-10-20 23:22:07,988:INFO:_display_container: 2
2023-10-20 23:22:07,988:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-10-20 23:22:07,988:INFO:create_model() successfully completed......................................
2023-10-20 23:22:08,099:INFO:SubProcess create_model() end ==================================
2023-10-20 23:22:08,099:INFO:Creating metrics dataframe
2023-10-20 23:22:08,117:INFO:Initializing Extra Trees Regressor
2023-10-20 23:22:08,117:INFO:Total runtime is 1.295339612166087 minutes
2023-10-20 23:22:08,118:INFO:SubProcess create_model() called ==================================
2023-10-20 23:22:08,118:INFO:Initializing create_model()
2023-10-20 23:22:08,118:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:22:08,118:INFO:Checking exceptions
2023-10-20 23:22:08,118:INFO:Importing libraries
2023-10-20 23:22:08,118:INFO:Copying training dataset
2023-10-20 23:22:08,138:INFO:Defining folds
2023-10-20 23:22:08,138:INFO:Declaring metric variables
2023-10-20 23:22:08,138:INFO:Importing untrained model
2023-10-20 23:22:08,138:INFO:Extra Trees Regressor Imported successfully
2023-10-20 23:22:08,138:INFO:Starting cross validation
2023-10-20 23:22:08,138:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:22:24,238:INFO:Calculating mean and std
2023-10-20 23:22:24,238:INFO:Creating metrics dataframe
2023-10-20 23:22:24,238:INFO:Uploading results into container
2023-10-20 23:22:24,238:INFO:Uploading model into container now
2023-10-20 23:22:24,238:INFO:_master_model_container: 14
2023-10-20 23:22:24,238:INFO:_display_container: 2
2023-10-20 23:22:24,238:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-10-20 23:22:24,238:INFO:create_model() successfully completed......................................
2023-10-20 23:22:24,410:INFO:SubProcess create_model() end ==================================
2023-10-20 23:22:24,410:INFO:Creating metrics dataframe
2023-10-20 23:22:24,421:INFO:Initializing AdaBoost Regressor
2023-10-20 23:22:24,421:INFO:Total runtime is 1.5670756936073305 minutes
2023-10-20 23:22:24,421:INFO:SubProcess create_model() called ==================================
2023-10-20 23:22:24,421:INFO:Initializing create_model()
2023-10-20 23:22:24,421:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:22:24,421:INFO:Checking exceptions
2023-10-20 23:22:24,421:INFO:Importing libraries
2023-10-20 23:22:24,421:INFO:Copying training dataset
2023-10-20 23:22:24,438:INFO:Defining folds
2023-10-20 23:22:24,438:INFO:Declaring metric variables
2023-10-20 23:22:24,438:INFO:Importing untrained model
2023-10-20 23:22:24,438:INFO:AdaBoost Regressor Imported successfully
2023-10-20 23:22:24,438:INFO:Starting cross validation
2023-10-20 23:22:24,453:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:22:31,199:INFO:Calculating mean and std
2023-10-20 23:22:31,199:INFO:Creating metrics dataframe
2023-10-20 23:22:31,199:INFO:Uploading results into container
2023-10-20 23:22:31,199:INFO:Uploading model into container now
2023-10-20 23:22:31,199:INFO:_master_model_container: 15
2023-10-20 23:22:31,199:INFO:_display_container: 2
2023-10-20 23:22:31,199:INFO:AdaBoostRegressor(random_state=123)
2023-10-20 23:22:31,199:INFO:create_model() successfully completed......................................
2023-10-20 23:22:31,299:INFO:SubProcess create_model() end ==================================
2023-10-20 23:22:31,299:INFO:Creating metrics dataframe
2023-10-20 23:22:31,299:INFO:Initializing Gradient Boosting Regressor
2023-10-20 23:22:31,299:INFO:Total runtime is 1.6817017118136088 minutes
2023-10-20 23:22:31,299:INFO:SubProcess create_model() called ==================================
2023-10-20 23:22:31,299:INFO:Initializing create_model()
2023-10-20 23:22:31,299:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:22:31,299:INFO:Checking exceptions
2023-10-20 23:22:31,299:INFO:Importing libraries
2023-10-20 23:22:31,299:INFO:Copying training dataset
2023-10-20 23:22:31,333:INFO:Defining folds
2023-10-20 23:22:31,333:INFO:Declaring metric variables
2023-10-20 23:22:31,333:INFO:Importing untrained model
2023-10-20 23:22:31,333:INFO:Gradient Boosting Regressor Imported successfully
2023-10-20 23:22:31,333:INFO:Starting cross validation
2023-10-20 23:22:31,333:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:22:52,132:INFO:Calculating mean and std
2023-10-20 23:22:52,133:INFO:Creating metrics dataframe
2023-10-20 23:22:52,133:INFO:Uploading results into container
2023-10-20 23:22:52,133:INFO:Uploading model into container now
2023-10-20 23:22:52,133:INFO:_master_model_container: 16
2023-10-20 23:22:52,133:INFO:_display_container: 2
2023-10-20 23:22:52,133:INFO:GradientBoostingRegressor(random_state=123)
2023-10-20 23:22:52,133:INFO:create_model() successfully completed......................................
2023-10-20 23:22:52,232:INFO:SubProcess create_model() end ==================================
2023-10-20 23:22:52,232:INFO:Creating metrics dataframe
2023-10-20 23:22:52,232:INFO:Initializing Light Gradient Boosting Machine
2023-10-20 23:22:52,232:INFO:Total runtime is 2.0305909077326456 minutes
2023-10-20 23:22:52,232:INFO:SubProcess create_model() called ==================================
2023-10-20 23:22:52,232:INFO:Initializing create_model()
2023-10-20 23:22:52,232:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:22:52,232:INFO:Checking exceptions
2023-10-20 23:22:52,232:INFO:Importing libraries
2023-10-20 23:22:52,232:INFO:Copying training dataset
2023-10-20 23:22:52,253:INFO:Defining folds
2023-10-20 23:22:52,253:INFO:Declaring metric variables
2023-10-20 23:22:52,253:INFO:Importing untrained model
2023-10-20 23:22:52,253:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-20 23:22:52,253:INFO:Starting cross validation
2023-10-20 23:22:52,253:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:22:54,847:INFO:Calculating mean and std
2023-10-20 23:22:54,850:INFO:Creating metrics dataframe
2023-10-20 23:22:54,851:INFO:Uploading results into container
2023-10-20 23:22:54,851:INFO:Uploading model into container now
2023-10-20 23:22:54,851:INFO:_master_model_container: 17
2023-10-20 23:22:54,851:INFO:_display_container: 2
2023-10-20 23:22:54,851:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-20 23:22:54,851:INFO:create_model() successfully completed......................................
2023-10-20 23:22:54,953:INFO:SubProcess create_model() end ==================================
2023-10-20 23:22:54,953:INFO:Creating metrics dataframe
2023-10-20 23:22:54,962:INFO:Initializing CatBoost Regressor
2023-10-20 23:22:54,962:INFO:Total runtime is 2.076080063978831 minutes
2023-10-20 23:22:54,962:INFO:SubProcess create_model() called ==================================
2023-10-20 23:22:54,963:INFO:Initializing create_model()
2023-10-20 23:22:54,963:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:22:54,963:INFO:Checking exceptions
2023-10-20 23:22:54,963:INFO:Importing libraries
2023-10-20 23:22:54,963:INFO:Copying training dataset
2023-10-20 23:22:54,979:INFO:Defining folds
2023-10-20 23:22:54,979:INFO:Declaring metric variables
2023-10-20 23:22:54,979:INFO:Importing untrained model
2023-10-20 23:22:54,979:INFO:CatBoost Regressor Imported successfully
2023-10-20 23:22:54,979:INFO:Starting cross validation
2023-10-20 23:22:54,979:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:23:28,367:INFO:Calculating mean and std
2023-10-20 23:23:28,368:INFO:Creating metrics dataframe
2023-10-20 23:23:28,368:INFO:Uploading results into container
2023-10-20 23:23:28,368:INFO:Uploading model into container now
2023-10-20 23:23:28,368:INFO:_master_model_container: 18
2023-10-20 23:23:28,368:INFO:_display_container: 2
2023-10-20 23:23:28,368:INFO:<catboost.core.CatBoostRegressor object at 0x00000209E3906F40>
2023-10-20 23:23:28,368:INFO:create_model() successfully completed......................................
2023-10-20 23:23:28,485:INFO:SubProcess create_model() end ==================================
2023-10-20 23:23:28,485:INFO:Creating metrics dataframe
2023-10-20 23:23:28,502:INFO:Initializing Dummy Regressor
2023-10-20 23:23:28,502:INFO:Total runtime is 2.6350830396016436 minutes
2023-10-20 23:23:28,502:INFO:SubProcess create_model() called ==================================
2023-10-20 23:23:28,502:INFO:Initializing create_model()
2023-10-20 23:23:28,502:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3B5B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:23:28,502:INFO:Checking exceptions
2023-10-20 23:23:28,502:INFO:Importing libraries
2023-10-20 23:23:28,502:INFO:Copying training dataset
2023-10-20 23:23:28,519:INFO:Defining folds
2023-10-20 23:23:28,519:INFO:Declaring metric variables
2023-10-20 23:23:28,519:INFO:Importing untrained model
2023-10-20 23:23:28,534:INFO:Dummy Regressor Imported successfully
2023-10-20 23:23:28,535:INFO:Starting cross validation
2023-10-20 23:23:28,535:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:23:28,834:INFO:Calculating mean and std
2023-10-20 23:23:28,834:INFO:Creating metrics dataframe
2023-10-20 23:23:28,834:INFO:Uploading results into container
2023-10-20 23:23:28,834:INFO:Uploading model into container now
2023-10-20 23:23:28,834:INFO:_master_model_container: 19
2023-10-20 23:23:28,834:INFO:_display_container: 2
2023-10-20 23:23:28,834:INFO:DummyRegressor()
2023-10-20 23:23:28,834:INFO:create_model() successfully completed......................................
2023-10-20 23:23:28,951:INFO:SubProcess create_model() end ==================================
2023-10-20 23:23:28,951:INFO:Creating metrics dataframe
2023-10-20 23:23:28,951:INFO:Initializing create_model()
2023-10-20 23:23:28,951:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=<catboost.core.CatBoostRegressor object at 0x00000209E3906F40>, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:23:28,951:INFO:Checking exceptions
2023-10-20 23:23:28,968:INFO:Importing libraries
2023-10-20 23:23:28,968:INFO:Copying training dataset
2023-10-20 23:23:28,985:INFO:Defining folds
2023-10-20 23:23:28,985:INFO:Declaring metric variables
2023-10-20 23:23:28,985:INFO:Importing untrained model
2023-10-20 23:23:28,985:INFO:Declaring custom model
2023-10-20 23:23:28,985:INFO:CatBoost Regressor Imported successfully
2023-10-20 23:23:28,985:INFO:Cross validation set to False
2023-10-20 23:23:28,985:INFO:Fitting Model
2023-10-20 23:23:35,896:INFO:<catboost.core.CatBoostRegressor object at 0x00000209E3BDBC70>
2023-10-20 23:23:35,896:INFO:create_model() successfully completed......................................
2023-10-20 23:23:35,996:INFO:Creating Dashboard logs
2023-10-20 23:23:35,996:INFO:Model: CatBoost Regressor
2023-10-20 23:23:36,062:INFO:Logged params: {'nan_mode': 'Min', 'eval_metric': 'RMSE', 'iterations': 1000, 'sampling_frequency': 'PerTree', 'leaf_estimation_method': 'Newton', 'random_score_type': 'NormalWithModelSizeDecrease', 'grow_policy': 'SymmetricTree', 'penalties_coefficient': 1, 'boosting_type': 'Plain', 'model_shrink_mode': 'Constant', 'feature_border_type': 'GreedyLogSum', 'bayesian_matrix_reg': 0.10000000149011612, 'eval_fraction': 0, 'force_unit_auto_pair_weights': False, 'l2_leaf_reg': 3, 'random_strength': 1, 'rsm': 1, 'boost_from_average': True, 'model_size_reg': 0.5, 'pool_metainfo_options': {'tags': {}}, 'subsample': 0.800000011920929, 'use_best_model': False, 'random_seed': 123, 'depth': 6, 'posterior_sampling': False, 'border_count': 254, 'classes_count': 0, 'auto_class_weights': 'None', 'sparse_features_conflict_fraction': 0, 'leaf_estimation_backtracking': 'AnyImprovement', 'best_model_min_trees': 1, 'model_shrink_rate': 0, 'min_data_in_leaf': 1, 'loss_function': 'RMSE', 'learning_rate': 0.06757699698209763, 'score_function': 'Cosine', 'task_type': 'CPU', 'leaf_estimation_iterations': 1, 'bootstrap_type': 'MVS', 'max_leaves': 64}
2023-10-20 23:23:36,362:INFO:Initializing predict_model()
2023-10-20 23:23:36,362:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAA9C1F0>, estimator=<catboost.core.CatBoostRegressor object at 0x00000209E3BDBC70>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209E3CC7820>)
2023-10-20 23:23:36,362:INFO:Checking exceptions
2023-10-20 23:23:36,362:INFO:Preloading libraries
2023-10-20 23:23:36,595:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\_distutils_hack\__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2023-10-20 23:23:36,779:INFO:Creating Dashboard logs
2023-10-20 23:23:36,779:INFO:Model: Light Gradient Boosting Machine
2023-10-20 23:23:36,851:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-20 23:23:37,194:INFO:Creating Dashboard logs
2023-10-20 23:23:37,194:INFO:Model: Extra Trees Regressor
2023-10-20 23:23:37,244:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-20 23:23:37,582:INFO:Creating Dashboard logs
2023-10-20 23:23:37,582:INFO:Model: Random Forest Regressor
2023-10-20 23:23:37,645:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-20 23:23:37,960:INFO:Creating Dashboard logs
2023-10-20 23:23:37,960:INFO:Model: Gradient Boosting Regressor
2023-10-20 23:23:38,027:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 123, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-10-20 23:23:38,377:INFO:Creating Dashboard logs
2023-10-20 23:23:38,377:INFO:Model: Ridge Regression
2023-10-20 23:23:38,448:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 123, 'solver': 'auto', 'tol': 0.0001}
2023-10-20 23:23:38,727:INFO:Creating Dashboard logs
2023-10-20 23:23:38,727:INFO:Model: Lasso Regression
2023-10-20 23:23:38,793:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 123, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-10-20 23:23:39,084:INFO:Creating Dashboard logs
2023-10-20 23:23:39,084:INFO:Model: Elastic Net
2023-10-20 23:23:39,143:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 123, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-10-20 23:23:39,426:INFO:Creating Dashboard logs
2023-10-20 23:23:39,426:INFO:Model: Lasso Least Angle Regression
2023-10-20 23:23:39,477:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'max_iter': 500, 'normalize': 'deprecated', 'positive': False, 'precompute': 'auto', 'random_state': 123, 'verbose': False}
2023-10-20 23:23:39,776:INFO:Creating Dashboard logs
2023-10-20 23:23:39,776:INFO:Model: Linear Regression
2023-10-20 23:23:39,842:INFO:Logged params: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'positive': False}
2023-10-20 23:23:40,125:INFO:Creating Dashboard logs
2023-10-20 23:23:40,125:INFO:Model: AdaBoost Regressor
2023-10-20 23:23:40,192:INFO:Logged params: {'base_estimator': 'deprecated', 'estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': 123}
2023-10-20 23:23:40,492:INFO:Creating Dashboard logs
2023-10-20 23:23:40,492:INFO:Model: Orthogonal Matching Pursuit
2023-10-20 23:23:40,542:INFO:Logged params: {'fit_intercept': True, 'n_nonzero_coefs': None, 'normalize': 'deprecated', 'precompute': 'auto', 'tol': None}
2023-10-20 23:23:40,809:INFO:Creating Dashboard logs
2023-10-20 23:23:40,809:INFO:Model: Huber Regressor
2023-10-20 23:23:40,875:INFO:Logged params: {'alpha': 0.0001, 'epsilon': 1.35, 'fit_intercept': True, 'max_iter': 100, 'tol': 1e-05, 'warm_start': False}
2023-10-20 23:23:41,158:INFO:Creating Dashboard logs
2023-10-20 23:23:41,158:INFO:Model: Decision Tree Regressor
2023-10-20 23:23:41,226:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 123, 'splitter': 'best'}
2023-10-20 23:23:41,507:INFO:Creating Dashboard logs
2023-10-20 23:23:41,507:INFO:Model: K Neighbors Regressor
2023-10-20 23:23:41,574:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2023-10-20 23:23:41,858:INFO:Creating Dashboard logs
2023-10-20 23:23:41,858:INFO:Model: Dummy Regressor
2023-10-20 23:23:41,924:INFO:Logged params: {'constant': None, 'quantile': None, 'strategy': 'mean'}
2023-10-20 23:23:42,224:INFO:Creating Dashboard logs
2023-10-20 23:23:42,224:INFO:Model: Passive Aggressive Regressor
2023-10-20 23:23:42,274:INFO:Logged params: {'C': 1.0, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'fit_intercept': True, 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 5, 'random_state': 123, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-10-20 23:23:42,557:INFO:Creating Dashboard logs
2023-10-20 23:23:42,557:INFO:Model: Bayesian Ridge
2023-10-20 23:23:42,623:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'tol': 0.001, 'verbose': False}
2023-10-20 23:23:42,906:INFO:Creating Dashboard logs
2023-10-20 23:23:42,906:INFO:Model: Least Angle Regression
2023-10-20 23:23:42,973:INFO:Logged params: {'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'n_nonzero_coefs': 500, 'normalize': 'deprecated', 'precompute': 'auto', 'random_state': 123, 'verbose': False}
2023-10-20 23:23:43,272:INFO:_master_model_container: 19
2023-10-20 23:23:43,272:INFO:_display_container: 2
2023-10-20 23:23:43,273:INFO:<catboost.core.CatBoostRegressor object at 0x00000209E3BDBC70>
2023-10-20 23:23:43,273:INFO:compare_models() successfully completed......................................
2023-10-20 23:29:24,017:INFO:PyCaret RegressionExperiment
2023-10-20 23:29:24,019:INFO:Logging name: exp_A
2023-10-20 23:29:24,019:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-20 23:29:24,020:INFO:version 3.1.0
2023-10-20 23:29:24,020:INFO:Initializing setup()
2023-10-20 23:29:24,020:INFO:self.USI: f486
2023-10-20 23:29:24,020:INFO:self._variable_keys: {'transform_target_param', 'exp_name_log', 'y_train', 'logging_param', 'n_jobs_param', 'X_train', 'target_param', 'USI', 'gpu_n_jobs_param', 'fold_groups_param', '_ml_usecase', 'seed', 'fold_generator', 'idx', 'html_param', 'log_plots_param', 'y', 'gpu_param', 'X_test', 'memory', 'y_test', 'data', 'X', 'exp_id', '_available_plots', 'fold_shuffle_param', 'pipeline'}
2023-10-20 23:29:24,020:INFO:Checking environment
2023-10-20 23:29:24,021:INFO:python_version: 3.8.18
2023-10-20 23:29:24,021:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-20 23:29:24,021:INFO:machine: AMD64
2023-10-20 23:29:24,022:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-20 23:29:24,022:INFO:Memory: svmem(total=16505954304, available=2596114432, percent=84.3, used=13909839872, free=2596114432)
2023-10-20 23:29:24,022:INFO:Physical Core: 8
2023-10-20 23:29:24,022:INFO:Logical Core: 16
2023-10-20 23:29:24,023:INFO:Checking libraries
2023-10-20 23:29:24,023:INFO:System:
2023-10-20 23:29:24,023:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-20 23:29:24,023:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-20 23:29:24,023:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-20 23:29:24,023:INFO:PyCaret required dependencies:
2023-10-20 23:29:24,023:INFO:                 pip: 23.3
2023-10-20 23:29:24,023:INFO:          setuptools: 68.0.0
2023-10-20 23:29:24,023:INFO:             pycaret: 3.1.0
2023-10-20 23:29:24,023:INFO:             IPython: 8.12.0
2023-10-20 23:29:24,023:INFO:          ipywidgets: 8.1.1
2023-10-20 23:29:24,023:INFO:                tqdm: 4.66.1
2023-10-20 23:29:24,024:INFO:               numpy: 1.23.5
2023-10-20 23:29:24,024:INFO:              pandas: 1.5.3
2023-10-20 23:29:24,024:INFO:              jinja2: 3.1.2
2023-10-20 23:29:24,024:INFO:               scipy: 1.10.1
2023-10-20 23:29:24,024:INFO:              joblib: 1.3.2
2023-10-20 23:29:24,024:INFO:             sklearn: 1.2.2
2023-10-20 23:29:24,024:INFO:                pyod: 1.1.0
2023-10-20 23:29:24,024:INFO:            imblearn: 0.11.0
2023-10-20 23:29:24,024:INFO:   category_encoders: 2.6.2
2023-10-20 23:29:24,024:INFO:            lightgbm: 4.1.0
2023-10-20 23:29:24,024:INFO:               numba: 0.58.1
2023-10-20 23:29:24,024:INFO:            requests: 2.31.0
2023-10-20 23:29:24,024:INFO:          matplotlib: 3.7.3
2023-10-20 23:29:24,024:INFO:          scikitplot: 0.3.7
2023-10-20 23:29:24,024:INFO:         yellowbrick: 1.5
2023-10-20 23:29:24,024:INFO:              plotly: 5.17.0
2023-10-20 23:29:24,024:INFO:    plotly-resampler: Not installed
2023-10-20 23:29:24,025:INFO:             kaleido: 0.2.1
2023-10-20 23:29:24,025:INFO:           schemdraw: 0.15
2023-10-20 23:29:24,025:INFO:         statsmodels: 0.14.0
2023-10-20 23:29:24,025:INFO:              sktime: 0.21.1
2023-10-20 23:29:24,025:INFO:               tbats: 1.1.3
2023-10-20 23:29:24,025:INFO:            pmdarima: 2.0.3
2023-10-20 23:29:24,025:INFO:              psutil: 5.9.0
2023-10-20 23:29:24,025:INFO:          markupsafe: 2.1.3
2023-10-20 23:29:24,025:INFO:             pickle5: Not installed
2023-10-20 23:29:24,025:INFO:         cloudpickle: 2.2.1
2023-10-20 23:29:24,025:INFO:         deprecation: 2.1.0
2023-10-20 23:29:24,025:INFO:              xxhash: 3.4.1
2023-10-20 23:29:24,025:INFO:           wurlitzer: Not installed
2023-10-20 23:29:24,025:INFO:PyCaret optional dependencies:
2023-10-20 23:29:24,025:INFO:                shap: Not installed
2023-10-20 23:29:24,026:INFO:           interpret: Not installed
2023-10-20 23:29:24,026:INFO:                umap: Not installed
2023-10-20 23:29:24,026:INFO:     ydata_profiling: Not installed
2023-10-20 23:29:24,026:INFO:  explainerdashboard: Not installed
2023-10-20 23:29:24,026:INFO:             autoviz: Not installed
2023-10-20 23:29:24,026:INFO:           fairlearn: Not installed
2023-10-20 23:29:24,026:INFO:          deepchecks: Not installed
2023-10-20 23:29:24,026:INFO:             xgboost: Not installed
2023-10-20 23:29:24,026:INFO:            catboost: 1.2.2
2023-10-20 23:29:24,026:INFO:              kmodes: Not installed
2023-10-20 23:29:24,026:INFO:             mlxtend: Not installed
2023-10-20 23:29:24,026:INFO:       statsforecast: Not installed
2023-10-20 23:29:24,026:INFO:        tune_sklearn: Not installed
2023-10-20 23:29:24,026:INFO:                 ray: Not installed
2023-10-20 23:29:24,026:INFO:            hyperopt: Not installed
2023-10-20 23:29:24,026:INFO:              optuna: Not installed
2023-10-20 23:29:24,027:INFO:               skopt: Not installed
2023-10-20 23:29:24,027:INFO:              mlflow: 2.7.1
2023-10-20 23:29:24,027:INFO:              gradio: Not installed
2023-10-20 23:29:24,027:INFO:             fastapi: Not installed
2023-10-20 23:29:24,027:INFO:             uvicorn: Not installed
2023-10-20 23:29:24,027:INFO:              m2cgen: Not installed
2023-10-20 23:29:24,027:INFO:           evidently: Not installed
2023-10-20 23:29:24,027:INFO:               fugue: Not installed
2023-10-20 23:29:24,027:INFO:           streamlit: Not installed
2023-10-20 23:29:24,027:INFO:             prophet: Not installed
2023-10-20 23:29:24,027:INFO:None
2023-10-20 23:29:24,027:INFO:Set up data.
2023-10-20 23:29:24,057:INFO:Set up folding strategy.
2023-10-20 23:29:24,057:INFO:Set up train/test split.
2023-10-20 23:29:24,081:INFO:Set up index.
2023-10-20 23:29:24,082:INFO:Assigning column types.
2023-10-20 23:29:24,100:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-20 23:29:24,100:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,107:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,107:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,190:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,241:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,242:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:29:24,242:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:29:24,243:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,248:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,253:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,325:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,383:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,385:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:29:24,385:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:29:24,385:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-20 23:29:24,391:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,396:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,475:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,529:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,529:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:29:24,529:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:29:24,535:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,541:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,626:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,676:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,677:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:29:24,677:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:29:24,678:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-20 23:29:24,680:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,772:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,824:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,824:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:29:24,824:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:29:24,824:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,919:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,962:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:29:24,962:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:29:24,962:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:29:24,962:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-20 23:29:25,079:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:29:25,126:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:29:25,126:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:29:25,126:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:29:25,213:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:29:25,257:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-20 23:29:25,257:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:29:25,257:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:29:25,257:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-20 23:29:25,341:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:29:25,400:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:29:25,400:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:29:25,474:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-20 23:29:25,527:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:29:25,527:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:29:25,527:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-20 23:29:25,656:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:29:25,656:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:29:25,806:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:29:25,806:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:29:25,806:INFO:Preparing preprocessing pipeline...
2023-10-20 23:29:25,806:INFO:Set up simple imputation.
2023-10-20 23:29:25,806:INFO:Set up column name cleaning.
2023-10-20 23:29:25,859:INFO:Finished creating preprocessing pipeline.
2023-10-20 23:29:25,875:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-20 23:29:25,875:INFO:Creating final display dataframe.
2023-10-20 23:29:26,062:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (34061, 39)
4        Transformed data shape   (34061, 39)
5   Transformed train set shape   (23842, 39)
6    Transformed test set shape   (10219, 39)
7              Numeric features            38
8      Rows with missing values         23.1%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_A
19                          USI          f486
2023-10-20 23:29:26,191:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:29:26,191:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:29:26,340:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-20 23:29:26,340:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-20 23:29:26,341:INFO:Logging experiment in loggers
2023-10-20 23:29:26,442:INFO:SubProcess save_model() called ==================================
2023-10-20 23:29:26,445:INFO:Initializing save_model()
2023-10-20 23:29:26,445:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmplzngiykf\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-20 23:29:26,445:INFO:Adding model into prep_pipe
2023-10-20 23:29:26,445:WARNING:Only Model saved as it was a pipeline.
2023-10-20 23:29:26,445:INFO:C:\Users\thoma\AppData\Local\Temp\tmplzngiykf\Transformation Pipeline.pkl saved in current working directory
2023-10-20 23:29:26,460:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-20 23:29:26,460:INFO:save_model() successfully completed......................................
2023-10-20 23:29:26,572:INFO:SubProcess save_model() end ==================================
2023-10-20 23:29:26,612:INFO:setup() successfully completed in 2.33s...............
2023-10-20 23:29:26,612:INFO:Initializing compare_models()
2023-10-20 23:29:26,612:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, 'include': None, 'exclude': ['ransac'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=['ransac'])
2023-10-20 23:29:26,612:INFO:Checking exceptions
2023-10-20 23:29:26,630:INFO:Preparing display monitor
2023-10-20 23:29:26,634:INFO:Initializing Linear Regression
2023-10-20 23:29:26,634:INFO:Total runtime is 0.0 minutes
2023-10-20 23:29:26,635:INFO:SubProcess create_model() called ==================================
2023-10-20 23:29:26,635:INFO:Initializing create_model()
2023-10-20 23:29:26,635:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:29:26,635:INFO:Checking exceptions
2023-10-20 23:29:26,635:INFO:Importing libraries
2023-10-20 23:29:26,635:INFO:Copying training dataset
2023-10-20 23:29:26,657:INFO:Defining folds
2023-10-20 23:29:26,657:INFO:Declaring metric variables
2023-10-20 23:29:26,657:INFO:Importing untrained model
2023-10-20 23:29:26,658:INFO:Linear Regression Imported successfully
2023-10-20 23:29:26,658:INFO:Starting cross validation
2023-10-20 23:29:26,659:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:29:28,951:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\joblib\externals\loky\process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(

2023-10-20 23:29:31,883:INFO:Calculating mean and std
2023-10-20 23:29:31,883:INFO:Creating metrics dataframe
2023-10-20 23:29:31,883:INFO:Uploading results into container
2023-10-20 23:29:31,883:INFO:Uploading model into container now
2023-10-20 23:29:31,883:INFO:_master_model_container: 1
2023-10-20 23:29:31,883:INFO:_display_container: 2
2023-10-20 23:29:31,883:INFO:LinearRegression(n_jobs=-1)
2023-10-20 23:29:31,883:INFO:create_model() successfully completed......................................
2023-10-20 23:29:31,985:INFO:SubProcess create_model() end ==================================
2023-10-20 23:29:31,985:INFO:Creating metrics dataframe
2023-10-20 23:29:31,985:INFO:Initializing Lasso Regression
2023-10-20 23:29:31,985:INFO:Total runtime is 0.08918093045552572 minutes
2023-10-20 23:29:32,000:INFO:SubProcess create_model() called ==================================
2023-10-20 23:29:32,000:INFO:Initializing create_model()
2023-10-20 23:29:32,000:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:29:32,000:INFO:Checking exceptions
2023-10-20 23:29:32,000:INFO:Importing libraries
2023-10-20 23:29:32,000:INFO:Copying training dataset
2023-10-20 23:29:32,022:INFO:Defining folds
2023-10-20 23:29:32,022:INFO:Declaring metric variables
2023-10-20 23:29:32,022:INFO:Importing untrained model
2023-10-20 23:29:32,022:INFO:Lasso Regression Imported successfully
2023-10-20 23:29:32,022:INFO:Starting cross validation
2023-10-20 23:29:32,022:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:29:32,688:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.427e+09, tolerance: 2.896e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:37,881:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.463e+09, tolerance: 2.927e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:37,894:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.464e+09, tolerance: 2.904e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:37,997:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.457e+09, tolerance: 2.881e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:38,014:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.460e+09, tolerance: 2.900e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:38,014:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.450e+09, tolerance: 2.898e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:38,030:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.448e+09, tolerance: 2.871e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:38,030:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.410e+09, tolerance: 2.856e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:38,046:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.470e+09, tolerance: 2.933e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:38,046:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.456e+09, tolerance: 2.898e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:38,180:INFO:Calculating mean and std
2023-10-20 23:29:38,181:INFO:Creating metrics dataframe
2023-10-20 23:29:38,183:INFO:Uploading results into container
2023-10-20 23:29:38,183:INFO:Uploading model into container now
2023-10-20 23:29:38,183:INFO:_master_model_container: 2
2023-10-20 23:29:38,183:INFO:_display_container: 2
2023-10-20 23:29:38,183:INFO:Lasso(random_state=123)
2023-10-20 23:29:38,183:INFO:create_model() successfully completed......................................
2023-10-20 23:29:38,284:INFO:SubProcess create_model() end ==================================
2023-10-20 23:29:38,284:INFO:Creating metrics dataframe
2023-10-20 23:29:38,296:INFO:Initializing Ridge Regression
2023-10-20 23:29:38,296:INFO:Total runtime is 0.19436156749725342 minutes
2023-10-20 23:29:38,296:INFO:SubProcess create_model() called ==================================
2023-10-20 23:29:38,297:INFO:Initializing create_model()
2023-10-20 23:29:38,297:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:29:38,297:INFO:Checking exceptions
2023-10-20 23:29:38,297:INFO:Importing libraries
2023-10-20 23:29:38,297:INFO:Copying training dataset
2023-10-20 23:29:38,315:INFO:Defining folds
2023-10-20 23:29:38,315:INFO:Declaring metric variables
2023-10-20 23:29:38,315:INFO:Importing untrained model
2023-10-20 23:29:38,315:INFO:Ridge Regression Imported successfully
2023-10-20 23:29:38,315:INFO:Starting cross validation
2023-10-20 23:29:38,315:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:29:38,454:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.06625e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:29:38,470:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.06293e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:29:38,470:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.1254e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:29:38,470:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.05971e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:29:41,802:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.06296e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:29:41,821:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.07861e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:29:41,826:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.09042e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:29:41,827:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.05293e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:29:41,831:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.07372e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:29:41,834:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.08204e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-10-20 23:29:41,977:INFO:Calculating mean and std
2023-10-20 23:29:41,977:INFO:Creating metrics dataframe
2023-10-20 23:29:41,977:INFO:Uploading results into container
2023-10-20 23:29:41,977:INFO:Uploading model into container now
2023-10-20 23:29:41,977:INFO:_master_model_container: 3
2023-10-20 23:29:41,977:INFO:_display_container: 2
2023-10-20 23:29:41,977:INFO:Ridge(random_state=123)
2023-10-20 23:29:41,977:INFO:create_model() successfully completed......................................
2023-10-20 23:29:42,093:INFO:SubProcess create_model() end ==================================
2023-10-20 23:29:42,093:INFO:Creating metrics dataframe
2023-10-20 23:29:42,096:INFO:Initializing Elastic Net
2023-10-20 23:29:42,096:INFO:Total runtime is 0.257698396841685 minutes
2023-10-20 23:29:42,096:INFO:SubProcess create_model() called ==================================
2023-10-20 23:29:42,096:INFO:Initializing create_model()
2023-10-20 23:29:42,096:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:29:42,096:INFO:Checking exceptions
2023-10-20 23:29:42,096:INFO:Importing libraries
2023-10-20 23:29:42,096:INFO:Copying training dataset
2023-10-20 23:29:42,117:INFO:Defining folds
2023-10-20 23:29:42,117:INFO:Declaring metric variables
2023-10-20 23:29:42,117:INFO:Importing untrained model
2023-10-20 23:29:42,117:INFO:Elastic Net Imported successfully
2023-10-20 23:29:42,117:INFO:Starting cross validation
2023-10-20 23:29:42,117:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:29:43,444:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.468e+09, tolerance: 2.871e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:43,544:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.484e+09, tolerance: 2.904e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:43,560:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.448e+09, tolerance: 2.896e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:43,560:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.477e+09, tolerance: 2.881e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:43,585:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.470e+09, tolerance: 2.898e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:43,593:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.482e+09, tolerance: 2.927e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:43,593:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.476e+09, tolerance: 2.898e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:43,593:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.481e+09, tolerance: 2.900e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:43,613:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.490e+09, tolerance: 2.933e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:43,631:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.431e+09, tolerance: 2.856e+06
  model = cd_fast.enet_coordinate_descent(

2023-10-20 23:29:43,758:INFO:Calculating mean and std
2023-10-20 23:29:43,758:INFO:Creating metrics dataframe
2023-10-20 23:29:43,758:INFO:Uploading results into container
2023-10-20 23:29:43,758:INFO:Uploading model into container now
2023-10-20 23:29:43,758:INFO:_master_model_container: 4
2023-10-20 23:29:43,758:INFO:_display_container: 2
2023-10-20 23:29:43,758:INFO:ElasticNet(random_state=123)
2023-10-20 23:29:43,758:INFO:create_model() successfully completed......................................
2023-10-20 23:29:43,858:INFO:SubProcess create_model() end ==================================
2023-10-20 23:29:43,858:INFO:Creating metrics dataframe
2023-10-20 23:29:43,875:INFO:Initializing Least Angle Regression
2023-10-20 23:29:43,875:INFO:Total runtime is 0.2873404979705811 minutes
2023-10-20 23:29:43,875:INFO:SubProcess create_model() called ==================================
2023-10-20 23:29:43,875:INFO:Initializing create_model()
2023-10-20 23:29:43,875:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:29:43,875:INFO:Checking exceptions
2023-10-20 23:29:43,875:INFO:Importing libraries
2023-10-20 23:29:43,875:INFO:Copying training dataset
2023-10-20 23:29:43,891:INFO:Defining folds
2023-10-20 23:29:43,891:INFO:Declaring metric variables
2023-10-20 23:29:43,891:INFO:Importing untrained model
2023-10-20 23:29:43,891:INFO:Least Angle Regression Imported successfully
2023-10-20 23:29:43,891:INFO:Starting cross validation
2023-10-20 23:29:43,891:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:29:44,227:INFO:Calculating mean and std
2023-10-20 23:29:44,227:INFO:Creating metrics dataframe
2023-10-20 23:29:44,227:INFO:Uploading results into container
2023-10-20 23:29:44,227:INFO:Uploading model into container now
2023-10-20 23:29:44,227:INFO:_master_model_container: 5
2023-10-20 23:29:44,227:INFO:_display_container: 2
2023-10-20 23:29:44,227:INFO:Lars(random_state=123)
2023-10-20 23:29:44,227:INFO:create_model() successfully completed......................................
2023-10-20 23:29:44,341:INFO:SubProcess create_model() end ==================================
2023-10-20 23:29:44,341:INFO:Creating metrics dataframe
2023-10-20 23:29:44,341:INFO:Initializing Lasso Least Angle Regression
2023-10-20 23:29:44,341:INFO:Total runtime is 0.2951181729634603 minutes
2023-10-20 23:29:44,341:INFO:SubProcess create_model() called ==================================
2023-10-20 23:29:44,341:INFO:Initializing create_model()
2023-10-20 23:29:44,341:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:29:44,341:INFO:Checking exceptions
2023-10-20 23:29:44,341:INFO:Importing libraries
2023-10-20 23:29:44,341:INFO:Copying training dataset
2023-10-20 23:29:44,358:INFO:Defining folds
2023-10-20 23:29:44,358:INFO:Declaring metric variables
2023-10-20 23:29:44,358:INFO:Importing untrained model
2023-10-20 23:29:44,358:INFO:Lasso Least Angle Regression Imported successfully
2023-10-20 23:29:44,358:INFO:Starting cross validation
2023-10-20 23:29:44,374:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:29:44,491:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=1.588e+02, previous alpha=1.437e+02, with an active set of 14 regressors.
  warnings.warn(

2023-10-20 23:29:44,491:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 26 iterations, alpha=3.480e+01, previous alpha=3.271e+01, with an active set of 17 regressors.
  warnings.warn(

2023-10-20 23:29:44,507:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 35 iterations, alpha=8.305e+00, previous alpha=6.087e+00, with an active set of 26 regressors.
  warnings.warn(

2023-10-20 23:29:44,508:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 26 iterations, alpha=3.393e+01, previous alpha=3.161e+01, with an active set of 17 regressors.
  warnings.warn(

2023-10-20 23:29:44,508:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 29 iterations, alpha=1.570e+01, previous alpha=1.483e+01, with an active set of 20 regressors.
  warnings.warn(

2023-10-20 23:29:44,525:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 31 iterations, alpha=2.233e+01, previous alpha=2.086e+01, with an active set of 18 regressors.
  warnings.warn(

2023-10-20 23:29:44,541:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 26 iterations, alpha=3.158e+01, previous alpha=2.937e+01, with an active set of 17 regressors.
  warnings.warn(

2023-10-20 23:29:44,547:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 32 iterations, alpha=1.675e+01, previous alpha=1.367e+01, with an active set of 23 regressors.
  warnings.warn(

2023-10-20 23:29:44,557:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 31 iterations, alpha=7.665e+00, previous alpha=7.128e+00, with an active set of 22 regressors.
  warnings.warn(

2023-10-20 23:29:44,690:INFO:Calculating mean and std
2023-10-20 23:29:44,690:INFO:Creating metrics dataframe
2023-10-20 23:29:44,690:INFO:Uploading results into container
2023-10-20 23:29:44,690:INFO:Uploading model into container now
2023-10-20 23:29:44,690:INFO:_master_model_container: 6
2023-10-20 23:29:44,690:INFO:_display_container: 2
2023-10-20 23:29:44,690:INFO:LassoLars(random_state=123)
2023-10-20 23:29:44,690:INFO:create_model() successfully completed......................................
2023-10-20 23:29:44,807:INFO:SubProcess create_model() end ==================================
2023-10-20 23:29:44,807:INFO:Creating metrics dataframe
2023-10-20 23:29:44,807:INFO:Initializing Orthogonal Matching Pursuit
2023-10-20 23:29:44,807:INFO:Total runtime is 0.3028773665428162 minutes
2023-10-20 23:29:44,807:INFO:SubProcess create_model() called ==================================
2023-10-20 23:29:44,807:INFO:Initializing create_model()
2023-10-20 23:29:44,807:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:29:44,807:INFO:Checking exceptions
2023-10-20 23:29:44,807:INFO:Importing libraries
2023-10-20 23:29:44,807:INFO:Copying training dataset
2023-10-20 23:29:44,824:INFO:Defining folds
2023-10-20 23:29:44,824:INFO:Declaring metric variables
2023-10-20 23:29:44,824:INFO:Importing untrained model
2023-10-20 23:29:44,824:INFO:Orthogonal Matching Pursuit Imported successfully
2023-10-20 23:29:44,839:INFO:Starting cross validation
2023-10-20 23:29:44,840:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:29:45,157:INFO:Calculating mean and std
2023-10-20 23:29:45,157:INFO:Creating metrics dataframe
2023-10-20 23:29:45,157:INFO:Uploading results into container
2023-10-20 23:29:45,157:INFO:Uploading model into container now
2023-10-20 23:29:45,157:INFO:_master_model_container: 7
2023-10-20 23:29:45,157:INFO:_display_container: 2
2023-10-20 23:29:45,157:INFO:OrthogonalMatchingPursuit()
2023-10-20 23:29:45,157:INFO:create_model() successfully completed......................................
2023-10-20 23:29:45,258:INFO:SubProcess create_model() end ==================================
2023-10-20 23:29:45,258:INFO:Creating metrics dataframe
2023-10-20 23:29:45,258:INFO:Initializing Bayesian Ridge
2023-10-20 23:29:45,258:INFO:Total runtime is 0.3103906472524008 minutes
2023-10-20 23:29:45,258:INFO:SubProcess create_model() called ==================================
2023-10-20 23:29:45,258:INFO:Initializing create_model()
2023-10-20 23:29:45,258:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:29:45,258:INFO:Checking exceptions
2023-10-20 23:29:45,258:INFO:Importing libraries
2023-10-20 23:29:45,258:INFO:Copying training dataset
2023-10-20 23:29:45,288:INFO:Defining folds
2023-10-20 23:29:45,288:INFO:Declaring metric variables
2023-10-20 23:29:45,288:INFO:Importing untrained model
2023-10-20 23:29:45,290:INFO:Bayesian Ridge Imported successfully
2023-10-20 23:29:45,290:INFO:Starting cross validation
2023-10-20 23:29:45,290:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:29:45,840:INFO:Calculating mean and std
2023-10-20 23:29:45,840:INFO:Creating metrics dataframe
2023-10-20 23:29:45,840:INFO:Uploading results into container
2023-10-20 23:29:45,840:INFO:Uploading model into container now
2023-10-20 23:29:45,840:INFO:_master_model_container: 8
2023-10-20 23:29:45,840:INFO:_display_container: 2
2023-10-20 23:29:45,840:INFO:BayesianRidge()
2023-10-20 23:29:45,840:INFO:create_model() successfully completed......................................
2023-10-20 23:29:45,943:INFO:SubProcess create_model() end ==================================
2023-10-20 23:29:45,943:INFO:Creating metrics dataframe
2023-10-20 23:29:45,943:INFO:Initializing Passive Aggressive Regressor
2023-10-20 23:29:45,943:INFO:Total runtime is 0.32181796630223597 minutes
2023-10-20 23:29:45,943:INFO:SubProcess create_model() called ==================================
2023-10-20 23:29:45,943:INFO:Initializing create_model()
2023-10-20 23:29:45,943:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:29:45,943:INFO:Checking exceptions
2023-10-20 23:29:45,943:INFO:Importing libraries
2023-10-20 23:29:45,943:INFO:Copying training dataset
2023-10-20 23:29:45,974:INFO:Defining folds
2023-10-20 23:29:45,974:INFO:Declaring metric variables
2023-10-20 23:29:45,974:INFO:Importing untrained model
2023-10-20 23:29:45,974:INFO:Passive Aggressive Regressor Imported successfully
2023-10-20 23:29:45,974:INFO:Starting cross validation
2023-10-20 23:29:45,974:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:29:46,406:INFO:Calculating mean and std
2023-10-20 23:29:46,407:INFO:Creating metrics dataframe
2023-10-20 23:29:46,407:INFO:Uploading results into container
2023-10-20 23:29:46,407:INFO:Uploading model into container now
2023-10-20 23:29:46,407:INFO:_master_model_container: 9
2023-10-20 23:29:46,407:INFO:_display_container: 2
2023-10-20 23:29:46,407:INFO:PassiveAggressiveRegressor(random_state=123)
2023-10-20 23:29:46,407:INFO:create_model() successfully completed......................................
2023-10-20 23:29:46,517:INFO:SubProcess create_model() end ==================================
2023-10-20 23:29:46,517:INFO:Creating metrics dataframe
2023-10-20 23:29:46,523:INFO:Initializing Huber Regressor
2023-10-20 23:29:46,523:INFO:Total runtime is 0.33148535887400316 minutes
2023-10-20 23:29:46,523:INFO:SubProcess create_model() called ==================================
2023-10-20 23:29:46,523:INFO:Initializing create_model()
2023-10-20 23:29:46,523:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:29:46,523:INFO:Checking exceptions
2023-10-20 23:29:46,523:INFO:Importing libraries
2023-10-20 23:29:46,524:INFO:Copying training dataset
2023-10-20 23:29:46,539:INFO:Defining folds
2023-10-20 23:29:46,539:INFO:Declaring metric variables
2023-10-20 23:29:46,539:INFO:Importing untrained model
2023-10-20 23:29:46,539:INFO:Huber Regressor Imported successfully
2023-10-20 23:29:46,539:INFO:Starting cross validation
2023-10-20 23:29:46,539:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:29:50,652:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:29:50,706:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:29:50,706:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:29:50,729:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:29:50,736:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:29:50,754:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:29:50,803:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:29:50,819:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:29:50,836:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:29:50,929:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-20 23:29:51,053:INFO:Calculating mean and std
2023-10-20 23:29:51,053:INFO:Creating metrics dataframe
2023-10-20 23:29:51,053:INFO:Uploading results into container
2023-10-20 23:29:51,053:INFO:Uploading model into container now
2023-10-20 23:29:51,053:INFO:_master_model_container: 10
2023-10-20 23:29:51,053:INFO:_display_container: 2
2023-10-20 23:29:51,053:INFO:HuberRegressor()
2023-10-20 23:29:51,053:INFO:create_model() successfully completed......................................
2023-10-20 23:29:51,168:INFO:SubProcess create_model() end ==================================
2023-10-20 23:29:51,168:INFO:Creating metrics dataframe
2023-10-20 23:29:51,168:INFO:Initializing K Neighbors Regressor
2023-10-20 23:29:51,168:INFO:Total runtime is 0.4089048584302267 minutes
2023-10-20 23:29:51,168:INFO:SubProcess create_model() called ==================================
2023-10-20 23:29:51,168:INFO:Initializing create_model()
2023-10-20 23:29:51,168:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:29:51,168:INFO:Checking exceptions
2023-10-20 23:29:51,168:INFO:Importing libraries
2023-10-20 23:29:51,168:INFO:Copying training dataset
2023-10-20 23:29:51,186:INFO:Defining folds
2023-10-20 23:29:51,186:INFO:Declaring metric variables
2023-10-20 23:29:51,186:INFO:Importing untrained model
2023-10-20 23:29:51,186:INFO:K Neighbors Regressor Imported successfully
2023-10-20 23:29:51,186:INFO:Starting cross validation
2023-10-20 23:29:51,186:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:29:52,272:INFO:Calculating mean and std
2023-10-20 23:29:52,272:INFO:Creating metrics dataframe
2023-10-20 23:29:52,272:INFO:Uploading results into container
2023-10-20 23:29:52,272:INFO:Uploading model into container now
2023-10-20 23:29:52,283:INFO:_master_model_container: 11
2023-10-20 23:29:52,284:INFO:_display_container: 2
2023-10-20 23:29:52,284:INFO:KNeighborsRegressor(n_jobs=-1)
2023-10-20 23:29:52,284:INFO:create_model() successfully completed......................................
2023-10-20 23:29:52,400:INFO:SubProcess create_model() end ==================================
2023-10-20 23:29:52,400:INFO:Creating metrics dataframe
2023-10-20 23:29:52,417:INFO:Initializing Decision Tree Regressor
2023-10-20 23:29:52,417:INFO:Total runtime is 0.4297126571337383 minutes
2023-10-20 23:29:52,417:INFO:SubProcess create_model() called ==================================
2023-10-20 23:29:52,417:INFO:Initializing create_model()
2023-10-20 23:29:52,417:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:29:52,417:INFO:Checking exceptions
2023-10-20 23:29:52,417:INFO:Importing libraries
2023-10-20 23:29:52,417:INFO:Copying training dataset
2023-10-20 23:29:52,437:INFO:Defining folds
2023-10-20 23:29:52,437:INFO:Declaring metric variables
2023-10-20 23:29:52,437:INFO:Importing untrained model
2023-10-20 23:29:52,437:INFO:Decision Tree Regressor Imported successfully
2023-10-20 23:29:52,437:INFO:Starting cross validation
2023-10-20 23:29:52,437:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:29:53,583:INFO:Calculating mean and std
2023-10-20 23:29:53,583:INFO:Creating metrics dataframe
2023-10-20 23:29:53,583:INFO:Uploading results into container
2023-10-20 23:29:53,583:INFO:Uploading model into container now
2023-10-20 23:29:53,583:INFO:_master_model_container: 12
2023-10-20 23:29:53,583:INFO:_display_container: 2
2023-10-20 23:29:53,583:INFO:DecisionTreeRegressor(random_state=123)
2023-10-20 23:29:53,583:INFO:create_model() successfully completed......................................
2023-10-20 23:29:53,700:INFO:SubProcess create_model() end ==================================
2023-10-20 23:29:53,700:INFO:Creating metrics dataframe
2023-10-20 23:29:53,700:INFO:Initializing Random Forest Regressor
2023-10-20 23:29:53,700:INFO:Total runtime is 0.45109365781148286 minutes
2023-10-20 23:29:53,700:INFO:SubProcess create_model() called ==================================
2023-10-20 23:29:53,700:INFO:Initializing create_model()
2023-10-20 23:29:53,700:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:29:53,700:INFO:Checking exceptions
2023-10-20 23:29:53,700:INFO:Importing libraries
2023-10-20 23:29:53,700:INFO:Copying training dataset
2023-10-20 23:29:53,716:INFO:Defining folds
2023-10-20 23:29:53,716:INFO:Declaring metric variables
2023-10-20 23:29:53,716:INFO:Importing untrained model
2023-10-20 23:29:53,731:INFO:Random Forest Regressor Imported successfully
2023-10-20 23:29:53,732:INFO:Starting cross validation
2023-10-20 23:29:53,733:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:30:46,477:INFO:Calculating mean and std
2023-10-20 23:30:46,477:INFO:Creating metrics dataframe
2023-10-20 23:30:46,477:INFO:Uploading results into container
2023-10-20 23:30:46,477:INFO:Uploading model into container now
2023-10-20 23:30:46,477:INFO:_master_model_container: 13
2023-10-20 23:30:46,477:INFO:_display_container: 2
2023-10-20 23:30:46,477:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-10-20 23:30:46,477:INFO:create_model() successfully completed......................................
2023-10-20 23:30:46,606:INFO:SubProcess create_model() end ==================================
2023-10-20 23:30:46,606:INFO:Creating metrics dataframe
2023-10-20 23:30:46,621:INFO:Initializing Extra Trees Regressor
2023-10-20 23:30:46,621:INFO:Total runtime is 1.333108727137248 minutes
2023-10-20 23:30:46,621:INFO:SubProcess create_model() called ==================================
2023-10-20 23:30:46,621:INFO:Initializing create_model()
2023-10-20 23:30:46,621:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:30:46,621:INFO:Checking exceptions
2023-10-20 23:30:46,621:INFO:Importing libraries
2023-10-20 23:30:46,621:INFO:Copying training dataset
2023-10-20 23:30:46,639:INFO:Defining folds
2023-10-20 23:30:46,639:INFO:Declaring metric variables
2023-10-20 23:30:46,639:INFO:Importing untrained model
2023-10-20 23:30:46,639:INFO:Extra Trees Regressor Imported successfully
2023-10-20 23:30:46,639:INFO:Starting cross validation
2023-10-20 23:30:46,639:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:31:02,598:INFO:Calculating mean and std
2023-10-20 23:31:02,598:INFO:Creating metrics dataframe
2023-10-20 23:31:02,613:INFO:Uploading results into container
2023-10-20 23:31:02,613:INFO:Uploading model into container now
2023-10-20 23:31:02,613:INFO:_master_model_container: 14
2023-10-20 23:31:02,613:INFO:_display_container: 2
2023-10-20 23:31:02,618:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-10-20 23:31:02,619:INFO:create_model() successfully completed......................................
2023-10-20 23:31:02,852:INFO:SubProcess create_model() end ==================================
2023-10-20 23:31:02,852:INFO:Creating metrics dataframe
2023-10-20 23:31:02,868:INFO:Initializing AdaBoost Regressor
2023-10-20 23:31:02,868:INFO:Total runtime is 1.603890113035838 minutes
2023-10-20 23:31:02,868:INFO:SubProcess create_model() called ==================================
2023-10-20 23:31:02,868:INFO:Initializing create_model()
2023-10-20 23:31:02,868:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:31:02,868:INFO:Checking exceptions
2023-10-20 23:31:02,868:INFO:Importing libraries
2023-10-20 23:31:02,868:INFO:Copying training dataset
2023-10-20 23:31:02,914:INFO:Defining folds
2023-10-20 23:31:02,914:INFO:Declaring metric variables
2023-10-20 23:31:02,914:INFO:Importing untrained model
2023-10-20 23:31:02,914:INFO:AdaBoost Regressor Imported successfully
2023-10-20 23:31:02,914:INFO:Starting cross validation
2023-10-20 23:31:02,930:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:31:10,552:INFO:Calculating mean and std
2023-10-20 23:31:10,553:INFO:Creating metrics dataframe
2023-10-20 23:31:10,553:INFO:Uploading results into container
2023-10-20 23:31:10,553:INFO:Uploading model into container now
2023-10-20 23:31:10,553:INFO:_master_model_container: 15
2023-10-20 23:31:10,553:INFO:_display_container: 2
2023-10-20 23:31:10,553:INFO:AdaBoostRegressor(random_state=123)
2023-10-20 23:31:10,553:INFO:create_model() successfully completed......................................
2023-10-20 23:31:10,653:INFO:SubProcess create_model() end ==================================
2023-10-20 23:31:10,653:INFO:Creating metrics dataframe
2023-10-20 23:31:10,669:INFO:Initializing Gradient Boosting Regressor
2023-10-20 23:31:10,669:INFO:Total runtime is 1.7339226762453717 minutes
2023-10-20 23:31:10,669:INFO:SubProcess create_model() called ==================================
2023-10-20 23:31:10,669:INFO:Initializing create_model()
2023-10-20 23:31:10,669:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:31:10,669:INFO:Checking exceptions
2023-10-20 23:31:10,669:INFO:Importing libraries
2023-10-20 23:31:10,669:INFO:Copying training dataset
2023-10-20 23:31:10,691:INFO:Defining folds
2023-10-20 23:31:10,691:INFO:Declaring metric variables
2023-10-20 23:31:10,691:INFO:Importing untrained model
2023-10-20 23:31:10,691:INFO:Gradient Boosting Regressor Imported successfully
2023-10-20 23:31:10,691:INFO:Starting cross validation
2023-10-20 23:31:10,691:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:31:31,253:INFO:Calculating mean and std
2023-10-20 23:31:31,253:INFO:Creating metrics dataframe
2023-10-20 23:31:31,253:INFO:Uploading results into container
2023-10-20 23:31:31,253:INFO:Uploading model into container now
2023-10-20 23:31:31,253:INFO:_master_model_container: 16
2023-10-20 23:31:31,253:INFO:_display_container: 2
2023-10-20 23:31:31,253:INFO:GradientBoostingRegressor(random_state=123)
2023-10-20 23:31:31,253:INFO:create_model() successfully completed......................................
2023-10-20 23:31:31,352:INFO:SubProcess create_model() end ==================================
2023-10-20 23:31:31,352:INFO:Creating metrics dataframe
2023-10-20 23:31:31,352:INFO:Initializing Light Gradient Boosting Machine
2023-10-20 23:31:31,352:INFO:Total runtime is 2.0786349614461264 minutes
2023-10-20 23:31:31,352:INFO:SubProcess create_model() called ==================================
2023-10-20 23:31:31,352:INFO:Initializing create_model()
2023-10-20 23:31:31,352:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:31:31,352:INFO:Checking exceptions
2023-10-20 23:31:31,352:INFO:Importing libraries
2023-10-20 23:31:31,352:INFO:Copying training dataset
2023-10-20 23:31:31,386:INFO:Defining folds
2023-10-20 23:31:31,386:INFO:Declaring metric variables
2023-10-20 23:31:31,386:INFO:Importing untrained model
2023-10-20 23:31:31,386:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-20 23:31:31,386:INFO:Starting cross validation
2023-10-20 23:31:31,386:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:31:34,148:INFO:Calculating mean and std
2023-10-20 23:31:34,150:INFO:Creating metrics dataframe
2023-10-20 23:31:34,150:INFO:Uploading results into container
2023-10-20 23:31:34,150:INFO:Uploading model into container now
2023-10-20 23:31:34,150:INFO:_master_model_container: 17
2023-10-20 23:31:34,150:INFO:_display_container: 2
2023-10-20 23:31:34,150:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-20 23:31:34,150:INFO:create_model() successfully completed......................................
2023-10-20 23:31:34,266:INFO:SubProcess create_model() end ==================================
2023-10-20 23:31:34,266:INFO:Creating metrics dataframe
2023-10-20 23:31:34,283:INFO:Initializing CatBoost Regressor
2023-10-20 23:31:34,283:INFO:Total runtime is 2.127480455239614 minutes
2023-10-20 23:31:34,283:INFO:SubProcess create_model() called ==================================
2023-10-20 23:31:34,283:INFO:Initializing create_model()
2023-10-20 23:31:34,283:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:31:34,283:INFO:Checking exceptions
2023-10-20 23:31:34,283:INFO:Importing libraries
2023-10-20 23:31:34,283:INFO:Copying training dataset
2023-10-20 23:31:34,311:INFO:Defining folds
2023-10-20 23:31:34,312:INFO:Declaring metric variables
2023-10-20 23:31:34,313:INFO:Importing untrained model
2023-10-20 23:31:34,313:INFO:CatBoost Regressor Imported successfully
2023-10-20 23:31:34,313:INFO:Starting cross validation
2023-10-20 23:31:34,316:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:32:07,875:INFO:Calculating mean and std
2023-10-20 23:32:07,875:INFO:Creating metrics dataframe
2023-10-20 23:32:07,875:INFO:Uploading results into container
2023-10-20 23:32:07,875:INFO:Uploading model into container now
2023-10-20 23:32:07,875:INFO:_master_model_container: 18
2023-10-20 23:32:07,875:INFO:_display_container: 2
2023-10-20 23:32:07,875:INFO:<catboost.core.CatBoostRegressor object at 0x00000209D5A82340>
2023-10-20 23:32:07,875:INFO:create_model() successfully completed......................................
2023-10-20 23:32:08,002:INFO:SubProcess create_model() end ==================================
2023-10-20 23:32:08,002:INFO:Creating metrics dataframe
2023-10-20 23:32:08,002:INFO:Initializing Dummy Regressor
2023-10-20 23:32:08,002:INFO:Total runtime is 2.689457360903422 minutes
2023-10-20 23:32:08,002:INFO:SubProcess create_model() called ==================================
2023-10-20 23:32:08,002:INFO:Initializing create_model()
2023-10-20 23:32:08,002:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E384B640>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:32:08,002:INFO:Checking exceptions
2023-10-20 23:32:08,002:INFO:Importing libraries
2023-10-20 23:32:08,002:INFO:Copying training dataset
2023-10-20 23:32:08,040:INFO:Defining folds
2023-10-20 23:32:08,040:INFO:Declaring metric variables
2023-10-20 23:32:08,040:INFO:Importing untrained model
2023-10-20 23:32:08,041:INFO:Dummy Regressor Imported successfully
2023-10-20 23:32:08,041:INFO:Starting cross validation
2023-10-20 23:32:08,043:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:32:08,354:INFO:Calculating mean and std
2023-10-20 23:32:08,354:INFO:Creating metrics dataframe
2023-10-20 23:32:08,354:INFO:Uploading results into container
2023-10-20 23:32:08,354:INFO:Uploading model into container now
2023-10-20 23:32:08,354:INFO:_master_model_container: 19
2023-10-20 23:32:08,354:INFO:_display_container: 2
2023-10-20 23:32:08,354:INFO:DummyRegressor()
2023-10-20 23:32:08,354:INFO:create_model() successfully completed......................................
2023-10-20 23:32:08,476:INFO:SubProcess create_model() end ==================================
2023-10-20 23:32:08,476:INFO:Creating metrics dataframe
2023-10-20 23:32:08,476:INFO:Initializing create_model()
2023-10-20 23:32:08,476:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=<catboost.core.CatBoostRegressor object at 0x00000209D5A82340>, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:32:08,476:INFO:Checking exceptions
2023-10-20 23:32:08,476:INFO:Importing libraries
2023-10-20 23:32:08,476:INFO:Copying training dataset
2023-10-20 23:32:08,507:INFO:Defining folds
2023-10-20 23:32:08,507:INFO:Declaring metric variables
2023-10-20 23:32:08,507:INFO:Importing untrained model
2023-10-20 23:32:08,507:INFO:Declaring custom model
2023-10-20 23:32:08,507:INFO:CatBoost Regressor Imported successfully
2023-10-20 23:32:08,507:INFO:Cross validation set to False
2023-10-20 23:32:08,507:INFO:Fitting Model
2023-10-20 23:32:15,516:INFO:<catboost.core.CatBoostRegressor object at 0x00000209E4212880>
2023-10-20 23:32:15,516:INFO:create_model() successfully completed......................................
2023-10-20 23:32:15,616:INFO:Creating Dashboard logs
2023-10-20 23:32:15,616:INFO:Model: CatBoost Regressor
2023-10-20 23:32:15,685:INFO:Logged params: {'nan_mode': 'Min', 'eval_metric': 'RMSE', 'iterations': 1000, 'sampling_frequency': 'PerTree', 'leaf_estimation_method': 'Newton', 'random_score_type': 'NormalWithModelSizeDecrease', 'grow_policy': 'SymmetricTree', 'penalties_coefficient': 1, 'boosting_type': 'Plain', 'model_shrink_mode': 'Constant', 'feature_border_type': 'GreedyLogSum', 'bayesian_matrix_reg': 0.10000000149011612, 'eval_fraction': 0, 'force_unit_auto_pair_weights': False, 'l2_leaf_reg': 3, 'random_strength': 1, 'rsm': 1, 'boost_from_average': True, 'model_size_reg': 0.5, 'pool_metainfo_options': {'tags': {}}, 'subsample': 0.800000011920929, 'use_best_model': False, 'random_seed': 123, 'depth': 6, 'posterior_sampling': False, 'border_count': 254, 'classes_count': 0, 'auto_class_weights': 'None', 'sparse_features_conflict_fraction': 0, 'leaf_estimation_backtracking': 'AnyImprovement', 'best_model_min_trees': 1, 'model_shrink_rate': 0, 'min_data_in_leaf': 1, 'loss_function': 'RMSE', 'learning_rate': 0.06757699698209763, 'score_function': 'Cosine', 'task_type': 'CPU', 'leaf_estimation_iterations': 1, 'bootstrap_type': 'MVS', 'max_leaves': 64}
2023-10-20 23:32:15,939:INFO:Initializing predict_model()
2023-10-20 23:32:15,947:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=<catboost.core.CatBoostRegressor object at 0x00000209E4212880>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DA9FBF70>)
2023-10-20 23:32:15,947:INFO:Checking exceptions
2023-10-20 23:32:15,947:INFO:Preloading libraries
2023-10-20 23:32:16,353:INFO:Creating Dashboard logs
2023-10-20 23:32:16,354:INFO:Model: Light Gradient Boosting Machine
2023-10-20 23:32:16,416:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-20 23:32:16,740:INFO:Creating Dashboard logs
2023-10-20 23:32:16,740:INFO:Model: Extra Trees Regressor
2023-10-20 23:32:16,802:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-20 23:32:17,117:INFO:Creating Dashboard logs
2023-10-20 23:32:17,117:INFO:Model: Random Forest Regressor
2023-10-20 23:32:17,180:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-20 23:32:17,520:INFO:Creating Dashboard logs
2023-10-20 23:32:17,520:INFO:Model: Gradient Boosting Regressor
2023-10-20 23:32:17,585:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 123, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-10-20 23:32:17,904:INFO:Creating Dashboard logs
2023-10-20 23:32:17,904:INFO:Model: Ridge Regression
2023-10-20 23:32:17,951:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 123, 'solver': 'auto', 'tol': 0.0001}
2023-10-20 23:32:18,231:INFO:Creating Dashboard logs
2023-10-20 23:32:18,242:INFO:Model: Lasso Regression
2023-10-20 23:32:18,303:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 123, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-10-20 23:32:18,634:INFO:Creating Dashboard logs
2023-10-20 23:32:18,634:INFO:Model: Elastic Net
2023-10-20 23:32:18,688:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 123, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-10-20 23:32:18,992:INFO:Creating Dashboard logs
2023-10-20 23:32:18,992:INFO:Model: Lasso Least Angle Regression
2023-10-20 23:32:19,048:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'max_iter': 500, 'normalize': 'deprecated', 'positive': False, 'precompute': 'auto', 'random_state': 123, 'verbose': False}
2023-10-20 23:32:19,360:INFO:Creating Dashboard logs
2023-10-20 23:32:19,360:INFO:Model: Linear Regression
2023-10-20 23:32:19,419:INFO:Logged params: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'positive': False}
2023-10-20 23:32:19,712:INFO:Creating Dashboard logs
2023-10-20 23:32:19,712:INFO:Model: AdaBoost Regressor
2023-10-20 23:32:19,768:INFO:Logged params: {'base_estimator': 'deprecated', 'estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': 123}
2023-10-20 23:32:20,078:INFO:Creating Dashboard logs
2023-10-20 23:32:20,080:INFO:Model: Orthogonal Matching Pursuit
2023-10-20 23:32:20,130:INFO:Logged params: {'fit_intercept': True, 'n_nonzero_coefs': None, 'normalize': 'deprecated', 'precompute': 'auto', 'tol': None}
2023-10-20 23:32:20,416:INFO:Creating Dashboard logs
2023-10-20 23:32:20,416:INFO:Model: Huber Regressor
2023-10-20 23:32:20,485:INFO:Logged params: {'alpha': 0.0001, 'epsilon': 1.35, 'fit_intercept': True, 'max_iter': 100, 'tol': 1e-05, 'warm_start': False}
2023-10-20 23:32:20,762:INFO:Creating Dashboard logs
2023-10-20 23:32:20,762:INFO:Model: Decision Tree Regressor
2023-10-20 23:32:20,817:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 123, 'splitter': 'best'}
2023-10-20 23:32:21,106:INFO:Creating Dashboard logs
2023-10-20 23:32:21,106:INFO:Model: K Neighbors Regressor
2023-10-20 23:32:21,164:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2023-10-20 23:32:21,462:INFO:Creating Dashboard logs
2023-10-20 23:32:21,462:INFO:Model: Dummy Regressor
2023-10-20 23:32:21,509:INFO:Logged params: {'constant': None, 'quantile': None, 'strategy': 'mean'}
2023-10-20 23:32:21,795:INFO:Creating Dashboard logs
2023-10-20 23:32:21,795:INFO:Model: Passive Aggressive Regressor
2023-10-20 23:32:21,848:INFO:Logged params: {'C': 1.0, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'fit_intercept': True, 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 5, 'random_state': 123, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-10-20 23:32:22,165:INFO:Creating Dashboard logs
2023-10-20 23:32:22,165:INFO:Model: Bayesian Ridge
2023-10-20 23:32:22,227:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'tol': 0.001, 'verbose': False}
2023-10-20 23:32:22,546:INFO:Creating Dashboard logs
2023-10-20 23:32:22,546:INFO:Model: Least Angle Regression
2023-10-20 23:32:22,613:INFO:Logged params: {'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'n_nonzero_coefs': 500, 'normalize': 'deprecated', 'precompute': 'auto', 'random_state': 123, 'verbose': False}
2023-10-20 23:32:22,909:INFO:_master_model_container: 19
2023-10-20 23:32:22,909:INFO:_display_container: 2
2023-10-20 23:32:22,909:INFO:<catboost.core.CatBoostRegressor object at 0x00000209E4212880>
2023-10-20 23:32:22,911:INFO:compare_models() successfully completed......................................
2023-10-20 23:32:22,911:INFO:Initializing ensemble_model()
2023-10-20 23:32:22,911:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=<catboost.core.CatBoostRegressor object at 0x00000209E4212880>, method=Boosting, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-20 23:32:22,911:INFO:Checking exceptions
2023-10-20 23:33:31,120:INFO:Importing libraries
2023-10-20 23:33:31,120:INFO:Copying training dataset
2023-10-20 23:33:31,120:INFO:Checking base model
2023-10-20 23:33:31,120:INFO:Base model : CatBoost Regressor
2023-10-20 23:33:31,120:INFO:Importing untrained ensembler
2023-10-20 23:33:31,120:INFO:Ensemble method set to Boosting
2023-10-20 23:33:31,120:INFO:SubProcess create_model() called ==================================
2023-10-20 23:33:31,135:INFO:Initializing create_model()
2023-10-20 23:33:31,135:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=AdaBoostRegressor(estimator=<catboost.core.CatBoostRegressor object at 0x00000209E4212880>,
                  n_estimators=10, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3CA4430>, model_only=True, return_train_score=False, kwargs={})
2023-10-20 23:33:31,135:INFO:Checking exceptions
2023-10-20 23:33:31,135:INFO:Importing libraries
2023-10-20 23:33:31,135:INFO:Copying training dataset
2023-10-20 23:33:31,156:INFO:Defining folds
2023-10-20 23:33:31,157:INFO:Declaring metric variables
2023-10-20 23:33:31,157:INFO:Importing untrained model
2023-10-20 23:33:31,157:INFO:Declaring custom model
2023-10-20 23:33:31,159:INFO:AdaBoost Regressor Imported successfully
2023-10-20 23:33:31,159:INFO:Starting cross validation
2023-10-20 23:33:31,159:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-20 23:39:41,850:INFO:Calculating mean and std
2023-10-20 23:39:41,851:INFO:Creating metrics dataframe
2023-10-20 23:39:41,851:INFO:Finalizing model
2023-10-20 23:40:50,507:INFO:Uploading results into container
2023-10-20 23:40:50,507:INFO:Uploading model into container now
2023-10-20 23:40:50,507:INFO:_master_model_container: 20
2023-10-20 23:40:50,507:INFO:_display_container: 3
2023-10-20 23:40:50,507:INFO:AdaBoostRegressor(estimator=<catboost.core.CatBoostRegressor object at 0x00000209E421A670>,
                  n_estimators=10, random_state=123)
2023-10-20 23:40:50,507:INFO:create_model() successfully completed......................................
2023-10-20 23:40:50,607:INFO:SubProcess create_model() end ==================================
2023-10-20 23:40:50,623:INFO:Creating Dashboard logs
2023-10-20 23:40:50,624:INFO:Model: AdaBoost Regressor
2023-10-20 23:40:50,681:INFO:Logged params: {'base_estimator': 'deprecated', 'estimator__loss_function': 'RMSE', 'estimator__border_count': 254, 'estimator__verbose': False, 'estimator__task_type': 'CPU', 'estimator__random_state': 123, 'estimator': <catboost.core.CatBoostRegressor object at 0x00000209E421A670>, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 10, 'random_state': 123}
2023-10-20 23:40:50,840:INFO:Initializing predict_model()
2023-10-20 23:40:50,840:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>, estimator=AdaBoostRegressor(estimator=<catboost.core.CatBoostRegressor object at 0x00000209E421A670>,
                  n_estimators=10, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DC9DE1F0>)
2023-10-20 23:40:50,840:INFO:Checking exceptions
2023-10-20 23:40:50,840:INFO:Preloading libraries
2023-10-20 23:40:51,323:INFO:_master_model_container: 20
2023-10-20 23:40:51,323:INFO:_display_container: 3
2023-10-20 23:40:51,323:INFO:AdaBoostRegressor(estimator=<catboost.core.CatBoostRegressor object at 0x00000209E421A670>,
                  n_estimators=10, random_state=123)
2023-10-20 23:40:51,323:INFO:ensemble_model() successfully completed......................................
2023-10-20 23:40:51,425:INFO:Initializing tune_model()
2023-10-20 23:40:51,425:INFO:tune_model(estimator=AdaBoostRegressor(estimator=<catboost.core.CatBoostRegressor object at 0x00000209E421A670>,
                  n_estimators=10, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E35B7A30>)
2023-10-20 23:40:51,425:INFO:Checking exceptions
2023-10-20 23:40:51,441:INFO:Copying training dataset
2023-10-20 23:40:51,457:INFO:Checking base model
2023-10-20 23:40:51,457:INFO:Base model : AdaBoost Regressor
2023-10-20 23:40:51,457:INFO:Declaring metric variables
2023-10-20 23:40:51,457:INFO:Defining Hyperparameters
2023-10-20 23:40:51,574:INFO:Tuning with n_jobs=-1
2023-10-20 23:40:51,574:INFO:Initializing RandomizedSearchCV
2023-10-21 08:53:05,939:INFO:PyCaret RegressionExperiment
2023-10-21 08:53:05,940:INFO:Logging name: exp_A
2023-10-21 08:53:05,940:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-21 08:53:05,941:INFO:version 3.1.0
2023-10-21 08:53:05,941:INFO:Initializing setup()
2023-10-21 08:53:05,941:INFO:self.USI: 0c8f
2023-10-21 08:53:05,941:INFO:self._variable_keys: {'transform_target_param', 'exp_name_log', 'y_train', 'logging_param', 'n_jobs_param', 'X_train', 'target_param', 'USI', 'gpu_n_jobs_param', 'fold_groups_param', '_ml_usecase', 'seed', 'fold_generator', 'idx', 'html_param', 'log_plots_param', 'y', 'gpu_param', 'X_test', 'memory', 'y_test', 'data', 'X', 'exp_id', '_available_plots', 'fold_shuffle_param', 'pipeline'}
2023-10-21 08:53:05,942:INFO:Checking environment
2023-10-21 08:53:05,942:INFO:python_version: 3.8.18
2023-10-21 08:53:05,942:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-21 08:53:05,942:INFO:machine: AMD64
2023-10-21 08:53:05,943:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-21 08:53:05,943:INFO:Memory: svmem(total=16505954304, available=5360242688, percent=67.5, used=11145711616, free=5360242688)
2023-10-21 08:53:05,943:INFO:Physical Core: 8
2023-10-21 08:53:05,943:INFO:Logical Core: 16
2023-10-21 08:53:05,943:INFO:Checking libraries
2023-10-21 08:53:05,944:INFO:System:
2023-10-21 08:53:05,944:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-21 08:53:05,944:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-21 08:53:05,944:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-21 08:53:05,944:INFO:PyCaret required dependencies:
2023-10-21 08:53:05,944:INFO:                 pip: 23.3
2023-10-21 08:53:05,944:INFO:          setuptools: 68.0.0
2023-10-21 08:53:05,944:INFO:             pycaret: 3.1.0
2023-10-21 08:53:05,944:INFO:             IPython: 8.12.0
2023-10-21 08:53:05,944:INFO:          ipywidgets: 8.1.1
2023-10-21 08:53:05,945:INFO:                tqdm: 4.66.1
2023-10-21 08:53:05,945:INFO:               numpy: 1.23.5
2023-10-21 08:53:05,945:INFO:              pandas: 1.5.3
2023-10-21 08:53:05,945:INFO:              jinja2: 3.1.2
2023-10-21 08:53:05,945:INFO:               scipy: 1.10.1
2023-10-21 08:53:05,945:INFO:              joblib: 1.3.2
2023-10-21 08:53:05,945:INFO:             sklearn: 1.2.2
2023-10-21 08:53:05,945:INFO:                pyod: 1.1.0
2023-10-21 08:53:05,945:INFO:            imblearn: 0.11.0
2023-10-21 08:53:05,945:INFO:   category_encoders: 2.6.2
2023-10-21 08:53:05,945:INFO:            lightgbm: 4.1.0
2023-10-21 08:53:05,945:INFO:               numba: 0.58.1
2023-10-21 08:53:05,945:INFO:            requests: 2.31.0
2023-10-21 08:53:05,945:INFO:          matplotlib: 3.7.3
2023-10-21 08:53:05,945:INFO:          scikitplot: 0.3.7
2023-10-21 08:53:05,946:INFO:         yellowbrick: 1.5
2023-10-21 08:53:05,946:INFO:              plotly: 5.17.0
2023-10-21 08:53:05,946:INFO:    plotly-resampler: Not installed
2023-10-21 08:53:05,946:INFO:             kaleido: 0.2.1
2023-10-21 08:53:05,946:INFO:           schemdraw: 0.15
2023-10-21 08:53:05,946:INFO:         statsmodels: 0.14.0
2023-10-21 08:53:05,946:INFO:              sktime: 0.21.1
2023-10-21 08:53:05,946:INFO:               tbats: 1.1.3
2023-10-21 08:53:05,946:INFO:            pmdarima: 2.0.3
2023-10-21 08:53:05,946:INFO:              psutil: 5.9.0
2023-10-21 08:53:05,946:INFO:          markupsafe: 2.1.3
2023-10-21 08:53:05,946:INFO:             pickle5: Not installed
2023-10-21 08:53:05,946:INFO:         cloudpickle: 2.2.1
2023-10-21 08:53:05,946:INFO:         deprecation: 2.1.0
2023-10-21 08:53:05,946:INFO:              xxhash: 3.4.1
2023-10-21 08:53:05,946:INFO:           wurlitzer: Not installed
2023-10-21 08:53:05,946:INFO:PyCaret optional dependencies:
2023-10-21 08:53:05,946:INFO:                shap: Not installed
2023-10-21 08:53:05,947:INFO:           interpret: Not installed
2023-10-21 08:53:05,947:INFO:                umap: Not installed
2023-10-21 08:53:05,947:INFO:     ydata_profiling: Not installed
2023-10-21 08:53:05,947:INFO:  explainerdashboard: Not installed
2023-10-21 08:53:05,947:INFO:             autoviz: Not installed
2023-10-21 08:53:05,947:INFO:           fairlearn: Not installed
2023-10-21 08:53:05,947:INFO:          deepchecks: Not installed
2023-10-21 08:53:05,947:INFO:             xgboost: Not installed
2023-10-21 08:53:05,947:INFO:            catboost: 1.2.2
2023-10-21 08:53:05,947:INFO:              kmodes: Not installed
2023-10-21 08:53:05,947:INFO:             mlxtend: Not installed
2023-10-21 08:53:05,947:INFO:       statsforecast: Not installed
2023-10-21 08:53:05,947:INFO:        tune_sklearn: Not installed
2023-10-21 08:53:05,947:INFO:                 ray: Not installed
2023-10-21 08:53:05,947:INFO:            hyperopt: Not installed
2023-10-21 08:53:05,947:INFO:              optuna: Not installed
2023-10-21 08:53:05,947:INFO:               skopt: Not installed
2023-10-21 08:53:05,947:INFO:              mlflow: 2.7.1
2023-10-21 08:53:05,947:INFO:              gradio: Not installed
2023-10-21 08:53:05,948:INFO:             fastapi: Not installed
2023-10-21 08:53:05,948:INFO:             uvicorn: Not installed
2023-10-21 08:53:05,948:INFO:              m2cgen: Not installed
2023-10-21 08:53:05,948:INFO:           evidently: Not installed
2023-10-21 08:53:05,948:INFO:               fugue: Not installed
2023-10-21 08:53:05,948:INFO:           streamlit: Not installed
2023-10-21 08:53:05,948:INFO:             prophet: Not installed
2023-10-21 08:53:05,948:INFO:None
2023-10-21 08:53:05,948:INFO:Set up data.
2023-10-21 08:53:05,970:INFO:Set up folding strategy.
2023-10-21 08:53:05,970:INFO:Set up train/test split.
2023-10-21 08:53:06,004:INFO:Set up index.
2023-10-21 08:53:06,005:INFO:Assigning column types.
2023-10-21 08:53:06,027:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-21 08:53:06,028:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,034:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,039:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,124:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,179:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,180:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:53:06,180:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:53:06,181:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,184:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,192:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,278:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,334:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,334:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:53:06,335:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:53:06,336:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-21 08:53:06,341:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,347:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,430:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,487:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,488:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:53:06,488:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:53:06,494:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,500:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,586:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,651:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,651:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:53:06,651:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:53:06,660:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-21 08:53:06,671:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,738:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,792:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,792:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:53:06,792:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:53:06,808:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,871:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,923:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:53:06,923:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:53:06,923:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:53:06,923:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-21 08:53:07,008:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:53:07,060:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:53:07,060:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:53:07,060:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:53:07,140:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:53:07,203:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:53:07,204:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:53:07,204:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:53:07,205:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-21 08:53:07,291:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:53:07,341:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:53:07,341:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:53:07,426:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:53:07,472:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:53:07,472:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:53:07,472:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-21 08:53:07,612:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:53:07,612:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:53:07,739:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:53:07,739:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:53:07,739:INFO:Preparing preprocessing pipeline...
2023-10-21 08:53:07,739:INFO:Set up simple imputation.
2023-10-21 08:53:07,739:INFO:Set up column name cleaning.
2023-10-21 08:53:07,802:INFO:Finished creating preprocessing pipeline.
2023-10-21 08:53:07,802:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 08:53:07,802:INFO:Creating final display dataframe.
2023-10-21 08:53:07,973:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (34061, 39)
4        Transformed data shape   (34061, 39)
5   Transformed train set shape   (23842, 39)
6    Transformed test set shape   (10219, 39)
7              Numeric features            38
8      Rows with missing values         23.1%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_A
19                          USI          0c8f
2023-10-21 08:53:08,108:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:53:08,108:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:53:08,235:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:53:08,235:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:53:08,252:INFO:Logging experiment in loggers
2023-10-21 08:53:08,357:INFO:SubProcess save_model() called ==================================
2023-10-21 08:53:08,372:INFO:Initializing save_model()
2023-10-21 08:53:08,372:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmpid5n4mr7\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 08:53:08,372:INFO:Adding model into prep_pipe
2023-10-21 08:53:08,372:WARNING:Only Model saved as it was a pipeline.
2023-10-21 08:53:08,372:INFO:C:\Users\thoma\AppData\Local\Temp\tmpid5n4mr7\Transformation Pipeline.pkl saved in current working directory
2023-10-21 08:53:08,372:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 08:53:08,372:INFO:save_model() successfully completed......................................
2023-10-21 08:53:08,507:INFO:SubProcess save_model() end ==================================
2023-10-21 08:53:08,564:INFO:setup() successfully completed in 2.31s...............
2023-10-21 08:53:08,564:INFO:Initializing create_model()
2023-10-21 08:53:08,564:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6BB93A0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 08:53:08,564:INFO:Checking exceptions
2023-10-21 08:53:08,570:INFO:Importing libraries
2023-10-21 08:53:08,570:INFO:Copying training dataset
2023-10-21 08:53:08,590:INFO:Defining folds
2023-10-21 08:53:08,590:INFO:Declaring metric variables
2023-10-21 08:53:08,590:INFO:Importing untrained model
2023-10-21 08:53:08,590:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 08:53:08,590:INFO:Starting cross validation
2023-10-21 08:53:08,590:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 08:53:18,947:INFO:Calculating mean and std
2023-10-21 08:53:18,950:INFO:Creating metrics dataframe
2023-10-21 08:53:18,950:INFO:Finalizing model
2023-10-21 08:53:19,081:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005763 seconds.
2023-10-21 08:53:19,081:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 08:53:19,082:INFO:[LightGBM] [Info] Total Bins 6173
2023-10-21 08:53:19,082:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 37
2023-10-21 08:53:19,084:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-21 08:53:19,327:INFO:Creating Dashboard logs
2023-10-21 08:53:19,327:INFO:Model: Light Gradient Boosting Machine
2023-10-21 08:53:19,410:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 08:53:19,610:INFO:Initializing predict_model()
2023-10-21 08:53:19,610:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6BB93A0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DCC6AA60>)
2023-10-21 08:53:19,610:INFO:Checking exceptions
2023-10-21 08:53:19,610:INFO:Preloading libraries
2023-10-21 08:53:20,160:INFO:Uploading results into container
2023-10-21 08:53:20,172:INFO:Uploading model into container now
2023-10-21 08:53:20,176:INFO:_master_model_container: 1
2023-10-21 08:53:20,176:INFO:_display_container: 2
2023-10-21 08:53:20,176:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 08:53:20,176:INFO:create_model() successfully completed......................................
2023-10-21 08:53:20,310:INFO:Initializing tune_model()
2023-10-21 08:53:20,310:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6BB93A0>)
2023-10-21 08:53:20,310:INFO:Checking exceptions
2023-10-21 08:53:20,327:INFO:Copying training dataset
2023-10-21 08:53:20,350:INFO:Checking base model
2023-10-21 08:53:20,350:INFO:Base model : Light Gradient Boosting Machine
2023-10-21 08:53:20,350:INFO:Declaring metric variables
2023-10-21 08:53:20,350:INFO:Defining Hyperparameters
2023-10-21 08:53:20,509:INFO:Tuning with n_jobs=-1
2023-10-21 08:53:20,509:INFO:Initializing RandomizedSearchCV
2023-10-21 08:54:14,998:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-21 08:54:14,998:INFO:Hyperparameter search completed
2023-10-21 08:54:14,998:INFO:SubProcess create_model() called ==================================
2023-10-21 08:54:14,998:INFO:Initializing create_model()
2023-10-21 08:54:14,998:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6BB93A0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209DAADED30>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-21 08:54:14,998:INFO:Checking exceptions
2023-10-21 08:54:14,998:INFO:Importing libraries
2023-10-21 08:54:14,998:INFO:Copying training dataset
2023-10-21 08:54:15,032:INFO:Defining folds
2023-10-21 08:54:15,032:INFO:Declaring metric variables
2023-10-21 08:54:15,032:INFO:Importing untrained model
2023-10-21 08:54:15,032:INFO:Declaring custom model
2023-10-21 08:54:15,032:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 08:54:15,032:INFO:Starting cross validation
2023-10-21 08:54:15,032:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 08:54:24,628:INFO:Calculating mean and std
2023-10-21 08:54:24,628:INFO:Creating metrics dataframe
2023-10-21 08:54:24,628:INFO:Finalizing model
2023-10-21 08:54:24,693:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 08:54:24,693:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 08:54:24,694:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 08:54:24,729:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 08:54:24,729:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 08:54:24,729:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 08:54:24,729:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005286 seconds.
2023-10-21 08:54:24,729:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 08:54:24,739:INFO:[LightGBM] [Info] Total Bins 6173
2023-10-21 08:54:24,739:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 37
2023-10-21 08:54:24,741:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-21 08:54:25,845:INFO:Uploading results into container
2023-10-21 08:54:25,845:INFO:Uploading model into container now
2023-10-21 08:54:25,845:INFO:_master_model_container: 2
2023-10-21 08:54:25,845:INFO:_display_container: 3
2023-10-21 08:54:25,845:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-21 08:54:25,845:INFO:create_model() successfully completed......................................
2023-10-21 08:54:26,009:INFO:SubProcess create_model() end ==================================
2023-10-21 08:54:26,009:INFO:choose_better activated
2023-10-21 08:54:26,009:INFO:SubProcess create_model() called ==================================
2023-10-21 08:54:26,009:INFO:Initializing create_model()
2023-10-21 08:54:26,009:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6BB93A0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 08:54:26,009:INFO:Checking exceptions
2023-10-21 08:54:26,009:INFO:Importing libraries
2023-10-21 08:54:26,009:INFO:Copying training dataset
2023-10-21 08:54:26,024:INFO:Defining folds
2023-10-21 08:54:26,024:INFO:Declaring metric variables
2023-10-21 08:54:26,024:INFO:Importing untrained model
2023-10-21 08:54:26,024:INFO:Declaring custom model
2023-10-21 08:54:26,024:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 08:54:26,024:INFO:Starting cross validation
2023-10-21 08:54:26,024:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 08:54:28,843:INFO:Calculating mean and std
2023-10-21 08:54:28,843:INFO:Creating metrics dataframe
2023-10-21 08:54:28,843:INFO:Finalizing model
2023-10-21 08:54:28,903:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004530 seconds.
2023-10-21 08:54:28,903:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 08:54:28,903:INFO:[LightGBM] [Info] Total Bins 6173
2023-10-21 08:54:28,903:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 37
2023-10-21 08:54:28,903:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-21 08:54:29,140:INFO:Uploading results into container
2023-10-21 08:54:29,140:INFO:Uploading model into container now
2023-10-21 08:54:29,140:INFO:_master_model_container: 3
2023-10-21 08:54:29,140:INFO:_display_container: 4
2023-10-21 08:54:29,140:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 08:54:29,140:INFO:create_model() successfully completed......................................
2023-10-21 08:54:29,302:INFO:SubProcess create_model() end ==================================
2023-10-21 08:54:29,302:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8702
2023-10-21 08:54:29,302:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.867
2023-10-21 08:54:29,302:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-21 08:54:29,302:INFO:choose_better completed
2023-10-21 08:54:29,302:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-21 08:54:29,302:INFO:Creating Dashboard logs
2023-10-21 08:54:29,302:INFO:Model: Light Gradient Boosting Machine
2023-10-21 08:54:29,365:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 08:54:29,535:INFO:Initializing predict_model()
2023-10-21 08:54:29,535:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6BB93A0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DCC6A670>)
2023-10-21 08:54:29,535:INFO:Checking exceptions
2023-10-21 08:54:29,535:INFO:Preloading libraries
2023-10-21 08:54:30,089:INFO:_master_model_container: 3
2023-10-21 08:54:30,089:INFO:_display_container: 3
2023-10-21 08:54:30,090:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 08:54:30,090:INFO:tune_model() successfully completed......................................
2023-10-21 08:54:30,220:INFO:Initializing finalize_model()
2023-10-21 08:54:30,220:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6BB93A0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-21 08:54:30,220:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 08:54:30,236:INFO:Initializing create_model()
2023-10-21 08:54:30,236:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6BB93A0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-21 08:54:30,236:INFO:Checking exceptions
2023-10-21 08:54:30,236:INFO:Importing libraries
2023-10-21 08:54:30,236:INFO:Copying training dataset
2023-10-21 08:54:30,236:INFO:Defining folds
2023-10-21 08:54:30,236:INFO:Declaring metric variables
2023-10-21 08:54:30,236:INFO:Importing untrained model
2023-10-21 08:54:30,236:INFO:Declaring custom model
2023-10-21 08:54:30,236:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 08:54:30,236:INFO:Cross validation set to False
2023-10-21 08:54:30,236:INFO:Fitting Model
2023-10-21 08:54:30,341:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010197 seconds.
2023-10-21 08:54:30,341:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 08:54:30,341:INFO:[LightGBM] [Info] Total Bins 6208
2023-10-21 08:54:30,356:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 37
2023-10-21 08:54:30,356:INFO:[LightGBM] [Info] Start training from score 631.011165
2023-10-21 08:54:30,654:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-21 08:54:30,654:INFO:create_model() successfully completed......................................
2023-10-21 08:54:30,799:INFO:Creating Dashboard logs
2023-10-21 08:54:30,799:INFO:Model: Light Gradient Boosting Machine
2023-10-21 08:54:30,869:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 08:54:31,217:INFO:_master_model_container: 3
2023-10-21 08:54:31,217:INFO:_display_container: 3
2023-10-21 08:54:31,221:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-21 08:54:31,221:INFO:finalize_model() successfully completed......................................
2023-10-21 08:54:31,375:INFO:Initializing save_model()
2023-10-21 08:54:31,375:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_A, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 08:54:31,375:INFO:Adding model into prep_pipe
2023-10-21 08:54:31,375:WARNING:Only Model saved as it was a pipeline.
2023-10-21 08:54:31,386:INFO:final_model_for_location_A.pkl saved in current working directory
2023-10-21 08:54:31,386:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-21 08:54:31,386:INFO:save_model() successfully completed......................................
2023-10-21 08:54:31,555:INFO:PyCaret RegressionExperiment
2023-10-21 08:54:31,555:INFO:Logging name: exp_B
2023-10-21 08:54:31,555:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-21 08:54:31,555:INFO:version 3.1.0
2023-10-21 08:54:31,555:INFO:Initializing setup()
2023-10-21 08:54:31,555:INFO:self.USI: 024c
2023-10-21 08:54:31,555:INFO:self._variable_keys: {'transform_target_param', 'exp_name_log', 'y_train', 'logging_param', 'n_jobs_param', 'X_train', 'target_param', 'USI', 'gpu_n_jobs_param', 'fold_groups_param', '_ml_usecase', 'seed', 'fold_generator', 'idx', 'html_param', 'log_plots_param', 'y', 'gpu_param', 'X_test', 'memory', 'y_test', 'data', 'X', 'exp_id', '_available_plots', 'fold_shuffle_param', 'pipeline'}
2023-10-21 08:54:31,555:INFO:Checking environment
2023-10-21 08:54:31,555:INFO:python_version: 3.8.18
2023-10-21 08:54:31,555:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-21 08:54:31,555:INFO:machine: AMD64
2023-10-21 08:54:31,555:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-21 08:54:31,555:INFO:Memory: svmem(total=16505954304, available=3512782848, percent=78.7, used=12993171456, free=3512782848)
2023-10-21 08:54:31,555:INFO:Physical Core: 8
2023-10-21 08:54:31,555:INFO:Logical Core: 16
2023-10-21 08:54:31,555:INFO:Checking libraries
2023-10-21 08:54:31,555:INFO:System:
2023-10-21 08:54:31,555:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-21 08:54:31,555:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-21 08:54:31,555:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-21 08:54:31,555:INFO:PyCaret required dependencies:
2023-10-21 08:54:31,555:INFO:                 pip: 23.3
2023-10-21 08:54:31,555:INFO:          setuptools: 68.0.0
2023-10-21 08:54:31,555:INFO:             pycaret: 3.1.0
2023-10-21 08:54:31,555:INFO:             IPython: 8.12.0
2023-10-21 08:54:31,555:INFO:          ipywidgets: 8.1.1
2023-10-21 08:54:31,555:INFO:                tqdm: 4.66.1
2023-10-21 08:54:31,555:INFO:               numpy: 1.23.5
2023-10-21 08:54:31,555:INFO:              pandas: 1.5.3
2023-10-21 08:54:31,555:INFO:              jinja2: 3.1.2
2023-10-21 08:54:31,555:INFO:               scipy: 1.10.1
2023-10-21 08:54:31,555:INFO:              joblib: 1.3.2
2023-10-21 08:54:31,555:INFO:             sklearn: 1.2.2
2023-10-21 08:54:31,555:INFO:                pyod: 1.1.0
2023-10-21 08:54:31,555:INFO:            imblearn: 0.11.0
2023-10-21 08:54:31,555:INFO:   category_encoders: 2.6.2
2023-10-21 08:54:31,555:INFO:            lightgbm: 4.1.0
2023-10-21 08:54:31,555:INFO:               numba: 0.58.1
2023-10-21 08:54:31,555:INFO:            requests: 2.31.0
2023-10-21 08:54:31,555:INFO:          matplotlib: 3.7.3
2023-10-21 08:54:31,555:INFO:          scikitplot: 0.3.7
2023-10-21 08:54:31,555:INFO:         yellowbrick: 1.5
2023-10-21 08:54:31,555:INFO:              plotly: 5.17.0
2023-10-21 08:54:31,555:INFO:    plotly-resampler: Not installed
2023-10-21 08:54:31,555:INFO:             kaleido: 0.2.1
2023-10-21 08:54:31,555:INFO:           schemdraw: 0.15
2023-10-21 08:54:31,555:INFO:         statsmodels: 0.14.0
2023-10-21 08:54:31,555:INFO:              sktime: 0.21.1
2023-10-21 08:54:31,555:INFO:               tbats: 1.1.3
2023-10-21 08:54:31,555:INFO:            pmdarima: 2.0.3
2023-10-21 08:54:31,555:INFO:              psutil: 5.9.0
2023-10-21 08:54:31,555:INFO:          markupsafe: 2.1.3
2023-10-21 08:54:31,555:INFO:             pickle5: Not installed
2023-10-21 08:54:31,555:INFO:         cloudpickle: 2.2.1
2023-10-21 08:54:31,555:INFO:         deprecation: 2.1.0
2023-10-21 08:54:31,555:INFO:              xxhash: 3.4.1
2023-10-21 08:54:31,555:INFO:           wurlitzer: Not installed
2023-10-21 08:54:31,555:INFO:PyCaret optional dependencies:
2023-10-21 08:54:31,555:INFO:                shap: Not installed
2023-10-21 08:54:31,555:INFO:           interpret: Not installed
2023-10-21 08:54:31,555:INFO:                umap: Not installed
2023-10-21 08:54:31,555:INFO:     ydata_profiling: Not installed
2023-10-21 08:54:31,555:INFO:  explainerdashboard: Not installed
2023-10-21 08:54:31,555:INFO:             autoviz: Not installed
2023-10-21 08:54:31,555:INFO:           fairlearn: Not installed
2023-10-21 08:54:31,555:INFO:          deepchecks: Not installed
2023-10-21 08:54:31,555:INFO:             xgboost: Not installed
2023-10-21 08:54:31,555:INFO:            catboost: 1.2.2
2023-10-21 08:54:31,555:INFO:              kmodes: Not installed
2023-10-21 08:54:31,555:INFO:             mlxtend: Not installed
2023-10-21 08:54:31,555:INFO:       statsforecast: Not installed
2023-10-21 08:54:31,555:INFO:        tune_sklearn: Not installed
2023-10-21 08:54:31,555:INFO:                 ray: Not installed
2023-10-21 08:54:31,571:INFO:            hyperopt: Not installed
2023-10-21 08:54:31,571:INFO:              optuna: Not installed
2023-10-21 08:54:31,571:INFO:               skopt: Not installed
2023-10-21 08:54:31,571:INFO:              mlflow: 2.7.1
2023-10-21 08:54:31,571:INFO:              gradio: Not installed
2023-10-21 08:54:31,571:INFO:             fastapi: Not installed
2023-10-21 08:54:31,571:INFO:             uvicorn: Not installed
2023-10-21 08:54:31,571:INFO:              m2cgen: Not installed
2023-10-21 08:54:31,571:INFO:           evidently: Not installed
2023-10-21 08:54:31,571:INFO:               fugue: Not installed
2023-10-21 08:54:31,571:INFO:           streamlit: Not installed
2023-10-21 08:54:31,571:INFO:             prophet: Not installed
2023-10-21 08:54:31,571:INFO:None
2023-10-21 08:54:31,571:INFO:Set up data.
2023-10-21 08:54:31,589:INFO:Set up folding strategy.
2023-10-21 08:54:31,589:INFO:Set up train/test split.
2023-10-21 08:54:31,621:INFO:Set up index.
2023-10-21 08:54:31,621:INFO:Assigning column types.
2023-10-21 08:54:31,637:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-21 08:54:31,637:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 08:54:31,637:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 08:54:31,653:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:54:31,721:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:54:31,787:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:54:31,787:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:54:31,787:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:54:31,787:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 08:54:31,787:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 08:54:31,787:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:54:31,884:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:54:31,924:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:54:31,924:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:54:31,924:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:54:31,924:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-21 08:54:31,939:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 08:54:31,939:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,021:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,087:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,087:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:54:32,088:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:54:32,093:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,100:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,186:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,235:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,235:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:54:32,235:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:54:32,235:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-21 08:54:32,251:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,336:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,383:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,383:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:54:32,383:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:54:32,399:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,483:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,537:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,537:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:54:32,537:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:54:32,537:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-21 08:54:32,637:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,722:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,731:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:54:32,731:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:54:32,822:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,883:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:54:32,884:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:54:32,884:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:54:32,885:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-21 08:54:32,969:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:54:33,022:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:54:33,022:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:54:33,122:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:54:33,170:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:54:33,170:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:54:33,170:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-21 08:54:33,323:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:54:33,323:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:54:33,469:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:54:33,469:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:54:33,469:INFO:Preparing preprocessing pipeline...
2023-10-21 08:54:33,469:INFO:Set up simple imputation.
2023-10-21 08:54:33,485:INFO:Set up column name cleaning.
2023-10-21 08:54:33,532:INFO:Finished creating preprocessing pipeline.
2023-10-21 08:54:33,532:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 08:54:33,532:INFO:Creating final display dataframe.
2023-10-21 08:54:33,702:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (32819, 39)
4        Transformed data shape   (32819, 39)
5   Transformed train set shape   (22973, 39)
6    Transformed test set shape    (9846, 39)
7              Numeric features            38
8      Rows with missing values         19.9%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_B
19                          USI          024c
2023-10-21 08:54:33,901:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:54:33,901:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:54:34,103:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:54:34,103:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:54:34,103:INFO:Logging experiment in loggers
2023-10-21 08:54:34,225:INFO:SubProcess save_model() called ==================================
2023-10-21 08:54:34,234:INFO:Initializing save_model()
2023-10-21 08:54:34,234:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmpov9bwx63\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 08:54:34,234:INFO:Adding model into prep_pipe
2023-10-21 08:54:34,234:WARNING:Only Model saved as it was a pipeline.
2023-10-21 08:54:34,234:INFO:C:\Users\thoma\AppData\Local\Temp\tmpov9bwx63\Transformation Pipeline.pkl saved in current working directory
2023-10-21 08:54:34,249:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 08:54:34,249:INFO:save_model() successfully completed......................................
2023-10-21 08:54:34,370:INFO:SubProcess save_model() end ==================================
2023-10-21 08:54:34,433:INFO:setup() successfully completed in 2.55s...............
2023-10-21 08:54:34,433:INFO:Initializing create_model()
2023-10-21 08:54:34,433:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E3690730>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 08:54:34,433:INFO:Checking exceptions
2023-10-21 08:54:34,433:INFO:Importing libraries
2023-10-21 08:54:34,433:INFO:Copying training dataset
2023-10-21 08:54:34,448:INFO:Defining folds
2023-10-21 08:54:34,448:INFO:Declaring metric variables
2023-10-21 08:54:34,448:INFO:Importing untrained model
2023-10-21 08:54:34,448:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 08:54:34,448:INFO:Starting cross validation
2023-10-21 08:54:34,448:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 08:54:37,332:INFO:Calculating mean and std
2023-10-21 08:54:37,332:INFO:Creating metrics dataframe
2023-10-21 08:54:37,332:INFO:Finalizing model
2023-10-21 08:54:37,398:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003893 seconds.
2023-10-21 08:54:37,398:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 08:54:37,398:INFO:[LightGBM] [Info] Total Bins 6163
2023-10-21 08:54:37,398:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 37
2023-10-21 08:54:37,398:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-21 08:54:37,602:INFO:Creating Dashboard logs
2023-10-21 08:54:37,618:INFO:Model: Light Gradient Boosting Machine
2023-10-21 08:54:37,702:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 08:54:37,879:INFO:Initializing predict_model()
2023-10-21 08:54:37,879:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E3690730>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209D70B8160>)
2023-10-21 08:54:37,879:INFO:Checking exceptions
2023-10-21 08:54:37,879:INFO:Preloading libraries
2023-10-21 08:54:38,375:INFO:Uploading results into container
2023-10-21 08:54:38,376:INFO:Uploading model into container now
2023-10-21 08:54:38,378:INFO:_master_model_container: 1
2023-10-21 08:54:38,378:INFO:_display_container: 2
2023-10-21 08:54:38,378:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 08:54:38,378:INFO:create_model() successfully completed......................................
2023-10-21 08:54:38,511:INFO:Initializing tune_model()
2023-10-21 08:54:38,511:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E3690730>)
2023-10-21 08:54:38,511:INFO:Checking exceptions
2023-10-21 08:54:38,526:INFO:Copying training dataset
2023-10-21 08:54:38,536:INFO:Checking base model
2023-10-21 08:54:38,536:INFO:Base model : Light Gradient Boosting Machine
2023-10-21 08:54:38,536:INFO:Declaring metric variables
2023-10-21 08:54:38,536:INFO:Defining Hyperparameters
2023-10-21 08:54:38,677:INFO:Tuning with n_jobs=-1
2023-10-21 08:54:38,677:INFO:Initializing RandomizedSearchCV
2023-10-21 08:55:25,730:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-21 08:55:25,730:INFO:Hyperparameter search completed
2023-10-21 08:55:25,730:INFO:SubProcess create_model() called ==================================
2023-10-21 08:55:25,730:INFO:Initializing create_model()
2023-10-21 08:55:25,730:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E3690730>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E373BC10>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-21 08:55:25,730:INFO:Checking exceptions
2023-10-21 08:55:25,730:INFO:Importing libraries
2023-10-21 08:55:25,730:INFO:Copying training dataset
2023-10-21 08:55:25,761:INFO:Defining folds
2023-10-21 08:55:25,761:INFO:Declaring metric variables
2023-10-21 08:55:25,761:INFO:Importing untrained model
2023-10-21 08:55:25,761:INFO:Declaring custom model
2023-10-21 08:55:25,761:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 08:55:25,761:INFO:Starting cross validation
2023-10-21 08:55:25,761:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 08:55:35,480:INFO:Calculating mean and std
2023-10-21 08:55:35,484:INFO:Creating metrics dataframe
2023-10-21 08:55:35,486:INFO:Finalizing model
2023-10-21 08:55:35,519:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 08:55:35,519:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 08:55:35,519:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 08:55:35,553:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 08:55:35,553:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 08:55:35,553:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 08:55:35,553:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001322 seconds.
2023-10-21 08:55:35,553:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-21 08:55:35,553:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-21 08:55:35,553:INFO:[LightGBM] [Info] Total Bins 6163
2023-10-21 08:55:35,553:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 37
2023-10-21 08:55:35,565:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-21 08:55:36,930:INFO:Uploading results into container
2023-10-21 08:55:36,930:INFO:Uploading model into container now
2023-10-21 08:55:36,930:INFO:_master_model_container: 2
2023-10-21 08:55:36,930:INFO:_display_container: 3
2023-10-21 08:55:36,930:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-21 08:55:36,930:INFO:create_model() successfully completed......................................
2023-10-21 08:55:37,084:INFO:SubProcess create_model() end ==================================
2023-10-21 08:55:37,084:INFO:choose_better activated
2023-10-21 08:55:37,084:INFO:SubProcess create_model() called ==================================
2023-10-21 08:55:37,084:INFO:Initializing create_model()
2023-10-21 08:55:37,084:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E3690730>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 08:55:37,084:INFO:Checking exceptions
2023-10-21 08:55:37,096:INFO:Importing libraries
2023-10-21 08:55:37,097:INFO:Copying training dataset
2023-10-21 08:55:37,114:INFO:Defining folds
2023-10-21 08:55:37,114:INFO:Declaring metric variables
2023-10-21 08:55:37,114:INFO:Importing untrained model
2023-10-21 08:55:37,114:INFO:Declaring custom model
2023-10-21 08:55:37,114:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 08:55:37,114:INFO:Starting cross validation
2023-10-21 08:55:37,114:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 08:55:40,094:INFO:Calculating mean and std
2023-10-21 08:55:40,094:INFO:Creating metrics dataframe
2023-10-21 08:55:40,094:INFO:Finalizing model
2023-10-21 08:55:40,173:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005807 seconds.
2023-10-21 08:55:40,174:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 08:55:40,174:INFO:[LightGBM] [Info] Total Bins 6163
2023-10-21 08:55:40,175:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 37
2023-10-21 08:55:40,175:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-21 08:55:40,418:INFO:Uploading results into container
2023-10-21 08:55:40,418:INFO:Uploading model into container now
2023-10-21 08:55:40,418:INFO:_master_model_container: 3
2023-10-21 08:55:40,418:INFO:_display_container: 4
2023-10-21 08:55:40,418:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 08:55:40,418:INFO:create_model() successfully completed......................................
2023-10-21 08:55:40,577:INFO:SubProcess create_model() end ==================================
2023-10-21 08:55:40,578:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.836
2023-10-21 08:55:40,579:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8394
2023-10-21 08:55:40,579:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) is best model
2023-10-21 08:55:40,579:INFO:choose_better completed
2023-10-21 08:55:40,580:INFO:Creating Dashboard logs
2023-10-21 08:55:40,580:INFO:Model: Light Gradient Boosting Machine
2023-10-21 08:55:40,631:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 41, 'min_child_weight': 0.001, 'min_split_gain': 0.9, 'n_estimators': 260, 'n_jobs': -1, 'num_leaves': 70, 'objective': None, 'random_state': 123, 'reg_alpha': 2, 'reg_lambda': 3, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6}
2023-10-21 08:55:40,810:INFO:Initializing predict_model()
2023-10-21 08:55:40,810:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E3690730>, estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DCE7EAF0>)
2023-10-21 08:55:40,810:INFO:Checking exceptions
2023-10-21 08:55:40,810:INFO:Preloading libraries
2023-10-21 08:55:41,393:INFO:_master_model_container: 3
2023-10-21 08:55:41,393:INFO:_display_container: 3
2023-10-21 08:55:41,393:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-21 08:55:41,393:INFO:tune_model() successfully completed......................................
2023-10-21 08:55:41,515:INFO:Initializing finalize_model()
2023-10-21 08:55:41,515:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E3690730>, estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-21 08:55:41,515:INFO:Finalizing LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-21 08:55:41,527:INFO:Initializing create_model()
2023-10-21 08:55:41,527:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E3690730>, estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-21 08:55:41,527:INFO:Checking exceptions
2023-10-21 08:55:41,527:INFO:Importing libraries
2023-10-21 08:55:41,527:INFO:Copying training dataset
2023-10-21 08:55:41,527:INFO:Defining folds
2023-10-21 08:55:41,527:INFO:Declaring metric variables
2023-10-21 08:55:41,527:INFO:Importing untrained model
2023-10-21 08:55:41,527:INFO:Declaring custom model
2023-10-21 08:55:41,527:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 08:55:41,527:INFO:Cross validation set to False
2023-10-21 08:55:41,527:INFO:Fitting Model
2023-10-21 08:55:41,576:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 08:55:41,576:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 08:55:41,576:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 08:55:41,609:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 08:55:41,609:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 08:55:41,609:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 08:55:41,629:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006571 seconds.
2023-10-21 08:55:41,629:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 08:55:41,629:INFO:[LightGBM] [Info] Total Bins 6208
2023-10-21 08:55:41,631:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 37
2023-10-21 08:55:41,632:INFO:[LightGBM] [Info] Start training from score 96.893335
2023-10-21 08:55:42,825:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                               feature_fraction=0.4, min_child_samples=41,
                               min_split_gain=0.9, n_estimators=260, n_jobs=-1,
                               num_leaves=70, random_state=123, reg_alpha=2,
                               reg_lambda=3))])
2023-10-21 08:55:42,825:INFO:create_model() successfully completed......................................
2023-10-21 08:55:42,978:INFO:Creating Dashboard logs
2023-10-21 08:55:42,978:INFO:Model: Light Gradient Boosting Machine
2023-10-21 08:55:43,042:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 41, 'min_child_weight': 0.001, 'min_split_gain': 0.9, 'n_estimators': 260, 'n_jobs': -1, 'num_leaves': 70, 'objective': None, 'random_state': 123, 'reg_alpha': 2, 'reg_lambda': 3, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6}
2023-10-21 08:55:43,426:INFO:_master_model_container: 3
2023-10-21 08:55:43,426:INFO:_display_container: 3
2023-10-21 08:55:43,430:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                               feature_fraction=0.4, min_child_samples=41,
                               min_split_gain=0.9, n_estimators=260, n_jobs=-1,
                               num_leaves=70, random_state=123, reg_alpha=2,
                               reg_lambda=3))])
2023-10-21 08:55:43,430:INFO:finalize_model() successfully completed......................................
2023-10-21 08:55:43,560:INFO:Initializing save_model()
2023-10-21 08:55:43,560:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                               feature_fraction=0.4, min_child_samples=41,
                               min_split_gain=0.9, n_estimators=260, n_jobs=-1,
                               num_leaves=70, random_state=123, reg_alpha=2,
                               reg_lambda=3))]), model_name=final_model_for_location_B, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 08:55:43,560:INFO:Adding model into prep_pipe
2023-10-21 08:55:43,560:WARNING:Only Model saved as it was a pipeline.
2023-10-21 08:55:43,608:INFO:final_model_for_location_B.pkl saved in current working directory
2023-10-21 08:55:43,627:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                               feature_fraction=0.4, min_child_samples=41,
                               min_split_gain=0.9, n_estimators=260, n_jobs=-1,
                               num_leaves=70, random_state=123, reg_alpha=2,
                               reg_lambda=3))])
2023-10-21 08:55:43,627:INFO:save_model() successfully completed......................................
2023-10-21 08:55:43,791:INFO:PyCaret RegressionExperiment
2023-10-21 08:55:43,791:INFO:Logging name: exp_C
2023-10-21 08:55:43,791:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-21 08:55:43,791:INFO:version 3.1.0
2023-10-21 08:55:43,791:INFO:Initializing setup()
2023-10-21 08:55:43,791:INFO:self.USI: f8e8
2023-10-21 08:55:43,792:INFO:self._variable_keys: {'transform_target_param', 'exp_name_log', 'y_train', 'logging_param', 'n_jobs_param', 'X_train', 'target_param', 'USI', 'gpu_n_jobs_param', 'fold_groups_param', '_ml_usecase', 'seed', 'fold_generator', 'idx', 'html_param', 'log_plots_param', 'y', 'gpu_param', 'X_test', 'memory', 'y_test', 'data', 'X', 'exp_id', '_available_plots', 'fold_shuffle_param', 'pipeline'}
2023-10-21 08:55:43,792:INFO:Checking environment
2023-10-21 08:55:43,792:INFO:python_version: 3.8.18
2023-10-21 08:55:43,792:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-21 08:55:43,792:INFO:machine: AMD64
2023-10-21 08:55:43,792:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-21 08:55:43,792:INFO:Memory: svmem(total=16505954304, available=3406655488, percent=79.4, used=13099298816, free=3406655488)
2023-10-21 08:55:43,792:INFO:Physical Core: 8
2023-10-21 08:55:43,792:INFO:Logical Core: 16
2023-10-21 08:55:43,792:INFO:Checking libraries
2023-10-21 08:55:43,792:INFO:System:
2023-10-21 08:55:43,792:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-21 08:55:43,792:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-21 08:55:43,792:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-21 08:55:43,792:INFO:PyCaret required dependencies:
2023-10-21 08:55:43,792:INFO:                 pip: 23.3
2023-10-21 08:55:43,792:INFO:          setuptools: 68.0.0
2023-10-21 08:55:43,792:INFO:             pycaret: 3.1.0
2023-10-21 08:55:43,792:INFO:             IPython: 8.12.0
2023-10-21 08:55:43,792:INFO:          ipywidgets: 8.1.1
2023-10-21 08:55:43,792:INFO:                tqdm: 4.66.1
2023-10-21 08:55:43,792:INFO:               numpy: 1.23.5
2023-10-21 08:55:43,792:INFO:              pandas: 1.5.3
2023-10-21 08:55:43,792:INFO:              jinja2: 3.1.2
2023-10-21 08:55:43,792:INFO:               scipy: 1.10.1
2023-10-21 08:55:43,792:INFO:              joblib: 1.3.2
2023-10-21 08:55:43,792:INFO:             sklearn: 1.2.2
2023-10-21 08:55:43,792:INFO:                pyod: 1.1.0
2023-10-21 08:55:43,792:INFO:            imblearn: 0.11.0
2023-10-21 08:55:43,792:INFO:   category_encoders: 2.6.2
2023-10-21 08:55:43,792:INFO:            lightgbm: 4.1.0
2023-10-21 08:55:43,792:INFO:               numba: 0.58.1
2023-10-21 08:55:43,792:INFO:            requests: 2.31.0
2023-10-21 08:55:43,792:INFO:          matplotlib: 3.7.3
2023-10-21 08:55:43,792:INFO:          scikitplot: 0.3.7
2023-10-21 08:55:43,792:INFO:         yellowbrick: 1.5
2023-10-21 08:55:43,792:INFO:              plotly: 5.17.0
2023-10-21 08:55:43,792:INFO:    plotly-resampler: Not installed
2023-10-21 08:55:43,792:INFO:             kaleido: 0.2.1
2023-10-21 08:55:43,792:INFO:           schemdraw: 0.15
2023-10-21 08:55:43,792:INFO:         statsmodels: 0.14.0
2023-10-21 08:55:43,792:INFO:              sktime: 0.21.1
2023-10-21 08:55:43,792:INFO:               tbats: 1.1.3
2023-10-21 08:55:43,792:INFO:            pmdarima: 2.0.3
2023-10-21 08:55:43,792:INFO:              psutil: 5.9.0
2023-10-21 08:55:43,792:INFO:          markupsafe: 2.1.3
2023-10-21 08:55:43,792:INFO:             pickle5: Not installed
2023-10-21 08:55:43,792:INFO:         cloudpickle: 2.2.1
2023-10-21 08:55:43,792:INFO:         deprecation: 2.1.0
2023-10-21 08:55:43,792:INFO:              xxhash: 3.4.1
2023-10-21 08:55:43,792:INFO:           wurlitzer: Not installed
2023-10-21 08:55:43,792:INFO:PyCaret optional dependencies:
2023-10-21 08:55:43,792:INFO:                shap: Not installed
2023-10-21 08:55:43,792:INFO:           interpret: Not installed
2023-10-21 08:55:43,792:INFO:                umap: Not installed
2023-10-21 08:55:43,792:INFO:     ydata_profiling: Not installed
2023-10-21 08:55:43,792:INFO:  explainerdashboard: Not installed
2023-10-21 08:55:43,792:INFO:             autoviz: Not installed
2023-10-21 08:55:43,792:INFO:           fairlearn: Not installed
2023-10-21 08:55:43,792:INFO:          deepchecks: Not installed
2023-10-21 08:55:43,792:INFO:             xgboost: Not installed
2023-10-21 08:55:43,792:INFO:            catboost: 1.2.2
2023-10-21 08:55:43,792:INFO:              kmodes: Not installed
2023-10-21 08:55:43,792:INFO:             mlxtend: Not installed
2023-10-21 08:55:43,792:INFO:       statsforecast: Not installed
2023-10-21 08:55:43,792:INFO:        tune_sklearn: Not installed
2023-10-21 08:55:43,792:INFO:                 ray: Not installed
2023-10-21 08:55:43,792:INFO:            hyperopt: Not installed
2023-10-21 08:55:43,792:INFO:              optuna: Not installed
2023-10-21 08:55:43,792:INFO:               skopt: Not installed
2023-10-21 08:55:43,792:INFO:              mlflow: 2.7.1
2023-10-21 08:55:43,792:INFO:              gradio: Not installed
2023-10-21 08:55:43,792:INFO:             fastapi: Not installed
2023-10-21 08:55:43,792:INFO:             uvicorn: Not installed
2023-10-21 08:55:43,792:INFO:              m2cgen: Not installed
2023-10-21 08:55:43,792:INFO:           evidently: Not installed
2023-10-21 08:55:43,792:INFO:               fugue: Not installed
2023-10-21 08:55:43,792:INFO:           streamlit: Not installed
2023-10-21 08:55:43,792:INFO:             prophet: Not installed
2023-10-21 08:55:43,792:INFO:None
2023-10-21 08:55:43,792:INFO:Set up data.
2023-10-21 08:55:43,825:INFO:Set up folding strategy.
2023-10-21 08:55:43,825:INFO:Set up train/test split.
2023-10-21 08:55:43,847:INFO:Set up index.
2023-10-21 08:55:43,847:INFO:Assigning column types.
2023-10-21 08:55:43,860:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-21 08:55:43,860:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 08:55:43,873:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 08:55:43,875:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:55:43,945:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:55:43,991:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,007:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:55:44,007:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:55:44,008:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,008:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,008:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,091:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,140:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,141:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:55:44,142:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:55:44,142:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-21 08:55:44,142:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,142:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,224:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,274:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,274:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:55:44,274:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:55:44,274:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,290:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,363:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,425:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,426:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:55:44,426:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:55:44,427:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-21 08:55:44,428:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,508:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,560:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,560:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:55:44,560:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:55:44,576:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,641:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,694:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,694:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:55:44,694:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:55:44,694:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-21 08:55:44,797:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,856:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:55:44,857:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:55:44,857:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:55:44,947:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:55:45,007:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 08:55:45,008:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:55:45,009:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:55:45,009:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-21 08:55:45,095:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:55:45,149:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:55:45,149:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:55:45,235:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 08:55:45,273:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:55:45,273:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:55:45,273:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-21 08:55:45,430:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:55:45,431:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:55:45,581:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:55:45,581:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:55:45,581:INFO:Preparing preprocessing pipeline...
2023-10-21 08:55:45,581:INFO:Set up simple imputation.
2023-10-21 08:55:45,590:INFO:Set up column name cleaning.
2023-10-21 08:55:45,644:INFO:Finished creating preprocessing pipeline.
2023-10-21 08:55:45,649:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 08:55:45,649:INFO:Creating final display dataframe.
2023-10-21 08:55:45,828:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (26071, 39)
4        Transformed data shape   (26071, 39)
5   Transformed train set shape   (18249, 39)
6    Transformed test set shape    (7822, 39)
7              Numeric features            38
8      Rows with missing values         25.0%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_C
19                          USI          f8e8
2023-10-21 08:55:45,974:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:55:45,974:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:55:46,106:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 08:55:46,106:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 08:55:46,106:INFO:Logging experiment in loggers
2023-10-21 08:55:46,263:INFO:SubProcess save_model() called ==================================
2023-10-21 08:55:46,278:INFO:Initializing save_model()
2023-10-21 08:55:46,278:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmp20uec8o6\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 08:55:46,278:INFO:Adding model into prep_pipe
2023-10-21 08:55:46,278:WARNING:Only Model saved as it was a pipeline.
2023-10-21 08:55:46,280:INFO:C:\Users\thoma\AppData\Local\Temp\tmp20uec8o6\Transformation Pipeline.pkl saved in current working directory
2023-10-21 08:55:46,291:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 08:55:46,291:INFO:save_model() successfully completed......................................
2023-10-21 08:55:46,439:INFO:SubProcess save_model() end ==================================
2023-10-21 08:55:46,520:INFO:setup() successfully completed in 2.33s...............
2023-10-21 08:55:46,520:INFO:Initializing create_model()
2023-10-21 08:55:46,520:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 08:55:46,520:INFO:Checking exceptions
2023-10-21 08:55:46,526:INFO:Importing libraries
2023-10-21 08:55:46,526:INFO:Copying training dataset
2023-10-21 08:55:46,545:INFO:Defining folds
2023-10-21 08:55:46,546:INFO:Declaring metric variables
2023-10-21 08:55:46,546:INFO:Importing untrained model
2023-10-21 08:55:46,546:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 08:55:46,547:INFO:Starting cross validation
2023-10-21 08:55:46,548:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 08:55:49,622:INFO:Calculating mean and std
2023-10-21 08:55:49,622:INFO:Creating metrics dataframe
2023-10-21 08:55:49,622:INFO:Finalizing model
2023-10-21 08:55:49,728:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004660 seconds.
2023-10-21 08:55:49,728:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 08:55:49,728:INFO:[LightGBM] [Info] Total Bins 6153
2023-10-21 08:55:49,728:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 37
2023-10-21 08:55:49,728:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-21 08:55:50,025:INFO:Creating Dashboard logs
2023-10-21 08:55:50,027:INFO:Model: Light Gradient Boosting Machine
2023-10-21 08:55:50,137:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 08:55:50,336:INFO:Initializing predict_model()
2023-10-21 08:55:50,336:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209D6F36CA0>)
2023-10-21 08:55:50,337:INFO:Checking exceptions
2023-10-21 08:55:50,337:INFO:Preloading libraries
2023-10-21 08:55:50,887:INFO:Uploading results into container
2023-10-21 08:55:50,887:INFO:Uploading model into container now
2023-10-21 08:55:50,887:INFO:_master_model_container: 1
2023-10-21 08:55:50,903:INFO:_display_container: 2
2023-10-21 08:55:50,903:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 08:55:50,903:INFO:create_model() successfully completed......................................
2023-10-21 08:55:51,043:INFO:Initializing tune_model()
2023-10-21 08:55:51,043:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>)
2023-10-21 08:55:51,043:INFO:Checking exceptions
2023-10-21 08:55:51,055:INFO:Copying training dataset
2023-10-21 08:55:51,068:INFO:Checking base model
2023-10-21 08:55:51,068:INFO:Base model : Light Gradient Boosting Machine
2023-10-21 08:55:51,069:INFO:Declaring metric variables
2023-10-21 08:55:51,070:INFO:Defining Hyperparameters
2023-10-21 08:55:51,224:INFO:Tuning with n_jobs=-1
2023-10-21 08:55:51,225:INFO:Initializing RandomizedSearchCV
2023-10-21 08:56:36,065:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-21 08:56:36,068:INFO:Hyperparameter search completed
2023-10-21 08:56:36,068:INFO:SubProcess create_model() called ==================================
2023-10-21 08:56:36,069:INFO:Initializing create_model()
2023-10-21 08:56:36,069:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E421AF10>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-21 08:56:36,069:INFO:Checking exceptions
2023-10-21 08:56:36,070:INFO:Importing libraries
2023-10-21 08:56:36,070:INFO:Copying training dataset
2023-10-21 08:56:36,094:INFO:Defining folds
2023-10-21 08:56:36,094:INFO:Declaring metric variables
2023-10-21 08:56:36,094:INFO:Importing untrained model
2023-10-21 08:56:36,094:INFO:Declaring custom model
2023-10-21 08:56:36,094:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 08:56:36,097:INFO:Starting cross validation
2023-10-21 08:56:36,099:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 08:56:45,640:INFO:Calculating mean and std
2023-10-21 08:56:45,640:INFO:Creating metrics dataframe
2023-10-21 08:56:45,640:INFO:Finalizing model
2023-10-21 08:56:45,679:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 08:56:45,679:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 08:56:45,679:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 08:56:45,696:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 08:56:45,696:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 08:56:45,696:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 08:56:45,696:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002809 seconds.
2023-10-21 08:56:45,696:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 08:56:45,696:INFO:[LightGBM] [Info] Total Bins 6153
2023-10-21 08:56:45,706:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 37
2023-10-21 08:56:45,707:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-21 08:56:45,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 08:56:45,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 08:56:45,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 08:56:45,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 08:56:46,706:INFO:Uploading results into container
2023-10-21 08:56:46,706:INFO:Uploading model into container now
2023-10-21 08:56:46,706:INFO:_master_model_container: 2
2023-10-21 08:56:46,706:INFO:_display_container: 3
2023-10-21 08:56:46,706:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-21 08:56:46,706:INFO:create_model() successfully completed......................................
2023-10-21 08:56:46,873:INFO:SubProcess create_model() end ==================================
2023-10-21 08:56:46,873:INFO:choose_better activated
2023-10-21 08:56:46,873:INFO:SubProcess create_model() called ==================================
2023-10-21 08:56:46,873:INFO:Initializing create_model()
2023-10-21 08:56:46,873:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 08:56:46,873:INFO:Checking exceptions
2023-10-21 08:56:46,873:INFO:Importing libraries
2023-10-21 08:56:46,873:INFO:Copying training dataset
2023-10-21 08:56:46,896:INFO:Defining folds
2023-10-21 08:56:46,896:INFO:Declaring metric variables
2023-10-21 08:56:46,896:INFO:Importing untrained model
2023-10-21 08:56:46,896:INFO:Declaring custom model
2023-10-21 08:56:46,896:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 08:56:46,896:INFO:Starting cross validation
2023-10-21 08:56:46,896:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 08:56:49,187:INFO:Calculating mean and std
2023-10-21 08:56:49,187:INFO:Creating metrics dataframe
2023-10-21 08:56:49,187:INFO:Finalizing model
2023-10-21 08:56:49,254:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003392 seconds.
2023-10-21 08:56:49,254:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 08:56:49,254:INFO:[LightGBM] [Info] Total Bins 6153
2023-10-21 08:56:49,254:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 37
2023-10-21 08:56:49,254:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-21 08:56:49,487:INFO:Uploading results into container
2023-10-21 08:56:49,487:INFO:Uploading model into container now
2023-10-21 08:56:49,487:INFO:_master_model_container: 3
2023-10-21 08:56:49,487:INFO:_display_container: 4
2023-10-21 08:56:49,487:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 08:56:49,487:INFO:create_model() successfully completed......................................
2023-10-21 08:56:49,635:INFO:SubProcess create_model() end ==================================
2023-10-21 08:56:49,636:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.9008
2023-10-21 08:56:49,637:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8936
2023-10-21 08:56:49,637:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-21 08:56:49,637:INFO:choose_better completed
2023-10-21 08:56:49,637:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-21 08:56:49,637:INFO:Creating Dashboard logs
2023-10-21 08:56:49,637:INFO:Model: Light Gradient Boosting Machine
2023-10-21 08:56:49,698:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 08:56:49,871:INFO:Initializing predict_model()
2023-10-21 08:56:49,871:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209D6F36310>)
2023-10-21 08:56:49,871:INFO:Checking exceptions
2023-10-21 08:56:49,871:INFO:Preloading libraries
2023-10-21 08:56:50,355:INFO:_master_model_container: 3
2023-10-21 08:56:50,369:INFO:_display_container: 3
2023-10-21 08:56:50,369:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 08:56:50,369:INFO:tune_model() successfully completed......................................
2023-10-21 08:56:50,490:INFO:Initializing finalize_model()
2023-10-21 08:56:50,490:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-21 08:56:50,490:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 08:56:50,500:INFO:Initializing create_model()
2023-10-21 08:56:50,506:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-21 08:56:50,506:INFO:Checking exceptions
2023-10-21 08:56:50,506:INFO:Importing libraries
2023-10-21 08:56:50,506:INFO:Copying training dataset
2023-10-21 08:56:50,506:INFO:Defining folds
2023-10-21 08:56:50,506:INFO:Declaring metric variables
2023-10-21 08:56:50,506:INFO:Importing untrained model
2023-10-21 08:56:50,506:INFO:Declaring custom model
2023-10-21 08:56:50,506:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 08:56:50,506:INFO:Cross validation set to False
2023-10-21 08:56:50,506:INFO:Fitting Model
2023-10-21 08:56:50,579:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004880 seconds.
2023-10-21 08:56:50,579:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 08:56:50,579:INFO:[LightGBM] [Info] Total Bins 6199
2023-10-21 08:56:50,579:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 37
2023-10-21 08:56:50,579:INFO:[LightGBM] [Info] Start training from score 77.700043
2023-10-21 08:56:50,820:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-21 08:56:50,820:INFO:create_model() successfully completed......................................
2023-10-21 08:56:50,973:INFO:Creating Dashboard logs
2023-10-21 08:56:50,973:INFO:Model: Light Gradient Boosting Machine
2023-10-21 08:56:51,035:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 08:56:51,351:INFO:_master_model_container: 3
2023-10-21 08:56:51,351:INFO:_display_container: 3
2023-10-21 08:56:51,351:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-21 08:56:51,351:INFO:finalize_model() successfully completed......................................
2023-10-21 08:56:51,489:INFO:Initializing save_model()
2023-10-21 08:56:51,489:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_C, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 08:56:51,489:INFO:Adding model into prep_pipe
2023-10-21 08:56:51,489:WARNING:Only Model saved as it was a pipeline.
2023-10-21 08:56:51,504:INFO:final_model_for_location_C.pkl saved in current working directory
2023-10-21 08:56:51,520:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-21 08:56:51,520:INFO:save_model() successfully completed......................................
2023-10-21 08:56:52,850:INFO:Initializing load_model()
2023-10-21 08:56:52,851:INFO:load_model(model_name=final_model_for_location_A, platform=None, authentication=None, verbose=True)
2023-10-21 08:56:52,866:INFO:Initializing load_model()
2023-10-21 08:56:52,866:INFO:load_model(model_name=final_model_for_location_B, platform=None, authentication=None, verbose=True)
2023-10-21 08:56:52,897:INFO:Initializing load_model()
2023-10-21 08:56:52,898:INFO:load_model(model_name=final_model_for_location_C, platform=None, authentication=None, verbose=True)
2023-10-21 08:56:52,933:INFO:Initializing predict_model()
2023-10-21 08:56:52,934:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DCC6AF70>)
2023-10-21 08:56:52,934:INFO:Checking exceptions
2023-10-21 08:56:52,934:INFO:Preloading libraries
2023-10-21 08:56:52,935:INFO:Set up data.
2023-10-21 08:56:52,959:INFO:Set up index.
2023-10-21 08:56:53,157:INFO:Initializing predict_model()
2023-10-21 08:56:53,157:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                               feature_fraction=0.4, min_child_samples=41,
                               min_split_gain=0.9, n_estimators=260, n_jobs=-1,
                               num_leaves=70, random_state=123, reg_alpha=2,
                               reg_lambda=3))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209D98B08B0>)
2023-10-21 08:56:53,157:INFO:Checking exceptions
2023-10-21 08:56:53,157:INFO:Preloading libraries
2023-10-21 08:56:53,157:INFO:Set up data.
2023-10-21 08:56:53,170:INFO:Set up index.
2023-10-21 08:56:53,398:INFO:Initializing predict_model()
2023-10-21 08:56:53,398:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209D98B08B0>)
2023-10-21 08:56:53,398:INFO:Checking exceptions
2023-10-21 08:56:53,398:INFO:Preloading libraries
2023-10-21 08:56:53,399:INFO:Set up data.
2023-10-21 08:56:53,412:INFO:Set up index.
2023-10-21 08:59:42,011:INFO:Initializing load_model()
2023-10-21 08:59:42,012:INFO:load_model(model_name=final_model_for_location_A, platform=None, authentication=None, verbose=True)
2023-10-21 08:59:42,013:INFO:Initializing load_model()
2023-10-21 08:59:42,013:INFO:load_model(model_name=final_model_for_location_B, platform=None, authentication=None, verbose=True)
2023-10-21 08:59:42,040:INFO:Initializing load_model()
2023-10-21 08:59:42,041:INFO:load_model(model_name=final_model_for_location_C, platform=None, authentication=None, verbose=True)
2023-10-21 08:59:42,063:INFO:Initializing predict_model()
2023-10-21 08:59:42,063:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209D5905EE0>)
2023-10-21 08:59:42,064:INFO:Checking exceptions
2023-10-21 08:59:42,064:INFO:Preloading libraries
2023-10-21 08:59:42,064:INFO:Set up data.
2023-10-21 08:59:42,078:INFO:Set up index.
2023-10-21 08:59:42,293:INFO:Initializing predict_model()
2023-10-21 08:59:42,293:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                               feature_fraction=0.4, min_child_samples=41,
                               min_split_gain=0.9, n_estimators=260, n_jobs=-1,
                               num_leaves=70, random_state=123, reg_alpha=2,
                               reg_lambda=3))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209D5905EE0>)
2023-10-21 08:59:42,293:INFO:Checking exceptions
2023-10-21 08:59:42,293:INFO:Preloading libraries
2023-10-21 08:59:42,294:INFO:Set up data.
2023-10-21 08:59:42,297:INFO:Set up index.
2023-10-21 08:59:42,516:INFO:Initializing predict_model()
2023-10-21 08:59:42,516:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209D5905EE0>)
2023-10-21 08:59:42,516:INFO:Checking exceptions
2023-10-21 08:59:42,516:INFO:Preloading libraries
2023-10-21 08:59:42,516:INFO:Set up data.
2023-10-21 08:59:42,533:INFO:Set up index.
2023-10-21 09:00:42,577:INFO:Initializing load_model()
2023-10-21 09:00:42,577:INFO:load_model(model_name=final_model_for_location_A, platform=None, authentication=None, verbose=True)
2023-10-21 09:00:42,589:INFO:Initializing load_model()
2023-10-21 09:00:42,589:INFO:load_model(model_name=final_model_for_location_B, platform=None, authentication=None, verbose=True)
2023-10-21 09:00:42,611:INFO:Initializing load_model()
2023-10-21 09:00:42,611:INFO:load_model(model_name=final_model_for_location_C, platform=None, authentication=None, verbose=True)
2023-10-21 09:00:42,635:INFO:Initializing predict_model()
2023-10-21 09:00:42,635:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DACFEA60>)
2023-10-21 09:00:42,635:INFO:Checking exceptions
2023-10-21 09:00:42,635:INFO:Preloading libraries
2023-10-21 09:00:42,636:INFO:Set up data.
2023-10-21 09:00:42,653:INFO:Set up index.
2023-10-21 09:00:42,860:INFO:Initializing predict_model()
2023-10-21 09:00:42,861:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                               feature_fraction=0.4, min_child_samples=41,
                               min_split_gain=0.9, n_estimators=260, n_jobs=-1,
                               num_leaves=70, random_state=123, reg_alpha=2,
                               reg_lambda=3))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209E36DEE50>)
2023-10-21 09:00:42,862:INFO:Checking exceptions
2023-10-21 09:00:42,862:INFO:Preloading libraries
2023-10-21 09:00:42,862:INFO:Set up data.
2023-10-21 09:00:42,862:INFO:Set up index.
2023-10-21 09:00:43,079:INFO:Initializing predict_model()
2023-10-21 09:00:43,079:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209E370C4C0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'snow_water:kgm2', 'sun_azimuth:d',
                                             'sun_elevation:d',
                                             'super_cooled_liquid_water:kgm2',
                                             't_1000hPa:K', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209E36DEE50>)
2023-10-21 09:00:43,079:INFO:Checking exceptions
2023-10-21 09:00:43,079:INFO:Preloading libraries
2023-10-21 09:00:43,079:INFO:Set up data.
2023-10-21 09:00:43,096:INFO:Set up index.
2023-10-21 13:11:47,221:INFO:PyCaret RegressionExperiment
2023-10-21 13:11:47,221:INFO:Logging name: exp_A
2023-10-21 13:11:47,221:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-21 13:11:47,221:INFO:version 3.1.0
2023-10-21 13:11:47,221:INFO:Initializing setup()
2023-10-21 13:11:47,221:INFO:self.USI: 1fbb
2023-10-21 13:11:47,221:INFO:self._variable_keys: {'transform_target_param', 'exp_name_log', 'y_train', 'logging_param', 'n_jobs_param', 'X_train', 'target_param', 'USI', 'gpu_n_jobs_param', 'fold_groups_param', '_ml_usecase', 'seed', 'fold_generator', 'idx', 'html_param', 'log_plots_param', 'y', 'gpu_param', 'X_test', 'memory', 'y_test', 'data', 'X', 'exp_id', '_available_plots', 'fold_shuffle_param', 'pipeline'}
2023-10-21 13:11:47,221:INFO:Checking environment
2023-10-21 13:11:47,221:INFO:python_version: 3.8.18
2023-10-21 13:11:47,221:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-21 13:11:47,221:INFO:machine: AMD64
2023-10-21 13:11:47,221:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-21 13:11:47,221:INFO:Memory: svmem(total=16505954304, available=4054556672, percent=75.4, used=12451397632, free=4054556672)
2023-10-21 13:11:47,221:INFO:Physical Core: 8
2023-10-21 13:11:47,221:INFO:Logical Core: 16
2023-10-21 13:11:47,221:INFO:Checking libraries
2023-10-21 13:11:47,221:INFO:System:
2023-10-21 13:11:47,221:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-21 13:11:47,221:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-21 13:11:47,221:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-21 13:11:47,221:INFO:PyCaret required dependencies:
2023-10-21 13:11:47,221:INFO:                 pip: 23.3
2023-10-21 13:11:47,221:INFO:          setuptools: 68.0.0
2023-10-21 13:11:47,221:INFO:             pycaret: 3.1.0
2023-10-21 13:11:47,221:INFO:             IPython: 8.12.0
2023-10-21 13:11:47,221:INFO:          ipywidgets: 8.1.1
2023-10-21 13:11:47,221:INFO:                tqdm: 4.66.1
2023-10-21 13:11:47,221:INFO:               numpy: 1.23.5
2023-10-21 13:11:47,221:INFO:              pandas: 1.5.3
2023-10-21 13:11:47,221:INFO:              jinja2: 3.1.2
2023-10-21 13:11:47,221:INFO:               scipy: 1.10.1
2023-10-21 13:11:47,221:INFO:              joblib: 1.3.2
2023-10-21 13:11:47,221:INFO:             sklearn: 1.2.2
2023-10-21 13:11:47,221:INFO:                pyod: 1.1.0
2023-10-21 13:11:47,221:INFO:            imblearn: 0.11.0
2023-10-21 13:11:47,221:INFO:   category_encoders: 2.6.2
2023-10-21 13:11:47,221:INFO:            lightgbm: 4.1.0
2023-10-21 13:11:47,221:INFO:               numba: 0.58.1
2023-10-21 13:11:47,221:INFO:            requests: 2.31.0
2023-10-21 13:11:47,221:INFO:          matplotlib: 3.7.3
2023-10-21 13:11:47,221:INFO:          scikitplot: 0.3.7
2023-10-21 13:11:47,221:INFO:         yellowbrick: 1.5
2023-10-21 13:11:47,221:INFO:              plotly: 5.17.0
2023-10-21 13:11:47,221:INFO:    plotly-resampler: Not installed
2023-10-21 13:11:47,221:INFO:             kaleido: 0.2.1
2023-10-21 13:11:47,221:INFO:           schemdraw: 0.15
2023-10-21 13:11:47,221:INFO:         statsmodels: 0.14.0
2023-10-21 13:11:47,221:INFO:              sktime: 0.21.1
2023-10-21 13:11:47,221:INFO:               tbats: 1.1.3
2023-10-21 13:11:47,221:INFO:            pmdarima: 2.0.3
2023-10-21 13:11:47,221:INFO:              psutil: 5.9.0
2023-10-21 13:11:47,221:INFO:          markupsafe: 2.1.3
2023-10-21 13:11:47,221:INFO:             pickle5: Not installed
2023-10-21 13:11:47,221:INFO:         cloudpickle: 2.2.1
2023-10-21 13:11:47,221:INFO:         deprecation: 2.1.0
2023-10-21 13:11:47,221:INFO:              xxhash: 3.4.1
2023-10-21 13:11:47,221:INFO:           wurlitzer: Not installed
2023-10-21 13:11:47,221:INFO:PyCaret optional dependencies:
2023-10-21 13:11:47,221:INFO:                shap: Not installed
2023-10-21 13:11:47,221:INFO:           interpret: Not installed
2023-10-21 13:11:47,221:INFO:                umap: Not installed
2023-10-21 13:11:47,221:INFO:     ydata_profiling: Not installed
2023-10-21 13:11:47,221:INFO:  explainerdashboard: Not installed
2023-10-21 13:11:47,221:INFO:             autoviz: Not installed
2023-10-21 13:11:47,221:INFO:           fairlearn: Not installed
2023-10-21 13:11:47,221:INFO:          deepchecks: Not installed
2023-10-21 13:11:47,221:INFO:             xgboost: Not installed
2023-10-21 13:11:47,221:INFO:            catboost: 1.2.2
2023-10-21 13:11:47,221:INFO:              kmodes: Not installed
2023-10-21 13:11:47,221:INFO:             mlxtend: Not installed
2023-10-21 13:11:47,221:INFO:       statsforecast: Not installed
2023-10-21 13:11:47,221:INFO:        tune_sklearn: Not installed
2023-10-21 13:11:47,221:INFO:                 ray: Not installed
2023-10-21 13:11:47,221:INFO:            hyperopt: Not installed
2023-10-21 13:11:47,221:INFO:              optuna: Not installed
2023-10-21 13:11:47,221:INFO:               skopt: Not installed
2023-10-21 13:11:47,221:INFO:              mlflow: 2.7.1
2023-10-21 13:11:47,221:INFO:              gradio: Not installed
2023-10-21 13:11:47,221:INFO:             fastapi: Not installed
2023-10-21 13:11:47,221:INFO:             uvicorn: Not installed
2023-10-21 13:11:47,221:INFO:              m2cgen: Not installed
2023-10-21 13:11:47,221:INFO:           evidently: Not installed
2023-10-21 13:11:47,221:INFO:               fugue: Not installed
2023-10-21 13:11:47,221:INFO:           streamlit: Not installed
2023-10-21 13:11:47,221:INFO:             prophet: Not installed
2023-10-21 13:11:47,221:INFO:None
2023-10-21 13:11:47,221:INFO:Set up data.
2023-10-21 13:11:47,268:INFO:Set up folding strategy.
2023-10-21 13:11:47,268:INFO:Set up train/test split.
2023-10-21 13:11:47,312:INFO:Set up index.
2023-10-21 13:11:47,315:INFO:Assigning column types.
2023-10-21 13:11:47,347:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-21 13:11:47,347:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,347:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,347:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,442:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,512:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,512:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:11:47,512:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:11:47,512:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,521:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,521:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,616:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,679:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,679:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:11:47,679:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:11:47,679:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-21 13:11:47,695:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,695:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,790:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,838:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,838:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:11:47,838:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:11:47,854:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,854:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:11:47,949:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:11:48,013:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:11:48,028:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:11:48,028:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:11:48,028:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-21 13:11:48,044:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:11:48,145:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:11:48,194:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:11:48,195:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:11:48,195:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:11:48,206:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:11:48,279:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:11:48,329:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:11:48,329:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:11:48,329:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:11:48,329:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-21 13:11:48,428:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:11:48,487:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:11:48,487:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:11:48,488:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:11:48,578:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:11:48,629:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:11:48,629:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:11:48,629:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:11:48,629:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-21 13:11:48,730:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:11:48,787:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:11:48,787:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:11:48,884:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:11:48,942:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:11:48,942:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:11:48,943:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-21 13:11:49,113:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:11:49,114:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:11:49,283:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:11:49,283:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:11:49,283:INFO:Preparing preprocessing pipeline...
2023-10-21 13:11:49,283:INFO:Set up simple imputation.
2023-10-21 13:11:49,298:INFO:Set up column name cleaning.
2023-10-21 13:11:49,377:INFO:Finished creating preprocessing pipeline.
2023-10-21 13:11:49,393:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 13:11:49,393:INFO:Creating final display dataframe.
2023-10-21 13:11:49,720:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (34061, 50)
4        Transformed data shape   (34061, 50)
5   Transformed train set shape   (23842, 50)
6    Transformed test set shape   (10219, 50)
7              Numeric features            49
8      Rows with missing values         97.6%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_A
19                          USI          1fbb
2023-10-21 13:11:49,914:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:11:49,914:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:11:50,077:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:11:50,077:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:11:50,077:INFO:Logging experiment in loggers
2023-10-21 13:11:50,244:INFO:SubProcess save_model() called ==================================
2023-10-21 13:11:50,249:INFO:Initializing save_model()
2023-10-21 13:11:50,249:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmphuo33fa3\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 13:11:50,249:INFO:Adding model into prep_pipe
2023-10-21 13:11:50,249:WARNING:Only Model saved as it was a pipeline.
2023-10-21 13:11:50,262:INFO:C:\Users\thoma\AppData\Local\Temp\tmphuo33fa3\Transformation Pipeline.pkl saved in current working directory
2023-10-21 13:11:50,265:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 13:11:50,265:INFO:save_model() successfully completed......................................
2023-10-21 13:11:50,469:INFO:SubProcess save_model() end ==================================
2023-10-21 13:11:50,562:INFO:setup() successfully completed in 2.87s...............
2023-10-21 13:11:50,562:INFO:Initializing create_model()
2023-10-21 13:11:50,562:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6CC2520>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 13:11:50,562:INFO:Checking exceptions
2023-10-21 13:11:50,562:INFO:Importing libraries
2023-10-21 13:11:50,562:INFO:Copying training dataset
2023-10-21 13:11:50,593:INFO:Defining folds
2023-10-21 13:11:50,593:INFO:Declaring metric variables
2023-10-21 13:11:50,593:INFO:Importing untrained model
2023-10-21 13:11:50,595:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 13:11:50,595:INFO:Starting cross validation
2023-10-21 13:11:50,595:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 13:12:00,954:INFO:Calculating mean and std
2023-10-21 13:12:00,954:INFO:Creating metrics dataframe
2023-10-21 13:12:00,954:INFO:Finalizing model
2023-10-21 13:12:01,052:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006269 seconds.
2023-10-21 13:12:01,052:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 13:12:01,052:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 13:12:01,052:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 13:12:01,052:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-21 13:12:01,286:INFO:Creating Dashboard logs
2023-10-21 13:12:01,286:INFO:Model: Light Gradient Boosting Machine
2023-10-21 13:12:01,386:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 13:12:01,586:INFO:Initializing predict_model()
2023-10-21 13:12:01,586:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6CC2520>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DA6C63A0>)
2023-10-21 13:12:01,586:INFO:Checking exceptions
2023-10-21 13:12:01,586:INFO:Preloading libraries
2023-10-21 13:12:02,250:INFO:Uploading results into container
2023-10-21 13:12:02,250:INFO:Uploading model into container now
2023-10-21 13:12:02,250:INFO:_master_model_container: 1
2023-10-21 13:12:02,250:INFO:_display_container: 2
2023-10-21 13:12:02,250:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 13:12:02,250:INFO:create_model() successfully completed......................................
2023-10-21 13:12:02,433:INFO:Initializing tune_model()
2023-10-21 13:12:02,433:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6CC2520>)
2023-10-21 13:12:02,433:INFO:Checking exceptions
2023-10-21 13:12:02,434:INFO:Copying training dataset
2023-10-21 13:12:02,460:INFO:Checking base model
2023-10-21 13:12:02,461:INFO:Base model : Light Gradient Boosting Machine
2023-10-21 13:12:02,461:INFO:Declaring metric variables
2023-10-21 13:12:02,461:INFO:Defining Hyperparameters
2023-10-21 13:12:02,666:INFO:Tuning with n_jobs=-1
2023-10-21 13:12:02,667:INFO:Initializing RandomizedSearchCV
2023-10-21 13:13:00,964:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-21 13:13:00,964:INFO:Hyperparameter search completed
2023-10-21 13:13:00,964:INFO:SubProcess create_model() called ==================================
2023-10-21 13:13:00,967:INFO:Initializing create_model()
2023-10-21 13:13:00,968:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6CC2520>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209DAB65AF0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-21 13:13:00,968:INFO:Checking exceptions
2023-10-21 13:13:00,968:INFO:Importing libraries
2023-10-21 13:13:00,968:INFO:Copying training dataset
2023-10-21 13:13:01,003:INFO:Defining folds
2023-10-21 13:13:01,004:INFO:Declaring metric variables
2023-10-21 13:13:01,004:INFO:Importing untrained model
2023-10-21 13:13:01,004:INFO:Declaring custom model
2023-10-21 13:13:01,006:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 13:13:01,006:INFO:Starting cross validation
2023-10-21 13:13:01,008:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 13:13:10,401:INFO:Calculating mean and std
2023-10-21 13:13:10,401:INFO:Creating metrics dataframe
2023-10-21 13:13:10,401:INFO:Finalizing model
2023-10-21 13:13:10,476:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 13:13:10,476:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 13:13:10,476:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 13:13:10,514:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 13:13:10,514:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 13:13:10,514:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 13:13:10,529:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007281 seconds.
2023-10-21 13:13:10,529:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 13:13:10,529:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 13:13:10,529:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 13:13:10,529:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-21 13:13:11,809:INFO:Uploading results into container
2023-10-21 13:13:11,809:INFO:Uploading model into container now
2023-10-21 13:13:11,809:INFO:_master_model_container: 2
2023-10-21 13:13:11,809:INFO:_display_container: 3
2023-10-21 13:13:11,809:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-21 13:13:11,809:INFO:create_model() successfully completed......................................
2023-10-21 13:13:12,024:INFO:SubProcess create_model() end ==================================
2023-10-21 13:13:12,024:INFO:choose_better activated
2023-10-21 13:13:12,025:INFO:SubProcess create_model() called ==================================
2023-10-21 13:13:12,026:INFO:Initializing create_model()
2023-10-21 13:13:12,026:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6CC2520>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 13:13:12,026:INFO:Checking exceptions
2023-10-21 13:13:12,026:INFO:Importing libraries
2023-10-21 13:13:12,026:INFO:Copying training dataset
2023-10-21 13:13:12,046:INFO:Defining folds
2023-10-21 13:13:12,046:INFO:Declaring metric variables
2023-10-21 13:13:12,046:INFO:Importing untrained model
2023-10-21 13:13:12,046:INFO:Declaring custom model
2023-10-21 13:13:12,046:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 13:13:12,046:INFO:Starting cross validation
2023-10-21 13:13:12,046:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 13:13:15,290:INFO:Calculating mean and std
2023-10-21 13:13:15,290:INFO:Creating metrics dataframe
2023-10-21 13:13:15,290:INFO:Finalizing model
2023-10-21 13:13:15,389:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006151 seconds.
2023-10-21 13:13:15,389:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 13:13:15,389:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 13:13:15,389:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 13:13:15,389:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-21 13:13:15,641:INFO:Uploading results into container
2023-10-21 13:13:15,642:INFO:Uploading model into container now
2023-10-21 13:13:15,643:INFO:_master_model_container: 3
2023-10-21 13:13:15,643:INFO:_display_container: 4
2023-10-21 13:13:15,644:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 13:13:15,644:INFO:create_model() successfully completed......................................
2023-10-21 13:13:15,847:INFO:SubProcess create_model() end ==================================
2023-10-21 13:13:15,848:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8716
2023-10-21 13:13:15,848:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8712
2023-10-21 13:13:15,849:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-21 13:13:15,849:INFO:choose_better completed
2023-10-21 13:13:15,849:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-21 13:13:15,849:INFO:Creating Dashboard logs
2023-10-21 13:13:15,850:INFO:Model: Light Gradient Boosting Machine
2023-10-21 13:13:15,909:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 13:13:16,081:INFO:Initializing predict_model()
2023-10-21 13:13:16,081:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6CC2520>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DA6C6550>)
2023-10-21 13:13:16,081:INFO:Checking exceptions
2023-10-21 13:13:16,081:INFO:Preloading libraries
2023-10-21 13:13:16,704:INFO:_master_model_container: 3
2023-10-21 13:13:16,704:INFO:_display_container: 3
2023-10-21 13:13:16,704:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 13:13:16,704:INFO:tune_model() successfully completed......................................
2023-10-21 13:13:16,888:INFO:Initializing finalize_model()
2023-10-21 13:13:16,888:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6CC2520>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-21 13:13:16,888:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 13:13:16,888:INFO:Initializing create_model()
2023-10-21 13:13:16,888:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D6CC2520>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-21 13:13:16,888:INFO:Checking exceptions
2023-10-21 13:13:16,904:INFO:Importing libraries
2023-10-21 13:13:16,904:INFO:Copying training dataset
2023-10-21 13:13:16,904:INFO:Defining folds
2023-10-21 13:13:16,904:INFO:Declaring metric variables
2023-10-21 13:13:16,904:INFO:Importing untrained model
2023-10-21 13:13:16,904:INFO:Declaring custom model
2023-10-21 13:13:16,904:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 13:13:16,904:INFO:Cross validation set to False
2023-10-21 13:13:16,904:INFO:Fitting Model
2023-10-21 13:13:17,020:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007974 seconds.
2023-10-21 13:13:17,020:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 13:13:17,020:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-21 13:13:17,020:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-21 13:13:17,020:INFO:[LightGBM] [Info] Start training from score 631.011165
2023-10-21 13:13:17,376:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-21 13:13:17,376:INFO:create_model() successfully completed......................................
2023-10-21 13:13:17,574:INFO:Creating Dashboard logs
2023-10-21 13:13:17,574:INFO:Model: Light Gradient Boosting Machine
2023-10-21 13:13:17,622:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 13:13:17,990:INFO:_master_model_container: 3
2023-10-21 13:13:17,990:INFO:_display_container: 3
2023-10-21 13:13:18,006:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-21 13:13:18,006:INFO:finalize_model() successfully completed......................................
2023-10-21 13:13:18,186:INFO:Initializing save_model()
2023-10-21 13:13:18,186:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_A, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 13:13:18,186:INFO:Adding model into prep_pipe
2023-10-21 13:13:18,186:WARNING:Only Model saved as it was a pipeline.
2023-10-21 13:13:18,210:INFO:final_model_for_location_A.pkl saved in current working directory
2023-10-21 13:13:18,225:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-21 13:13:18,225:INFO:save_model() successfully completed......................................
2023-10-21 13:13:18,439:INFO:PyCaret RegressionExperiment
2023-10-21 13:13:18,439:INFO:Logging name: exp_B
2023-10-21 13:13:18,439:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-21 13:13:18,439:INFO:version 3.1.0
2023-10-21 13:13:18,439:INFO:Initializing setup()
2023-10-21 13:13:18,439:INFO:self.USI: 9f74
2023-10-21 13:13:18,439:INFO:self._variable_keys: {'transform_target_param', 'exp_name_log', 'y_train', 'logging_param', 'n_jobs_param', 'X_train', 'target_param', 'USI', 'gpu_n_jobs_param', 'fold_groups_param', '_ml_usecase', 'seed', 'fold_generator', 'idx', 'html_param', 'log_plots_param', 'y', 'gpu_param', 'X_test', 'memory', 'y_test', 'data', 'X', 'exp_id', '_available_plots', 'fold_shuffle_param', 'pipeline'}
2023-10-21 13:13:18,439:INFO:Checking environment
2023-10-21 13:13:18,439:INFO:python_version: 3.8.18
2023-10-21 13:13:18,439:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-21 13:13:18,439:INFO:machine: AMD64
2023-10-21 13:13:18,439:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-21 13:13:18,439:INFO:Memory: svmem(total=16505954304, available=3044720640, percent=81.6, used=13461233664, free=3044720640)
2023-10-21 13:13:18,439:INFO:Physical Core: 8
2023-10-21 13:13:18,439:INFO:Logical Core: 16
2023-10-21 13:13:18,439:INFO:Checking libraries
2023-10-21 13:13:18,439:INFO:System:
2023-10-21 13:13:18,439:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-21 13:13:18,439:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-21 13:13:18,439:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-21 13:13:18,439:INFO:PyCaret required dependencies:
2023-10-21 13:13:18,439:INFO:                 pip: 23.3
2023-10-21 13:13:18,439:INFO:          setuptools: 68.0.0
2023-10-21 13:13:18,439:INFO:             pycaret: 3.1.0
2023-10-21 13:13:18,439:INFO:             IPython: 8.12.0
2023-10-21 13:13:18,439:INFO:          ipywidgets: 8.1.1
2023-10-21 13:13:18,439:INFO:                tqdm: 4.66.1
2023-10-21 13:13:18,439:INFO:               numpy: 1.23.5
2023-10-21 13:13:18,439:INFO:              pandas: 1.5.3
2023-10-21 13:13:18,439:INFO:              jinja2: 3.1.2
2023-10-21 13:13:18,439:INFO:               scipy: 1.10.1
2023-10-21 13:13:18,439:INFO:              joblib: 1.3.2
2023-10-21 13:13:18,439:INFO:             sklearn: 1.2.2
2023-10-21 13:13:18,439:INFO:                pyod: 1.1.0
2023-10-21 13:13:18,439:INFO:            imblearn: 0.11.0
2023-10-21 13:13:18,439:INFO:   category_encoders: 2.6.2
2023-10-21 13:13:18,439:INFO:            lightgbm: 4.1.0
2023-10-21 13:13:18,439:INFO:               numba: 0.58.1
2023-10-21 13:13:18,439:INFO:            requests: 2.31.0
2023-10-21 13:13:18,439:INFO:          matplotlib: 3.7.3
2023-10-21 13:13:18,439:INFO:          scikitplot: 0.3.7
2023-10-21 13:13:18,439:INFO:         yellowbrick: 1.5
2023-10-21 13:13:18,439:INFO:              plotly: 5.17.0
2023-10-21 13:13:18,439:INFO:    plotly-resampler: Not installed
2023-10-21 13:13:18,439:INFO:             kaleido: 0.2.1
2023-10-21 13:13:18,439:INFO:           schemdraw: 0.15
2023-10-21 13:13:18,439:INFO:         statsmodels: 0.14.0
2023-10-21 13:13:18,439:INFO:              sktime: 0.21.1
2023-10-21 13:13:18,439:INFO:               tbats: 1.1.3
2023-10-21 13:13:18,439:INFO:            pmdarima: 2.0.3
2023-10-21 13:13:18,439:INFO:              psutil: 5.9.0
2023-10-21 13:13:18,439:INFO:          markupsafe: 2.1.3
2023-10-21 13:13:18,439:INFO:             pickle5: Not installed
2023-10-21 13:13:18,439:INFO:         cloudpickle: 2.2.1
2023-10-21 13:13:18,439:INFO:         deprecation: 2.1.0
2023-10-21 13:13:18,439:INFO:              xxhash: 3.4.1
2023-10-21 13:13:18,439:INFO:           wurlitzer: Not installed
2023-10-21 13:13:18,439:INFO:PyCaret optional dependencies:
2023-10-21 13:13:18,439:INFO:                shap: Not installed
2023-10-21 13:13:18,439:INFO:           interpret: Not installed
2023-10-21 13:13:18,439:INFO:                umap: Not installed
2023-10-21 13:13:18,439:INFO:     ydata_profiling: Not installed
2023-10-21 13:13:18,439:INFO:  explainerdashboard: Not installed
2023-10-21 13:13:18,439:INFO:             autoviz: Not installed
2023-10-21 13:13:18,439:INFO:           fairlearn: Not installed
2023-10-21 13:13:18,439:INFO:          deepchecks: Not installed
2023-10-21 13:13:18,439:INFO:             xgboost: Not installed
2023-10-21 13:13:18,439:INFO:            catboost: 1.2.2
2023-10-21 13:13:18,439:INFO:              kmodes: Not installed
2023-10-21 13:13:18,439:INFO:             mlxtend: Not installed
2023-10-21 13:13:18,439:INFO:       statsforecast: Not installed
2023-10-21 13:13:18,439:INFO:        tune_sklearn: Not installed
2023-10-21 13:13:18,439:INFO:                 ray: Not installed
2023-10-21 13:13:18,439:INFO:            hyperopt: Not installed
2023-10-21 13:13:18,439:INFO:              optuna: Not installed
2023-10-21 13:13:18,439:INFO:               skopt: Not installed
2023-10-21 13:13:18,439:INFO:              mlflow: 2.7.1
2023-10-21 13:13:18,439:INFO:              gradio: Not installed
2023-10-21 13:13:18,439:INFO:             fastapi: Not installed
2023-10-21 13:13:18,439:INFO:             uvicorn: Not installed
2023-10-21 13:13:18,439:INFO:              m2cgen: Not installed
2023-10-21 13:13:18,439:INFO:           evidently: Not installed
2023-10-21 13:13:18,439:INFO:               fugue: Not installed
2023-10-21 13:13:18,439:INFO:           streamlit: Not installed
2023-10-21 13:13:18,439:INFO:             prophet: Not installed
2023-10-21 13:13:18,439:INFO:None
2023-10-21 13:13:18,439:INFO:Set up data.
2023-10-21 13:13:18,479:INFO:Set up folding strategy.
2023-10-21 13:13:18,479:INFO:Set up train/test split.
2023-10-21 13:13:18,507:INFO:Set up index.
2023-10-21 13:13:18,509:INFO:Assigning column types.
2023-10-21 13:13:18,533:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-21 13:13:18,533:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 13:13:18,539:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 13:13:18,545:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:13:18,627:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:13:18,679:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:13:18,680:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:13:18,680:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:13:18,681:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 13:13:18,686:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 13:13:18,692:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:13:18,772:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:13:18,819:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:13:18,819:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:13:18,819:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:13:18,819:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-21 13:13:18,819:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 13:13:18,835:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:13:18,902:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:13:18,955:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:13:18,955:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:13:18,955:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:13:18,955:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 13:13:18,971:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:13:19,053:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:13:19,106:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:13:19,107:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:13:19,107:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:13:19,108:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-21 13:13:19,119:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:13:19,191:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:13:19,256:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:13:19,257:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:13:19,257:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:13:19,269:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:13:19,350:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:13:19,392:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:13:19,392:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:13:19,392:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:13:19,392:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-21 13:13:19,495:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:13:19,561:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:13:19,562:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:13:19,562:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:13:19,666:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:13:19,719:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:13:19,719:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:13:19,720:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:13:19,720:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-21 13:13:19,804:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:13:19,870:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:13:19,870:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:13:19,975:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:13:20,035:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:13:20,036:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:13:20,036:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-21 13:13:20,190:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:13:20,190:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:13:20,336:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:13:20,336:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:13:20,350:INFO:Preparing preprocessing pipeline...
2023-10-21 13:13:20,351:INFO:Set up simple imputation.
2023-10-21 13:13:20,355:INFO:Set up column name cleaning.
2023-10-21 13:13:20,419:INFO:Finished creating preprocessing pipeline.
2023-10-21 13:13:20,423:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 13:13:20,423:INFO:Creating final display dataframe.
2023-10-21 13:13:20,619:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (32819, 50)
4        Transformed data shape   (32819, 50)
5   Transformed train set shape   (22973, 50)
6    Transformed test set shape    (9846, 50)
7              Numeric features            49
8      Rows with missing values         95.9%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_B
19                          USI          9f74
2023-10-21 13:13:20,771:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:13:20,771:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:13:20,917:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:13:20,917:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:13:20,917:INFO:Logging experiment in loggers
2023-10-21 13:13:21,032:INFO:SubProcess save_model() called ==================================
2023-10-21 13:13:21,032:INFO:Initializing save_model()
2023-10-21 13:13:21,032:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmpiturykv6\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 13:13:21,032:INFO:Adding model into prep_pipe
2023-10-21 13:13:21,032:WARNING:Only Model saved as it was a pipeline.
2023-10-21 13:13:21,047:INFO:C:\Users\thoma\AppData\Local\Temp\tmpiturykv6\Transformation Pipeline.pkl saved in current working directory
2023-10-21 13:13:21,047:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 13:13:21,047:INFO:save_model() successfully completed......................................
2023-10-21 13:13:21,235:INFO:SubProcess save_model() end ==================================
2023-10-21 13:13:21,287:INFO:setup() successfully completed in 2.48s...............
2023-10-21 13:13:21,287:INFO:Initializing create_model()
2023-10-21 13:13:21,287:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAB65940>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 13:13:21,287:INFO:Checking exceptions
2023-10-21 13:13:21,303:INFO:Importing libraries
2023-10-21 13:13:21,303:INFO:Copying training dataset
2023-10-21 13:13:21,327:INFO:Defining folds
2023-10-21 13:13:21,327:INFO:Declaring metric variables
2023-10-21 13:13:21,327:INFO:Importing untrained model
2023-10-21 13:13:21,327:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 13:13:21,327:INFO:Starting cross validation
2023-10-21 13:13:21,327:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 13:13:24,373:INFO:Calculating mean and std
2023-10-21 13:13:24,373:INFO:Creating metrics dataframe
2023-10-21 13:13:24,373:INFO:Finalizing model
2023-10-21 13:13:24,472:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005085 seconds.
2023-10-21 13:13:24,472:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 13:13:24,473:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 13:13:24,473:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 13:13:24,474:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-21 13:13:24,733:INFO:Creating Dashboard logs
2023-10-21 13:13:24,733:INFO:Model: Light Gradient Boosting Machine
2023-10-21 13:13:24,831:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 13:13:25,049:INFO:Initializing predict_model()
2023-10-21 13:13:25,049:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAB65940>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209D98B01F0>)
2023-10-21 13:13:25,049:INFO:Checking exceptions
2023-10-21 13:13:25,049:INFO:Preloading libraries
2023-10-21 13:13:25,816:INFO:Uploading results into container
2023-10-21 13:13:25,816:INFO:Uploading model into container now
2023-10-21 13:13:25,816:INFO:_master_model_container: 1
2023-10-21 13:13:25,816:INFO:_display_container: 2
2023-10-21 13:13:25,816:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 13:13:25,816:INFO:create_model() successfully completed......................................
2023-10-21 13:13:26,033:INFO:Initializing tune_model()
2023-10-21 13:13:26,033:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAB65940>)
2023-10-21 13:13:26,033:INFO:Checking exceptions
2023-10-21 13:13:26,048:INFO:Copying training dataset
2023-10-21 13:13:26,065:INFO:Checking base model
2023-10-21 13:13:26,065:INFO:Base model : Light Gradient Boosting Machine
2023-10-21 13:13:26,065:INFO:Declaring metric variables
2023-10-21 13:13:26,065:INFO:Defining Hyperparameters
2023-10-21 13:13:26,271:INFO:Tuning with n_jobs=-1
2023-10-21 13:13:26,271:INFO:Initializing RandomizedSearchCV
2023-10-21 13:14:17,771:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-21 13:14:17,771:INFO:Hyperparameter search completed
2023-10-21 13:14:17,771:INFO:SubProcess create_model() called ==================================
2023-10-21 13:14:17,771:INFO:Initializing create_model()
2023-10-21 13:14:17,771:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAB65940>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209DCBE0D90>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-21 13:14:17,771:INFO:Checking exceptions
2023-10-21 13:14:17,771:INFO:Importing libraries
2023-10-21 13:14:17,771:INFO:Copying training dataset
2023-10-21 13:14:17,788:INFO:Defining folds
2023-10-21 13:14:17,788:INFO:Declaring metric variables
2023-10-21 13:14:17,788:INFO:Importing untrained model
2023-10-21 13:14:17,788:INFO:Declaring custom model
2023-10-21 13:14:17,803:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 13:14:17,803:INFO:Starting cross validation
2023-10-21 13:14:17,804:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 13:14:27,280:INFO:Calculating mean and std
2023-10-21 13:14:27,280:INFO:Creating metrics dataframe
2023-10-21 13:14:27,280:INFO:Finalizing model
2023-10-21 13:14:27,346:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 13:14:27,346:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 13:14:27,346:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 13:14:27,380:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 13:14:27,380:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 13:14:27,380:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 13:14:27,397:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005985 seconds.
2023-10-21 13:14:27,397:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 13:14:27,397:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 13:14:27,397:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 13:14:27,397:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-21 13:14:28,840:INFO:Uploading results into container
2023-10-21 13:14:28,840:INFO:Uploading model into container now
2023-10-21 13:14:28,840:INFO:_master_model_container: 2
2023-10-21 13:14:28,840:INFO:_display_container: 3
2023-10-21 13:14:28,840:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-21 13:14:28,840:INFO:create_model() successfully completed......................................
2023-10-21 13:14:29,060:INFO:SubProcess create_model() end ==================================
2023-10-21 13:14:29,060:INFO:choose_better activated
2023-10-21 13:14:29,060:INFO:SubProcess create_model() called ==================================
2023-10-21 13:14:29,060:INFO:Initializing create_model()
2023-10-21 13:14:29,060:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAB65940>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 13:14:29,060:INFO:Checking exceptions
2023-10-21 13:14:29,060:INFO:Importing libraries
2023-10-21 13:14:29,060:INFO:Copying training dataset
2023-10-21 13:14:29,091:INFO:Defining folds
2023-10-21 13:14:29,091:INFO:Declaring metric variables
2023-10-21 13:14:29,091:INFO:Importing untrained model
2023-10-21 13:14:29,091:INFO:Declaring custom model
2023-10-21 13:14:29,091:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 13:14:29,091:INFO:Starting cross validation
2023-10-21 13:14:29,091:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 13:14:31,610:INFO:Calculating mean and std
2023-10-21 13:14:31,610:INFO:Creating metrics dataframe
2023-10-21 13:14:31,610:INFO:Finalizing model
2023-10-21 13:14:31,693:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004877 seconds.
2023-10-21 13:14:31,693:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 13:14:31,693:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 13:14:31,693:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 13:14:31,693:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-21 13:14:31,926:INFO:Uploading results into container
2023-10-21 13:14:31,926:INFO:Uploading model into container now
2023-10-21 13:14:31,936:INFO:_master_model_container: 3
2023-10-21 13:14:31,936:INFO:_display_container: 4
2023-10-21 13:14:31,936:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 13:14:31,936:INFO:create_model() successfully completed......................................
2023-10-21 13:14:32,126:INFO:SubProcess create_model() end ==================================
2023-10-21 13:14:32,137:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8523
2023-10-21 13:14:32,137:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8523
2023-10-21 13:14:32,137:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-21 13:14:32,137:INFO:choose_better completed
2023-10-21 13:14:32,137:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-21 13:14:32,137:INFO:Creating Dashboard logs
2023-10-21 13:14:32,137:INFO:Model: Light Gradient Boosting Machine
2023-10-21 13:14:32,195:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 13:14:32,392:INFO:Initializing predict_model()
2023-10-21 13:14:32,392:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAB65940>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209D98B0AF0>)
2023-10-21 13:14:32,392:INFO:Checking exceptions
2023-10-21 13:14:32,392:INFO:Preloading libraries
2023-10-21 13:14:33,041:INFO:_master_model_container: 3
2023-10-21 13:14:33,041:INFO:_display_container: 3
2023-10-21 13:14:33,041:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 13:14:33,041:INFO:tune_model() successfully completed......................................
2023-10-21 13:14:33,208:INFO:Initializing finalize_model()
2023-10-21 13:14:33,208:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAB65940>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-21 13:14:33,208:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 13:14:33,225:INFO:Initializing create_model()
2023-10-21 13:14:33,225:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DAB65940>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-21 13:14:33,225:INFO:Checking exceptions
2023-10-21 13:14:33,225:INFO:Importing libraries
2023-10-21 13:14:33,225:INFO:Copying training dataset
2023-10-21 13:14:33,238:INFO:Defining folds
2023-10-21 13:14:33,238:INFO:Declaring metric variables
2023-10-21 13:14:33,238:INFO:Importing untrained model
2023-10-21 13:14:33,238:INFO:Declaring custom model
2023-10-21 13:14:33,238:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 13:14:33,240:INFO:Cross validation set to False
2023-10-21 13:14:33,240:INFO:Fitting Model
2023-10-21 13:14:33,366:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009484 seconds.
2023-10-21 13:14:33,366:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 13:14:33,367:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-21 13:14:33,368:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-21 13:14:33,369:INFO:[LightGBM] [Info] Start training from score 96.893335
2023-10-21 13:14:33,658:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-21 13:14:33,658:INFO:create_model() successfully completed......................................
2023-10-21 13:14:33,874:INFO:Creating Dashboard logs
2023-10-21 13:14:33,874:INFO:Model: Light Gradient Boosting Machine
2023-10-21 13:14:33,942:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 13:14:34,358:INFO:_master_model_container: 3
2023-10-21 13:14:34,358:INFO:_display_container: 3
2023-10-21 13:14:34,373:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-21 13:14:34,373:INFO:finalize_model() successfully completed......................................
2023-10-21 13:14:34,557:INFO:Initializing save_model()
2023-10-21 13:14:34,557:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_B, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 13:14:34,557:INFO:Adding model into prep_pipe
2023-10-21 13:14:34,557:WARNING:Only Model saved as it was a pipeline.
2023-10-21 13:14:34,557:INFO:final_model_for_location_B.pkl saved in current working directory
2023-10-21 13:14:34,574:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-21 13:14:34,574:INFO:save_model() successfully completed......................................
2023-10-21 13:14:34,790:INFO:PyCaret RegressionExperiment
2023-10-21 13:14:34,790:INFO:Logging name: exp_C
2023-10-21 13:14:34,790:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-21 13:14:34,790:INFO:version 3.1.0
2023-10-21 13:14:34,790:INFO:Initializing setup()
2023-10-21 13:14:34,790:INFO:self.USI: f13b
2023-10-21 13:14:34,790:INFO:self._variable_keys: {'transform_target_param', 'exp_name_log', 'y_train', 'logging_param', 'n_jobs_param', 'X_train', 'target_param', 'USI', 'gpu_n_jobs_param', 'fold_groups_param', '_ml_usecase', 'seed', 'fold_generator', 'idx', 'html_param', 'log_plots_param', 'y', 'gpu_param', 'X_test', 'memory', 'y_test', 'data', 'X', 'exp_id', '_available_plots', 'fold_shuffle_param', 'pipeline'}
2023-10-21 13:14:34,790:INFO:Checking environment
2023-10-21 13:14:34,790:INFO:python_version: 3.8.18
2023-10-21 13:14:34,790:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-21 13:14:34,790:INFO:machine: AMD64
2023-10-21 13:14:34,790:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-21 13:14:34,790:INFO:Memory: svmem(total=16505954304, available=3200471040, percent=80.6, used=13305483264, free=3200471040)
2023-10-21 13:14:34,790:INFO:Physical Core: 8
2023-10-21 13:14:34,790:INFO:Logical Core: 16
2023-10-21 13:14:34,790:INFO:Checking libraries
2023-10-21 13:14:34,790:INFO:System:
2023-10-21 13:14:34,790:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-21 13:14:34,790:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-21 13:14:34,790:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-21 13:14:34,790:INFO:PyCaret required dependencies:
2023-10-21 13:14:34,790:INFO:                 pip: 23.3
2023-10-21 13:14:34,790:INFO:          setuptools: 68.0.0
2023-10-21 13:14:34,790:INFO:             pycaret: 3.1.0
2023-10-21 13:14:34,790:INFO:             IPython: 8.12.0
2023-10-21 13:14:34,790:INFO:          ipywidgets: 8.1.1
2023-10-21 13:14:34,790:INFO:                tqdm: 4.66.1
2023-10-21 13:14:34,790:INFO:               numpy: 1.23.5
2023-10-21 13:14:34,790:INFO:              pandas: 1.5.3
2023-10-21 13:14:34,790:INFO:              jinja2: 3.1.2
2023-10-21 13:14:34,790:INFO:               scipy: 1.10.1
2023-10-21 13:14:34,790:INFO:              joblib: 1.3.2
2023-10-21 13:14:34,790:INFO:             sklearn: 1.2.2
2023-10-21 13:14:34,790:INFO:                pyod: 1.1.0
2023-10-21 13:14:34,790:INFO:            imblearn: 0.11.0
2023-10-21 13:14:34,790:INFO:   category_encoders: 2.6.2
2023-10-21 13:14:34,790:INFO:            lightgbm: 4.1.0
2023-10-21 13:14:34,790:INFO:               numba: 0.58.1
2023-10-21 13:14:34,790:INFO:            requests: 2.31.0
2023-10-21 13:14:34,790:INFO:          matplotlib: 3.7.3
2023-10-21 13:14:34,790:INFO:          scikitplot: 0.3.7
2023-10-21 13:14:34,790:INFO:         yellowbrick: 1.5
2023-10-21 13:14:34,790:INFO:              plotly: 5.17.0
2023-10-21 13:14:34,790:INFO:    plotly-resampler: Not installed
2023-10-21 13:14:34,790:INFO:             kaleido: 0.2.1
2023-10-21 13:14:34,790:INFO:           schemdraw: 0.15
2023-10-21 13:14:34,790:INFO:         statsmodels: 0.14.0
2023-10-21 13:14:34,790:INFO:              sktime: 0.21.1
2023-10-21 13:14:34,790:INFO:               tbats: 1.1.3
2023-10-21 13:14:34,790:INFO:            pmdarima: 2.0.3
2023-10-21 13:14:34,790:INFO:              psutil: 5.9.0
2023-10-21 13:14:34,790:INFO:          markupsafe: 2.1.3
2023-10-21 13:14:34,790:INFO:             pickle5: Not installed
2023-10-21 13:14:34,790:INFO:         cloudpickle: 2.2.1
2023-10-21 13:14:34,790:INFO:         deprecation: 2.1.0
2023-10-21 13:14:34,790:INFO:              xxhash: 3.4.1
2023-10-21 13:14:34,790:INFO:           wurlitzer: Not installed
2023-10-21 13:14:34,790:INFO:PyCaret optional dependencies:
2023-10-21 13:14:34,790:INFO:                shap: Not installed
2023-10-21 13:14:34,790:INFO:           interpret: Not installed
2023-10-21 13:14:34,790:INFO:                umap: Not installed
2023-10-21 13:14:34,790:INFO:     ydata_profiling: Not installed
2023-10-21 13:14:34,790:INFO:  explainerdashboard: Not installed
2023-10-21 13:14:34,790:INFO:             autoviz: Not installed
2023-10-21 13:14:34,790:INFO:           fairlearn: Not installed
2023-10-21 13:14:34,790:INFO:          deepchecks: Not installed
2023-10-21 13:14:34,790:INFO:             xgboost: Not installed
2023-10-21 13:14:34,790:INFO:            catboost: 1.2.2
2023-10-21 13:14:34,790:INFO:              kmodes: Not installed
2023-10-21 13:14:34,790:INFO:             mlxtend: Not installed
2023-10-21 13:14:34,790:INFO:       statsforecast: Not installed
2023-10-21 13:14:34,790:INFO:        tune_sklearn: Not installed
2023-10-21 13:14:34,790:INFO:                 ray: Not installed
2023-10-21 13:14:34,790:INFO:            hyperopt: Not installed
2023-10-21 13:14:34,790:INFO:              optuna: Not installed
2023-10-21 13:14:34,790:INFO:               skopt: Not installed
2023-10-21 13:14:34,790:INFO:              mlflow: 2.7.1
2023-10-21 13:14:34,790:INFO:              gradio: Not installed
2023-10-21 13:14:34,790:INFO:             fastapi: Not installed
2023-10-21 13:14:34,790:INFO:             uvicorn: Not installed
2023-10-21 13:14:34,790:INFO:              m2cgen: Not installed
2023-10-21 13:14:34,790:INFO:           evidently: Not installed
2023-10-21 13:14:34,790:INFO:               fugue: Not installed
2023-10-21 13:14:34,790:INFO:           streamlit: Not installed
2023-10-21 13:14:34,790:INFO:             prophet: Not installed
2023-10-21 13:14:34,790:INFO:None
2023-10-21 13:14:34,790:INFO:Set up data.
2023-10-21 13:14:34,824:INFO:Set up folding strategy.
2023-10-21 13:14:34,824:INFO:Set up train/test split.
2023-10-21 13:14:34,852:INFO:Set up index.
2023-10-21 13:14:34,853:INFO:Assigning column types.
2023-10-21 13:14:34,857:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-21 13:14:34,857:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 13:14:34,873:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 13:14:34,873:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:14:34,956:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,007:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,007:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:14:35,007:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:14:35,007:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,007:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,007:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,090:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,147:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,148:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:14:35,148:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:14:35,148:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-21 13:14:35,154:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,156:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,223:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,273:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,287:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:14:35,287:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:14:35,290:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,290:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,373:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,423:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,423:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:14:35,423:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:14:35,423:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-21 13:14:35,445:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,506:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,556:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,572:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:14:35,573:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:14:35,573:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,656:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,706:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,706:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:14:35,706:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:14:35,706:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-21 13:14:35,790:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,847:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,848:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:14:35,848:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:14:35,923:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,988:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 13:14:35,988:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:14:35,989:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:14:35,989:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-21 13:14:36,072:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:14:36,123:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:14:36,123:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:14:36,206:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 13:14:36,255:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:14:36,255:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:14:36,255:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-21 13:14:36,406:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:14:36,406:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:14:36,551:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:14:36,552:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:14:36,553:INFO:Preparing preprocessing pipeline...
2023-10-21 13:14:36,553:INFO:Set up simple imputation.
2023-10-21 13:14:36,556:INFO:Set up column name cleaning.
2023-10-21 13:14:36,606:INFO:Finished creating preprocessing pipeline.
2023-10-21 13:14:36,606:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 13:14:36,606:INFO:Creating final display dataframe.
2023-10-21 13:14:36,789:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (26071, 50)
4        Transformed data shape   (26071, 50)
5   Transformed train set shape   (18249, 50)
6    Transformed test set shape    (7822, 50)
7              Numeric features            49
8      Rows with missing values         95.9%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_C
19                          USI          f13b
2023-10-21 13:14:36,941:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:14:36,941:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:14:37,088:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 13:14:37,088:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 13:14:37,088:INFO:Logging experiment in loggers
2023-10-21 13:14:37,205:INFO:SubProcess save_model() called ==================================
2023-10-21 13:14:37,205:INFO:Initializing save_model()
2023-10-21 13:14:37,205:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmpokoacz1e\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 13:14:37,205:INFO:Adding model into prep_pipe
2023-10-21 13:14:37,205:WARNING:Only Model saved as it was a pipeline.
2023-10-21 13:14:37,221:INFO:C:\Users\thoma\AppData\Local\Temp\tmpokoacz1e\Transformation Pipeline.pkl saved in current working directory
2023-10-21 13:14:37,221:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 13:14:37,221:INFO:save_model() successfully completed......................................
2023-10-21 13:14:37,404:INFO:SubProcess save_model() end ==================================
2023-10-21 13:14:37,455:INFO:setup() successfully completed in 2.3s...............
2023-10-21 13:14:37,455:INFO:Initializing create_model()
2023-10-21 13:14:37,455:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCD99880>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 13:14:37,455:INFO:Checking exceptions
2023-10-21 13:14:37,455:INFO:Importing libraries
2023-10-21 13:14:37,455:INFO:Copying training dataset
2023-10-21 13:14:37,471:INFO:Defining folds
2023-10-21 13:14:37,471:INFO:Declaring metric variables
2023-10-21 13:14:37,471:INFO:Importing untrained model
2023-10-21 13:14:37,471:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 13:14:37,471:INFO:Starting cross validation
2023-10-21 13:14:37,471:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 13:14:40,103:INFO:Calculating mean and std
2023-10-21 13:14:40,103:INFO:Creating metrics dataframe
2023-10-21 13:14:40,103:INFO:Finalizing model
2023-10-21 13:14:40,186:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004403 seconds.
2023-10-21 13:14:40,186:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 13:14:40,186:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-21 13:14:40,186:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-21 13:14:40,186:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-21 13:14:40,436:INFO:Creating Dashboard logs
2023-10-21 13:14:40,436:INFO:Model: Light Gradient Boosting Machine
2023-10-21 13:14:40,534:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 13:14:40,702:INFO:Initializing predict_model()
2023-10-21 13:14:40,702:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCD99880>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DB43D670>)
2023-10-21 13:14:40,702:INFO:Checking exceptions
2023-10-21 13:14:40,702:INFO:Preloading libraries
2023-10-21 13:14:41,285:INFO:Uploading results into container
2023-10-21 13:14:41,285:INFO:Uploading model into container now
2023-10-21 13:14:41,285:INFO:_master_model_container: 1
2023-10-21 13:14:41,285:INFO:_display_container: 2
2023-10-21 13:14:41,285:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 13:14:41,285:INFO:create_model() successfully completed......................................
2023-10-21 13:14:41,469:INFO:Initializing tune_model()
2023-10-21 13:14:41,469:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCD99880>)
2023-10-21 13:14:41,469:INFO:Checking exceptions
2023-10-21 13:14:41,485:INFO:Copying training dataset
2023-10-21 13:14:41,502:INFO:Checking base model
2023-10-21 13:14:41,502:INFO:Base model : Light Gradient Boosting Machine
2023-10-21 13:14:41,502:INFO:Declaring metric variables
2023-10-21 13:14:41,502:INFO:Defining Hyperparameters
2023-10-21 13:14:41,668:INFO:Tuning with n_jobs=-1
2023-10-21 13:14:41,668:INFO:Initializing RandomizedSearchCV
2023-10-21 13:15:23,268:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-21 13:15:23,268:INFO:Hyperparameter search completed
2023-10-21 13:15:23,268:INFO:SubProcess create_model() called ==================================
2023-10-21 13:15:23,268:INFO:Initializing create_model()
2023-10-21 13:15:23,268:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCD99880>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209E3955D00>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-21 13:15:23,268:INFO:Checking exceptions
2023-10-21 13:15:23,268:INFO:Importing libraries
2023-10-21 13:15:23,268:INFO:Copying training dataset
2023-10-21 13:15:23,306:INFO:Defining folds
2023-10-21 13:15:23,306:INFO:Declaring metric variables
2023-10-21 13:15:23,307:INFO:Importing untrained model
2023-10-21 13:15:23,307:INFO:Declaring custom model
2023-10-21 13:15:23,308:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 13:15:23,309:INFO:Starting cross validation
2023-10-21 13:15:23,310:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 13:15:32,027:INFO:Calculating mean and std
2023-10-21 13:15:32,027:INFO:Creating metrics dataframe
2023-10-21 13:15:32,027:INFO:Finalizing model
2023-10-21 13:15:32,074:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 13:15:32,074:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 13:15:32,074:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 13:15:32,093:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 13:15:32,093:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 13:15:32,093:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 13:15:32,110:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004872 seconds.
2023-10-21 13:15:32,110:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 13:15:32,110:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-21 13:15:32,110:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-21 13:15:32,110:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-21 13:15:32,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 13:15:32,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 13:15:32,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 13:15:32,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 13:15:32,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 13:15:32,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 13:15:32,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 13:15:32,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 13:15:33,242:INFO:Uploading results into container
2023-10-21 13:15:33,242:INFO:Uploading model into container now
2023-10-21 13:15:33,242:INFO:_master_model_container: 2
2023-10-21 13:15:33,242:INFO:_display_container: 3
2023-10-21 13:15:33,242:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-21 13:15:33,242:INFO:create_model() successfully completed......................................
2023-10-21 13:15:33,474:INFO:SubProcess create_model() end ==================================
2023-10-21 13:15:33,475:INFO:choose_better activated
2023-10-21 13:15:33,475:INFO:SubProcess create_model() called ==================================
2023-10-21 13:15:33,475:INFO:Initializing create_model()
2023-10-21 13:15:33,475:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCD99880>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 13:15:33,475:INFO:Checking exceptions
2023-10-21 13:15:33,475:INFO:Importing libraries
2023-10-21 13:15:33,475:INFO:Copying training dataset
2023-10-21 13:15:33,492:INFO:Defining folds
2023-10-21 13:15:33,492:INFO:Declaring metric variables
2023-10-21 13:15:33,492:INFO:Importing untrained model
2023-10-21 13:15:33,492:INFO:Declaring custom model
2023-10-21 13:15:33,492:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 13:15:33,492:INFO:Starting cross validation
2023-10-21 13:15:33,492:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 13:15:36,256:INFO:Calculating mean and std
2023-10-21 13:15:36,256:INFO:Creating metrics dataframe
2023-10-21 13:15:36,256:INFO:Finalizing model
2023-10-21 13:15:36,338:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005240 seconds.
2023-10-21 13:15:36,338:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 13:15:36,339:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-21 13:15:36,339:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-21 13:15:36,340:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-21 13:15:36,648:INFO:Uploading results into container
2023-10-21 13:15:36,649:INFO:Uploading model into container now
2023-10-21 13:15:36,650:INFO:_master_model_container: 3
2023-10-21 13:15:36,650:INFO:_display_container: 4
2023-10-21 13:15:36,651:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 13:15:36,651:INFO:create_model() successfully completed......................................
2023-10-21 13:15:36,856:INFO:SubProcess create_model() end ==================================
2023-10-21 13:15:36,856:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.905
2023-10-21 13:15:36,856:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8993
2023-10-21 13:15:36,856:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-21 13:15:36,856:INFO:choose_better completed
2023-10-21 13:15:36,856:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-21 13:15:36,856:INFO:Creating Dashboard logs
2023-10-21 13:15:36,856:INFO:Model: Light Gradient Boosting Machine
2023-10-21 13:15:36,922:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 13:15:37,122:INFO:Initializing predict_model()
2023-10-21 13:15:37,122:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCD99880>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DB43D040>)
2023-10-21 13:15:37,122:INFO:Checking exceptions
2023-10-21 13:15:37,122:INFO:Preloading libraries
2023-10-21 13:15:37,752:INFO:_master_model_container: 3
2023-10-21 13:15:37,753:INFO:_display_container: 3
2023-10-21 13:15:37,754:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 13:15:37,754:INFO:tune_model() successfully completed......................................
2023-10-21 13:15:37,943:INFO:Initializing finalize_model()
2023-10-21 13:15:37,943:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCD99880>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-21 13:15:37,943:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 13:15:37,955:INFO:Initializing create_model()
2023-10-21 13:15:37,955:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCD99880>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-21 13:15:37,955:INFO:Checking exceptions
2023-10-21 13:15:37,955:INFO:Importing libraries
2023-10-21 13:15:37,955:INFO:Copying training dataset
2023-10-21 13:15:37,955:INFO:Defining folds
2023-10-21 13:15:37,955:INFO:Declaring metric variables
2023-10-21 13:15:37,955:INFO:Importing untrained model
2023-10-21 13:15:37,955:INFO:Declaring custom model
2023-10-21 13:15:37,955:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 13:15:37,955:INFO:Cross validation set to False
2023-10-21 13:15:37,955:INFO:Fitting Model
2023-10-21 13:15:38,055:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005569 seconds.
2023-10-21 13:15:38,055:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 13:15:38,055:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-21 13:15:38,055:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-21 13:15:38,055:INFO:[LightGBM] [Info] Start training from score 77.700043
2023-10-21 13:15:38,336:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-21 13:15:38,336:INFO:create_model() successfully completed......................................
2023-10-21 13:15:38,522:INFO:Creating Dashboard logs
2023-10-21 13:15:38,522:INFO:Model: Light Gradient Boosting Machine
2023-10-21 13:15:38,587:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 13:15:38,955:INFO:_master_model_container: 3
2023-10-21 13:15:38,955:INFO:_display_container: 3
2023-10-21 13:15:38,972:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-21 13:15:38,972:INFO:finalize_model() successfully completed......................................
2023-10-21 13:15:39,172:INFO:Initializing save_model()
2023-10-21 13:15:39,172:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_C, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 13:15:39,172:INFO:Adding model into prep_pipe
2023-10-21 13:15:39,172:WARNING:Only Model saved as it was a pipeline.
2023-10-21 13:15:39,187:INFO:final_model_for_location_C.pkl saved in current working directory
2023-10-21 13:15:39,187:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-21 13:15:39,187:INFO:save_model() successfully completed......................................
2023-10-21 13:47:22,068:INFO:Initializing predict_model()
2023-10-21 13:47:22,068:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCD99880>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209D9514EE0>)
2023-10-21 13:47:22,068:INFO:Checking exceptions
2023-10-21 13:47:22,068:INFO:Preloading libraries
2023-10-21 13:47:22,068:INFO:Set up data.
2023-10-21 13:47:22,102:INFO:Set up index.
2023-10-21 14:11:14,187:INFO:Initializing predict_model()
2023-10-21 14:11:14,187:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCD99880>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209D95198B0>)
2023-10-21 14:11:14,187:INFO:Checking exceptions
2023-10-21 14:11:14,187:INFO:Preloading libraries
2023-10-21 14:11:14,196:INFO:Set up data.
2023-10-21 14:11:14,225:INFO:Set up index.
2023-10-21 14:24:13,932:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\base\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals
  warnings.warn("Maximum Likelihood optimization failed to "

2023-10-21 14:27:19,293:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.
  self._init_dates(dates, freq)

2023-10-21 14:27:19,294:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.
  self._init_dates(dates, freq)

2023-10-21 14:27:19,295:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.
  self._init_dates(dates, freq)

2023-10-21 14:31:24,554:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.
  self._init_dates(dates, freq)

2023-10-21 14:31:24,554:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.
  self._init_dates(dates, freq)

2023-10-21 14:31:24,554:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.
  self._init_dates(dates, freq)

2023-10-21 15:42:01,872:INFO:Initializing predict_model()
2023-10-21 15:42:01,872:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCD99880>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209D9519310>)
2023-10-21 15:42:01,872:INFO:Checking exceptions
2023-10-21 15:42:01,874:INFO:Preloading libraries
2023-10-21 15:42:01,877:INFO:Set up data.
2023-10-21 15:42:01,912:INFO:Set up index.
2023-10-21 15:42:45,886:INFO:PyCaret RegressionExperiment
2023-10-21 15:42:45,886:INFO:Logging name: exp_A
2023-10-21 15:42:45,886:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-21 15:42:45,886:INFO:version 3.1.0
2023-10-21 15:42:45,886:INFO:Initializing setup()
2023-10-21 15:42:45,886:INFO:self.USI: af10
2023-10-21 15:42:45,887:INFO:self._variable_keys: {'transform_target_param', 'exp_name_log', 'y_train', 'logging_param', 'n_jobs_param', 'X_train', 'target_param', 'USI', 'gpu_n_jobs_param', 'fold_groups_param', '_ml_usecase', 'seed', 'fold_generator', 'idx', 'html_param', 'log_plots_param', 'y', 'gpu_param', 'X_test', 'memory', 'y_test', 'data', 'X', 'exp_id', '_available_plots', 'fold_shuffle_param', 'pipeline'}
2023-10-21 15:42:45,887:INFO:Checking environment
2023-10-21 15:42:45,887:INFO:python_version: 3.8.18
2023-10-21 15:42:45,887:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-21 15:42:45,887:INFO:machine: AMD64
2023-10-21 15:42:45,887:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-21 15:42:45,887:INFO:Memory: svmem(total=16505954304, available=4074913792, percent=75.3, used=12431040512, free=4074913792)
2023-10-21 15:42:45,887:INFO:Physical Core: 8
2023-10-21 15:42:45,887:INFO:Logical Core: 16
2023-10-21 15:42:45,887:INFO:Checking libraries
2023-10-21 15:42:45,888:INFO:System:
2023-10-21 15:42:45,888:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-21 15:42:45,888:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-21 15:42:45,888:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-21 15:42:45,888:INFO:PyCaret required dependencies:
2023-10-21 15:42:45,888:INFO:                 pip: 23.3
2023-10-21 15:42:45,888:INFO:          setuptools: 68.0.0
2023-10-21 15:42:45,888:INFO:             pycaret: 3.1.0
2023-10-21 15:42:45,888:INFO:             IPython: 8.12.0
2023-10-21 15:42:45,888:INFO:          ipywidgets: 8.1.1
2023-10-21 15:42:45,888:INFO:                tqdm: 4.66.1
2023-10-21 15:42:45,888:INFO:               numpy: 1.23.5
2023-10-21 15:42:45,888:INFO:              pandas: 1.5.3
2023-10-21 15:42:45,888:INFO:              jinja2: 3.1.2
2023-10-21 15:42:45,888:INFO:               scipy: 1.10.1
2023-10-21 15:42:45,889:INFO:              joblib: 1.3.2
2023-10-21 15:42:45,889:INFO:             sklearn: 1.2.2
2023-10-21 15:42:45,889:INFO:                pyod: 1.1.0
2023-10-21 15:42:45,889:INFO:            imblearn: 0.11.0
2023-10-21 15:42:45,889:INFO:   category_encoders: 2.6.2
2023-10-21 15:42:45,889:INFO:            lightgbm: 4.1.0
2023-10-21 15:42:45,889:INFO:               numba: 0.58.1
2023-10-21 15:42:45,889:INFO:            requests: 2.31.0
2023-10-21 15:42:45,889:INFO:          matplotlib: 3.7.3
2023-10-21 15:42:45,889:INFO:          scikitplot: 0.3.7
2023-10-21 15:42:45,889:INFO:         yellowbrick: 1.5
2023-10-21 15:42:45,889:INFO:              plotly: 5.17.0
2023-10-21 15:42:45,889:INFO:    plotly-resampler: Not installed
2023-10-21 15:42:45,889:INFO:             kaleido: 0.2.1
2023-10-21 15:42:45,889:INFO:           schemdraw: 0.15
2023-10-21 15:42:45,890:INFO:         statsmodels: 0.14.0
2023-10-21 15:42:45,890:INFO:              sktime: 0.21.1
2023-10-21 15:42:45,890:INFO:               tbats: 1.1.3
2023-10-21 15:42:45,890:INFO:            pmdarima: 2.0.3
2023-10-21 15:42:45,890:INFO:              psutil: 5.9.0
2023-10-21 15:42:45,890:INFO:          markupsafe: 2.1.3
2023-10-21 15:42:45,890:INFO:             pickle5: Not installed
2023-10-21 15:42:45,890:INFO:         cloudpickle: 2.2.1
2023-10-21 15:42:45,890:INFO:         deprecation: 2.1.0
2023-10-21 15:42:45,890:INFO:              xxhash: 3.4.1
2023-10-21 15:42:45,890:INFO:           wurlitzer: Not installed
2023-10-21 15:42:45,890:INFO:PyCaret optional dependencies:
2023-10-21 15:42:45,890:INFO:                shap: Not installed
2023-10-21 15:42:45,890:INFO:           interpret: Not installed
2023-10-21 15:42:45,890:INFO:                umap: Not installed
2023-10-21 15:42:45,890:INFO:     ydata_profiling: Not installed
2023-10-21 15:42:45,890:INFO:  explainerdashboard: Not installed
2023-10-21 15:42:45,890:INFO:             autoviz: Not installed
2023-10-21 15:42:45,890:INFO:           fairlearn: Not installed
2023-10-21 15:42:45,892:INFO:          deepchecks: Not installed
2023-10-21 15:42:45,892:INFO:             xgboost: Not installed
2023-10-21 15:42:45,892:INFO:            catboost: 1.2.2
2023-10-21 15:42:45,892:INFO:              kmodes: Not installed
2023-10-21 15:42:45,892:INFO:             mlxtend: Not installed
2023-10-21 15:42:45,892:INFO:       statsforecast: Not installed
2023-10-21 15:42:45,892:INFO:        tune_sklearn: Not installed
2023-10-21 15:42:45,892:INFO:                 ray: Not installed
2023-10-21 15:42:45,892:INFO:            hyperopt: Not installed
2023-10-21 15:42:45,892:INFO:              optuna: Not installed
2023-10-21 15:42:45,892:INFO:               skopt: Not installed
2023-10-21 15:42:45,892:INFO:              mlflow: 2.7.1
2023-10-21 15:42:45,892:INFO:              gradio: Not installed
2023-10-21 15:42:45,892:INFO:             fastapi: Not installed
2023-10-21 15:42:45,892:INFO:             uvicorn: Not installed
2023-10-21 15:42:45,892:INFO:              m2cgen: Not installed
2023-10-21 15:42:45,892:INFO:           evidently: Not installed
2023-10-21 15:42:45,892:INFO:               fugue: Not installed
2023-10-21 15:42:45,893:INFO:           streamlit: Not installed
2023-10-21 15:42:45,893:INFO:             prophet: Not installed
2023-10-21 15:42:45,893:INFO:None
2023-10-21 15:42:45,893:INFO:Set up data.
2023-10-21 15:42:45,932:INFO:Set up folding strategy.
2023-10-21 15:42:45,932:INFO:Set up train/test split.
2023-10-21 15:42:45,960:INFO:Set up index.
2023-10-21 15:42:45,963:INFO:Assigning column types.
2023-10-21 15:42:45,989:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-21 15:42:45,990:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 15:42:45,995:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,001:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,100:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,148:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,149:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:42:46,150:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:42:46,150:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,156:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,161:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,240:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,288:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,288:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:42:46,288:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:42:46,289:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-21 15:42:46,295:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,300:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,378:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,426:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,426:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:42:46,427:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:42:46,433:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,438:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,527:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,579:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,579:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:42:46,580:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:42:46,580:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-21 15:42:46,584:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,662:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,710:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,710:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:42:46,710:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:42:46,725:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,804:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,852:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,852:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:42:46,852:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:42:46,852:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-21 15:42:46,936:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,987:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:42:46,988:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:42:46,988:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:42:47,067:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:42:47,115:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:42:47,115:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:42:47,115:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:42:47,115:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-21 15:42:47,210:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:42:47,257:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:42:47,257:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:42:47,337:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:42:47,402:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:42:47,402:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:42:47,402:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-21 15:42:47,531:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:42:47,531:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:42:47,670:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:42:47,670:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:42:47,670:INFO:Preparing preprocessing pipeline...
2023-10-21 15:42:47,670:INFO:Set up simple imputation.
2023-10-21 15:42:47,670:INFO:Set up column name cleaning.
2023-10-21 15:42:47,732:INFO:Finished creating preprocessing pipeline.
2023-10-21 15:42:47,732:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 15:42:47,732:INFO:Creating final display dataframe.
2023-10-21 15:42:47,952:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (34061, 50)
4        Transformed data shape   (34061, 50)
5   Transformed train set shape   (23842, 50)
6    Transformed test set shape   (10219, 50)
7              Numeric features            49
8      Rows with missing values         97.6%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_A
19                          USI          af10
2023-10-21 15:42:48,101:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:42:48,101:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:42:48,231:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:42:48,231:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:42:48,231:INFO:Logging experiment in loggers
2023-10-21 15:42:48,346:INFO:SubProcess save_model() called ==================================
2023-10-21 15:42:48,346:INFO:Initializing save_model()
2023-10-21 15:42:48,346:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmp1lfcq50a\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 15:42:48,346:INFO:Adding model into prep_pipe
2023-10-21 15:42:48,346:WARNING:Only Model saved as it was a pipeline.
2023-10-21 15:42:48,362:INFO:C:\Users\thoma\AppData\Local\Temp\tmp1lfcq50a\Transformation Pipeline.pkl saved in current working directory
2023-10-21 15:42:48,368:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 15:42:48,369:INFO:save_model() successfully completed......................................
2023-10-21 15:42:48,618:INFO:SubProcess save_model() end ==================================
2023-10-21 15:42:48,702:INFO:setup() successfully completed in 2.35s...............
2023-10-21 15:42:48,702:INFO:Initializing create_model()
2023-10-21 15:42:48,702:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D936C850>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 15:42:48,702:INFO:Checking exceptions
2023-10-21 15:42:48,702:INFO:Importing libraries
2023-10-21 15:42:48,702:INFO:Copying training dataset
2023-10-21 15:42:48,734:INFO:Defining folds
2023-10-21 15:42:48,734:INFO:Declaring metric variables
2023-10-21 15:42:48,734:INFO:Importing untrained model
2023-10-21 15:42:48,736:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 15:42:48,736:INFO:Starting cross validation
2023-10-21 15:42:48,736:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 15:42:58,941:INFO:Calculating mean and std
2023-10-21 15:42:58,941:INFO:Creating metrics dataframe
2023-10-21 15:42:58,941:INFO:Finalizing model
2023-10-21 15:42:59,042:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005359 seconds.
2023-10-21 15:42:59,042:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:42:59,042:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 15:42:59,042:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 15:42:59,042:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-21 15:42:59,307:INFO:Creating Dashboard logs
2023-10-21 15:42:59,307:INFO:Model: Light Gradient Boosting Machine
2023-10-21 15:42:59,390:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 15:42:59,575:INFO:Initializing predict_model()
2023-10-21 15:42:59,575:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D936C850>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DB02D9D0>)
2023-10-21 15:42:59,575:INFO:Checking exceptions
2023-10-21 15:42:59,575:INFO:Preloading libraries
2023-10-21 15:43:00,271:INFO:Uploading results into container
2023-10-21 15:43:00,273:INFO:Uploading model into container now
2023-10-21 15:43:00,273:INFO:_master_model_container: 1
2023-10-21 15:43:00,273:INFO:_display_container: 2
2023-10-21 15:43:00,273:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 15:43:00,273:INFO:create_model() successfully completed......................................
2023-10-21 15:43:00,538:INFO:Initializing tune_model()
2023-10-21 15:43:00,538:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D936C850>)
2023-10-21 15:43:00,539:INFO:Checking exceptions
2023-10-21 15:43:00,540:INFO:Copying training dataset
2023-10-21 15:43:00,569:INFO:Checking base model
2023-10-21 15:43:00,569:INFO:Base model : Light Gradient Boosting Machine
2023-10-21 15:43:00,569:INFO:Declaring metric variables
2023-10-21 15:43:00,570:INFO:Defining Hyperparameters
2023-10-21 15:43:00,790:INFO:Tuning with n_jobs=-1
2023-10-21 15:43:00,790:INFO:Initializing RandomizedSearchCV
2023-10-21 15:43:50,349:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-21 15:43:50,349:INFO:Hyperparameter search completed
2023-10-21 15:43:50,349:INFO:SubProcess create_model() called ==================================
2023-10-21 15:43:50,349:INFO:Initializing create_model()
2023-10-21 15:43:50,349:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D936C850>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209DB287A60>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-21 15:43:50,349:INFO:Checking exceptions
2023-10-21 15:43:50,349:INFO:Importing libraries
2023-10-21 15:43:50,349:INFO:Copying training dataset
2023-10-21 15:43:50,382:INFO:Defining folds
2023-10-21 15:43:50,383:INFO:Declaring metric variables
2023-10-21 15:43:50,383:INFO:Importing untrained model
2023-10-21 15:43:50,383:INFO:Declaring custom model
2023-10-21 15:43:50,384:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 15:43:50,385:INFO:Starting cross validation
2023-10-21 15:43:50,386:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 15:43:58,073:INFO:Calculating mean and std
2023-10-21 15:43:58,075:INFO:Creating metrics dataframe
2023-10-21 15:43:58,075:INFO:Finalizing model
2023-10-21 15:43:58,137:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 15:43:58,137:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 15:43:58,137:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 15:43:58,175:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 15:43:58,175:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 15:43:58,175:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 15:43:58,175:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005496 seconds.
2023-10-21 15:43:58,175:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:43:58,175:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 15:43:58,175:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 15:43:58,191:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-21 15:43:59,341:INFO:Uploading results into container
2023-10-21 15:43:59,341:INFO:Uploading model into container now
2023-10-21 15:43:59,356:INFO:_master_model_container: 2
2023-10-21 15:43:59,357:INFO:_display_container: 3
2023-10-21 15:43:59,358:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-21 15:43:59,359:INFO:create_model() successfully completed......................................
2023-10-21 15:43:59,624:INFO:SubProcess create_model() end ==================================
2023-10-21 15:43:59,624:INFO:choose_better activated
2023-10-21 15:43:59,624:INFO:SubProcess create_model() called ==================================
2023-10-21 15:43:59,624:INFO:Initializing create_model()
2023-10-21 15:43:59,624:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D936C850>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 15:43:59,624:INFO:Checking exceptions
2023-10-21 15:43:59,624:INFO:Importing libraries
2023-10-21 15:43:59,624:INFO:Copying training dataset
2023-10-21 15:43:59,660:INFO:Defining folds
2023-10-21 15:43:59,660:INFO:Declaring metric variables
2023-10-21 15:43:59,660:INFO:Importing untrained model
2023-10-21 15:43:59,660:INFO:Declaring custom model
2023-10-21 15:43:59,661:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 15:43:59,662:INFO:Starting cross validation
2023-10-21 15:43:59,663:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 15:44:02,905:INFO:Calculating mean and std
2023-10-21 15:44:02,905:INFO:Creating metrics dataframe
2023-10-21 15:44:02,905:INFO:Finalizing model
2023-10-21 15:44:03,005:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006647 seconds.
2023-10-21 15:44:03,005:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:03,005:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 15:44:03,005:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 15:44:03,005:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-21 15:44:03,288:INFO:Uploading results into container
2023-10-21 15:44:03,304:INFO:Uploading model into container now
2023-10-21 15:44:03,304:INFO:_master_model_container: 3
2023-10-21 15:44:03,304:INFO:_display_container: 4
2023-10-21 15:44:03,304:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 15:44:03,304:INFO:create_model() successfully completed......................................
2023-10-21 15:44:03,588:INFO:SubProcess create_model() end ==================================
2023-10-21 15:44:03,588:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8716
2023-10-21 15:44:03,588:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8712
2023-10-21 15:44:03,588:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-21 15:44:03,588:INFO:choose_better completed
2023-10-21 15:44:03,588:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-21 15:44:03,588:INFO:Creating Dashboard logs
2023-10-21 15:44:03,588:INFO:Model: Light Gradient Boosting Machine
2023-10-21 15:44:03,654:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 15:44:03,842:INFO:Initializing predict_model()
2023-10-21 15:44:03,842:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D936C850>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DB02D310>)
2023-10-21 15:44:03,842:INFO:Checking exceptions
2023-10-21 15:44:03,842:INFO:Preloading libraries
2023-10-21 15:44:04,503:INFO:_master_model_container: 3
2023-10-21 15:44:04,503:INFO:_display_container: 3
2023-10-21 15:44:04,503:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 15:44:04,503:INFO:tune_model() successfully completed......................................
2023-10-21 15:44:04,720:INFO:Initializing ensemble_model()
2023-10-21 15:44:04,720:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D936C850>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-21 15:44:04,720:INFO:Checking exceptions
2023-10-21 15:44:04,744:INFO:Importing libraries
2023-10-21 15:44:04,744:INFO:Copying training dataset
2023-10-21 15:44:04,744:INFO:Checking base model
2023-10-21 15:44:04,744:INFO:Base model : Light Gradient Boosting Machine
2023-10-21 15:44:04,744:INFO:Importing untrained ensembler
2023-10-21 15:44:04,744:INFO:Ensemble method set to Bagging
2023-10-21 15:44:04,744:INFO:SubProcess create_model() called ==================================
2023-10-21 15:44:04,744:INFO:Initializing create_model()
2023-10-21 15:44:04,744:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D936C850>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209DB287A60>, model_only=True, return_train_score=False, kwargs={})
2023-10-21 15:44:04,744:INFO:Checking exceptions
2023-10-21 15:44:04,744:INFO:Importing libraries
2023-10-21 15:44:04,744:INFO:Copying training dataset
2023-10-21 15:44:04,771:INFO:Defining folds
2023-10-21 15:44:04,771:INFO:Declaring metric variables
2023-10-21 15:44:04,771:INFO:Importing untrained model
2023-10-21 15:44:04,771:INFO:Declaring custom model
2023-10-21 15:44:04,771:INFO:Bagging Regressor Imported successfully
2023-10-21 15:44:04,771:INFO:Starting cross validation
2023-10-21 15:44:04,775:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 15:44:28,750:INFO:Calculating mean and std
2023-10-21 15:44:28,750:INFO:Creating metrics dataframe
2023-10-21 15:44:28,750:INFO:Finalizing model
2023-10-21 15:44:28,833:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004075 seconds.
2023-10-21 15:44:28,833:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:28,833:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 15:44:28,833:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 15:44:28,833:INFO:[LightGBM] [Info] Start training from score 626.831517
2023-10-21 15:44:29,083:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005246 seconds.
2023-10-21 15:44:29,083:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:29,083:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 15:44:29,083:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 15:44:29,083:INFO:[LightGBM] [Info] Start training from score 640.013980
2023-10-21 15:44:29,333:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005388 seconds.
2023-10-21 15:44:29,333:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:29,333:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 15:44:29,333:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 15:44:29,333:INFO:[LightGBM] [Info] Start training from score 623.946930
2023-10-21 15:44:29,583:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005223 seconds.
2023-10-21 15:44:29,583:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:29,583:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 15:44:29,583:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 15:44:29,583:INFO:[LightGBM] [Info] Start training from score 632.335152
2023-10-21 15:44:29,832:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004364 seconds.
2023-10-21 15:44:29,832:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:29,832:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 15:44:29,832:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 15:44:29,848:INFO:[LightGBM] [Info] Start training from score 620.070240
2023-10-21 15:44:30,165:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005504 seconds.
2023-10-21 15:44:30,165:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:30,165:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 15:44:30,165:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 15:44:30,165:INFO:[LightGBM] [Info] Start training from score 635.137343
2023-10-21 15:44:30,465:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006071 seconds.
2023-10-21 15:44:30,465:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:30,465:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 15:44:30,465:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 15:44:30,465:INFO:[LightGBM] [Info] Start training from score 620.066941
2023-10-21 15:44:30,765:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006645 seconds.
2023-10-21 15:44:30,765:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:30,765:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 15:44:30,765:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 15:44:30,765:INFO:[LightGBM] [Info] Start training from score 623.069874
2023-10-21 15:44:31,031:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004510 seconds.
2023-10-21 15:44:31,031:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:31,047:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 15:44:31,047:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 15:44:31,048:INFO:[LightGBM] [Info] Start training from score 633.817057
2023-10-21 15:44:31,315:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005548 seconds.
2023-10-21 15:44:31,315:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:31,315:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-21 15:44:31,315:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-21 15:44:31,315:INFO:[LightGBM] [Info] Start training from score 641.113408
2023-10-21 15:44:31,564:INFO:Uploading results into container
2023-10-21 15:44:31,564:INFO:Uploading model into container now
2023-10-21 15:44:31,564:INFO:_master_model_container: 4
2023-10-21 15:44:31,564:INFO:_display_container: 4
2023-10-21 15:44:31,564:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-21 15:44:31,564:INFO:create_model() successfully completed......................................
2023-10-21 15:44:31,815:INFO:SubProcess create_model() end ==================================
2023-10-21 15:44:31,815:INFO:Creating Dashboard logs
2023-10-21 15:44:31,815:INFO:Model: Bagging Regressor
2023-10-21 15:44:31,897:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-21 15:44:32,114:INFO:Initializing predict_model()
2023-10-21 15:44:32,114:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D936C850>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020986AFBCA0>)
2023-10-21 15:44:32,114:INFO:Checking exceptions
2023-10-21 15:44:32,114:INFO:Preloading libraries
2023-10-21 15:44:32,963:INFO:_master_model_container: 4
2023-10-21 15:44:32,963:INFO:_display_container: 4
2023-10-21 15:44:32,963:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-21 15:44:32,963:INFO:ensemble_model() successfully completed......................................
2023-10-21 15:44:33,180:INFO:Initializing finalize_model()
2023-10-21 15:44:33,180:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D936C850>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-21 15:44:33,180:INFO:Finalizing BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-21 15:44:33,196:INFO:Initializing create_model()
2023-10-21 15:44:33,196:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209D936C850>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-21 15:44:33,196:INFO:Checking exceptions
2023-10-21 15:44:33,196:INFO:Importing libraries
2023-10-21 15:44:33,196:INFO:Copying training dataset
2023-10-21 15:44:33,196:INFO:Defining folds
2023-10-21 15:44:33,196:INFO:Declaring metric variables
2023-10-21 15:44:33,196:INFO:Importing untrained model
2023-10-21 15:44:33,196:INFO:Declaring custom model
2023-10-21 15:44:33,196:INFO:Bagging Regressor Imported successfully
2023-10-21 15:44:33,196:INFO:Cross validation set to False
2023-10-21 15:44:33,196:INFO:Fitting Model
2023-10-21 15:44:33,313:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008017 seconds.
2023-10-21 15:44:33,313:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:33,313:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-21 15:44:33,313:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-21 15:44:33,313:INFO:[LightGBM] [Info] Start training from score 634.491655
2023-10-21 15:44:33,713:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006599 seconds.
2023-10-21 15:44:33,713:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:33,713:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-21 15:44:33,713:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-21 15:44:33,728:INFO:[LightGBM] [Info] Start training from score 635.470959
2023-10-21 15:44:34,096:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007300 seconds.
2023-10-21 15:44:34,096:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:34,096:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-21 15:44:34,096:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-21 15:44:34,096:INFO:[LightGBM] [Info] Start training from score 634.053589
2023-10-21 15:44:34,528:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008366 seconds.
2023-10-21 15:44:34,528:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:34,528:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-21 15:44:34,528:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-21 15:44:34,528:INFO:[LightGBM] [Info] Start training from score 635.251785
2023-10-21 15:44:34,962:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006308 seconds.
2023-10-21 15:44:34,962:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:34,962:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-21 15:44:34,962:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-21 15:44:34,962:INFO:[LightGBM] [Info] Start training from score 627.555784
2023-10-21 15:44:35,261:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008473 seconds.
2023-10-21 15:44:35,261:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:35,262:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-21 15:44:35,262:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-21 15:44:35,262:INFO:[LightGBM] [Info] Start training from score 638.162596
2023-10-21 15:44:35,578:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008136 seconds.
2023-10-21 15:44:35,578:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:35,578:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-21 15:44:35,578:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-21 15:44:35,578:INFO:[LightGBM] [Info] Start training from score 633.181363
2023-10-21 15:44:35,861:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006286 seconds.
2023-10-21 15:44:35,861:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:35,861:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-21 15:44:35,861:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-21 15:44:35,861:INFO:[LightGBM] [Info] Start training from score 611.992287
2023-10-21 15:44:36,161:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008329 seconds.
2023-10-21 15:44:36,161:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:36,161:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-21 15:44:36,161:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-21 15:44:36,161:INFO:[LightGBM] [Info] Start training from score 638.181417
2023-10-21 15:44:36,477:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008043 seconds.
2023-10-21 15:44:36,477:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:36,477:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-21 15:44:36,477:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-21 15:44:36,477:INFO:[LightGBM] [Info] Start training from score 639.502137
2023-10-21 15:44:36,710:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-21 15:44:36,710:INFO:create_model() successfully completed......................................
2023-10-21 15:44:36,944:INFO:Creating Dashboard logs
2023-10-21 15:44:36,944:INFO:Model: Bagging Regressor
2023-10-21 15:44:37,010:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-21 15:44:37,477:INFO:_master_model_container: 4
2023-10-21 15:44:37,477:INFO:_display_container: 4
2023-10-21 15:44:37,477:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-21 15:44:37,477:INFO:finalize_model() successfully completed......................................
2023-10-21 15:44:37,693:INFO:Initializing save_model()
2023-10-21 15:44:37,693:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), model_name=final_model_for_location_A, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 15:44:37,693:INFO:Adding model into prep_pipe
2023-10-21 15:44:37,693:WARNING:Only Model saved as it was a pipeline.
2023-10-21 15:44:37,776:INFO:final_model_for_location_A.pkl saved in current working directory
2023-10-21 15:44:37,791:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-21 15:44:37,791:INFO:save_model() successfully completed......................................
2023-10-21 15:44:38,026:INFO:PyCaret RegressionExperiment
2023-10-21 15:44:38,026:INFO:Logging name: exp_B
2023-10-21 15:44:38,026:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-21 15:44:38,026:INFO:version 3.1.0
2023-10-21 15:44:38,026:INFO:Initializing setup()
2023-10-21 15:44:38,026:INFO:self.USI: e04f
2023-10-21 15:44:38,026:INFO:self._variable_keys: {'transform_target_param', 'exp_name_log', 'y_train', 'logging_param', 'n_jobs_param', 'X_train', 'target_param', 'USI', 'gpu_n_jobs_param', 'fold_groups_param', '_ml_usecase', 'seed', 'fold_generator', 'idx', 'html_param', 'log_plots_param', 'y', 'gpu_param', 'X_test', 'memory', 'y_test', 'data', 'X', 'exp_id', '_available_plots', 'fold_shuffle_param', 'pipeline'}
2023-10-21 15:44:38,026:INFO:Checking environment
2023-10-21 15:44:38,026:INFO:python_version: 3.8.18
2023-10-21 15:44:38,026:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-21 15:44:38,026:INFO:machine: AMD64
2023-10-21 15:44:38,026:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-21 15:44:38,026:INFO:Memory: svmem(total=16505954304, available=2976317440, percent=82.0, used=13529636864, free=2976317440)
2023-10-21 15:44:38,026:INFO:Physical Core: 8
2023-10-21 15:44:38,026:INFO:Logical Core: 16
2023-10-21 15:44:38,026:INFO:Checking libraries
2023-10-21 15:44:38,026:INFO:System:
2023-10-21 15:44:38,026:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-21 15:44:38,026:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-21 15:44:38,026:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-21 15:44:38,026:INFO:PyCaret required dependencies:
2023-10-21 15:44:38,026:INFO:                 pip: 23.3
2023-10-21 15:44:38,026:INFO:          setuptools: 68.0.0
2023-10-21 15:44:38,026:INFO:             pycaret: 3.1.0
2023-10-21 15:44:38,026:INFO:             IPython: 8.12.0
2023-10-21 15:44:38,026:INFO:          ipywidgets: 8.1.1
2023-10-21 15:44:38,026:INFO:                tqdm: 4.66.1
2023-10-21 15:44:38,026:INFO:               numpy: 1.23.5
2023-10-21 15:44:38,026:INFO:              pandas: 1.5.3
2023-10-21 15:44:38,026:INFO:              jinja2: 3.1.2
2023-10-21 15:44:38,026:INFO:               scipy: 1.10.1
2023-10-21 15:44:38,026:INFO:              joblib: 1.3.2
2023-10-21 15:44:38,026:INFO:             sklearn: 1.2.2
2023-10-21 15:44:38,026:INFO:                pyod: 1.1.0
2023-10-21 15:44:38,026:INFO:            imblearn: 0.11.0
2023-10-21 15:44:38,026:INFO:   category_encoders: 2.6.2
2023-10-21 15:44:38,026:INFO:            lightgbm: 4.1.0
2023-10-21 15:44:38,026:INFO:               numba: 0.58.1
2023-10-21 15:44:38,026:INFO:            requests: 2.31.0
2023-10-21 15:44:38,026:INFO:          matplotlib: 3.7.3
2023-10-21 15:44:38,026:INFO:          scikitplot: 0.3.7
2023-10-21 15:44:38,026:INFO:         yellowbrick: 1.5
2023-10-21 15:44:38,026:INFO:              plotly: 5.17.0
2023-10-21 15:44:38,026:INFO:    plotly-resampler: Not installed
2023-10-21 15:44:38,026:INFO:             kaleido: 0.2.1
2023-10-21 15:44:38,026:INFO:           schemdraw: 0.15
2023-10-21 15:44:38,026:INFO:         statsmodels: 0.14.0
2023-10-21 15:44:38,041:INFO:              sktime: 0.21.1
2023-10-21 15:44:38,041:INFO:               tbats: 1.1.3
2023-10-21 15:44:38,041:INFO:            pmdarima: 2.0.3
2023-10-21 15:44:38,041:INFO:              psutil: 5.9.0
2023-10-21 15:44:38,041:INFO:          markupsafe: 2.1.3
2023-10-21 15:44:38,041:INFO:             pickle5: Not installed
2023-10-21 15:44:38,041:INFO:         cloudpickle: 2.2.1
2023-10-21 15:44:38,041:INFO:         deprecation: 2.1.0
2023-10-21 15:44:38,041:INFO:              xxhash: 3.4.1
2023-10-21 15:44:38,041:INFO:           wurlitzer: Not installed
2023-10-21 15:44:38,041:INFO:PyCaret optional dependencies:
2023-10-21 15:44:38,041:INFO:                shap: Not installed
2023-10-21 15:44:38,041:INFO:           interpret: Not installed
2023-10-21 15:44:38,042:INFO:                umap: Not installed
2023-10-21 15:44:38,042:INFO:     ydata_profiling: Not installed
2023-10-21 15:44:38,042:INFO:  explainerdashboard: Not installed
2023-10-21 15:44:38,042:INFO:             autoviz: Not installed
2023-10-21 15:44:38,042:INFO:           fairlearn: Not installed
2023-10-21 15:44:38,042:INFO:          deepchecks: Not installed
2023-10-21 15:44:38,042:INFO:             xgboost: Not installed
2023-10-21 15:44:38,042:INFO:            catboost: 1.2.2
2023-10-21 15:44:38,042:INFO:              kmodes: Not installed
2023-10-21 15:44:38,042:INFO:             mlxtend: Not installed
2023-10-21 15:44:38,042:INFO:       statsforecast: Not installed
2023-10-21 15:44:38,042:INFO:        tune_sklearn: Not installed
2023-10-21 15:44:38,042:INFO:                 ray: Not installed
2023-10-21 15:44:38,042:INFO:            hyperopt: Not installed
2023-10-21 15:44:38,042:INFO:              optuna: Not installed
2023-10-21 15:44:38,042:INFO:               skopt: Not installed
2023-10-21 15:44:38,042:INFO:              mlflow: 2.7.1
2023-10-21 15:44:38,042:INFO:              gradio: Not installed
2023-10-21 15:44:38,042:INFO:             fastapi: Not installed
2023-10-21 15:44:38,042:INFO:             uvicorn: Not installed
2023-10-21 15:44:38,042:INFO:              m2cgen: Not installed
2023-10-21 15:44:38,042:INFO:           evidently: Not installed
2023-10-21 15:44:38,042:INFO:               fugue: Not installed
2023-10-21 15:44:38,042:INFO:           streamlit: Not installed
2023-10-21 15:44:38,042:INFO:             prophet: Not installed
2023-10-21 15:44:38,042:INFO:None
2023-10-21 15:44:38,042:INFO:Set up data.
2023-10-21 15:44:38,060:INFO:Set up folding strategy.
2023-10-21 15:44:38,060:INFO:Set up train/test split.
2023-10-21 15:44:38,093:INFO:Set up index.
2023-10-21 15:44:38,093:INFO:Assigning column types.
2023-10-21 15:44:38,110:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-21 15:44:38,110:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,124:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,126:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,209:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,260:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,260:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:44:38,260:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:44:38,260:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,274:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,276:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,358:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,409:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,409:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:44:38,409:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:44:38,409:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-21 15:44:38,409:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,409:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,492:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,558:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,559:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:44:38,559:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:44:38,561:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,561:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,642:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,693:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,693:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:44:38,707:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:44:38,707:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-21 15:44:38,708:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,792:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,842:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,857:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:44:38,857:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:44:38,869:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,942:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,991:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:44:38,991:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:44:38,991:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:44:38,991:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-21 15:44:39,092:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:44:39,142:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:44:39,142:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:44:39,142:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:44:39,241:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:44:39,291:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:44:39,291:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:44:39,291:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:44:39,291:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-21 15:44:39,378:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:44:39,425:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:44:39,425:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:44:39,525:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:44:39,574:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:44:39,574:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:44:39,574:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-21 15:44:39,724:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:44:39,724:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:44:39,881:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:44:39,881:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:44:39,883:INFO:Preparing preprocessing pipeline...
2023-10-21 15:44:39,883:INFO:Set up simple imputation.
2023-10-21 15:44:39,883:INFO:Set up column name cleaning.
2023-10-21 15:44:39,941:INFO:Finished creating preprocessing pipeline.
2023-10-21 15:44:39,956:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 15:44:39,956:INFO:Creating final display dataframe.
2023-10-21 15:44:40,166:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (32819, 50)
4        Transformed data shape   (32819, 50)
5   Transformed train set shape   (22973, 50)
6    Transformed test set shape    (9846, 50)
7              Numeric features            49
8      Rows with missing values         95.9%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_B
19                          USI          e04f
2023-10-21 15:44:40,307:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:44:40,307:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:44:40,440:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:44:40,440:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:44:40,440:INFO:Logging experiment in loggers
2023-10-21 15:44:40,567:INFO:SubProcess save_model() called ==================================
2023-10-21 15:44:40,573:INFO:Initializing save_model()
2023-10-21 15:44:40,573:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmpc91y37zv\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 15:44:40,573:INFO:Adding model into prep_pipe
2023-10-21 15:44:40,573:WARNING:Only Model saved as it was a pipeline.
2023-10-21 15:44:40,573:INFO:C:\Users\thoma\AppData\Local\Temp\tmpc91y37zv\Transformation Pipeline.pkl saved in current working directory
2023-10-21 15:44:40,590:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 15:44:40,590:INFO:save_model() successfully completed......................................
2023-10-21 15:44:40,790:INFO:SubProcess save_model() end ==================================
2023-10-21 15:44:40,841:INFO:setup() successfully completed in 2.41s...............
2023-10-21 15:44:40,841:INFO:Initializing create_model()
2023-10-21 15:44:40,841:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCAFE9D0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 15:44:40,841:INFO:Checking exceptions
2023-10-21 15:44:40,841:INFO:Importing libraries
2023-10-21 15:44:40,841:INFO:Copying training dataset
2023-10-21 15:44:40,868:INFO:Defining folds
2023-10-21 15:44:40,868:INFO:Declaring metric variables
2023-10-21 15:44:40,868:INFO:Importing untrained model
2023-10-21 15:44:40,869:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 15:44:40,869:INFO:Starting cross validation
2023-10-21 15:44:40,870:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 15:44:43,655:INFO:Calculating mean and std
2023-10-21 15:44:43,655:INFO:Creating metrics dataframe
2023-10-21 15:44:43,655:INFO:Finalizing model
2023-10-21 15:44:43,738:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004451 seconds.
2023-10-21 15:44:43,738:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:44:43,738:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 15:44:43,738:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 15:44:43,753:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-21 15:44:43,989:INFO:Creating Dashboard logs
2023-10-21 15:44:43,989:INFO:Model: Light Gradient Boosting Machine
2023-10-21 15:44:44,087:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 15:44:44,271:INFO:Initializing predict_model()
2023-10-21 15:44:44,271:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCAFE9D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002098123F550>)
2023-10-21 15:44:44,271:INFO:Checking exceptions
2023-10-21 15:44:44,271:INFO:Preloading libraries
2023-10-21 15:44:44,966:INFO:Uploading results into container
2023-10-21 15:44:44,966:INFO:Uploading model into container now
2023-10-21 15:44:44,970:INFO:_master_model_container: 1
2023-10-21 15:44:44,970:INFO:_display_container: 2
2023-10-21 15:44:44,970:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 15:44:44,970:INFO:create_model() successfully completed......................................
2023-10-21 15:44:45,170:INFO:Initializing tune_model()
2023-10-21 15:44:45,170:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCAFE9D0>)
2023-10-21 15:44:45,170:INFO:Checking exceptions
2023-10-21 15:44:45,187:INFO:Copying training dataset
2023-10-21 15:44:45,205:INFO:Checking base model
2023-10-21 15:44:45,205:INFO:Base model : Light Gradient Boosting Machine
2023-10-21 15:44:45,205:INFO:Declaring metric variables
2023-10-21 15:44:45,205:INFO:Defining Hyperparameters
2023-10-21 15:44:45,404:INFO:Tuning with n_jobs=-1
2023-10-21 15:44:45,404:INFO:Initializing RandomizedSearchCV
2023-10-21 15:45:31,981:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-21 15:45:31,981:INFO:Hyperparameter search completed
2023-10-21 15:45:31,981:INFO:SubProcess create_model() called ==================================
2023-10-21 15:45:31,981:INFO:Initializing create_model()
2023-10-21 15:45:31,981:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCAFE9D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209DAC11A60>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-21 15:45:31,981:INFO:Checking exceptions
2023-10-21 15:45:31,981:INFO:Importing libraries
2023-10-21 15:45:31,981:INFO:Copying training dataset
2023-10-21 15:45:32,017:INFO:Defining folds
2023-10-21 15:45:32,017:INFO:Declaring metric variables
2023-10-21 15:45:32,017:INFO:Importing untrained model
2023-10-21 15:45:32,017:INFO:Declaring custom model
2023-10-21 15:45:32,017:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 15:45:32,017:INFO:Starting cross validation
2023-10-21 15:45:32,017:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 15:45:43,372:INFO:Calculating mean and std
2023-10-21 15:45:43,372:INFO:Creating metrics dataframe
2023-10-21 15:45:43,372:INFO:Finalizing model
2023-10-21 15:45:43,422:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 15:45:43,422:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 15:45:43,422:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 15:45:43,455:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 15:45:43,455:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 15:45:43,455:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 15:45:43,472:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005311 seconds.
2023-10-21 15:45:43,472:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:45:43,472:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 15:45:43,472:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 15:45:43,472:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-21 15:45:44,654:INFO:Uploading results into container
2023-10-21 15:45:44,654:INFO:Uploading model into container now
2023-10-21 15:45:44,654:INFO:_master_model_container: 2
2023-10-21 15:45:44,654:INFO:_display_container: 3
2023-10-21 15:45:44,654:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-21 15:45:44,654:INFO:create_model() successfully completed......................................
2023-10-21 15:45:44,904:INFO:SubProcess create_model() end ==================================
2023-10-21 15:45:44,904:INFO:choose_better activated
2023-10-21 15:45:44,904:INFO:SubProcess create_model() called ==================================
2023-10-21 15:45:44,904:INFO:Initializing create_model()
2023-10-21 15:45:44,904:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCAFE9D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 15:45:44,904:INFO:Checking exceptions
2023-10-21 15:45:44,904:INFO:Importing libraries
2023-10-21 15:45:44,904:INFO:Copying training dataset
2023-10-21 15:45:44,921:INFO:Defining folds
2023-10-21 15:45:44,921:INFO:Declaring metric variables
2023-10-21 15:45:44,921:INFO:Importing untrained model
2023-10-21 15:45:44,921:INFO:Declaring custom model
2023-10-21 15:45:44,921:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 15:45:44,921:INFO:Starting cross validation
2023-10-21 15:45:44,921:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 15:45:47,485:INFO:Calculating mean and std
2023-10-21 15:45:47,485:INFO:Creating metrics dataframe
2023-10-21 15:45:47,485:INFO:Finalizing model
2023-10-21 15:45:47,568:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005051 seconds.
2023-10-21 15:45:47,568:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:45:47,568:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 15:45:47,584:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 15:45:47,585:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-21 15:45:47,852:INFO:Uploading results into container
2023-10-21 15:45:47,852:INFO:Uploading model into container now
2023-10-21 15:45:47,852:INFO:_master_model_container: 3
2023-10-21 15:45:47,852:INFO:_display_container: 4
2023-10-21 15:45:47,852:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 15:45:47,852:INFO:create_model() successfully completed......................................
2023-10-21 15:45:48,085:INFO:SubProcess create_model() end ==================================
2023-10-21 15:45:48,085:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8523
2023-10-21 15:45:48,085:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8523
2023-10-21 15:45:48,085:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-21 15:45:48,085:INFO:choose_better completed
2023-10-21 15:45:48,085:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-21 15:45:48,085:INFO:Creating Dashboard logs
2023-10-21 15:45:48,085:INFO:Model: Light Gradient Boosting Machine
2023-10-21 15:45:48,151:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 15:45:48,335:INFO:Initializing predict_model()
2023-10-21 15:45:48,335:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCAFE9D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209D83A4F70>)
2023-10-21 15:45:48,335:INFO:Checking exceptions
2023-10-21 15:45:48,335:INFO:Preloading libraries
2023-10-21 15:45:49,018:INFO:_master_model_container: 3
2023-10-21 15:45:49,018:INFO:_display_container: 3
2023-10-21 15:45:49,018:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 15:45:49,018:INFO:tune_model() successfully completed......................................
2023-10-21 15:45:49,227:INFO:Initializing ensemble_model()
2023-10-21 15:45:49,228:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCAFE9D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-21 15:45:49,228:INFO:Checking exceptions
2023-10-21 15:45:49,234:INFO:Importing libraries
2023-10-21 15:45:49,234:INFO:Copying training dataset
2023-10-21 15:45:49,234:INFO:Checking base model
2023-10-21 15:45:49,234:INFO:Base model : Light Gradient Boosting Machine
2023-10-21 15:45:49,234:INFO:Importing untrained ensembler
2023-10-21 15:45:49,234:INFO:Ensemble method set to Bagging
2023-10-21 15:45:49,234:INFO:SubProcess create_model() called ==================================
2023-10-21 15:45:49,234:INFO:Initializing create_model()
2023-10-21 15:45:49,234:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCAFE9D0>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209DCD99490>, model_only=True, return_train_score=False, kwargs={})
2023-10-21 15:45:49,234:INFO:Checking exceptions
2023-10-21 15:45:49,234:INFO:Importing libraries
2023-10-21 15:45:49,234:INFO:Copying training dataset
2023-10-21 15:45:49,250:INFO:Defining folds
2023-10-21 15:45:49,250:INFO:Declaring metric variables
2023-10-21 15:45:49,250:INFO:Importing untrained model
2023-10-21 15:45:49,250:INFO:Declaring custom model
2023-10-21 15:45:49,266:INFO:Bagging Regressor Imported successfully
2023-10-21 15:45:49,266:INFO:Starting cross validation
2023-10-21 15:45:49,267:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 15:46:17,913:INFO:Calculating mean and std
2023-10-21 15:46:17,913:INFO:Creating metrics dataframe
2023-10-21 15:46:17,913:INFO:Finalizing model
2023-10-21 15:46:18,008:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005190 seconds.
2023-10-21 15:46:18,008:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:18,008:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 15:46:18,008:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 15:46:18,008:INFO:[LightGBM] [Info] Start training from score 99.624795
2023-10-21 15:46:18,307:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005292 seconds.
2023-10-21 15:46:18,307:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:18,307:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 15:46:18,307:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 15:46:18,307:INFO:[LightGBM] [Info] Start training from score 96.229614
2023-10-21 15:46:18,587:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004625 seconds.
2023-10-21 15:46:18,587:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:18,587:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 15:46:18,587:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 15:46:18,587:INFO:[LightGBM] [Info] Start training from score 95.360987
2023-10-21 15:46:18,860:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005025 seconds.
2023-10-21 15:46:18,860:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:18,860:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 15:46:18,860:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 15:46:18,860:INFO:[LightGBM] [Info] Start training from score 94.348528
2023-10-21 15:46:19,148:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005167 seconds.
2023-10-21 15:46:19,148:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:19,148:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 15:46:19,148:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 15:46:19,148:INFO:[LightGBM] [Info] Start training from score 95.509684
2023-10-21 15:46:19,475:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005509 seconds.
2023-10-21 15:46:19,475:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:19,475:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 15:46:19,475:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 15:46:19,491:INFO:[LightGBM] [Info] Start training from score 96.036959
2023-10-21 15:46:19,775:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006716 seconds.
2023-10-21 15:46:19,775:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:19,775:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 15:46:19,775:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 15:46:19,775:INFO:[LightGBM] [Info] Start training from score 97.844637
2023-10-21 15:46:20,059:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004742 seconds.
2023-10-21 15:46:20,059:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:20,059:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 15:46:20,059:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 15:46:20,060:INFO:[LightGBM] [Info] Start training from score 96.245614
2023-10-21 15:46:20,325:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005188 seconds.
2023-10-21 15:46:20,325:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:20,325:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 15:46:20,325:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 15:46:20,325:INFO:[LightGBM] [Info] Start training from score 97.594984
2023-10-21 15:46:20,591:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006478 seconds.
2023-10-21 15:46:20,591:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:20,606:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-21 15:46:20,606:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-21 15:46:20,607:INFO:[LightGBM] [Info] Start training from score 96.370407
2023-10-21 15:46:20,841:INFO:Uploading results into container
2023-10-21 15:46:20,841:INFO:Uploading model into container now
2023-10-21 15:46:20,841:INFO:_master_model_container: 4
2023-10-21 15:46:20,841:INFO:_display_container: 4
2023-10-21 15:46:20,841:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-21 15:46:20,841:INFO:create_model() successfully completed......................................
2023-10-21 15:46:21,089:INFO:SubProcess create_model() end ==================================
2023-10-21 15:46:21,090:INFO:Creating Dashboard logs
2023-10-21 15:46:21,090:INFO:Model: Bagging Regressor
2023-10-21 15:46:21,140:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-21 15:46:21,363:INFO:Initializing predict_model()
2023-10-21 15:46:21,363:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCAFE9D0>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DCE93550>)
2023-10-21 15:46:21,363:INFO:Checking exceptions
2023-10-21 15:46:21,363:INFO:Preloading libraries
2023-10-21 15:46:22,189:INFO:_master_model_container: 4
2023-10-21 15:46:22,189:INFO:_display_container: 4
2023-10-21 15:46:22,189:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-21 15:46:22,189:INFO:ensemble_model() successfully completed......................................
2023-10-21 15:46:22,406:INFO:Initializing finalize_model()
2023-10-21 15:46:22,406:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCAFE9D0>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-21 15:46:22,406:INFO:Finalizing BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-21 15:46:22,423:INFO:Initializing create_model()
2023-10-21 15:46:22,423:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCAFE9D0>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-21 15:46:22,423:INFO:Checking exceptions
2023-10-21 15:46:22,423:INFO:Importing libraries
2023-10-21 15:46:22,423:INFO:Copying training dataset
2023-10-21 15:46:22,423:INFO:Defining folds
2023-10-21 15:46:22,423:INFO:Declaring metric variables
2023-10-21 15:46:22,423:INFO:Importing untrained model
2023-10-21 15:46:22,423:INFO:Declaring custom model
2023-10-21 15:46:22,423:INFO:Bagging Regressor Imported successfully
2023-10-21 15:46:22,423:INFO:Cross validation set to False
2023-10-21 15:46:22,423:INFO:Fitting Model
2023-10-21 15:46:22,570:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007404 seconds.
2023-10-21 15:46:22,571:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:22,571:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-21 15:46:22,572:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-21 15:46:22,573:INFO:[LightGBM] [Info] Start training from score 96.465021
2023-10-21 15:46:22,955:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007477 seconds.
2023-10-21 15:46:22,955:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:22,956:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-21 15:46:22,956:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-21 15:46:22,958:INFO:[LightGBM] [Info] Start training from score 97.264361
2023-10-21 15:46:23,356:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007300 seconds.
2023-10-21 15:46:23,356:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:23,356:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-21 15:46:23,356:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-21 15:46:23,356:INFO:[LightGBM] [Info] Start training from score 95.842370
2023-10-21 15:46:23,772:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007613 seconds.
2023-10-21 15:46:23,772:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:23,772:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-21 15:46:23,772:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-21 15:46:23,772:INFO:[LightGBM] [Info] Start training from score 95.431515
2023-10-21 15:46:24,213:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006845 seconds.
2023-10-21 15:46:24,213:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:24,213:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-21 15:46:24,213:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-21 15:46:24,213:INFO:[LightGBM] [Info] Start training from score 97.222213
2023-10-21 15:46:24,571:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008044 seconds.
2023-10-21 15:46:24,571:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:24,571:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-21 15:46:24,571:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-21 15:46:24,571:INFO:[LightGBM] [Info] Start training from score 97.332701
2023-10-21 15:46:25,004:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007975 seconds.
2023-10-21 15:46:25,004:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:25,004:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-21 15:46:25,004:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-21 15:46:25,004:INFO:[LightGBM] [Info] Start training from score 96.452612
2023-10-21 15:46:25,377:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007679 seconds.
2023-10-21 15:46:25,377:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:25,377:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-21 15:46:25,377:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-21 15:46:25,377:INFO:[LightGBM] [Info] Start training from score 97.322509
2023-10-21 15:46:25,737:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007850 seconds.
2023-10-21 15:46:25,737:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:25,737:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-21 15:46:25,737:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-21 15:46:25,737:INFO:[LightGBM] [Info] Start training from score 96.419103
2023-10-21 15:46:26,103:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007504 seconds.
2023-10-21 15:46:26,103:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:26,103:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-21 15:46:26,103:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-21 15:46:26,103:INFO:[LightGBM] [Info] Start training from score 95.095963
2023-10-21 15:46:26,403:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-21 15:46:26,403:INFO:create_model() successfully completed......................................
2023-10-21 15:46:26,670:INFO:Creating Dashboard logs
2023-10-21 15:46:26,670:INFO:Model: Bagging Regressor
2023-10-21 15:46:26,736:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-21 15:46:27,253:INFO:_master_model_container: 4
2023-10-21 15:46:27,268:INFO:_display_container: 4
2023-10-21 15:46:27,269:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-21 15:46:27,269:INFO:finalize_model() successfully completed......................................
2023-10-21 15:46:27,485:INFO:Initializing save_model()
2023-10-21 15:46:27,485:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), model_name=final_model_for_location_B, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 15:46:27,485:INFO:Adding model into prep_pipe
2023-10-21 15:46:27,485:WARNING:Only Model saved as it was a pipeline.
2023-10-21 15:46:27,552:INFO:final_model_for_location_B.pkl saved in current working directory
2023-10-21 15:46:27,569:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-21 15:46:27,569:INFO:save_model() successfully completed......................................
2023-10-21 15:46:27,819:INFO:PyCaret RegressionExperiment
2023-10-21 15:46:27,819:INFO:Logging name: exp_C
2023-10-21 15:46:27,819:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-21 15:46:27,819:INFO:version 3.1.0
2023-10-21 15:46:27,819:INFO:Initializing setup()
2023-10-21 15:46:27,819:INFO:self.USI: 54c7
2023-10-21 15:46:27,819:INFO:self._variable_keys: {'transform_target_param', 'exp_name_log', 'y_train', 'logging_param', 'n_jobs_param', 'X_train', 'target_param', 'USI', 'gpu_n_jobs_param', 'fold_groups_param', '_ml_usecase', 'seed', 'fold_generator', 'idx', 'html_param', 'log_plots_param', 'y', 'gpu_param', 'X_test', 'memory', 'y_test', 'data', 'X', 'exp_id', '_available_plots', 'fold_shuffle_param', 'pipeline'}
2023-10-21 15:46:27,819:INFO:Checking environment
2023-10-21 15:46:27,819:INFO:python_version: 3.8.18
2023-10-21 15:46:27,819:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-21 15:46:27,819:INFO:machine: AMD64
2023-10-21 15:46:27,819:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-21 15:46:27,819:INFO:Memory: svmem(total=16505954304, available=2961993728, percent=82.1, used=13543960576, free=2961993728)
2023-10-21 15:46:27,819:INFO:Physical Core: 8
2023-10-21 15:46:27,819:INFO:Logical Core: 16
2023-10-21 15:46:27,819:INFO:Checking libraries
2023-10-21 15:46:27,819:INFO:System:
2023-10-21 15:46:27,819:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-21 15:46:27,819:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-21 15:46:27,819:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-21 15:46:27,819:INFO:PyCaret required dependencies:
2023-10-21 15:46:27,819:INFO:                 pip: 23.3
2023-10-21 15:46:27,819:INFO:          setuptools: 68.0.0
2023-10-21 15:46:27,819:INFO:             pycaret: 3.1.0
2023-10-21 15:46:27,819:INFO:             IPython: 8.12.0
2023-10-21 15:46:27,819:INFO:          ipywidgets: 8.1.1
2023-10-21 15:46:27,819:INFO:                tqdm: 4.66.1
2023-10-21 15:46:27,819:INFO:               numpy: 1.23.5
2023-10-21 15:46:27,819:INFO:              pandas: 1.5.3
2023-10-21 15:46:27,819:INFO:              jinja2: 3.1.2
2023-10-21 15:46:27,819:INFO:               scipy: 1.10.1
2023-10-21 15:46:27,819:INFO:              joblib: 1.3.2
2023-10-21 15:46:27,819:INFO:             sklearn: 1.2.2
2023-10-21 15:46:27,819:INFO:                pyod: 1.1.0
2023-10-21 15:46:27,819:INFO:            imblearn: 0.11.0
2023-10-21 15:46:27,819:INFO:   category_encoders: 2.6.2
2023-10-21 15:46:27,819:INFO:            lightgbm: 4.1.0
2023-10-21 15:46:27,819:INFO:               numba: 0.58.1
2023-10-21 15:46:27,819:INFO:            requests: 2.31.0
2023-10-21 15:46:27,819:INFO:          matplotlib: 3.7.3
2023-10-21 15:46:27,819:INFO:          scikitplot: 0.3.7
2023-10-21 15:46:27,819:INFO:         yellowbrick: 1.5
2023-10-21 15:46:27,819:INFO:              plotly: 5.17.0
2023-10-21 15:46:27,819:INFO:    plotly-resampler: Not installed
2023-10-21 15:46:27,819:INFO:             kaleido: 0.2.1
2023-10-21 15:46:27,819:INFO:           schemdraw: 0.15
2023-10-21 15:46:27,819:INFO:         statsmodels: 0.14.0
2023-10-21 15:46:27,819:INFO:              sktime: 0.21.1
2023-10-21 15:46:27,819:INFO:               tbats: 1.1.3
2023-10-21 15:46:27,819:INFO:            pmdarima: 2.0.3
2023-10-21 15:46:27,819:INFO:              psutil: 5.9.0
2023-10-21 15:46:27,819:INFO:          markupsafe: 2.1.3
2023-10-21 15:46:27,819:INFO:             pickle5: Not installed
2023-10-21 15:46:27,819:INFO:         cloudpickle: 2.2.1
2023-10-21 15:46:27,819:INFO:         deprecation: 2.1.0
2023-10-21 15:46:27,819:INFO:              xxhash: 3.4.1
2023-10-21 15:46:27,819:INFO:           wurlitzer: Not installed
2023-10-21 15:46:27,819:INFO:PyCaret optional dependencies:
2023-10-21 15:46:27,819:INFO:                shap: Not installed
2023-10-21 15:46:27,819:INFO:           interpret: Not installed
2023-10-21 15:46:27,819:INFO:                umap: Not installed
2023-10-21 15:46:27,819:INFO:     ydata_profiling: Not installed
2023-10-21 15:46:27,819:INFO:  explainerdashboard: Not installed
2023-10-21 15:46:27,819:INFO:             autoviz: Not installed
2023-10-21 15:46:27,819:INFO:           fairlearn: Not installed
2023-10-21 15:46:27,819:INFO:          deepchecks: Not installed
2023-10-21 15:46:27,819:INFO:             xgboost: Not installed
2023-10-21 15:46:27,819:INFO:            catboost: 1.2.2
2023-10-21 15:46:27,819:INFO:              kmodes: Not installed
2023-10-21 15:46:27,819:INFO:             mlxtend: Not installed
2023-10-21 15:46:27,819:INFO:       statsforecast: Not installed
2023-10-21 15:46:27,819:INFO:        tune_sklearn: Not installed
2023-10-21 15:46:27,819:INFO:                 ray: Not installed
2023-10-21 15:46:27,819:INFO:            hyperopt: Not installed
2023-10-21 15:46:27,819:INFO:              optuna: Not installed
2023-10-21 15:46:27,819:INFO:               skopt: Not installed
2023-10-21 15:46:27,819:INFO:              mlflow: 2.7.1
2023-10-21 15:46:27,819:INFO:              gradio: Not installed
2023-10-21 15:46:27,819:INFO:             fastapi: Not installed
2023-10-21 15:46:27,819:INFO:             uvicorn: Not installed
2023-10-21 15:46:27,819:INFO:              m2cgen: Not installed
2023-10-21 15:46:27,819:INFO:           evidently: Not installed
2023-10-21 15:46:27,834:INFO:               fugue: Not installed
2023-10-21 15:46:27,834:INFO:           streamlit: Not installed
2023-10-21 15:46:27,834:INFO:             prophet: Not installed
2023-10-21 15:46:27,834:INFO:None
2023-10-21 15:46:27,834:INFO:Set up data.
2023-10-21 15:46:27,852:INFO:Set up folding strategy.
2023-10-21 15:46:27,852:INFO:Set up train/test split.
2023-10-21 15:46:27,873:INFO:Set up index.
2023-10-21 15:46:27,873:INFO:Assigning column types.
2023-10-21 15:46:27,885:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-21 15:46:27,885:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 15:46:27,902:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 15:46:27,902:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:46:27,985:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,035:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,035:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:46:28,035:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:46:28,035:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,035:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,050:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,119:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,169:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,169:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:46:28,169:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:46:28,169:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-21 15:46:28,185:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,185:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,268:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,318:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,318:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:46:28,318:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:46:28,318:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,318:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,402:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,451:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,451:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:46:28,451:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:46:28,451:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-21 15:46:28,467:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,536:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,585:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,585:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:46:28,585:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:46:28,602:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,668:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,736:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,736:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:46:28,736:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:46:28,736:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-21 15:46:28,818:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,872:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:46:28,872:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:46:28,872:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:46:28,966:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:46:29,018:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-21 15:46:29,018:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:46:29,018:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:46:29,018:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-21 15:46:29,101:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:46:29,151:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:46:29,151:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:46:29,236:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-21 15:46:29,284:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:46:29,284:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:46:29,299:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-21 15:46:29,436:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:46:29,436:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:46:29,584:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:46:29,584:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:46:29,584:INFO:Preparing preprocessing pipeline...
2023-10-21 15:46:29,584:INFO:Set up simple imputation.
2023-10-21 15:46:29,584:INFO:Set up column name cleaning.
2023-10-21 15:46:29,637:INFO:Finished creating preprocessing pipeline.
2023-10-21 15:46:29,650:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 15:46:29,650:INFO:Creating final display dataframe.
2023-10-21 15:46:29,837:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (26071, 50)
4        Transformed data shape   (26071, 50)
5   Transformed train set shape   (18249, 50)
6    Transformed test set shape    (7822, 50)
7              Numeric features            49
8      Rows with missing values         95.9%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_C
19                          USI          54c7
2023-10-21 15:46:30,000:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:46:30,000:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:46:30,137:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-21 15:46:30,148:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-21 15:46:30,150:INFO:Logging experiment in loggers
2023-10-21 15:46:30,250:INFO:SubProcess save_model() called ==================================
2023-10-21 15:46:30,267:INFO:Initializing save_model()
2023-10-21 15:46:30,267:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmpdslaeafk\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-21 15:46:30,267:INFO:Adding model into prep_pipe
2023-10-21 15:46:30,267:WARNING:Only Model saved as it was a pipeline.
2023-10-21 15:46:30,267:INFO:C:\Users\thoma\AppData\Local\Temp\tmpdslaeafk\Transformation Pipeline.pkl saved in current working directory
2023-10-21 15:46:30,267:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-21 15:46:30,267:INFO:save_model() successfully completed......................................
2023-10-21 15:46:30,483:INFO:SubProcess save_model() end ==================================
2023-10-21 15:46:30,517:INFO:setup() successfully completed in 2.33s...............
2023-10-21 15:46:30,517:INFO:Initializing create_model()
2023-10-21 15:46:30,517:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCBE0D90>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 15:46:30,517:INFO:Checking exceptions
2023-10-21 15:46:30,517:INFO:Importing libraries
2023-10-21 15:46:30,517:INFO:Copying training dataset
2023-10-21 15:46:30,538:INFO:Defining folds
2023-10-21 15:46:30,538:INFO:Declaring metric variables
2023-10-21 15:46:30,538:INFO:Importing untrained model
2023-10-21 15:46:30,538:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 15:46:30,538:INFO:Starting cross validation
2023-10-21 15:46:30,538:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 15:46:33,141:INFO:Calculating mean and std
2023-10-21 15:46:33,141:INFO:Creating metrics dataframe
2023-10-21 15:46:33,147:INFO:Finalizing model
2023-10-21 15:46:33,251:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005335 seconds.
2023-10-21 15:46:33,251:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:46:33,252:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-21 15:46:33,252:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-21 15:46:33,253:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-21 15:46:33,464:INFO:Creating Dashboard logs
2023-10-21 15:46:33,464:INFO:Model: Light Gradient Boosting Machine
2023-10-21 15:46:33,564:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 15:46:33,747:INFO:Initializing predict_model()
2023-10-21 15:46:33,747:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCBE0D90>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002098DAA5790>)
2023-10-21 15:46:33,747:INFO:Checking exceptions
2023-10-21 15:46:33,747:INFO:Preloading libraries
2023-10-21 15:46:34,430:INFO:Uploading results into container
2023-10-21 15:46:34,430:INFO:Uploading model into container now
2023-10-21 15:46:34,443:INFO:_master_model_container: 1
2023-10-21 15:46:34,445:INFO:_display_container: 2
2023-10-21 15:46:34,446:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 15:46:34,446:INFO:create_model() successfully completed......................................
2023-10-21 15:46:34,646:INFO:Initializing tune_model()
2023-10-21 15:46:34,646:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCBE0D90>)
2023-10-21 15:46:34,646:INFO:Checking exceptions
2023-10-21 15:46:34,663:INFO:Copying training dataset
2023-10-21 15:46:34,682:INFO:Checking base model
2023-10-21 15:46:34,682:INFO:Base model : Light Gradient Boosting Machine
2023-10-21 15:46:34,682:INFO:Declaring metric variables
2023-10-21 15:46:34,682:INFO:Defining Hyperparameters
2023-10-21 15:46:34,896:INFO:Tuning with n_jobs=-1
2023-10-21 15:46:34,896:INFO:Initializing RandomizedSearchCV
2023-10-21 15:47:21,125:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-21 15:47:21,125:INFO:Hyperparameter search completed
2023-10-21 15:47:21,125:INFO:SubProcess create_model() called ==================================
2023-10-21 15:47:21,125:INFO:Initializing create_model()
2023-10-21 15:47:21,125:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCBE0D90>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002098DA01E80>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-21 15:47:21,125:INFO:Checking exceptions
2023-10-21 15:47:21,125:INFO:Importing libraries
2023-10-21 15:47:21,125:INFO:Copying training dataset
2023-10-21 15:47:21,169:INFO:Defining folds
2023-10-21 15:47:21,169:INFO:Declaring metric variables
2023-10-21 15:47:21,171:INFO:Importing untrained model
2023-10-21 15:47:21,171:INFO:Declaring custom model
2023-10-21 15:47:21,172:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 15:47:21,173:INFO:Starting cross validation
2023-10-21 15:47:21,174:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 15:47:30,367:INFO:Calculating mean and std
2023-10-21 15:47:30,367:INFO:Creating metrics dataframe
2023-10-21 15:47:30,367:INFO:Finalizing model
2023-10-21 15:47:30,426:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 15:47:30,427:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 15:47:30,427:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 15:47:30,450:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-21 15:47:30,450:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-21 15:47:30,450:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-21 15:47:30,467:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005335 seconds.
2023-10-21 15:47:30,467:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:47:30,467:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-21 15:47:30,467:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-21 15:47:30,467:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-21 15:47:30,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 15:47:30,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 15:47:30,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 15:47:30,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 15:47:30,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 15:47:30,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 15:47:30,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 15:47:30,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-21 15:47:31,617:INFO:Uploading results into container
2023-10-21 15:47:31,619:INFO:Uploading model into container now
2023-10-21 15:47:31,621:INFO:_master_model_container: 2
2023-10-21 15:47:31,621:INFO:_display_container: 3
2023-10-21 15:47:31,623:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-21 15:47:31,623:INFO:create_model() successfully completed......................................
2023-10-21 15:47:31,870:INFO:SubProcess create_model() end ==================================
2023-10-21 15:47:31,870:INFO:choose_better activated
2023-10-21 15:47:31,870:INFO:SubProcess create_model() called ==================================
2023-10-21 15:47:31,876:INFO:Initializing create_model()
2023-10-21 15:47:31,876:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCBE0D90>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-21 15:47:31,876:INFO:Checking exceptions
2023-10-21 15:47:31,876:INFO:Importing libraries
2023-10-21 15:47:31,876:INFO:Copying training dataset
2023-10-21 15:47:31,899:INFO:Defining folds
2023-10-21 15:47:31,899:INFO:Declaring metric variables
2023-10-21 15:47:31,899:INFO:Importing untrained model
2023-10-21 15:47:31,899:INFO:Declaring custom model
2023-10-21 15:47:31,899:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-21 15:47:31,899:INFO:Starting cross validation
2023-10-21 15:47:31,899:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-21 15:47:34,496:INFO:Calculating mean and std
2023-10-21 15:47:34,497:INFO:Creating metrics dataframe
2023-10-21 15:47:34,497:INFO:Finalizing model
2023-10-21 15:47:34,563:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004016 seconds.
2023-10-21 15:47:34,563:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-21 15:47:34,563:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-21 15:47:34,563:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-21 15:47:34,563:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-21 15:47:34,797:INFO:Uploading results into container
2023-10-21 15:47:34,797:INFO:Uploading model into container now
2023-10-21 15:47:34,797:INFO:_master_model_container: 3
2023-10-21 15:47:34,797:INFO:_display_container: 4
2023-10-21 15:47:34,797:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 15:47:34,797:INFO:create_model() successfully completed......................................
2023-10-21 15:47:35,013:INFO:SubProcess create_model() end ==================================
2023-10-21 15:47:35,013:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.905
2023-10-21 15:47:35,028:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8993
2023-10-21 15:47:35,028:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-21 15:47:35,028:INFO:choose_better completed
2023-10-21 15:47:35,028:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-21 15:47:35,030:INFO:Creating Dashboard logs
2023-10-21 15:47:35,030:INFO:Model: Light Gradient Boosting Machine
2023-10-21 15:47:35,080:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-21 15:47:35,246:INFO:Initializing predict_model()
2023-10-21 15:47:35,246:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCBE0D90>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DBA03670>)
2023-10-21 15:47:35,246:INFO:Checking exceptions
2023-10-21 15:47:35,246:INFO:Preloading libraries
2023-10-21 15:47:35,929:INFO:_master_model_container: 3
2023-10-21 15:47:35,929:INFO:_display_container: 3
2023-10-21 15:47:35,929:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-21 15:47:35,929:INFO:tune_model() successfully completed......................................
2023-10-21 15:47:36,129:INFO:Initializing ensemble_model()
2023-10-21 15:47:36,129:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCBE0D90>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-21 15:47:36,129:INFO:Checking exceptions
2023-10-21 15:47:36,145:INFO:Importing libraries
2023-10-21 15:47:36,145:INFO:Copying training dataset
2023-10-21 15:47:36,145:INFO:Checking base model
2023-10-21 15:47:36,145:INFO:Base model : Light Gradient Boosting Machine
2023-10-21 15:47:36,145:INFO:Importing untrained ensembler
2023-10-21 15:47:36,145:INFO:Ensemble method set to Bagging
2023-10-21 15:47:36,145:INFO:SubProcess create_model() called ==================================
2023-10-21 15:47:36,145:INFO:Initializing create_model()
2023-10-21 15:47:36,145:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCBE0D90>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209D9BE5BB0>, model_only=True, return_train_score=False, kwargs={})
2023-10-21 15:47:36,145:INFO:Checking exceptions
2023-10-21 15:47:36,145:INFO:Importing libraries
2023-10-21 15:47:36,145:INFO:Copying training dataset
2023-10-21 15:47:36,162:INFO:Defining folds
2023-10-21 15:47:36,162:INFO:Declaring metric variables
2023-10-21 15:47:36,162:INFO:Importing untrained model
2023-10-21 15:47:36,162:INFO:Declaring custom model
2023-10-21 15:47:36,162:INFO:Bagging Regressor Imported successfully
2023-10-21 15:47:36,162:INFO:Starting cross validation
2023-10-21 15:47:36,162:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 06:00:12,211:INFO:Calculating mean and std
2023-10-22 06:00:12,213:INFO:Creating metrics dataframe
2023-10-22 06:00:12,213:INFO:Finalizing model
2023-10-22 06:00:12,427:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018408 seconds.
2023-10-22 06:00:12,427:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:12,429:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-22 06:00:12,429:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-22 06:00:12,429:INFO:[LightGBM] [Info] Start training from score 77.044367
2023-10-22 06:00:13,641:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013711 seconds.
2023-10-22 06:00:13,641:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:13,641:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-22 06:00:13,643:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-22 06:00:13,646:INFO:[LightGBM] [Info] Start training from score 76.520588
2023-10-22 06:00:14,362:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008493 seconds.
2023-10-22 06:00:14,362:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:14,362:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-22 06:00:14,362:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-22 06:00:14,362:INFO:[LightGBM] [Info] Start training from score 76.462170
2023-10-22 06:00:15,064:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005862 seconds.
2023-10-22 06:00:15,064:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:15,064:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-22 06:00:15,075:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-22 06:00:15,078:INFO:[LightGBM] [Info] Start training from score 77.386428
2023-10-22 06:00:15,693:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003786 seconds.
2023-10-22 06:00:15,693:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-22 06:00:15,693:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-22 06:00:15,693:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-22 06:00:15,693:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-22 06:00:15,700:INFO:[LightGBM] [Info] Start training from score 73.916304
2023-10-22 06:00:16,460:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009418 seconds.
2023-10-22 06:00:16,460:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:16,460:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-22 06:00:16,460:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-22 06:00:16,460:INFO:[LightGBM] [Info] Start training from score 75.879633
2023-10-22 06:00:17,177:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005668 seconds.
2023-10-22 06:00:17,177:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:17,177:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-22 06:00:17,177:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-22 06:00:17,177:INFO:[LightGBM] [Info] Start training from score 75.615395
2023-10-22 06:00:17,745:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005515 seconds.
2023-10-22 06:00:17,745:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:17,745:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-22 06:00:17,745:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-22 06:00:17,745:INFO:[LightGBM] [Info] Start training from score 79.544595
2023-10-22 06:00:18,259:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005585 seconds.
2023-10-22 06:00:18,259:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:18,259:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-22 06:00:18,273:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-22 06:00:18,274:INFO:[LightGBM] [Info] Start training from score 76.012052
2023-10-22 06:00:18,776:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004686 seconds.
2023-10-22 06:00:18,776:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:18,776:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-22 06:00:18,776:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-22 06:00:18,776:INFO:[LightGBM] [Info] Start training from score 78.124037
2023-10-22 06:00:19,141:INFO:Uploading results into container
2023-10-22 06:00:19,141:INFO:Uploading model into container now
2023-10-22 06:00:19,141:INFO:_master_model_container: 4
2023-10-22 06:00:19,141:INFO:_display_container: 4
2023-10-22 06:00:19,155:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-22 06:00:19,156:INFO:create_model() successfully completed......................................
2023-10-22 06:00:19,479:INFO:SubProcess create_model() end ==================================
2023-10-22 06:00:19,479:INFO:Creating Dashboard logs
2023-10-22 06:00:19,479:INFO:Model: Bagging Regressor
2023-10-22 06:00:19,641:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-22 06:00:20,026:INFO:Initializing predict_model()
2023-10-22 06:00:20,026:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCBE0D90>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209831F0DC0>)
2023-10-22 06:00:20,026:INFO:Checking exceptions
2023-10-22 06:00:20,026:INFO:Preloading libraries
2023-10-22 06:00:21,305:INFO:_master_model_container: 4
2023-10-22 06:00:21,305:INFO:_display_container: 4
2023-10-22 06:00:21,305:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-22 06:00:21,305:INFO:ensemble_model() successfully completed......................................
2023-10-22 06:00:21,688:INFO:Initializing finalize_model()
2023-10-22 06:00:21,688:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCBE0D90>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-22 06:00:21,688:INFO:Finalizing BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-22 06:00:21,710:INFO:Initializing create_model()
2023-10-22 06:00:21,710:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCBE0D90>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-22 06:00:21,710:INFO:Checking exceptions
2023-10-22 06:00:21,710:INFO:Importing libraries
2023-10-22 06:00:21,710:INFO:Copying training dataset
2023-10-22 06:00:21,710:INFO:Defining folds
2023-10-22 06:00:21,710:INFO:Declaring metric variables
2023-10-22 06:00:21,710:INFO:Importing untrained model
2023-10-22 06:00:21,710:INFO:Declaring custom model
2023-10-22 06:00:21,720:INFO:Bagging Regressor Imported successfully
2023-10-22 06:00:21,721:INFO:Cross validation set to False
2023-10-22 06:00:21,721:INFO:Fitting Model
2023-10-22 06:00:21,871:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007416 seconds.
2023-10-22 06:00:21,871:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:21,871:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-22 06:00:21,871:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-22 06:00:21,871:INFO:[LightGBM] [Info] Start training from score 77.360615
2023-10-22 06:00:22,287:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005908 seconds.
2023-10-22 06:00:22,287:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:22,287:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-22 06:00:22,296:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-22 06:00:22,296:INFO:[LightGBM] [Info] Start training from score 78.162759
2023-10-22 06:00:22,920:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007327 seconds.
2023-10-22 06:00:22,920:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:22,920:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-22 06:00:22,920:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-22 06:00:22,926:INFO:[LightGBM] [Info] Start training from score 77.185434
2023-10-22 06:00:23,379:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007738 seconds.
2023-10-22 06:00:23,379:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:23,379:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-22 06:00:23,379:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-22 06:00:23,379:INFO:[LightGBM] [Info] Start training from score 78.293126
2023-10-22 06:00:23,886:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008236 seconds.
2023-10-22 06:00:23,886:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:23,886:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-22 06:00:23,886:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-22 06:00:23,891:INFO:[LightGBM] [Info] Start training from score 75.493649
2023-10-22 06:00:24,329:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006544 seconds.
2023-10-22 06:00:24,329:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:24,329:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-22 06:00:24,329:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-22 06:00:24,334:INFO:[LightGBM] [Info] Start training from score 77.467219
2023-10-22 06:00:24,777:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006316 seconds.
2023-10-22 06:00:24,777:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:24,777:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-22 06:00:24,777:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-22 06:00:24,782:INFO:[LightGBM] [Info] Start training from score 77.083598
2023-10-22 06:00:25,278:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006562 seconds.
2023-10-22 06:00:25,278:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:25,278:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-22 06:00:25,278:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-22 06:00:25,278:INFO:[LightGBM] [Info] Start training from score 79.854607
2023-10-22 06:00:25,779:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007476 seconds.
2023-10-22 06:00:25,779:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:25,779:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-22 06:00:25,779:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-22 06:00:25,779:INFO:[LightGBM] [Info] Start training from score 76.153078
2023-10-22 06:00:26,203:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006755 seconds.
2023-10-22 06:00:26,203:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-22 06:00:26,211:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-22 06:00:26,211:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-22 06:00:26,211:INFO:[LightGBM] [Info] Start training from score 78.843978
2023-10-22 06:00:26,596:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-22 06:00:26,599:INFO:create_model() successfully completed......................................
2023-10-22 06:00:27,178:INFO:Creating Dashboard logs
2023-10-22 06:00:27,180:INFO:Model: Bagging Regressor
2023-10-22 06:00:27,309:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-22 06:00:28,283:INFO:_master_model_container: 4
2023-10-22 06:00:28,283:INFO:_display_container: 4
2023-10-22 06:00:28,304:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-22 06:00:28,304:INFO:finalize_model() successfully completed......................................
2023-10-22 06:00:28,746:INFO:Initializing save_model()
2023-10-22 06:00:28,746:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), model_name=final_model_for_location_C, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-22 06:00:28,746:INFO:Adding model into prep_pipe
2023-10-22 06:00:28,746:WARNING:Only Model saved as it was a pipeline.
2023-10-22 06:00:28,827:INFO:final_model_for_location_C.pkl saved in current working directory
2023-10-22 06:00:28,851:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-22 06:00:28,851:INFO:save_model() successfully completed......................................
2023-10-22 20:28:39,809:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\base\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals
  warnings.warn("Maximum Likelihood optimization failed to "

2023-10-23 09:36:55,148:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.
  self._init_dates(dates, freq)

2023-10-23 09:36:55,150:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.
  self._init_dates(dates, freq)

2023-10-23 09:36:55,152:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.
  self._init_dates(dates, freq)

2023-10-23 09:41:36,374:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.
  self._init_dates(dates, freq)

2023-10-23 09:41:36,374:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.
  self._init_dates(dates, freq)

2023-10-23 09:41:36,374:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.
  self._init_dates(dates, freq)

2023-10-23 09:41:45,324:INFO:Initializing predict_model()
2023-10-23 09:41:45,340:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCBE0D90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002098DAA5A60>)
2023-10-23 09:41:45,340:INFO:Checking exceptions
2023-10-23 09:41:45,340:INFO:Preloading libraries
2023-10-23 09:41:45,340:INFO:Set up data.
2023-10-23 09:41:45,402:INFO:Set up index.
2023-10-23 09:42:01,711:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\base\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals
  warnings.warn("Maximum Likelihood optimization failed to "

2023-10-23 09:42:03,101:INFO:Initializing predict_model()
2023-10-23 09:42:03,101:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209DCBE0D90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209DA6BEA60>)
2023-10-23 09:42:03,101:INFO:Checking exceptions
2023-10-23 09:42:03,101:INFO:Preloading libraries
2023-10-23 09:42:03,102:INFO:Set up data.
2023-10-23 09:42:03,137:INFO:Set up index.
2023-10-23 09:42:03,786:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.
  self._init_dates(dates, freq)

2023-10-23 09:42:03,786:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.
  self._init_dates(dates, freq)

2023-10-23 09:42:03,787:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.
  self._init_dates(dates, freq)

2023-10-23 10:27:50,104:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-23 10:27:50,104:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-23 10:27:50,104:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-23 10:27:50,104:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-23 10:27:50,458:INFO:PyCaret RegressionExperiment
2023-10-23 10:27:50,458:INFO:Logging name: exp_A
2023-10-23 10:27:50,458:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 10:27:50,458:INFO:version 3.1.0
2023-10-23 10:27:50,458:INFO:Initializing setup()
2023-10-23 10:27:50,458:INFO:self.USI: eaad
2023-10-23 10:27:50,458:INFO:self._variable_keys: {'data', 'X_test', 'html_param', 'exp_id', 'exp_name_log', 'log_plots_param', '_available_plots', 'idx', 'pipeline', 'fold_generator', 'y', 'X', 'gpu_n_jobs_param', 'logging_param', 'memory', 'n_jobs_param', 'target_param', 'X_train', 'gpu_param', 'seed', 'USI', 'y_test', 'transform_target_param', 'y_train', 'fold_shuffle_param', 'fold_groups_param', '_ml_usecase'}
2023-10-23 10:27:50,458:INFO:Checking environment
2023-10-23 10:27:50,458:INFO:python_version: 3.8.18
2023-10-23 10:27:50,458:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 10:27:50,458:INFO:machine: AMD64
2023-10-23 10:27:50,472:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 10:27:50,472:INFO:Memory: svmem(total=16505954304, available=4717416448, percent=71.4, used=11788537856, free=4717416448)
2023-10-23 10:27:50,472:INFO:Physical Core: 8
2023-10-23 10:27:50,472:INFO:Logical Core: 16
2023-10-23 10:27:50,472:INFO:Checking libraries
2023-10-23 10:27:50,472:INFO:System:
2023-10-23 10:27:50,472:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 10:27:50,472:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 10:27:50,472:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 10:27:50,472:INFO:PyCaret required dependencies:
2023-10-23 10:27:50,596:INFO:                 pip: 23.3
2023-10-23 10:27:50,596:INFO:          setuptools: 68.0.0
2023-10-23 10:27:50,596:INFO:             pycaret: 3.1.0
2023-10-23 10:27:50,596:INFO:             IPython: 8.12.0
2023-10-23 10:27:50,596:INFO:          ipywidgets: 8.1.1
2023-10-23 10:27:50,596:INFO:                tqdm: 4.66.1
2023-10-23 10:27:50,596:INFO:               numpy: 1.23.5
2023-10-23 10:27:50,596:INFO:              pandas: 1.5.3
2023-10-23 10:27:50,596:INFO:              jinja2: 3.1.2
2023-10-23 10:27:50,596:INFO:               scipy: 1.10.1
2023-10-23 10:27:50,596:INFO:              joblib: 1.3.2
2023-10-23 10:27:50,596:INFO:             sklearn: 1.2.2
2023-10-23 10:27:50,596:INFO:                pyod: 1.1.0
2023-10-23 10:27:50,596:INFO:            imblearn: 0.11.0
2023-10-23 10:27:50,596:INFO:   category_encoders: 2.6.2
2023-10-23 10:27:50,596:INFO:            lightgbm: 4.1.0
2023-10-23 10:27:50,596:INFO:               numba: 0.58.1
2023-10-23 10:27:50,596:INFO:            requests: 2.31.0
2023-10-23 10:27:50,596:INFO:          matplotlib: 3.7.3
2023-10-23 10:27:50,596:INFO:          scikitplot: 0.3.7
2023-10-23 10:27:50,596:INFO:         yellowbrick: 1.5
2023-10-23 10:27:50,596:INFO:              plotly: 5.17.0
2023-10-23 10:27:50,596:INFO:    plotly-resampler: Not installed
2023-10-23 10:27:50,596:INFO:             kaleido: 0.2.1
2023-10-23 10:27:50,596:INFO:           schemdraw: 0.15
2023-10-23 10:27:50,596:INFO:         statsmodels: 0.14.0
2023-10-23 10:27:50,596:INFO:              sktime: 0.21.1
2023-10-23 10:27:50,596:INFO:               tbats: 1.1.3
2023-10-23 10:27:50,596:INFO:            pmdarima: 2.0.3
2023-10-23 10:27:50,596:INFO:              psutil: 5.9.0
2023-10-23 10:27:50,596:INFO:          markupsafe: 2.1.3
2023-10-23 10:27:50,596:INFO:             pickle5: Not installed
2023-10-23 10:27:50,596:INFO:         cloudpickle: 2.2.1
2023-10-23 10:27:50,596:INFO:         deprecation: 2.1.0
2023-10-23 10:27:50,596:INFO:              xxhash: 3.4.1
2023-10-23 10:27:50,596:INFO:           wurlitzer: Not installed
2023-10-23 10:27:50,596:INFO:PyCaret optional dependencies:
2023-10-23 10:27:50,638:INFO:                shap: Not installed
2023-10-23 10:27:50,638:INFO:           interpret: Not installed
2023-10-23 10:27:50,638:INFO:                umap: Not installed
2023-10-23 10:27:50,638:INFO:     ydata_profiling: Not installed
2023-10-23 10:27:50,638:INFO:  explainerdashboard: Not installed
2023-10-23 10:27:50,638:INFO:             autoviz: Not installed
2023-10-23 10:27:50,638:INFO:           fairlearn: Not installed
2023-10-23 10:27:50,638:INFO:          deepchecks: Not installed
2023-10-23 10:27:50,638:INFO:             xgboost: Not installed
2023-10-23 10:27:50,638:INFO:            catboost: 1.2.2
2023-10-23 10:27:50,638:INFO:              kmodes: Not installed
2023-10-23 10:27:50,638:INFO:             mlxtend: Not installed
2023-10-23 10:27:50,638:INFO:       statsforecast: Not installed
2023-10-23 10:27:50,638:INFO:        tune_sklearn: Not installed
2023-10-23 10:27:50,638:INFO:                 ray: Not installed
2023-10-23 10:27:50,638:INFO:            hyperopt: Not installed
2023-10-23 10:27:50,638:INFO:              optuna: Not installed
2023-10-23 10:27:50,638:INFO:               skopt: Not installed
2023-10-23 10:27:50,638:INFO:              mlflow: 2.7.1
2023-10-23 10:27:50,638:INFO:              gradio: Not installed
2023-10-23 10:27:50,638:INFO:             fastapi: Not installed
2023-10-23 10:27:50,638:INFO:             uvicorn: Not installed
2023-10-23 10:27:50,638:INFO:              m2cgen: Not installed
2023-10-23 10:27:50,638:INFO:           evidently: Not installed
2023-10-23 10:27:50,638:INFO:               fugue: Not installed
2023-10-23 10:27:50,638:INFO:           streamlit: Not installed
2023-10-23 10:27:50,638:INFO:             prophet: Not installed
2023-10-23 10:27:50,638:INFO:None
2023-10-23 10:27:50,638:INFO:Set up data.
2023-10-23 10:27:50,689:INFO:Set up folding strategy.
2023-10-23 10:27:50,689:INFO:Set up train/test split.
2023-10-23 10:27:50,728:INFO:Set up index.
2023-10-23 10:27:50,728:INFO:Assigning column types.
2023-10-23 10:27:50,768:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 10:27:50,768:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 10:27:50,774:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 10:27:50,789:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 10:27:50,916:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 10:27:50,990:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 10:27:50,990:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 10:27:50,990:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 10:27:50,990:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,002:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,002:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,136:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,214:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,214:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 10:27:51,214:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 10:27:51,214:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 10:27:51,230:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,230:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,348:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,434:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,434:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 10:27:51,434:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 10:27:51,450:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,450:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,568:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,653:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,653:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 10:27:51,653:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 10:27:51,653:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 10:27:51,669:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,800:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,878:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 10:27:51,878:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 10:27:51,878:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 10:27:51,894:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 10:27:52,022:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 10:27:52,115:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 10:27:52,115:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 10:27:52,115:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 10:27:52,115:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 10:27:52,270:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 10:27:52,353:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 10:27:52,356:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 10:27:52,356:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 10:27:52,513:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 10:27:52,596:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 10:27:52,596:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 10:27:52,596:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 10:27:52,596:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 10:27:52,747:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 10:27:52,831:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 10:27:52,831:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 10:27:52,994:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 10:27:53,079:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 10:27:53,079:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 10:27:53,081:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 10:27:53,338:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 10:27:53,338:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 10:27:53,612:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 10:27:53,612:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 10:27:53,612:INFO:Preparing preprocessing pipeline...
2023-10-23 10:27:53,612:INFO:Set up simple imputation.
2023-10-23 10:27:53,619:INFO:Set up column name cleaning.
2023-10-23 10:27:53,738:INFO:Finished creating preprocessing pipeline.
2023-10-23 10:27:53,754:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 10:27:53,754:INFO:Creating final display dataframe.
2023-10-23 10:27:54,124:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (34061, 50)
4        Transformed data shape   (34061, 50)
5   Transformed train set shape   (23842, 50)
6    Transformed test set shape   (10219, 50)
7              Numeric features            49
8      Rows with missing values         97.6%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_A
19                          USI          eaad
2023-10-23 10:27:54,316:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 10:27:54,316:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 10:27:54,521:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 10:27:54,521:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 10:27:54,521:INFO:Logging experiment in loggers
2023-10-23 10:27:55,047:INFO:SubProcess save_model() called ==================================
2023-10-23 10:27:55,060:INFO:Initializing save_model()
2023-10-23 10:27:55,060:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmps3mkt90d\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 10:27:55,060:INFO:Adding model into prep_pipe
2023-10-23 10:27:55,060:WARNING:Only Model saved as it was a pipeline.
2023-10-23 10:27:55,062:INFO:C:\Users\thoma\AppData\Local\Temp\tmps3mkt90d\Transformation Pipeline.pkl saved in current working directory
2023-10-23 10:27:55,068:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 10:27:55,068:INFO:save_model() successfully completed......................................
2023-10-23 10:27:55,164:INFO:SubProcess save_model() end ==================================
2023-10-23 10:27:55,252:INFO:setup() successfully completed in 4.06s...............
2023-10-23 10:27:55,252:INFO:Initializing create_model()
2023-10-23 10:27:55,252:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018BFA725310>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 10:27:55,252:INFO:Checking exceptions
2023-10-23 10:27:55,252:INFO:Importing libraries
2023-10-23 10:27:55,252:INFO:Copying training dataset
2023-10-23 10:27:55,277:INFO:Defining folds
2023-10-23 10:27:55,277:INFO:Declaring metric variables
2023-10-23 10:27:55,277:INFO:Importing untrained model
2023-10-23 10:27:55,277:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 10:27:55,277:INFO:Starting cross validation
2023-10-23 10:27:55,277:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 10:28:02,921:INFO:Calculating mean and std
2023-10-23 10:28:02,923:INFO:Creating metrics dataframe
2023-10-23 10:28:02,923:INFO:Finalizing model
2023-10-23 10:28:03,055:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006533 seconds.
2023-10-23 10:28:03,055:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 10:28:03,055:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 10:28:03,055:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 10:28:03,060:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-23 10:28:03,282:INFO:Creating Dashboard logs
2023-10-23 10:28:03,282:INFO:Model: Light Gradient Boosting Machine
2023-10-23 10:28:03,361:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 10:28:03,549:INFO:Initializing predict_model()
2023-10-23 10:28:03,549:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018BFA725310>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018B80298820>)
2023-10-23 10:28:03,549:INFO:Checking exceptions
2023-10-23 10:28:03,549:INFO:Preloading libraries
2023-10-23 10:28:03,817:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\_distutils_hack\__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2023-10-23 10:28:04,006:INFO:Uploading results into container
2023-10-23 10:28:04,006:INFO:Uploading model into container now
2023-10-23 10:28:04,014:INFO:_master_model_container: 1
2023-10-23 10:28:04,014:INFO:_display_container: 2
2023-10-23 10:28:04,014:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 10:28:04,014:INFO:create_model() successfully completed......................................
2023-10-23 10:28:04,118:INFO:Initializing tune_model()
2023-10-23 10:28:04,118:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018BFA725310>)
2023-10-23 10:28:04,118:INFO:Checking exceptions
2023-10-23 10:28:04,132:INFO:Copying training dataset
2023-10-23 10:28:04,143:INFO:Checking base model
2023-10-23 10:28:04,143:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 10:28:04,143:INFO:Declaring metric variables
2023-10-23 10:28:04,143:INFO:Defining Hyperparameters
2023-10-23 10:28:04,244:INFO:Tuning with n_jobs=-1
2023-10-23 10:28:04,244:INFO:Initializing RandomizedSearchCV
2023-10-23 14:31:20,238:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-23 14:31:20,238:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-23 14:31:20,238:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-23 14:31:20,238:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-23 14:31:20,480:INFO:PyCaret RegressionExperiment
2023-10-23 14:31:20,480:INFO:Logging name: exp_A
2023-10-23 14:31:20,480:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 14:31:20,480:INFO:version 3.1.0
2023-10-23 14:31:20,480:INFO:Initializing setup()
2023-10-23 14:31:20,480:INFO:self.USI: fafb
2023-10-23 14:31:20,480:INFO:self._variable_keys: {'gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', '_ml_usecase', 'gpu_param', 'exp_name_log', 'html_param', 'fold_generator', 'y', 'seed', 'y_train', 'transform_target_param', 'n_jobs_param', 'target_param', 'idx', '_available_plots', 'log_plots_param', 'memory', 'data', 'USI', 'X', 'logging_param', 'pipeline', 'exp_id', 'X_train', 'X_test', 'fold_groups_param'}
2023-10-23 14:31:20,480:INFO:Checking environment
2023-10-23 14:31:20,480:INFO:python_version: 3.8.18
2023-10-23 14:31:20,481:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 14:31:20,481:INFO:machine: AMD64
2023-10-23 14:31:20,481:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 14:31:20,481:INFO:Memory: svmem(total=16505954304, available=4661129216, percent=71.8, used=11844825088, free=4661129216)
2023-10-23 14:31:20,481:INFO:Physical Core: 8
2023-10-23 14:31:20,481:INFO:Logical Core: 16
2023-10-23 14:31:20,481:INFO:Checking libraries
2023-10-23 14:31:20,481:INFO:System:
2023-10-23 14:31:20,481:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 14:31:20,481:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 14:31:20,481:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 14:31:20,481:INFO:PyCaret required dependencies:
2023-10-23 14:31:20,573:INFO:                 pip: 23.3
2023-10-23 14:31:20,573:INFO:          setuptools: 68.0.0
2023-10-23 14:31:20,573:INFO:             pycaret: 3.1.0
2023-10-23 14:31:20,574:INFO:             IPython: 8.12.0
2023-10-23 14:31:20,574:INFO:          ipywidgets: 8.1.1
2023-10-23 14:31:20,574:INFO:                tqdm: 4.66.1
2023-10-23 14:31:20,574:INFO:               numpy: 1.23.5
2023-10-23 14:31:20,574:INFO:              pandas: 1.5.3
2023-10-23 14:31:20,574:INFO:              jinja2: 3.1.2
2023-10-23 14:31:20,574:INFO:               scipy: 1.10.1
2023-10-23 14:31:20,574:INFO:              joblib: 1.3.2
2023-10-23 14:31:20,574:INFO:             sklearn: 1.2.2
2023-10-23 14:31:20,574:INFO:                pyod: 1.1.0
2023-10-23 14:31:20,574:INFO:            imblearn: 0.11.0
2023-10-23 14:31:20,574:INFO:   category_encoders: 2.6.2
2023-10-23 14:31:20,574:INFO:            lightgbm: 4.1.0
2023-10-23 14:31:20,574:INFO:               numba: 0.58.1
2023-10-23 14:31:20,574:INFO:            requests: 2.31.0
2023-10-23 14:31:20,574:INFO:          matplotlib: 3.7.3
2023-10-23 14:31:20,574:INFO:          scikitplot: 0.3.7
2023-10-23 14:31:20,574:INFO:         yellowbrick: 1.5
2023-10-23 14:31:20,574:INFO:              plotly: 5.17.0
2023-10-23 14:31:20,574:INFO:    plotly-resampler: Not installed
2023-10-23 14:31:20,574:INFO:             kaleido: 0.2.1
2023-10-23 14:31:20,575:INFO:           schemdraw: 0.15
2023-10-23 14:31:20,575:INFO:         statsmodels: 0.14.0
2023-10-23 14:31:20,575:INFO:              sktime: 0.21.1
2023-10-23 14:31:20,575:INFO:               tbats: 1.1.3
2023-10-23 14:31:20,575:INFO:            pmdarima: 2.0.3
2023-10-23 14:31:20,575:INFO:              psutil: 5.9.0
2023-10-23 14:31:20,575:INFO:          markupsafe: 2.1.3
2023-10-23 14:31:20,575:INFO:             pickle5: Not installed
2023-10-23 14:31:20,575:INFO:         cloudpickle: 2.2.1
2023-10-23 14:31:20,575:INFO:         deprecation: 2.1.0
2023-10-23 14:31:20,575:INFO:              xxhash: 3.4.1
2023-10-23 14:31:20,575:INFO:           wurlitzer: Not installed
2023-10-23 14:31:20,575:INFO:PyCaret optional dependencies:
2023-10-23 14:31:20,591:INFO:                shap: Not installed
2023-10-23 14:31:20,591:INFO:           interpret: Not installed
2023-10-23 14:31:20,591:INFO:                umap: Not installed
2023-10-23 14:31:20,591:INFO:     ydata_profiling: Not installed
2023-10-23 14:31:20,592:INFO:  explainerdashboard: Not installed
2023-10-23 14:31:20,592:INFO:             autoviz: Not installed
2023-10-23 14:31:20,592:INFO:           fairlearn: Not installed
2023-10-23 14:31:20,592:INFO:          deepchecks: Not installed
2023-10-23 14:31:20,592:INFO:             xgboost: Not installed
2023-10-23 14:31:20,592:INFO:            catboost: 1.2.2
2023-10-23 14:31:20,592:INFO:              kmodes: Not installed
2023-10-23 14:31:20,592:INFO:             mlxtend: Not installed
2023-10-23 14:31:20,592:INFO:       statsforecast: Not installed
2023-10-23 14:31:20,592:INFO:        tune_sklearn: Not installed
2023-10-23 14:31:20,592:INFO:                 ray: Not installed
2023-10-23 14:31:20,592:INFO:            hyperopt: Not installed
2023-10-23 14:31:20,592:INFO:              optuna: Not installed
2023-10-23 14:31:20,592:INFO:               skopt: Not installed
2023-10-23 14:31:20,592:INFO:              mlflow: 2.7.1
2023-10-23 14:31:20,592:INFO:              gradio: Not installed
2023-10-23 14:31:20,593:INFO:             fastapi: Not installed
2023-10-23 14:31:20,593:INFO:             uvicorn: Not installed
2023-10-23 14:31:20,593:INFO:              m2cgen: Not installed
2023-10-23 14:31:20,593:INFO:           evidently: Not installed
2023-10-23 14:31:20,593:INFO:               fugue: Not installed
2023-10-23 14:31:20,593:INFO:           streamlit: Not installed
2023-10-23 14:31:20,593:INFO:             prophet: Not installed
2023-10-23 14:31:20,593:INFO:None
2023-10-23 14:31:20,593:INFO:Set up data.
2023-10-23 14:31:20,624:INFO:Set up folding strategy.
2023-10-23 14:31:20,624:INFO:Set up train/test split.
2023-10-23 14:31:20,660:INFO:Set up index.
2023-10-23 14:31:20,660:INFO:Assigning column types.
2023-10-23 14:31:20,691:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 14:31:20,691:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 14:31:20,700:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:31:20,700:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:31:20,791:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:31:20,838:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:31:20,838:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:31:20,838:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:31:20,838:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 14:31:20,838:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:31:20,854:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:31:20,934:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:31:20,991:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:31:20,991:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:31:20,992:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:31:20,992:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 14:31:20,998:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,003:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,082:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,119:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,119:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:31:21,119:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:31:21,138:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,143:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,225:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,276:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,276:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:31:21,276:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:31:21,276:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 14:31:21,295:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,381:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,435:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,436:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:31:21,436:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:31:21,436:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,535:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,586:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,591:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:31:21,591:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:31:21,591:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 14:31:21,684:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,736:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,737:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:31:21,737:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:31:21,837:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,891:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:31:21,891:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:31:21,891:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:31:21,891:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 14:31:22,006:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:31:22,065:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:31:22,066:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:31:22,153:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:31:22,210:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:31:22,210:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:31:22,211:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 14:31:22,351:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:31:22,352:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:31:22,517:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:31:22,517:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:31:22,518:INFO:Preparing preprocessing pipeline...
2023-10-23 14:31:22,518:INFO:Set up simple imputation.
2023-10-23 14:31:22,518:INFO:Set up column name cleaning.
2023-10-23 14:31:22,620:INFO:Finished creating preprocessing pipeline.
2023-10-23 14:31:22,626:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 14:31:22,626:INFO:Creating final display dataframe.
2023-10-23 14:31:22,894:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (34061, 50)
4        Transformed data shape   (34061, 50)
5   Transformed train set shape   (23842, 50)
6    Transformed test set shape   (10219, 50)
7              Numeric features            49
8      Rows with missing values         97.6%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_A
19                          USI          fafb
2023-10-23 14:31:23,033:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:31:23,033:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:31:23,176:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:31:23,176:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:31:23,176:INFO:Logging experiment in loggers
2023-10-23 14:31:23,521:INFO:SubProcess save_model() called ==================================
2023-10-23 14:31:23,540:INFO:Initializing save_model()
2023-10-23 14:31:23,540:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmp9ih1lsac\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 14:31:23,540:INFO:Adding model into prep_pipe
2023-10-23 14:31:23,540:WARNING:Only Model saved as it was a pipeline.
2023-10-23 14:31:23,552:INFO:C:\Users\thoma\AppData\Local\Temp\tmp9ih1lsac\Transformation Pipeline.pkl saved in current working directory
2023-10-23 14:31:23,553:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 14:31:23,553:INFO:save_model() successfully completed......................................
2023-10-23 14:31:23,666:INFO:SubProcess save_model() end ==================================
2023-10-23 14:31:23,750:INFO:setup() successfully completed in 2.7s...............
2023-10-23 14:31:23,750:INFO:Initializing create_model()
2023-10-23 14:31:23,750:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08C9C0F40>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:31:23,750:INFO:Checking exceptions
2023-10-23 14:31:23,754:INFO:Importing libraries
2023-10-23 14:31:23,754:INFO:Copying training dataset
2023-10-23 14:31:23,784:INFO:Defining folds
2023-10-23 14:31:23,784:INFO:Declaring metric variables
2023-10-23 14:31:23,784:INFO:Importing untrained model
2023-10-23 14:31:23,785:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:31:23,785:INFO:Starting cross validation
2023-10-23 14:31:23,794:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:31:33,183:INFO:Calculating mean and std
2023-10-23 14:31:33,186:INFO:Creating metrics dataframe
2023-10-23 14:31:33,189:INFO:Finalizing model
2023-10-23 14:31:33,309:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007339 seconds.
2023-10-23 14:31:33,309:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:31:33,310:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:31:33,311:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:31:33,312:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-23 14:31:33,643:INFO:Creating Dashboard logs
2023-10-23 14:31:33,643:INFO:Model: Light Gradient Boosting Machine
2023-10-23 14:31:33,772:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 14:31:34,007:INFO:Initializing predict_model()
2023-10-23 14:31:34,008:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08C9C0F40>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E0971B6EE0>)
2023-10-23 14:31:34,008:INFO:Checking exceptions
2023-10-23 14:31:34,008:INFO:Preloading libraries
2023-10-23 14:31:34,363:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\_distutils_hack\__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2023-10-23 14:31:34,627:INFO:Uploading results into container
2023-10-23 14:31:34,627:INFO:Uploading model into container now
2023-10-23 14:31:34,642:INFO:_master_model_container: 1
2023-10-23 14:31:34,642:INFO:_display_container: 2
2023-10-23 14:31:34,643:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:31:34,643:INFO:create_model() successfully completed......................................
2023-10-23 14:31:34,776:INFO:Initializing tune_model()
2023-10-23 14:31:34,776:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08C9C0F40>)
2023-10-23 14:31:34,776:INFO:Checking exceptions
2023-10-23 14:31:34,791:INFO:Copying training dataset
2023-10-23 14:31:34,810:INFO:Checking base model
2023-10-23 14:31:34,811:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 14:31:34,812:INFO:Declaring metric variables
2023-10-23 14:31:34,812:INFO:Defining Hyperparameters
2023-10-23 14:31:34,967:INFO:Tuning with n_jobs=-1
2023-10-23 14:31:34,968:INFO:Initializing RandomizedSearchCV
2023-10-23 14:32:26,101:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-23 14:32:26,102:INFO:Hyperparameter search completed
2023-10-23 14:32:26,103:INFO:SubProcess create_model() called ==================================
2023-10-23 14:32:26,104:INFO:Initializing create_model()
2023-10-23 14:32:26,104:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08C9C0F40>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E096F053A0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-23 14:32:26,104:INFO:Checking exceptions
2023-10-23 14:32:26,105:INFO:Importing libraries
2023-10-23 14:32:26,105:INFO:Copying training dataset
2023-10-23 14:32:26,137:INFO:Defining folds
2023-10-23 14:32:26,137:INFO:Declaring metric variables
2023-10-23 14:32:26,137:INFO:Importing untrained model
2023-10-23 14:32:26,138:INFO:Declaring custom model
2023-10-23 14:32:26,140:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:32:26,140:INFO:Starting cross validation
2023-10-23 14:32:26,142:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:32:34,733:INFO:Calculating mean and std
2023-10-23 14:32:34,734:INFO:Creating metrics dataframe
2023-10-23 14:32:34,738:INFO:Finalizing model
2023-10-23 14:32:34,801:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-23 14:32:34,801:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-23 14:32:34,801:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-23 14:32:34,842:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-23 14:32:34,842:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-23 14:32:34,842:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-23 14:32:34,851:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006217 seconds.
2023-10-23 14:32:34,851:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:32:34,852:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:32:34,853:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:32:34,855:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-23 14:32:36,016:INFO:Uploading results into container
2023-10-23 14:32:36,017:INFO:Uploading model into container now
2023-10-23 14:32:36,018:INFO:_master_model_container: 2
2023-10-23 14:32:36,018:INFO:_display_container: 3
2023-10-23 14:32:36,019:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-23 14:32:36,020:INFO:create_model() successfully completed......................................
2023-10-23 14:32:36,140:INFO:SubProcess create_model() end ==================================
2023-10-23 14:32:36,141:INFO:choose_better activated
2023-10-23 14:32:36,141:INFO:SubProcess create_model() called ==================================
2023-10-23 14:32:36,142:INFO:Initializing create_model()
2023-10-23 14:32:36,142:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08C9C0F40>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:32:36,142:INFO:Checking exceptions
2023-10-23 14:32:36,143:INFO:Importing libraries
2023-10-23 14:32:36,143:INFO:Copying training dataset
2023-10-23 14:32:36,165:INFO:Defining folds
2023-10-23 14:32:36,166:INFO:Declaring metric variables
2023-10-23 14:32:36,166:INFO:Importing untrained model
2023-10-23 14:32:36,166:INFO:Declaring custom model
2023-10-23 14:32:36,167:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:32:36,167:INFO:Starting cross validation
2023-10-23 14:32:36,168:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:32:38,715:INFO:Calculating mean and std
2023-10-23 14:32:38,715:INFO:Creating metrics dataframe
2023-10-23 14:32:38,718:INFO:Finalizing model
2023-10-23 14:32:38,816:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006205 seconds.
2023-10-23 14:32:38,816:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:32:38,817:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:32:38,817:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:32:38,819:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-23 14:32:39,027:INFO:Uploading results into container
2023-10-23 14:32:39,028:INFO:Uploading model into container now
2023-10-23 14:32:39,028:INFO:_master_model_container: 3
2023-10-23 14:32:39,028:INFO:_display_container: 4
2023-10-23 14:32:39,029:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:32:39,029:INFO:create_model() successfully completed......................................
2023-10-23 14:32:39,151:INFO:SubProcess create_model() end ==================================
2023-10-23 14:32:39,152:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8716
2023-10-23 14:32:39,153:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8712
2023-10-23 14:32:39,153:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-23 14:32:39,154:INFO:choose_better completed
2023-10-23 14:32:39,154:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-23 14:32:39,154:INFO:Creating Dashboard logs
2023-10-23 14:32:39,155:INFO:Model: Light Gradient Boosting Machine
2023-10-23 14:32:39,225:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 14:32:39,422:INFO:Initializing predict_model()
2023-10-23 14:32:39,422:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08C9C0F40>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E0970AACA0>)
2023-10-23 14:32:39,422:INFO:Checking exceptions
2023-10-23 14:32:39,422:INFO:Preloading libraries
2023-10-23 14:32:39,882:INFO:_master_model_container: 3
2023-10-23 14:32:39,883:INFO:_display_container: 3
2023-10-23 14:32:39,883:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:32:39,883:INFO:tune_model() successfully completed......................................
2023-10-23 14:32:39,991:INFO:Initializing ensemble_model()
2023-10-23 14:32:39,991:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08C9C0F40>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-23 14:32:39,991:INFO:Checking exceptions
2023-10-23 14:32:40,002:INFO:Importing libraries
2023-10-23 14:32:40,002:INFO:Copying training dataset
2023-10-23 14:32:40,003:INFO:Checking base model
2023-10-23 14:32:40,003:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 14:32:40,004:INFO:Importing untrained ensembler
2023-10-23 14:32:40,004:INFO:Ensemble method set to Bagging
2023-10-23 14:32:40,004:INFO:SubProcess create_model() called ==================================
2023-10-23 14:32:40,006:INFO:Initializing create_model()
2023-10-23 14:32:40,006:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08C9C0F40>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E096980A00>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:32:40,006:INFO:Checking exceptions
2023-10-23 14:32:40,006:INFO:Importing libraries
2023-10-23 14:32:40,006:INFO:Copying training dataset
2023-10-23 14:32:40,031:INFO:Defining folds
2023-10-23 14:32:40,031:INFO:Declaring metric variables
2023-10-23 14:32:40,032:INFO:Importing untrained model
2023-10-23 14:32:40,032:INFO:Declaring custom model
2023-10-23 14:32:40,033:INFO:Bagging Regressor Imported successfully
2023-10-23 14:32:40,034:INFO:Starting cross validation
2023-10-23 14:32:40,035:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:33:03,739:INFO:Calculating mean and std
2023-10-23 14:33:03,740:INFO:Creating metrics dataframe
2023-10-23 14:33:03,743:INFO:Finalizing model
2023-10-23 14:33:03,847:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005392 seconds.
2023-10-23 14:33:03,847:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:03,848:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:33:03,848:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:33:03,849:INFO:[LightGBM] [Info] Start training from score 626.831517
2023-10-23 14:33:04,126:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005093 seconds.
2023-10-23 14:33:04,126:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:04,126:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:33:04,127:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:33:04,127:INFO:[LightGBM] [Info] Start training from score 640.013980
2023-10-23 14:33:04,360:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005521 seconds.
2023-10-23 14:33:04,360:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:04,360:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:33:04,360:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:33:04,360:INFO:[LightGBM] [Info] Start training from score 623.946930
2023-10-23 14:33:04,628:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005296 seconds.
2023-10-23 14:33:04,628:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:04,629:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:33:04,629:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:33:04,629:INFO:[LightGBM] [Info] Start training from score 632.335152
2023-10-23 14:33:04,919:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006870 seconds.
2023-10-23 14:33:04,919:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:04,919:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:33:04,920:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:33:04,921:INFO:[LightGBM] [Info] Start training from score 620.070240
2023-10-23 14:33:05,194:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013481 seconds.
2023-10-23 14:33:05,195:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:05,195:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:33:05,196:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:33:05,202:INFO:[LightGBM] [Info] Start training from score 635.137343
2023-10-23 14:33:05,504:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005992 seconds.
2023-10-23 14:33:05,504:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:05,504:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:33:05,504:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:33:05,504:INFO:[LightGBM] [Info] Start training from score 620.066941
2023-10-23 14:33:05,783:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005717 seconds.
2023-10-23 14:33:05,783:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:05,783:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:33:05,783:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:33:05,783:INFO:[LightGBM] [Info] Start training from score 623.069874
2023-10-23 14:33:06,126:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007570 seconds.
2023-10-23 14:33:06,126:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:06,127:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:33:06,130:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:33:06,132:INFO:[LightGBM] [Info] Start training from score 633.817057
2023-10-23 14:33:06,447:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005651 seconds.
2023-10-23 14:33:06,447:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:06,447:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:33:06,448:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:33:06,448:INFO:[LightGBM] [Info] Start training from score 641.113408
2023-10-23 14:33:06,712:INFO:Uploading results into container
2023-10-23 14:33:06,713:INFO:Uploading model into container now
2023-10-23 14:33:06,714:INFO:_master_model_container: 4
2023-10-23 14:33:06,715:INFO:_display_container: 4
2023-10-23 14:33:06,717:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:33:06,717:INFO:create_model() successfully completed......................................
2023-10-23 14:33:06,840:INFO:SubProcess create_model() end ==================================
2023-10-23 14:33:06,840:INFO:Creating Dashboard logs
2023-10-23 14:33:06,841:INFO:Model: Bagging Regressor
2023-10-23 14:33:06,915:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-23 14:33:07,147:INFO:Initializing predict_model()
2023-10-23 14:33:07,147:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08C9C0F40>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E097086F70>)
2023-10-23 14:33:07,147:INFO:Checking exceptions
2023-10-23 14:33:07,147:INFO:Preloading libraries
2023-10-23 14:33:07,797:INFO:_master_model_container: 4
2023-10-23 14:33:07,797:INFO:_display_container: 4
2023-10-23 14:33:07,797:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:33:07,797:INFO:ensemble_model() successfully completed......................................
2023-10-23 14:33:07,914:INFO:Initializing finalize_model()
2023-10-23 14:33:07,914:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08C9C0F40>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-23 14:33:07,914:INFO:Finalizing BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:33:07,930:INFO:Initializing create_model()
2023-10-23 14:33:07,930:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E08C9C0F40>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-23 14:33:07,930:INFO:Checking exceptions
2023-10-23 14:33:07,930:INFO:Importing libraries
2023-10-23 14:33:07,930:INFO:Copying training dataset
2023-10-23 14:33:07,930:INFO:Defining folds
2023-10-23 14:33:07,930:INFO:Declaring metric variables
2023-10-23 14:33:07,930:INFO:Importing untrained model
2023-10-23 14:33:07,930:INFO:Declaring custom model
2023-10-23 14:33:07,930:INFO:Bagging Regressor Imported successfully
2023-10-23 14:33:07,930:INFO:Cross validation set to False
2023-10-23 14:33:07,930:INFO:Fitting Model
2023-10-23 14:33:08,096:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009957 seconds.
2023-10-23 14:33:08,096:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:08,097:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:33:08,098:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:33:08,099:INFO:[LightGBM] [Info] Start training from score 634.491655
2023-10-23 14:33:08,482:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009853 seconds.
2023-10-23 14:33:08,482:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:08,482:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:33:08,483:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:33:08,485:INFO:[LightGBM] [Info] Start training from score 635.470959
2023-10-23 14:33:08,899:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009146 seconds.
2023-10-23 14:33:08,899:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:08,900:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:33:08,901:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:33:08,902:INFO:[LightGBM] [Info] Start training from score 634.053589
2023-10-23 14:33:09,365:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009197 seconds.
2023-10-23 14:33:09,365:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:09,365:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:33:09,365:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:33:09,365:INFO:[LightGBM] [Info] Start training from score 635.251785
2023-10-23 14:33:09,698:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008816 seconds.
2023-10-23 14:33:09,698:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:09,698:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:33:09,698:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:33:09,700:INFO:[LightGBM] [Info] Start training from score 627.555784
2023-10-23 14:33:10,053:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007364 seconds.
2023-10-23 14:33:10,053:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:10,054:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:33:10,054:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:33:10,056:INFO:[LightGBM] [Info] Start training from score 638.162596
2023-10-23 14:33:10,381:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007790 seconds.
2023-10-23 14:33:10,381:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:10,382:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:33:10,382:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:33:10,383:INFO:[LightGBM] [Info] Start training from score 633.181363
2023-10-23 14:33:10,722:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007785 seconds.
2023-10-23 14:33:10,722:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:10,723:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:33:10,723:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:33:10,724:INFO:[LightGBM] [Info] Start training from score 611.992287
2023-10-23 14:33:11,063:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007802 seconds.
2023-10-23 14:33:11,063:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:11,063:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:33:11,064:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:33:11,064:INFO:[LightGBM] [Info] Start training from score 638.181417
2023-10-23 14:33:11,383:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009670 seconds.
2023-10-23 14:33:11,383:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:11,383:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:33:11,383:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:33:11,383:INFO:[LightGBM] [Info] Start training from score 639.502137
2023-10-23 14:33:11,665:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:33:11,665:INFO:create_model() successfully completed......................................
2023-10-23 14:33:11,782:INFO:Creating Dashboard logs
2023-10-23 14:33:11,782:INFO:Model: Bagging Regressor
2023-10-23 14:33:11,860:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-23 14:33:12,279:INFO:_master_model_container: 4
2023-10-23 14:33:12,279:INFO:_display_container: 4
2023-10-23 14:33:12,290:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:33:12,290:INFO:finalize_model() successfully completed......................................
2023-10-23 14:33:12,404:INFO:Initializing save_model()
2023-10-23 14:33:12,404:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), model_name=final_model_for_location_A, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 14:33:12,404:INFO:Adding model into prep_pipe
2023-10-23 14:33:12,404:WARNING:Only Model saved as it was a pipeline.
2023-10-23 14:33:12,466:INFO:final_model_for_location_A.pkl saved in current working directory
2023-10-23 14:33:12,482:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:33:12,482:INFO:save_model() successfully completed......................................
2023-10-23 14:33:12,615:INFO:PyCaret RegressionExperiment
2023-10-23 14:33:12,615:INFO:Logging name: exp_B
2023-10-23 14:33:12,615:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 14:33:12,615:INFO:version 3.1.0
2023-10-23 14:33:12,615:INFO:Initializing setup()
2023-10-23 14:33:12,615:INFO:self.USI: 5eaa
2023-10-23 14:33:12,615:INFO:self._variable_keys: {'gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', '_ml_usecase', 'gpu_param', 'exp_name_log', 'html_param', 'fold_generator', 'y', 'seed', 'y_train', 'transform_target_param', 'n_jobs_param', 'target_param', 'idx', '_available_plots', 'log_plots_param', 'memory', 'data', 'USI', 'X', 'logging_param', 'pipeline', 'exp_id', 'X_train', 'X_test', 'fold_groups_param'}
2023-10-23 14:33:12,615:INFO:Checking environment
2023-10-23 14:33:12,615:INFO:python_version: 3.8.18
2023-10-23 14:33:12,615:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 14:33:12,615:INFO:machine: AMD64
2023-10-23 14:33:12,615:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 14:33:12,616:INFO:Memory: svmem(total=16505954304, available=2925641728, percent=82.3, used=13580312576, free=2925641728)
2023-10-23 14:33:12,616:INFO:Physical Core: 8
2023-10-23 14:33:12,616:INFO:Logical Core: 16
2023-10-23 14:33:12,616:INFO:Checking libraries
2023-10-23 14:33:12,616:INFO:System:
2023-10-23 14:33:12,616:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 14:33:12,616:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 14:33:12,616:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 14:33:12,616:INFO:PyCaret required dependencies:
2023-10-23 14:33:12,616:INFO:                 pip: 23.3
2023-10-23 14:33:12,617:INFO:          setuptools: 68.0.0
2023-10-23 14:33:12,617:INFO:             pycaret: 3.1.0
2023-10-23 14:33:12,617:INFO:             IPython: 8.12.0
2023-10-23 14:33:12,617:INFO:          ipywidgets: 8.1.1
2023-10-23 14:33:12,617:INFO:                tqdm: 4.66.1
2023-10-23 14:33:12,617:INFO:               numpy: 1.23.5
2023-10-23 14:33:12,617:INFO:              pandas: 1.5.3
2023-10-23 14:33:12,617:INFO:              jinja2: 3.1.2
2023-10-23 14:33:12,617:INFO:               scipy: 1.10.1
2023-10-23 14:33:12,617:INFO:              joblib: 1.3.2
2023-10-23 14:33:12,617:INFO:             sklearn: 1.2.2
2023-10-23 14:33:12,617:INFO:                pyod: 1.1.0
2023-10-23 14:33:12,617:INFO:            imblearn: 0.11.0
2023-10-23 14:33:12,617:INFO:   category_encoders: 2.6.2
2023-10-23 14:33:12,617:INFO:            lightgbm: 4.1.0
2023-10-23 14:33:12,618:INFO:               numba: 0.58.1
2023-10-23 14:33:12,618:INFO:            requests: 2.31.0
2023-10-23 14:33:12,618:INFO:          matplotlib: 3.7.3
2023-10-23 14:33:12,618:INFO:          scikitplot: 0.3.7
2023-10-23 14:33:12,618:INFO:         yellowbrick: 1.5
2023-10-23 14:33:12,618:INFO:              plotly: 5.17.0
2023-10-23 14:33:12,618:INFO:    plotly-resampler: Not installed
2023-10-23 14:33:12,618:INFO:             kaleido: 0.2.1
2023-10-23 14:33:12,618:INFO:           schemdraw: 0.15
2023-10-23 14:33:12,619:INFO:         statsmodels: 0.14.0
2023-10-23 14:33:12,619:INFO:              sktime: 0.21.1
2023-10-23 14:33:12,619:INFO:               tbats: 1.1.3
2023-10-23 14:33:12,619:INFO:            pmdarima: 2.0.3
2023-10-23 14:33:12,619:INFO:              psutil: 5.9.0
2023-10-23 14:33:12,619:INFO:          markupsafe: 2.1.3
2023-10-23 14:33:12,619:INFO:             pickle5: Not installed
2023-10-23 14:33:12,619:INFO:         cloudpickle: 2.2.1
2023-10-23 14:33:12,619:INFO:         deprecation: 2.1.0
2023-10-23 14:33:12,619:INFO:              xxhash: 3.4.1
2023-10-23 14:33:12,619:INFO:           wurlitzer: Not installed
2023-10-23 14:33:12,619:INFO:PyCaret optional dependencies:
2023-10-23 14:33:12,620:INFO:                shap: Not installed
2023-10-23 14:33:12,620:INFO:           interpret: Not installed
2023-10-23 14:33:12,620:INFO:                umap: Not installed
2023-10-23 14:33:12,620:INFO:     ydata_profiling: Not installed
2023-10-23 14:33:12,620:INFO:  explainerdashboard: Not installed
2023-10-23 14:33:12,620:INFO:             autoviz: Not installed
2023-10-23 14:33:12,620:INFO:           fairlearn: Not installed
2023-10-23 14:33:12,620:INFO:          deepchecks: Not installed
2023-10-23 14:33:12,620:INFO:             xgboost: Not installed
2023-10-23 14:33:12,620:INFO:            catboost: 1.2.2
2023-10-23 14:33:12,620:INFO:              kmodes: Not installed
2023-10-23 14:33:12,620:INFO:             mlxtend: Not installed
2023-10-23 14:33:12,620:INFO:       statsforecast: Not installed
2023-10-23 14:33:12,620:INFO:        tune_sklearn: Not installed
2023-10-23 14:33:12,621:INFO:                 ray: Not installed
2023-10-23 14:33:12,621:INFO:            hyperopt: Not installed
2023-10-23 14:33:12,621:INFO:              optuna: Not installed
2023-10-23 14:33:12,621:INFO:               skopt: Not installed
2023-10-23 14:33:12,621:INFO:              mlflow: 2.7.1
2023-10-23 14:33:12,621:INFO:              gradio: Not installed
2023-10-23 14:33:12,621:INFO:             fastapi: Not installed
2023-10-23 14:33:12,621:INFO:             uvicorn: Not installed
2023-10-23 14:33:12,621:INFO:              m2cgen: Not installed
2023-10-23 14:33:12,621:INFO:           evidently: Not installed
2023-10-23 14:33:12,621:INFO:               fugue: Not installed
2023-10-23 14:33:12,621:INFO:           streamlit: Not installed
2023-10-23 14:33:12,621:INFO:             prophet: Not installed
2023-10-23 14:33:12,622:INFO:None
2023-10-23 14:33:12,622:INFO:Set up data.
2023-10-23 14:33:12,660:INFO:Set up folding strategy.
2023-10-23 14:33:12,660:INFO:Set up train/test split.
2023-10-23 14:33:12,686:INFO:Set up index.
2023-10-23 14:33:12,688:INFO:Assigning column types.
2023-10-23 14:33:12,712:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 14:33:12,713:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 14:33:12,718:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:33:12,723:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:33:12,804:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:33:12,853:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:33:12,854:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:33:12,854:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:33:12,855:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 14:33:12,860:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:33:12,866:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:33:12,943:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:33:12,992:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:33:12,993:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:33:12,993:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:33:12,994:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 14:33:12,999:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,004:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,083:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,126:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,126:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:33:13,126:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:33:13,126:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,143:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,239:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,293:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,293:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:33:13,293:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:33:13,293:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 14:33:13,310:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,376:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,425:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,425:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:33:13,425:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:33:13,442:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,546:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,592:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,592:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:33:13,592:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:33:13,592:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 14:33:13,709:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,759:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,759:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:33:13,759:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:33:13,843:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,893:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:33:13,893:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:33:13,893:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:33:13,893:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 14:33:13,992:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:33:14,043:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:33:14,044:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:33:14,142:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:33:14,192:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:33:14,193:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:33:14,193:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 14:33:14,330:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:33:14,331:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:33:14,472:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:33:14,472:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:33:14,474:INFO:Preparing preprocessing pipeline...
2023-10-23 14:33:14,474:INFO:Set up simple imputation.
2023-10-23 14:33:14,477:INFO:Set up column name cleaning.
2023-10-23 14:33:14,547:INFO:Finished creating preprocessing pipeline.
2023-10-23 14:33:14,553:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 14:33:14,553:INFO:Creating final display dataframe.
2023-10-23 14:33:14,771:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (32819, 50)
4        Transformed data shape   (32819, 50)
5   Transformed train set shape   (22973, 50)
6    Transformed test set shape    (9846, 50)
7              Numeric features            49
8      Rows with missing values         95.9%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_B
19                          USI          5eaa
2023-10-23 14:33:14,933:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:33:14,934:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:33:15,078:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:33:15,078:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:33:15,079:INFO:Logging experiment in loggers
2023-10-23 14:33:15,206:INFO:SubProcess save_model() called ==================================
2023-10-23 14:33:15,210:INFO:Initializing save_model()
2023-10-23 14:33:15,210:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmplxeawuw9\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 14:33:15,210:INFO:Adding model into prep_pipe
2023-10-23 14:33:15,210:WARNING:Only Model saved as it was a pipeline.
2023-10-23 14:33:15,227:INFO:C:\Users\thoma\AppData\Local\Temp\tmplxeawuw9\Transformation Pipeline.pkl saved in current working directory
2023-10-23 14:33:15,229:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 14:33:15,229:INFO:save_model() successfully completed......................................
2023-10-23 14:33:15,343:INFO:SubProcess save_model() end ==================================
2023-10-23 14:33:15,406:INFO:setup() successfully completed in 2.47s...............
2023-10-23 14:33:15,406:INFO:Initializing create_model()
2023-10-23 14:33:15,406:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096DCF190>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:33:15,406:INFO:Checking exceptions
2023-10-23 14:33:15,410:INFO:Importing libraries
2023-10-23 14:33:15,410:INFO:Copying training dataset
2023-10-23 14:33:15,435:INFO:Defining folds
2023-10-23 14:33:15,435:INFO:Declaring metric variables
2023-10-23 14:33:15,435:INFO:Importing untrained model
2023-10-23 14:33:15,435:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:33:15,439:INFO:Starting cross validation
2023-10-23 14:33:15,440:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:33:17,998:INFO:Calculating mean and std
2023-10-23 14:33:18,000:INFO:Creating metrics dataframe
2023-10-23 14:33:18,002:INFO:Finalizing model
2023-10-23 14:33:18,101:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005265 seconds.
2023-10-23 14:33:18,101:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:33:18,101:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:33:18,102:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:33:18,103:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-23 14:33:18,346:INFO:Creating Dashboard logs
2023-10-23 14:33:18,347:INFO:Model: Light Gradient Boosting Machine
2023-10-23 14:33:18,448:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 14:33:18,669:INFO:Initializing predict_model()
2023-10-23 14:33:18,670:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096DCF190>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096789040>)
2023-10-23 14:33:18,670:INFO:Checking exceptions
2023-10-23 14:33:18,670:INFO:Preloading libraries
2023-10-23 14:33:19,177:INFO:Uploading results into container
2023-10-23 14:33:19,179:INFO:Uploading model into container now
2023-10-23 14:33:19,183:INFO:_master_model_container: 1
2023-10-23 14:33:19,183:INFO:_display_container: 2
2023-10-23 14:33:19,184:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:33:19,184:INFO:create_model() successfully completed......................................
2023-10-23 14:33:19,283:INFO:Initializing tune_model()
2023-10-23 14:33:19,283:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096DCF190>)
2023-10-23 14:33:19,283:INFO:Checking exceptions
2023-10-23 14:33:19,296:INFO:Copying training dataset
2023-10-23 14:33:19,311:INFO:Checking base model
2023-10-23 14:33:19,312:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 14:33:19,312:INFO:Declaring metric variables
2023-10-23 14:33:19,313:INFO:Defining Hyperparameters
2023-10-23 14:33:19,424:INFO:Tuning with n_jobs=-1
2023-10-23 14:33:19,424:INFO:Initializing RandomizedSearchCV
2023-10-23 14:34:01,842:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-23 14:34:01,844:INFO:Hyperparameter search completed
2023-10-23 14:34:01,844:INFO:SubProcess create_model() called ==================================
2023-10-23 14:34:01,845:INFO:Initializing create_model()
2023-10-23 14:34:01,846:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096DCF190>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E096AC0AC0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-23 14:34:01,846:INFO:Checking exceptions
2023-10-23 14:34:01,847:INFO:Importing libraries
2023-10-23 14:34:01,847:INFO:Copying training dataset
2023-10-23 14:34:01,879:INFO:Defining folds
2023-10-23 14:34:01,879:INFO:Declaring metric variables
2023-10-23 14:34:01,879:INFO:Importing untrained model
2023-10-23 14:34:01,879:INFO:Declaring custom model
2023-10-23 14:34:01,881:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:34:01,881:INFO:Starting cross validation
2023-10-23 14:34:01,883:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:34:10,558:INFO:Calculating mean and std
2023-10-23 14:34:10,558:INFO:Creating metrics dataframe
2023-10-23 14:34:10,563:INFO:Finalizing model
2023-10-23 14:34:10,612:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-23 14:34:10,612:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-23 14:34:10,612:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-23 14:34:10,658:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-23 14:34:10,658:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-23 14:34:10,658:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-23 14:34:10,658:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005687 seconds.
2023-10-23 14:34:10,658:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:10,658:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:34:10,673:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:34:10,673:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-23 14:34:11,591:INFO:Uploading results into container
2023-10-23 14:34:11,591:INFO:Uploading model into container now
2023-10-23 14:34:11,591:INFO:_master_model_container: 2
2023-10-23 14:34:11,591:INFO:_display_container: 3
2023-10-23 14:34:11,591:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-23 14:34:11,591:INFO:create_model() successfully completed......................................
2023-10-23 14:34:11,731:INFO:SubProcess create_model() end ==================================
2023-10-23 14:34:11,731:INFO:choose_better activated
2023-10-23 14:34:11,731:INFO:SubProcess create_model() called ==================================
2023-10-23 14:34:11,731:INFO:Initializing create_model()
2023-10-23 14:34:11,731:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096DCF190>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:34:11,731:INFO:Checking exceptions
2023-10-23 14:34:11,731:INFO:Importing libraries
2023-10-23 14:34:11,731:INFO:Copying training dataset
2023-10-23 14:34:11,749:INFO:Defining folds
2023-10-23 14:34:11,749:INFO:Declaring metric variables
2023-10-23 14:34:11,749:INFO:Importing untrained model
2023-10-23 14:34:11,749:INFO:Declaring custom model
2023-10-23 14:34:11,749:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:34:11,749:INFO:Starting cross validation
2023-10-23 14:34:11,749:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:34:14,239:INFO:Calculating mean and std
2023-10-23 14:34:14,239:INFO:Creating metrics dataframe
2023-10-23 14:34:14,239:INFO:Finalizing model
2023-10-23 14:34:14,344:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005003 seconds.
2023-10-23 14:34:14,344:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:14,344:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:34:14,344:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:34:14,344:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-23 14:34:14,560:INFO:Uploading results into container
2023-10-23 14:34:14,560:INFO:Uploading model into container now
2023-10-23 14:34:14,560:INFO:_master_model_container: 3
2023-10-23 14:34:14,560:INFO:_display_container: 4
2023-10-23 14:34:14,560:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:34:14,560:INFO:create_model() successfully completed......................................
2023-10-23 14:34:14,692:INFO:SubProcess create_model() end ==================================
2023-10-23 14:34:14,692:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8523
2023-10-23 14:34:14,692:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8523
2023-10-23 14:34:14,692:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-23 14:34:14,692:INFO:choose_better completed
2023-10-23 14:34:14,692:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-23 14:34:14,696:INFO:Creating Dashboard logs
2023-10-23 14:34:14,696:INFO:Model: Light Gradient Boosting Machine
2023-10-23 14:34:14,757:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 14:34:14,955:INFO:Initializing predict_model()
2023-10-23 14:34:14,956:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096DCF190>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096702B80>)
2023-10-23 14:34:14,956:INFO:Checking exceptions
2023-10-23 14:34:14,956:INFO:Preloading libraries
2023-10-23 14:34:15,442:INFO:_master_model_container: 3
2023-10-23 14:34:15,442:INFO:_display_container: 3
2023-10-23 14:34:15,442:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:34:15,442:INFO:tune_model() successfully completed......................................
2023-10-23 14:34:15,541:INFO:Initializing ensemble_model()
2023-10-23 14:34:15,541:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096DCF190>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-23 14:34:15,541:INFO:Checking exceptions
2023-10-23 14:34:15,541:INFO:Importing libraries
2023-10-23 14:34:15,557:INFO:Copying training dataset
2023-10-23 14:34:15,557:INFO:Checking base model
2023-10-23 14:34:15,557:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 14:34:15,557:INFO:Importing untrained ensembler
2023-10-23 14:34:15,557:INFO:Ensemble method set to Bagging
2023-10-23 14:34:15,557:INFO:SubProcess create_model() called ==================================
2023-10-23 14:34:15,557:INFO:Initializing create_model()
2023-10-23 14:34:15,557:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096DCF190>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E093358DC0>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:34:15,557:INFO:Checking exceptions
2023-10-23 14:34:15,557:INFO:Importing libraries
2023-10-23 14:34:15,557:INFO:Copying training dataset
2023-10-23 14:34:15,584:INFO:Defining folds
2023-10-23 14:34:15,584:INFO:Declaring metric variables
2023-10-23 14:34:15,584:INFO:Importing untrained model
2023-10-23 14:34:15,585:INFO:Declaring custom model
2023-10-23 14:34:15,586:INFO:Bagging Regressor Imported successfully
2023-10-23 14:34:15,586:INFO:Starting cross validation
2023-10-23 14:34:15,586:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:34:39,965:INFO:Calculating mean and std
2023-10-23 14:34:39,968:INFO:Creating metrics dataframe
2023-10-23 14:34:39,977:INFO:Finalizing model
2023-10-23 14:34:40,098:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005697 seconds.
2023-10-23 14:34:40,098:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:40,099:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:34:40,100:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:34:40,101:INFO:[LightGBM] [Info] Start training from score 99.624795
2023-10-23 14:34:40,488:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006397 seconds.
2023-10-23 14:34:40,488:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:40,488:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:34:40,488:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:34:40,488:INFO:[LightGBM] [Info] Start training from score 96.229614
2023-10-23 14:34:40,794:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007142 seconds.
2023-10-23 14:34:40,795:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:40,795:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:34:40,796:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:34:40,797:INFO:[LightGBM] [Info] Start training from score 95.360987
2023-10-23 14:34:41,165:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006056 seconds.
2023-10-23 14:34:41,165:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:41,166:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:34:41,167:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:34:41,168:INFO:[LightGBM] [Info] Start training from score 94.348528
2023-10-23 14:34:41,523:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006255 seconds.
2023-10-23 14:34:41,523:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:41,524:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:34:41,524:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:34:41,525:INFO:[LightGBM] [Info] Start training from score 95.509684
2023-10-23 14:34:41,805:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005180 seconds.
2023-10-23 14:34:41,805:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:41,805:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:34:41,806:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:34:41,807:INFO:[LightGBM] [Info] Start training from score 96.036959
2023-10-23 14:34:42,069:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005656 seconds.
2023-10-23 14:34:42,069:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:42,069:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:34:42,069:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:34:42,069:INFO:[LightGBM] [Info] Start training from score 97.844637
2023-10-23 14:34:42,339:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005494 seconds.
2023-10-23 14:34:42,339:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:42,339:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:34:42,339:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:34:42,339:INFO:[LightGBM] [Info] Start training from score 96.245614
2023-10-23 14:34:42,619:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007108 seconds.
2023-10-23 14:34:42,619:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:42,619:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:34:42,619:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:34:42,634:INFO:[LightGBM] [Info] Start training from score 97.594984
2023-10-23 14:34:42,901:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005595 seconds.
2023-10-23 14:34:42,901:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:42,917:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:34:42,918:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:34:42,918:INFO:[LightGBM] [Info] Start training from score 96.370407
2023-10-23 14:34:43,133:INFO:Uploading results into container
2023-10-23 14:34:43,134:INFO:Uploading model into container now
2023-10-23 14:34:43,136:INFO:_master_model_container: 4
2023-10-23 14:34:43,136:INFO:_display_container: 4
2023-10-23 14:34:43,138:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:34:43,138:INFO:create_model() successfully completed......................................
2023-10-23 14:34:43,255:INFO:SubProcess create_model() end ==================================
2023-10-23 14:34:43,255:INFO:Creating Dashboard logs
2023-10-23 14:34:43,255:INFO:Model: Bagging Regressor
2023-10-23 14:34:43,328:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-23 14:34:43,568:INFO:Initializing predict_model()
2023-10-23 14:34:43,568:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096DCF190>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096702DC0>)
2023-10-23 14:34:43,568:INFO:Checking exceptions
2023-10-23 14:34:43,568:INFO:Preloading libraries
2023-10-23 14:34:44,167:INFO:_master_model_container: 4
2023-10-23 14:34:44,167:INFO:_display_container: 4
2023-10-23 14:34:44,167:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:34:44,167:INFO:ensemble_model() successfully completed......................................
2023-10-23 14:34:44,272:INFO:Initializing finalize_model()
2023-10-23 14:34:44,272:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096DCF190>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-23 14:34:44,282:INFO:Finalizing BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:34:44,298:INFO:Initializing create_model()
2023-10-23 14:34:44,299:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096DCF190>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-23 14:34:44,299:INFO:Checking exceptions
2023-10-23 14:34:44,300:INFO:Importing libraries
2023-10-23 14:34:44,300:INFO:Copying training dataset
2023-10-23 14:34:44,301:INFO:Defining folds
2023-10-23 14:34:44,301:INFO:Declaring metric variables
2023-10-23 14:34:44,301:INFO:Importing untrained model
2023-10-23 14:34:44,301:INFO:Declaring custom model
2023-10-23 14:34:44,303:INFO:Bagging Regressor Imported successfully
2023-10-23 14:34:44,304:INFO:Cross validation set to False
2023-10-23 14:34:44,304:INFO:Fitting Model
2023-10-23 14:34:44,479:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017216 seconds.
2023-10-23 14:34:44,479:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:44,480:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:34:44,481:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:34:44,482:INFO:[LightGBM] [Info] Start training from score 96.465021
2023-10-23 14:34:44,857:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008815 seconds.
2023-10-23 14:34:44,868:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:44,868:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:34:44,868:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:34:44,868:INFO:[LightGBM] [Info] Start training from score 97.264361
2023-10-23 14:34:45,254:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008657 seconds.
2023-10-23 14:34:45,254:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:45,254:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:34:45,254:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:34:45,254:INFO:[LightGBM] [Info] Start training from score 95.842370
2023-10-23 14:34:45,684:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008002 seconds.
2023-10-23 14:34:45,684:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:45,684:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:34:45,684:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:34:45,684:INFO:[LightGBM] [Info] Start training from score 95.431515
2023-10-23 14:34:46,034:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008044 seconds.
2023-10-23 14:34:46,034:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:46,034:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:34:46,034:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:34:46,034:INFO:[LightGBM] [Info] Start training from score 97.222213
2023-10-23 14:34:46,383:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009419 seconds.
2023-10-23 14:34:46,383:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:46,383:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:34:46,383:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:34:46,383:INFO:[LightGBM] [Info] Start training from score 97.332701
2023-10-23 14:34:46,766:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007627 seconds.
2023-10-23 14:34:46,766:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:46,766:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:34:46,766:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:34:46,766:INFO:[LightGBM] [Info] Start training from score 96.452612
2023-10-23 14:34:47,167:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007072 seconds.
2023-10-23 14:34:47,167:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:47,168:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:34:47,168:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:34:47,168:INFO:[LightGBM] [Info] Start training from score 97.322509
2023-10-23 14:34:47,483:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007806 seconds.
2023-10-23 14:34:47,483:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:47,499:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:34:47,499:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:34:47,500:INFO:[LightGBM] [Info] Start training from score 96.419103
2023-10-23 14:34:47,840:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008775 seconds.
2023-10-23 14:34:47,840:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:47,840:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:34:47,840:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:34:47,840:INFO:[LightGBM] [Info] Start training from score 95.095963
2023-10-23 14:34:48,115:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:34:48,115:INFO:create_model() successfully completed......................................
2023-10-23 14:34:48,240:INFO:Creating Dashboard logs
2023-10-23 14:34:48,246:INFO:Model: Bagging Regressor
2023-10-23 14:34:48,316:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-23 14:34:48,729:INFO:_master_model_container: 4
2023-10-23 14:34:48,729:INFO:_display_container: 4
2023-10-23 14:34:48,740:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:34:48,740:INFO:finalize_model() successfully completed......................................
2023-10-23 14:34:48,849:INFO:Initializing save_model()
2023-10-23 14:34:48,849:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), model_name=final_model_for_location_B, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 14:34:48,849:INFO:Adding model into prep_pipe
2023-10-23 14:34:48,849:WARNING:Only Model saved as it was a pipeline.
2023-10-23 14:34:48,914:INFO:final_model_for_location_B.pkl saved in current working directory
2023-10-23 14:34:48,930:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:34:48,930:INFO:save_model() successfully completed......................................
2023-10-23 14:34:49,064:INFO:PyCaret RegressionExperiment
2023-10-23 14:34:49,064:INFO:Logging name: exp_C
2023-10-23 14:34:49,064:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 14:34:49,064:INFO:version 3.1.0
2023-10-23 14:34:49,065:INFO:Initializing setup()
2023-10-23 14:34:49,065:INFO:self.USI: cd30
2023-10-23 14:34:49,065:INFO:self._variable_keys: {'gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', '_ml_usecase', 'gpu_param', 'exp_name_log', 'html_param', 'fold_generator', 'y', 'seed', 'y_train', 'transform_target_param', 'n_jobs_param', 'target_param', 'idx', '_available_plots', 'log_plots_param', 'memory', 'data', 'USI', 'X', 'logging_param', 'pipeline', 'exp_id', 'X_train', 'X_test', 'fold_groups_param'}
2023-10-23 14:34:49,065:INFO:Checking environment
2023-10-23 14:34:49,065:INFO:python_version: 3.8.18
2023-10-23 14:34:49,065:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 14:34:49,065:INFO:machine: AMD64
2023-10-23 14:34:49,065:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 14:34:49,065:INFO:Memory: svmem(total=16505954304, available=2277785600, percent=86.2, used=14228168704, free=2277785600)
2023-10-23 14:34:49,065:INFO:Physical Core: 8
2023-10-23 14:34:49,065:INFO:Logical Core: 16
2023-10-23 14:34:49,065:INFO:Checking libraries
2023-10-23 14:34:49,065:INFO:System:
2023-10-23 14:34:49,065:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 14:34:49,065:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 14:34:49,065:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 14:34:49,065:INFO:PyCaret required dependencies:
2023-10-23 14:34:49,065:INFO:                 pip: 23.3
2023-10-23 14:34:49,065:INFO:          setuptools: 68.0.0
2023-10-23 14:34:49,065:INFO:             pycaret: 3.1.0
2023-10-23 14:34:49,065:INFO:             IPython: 8.12.0
2023-10-23 14:34:49,065:INFO:          ipywidgets: 8.1.1
2023-10-23 14:34:49,065:INFO:                tqdm: 4.66.1
2023-10-23 14:34:49,065:INFO:               numpy: 1.23.5
2023-10-23 14:34:49,065:INFO:              pandas: 1.5.3
2023-10-23 14:34:49,065:INFO:              jinja2: 3.1.2
2023-10-23 14:34:49,065:INFO:               scipy: 1.10.1
2023-10-23 14:34:49,065:INFO:              joblib: 1.3.2
2023-10-23 14:34:49,065:INFO:             sklearn: 1.2.2
2023-10-23 14:34:49,065:INFO:                pyod: 1.1.0
2023-10-23 14:34:49,065:INFO:            imblearn: 0.11.0
2023-10-23 14:34:49,065:INFO:   category_encoders: 2.6.2
2023-10-23 14:34:49,065:INFO:            lightgbm: 4.1.0
2023-10-23 14:34:49,065:INFO:               numba: 0.58.1
2023-10-23 14:34:49,065:INFO:            requests: 2.31.0
2023-10-23 14:34:49,065:INFO:          matplotlib: 3.7.3
2023-10-23 14:34:49,065:INFO:          scikitplot: 0.3.7
2023-10-23 14:34:49,065:INFO:         yellowbrick: 1.5
2023-10-23 14:34:49,065:INFO:              plotly: 5.17.0
2023-10-23 14:34:49,065:INFO:    plotly-resampler: Not installed
2023-10-23 14:34:49,065:INFO:             kaleido: 0.2.1
2023-10-23 14:34:49,065:INFO:           schemdraw: 0.15
2023-10-23 14:34:49,065:INFO:         statsmodels: 0.14.0
2023-10-23 14:34:49,065:INFO:              sktime: 0.21.1
2023-10-23 14:34:49,065:INFO:               tbats: 1.1.3
2023-10-23 14:34:49,065:INFO:            pmdarima: 2.0.3
2023-10-23 14:34:49,065:INFO:              psutil: 5.9.0
2023-10-23 14:34:49,065:INFO:          markupsafe: 2.1.3
2023-10-23 14:34:49,065:INFO:             pickle5: Not installed
2023-10-23 14:34:49,065:INFO:         cloudpickle: 2.2.1
2023-10-23 14:34:49,065:INFO:         deprecation: 2.1.0
2023-10-23 14:34:49,065:INFO:              xxhash: 3.4.1
2023-10-23 14:34:49,065:INFO:           wurlitzer: Not installed
2023-10-23 14:34:49,065:INFO:PyCaret optional dependencies:
2023-10-23 14:34:49,065:INFO:                shap: Not installed
2023-10-23 14:34:49,065:INFO:           interpret: Not installed
2023-10-23 14:34:49,065:INFO:                umap: Not installed
2023-10-23 14:34:49,065:INFO:     ydata_profiling: Not installed
2023-10-23 14:34:49,065:INFO:  explainerdashboard: Not installed
2023-10-23 14:34:49,065:INFO:             autoviz: Not installed
2023-10-23 14:34:49,065:INFO:           fairlearn: Not installed
2023-10-23 14:34:49,065:INFO:          deepchecks: Not installed
2023-10-23 14:34:49,065:INFO:             xgboost: Not installed
2023-10-23 14:34:49,065:INFO:            catboost: 1.2.2
2023-10-23 14:34:49,065:INFO:              kmodes: Not installed
2023-10-23 14:34:49,065:INFO:             mlxtend: Not installed
2023-10-23 14:34:49,065:INFO:       statsforecast: Not installed
2023-10-23 14:34:49,065:INFO:        tune_sklearn: Not installed
2023-10-23 14:34:49,065:INFO:                 ray: Not installed
2023-10-23 14:34:49,065:INFO:            hyperopt: Not installed
2023-10-23 14:34:49,065:INFO:              optuna: Not installed
2023-10-23 14:34:49,065:INFO:               skopt: Not installed
2023-10-23 14:34:49,065:INFO:              mlflow: 2.7.1
2023-10-23 14:34:49,065:INFO:              gradio: Not installed
2023-10-23 14:34:49,065:INFO:             fastapi: Not installed
2023-10-23 14:34:49,065:INFO:             uvicorn: Not installed
2023-10-23 14:34:49,065:INFO:              m2cgen: Not installed
2023-10-23 14:34:49,065:INFO:           evidently: Not installed
2023-10-23 14:34:49,065:INFO:               fugue: Not installed
2023-10-23 14:34:49,065:INFO:           streamlit: Not installed
2023-10-23 14:34:49,065:INFO:             prophet: Not installed
2023-10-23 14:34:49,065:INFO:None
2023-10-23 14:34:49,065:INFO:Set up data.
2023-10-23 14:34:49,098:INFO:Set up folding strategy.
2023-10-23 14:34:49,098:INFO:Set up train/test split.
2023-10-23 14:34:49,115:INFO:Set up index.
2023-10-23 14:34:49,115:INFO:Assigning column types.
2023-10-23 14:34:49,145:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 14:34:49,145:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,151:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,153:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,242:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,285:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,285:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:34:49,285:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:34:49,285:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,300:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,305:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,382:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,433:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,433:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:34:49,433:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:34:49,433:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 14:34:49,433:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,447:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,530:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,581:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,582:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:34:49,582:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:34:49,585:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,585:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,664:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,718:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,718:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:34:49,718:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:34:49,718:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 14:34:49,731:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,803:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,847:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,847:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:34:49,847:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:34:49,864:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,948:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,998:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:34:49,998:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:34:49,998:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:34:49,998:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 14:34:50,084:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:34:50,134:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:34:50,134:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:34:50,134:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:34:50,247:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:34:50,302:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:34:50,302:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:34:50,302:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:34:50,302:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 14:34:50,425:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:34:50,490:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:34:50,490:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:34:50,594:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:34:50,663:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:34:50,663:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:34:50,664:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 14:34:50,828:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:34:50,828:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:34:51,013:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:34:51,013:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:34:51,013:INFO:Preparing preprocessing pipeline...
2023-10-23 14:34:51,013:INFO:Set up simple imputation.
2023-10-23 14:34:51,028:INFO:Set up column name cleaning.
2023-10-23 14:34:51,096:INFO:Finished creating preprocessing pipeline.
2023-10-23 14:34:51,110:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 14:34:51,110:INFO:Creating final display dataframe.
2023-10-23 14:34:51,314:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (26071, 50)
4        Transformed data shape   (26071, 50)
5   Transformed train set shape   (18249, 50)
6    Transformed test set shape    (7822, 50)
7              Numeric features            49
8      Rows with missing values         95.9%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_C
19                          USI          cd30
2023-10-23 14:34:51,448:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:34:51,448:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:34:51,595:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:34:51,595:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:34:51,611:INFO:Logging experiment in loggers
2023-10-23 14:34:51,761:INFO:SubProcess save_model() called ==================================
2023-10-23 14:34:51,782:INFO:Initializing save_model()
2023-10-23 14:34:51,782:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmpmgj36nu5\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 14:34:51,782:INFO:Adding model into prep_pipe
2023-10-23 14:34:51,783:WARNING:Only Model saved as it was a pipeline.
2023-10-23 14:34:51,783:INFO:C:\Users\thoma\AppData\Local\Temp\tmpmgj36nu5\Transformation Pipeline.pkl saved in current working directory
2023-10-23 14:34:51,798:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 14:34:51,798:INFO:save_model() successfully completed......................................
2023-10-23 14:34:51,913:INFO:SubProcess save_model() end ==================================
2023-10-23 14:34:51,978:INFO:setup() successfully completed in 2.56s...............
2023-10-23 14:34:51,978:INFO:Initializing create_model()
2023-10-23 14:34:51,978:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84F40>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:34:51,978:INFO:Checking exceptions
2023-10-23 14:34:51,978:INFO:Importing libraries
2023-10-23 14:34:51,978:INFO:Copying training dataset
2023-10-23 14:34:51,996:INFO:Defining folds
2023-10-23 14:34:51,996:INFO:Declaring metric variables
2023-10-23 14:34:51,996:INFO:Importing untrained model
2023-10-23 14:34:52,010:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:34:52,010:INFO:Starting cross validation
2023-10-23 14:34:52,012:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:34:54,863:INFO:Calculating mean and std
2023-10-23 14:34:54,865:INFO:Creating metrics dataframe
2023-10-23 14:34:54,868:INFO:Finalizing model
2023-10-23 14:34:54,941:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004423 seconds.
2023-10-23 14:34:54,941:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:34:54,941:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:34:54,941:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:34:54,941:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-23 14:34:55,194:INFO:Creating Dashboard logs
2023-10-23 14:34:55,195:INFO:Model: Light Gradient Boosting Machine
2023-10-23 14:34:55,290:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 14:34:55,492:INFO:Initializing predict_model()
2023-10-23 14:34:55,492:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84F40>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096EA8EE0>)
2023-10-23 14:34:55,492:INFO:Checking exceptions
2023-10-23 14:34:55,492:INFO:Preloading libraries
2023-10-23 14:34:55,993:INFO:Uploading results into container
2023-10-23 14:34:55,993:INFO:Uploading model into container now
2023-10-23 14:34:55,993:INFO:_master_model_container: 1
2023-10-23 14:34:55,993:INFO:_display_container: 2
2023-10-23 14:34:55,993:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:34:55,993:INFO:create_model() successfully completed......................................
2023-10-23 14:34:56,110:INFO:Initializing tune_model()
2023-10-23 14:34:56,110:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84F40>)
2023-10-23 14:34:56,110:INFO:Checking exceptions
2023-10-23 14:34:56,125:INFO:Copying training dataset
2023-10-23 14:34:56,141:INFO:Checking base model
2023-10-23 14:34:56,141:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 14:34:56,145:INFO:Declaring metric variables
2023-10-23 14:34:56,145:INFO:Defining Hyperparameters
2023-10-23 14:34:56,264:INFO:Tuning with n_jobs=-1
2023-10-23 14:34:56,265:INFO:Initializing RandomizedSearchCV
2023-10-23 14:35:33,443:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-23 14:35:33,444:INFO:Hyperparameter search completed
2023-10-23 14:35:33,445:INFO:SubProcess create_model() called ==================================
2023-10-23 14:35:33,446:INFO:Initializing create_model()
2023-10-23 14:35:33,446:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84F40>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E096DBC580>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-23 14:35:33,446:INFO:Checking exceptions
2023-10-23 14:35:33,447:INFO:Importing libraries
2023-10-23 14:35:33,447:INFO:Copying training dataset
2023-10-23 14:35:33,469:INFO:Defining folds
2023-10-23 14:35:33,469:INFO:Declaring metric variables
2023-10-23 14:35:33,469:INFO:Importing untrained model
2023-10-23 14:35:33,475:INFO:Declaring custom model
2023-10-23 14:35:33,476:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:35:33,476:INFO:Starting cross validation
2023-10-23 14:35:33,478:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:35:42,059:INFO:Calculating mean and std
2023-10-23 14:35:42,059:INFO:Creating metrics dataframe
2023-10-23 14:35:42,059:INFO:Finalizing model
2023-10-23 14:35:42,117:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-23 14:35:42,117:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-23 14:35:42,117:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-23 14:35:42,135:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-23 14:35:42,135:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-23 14:35:42,135:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-23 14:35:42,151:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004649 seconds.
2023-10-23 14:35:42,151:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:35:42,151:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:35:42,151:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:35:42,151:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-23 14:35:42,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:35:42,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:35:42,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:35:42,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:35:42,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:35:42,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:35:42,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:35:42,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:35:43,388:INFO:Uploading results into container
2023-10-23 14:35:43,403:INFO:Uploading model into container now
2023-10-23 14:35:43,403:INFO:_master_model_container: 2
2023-10-23 14:35:43,403:INFO:_display_container: 3
2023-10-23 14:35:43,403:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-23 14:35:43,403:INFO:create_model() successfully completed......................................
2023-10-23 14:35:43,534:INFO:SubProcess create_model() end ==================================
2023-10-23 14:35:43,534:INFO:choose_better activated
2023-10-23 14:35:43,534:INFO:SubProcess create_model() called ==================================
2023-10-23 14:35:43,534:INFO:Initializing create_model()
2023-10-23 14:35:43,534:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84F40>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:35:43,534:INFO:Checking exceptions
2023-10-23 14:35:43,534:INFO:Importing libraries
2023-10-23 14:35:43,534:INFO:Copying training dataset
2023-10-23 14:35:43,557:INFO:Defining folds
2023-10-23 14:35:43,557:INFO:Declaring metric variables
2023-10-23 14:35:43,557:INFO:Importing untrained model
2023-10-23 14:35:43,557:INFO:Declaring custom model
2023-10-23 14:35:43,557:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:35:43,557:INFO:Starting cross validation
2023-10-23 14:35:43,557:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:35:45,883:INFO:Calculating mean and std
2023-10-23 14:35:45,883:INFO:Creating metrics dataframe
2023-10-23 14:35:45,883:INFO:Finalizing model
2023-10-23 14:35:45,966:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005855 seconds.
2023-10-23 14:35:45,966:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:35:45,966:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:35:45,966:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:35:45,966:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-23 14:35:46,183:INFO:Uploading results into container
2023-10-23 14:35:46,183:INFO:Uploading model into container now
2023-10-23 14:35:46,183:INFO:_master_model_container: 3
2023-10-23 14:35:46,183:INFO:_display_container: 4
2023-10-23 14:35:46,183:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:35:46,183:INFO:create_model() successfully completed......................................
2023-10-23 14:35:46,299:INFO:SubProcess create_model() end ==================================
2023-10-23 14:35:46,299:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.905
2023-10-23 14:35:46,299:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8993
2023-10-23 14:35:46,299:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-23 14:35:46,299:INFO:choose_better completed
2023-10-23 14:35:46,299:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-23 14:35:46,299:INFO:Creating Dashboard logs
2023-10-23 14:35:46,299:INFO:Model: Light Gradient Boosting Machine
2023-10-23 14:35:46,366:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 14:35:46,569:INFO:Initializing predict_model()
2023-10-23 14:35:46,569:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84F40>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096EA88B0>)
2023-10-23 14:35:46,569:INFO:Checking exceptions
2023-10-23 14:35:46,569:INFO:Preloading libraries
2023-10-23 14:35:47,018:INFO:_master_model_container: 3
2023-10-23 14:35:47,018:INFO:_display_container: 3
2023-10-23 14:35:47,018:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:35:47,018:INFO:tune_model() successfully completed......................................
2023-10-23 14:35:47,122:INFO:Initializing ensemble_model()
2023-10-23 14:35:47,122:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84F40>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-23 14:35:47,122:INFO:Checking exceptions
2023-10-23 14:35:47,138:INFO:Importing libraries
2023-10-23 14:35:47,138:INFO:Copying training dataset
2023-10-23 14:35:47,138:INFO:Checking base model
2023-10-23 14:35:47,138:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 14:35:47,138:INFO:Importing untrained ensembler
2023-10-23 14:35:47,138:INFO:Ensemble method set to Bagging
2023-10-23 14:35:47,138:INFO:SubProcess create_model() called ==================================
2023-10-23 14:35:47,138:INFO:Initializing create_model()
2023-10-23 14:35:47,138:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84F40>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E0971C0DF0>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:35:47,138:INFO:Checking exceptions
2023-10-23 14:35:47,138:INFO:Importing libraries
2023-10-23 14:35:47,138:INFO:Copying training dataset
2023-10-23 14:35:47,174:INFO:Defining folds
2023-10-23 14:35:47,174:INFO:Declaring metric variables
2023-10-23 14:35:47,174:INFO:Importing untrained model
2023-10-23 14:35:47,174:INFO:Declaring custom model
2023-10-23 14:35:47,176:INFO:Bagging Regressor Imported successfully
2023-10-23 14:35:47,177:INFO:Starting cross validation
2023-10-23 14:35:47,178:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:36:10,530:INFO:Calculating mean and std
2023-10-23 14:36:10,530:INFO:Creating metrics dataframe
2023-10-23 14:36:10,530:INFO:Finalizing model
2023-10-23 14:36:10,646:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005017 seconds.
2023-10-23 14:36:10,646:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:10,646:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:36:10,646:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:36:10,646:INFO:[LightGBM] [Info] Start training from score 77.044367
2023-10-23 14:36:10,912:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004618 seconds.
2023-10-23 14:36:10,912:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:10,912:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:36:10,912:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:36:10,912:INFO:[LightGBM] [Info] Start training from score 76.520588
2023-10-23 14:36:11,179:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005437 seconds.
2023-10-23 14:36:11,179:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:11,179:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:36:11,179:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:36:11,179:INFO:[LightGBM] [Info] Start training from score 76.462170
2023-10-23 14:36:11,446:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005279 seconds.
2023-10-23 14:36:11,446:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:11,446:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:36:11,446:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:36:11,446:INFO:[LightGBM] [Info] Start training from score 77.386428
2023-10-23 14:36:11,711:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005075 seconds.
2023-10-23 14:36:11,711:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:11,711:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:36:11,711:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:36:11,711:INFO:[LightGBM] [Info] Start training from score 73.916304
2023-10-23 14:36:11,961:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004452 seconds.
2023-10-23 14:36:11,961:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:11,961:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:36:11,961:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:36:11,977:INFO:[LightGBM] [Info] Start training from score 75.879633
2023-10-23 14:36:12,235:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004582 seconds.
2023-10-23 14:36:12,235:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:12,235:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:36:12,235:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:36:12,235:INFO:[LightGBM] [Info] Start training from score 75.615395
2023-10-23 14:36:12,494:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004239 seconds.
2023-10-23 14:36:12,494:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:12,494:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:36:12,494:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:36:12,494:INFO:[LightGBM] [Info] Start training from score 79.544595
2023-10-23 14:36:12,777:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005002 seconds.
2023-10-23 14:36:12,777:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:12,777:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:36:12,777:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:36:12,777:INFO:[LightGBM] [Info] Start training from score 76.012052
2023-10-23 14:36:13,094:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004560 seconds.
2023-10-23 14:36:13,094:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:13,094:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:36:13,094:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:36:13,094:INFO:[LightGBM] [Info] Start training from score 78.124037
2023-10-23 14:36:13,323:INFO:Uploading results into container
2023-10-23 14:36:13,325:INFO:Uploading model into container now
2023-10-23 14:36:13,326:INFO:_master_model_container: 4
2023-10-23 14:36:13,326:INFO:_display_container: 4
2023-10-23 14:36:13,327:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:36:13,327:INFO:create_model() successfully completed......................................
2023-10-23 14:36:13,443:INFO:SubProcess create_model() end ==================================
2023-10-23 14:36:13,443:INFO:Creating Dashboard logs
2023-10-23 14:36:13,443:INFO:Model: Bagging Regressor
2023-10-23 14:36:13,514:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-23 14:36:13,764:INFO:Initializing predict_model()
2023-10-23 14:36:13,764:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84F40>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096EA8670>)
2023-10-23 14:36:13,764:INFO:Checking exceptions
2023-10-23 14:36:13,764:INFO:Preloading libraries
2023-10-23 14:36:14,361:INFO:_master_model_container: 4
2023-10-23 14:36:14,361:INFO:_display_container: 4
2023-10-23 14:36:14,362:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:36:14,363:INFO:ensemble_model() successfully completed......................................
2023-10-23 14:36:14,458:INFO:Initializing finalize_model()
2023-10-23 14:36:14,458:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84F40>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-23 14:36:14,459:INFO:Finalizing BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:36:14,464:INFO:Initializing create_model()
2023-10-23 14:36:14,464:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84F40>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-23 14:36:14,464:INFO:Checking exceptions
2023-10-23 14:36:14,464:INFO:Importing libraries
2023-10-23 14:36:14,464:INFO:Copying training dataset
2023-10-23 14:36:14,464:INFO:Defining folds
2023-10-23 14:36:14,464:INFO:Declaring metric variables
2023-10-23 14:36:14,464:INFO:Importing untrained model
2023-10-23 14:36:14,464:INFO:Declaring custom model
2023-10-23 14:36:14,475:INFO:Bagging Regressor Imported successfully
2023-10-23 14:36:14,476:INFO:Cross validation set to False
2023-10-23 14:36:14,476:INFO:Fitting Model
2023-10-23 14:36:14,559:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008366 seconds.
2023-10-23 14:36:14,559:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:14,559:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:36:14,559:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:36:14,575:INFO:[LightGBM] [Info] Start training from score 77.360615
2023-10-23 14:36:14,929:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006046 seconds.
2023-10-23 14:36:14,929:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:14,945:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:36:14,945:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:36:14,945:INFO:[LightGBM] [Info] Start training from score 78.162759
2023-10-23 14:36:15,246:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006855 seconds.
2023-10-23 14:36:15,246:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:15,247:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:36:15,247:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:36:15,247:INFO:[LightGBM] [Info] Start training from score 77.185434
2023-10-23 14:36:15,545:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008025 seconds.
2023-10-23 14:36:15,545:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:15,545:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:36:15,545:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:36:15,545:INFO:[LightGBM] [Info] Start training from score 78.293126
2023-10-23 14:36:15,947:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007751 seconds.
2023-10-23 14:36:15,947:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:15,947:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:36:15,947:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:36:15,947:INFO:[LightGBM] [Info] Start training from score 75.493649
2023-10-23 14:36:16,251:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007603 seconds.
2023-10-23 14:36:16,251:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:16,251:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:36:16,252:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:36:16,252:INFO:[LightGBM] [Info] Start training from score 77.467219
2023-10-23 14:36:16,543:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005685 seconds.
2023-10-23 14:36:16,543:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:16,543:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:36:16,543:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:36:16,543:INFO:[LightGBM] [Info] Start training from score 77.083598
2023-10-23 14:36:16,849:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006492 seconds.
2023-10-23 14:36:16,849:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:16,849:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:36:16,849:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:36:16,849:INFO:[LightGBM] [Info] Start training from score 79.854607
2023-10-23 14:36:17,144:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006850 seconds.
2023-10-23 14:36:17,144:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:17,144:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:36:17,144:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:36:17,144:INFO:[LightGBM] [Info] Start training from score 76.153078
2023-10-23 14:36:17,461:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006621 seconds.
2023-10-23 14:36:17,461:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:36:17,461:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:36:17,461:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:36:17,461:INFO:[LightGBM] [Info] Start training from score 78.843978
2023-10-23 14:36:17,730:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:36:17,730:INFO:create_model() successfully completed......................................
2023-10-23 14:36:17,844:INFO:Creating Dashboard logs
2023-10-23 14:36:17,844:INFO:Model: Bagging Regressor
2023-10-23 14:36:17,923:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-23 14:36:18,341:INFO:_master_model_container: 4
2023-10-23 14:36:18,341:INFO:_display_container: 4
2023-10-23 14:36:18,357:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:36:18,357:INFO:finalize_model() successfully completed......................................
2023-10-23 14:36:18,477:INFO:Initializing save_model()
2023-10-23 14:36:18,477:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), model_name=final_model_for_location_C, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 14:36:18,477:INFO:Adding model into prep_pipe
2023-10-23 14:36:18,477:WARNING:Only Model saved as it was a pipeline.
2023-10-23 14:36:18,541:INFO:final_model_for_location_C.pkl saved in current working directory
2023-10-23 14:36:18,556:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:36:18,556:INFO:save_model() successfully completed......................................
2023-10-23 14:36:19,990:INFO:Initializing load_model()
2023-10-23 14:36:19,990:INFO:load_model(model_name=final_model_for_location_A, platform=None, authentication=None, verbose=True)
2023-10-23 14:36:20,024:INFO:Initializing load_model()
2023-10-23 14:36:20,024:INFO:load_model(model_name=final_model_for_location_B, platform=None, authentication=None, verbose=True)
2023-10-23 14:36:20,082:INFO:Initializing load_model()
2023-10-23 14:36:20,083:INFO:load_model(model_name=final_model_for_location_C, platform=None, authentication=None, verbose=True)
2023-10-23 14:36:20,152:INFO:Initializing predict_model()
2023-10-23 14:36:20,152:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84F40>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E0970AA5E0>)
2023-10-23 14:36:20,153:INFO:Checking exceptions
2023-10-23 14:36:20,153:INFO:Preloading libraries
2023-10-23 14:36:20,153:INFO:Set up data.
2023-10-23 14:36:20,183:INFO:Set up index.
2023-10-23 14:36:20,386:INFO:Initializing predict_model()
2023-10-23 14:36:20,386:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84F40>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E0970AA5E0>)
2023-10-23 14:36:20,386:INFO:Checking exceptions
2023-10-23 14:36:20,386:INFO:Preloading libraries
2023-10-23 14:36:20,386:INFO:Set up data.
2023-10-23 14:36:20,402:INFO:Set up index.
2023-10-23 14:36:20,593:INFO:Initializing predict_model()
2023-10-23 14:36:20,594:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84F40>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'sfc_pressure:hPa',
                                             'snow_density:kgm3', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E0970AA5E0>)
2023-10-23 14:36:20,594:INFO:Checking exceptions
2023-10-23 14:36:20,594:INFO:Preloading libraries
2023-10-23 14:36:20,594:INFO:Set up data.
2023-10-23 14:36:20,611:INFO:Set up index.
2023-10-23 14:44:05,097:INFO:PyCaret RegressionExperiment
2023-10-23 14:44:05,097:INFO:Logging name: exp_A
2023-10-23 14:44:05,098:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 14:44:05,098:INFO:version 3.1.0
2023-10-23 14:44:05,098:INFO:Initializing setup()
2023-10-23 14:44:05,098:INFO:self.USI: 9317
2023-10-23 14:44:05,099:INFO:self._variable_keys: {'gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', '_ml_usecase', 'gpu_param', 'exp_name_log', 'html_param', 'fold_generator', 'y', 'seed', 'y_train', 'transform_target_param', 'n_jobs_param', 'target_param', 'idx', '_available_plots', 'log_plots_param', 'memory', 'data', 'USI', 'X', 'logging_param', 'pipeline', 'exp_id', 'X_train', 'X_test', 'fold_groups_param'}
2023-10-23 14:44:05,099:INFO:Checking environment
2023-10-23 14:44:05,099:INFO:python_version: 3.8.18
2023-10-23 14:44:05,099:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 14:44:05,099:INFO:machine: AMD64
2023-10-23 14:44:05,099:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 14:44:05,100:INFO:Memory: svmem(total=16505954304, available=4620279808, percent=72.0, used=11885674496, free=4620279808)
2023-10-23 14:44:05,100:INFO:Physical Core: 8
2023-10-23 14:44:05,100:INFO:Logical Core: 16
2023-10-23 14:44:05,100:INFO:Checking libraries
2023-10-23 14:44:05,100:INFO:System:
2023-10-23 14:44:05,101:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 14:44:05,101:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 14:44:05,101:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 14:44:05,101:INFO:PyCaret required dependencies:
2023-10-23 14:44:05,101:INFO:                 pip: 23.3
2023-10-23 14:44:05,101:INFO:          setuptools: 68.0.0
2023-10-23 14:44:05,101:INFO:             pycaret: 3.1.0
2023-10-23 14:44:05,101:INFO:             IPython: 8.12.0
2023-10-23 14:44:05,101:INFO:          ipywidgets: 8.1.1
2023-10-23 14:44:05,101:INFO:                tqdm: 4.66.1
2023-10-23 14:44:05,101:INFO:               numpy: 1.23.5
2023-10-23 14:44:05,101:INFO:              pandas: 1.5.3
2023-10-23 14:44:05,101:INFO:              jinja2: 3.1.2
2023-10-23 14:44:05,101:INFO:               scipy: 1.10.1
2023-10-23 14:44:05,101:INFO:              joblib: 1.3.2
2023-10-23 14:44:05,102:INFO:             sklearn: 1.2.2
2023-10-23 14:44:05,102:INFO:                pyod: 1.1.0
2023-10-23 14:44:05,102:INFO:            imblearn: 0.11.0
2023-10-23 14:44:05,102:INFO:   category_encoders: 2.6.2
2023-10-23 14:44:05,102:INFO:            lightgbm: 4.1.0
2023-10-23 14:44:05,102:INFO:               numba: 0.58.1
2023-10-23 14:44:05,102:INFO:            requests: 2.31.0
2023-10-23 14:44:05,102:INFO:          matplotlib: 3.7.3
2023-10-23 14:44:05,102:INFO:          scikitplot: 0.3.7
2023-10-23 14:44:05,102:INFO:         yellowbrick: 1.5
2023-10-23 14:44:05,102:INFO:              plotly: 5.17.0
2023-10-23 14:44:05,102:INFO:    plotly-resampler: Not installed
2023-10-23 14:44:05,102:INFO:             kaleido: 0.2.1
2023-10-23 14:44:05,102:INFO:           schemdraw: 0.15
2023-10-23 14:44:05,102:INFO:         statsmodels: 0.14.0
2023-10-23 14:44:05,102:INFO:              sktime: 0.21.1
2023-10-23 14:44:05,102:INFO:               tbats: 1.1.3
2023-10-23 14:44:05,102:INFO:            pmdarima: 2.0.3
2023-10-23 14:44:05,103:INFO:              psutil: 5.9.0
2023-10-23 14:44:05,103:INFO:          markupsafe: 2.1.3
2023-10-23 14:44:05,103:INFO:             pickle5: Not installed
2023-10-23 14:44:05,103:INFO:         cloudpickle: 2.2.1
2023-10-23 14:44:05,103:INFO:         deprecation: 2.1.0
2023-10-23 14:44:05,103:INFO:              xxhash: 3.4.1
2023-10-23 14:44:05,103:INFO:           wurlitzer: Not installed
2023-10-23 14:44:05,103:INFO:PyCaret optional dependencies:
2023-10-23 14:44:05,103:INFO:                shap: Not installed
2023-10-23 14:44:05,103:INFO:           interpret: Not installed
2023-10-23 14:44:05,103:INFO:                umap: Not installed
2023-10-23 14:44:05,103:INFO:     ydata_profiling: Not installed
2023-10-23 14:44:05,103:INFO:  explainerdashboard: Not installed
2023-10-23 14:44:05,103:INFO:             autoviz: Not installed
2023-10-23 14:44:05,104:INFO:           fairlearn: Not installed
2023-10-23 14:44:05,104:INFO:          deepchecks: Not installed
2023-10-23 14:44:05,104:INFO:             xgboost: Not installed
2023-10-23 14:44:05,104:INFO:            catboost: 1.2.2
2023-10-23 14:44:05,104:INFO:              kmodes: Not installed
2023-10-23 14:44:05,104:INFO:             mlxtend: Not installed
2023-10-23 14:44:05,104:INFO:       statsforecast: Not installed
2023-10-23 14:44:05,104:INFO:        tune_sklearn: Not installed
2023-10-23 14:44:05,104:INFO:                 ray: Not installed
2023-10-23 14:44:05,104:INFO:            hyperopt: Not installed
2023-10-23 14:44:05,104:INFO:              optuna: Not installed
2023-10-23 14:44:05,104:INFO:               skopt: Not installed
2023-10-23 14:44:05,104:INFO:              mlflow: 2.7.1
2023-10-23 14:44:05,104:INFO:              gradio: Not installed
2023-10-23 14:44:05,104:INFO:             fastapi: Not installed
2023-10-23 14:44:05,104:INFO:             uvicorn: Not installed
2023-10-23 14:44:05,105:INFO:              m2cgen: Not installed
2023-10-23 14:44:05,105:INFO:           evidently: Not installed
2023-10-23 14:44:05,105:INFO:               fugue: Not installed
2023-10-23 14:44:05,105:INFO:           streamlit: Not installed
2023-10-23 14:44:05,105:INFO:             prophet: Not installed
2023-10-23 14:44:05,106:INFO:None
2023-10-23 14:44:05,106:INFO:Set up data.
2023-10-23 14:44:05,140:INFO:Set up folding strategy.
2023-10-23 14:44:05,141:INFO:Set up train/test split.
2023-10-23 14:44:05,167:INFO:Set up index.
2023-10-23 14:44:05,169:INFO:Assigning column types.
2023-10-23 14:44:05,192:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 14:44:05,194:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,199:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,204:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,290:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,356:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,358:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:44:05,358:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:44:05,359:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,365:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,371:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,450:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,499:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,500:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:44:05,500:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:44:05,501:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 14:44:05,506:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,512:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,596:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,647:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,647:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:44:05,648:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:44:05,653:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,659:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,741:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,793:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,794:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:44:05,794:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:44:05,795:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 14:44:05,806:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,890:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,947:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:44:05,948:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:44:05,948:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:44:05,960:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:44:06,057:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:44:06,125:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:44:06,126:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:44:06,126:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:44:06,128:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 14:44:06,231:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:44:06,286:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:44:06,287:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:44:06,287:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:44:06,383:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:44:06,436:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:44:06,437:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:44:06,437:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:44:06,438:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 14:44:06,552:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:44:06,603:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:44:06,603:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:44:06,691:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:44:06,752:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:44:06,754:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:44:06,755:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 14:44:06,913:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:44:06,913:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:44:07,055:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:44:07,055:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:44:07,057:INFO:Preparing preprocessing pipeline...
2023-10-23 14:44:07,057:INFO:Set up simple imputation.
2023-10-23 14:44:07,060:INFO:Set up column name cleaning.
2023-10-23 14:44:07,130:INFO:Finished creating preprocessing pipeline.
2023-10-23 14:44:07,135:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 14:44:07,136:INFO:Creating final display dataframe.
2023-10-23 14:44:07,340:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (34061, 49)
4        Transformed data shape   (34061, 49)
5   Transformed train set shape   (23842, 49)
6    Transformed test set shape   (10219, 49)
7              Numeric features            48
8      Rows with missing values         23.1%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_A
19                          USI          9317
2023-10-23 14:44:07,479:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:44:07,479:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:44:07,621:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:44:07,621:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:44:07,622:INFO:Logging experiment in loggers
2023-10-23 14:44:07,745:INFO:SubProcess save_model() called ==================================
2023-10-23 14:44:07,760:INFO:Initializing save_model()
2023-10-23 14:44:07,760:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmpl_wn4l99\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 14:44:07,760:INFO:Adding model into prep_pipe
2023-10-23 14:44:07,760:WARNING:Only Model saved as it was a pipeline.
2023-10-23 14:44:07,765:INFO:C:\Users\thoma\AppData\Local\Temp\tmpl_wn4l99\Transformation Pipeline.pkl saved in current working directory
2023-10-23 14:44:07,772:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 14:44:07,772:INFO:save_model() successfully completed......................................
2023-10-23 14:44:07,904:INFO:SubProcess save_model() end ==================================
2023-10-23 14:44:07,962:INFO:setup() successfully completed in 2.53s...............
2023-10-23 14:44:07,963:INFO:Initializing create_model()
2023-10-23 14:44:07,963:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84FD0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:44:07,963:INFO:Checking exceptions
2023-10-23 14:44:07,967:INFO:Importing libraries
2023-10-23 14:44:07,968:INFO:Copying training dataset
2023-10-23 14:44:07,992:INFO:Defining folds
2023-10-23 14:44:07,992:INFO:Declaring metric variables
2023-10-23 14:44:07,993:INFO:Importing untrained model
2023-10-23 14:44:07,993:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:44:07,993:INFO:Starting cross validation
2023-10-23 14:44:07,995:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:44:16,927:INFO:Calculating mean and std
2023-10-23 14:44:16,928:INFO:Creating metrics dataframe
2023-10-23 14:44:16,931:INFO:Finalizing model
2023-10-23 14:44:17,012:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005245 seconds.
2023-10-23 14:44:17,012:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:44:17,012:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:44:17,013:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:44:17,014:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-23 14:44:17,241:INFO:Creating Dashboard logs
2023-10-23 14:44:17,242:INFO:Model: Light Gradient Boosting Machine
2023-10-23 14:44:17,335:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 14:44:17,526:INFO:Initializing predict_model()
2023-10-23 14:44:17,526:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84FD0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E08C7A5160>)
2023-10-23 14:44:17,526:INFO:Checking exceptions
2023-10-23 14:44:17,526:INFO:Preloading libraries
2023-10-23 14:44:18,009:INFO:Uploading results into container
2023-10-23 14:44:18,010:INFO:Uploading model into container now
2023-10-23 14:44:18,018:INFO:_master_model_container: 1
2023-10-23 14:44:18,019:INFO:_display_container: 2
2023-10-23 14:44:18,020:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:44:18,020:INFO:create_model() successfully completed......................................
2023-10-23 14:44:18,137:INFO:Initializing tune_model()
2023-10-23 14:44:18,137:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84FD0>)
2023-10-23 14:44:18,138:INFO:Checking exceptions
2023-10-23 14:44:18,150:INFO:Copying training dataset
2023-10-23 14:44:18,165:INFO:Checking base model
2023-10-23 14:44:18,166:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 14:44:18,166:INFO:Declaring metric variables
2023-10-23 14:44:18,166:INFO:Defining Hyperparameters
2023-10-23 14:44:18,278:INFO:Tuning with n_jobs=-1
2023-10-23 14:44:18,278:INFO:Initializing RandomizedSearchCV
2023-10-23 14:45:08,698:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-23 14:45:08,699:INFO:Hyperparameter search completed
2023-10-23 14:45:08,699:INFO:SubProcess create_model() called ==================================
2023-10-23 14:45:08,700:INFO:Initializing create_model()
2023-10-23 14:45:08,700:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84FD0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E0C7ECD820>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-23 14:45:08,700:INFO:Checking exceptions
2023-10-23 14:45:08,701:INFO:Importing libraries
2023-10-23 14:45:08,701:INFO:Copying training dataset
2023-10-23 14:45:08,726:INFO:Defining folds
2023-10-23 14:45:08,726:INFO:Declaring metric variables
2023-10-23 14:45:08,726:INFO:Importing untrained model
2023-10-23 14:45:08,726:INFO:Declaring custom model
2023-10-23 14:45:08,726:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:45:08,726:INFO:Starting cross validation
2023-10-23 14:45:08,733:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:45:17,878:INFO:Calculating mean and std
2023-10-23 14:45:17,878:INFO:Creating metrics dataframe
2023-10-23 14:45:17,878:INFO:Finalizing model
2023-10-23 14:45:17,939:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-23 14:45:17,943:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-23 14:45:17,943:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-23 14:45:17,981:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-23 14:45:17,981:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-23 14:45:17,981:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-23 14:45:17,990:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006455 seconds.
2023-10-23 14:45:17,990:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:17,990:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:45:17,990:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:45:17,993:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-23 14:45:19,086:INFO:Uploading results into container
2023-10-23 14:45:19,086:INFO:Uploading model into container now
2023-10-23 14:45:19,086:INFO:_master_model_container: 2
2023-10-23 14:45:19,086:INFO:_display_container: 3
2023-10-23 14:45:19,086:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-23 14:45:19,086:INFO:create_model() successfully completed......................................
2023-10-23 14:45:19,218:INFO:SubProcess create_model() end ==================================
2023-10-23 14:45:19,218:INFO:choose_better activated
2023-10-23 14:45:19,218:INFO:SubProcess create_model() called ==================================
2023-10-23 14:45:19,218:INFO:Initializing create_model()
2023-10-23 14:45:19,218:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84FD0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:45:19,218:INFO:Checking exceptions
2023-10-23 14:45:19,218:INFO:Importing libraries
2023-10-23 14:45:19,218:INFO:Copying training dataset
2023-10-23 14:45:19,253:INFO:Defining folds
2023-10-23 14:45:19,253:INFO:Declaring metric variables
2023-10-23 14:45:19,253:INFO:Importing untrained model
2023-10-23 14:45:19,253:INFO:Declaring custom model
2023-10-23 14:45:19,254:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:45:19,254:INFO:Starting cross validation
2023-10-23 14:45:19,254:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:45:22,115:INFO:Calculating mean and std
2023-10-23 14:45:22,115:INFO:Creating metrics dataframe
2023-10-23 14:45:22,115:INFO:Finalizing model
2023-10-23 14:45:22,199:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006830 seconds.
2023-10-23 14:45:22,199:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:22,199:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:45:22,199:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:45:22,199:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-23 14:45:22,451:INFO:Uploading results into container
2023-10-23 14:45:22,451:INFO:Uploading model into container now
2023-10-23 14:45:22,451:INFO:_master_model_container: 3
2023-10-23 14:45:22,451:INFO:_display_container: 4
2023-10-23 14:45:22,451:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:45:22,451:INFO:create_model() successfully completed......................................
2023-10-23 14:45:22,590:INFO:SubProcess create_model() end ==================================
2023-10-23 14:45:22,590:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8716
2023-10-23 14:45:22,590:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8712
2023-10-23 14:45:22,590:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-23 14:45:22,590:INFO:choose_better completed
2023-10-23 14:45:22,590:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-23 14:45:22,590:INFO:Creating Dashboard logs
2023-10-23 14:45:22,590:INFO:Model: Light Gradient Boosting Machine
2023-10-23 14:45:22,679:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 14:45:22,874:INFO:Initializing predict_model()
2023-10-23 14:45:22,874:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84FD0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E08C6C3AF0>)
2023-10-23 14:45:22,874:INFO:Checking exceptions
2023-10-23 14:45:22,874:INFO:Preloading libraries
2023-10-23 14:45:23,391:INFO:_master_model_container: 3
2023-10-23 14:45:23,391:INFO:_display_container: 3
2023-10-23 14:45:23,391:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:45:23,391:INFO:tune_model() successfully completed......................................
2023-10-23 14:45:23,507:INFO:Initializing ensemble_model()
2023-10-23 14:45:23,507:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84FD0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-23 14:45:23,507:INFO:Checking exceptions
2023-10-23 14:45:23,524:INFO:Importing libraries
2023-10-23 14:45:23,524:INFO:Copying training dataset
2023-10-23 14:45:23,524:INFO:Checking base model
2023-10-23 14:45:23,524:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 14:45:23,524:INFO:Importing untrained ensembler
2023-10-23 14:45:23,524:INFO:Ensemble method set to Bagging
2023-10-23 14:45:23,524:INFO:SubProcess create_model() called ==================================
2023-10-23 14:45:23,524:INFO:Initializing create_model()
2023-10-23 14:45:23,524:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84FD0>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E096CDC790>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:45:23,524:INFO:Checking exceptions
2023-10-23 14:45:23,524:INFO:Importing libraries
2023-10-23 14:45:23,524:INFO:Copying training dataset
2023-10-23 14:45:23,541:INFO:Defining folds
2023-10-23 14:45:23,541:INFO:Declaring metric variables
2023-10-23 14:45:23,541:INFO:Importing untrained model
2023-10-23 14:45:23,541:INFO:Declaring custom model
2023-10-23 14:45:23,541:INFO:Bagging Regressor Imported successfully
2023-10-23 14:45:23,541:INFO:Starting cross validation
2023-10-23 14:45:23,555:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:45:48,468:INFO:Calculating mean and std
2023-10-23 14:45:48,468:INFO:Creating metrics dataframe
2023-10-23 14:45:48,468:INFO:Finalizing model
2023-10-23 14:45:48,559:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005709 seconds.
2023-10-23 14:45:48,559:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:48,559:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:45:48,559:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:45:48,567:INFO:[LightGBM] [Info] Start training from score 626.831517
2023-10-23 14:45:48,856:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007452 seconds.
2023-10-23 14:45:48,856:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:48,857:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:45:48,857:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:45:48,858:INFO:[LightGBM] [Info] Start training from score 640.013980
2023-10-23 14:45:49,182:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005122 seconds.
2023-10-23 14:45:49,182:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:49,182:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:45:49,184:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:45:49,184:INFO:[LightGBM] [Info] Start training from score 623.946930
2023-10-23 14:45:49,440:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005796 seconds.
2023-10-23 14:45:49,440:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:49,440:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:45:49,455:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:45:49,455:INFO:[LightGBM] [Info] Start training from score 632.335152
2023-10-23 14:45:49,756:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007570 seconds.
2023-10-23 14:45:49,756:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:49,756:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:45:49,757:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:45:49,758:INFO:[LightGBM] [Info] Start training from score 620.070240
2023-10-23 14:45:50,021:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005001 seconds.
2023-10-23 14:45:50,021:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:50,021:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:45:50,021:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:45:50,021:INFO:[LightGBM] [Info] Start training from score 635.137343
2023-10-23 14:45:50,352:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005117 seconds.
2023-10-23 14:45:50,352:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:50,353:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:45:50,353:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:45:50,354:INFO:[LightGBM] [Info] Start training from score 620.066941
2023-10-23 14:45:50,672:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005249 seconds.
2023-10-23 14:45:50,672:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:50,673:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:45:50,673:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:45:50,674:INFO:[LightGBM] [Info] Start training from score 623.069874
2023-10-23 14:45:50,950:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005444 seconds.
2023-10-23 14:45:50,950:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:50,951:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:45:50,951:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:45:50,952:INFO:[LightGBM] [Info] Start training from score 633.817057
2023-10-23 14:45:51,237:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005689 seconds.
2023-10-23 14:45:51,237:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:51,237:INFO:[LightGBM] [Info] Total Bins 6482
2023-10-23 14:45:51,237:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 45
2023-10-23 14:45:51,237:INFO:[LightGBM] [Info] Start training from score 641.113408
2023-10-23 14:45:51,491:INFO:Uploading results into container
2023-10-23 14:45:51,491:INFO:Uploading model into container now
2023-10-23 14:45:51,491:INFO:_master_model_container: 4
2023-10-23 14:45:51,491:INFO:_display_container: 4
2023-10-23 14:45:51,499:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:45:51,499:INFO:create_model() successfully completed......................................
2023-10-23 14:45:51,632:INFO:SubProcess create_model() end ==================================
2023-10-23 14:45:51,632:INFO:Creating Dashboard logs
2023-10-23 14:45:51,632:INFO:Model: Bagging Regressor
2023-10-23 14:45:51,700:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-23 14:45:51,908:INFO:Initializing predict_model()
2023-10-23 14:45:51,908:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84FD0>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E08C6C3B80>)
2023-10-23 14:45:51,908:INFO:Checking exceptions
2023-10-23 14:45:51,908:INFO:Preloading libraries
2023-10-23 14:45:52,568:INFO:_master_model_container: 4
2023-10-23 14:45:52,568:INFO:_display_container: 4
2023-10-23 14:45:52,568:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:45:52,568:INFO:ensemble_model() successfully completed......................................
2023-10-23 14:45:52,684:INFO:Initializing finalize_model()
2023-10-23 14:45:52,684:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84FD0>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-23 14:45:52,684:INFO:Finalizing BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:45:52,701:INFO:Initializing create_model()
2023-10-23 14:45:52,701:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E84FD0>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-23 14:45:52,701:INFO:Checking exceptions
2023-10-23 14:45:52,702:INFO:Importing libraries
2023-10-23 14:45:52,702:INFO:Copying training dataset
2023-10-23 14:45:52,702:INFO:Defining folds
2023-10-23 14:45:52,702:INFO:Declaring metric variables
2023-10-23 14:45:52,702:INFO:Importing untrained model
2023-10-23 14:45:52,702:INFO:Declaring custom model
2023-10-23 14:45:52,702:INFO:Bagging Regressor Imported successfully
2023-10-23 14:45:52,702:INFO:Cross validation set to False
2023-10-23 14:45:52,702:INFO:Fitting Model
2023-10-23 14:45:52,834:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008321 seconds.
2023-10-23 14:45:52,834:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:52,834:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:45:52,834:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:45:52,847:INFO:[LightGBM] [Info] Start training from score 634.491655
2023-10-23 14:45:53,204:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007528 seconds.
2023-10-23 14:45:53,204:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:53,204:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:45:53,204:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:45:53,204:INFO:[LightGBM] [Info] Start training from score 635.470959
2023-10-23 14:45:53,547:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006774 seconds.
2023-10-23 14:45:53,547:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:53,547:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:45:53,547:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:45:53,547:INFO:[LightGBM] [Info] Start training from score 634.053589
2023-10-23 14:45:53,980:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010125 seconds.
2023-10-23 14:45:53,980:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:53,981:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:45:53,981:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:45:53,982:INFO:[LightGBM] [Info] Start training from score 635.251785
2023-10-23 14:45:54,421:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008669 seconds.
2023-10-23 14:45:54,421:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:54,421:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:45:54,421:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:45:54,421:INFO:[LightGBM] [Info] Start training from score 627.555784
2023-10-23 14:45:54,780:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008666 seconds.
2023-10-23 14:45:54,780:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:54,780:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:45:54,780:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:45:54,780:INFO:[LightGBM] [Info] Start training from score 638.162596
2023-10-23 14:45:55,231:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007516 seconds.
2023-10-23 14:45:55,231:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:55,231:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:45:55,231:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:45:55,231:INFO:[LightGBM] [Info] Start training from score 633.181363
2023-10-23 14:45:55,595:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009193 seconds.
2023-10-23 14:45:55,595:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:55,596:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:45:55,597:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:45:55,598:INFO:[LightGBM] [Info] Start training from score 611.992287
2023-10-23 14:45:55,950:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007659 seconds.
2023-10-23 14:45:55,951:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:55,951:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:45:55,951:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:45:55,951:INFO:[LightGBM] [Info] Start training from score 638.181417
2023-10-23 14:45:56,282:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007908 seconds.
2023-10-23 14:45:56,283:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:45:56,283:INFO:[LightGBM] [Info] Total Bins 6597
2023-10-23 14:45:56,284:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 45
2023-10-23 14:45:56,285:INFO:[LightGBM] [Info] Start training from score 639.502137
2023-10-23 14:45:56,559:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:45:56,559:INFO:create_model() successfully completed......................................
2023-10-23 14:45:56,679:INFO:Creating Dashboard logs
2023-10-23 14:45:56,679:INFO:Model: Bagging Regressor
2023-10-23 14:45:56,749:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-23 14:45:57,134:INFO:_master_model_container: 4
2023-10-23 14:45:57,134:INFO:_display_container: 4
2023-10-23 14:45:57,149:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:45:57,149:INFO:finalize_model() successfully completed......................................
2023-10-23 14:45:57,266:INFO:Initializing save_model()
2023-10-23 14:45:57,266:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), model_name=final_model_for_location_A, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 14:45:57,266:INFO:Adding model into prep_pipe
2023-10-23 14:45:57,266:WARNING:Only Model saved as it was a pipeline.
2023-10-23 14:45:57,330:INFO:final_model_for_location_A.pkl saved in current working directory
2023-10-23 14:45:57,346:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:45:57,346:INFO:save_model() successfully completed......................................
2023-10-23 14:45:57,492:INFO:PyCaret RegressionExperiment
2023-10-23 14:45:57,492:INFO:Logging name: exp_B
2023-10-23 14:45:57,492:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 14:45:57,492:INFO:version 3.1.0
2023-10-23 14:45:57,492:INFO:Initializing setup()
2023-10-23 14:45:57,492:INFO:self.USI: b9ca
2023-10-23 14:45:57,492:INFO:self._variable_keys: {'gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', '_ml_usecase', 'gpu_param', 'exp_name_log', 'html_param', 'fold_generator', 'y', 'seed', 'y_train', 'transform_target_param', 'n_jobs_param', 'target_param', 'idx', '_available_plots', 'log_plots_param', 'memory', 'data', 'USI', 'X', 'logging_param', 'pipeline', 'exp_id', 'X_train', 'X_test', 'fold_groups_param'}
2023-10-23 14:45:57,492:INFO:Checking environment
2023-10-23 14:45:57,492:INFO:python_version: 3.8.18
2023-10-23 14:45:57,492:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 14:45:57,492:INFO:machine: AMD64
2023-10-23 14:45:57,492:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 14:45:57,492:INFO:Memory: svmem(total=16505954304, available=2717450240, percent=83.5, used=13788504064, free=2717450240)
2023-10-23 14:45:57,492:INFO:Physical Core: 8
2023-10-23 14:45:57,492:INFO:Logical Core: 16
2023-10-23 14:45:57,492:INFO:Checking libraries
2023-10-23 14:45:57,492:INFO:System:
2023-10-23 14:45:57,492:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 14:45:57,492:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 14:45:57,492:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 14:45:57,492:INFO:PyCaret required dependencies:
2023-10-23 14:45:57,492:INFO:                 pip: 23.3
2023-10-23 14:45:57,492:INFO:          setuptools: 68.0.0
2023-10-23 14:45:57,492:INFO:             pycaret: 3.1.0
2023-10-23 14:45:57,492:INFO:             IPython: 8.12.0
2023-10-23 14:45:57,492:INFO:          ipywidgets: 8.1.1
2023-10-23 14:45:57,492:INFO:                tqdm: 4.66.1
2023-10-23 14:45:57,492:INFO:               numpy: 1.23.5
2023-10-23 14:45:57,492:INFO:              pandas: 1.5.3
2023-10-23 14:45:57,492:INFO:              jinja2: 3.1.2
2023-10-23 14:45:57,492:INFO:               scipy: 1.10.1
2023-10-23 14:45:57,492:INFO:              joblib: 1.3.2
2023-10-23 14:45:57,492:INFO:             sklearn: 1.2.2
2023-10-23 14:45:57,492:INFO:                pyod: 1.1.0
2023-10-23 14:45:57,492:INFO:            imblearn: 0.11.0
2023-10-23 14:45:57,492:INFO:   category_encoders: 2.6.2
2023-10-23 14:45:57,492:INFO:            lightgbm: 4.1.0
2023-10-23 14:45:57,492:INFO:               numba: 0.58.1
2023-10-23 14:45:57,492:INFO:            requests: 2.31.0
2023-10-23 14:45:57,492:INFO:          matplotlib: 3.7.3
2023-10-23 14:45:57,492:INFO:          scikitplot: 0.3.7
2023-10-23 14:45:57,492:INFO:         yellowbrick: 1.5
2023-10-23 14:45:57,492:INFO:              plotly: 5.17.0
2023-10-23 14:45:57,492:INFO:    plotly-resampler: Not installed
2023-10-23 14:45:57,492:INFO:             kaleido: 0.2.1
2023-10-23 14:45:57,492:INFO:           schemdraw: 0.15
2023-10-23 14:45:57,492:INFO:         statsmodels: 0.14.0
2023-10-23 14:45:57,492:INFO:              sktime: 0.21.1
2023-10-23 14:45:57,492:INFO:               tbats: 1.1.3
2023-10-23 14:45:57,492:INFO:            pmdarima: 2.0.3
2023-10-23 14:45:57,492:INFO:              psutil: 5.9.0
2023-10-23 14:45:57,492:INFO:          markupsafe: 2.1.3
2023-10-23 14:45:57,492:INFO:             pickle5: Not installed
2023-10-23 14:45:57,492:INFO:         cloudpickle: 2.2.1
2023-10-23 14:45:57,492:INFO:         deprecation: 2.1.0
2023-10-23 14:45:57,492:INFO:              xxhash: 3.4.1
2023-10-23 14:45:57,492:INFO:           wurlitzer: Not installed
2023-10-23 14:45:57,492:INFO:PyCaret optional dependencies:
2023-10-23 14:45:57,492:INFO:                shap: Not installed
2023-10-23 14:45:57,492:INFO:           interpret: Not installed
2023-10-23 14:45:57,492:INFO:                umap: Not installed
2023-10-23 14:45:57,492:INFO:     ydata_profiling: Not installed
2023-10-23 14:45:57,492:INFO:  explainerdashboard: Not installed
2023-10-23 14:45:57,492:INFO:             autoviz: Not installed
2023-10-23 14:45:57,492:INFO:           fairlearn: Not installed
2023-10-23 14:45:57,492:INFO:          deepchecks: Not installed
2023-10-23 14:45:57,492:INFO:             xgboost: Not installed
2023-10-23 14:45:57,492:INFO:            catboost: 1.2.2
2023-10-23 14:45:57,492:INFO:              kmodes: Not installed
2023-10-23 14:45:57,492:INFO:             mlxtend: Not installed
2023-10-23 14:45:57,492:INFO:       statsforecast: Not installed
2023-10-23 14:45:57,492:INFO:        tune_sklearn: Not installed
2023-10-23 14:45:57,492:INFO:                 ray: Not installed
2023-10-23 14:45:57,492:INFO:            hyperopt: Not installed
2023-10-23 14:45:57,492:INFO:              optuna: Not installed
2023-10-23 14:45:57,492:INFO:               skopt: Not installed
2023-10-23 14:45:57,492:INFO:              mlflow: 2.7.1
2023-10-23 14:45:57,492:INFO:              gradio: Not installed
2023-10-23 14:45:57,492:INFO:             fastapi: Not installed
2023-10-23 14:45:57,492:INFO:             uvicorn: Not installed
2023-10-23 14:45:57,492:INFO:              m2cgen: Not installed
2023-10-23 14:45:57,492:INFO:           evidently: Not installed
2023-10-23 14:45:57,492:INFO:               fugue: Not installed
2023-10-23 14:45:57,492:INFO:           streamlit: Not installed
2023-10-23 14:45:57,492:INFO:             prophet: Not installed
2023-10-23 14:45:57,492:INFO:None
2023-10-23 14:45:57,492:INFO:Set up data.
2023-10-23 14:45:57,529:INFO:Set up folding strategy.
2023-10-23 14:45:57,530:INFO:Set up train/test split.
2023-10-23 14:45:57,545:INFO:Set up index.
2023-10-23 14:45:57,545:INFO:Assigning column types.
2023-10-23 14:45:57,561:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 14:45:57,561:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 14:45:57,581:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:45:57,581:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:45:57,662:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:45:57,712:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:45:57,712:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:45:57,712:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:45:57,712:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 14:45:57,712:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:45:57,712:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:45:57,802:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:45:57,846:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:45:57,846:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:45:57,846:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:45:57,846:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 14:45:57,846:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:45:57,863:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:45:57,929:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:45:57,979:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:45:57,993:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:45:57,993:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:45:57,996:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,002:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,080:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,127:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,127:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:45:58,127:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:45:58,127:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 14:45:58,127:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,212:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,265:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,266:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:45:58,266:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:45:58,266:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,342:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,389:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,389:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:45:58,389:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:45:58,389:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 14:45:58,479:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,528:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,528:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:45:58,528:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:45:58,632:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,677:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,677:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:45:58,677:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:45:58,677:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 14:45:58,764:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,816:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:45:58,816:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:45:58,905:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:45:58,956:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:45:58,957:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:45:58,957:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 14:45:59,095:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:45:59,095:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:45:59,243:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:45:59,243:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:45:59,245:INFO:Preparing preprocessing pipeline...
2023-10-23 14:45:59,245:INFO:Set up simple imputation.
2023-10-23 14:45:59,248:INFO:Set up column name cleaning.
2023-10-23 14:45:59,324:INFO:Finished creating preprocessing pipeline.
2023-10-23 14:45:59,324:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 14:45:59,324:INFO:Creating final display dataframe.
2023-10-23 14:45:59,565:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (32819, 49)
4        Transformed data shape   (32819, 49)
5   Transformed train set shape   (22973, 49)
6    Transformed test set shape    (9846, 49)
7              Numeric features            48
8      Rows with missing values         19.9%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_B
19                          USI          b9ca
2023-10-23 14:45:59,707:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:45:59,718:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:45:59,854:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:45:59,854:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:45:59,854:INFO:Logging experiment in loggers
2023-10-23 14:45:59,961:INFO:SubProcess save_model() called ==================================
2023-10-23 14:45:59,981:INFO:Initializing save_model()
2023-10-23 14:45:59,981:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmpe7u471_g\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 14:45:59,981:INFO:Adding model into prep_pipe
2023-10-23 14:45:59,982:WARNING:Only Model saved as it was a pipeline.
2023-10-23 14:45:59,986:INFO:C:\Users\thoma\AppData\Local\Temp\tmpe7u471_g\Transformation Pipeline.pkl saved in current working directory
2023-10-23 14:45:59,993:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 14:45:59,993:INFO:save_model() successfully completed......................................
2023-10-23 14:46:00,105:INFO:SubProcess save_model() end ==================================
2023-10-23 14:46:00,160:INFO:setup() successfully completed in 2.38s...............
2023-10-23 14:46:00,160:INFO:Initializing create_model()
2023-10-23 14:46:00,160:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E87DF0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:46:00,160:INFO:Checking exceptions
2023-10-23 14:46:00,160:INFO:Importing libraries
2023-10-23 14:46:00,160:INFO:Copying training dataset
2023-10-23 14:46:00,184:INFO:Defining folds
2023-10-23 14:46:00,184:INFO:Declaring metric variables
2023-10-23 14:46:00,184:INFO:Importing untrained model
2023-10-23 14:46:00,184:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:46:00,184:INFO:Starting cross validation
2023-10-23 14:46:00,191:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:46:03,398:INFO:Calculating mean and std
2023-10-23 14:46:03,398:INFO:Creating metrics dataframe
2023-10-23 14:46:03,398:INFO:Finalizing model
2023-10-23 14:46:03,498:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005603 seconds.
2023-10-23 14:46:03,498:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:46:03,499:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:46:03,499:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:46:03,500:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-23 14:46:03,727:INFO:Creating Dashboard logs
2023-10-23 14:46:03,727:INFO:Model: Light Gradient Boosting Machine
2023-10-23 14:46:03,815:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 14:46:03,992:INFO:Initializing predict_model()
2023-10-23 14:46:03,992:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E87DF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096364A60>)
2023-10-23 14:46:03,992:INFO:Checking exceptions
2023-10-23 14:46:03,992:INFO:Preloading libraries
2023-10-23 14:46:04,463:INFO:Uploading results into container
2023-10-23 14:46:04,463:INFO:Uploading model into container now
2023-10-23 14:46:04,463:INFO:_master_model_container: 1
2023-10-23 14:46:04,463:INFO:_display_container: 2
2023-10-23 14:46:04,463:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:46:04,463:INFO:create_model() successfully completed......................................
2023-10-23 14:46:04,604:INFO:Initializing tune_model()
2023-10-23 14:46:04,604:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E87DF0>)
2023-10-23 14:46:04,604:INFO:Checking exceptions
2023-10-23 14:46:04,611:INFO:Copying training dataset
2023-10-23 14:46:04,620:INFO:Checking base model
2023-10-23 14:46:04,620:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 14:46:04,620:INFO:Declaring metric variables
2023-10-23 14:46:04,620:INFO:Defining Hyperparameters
2023-10-23 14:46:04,727:INFO:Tuning with n_jobs=-1
2023-10-23 14:46:04,727:INFO:Initializing RandomizedSearchCV
2023-10-23 14:46:50,700:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-23 14:46:50,701:INFO:Hyperparameter search completed
2023-10-23 14:46:50,701:INFO:SubProcess create_model() called ==================================
2023-10-23 14:46:50,702:INFO:Initializing create_model()
2023-10-23 14:46:50,703:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E87DF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E0962FA850>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-23 14:46:50,703:INFO:Checking exceptions
2023-10-23 14:46:50,703:INFO:Importing libraries
2023-10-23 14:46:50,703:INFO:Copying training dataset
2023-10-23 14:46:50,737:INFO:Defining folds
2023-10-23 14:46:50,737:INFO:Declaring metric variables
2023-10-23 14:46:50,737:INFO:Importing untrained model
2023-10-23 14:46:50,737:INFO:Declaring custom model
2023-10-23 14:46:50,738:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:46:50,739:INFO:Starting cross validation
2023-10-23 14:46:50,740:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:47:00,304:INFO:Calculating mean and std
2023-10-23 14:47:00,306:INFO:Creating metrics dataframe
2023-10-23 14:47:00,309:INFO:Finalizing model
2023-10-23 14:47:00,360:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-23 14:47:00,360:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-23 14:47:00,361:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-23 14:47:00,394:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-23 14:47:00,394:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-23 14:47:00,394:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-23 14:47:00,395:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001608 seconds.
2023-10-23 14:47:00,395:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-23 14:47:00,395:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-23 14:47:00,395:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:47:00,395:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:47:00,395:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-23 14:47:01,750:INFO:Uploading results into container
2023-10-23 14:47:01,752:INFO:Uploading model into container now
2023-10-23 14:47:01,753:INFO:_master_model_container: 2
2023-10-23 14:47:01,753:INFO:_display_container: 3
2023-10-23 14:47:01,754:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-23 14:47:01,756:INFO:create_model() successfully completed......................................
2023-10-23 14:47:01,891:INFO:SubProcess create_model() end ==================================
2023-10-23 14:47:01,891:INFO:choose_better activated
2023-10-23 14:47:01,891:INFO:SubProcess create_model() called ==================================
2023-10-23 14:47:01,891:INFO:Initializing create_model()
2023-10-23 14:47:01,891:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E87DF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:47:01,891:INFO:Checking exceptions
2023-10-23 14:47:01,891:INFO:Importing libraries
2023-10-23 14:47:01,891:INFO:Copying training dataset
2023-10-23 14:47:01,908:INFO:Defining folds
2023-10-23 14:47:01,908:INFO:Declaring metric variables
2023-10-23 14:47:01,908:INFO:Importing untrained model
2023-10-23 14:47:01,908:INFO:Declaring custom model
2023-10-23 14:47:01,908:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:47:01,908:INFO:Starting cross validation
2023-10-23 14:47:01,908:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:47:04,461:INFO:Calculating mean and std
2023-10-23 14:47:04,461:INFO:Creating metrics dataframe
2023-10-23 14:47:04,461:INFO:Finalizing model
2023-10-23 14:47:04,544:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004684 seconds.
2023-10-23 14:47:04,544:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:04,544:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:47:04,545:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:47:04,545:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-23 14:47:04,822:INFO:Uploading results into container
2023-10-23 14:47:04,822:INFO:Uploading model into container now
2023-10-23 14:47:04,822:INFO:_master_model_container: 3
2023-10-23 14:47:04,822:INFO:_display_container: 4
2023-10-23 14:47:04,822:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:47:04,822:INFO:create_model() successfully completed......................................
2023-10-23 14:47:04,939:INFO:SubProcess create_model() end ==================================
2023-10-23 14:47:04,954:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8523
2023-10-23 14:47:04,955:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8523
2023-10-23 14:47:04,955:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-23 14:47:04,955:INFO:choose_better completed
2023-10-23 14:47:04,955:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-23 14:47:04,955:INFO:Creating Dashboard logs
2023-10-23 14:47:04,955:INFO:Model: Light Gradient Boosting Machine
2023-10-23 14:47:05,022:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 14:47:05,238:INFO:Initializing predict_model()
2023-10-23 14:47:05,238:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E87DF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E0970E9D30>)
2023-10-23 14:47:05,238:INFO:Checking exceptions
2023-10-23 14:47:05,238:INFO:Preloading libraries
2023-10-23 14:47:05,760:INFO:_master_model_container: 3
2023-10-23 14:47:05,760:INFO:_display_container: 3
2023-10-23 14:47:05,761:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:47:05,761:INFO:tune_model() successfully completed......................................
2023-10-23 14:47:05,860:INFO:Initializing ensemble_model()
2023-10-23 14:47:05,860:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E87DF0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-23 14:47:05,860:INFO:Checking exceptions
2023-10-23 14:47:05,874:INFO:Importing libraries
2023-10-23 14:47:05,874:INFO:Copying training dataset
2023-10-23 14:47:05,874:INFO:Checking base model
2023-10-23 14:47:05,874:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 14:47:05,874:INFO:Importing untrained ensembler
2023-10-23 14:47:05,874:INFO:Ensemble method set to Bagging
2023-10-23 14:47:05,874:INFO:SubProcess create_model() called ==================================
2023-10-23 14:47:05,874:INFO:Initializing create_model()
2023-10-23 14:47:05,874:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E87DF0>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E096781040>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:47:05,874:INFO:Checking exceptions
2023-10-23 14:47:05,874:INFO:Importing libraries
2023-10-23 14:47:05,874:INFO:Copying training dataset
2023-10-23 14:47:05,905:INFO:Defining folds
2023-10-23 14:47:05,905:INFO:Declaring metric variables
2023-10-23 14:47:05,905:INFO:Importing untrained model
2023-10-23 14:47:05,905:INFO:Declaring custom model
2023-10-23 14:47:05,909:INFO:Bagging Regressor Imported successfully
2023-10-23 14:47:05,909:INFO:Starting cross validation
2023-10-23 14:47:05,910:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:47:29,635:INFO:Calculating mean and std
2023-10-23 14:47:29,637:INFO:Creating metrics dataframe
2023-10-23 14:47:29,639:INFO:Finalizing model
2023-10-23 14:47:29,724:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005547 seconds.
2023-10-23 14:47:29,724:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:29,724:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:47:29,734:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:47:29,735:INFO:[LightGBM] [Info] Start training from score 99.624795
2023-10-23 14:47:30,054:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005853 seconds.
2023-10-23 14:47:30,054:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:30,054:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:47:30,054:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:47:30,054:INFO:[LightGBM] [Info] Start training from score 96.229614
2023-10-23 14:47:30,338:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005411 seconds.
2023-10-23 14:47:30,338:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:30,338:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:47:30,338:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:47:30,338:INFO:[LightGBM] [Info] Start training from score 95.360987
2023-10-23 14:47:30,623:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007590 seconds.
2023-10-23 14:47:30,623:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:30,623:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:47:30,623:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:47:30,623:INFO:[LightGBM] [Info] Start training from score 94.348528
2023-10-23 14:47:30,976:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005415 seconds.
2023-10-23 14:47:30,976:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:30,976:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:47:30,976:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:47:30,976:INFO:[LightGBM] [Info] Start training from score 95.509684
2023-10-23 14:47:31,253:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005506 seconds.
2023-10-23 14:47:31,254:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:31,254:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:47:31,255:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:47:31,256:INFO:[LightGBM] [Info] Start training from score 96.036959
2023-10-23 14:47:31,558:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005650 seconds.
2023-10-23 14:47:31,558:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:31,558:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:47:31,565:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:47:31,566:INFO:[LightGBM] [Info] Start training from score 97.844637
2023-10-23 14:47:31,883:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007215 seconds.
2023-10-23 14:47:31,883:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:31,883:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:47:31,883:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:47:31,883:INFO:[LightGBM] [Info] Start training from score 96.245614
2023-10-23 14:47:32,193:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005736 seconds.
2023-10-23 14:47:32,194:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:32,194:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:47:32,194:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:47:32,195:INFO:[LightGBM] [Info] Start training from score 97.594984
2023-10-23 14:47:32,515:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005202 seconds.
2023-10-23 14:47:32,515:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:32,516:INFO:[LightGBM] [Info] Total Bins 6466
2023-10-23 14:47:32,517:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 45
2023-10-23 14:47:32,517:INFO:[LightGBM] [Info] Start training from score 96.370407
2023-10-23 14:47:32,767:INFO:Uploading results into container
2023-10-23 14:47:32,767:INFO:Uploading model into container now
2023-10-23 14:47:32,767:INFO:_master_model_container: 4
2023-10-23 14:47:32,767:INFO:_display_container: 4
2023-10-23 14:47:32,773:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:47:32,773:INFO:create_model() successfully completed......................................
2023-10-23 14:47:32,905:INFO:SubProcess create_model() end ==================================
2023-10-23 14:47:32,906:INFO:Creating Dashboard logs
2023-10-23 14:47:32,906:INFO:Model: Bagging Regressor
2023-10-23 14:47:32,968:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-23 14:47:33,173:INFO:Initializing predict_model()
2023-10-23 14:47:33,173:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E87DF0>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096B345E0>)
2023-10-23 14:47:33,173:INFO:Checking exceptions
2023-10-23 14:47:33,173:INFO:Preloading libraries
2023-10-23 14:47:33,827:INFO:_master_model_container: 4
2023-10-23 14:47:33,827:INFO:_display_container: 4
2023-10-23 14:47:33,830:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:47:33,830:INFO:ensemble_model() successfully completed......................................
2023-10-23 14:47:33,965:INFO:Initializing finalize_model()
2023-10-23 14:47:33,965:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E87DF0>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-23 14:47:33,965:INFO:Finalizing BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:47:33,982:INFO:Initializing create_model()
2023-10-23 14:47:33,982:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E87DF0>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-23 14:47:33,982:INFO:Checking exceptions
2023-10-23 14:47:33,982:INFO:Importing libraries
2023-10-23 14:47:33,982:INFO:Copying training dataset
2023-10-23 14:47:33,982:INFO:Defining folds
2023-10-23 14:47:33,982:INFO:Declaring metric variables
2023-10-23 14:47:33,982:INFO:Importing untrained model
2023-10-23 14:47:33,982:INFO:Declaring custom model
2023-10-23 14:47:33,982:INFO:Bagging Regressor Imported successfully
2023-10-23 14:47:33,982:INFO:Cross validation set to False
2023-10-23 14:47:33,982:INFO:Fitting Model
2023-10-23 14:47:34,142:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009669 seconds.
2023-10-23 14:47:34,142:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:34,143:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:47:34,143:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:47:34,145:INFO:[LightGBM] [Info] Start training from score 96.465021
2023-10-23 14:47:34,513:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006795 seconds.
2023-10-23 14:47:34,513:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:34,513:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:47:34,514:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:47:34,515:INFO:[LightGBM] [Info] Start training from score 97.264361
2023-10-23 14:47:34,883:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010233 seconds.
2023-10-23 14:47:34,883:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:34,883:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:47:34,883:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:47:34,883:INFO:[LightGBM] [Info] Start training from score 95.842370
2023-10-23 14:47:35,429:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009869 seconds.
2023-10-23 14:47:35,429:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:35,430:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:47:35,431:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:47:35,431:INFO:[LightGBM] [Info] Start training from score 95.431515
2023-10-23 14:47:35,829:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009113 seconds.
2023-10-23 14:47:35,829:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:35,829:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:47:35,829:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:47:35,829:INFO:[LightGBM] [Info] Start training from score 97.222213
2023-10-23 14:47:36,301:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013524 seconds.
2023-10-23 14:47:36,301:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:36,302:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:47:36,303:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:47:36,303:INFO:[LightGBM] [Info] Start training from score 97.332701
2023-10-23 14:47:36,665:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009251 seconds.
2023-10-23 14:47:36,666:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:36,666:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:47:36,667:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:47:36,668:INFO:[LightGBM] [Info] Start training from score 96.452612
2023-10-23 14:47:37,030:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008704 seconds.
2023-10-23 14:47:37,030:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:37,030:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:47:37,030:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:47:37,030:INFO:[LightGBM] [Info] Start training from score 97.322509
2023-10-23 14:47:37,373:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009085 seconds.
2023-10-23 14:47:37,373:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:37,374:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:47:37,374:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:47:37,376:INFO:[LightGBM] [Info] Start training from score 96.419103
2023-10-23 14:47:37,708:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007364 seconds.
2023-10-23 14:47:37,708:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:37,709:INFO:[LightGBM] [Info] Total Bins 6544
2023-10-23 14:47:37,709:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 45
2023-10-23 14:47:37,710:INFO:[LightGBM] [Info] Start training from score 95.095963
2023-10-23 14:47:37,973:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:47:37,973:INFO:create_model() successfully completed......................................
2023-10-23 14:47:38,102:INFO:Creating Dashboard logs
2023-10-23 14:47:38,103:INFO:Model: Bagging Regressor
2023-10-23 14:47:38,171:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-23 14:47:38,565:INFO:_master_model_container: 4
2023-10-23 14:47:38,565:INFO:_display_container: 4
2023-10-23 14:47:38,575:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:47:38,575:INFO:finalize_model() successfully completed......................................
2023-10-23 14:47:38,691:INFO:Initializing save_model()
2023-10-23 14:47:38,691:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), model_name=final_model_for_location_B, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 14:47:38,691:INFO:Adding model into prep_pipe
2023-10-23 14:47:38,691:WARNING:Only Model saved as it was a pipeline.
2023-10-23 14:47:38,751:INFO:final_model_for_location_B.pkl saved in current working directory
2023-10-23 14:47:38,771:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:47:38,771:INFO:save_model() successfully completed......................................
2023-10-23 14:47:38,912:INFO:PyCaret RegressionExperiment
2023-10-23 14:47:38,912:INFO:Logging name: exp_C
2023-10-23 14:47:38,912:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 14:47:38,912:INFO:version 3.1.0
2023-10-23 14:47:38,912:INFO:Initializing setup()
2023-10-23 14:47:38,912:INFO:self.USI: 349b
2023-10-23 14:47:38,912:INFO:self._variable_keys: {'gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', '_ml_usecase', 'gpu_param', 'exp_name_log', 'html_param', 'fold_generator', 'y', 'seed', 'y_train', 'transform_target_param', 'n_jobs_param', 'target_param', 'idx', '_available_plots', 'log_plots_param', 'memory', 'data', 'USI', 'X', 'logging_param', 'pipeline', 'exp_id', 'X_train', 'X_test', 'fold_groups_param'}
2023-10-23 14:47:38,912:INFO:Checking environment
2023-10-23 14:47:38,913:INFO:python_version: 3.8.18
2023-10-23 14:47:38,913:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 14:47:38,913:INFO:machine: AMD64
2023-10-23 14:47:38,913:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 14:47:38,913:INFO:Memory: svmem(total=16505954304, available=2728316928, percent=83.5, used=13777637376, free=2728316928)
2023-10-23 14:47:38,913:INFO:Physical Core: 8
2023-10-23 14:47:38,913:INFO:Logical Core: 16
2023-10-23 14:47:38,913:INFO:Checking libraries
2023-10-23 14:47:38,914:INFO:System:
2023-10-23 14:47:38,914:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 14:47:38,914:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 14:47:38,914:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 14:47:38,914:INFO:PyCaret required dependencies:
2023-10-23 14:47:38,914:INFO:                 pip: 23.3
2023-10-23 14:47:38,914:INFO:          setuptools: 68.0.0
2023-10-23 14:47:38,914:INFO:             pycaret: 3.1.0
2023-10-23 14:47:38,914:INFO:             IPython: 8.12.0
2023-10-23 14:47:38,914:INFO:          ipywidgets: 8.1.1
2023-10-23 14:47:38,914:INFO:                tqdm: 4.66.1
2023-10-23 14:47:38,914:INFO:               numpy: 1.23.5
2023-10-23 14:47:38,914:INFO:              pandas: 1.5.3
2023-10-23 14:47:38,914:INFO:              jinja2: 3.1.2
2023-10-23 14:47:38,914:INFO:               scipy: 1.10.1
2023-10-23 14:47:38,915:INFO:              joblib: 1.3.2
2023-10-23 14:47:38,915:INFO:             sklearn: 1.2.2
2023-10-23 14:47:38,915:INFO:                pyod: 1.1.0
2023-10-23 14:47:38,915:INFO:            imblearn: 0.11.0
2023-10-23 14:47:38,915:INFO:   category_encoders: 2.6.2
2023-10-23 14:47:38,915:INFO:            lightgbm: 4.1.0
2023-10-23 14:47:38,915:INFO:               numba: 0.58.1
2023-10-23 14:47:38,915:INFO:            requests: 2.31.0
2023-10-23 14:47:38,915:INFO:          matplotlib: 3.7.3
2023-10-23 14:47:38,915:INFO:          scikitplot: 0.3.7
2023-10-23 14:47:38,915:INFO:         yellowbrick: 1.5
2023-10-23 14:47:38,915:INFO:              plotly: 5.17.0
2023-10-23 14:47:38,916:INFO:    plotly-resampler: Not installed
2023-10-23 14:47:38,916:INFO:             kaleido: 0.2.1
2023-10-23 14:47:38,916:INFO:           schemdraw: 0.15
2023-10-23 14:47:38,916:INFO:         statsmodels: 0.14.0
2023-10-23 14:47:38,916:INFO:              sktime: 0.21.1
2023-10-23 14:47:38,916:INFO:               tbats: 1.1.3
2023-10-23 14:47:38,916:INFO:            pmdarima: 2.0.3
2023-10-23 14:47:38,916:INFO:              psutil: 5.9.0
2023-10-23 14:47:38,916:INFO:          markupsafe: 2.1.3
2023-10-23 14:47:38,916:INFO:             pickle5: Not installed
2023-10-23 14:47:38,916:INFO:         cloudpickle: 2.2.1
2023-10-23 14:47:38,916:INFO:         deprecation: 2.1.0
2023-10-23 14:47:38,916:INFO:              xxhash: 3.4.1
2023-10-23 14:47:38,916:INFO:           wurlitzer: Not installed
2023-10-23 14:47:38,916:INFO:PyCaret optional dependencies:
2023-10-23 14:47:38,917:INFO:                shap: Not installed
2023-10-23 14:47:38,917:INFO:           interpret: Not installed
2023-10-23 14:47:38,917:INFO:                umap: Not installed
2023-10-23 14:47:38,917:INFO:     ydata_profiling: Not installed
2023-10-23 14:47:38,917:INFO:  explainerdashboard: Not installed
2023-10-23 14:47:38,917:INFO:             autoviz: Not installed
2023-10-23 14:47:38,917:INFO:           fairlearn: Not installed
2023-10-23 14:47:38,917:INFO:          deepchecks: Not installed
2023-10-23 14:47:38,917:INFO:             xgboost: Not installed
2023-10-23 14:47:38,917:INFO:            catboost: 1.2.2
2023-10-23 14:47:38,917:INFO:              kmodes: Not installed
2023-10-23 14:47:38,917:INFO:             mlxtend: Not installed
2023-10-23 14:47:38,917:INFO:       statsforecast: Not installed
2023-10-23 14:47:38,917:INFO:        tune_sklearn: Not installed
2023-10-23 14:47:38,917:INFO:                 ray: Not installed
2023-10-23 14:47:38,917:INFO:            hyperopt: Not installed
2023-10-23 14:47:38,917:INFO:              optuna: Not installed
2023-10-23 14:47:38,917:INFO:               skopt: Not installed
2023-10-23 14:47:38,917:INFO:              mlflow: 2.7.1
2023-10-23 14:47:38,918:INFO:              gradio: Not installed
2023-10-23 14:47:38,918:INFO:             fastapi: Not installed
2023-10-23 14:47:38,918:INFO:             uvicorn: Not installed
2023-10-23 14:47:38,918:INFO:              m2cgen: Not installed
2023-10-23 14:47:38,918:INFO:           evidently: Not installed
2023-10-23 14:47:38,918:INFO:               fugue: Not installed
2023-10-23 14:47:38,918:INFO:           streamlit: Not installed
2023-10-23 14:47:38,918:INFO:             prophet: Not installed
2023-10-23 14:47:38,918:INFO:None
2023-10-23 14:47:38,918:INFO:Set up data.
2023-10-23 14:47:38,948:INFO:Set up folding strategy.
2023-10-23 14:47:38,948:INFO:Set up train/test split.
2023-10-23 14:47:38,969:INFO:Set up index.
2023-10-23 14:47:38,970:INFO:Assigning column types.
2023-10-23 14:47:38,989:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 14:47:38,990:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 14:47:38,995:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,000:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,078:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,140:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,140:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:47:39,141:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:47:39,141:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,147:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,153:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,233:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,282:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,283:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:47:39,283:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:47:39,283:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 14:47:39,289:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,294:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,369:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,417:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,418:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:47:39,418:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:47:39,425:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,430:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,503:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,552:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,553:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:47:39,553:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:47:39,554:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 14:47:39,565:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,639:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,688:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,689:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:47:39,689:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:47:39,700:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,773:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,821:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,822:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:47:39,822:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:47:39,823:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 14:47:39,908:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,957:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:47:39,958:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:47:39,958:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:47:40,051:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:47:40,089:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 14:47:40,089:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:47:40,089:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:47:40,089:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 14:47:40,178:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:47:40,232:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:47:40,232:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:47:40,310:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 14:47:40,362:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:47:40,362:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:47:40,362:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 14:47:40,501:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:47:40,501:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:47:40,655:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:47:40,656:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:47:40,657:INFO:Preparing preprocessing pipeline...
2023-10-23 14:47:40,657:INFO:Set up simple imputation.
2023-10-23 14:47:40,660:INFO:Set up column name cleaning.
2023-10-23 14:47:40,740:INFO:Finished creating preprocessing pipeline.
2023-10-23 14:47:40,740:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 14:47:40,740:INFO:Creating final display dataframe.
2023-10-23 14:47:40,979:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (26071, 49)
4        Transformed data shape   (26071, 49)
5   Transformed train set shape   (18249, 49)
6    Transformed test set shape    (7822, 49)
7              Numeric features            48
8      Rows with missing values         25.0%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13               Fold Generator         KFold
14                  Fold Number            10
15                     CPU Jobs            -1
16                      Use GPU         False
17               Log Experiment  MlflowLogger
18              Experiment Name         exp_C
19                          USI          349b
2023-10-23 14:47:41,125:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:47:41,126:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:47:41,278:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 14:47:41,278:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 14:47:41,280:INFO:Logging experiment in loggers
2023-10-23 14:47:41,414:INFO:SubProcess save_model() called ==================================
2023-10-23 14:47:41,430:INFO:Initializing save_model()
2023-10-23 14:47:41,430:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmpy9t5z0ne\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 14:47:41,430:INFO:Adding model into prep_pipe
2023-10-23 14:47:41,430:WARNING:Only Model saved as it was a pipeline.
2023-10-23 14:47:41,434:INFO:C:\Users\thoma\AppData\Local\Temp\tmpy9t5z0ne\Transformation Pipeline.pkl saved in current working directory
2023-10-23 14:47:41,442:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 14:47:41,442:INFO:save_model() successfully completed......................................
2023-10-23 14:47:41,566:INFO:SubProcess save_model() end ==================================
2023-10-23 14:47:41,628:INFO:setup() successfully completed in 2.37s...............
2023-10-23 14:47:41,629:INFO:Initializing create_model()
2023-10-23 14:47:41,629:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E095E7AF70>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:47:41,629:INFO:Checking exceptions
2023-10-23 14:47:41,633:INFO:Importing libraries
2023-10-23 14:47:41,633:INFO:Copying training dataset
2023-10-23 14:47:41,656:INFO:Defining folds
2023-10-23 14:47:41,656:INFO:Declaring metric variables
2023-10-23 14:47:41,656:INFO:Importing untrained model
2023-10-23 14:47:41,657:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:47:41,657:INFO:Starting cross validation
2023-10-23 14:47:41,659:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:47:44,812:INFO:Calculating mean and std
2023-10-23 14:47:44,814:INFO:Creating metrics dataframe
2023-10-23 14:47:44,819:INFO:Finalizing model
2023-10-23 14:47:44,903:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003910 seconds.
2023-10-23 14:47:44,904:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:47:44,904:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:47:44,905:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:47:44,905:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-23 14:47:45,157:INFO:Creating Dashboard logs
2023-10-23 14:47:45,157:INFO:Model: Light Gradient Boosting Machine
2023-10-23 14:47:45,256:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 14:47:45,455:INFO:Initializing predict_model()
2023-10-23 14:47:45,455:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E095E7AF70>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096789310>)
2023-10-23 14:47:45,455:INFO:Checking exceptions
2023-10-23 14:47:45,455:INFO:Preloading libraries
2023-10-23 14:47:45,958:INFO:Uploading results into container
2023-10-23 14:47:45,958:INFO:Uploading model into container now
2023-10-23 14:47:45,958:INFO:_master_model_container: 1
2023-10-23 14:47:45,958:INFO:_display_container: 2
2023-10-23 14:47:45,958:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:47:45,958:INFO:create_model() successfully completed......................................
2023-10-23 14:47:46,069:INFO:Initializing tune_model()
2023-10-23 14:47:46,069:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E095E7AF70>)
2023-10-23 14:47:46,069:INFO:Checking exceptions
2023-10-23 14:47:46,082:INFO:Copying training dataset
2023-10-23 14:47:46,085:INFO:Checking base model
2023-10-23 14:47:46,085:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 14:47:46,085:INFO:Declaring metric variables
2023-10-23 14:47:46,085:INFO:Defining Hyperparameters
2023-10-23 14:47:46,232:INFO:Tuning with n_jobs=-1
2023-10-23 14:47:46,232:INFO:Initializing RandomizedSearchCV
2023-10-23 14:48:24,018:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-23 14:48:24,019:INFO:Hyperparameter search completed
2023-10-23 14:48:24,019:INFO:SubProcess create_model() called ==================================
2023-10-23 14:48:24,020:INFO:Initializing create_model()
2023-10-23 14:48:24,021:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E095E7AF70>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E096CD9760>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-23 14:48:24,021:INFO:Checking exceptions
2023-10-23 14:48:24,021:INFO:Importing libraries
2023-10-23 14:48:24,021:INFO:Copying training dataset
2023-10-23 14:48:24,050:INFO:Defining folds
2023-10-23 14:48:24,050:INFO:Declaring metric variables
2023-10-23 14:48:24,050:INFO:Importing untrained model
2023-10-23 14:48:24,051:INFO:Declaring custom model
2023-10-23 14:48:24,052:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:48:24,052:INFO:Starting cross validation
2023-10-23 14:48:24,054:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:48:34,839:INFO:Calculating mean and std
2023-10-23 14:48:34,840:INFO:Creating metrics dataframe
2023-10-23 14:48:34,844:INFO:Finalizing model
2023-10-23 14:48:34,890:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-23 14:48:34,890:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-23 14:48:34,890:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-23 14:48:34,916:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-23 14:48:34,916:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-23 14:48:34,916:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-23 14:48:34,922:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004448 seconds.
2023-10-23 14:48:34,922:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:48:34,923:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:48:34,923:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:48:34,925:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-23 14:48:34,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:48:34,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:48:34,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:48:34,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:48:34,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:48:34,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:48:34,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:48:34,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-23 14:48:36,170:INFO:Uploading results into container
2023-10-23 14:48:36,171:INFO:Uploading model into container now
2023-10-23 14:48:36,172:INFO:_master_model_container: 2
2023-10-23 14:48:36,172:INFO:_display_container: 3
2023-10-23 14:48:36,173:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-23 14:48:36,174:INFO:create_model() successfully completed......................................
2023-10-23 14:48:36,327:INFO:SubProcess create_model() end ==================================
2023-10-23 14:48:36,327:INFO:choose_better activated
2023-10-23 14:48:36,327:INFO:SubProcess create_model() called ==================================
2023-10-23 14:48:36,328:INFO:Initializing create_model()
2023-10-23 14:48:36,328:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E095E7AF70>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:48:36,329:INFO:Checking exceptions
2023-10-23 14:48:36,330:INFO:Importing libraries
2023-10-23 14:48:36,330:INFO:Copying training dataset
2023-10-23 14:48:36,354:INFO:Defining folds
2023-10-23 14:48:36,354:INFO:Declaring metric variables
2023-10-23 14:48:36,354:INFO:Importing untrained model
2023-10-23 14:48:36,354:INFO:Declaring custom model
2023-10-23 14:48:36,355:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 14:48:36,356:INFO:Starting cross validation
2023-10-23 14:48:36,357:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:48:39,155:INFO:Calculating mean and std
2023-10-23 14:48:39,155:INFO:Creating metrics dataframe
2023-10-23 14:48:39,155:INFO:Finalizing model
2023-10-23 14:48:39,233:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005192 seconds.
2023-10-23 14:48:39,233:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:48:39,233:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:48:39,233:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:48:39,233:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-23 14:48:39,479:INFO:Uploading results into container
2023-10-23 14:48:39,480:INFO:Uploading model into container now
2023-10-23 14:48:39,481:INFO:_master_model_container: 3
2023-10-23 14:48:39,481:INFO:_display_container: 4
2023-10-23 14:48:39,481:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:48:39,481:INFO:create_model() successfully completed......................................
2023-10-23 14:48:39,626:INFO:SubProcess create_model() end ==================================
2023-10-23 14:48:39,628:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.905
2023-10-23 14:48:39,629:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8993
2023-10-23 14:48:39,629:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-23 14:48:39,629:INFO:choose_better completed
2023-10-23 14:48:39,629:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-23 14:48:39,630:INFO:Creating Dashboard logs
2023-10-23 14:48:39,630:INFO:Model: Light Gradient Boosting Machine
2023-10-23 14:48:39,700:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 14:48:39,888:INFO:Initializing predict_model()
2023-10-23 14:48:39,889:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E095E7AF70>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096CAF550>)
2023-10-23 14:48:39,889:INFO:Checking exceptions
2023-10-23 14:48:39,889:INFO:Preloading libraries
2023-10-23 14:48:40,388:INFO:_master_model_container: 3
2023-10-23 14:48:40,389:INFO:_display_container: 3
2023-10-23 14:48:40,389:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 14:48:40,389:INFO:tune_model() successfully completed......................................
2023-10-23 14:48:40,504:INFO:Initializing ensemble_model()
2023-10-23 14:48:40,504:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E095E7AF70>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-23 14:48:40,504:INFO:Checking exceptions
2023-10-23 14:48:40,515:INFO:Importing libraries
2023-10-23 14:48:40,516:INFO:Copying training dataset
2023-10-23 14:48:40,516:INFO:Checking base model
2023-10-23 14:48:40,516:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 14:48:40,517:INFO:Importing untrained ensembler
2023-10-23 14:48:40,517:INFO:Ensemble method set to Bagging
2023-10-23 14:48:40,517:INFO:SubProcess create_model() called ==================================
2023-10-23 14:48:40,518:INFO:Initializing create_model()
2023-10-23 14:48:40,518:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E095E7AF70>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E096EFA970>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 14:48:40,518:INFO:Checking exceptions
2023-10-23 14:48:40,518:INFO:Importing libraries
2023-10-23 14:48:40,518:INFO:Copying training dataset
2023-10-23 14:48:40,540:INFO:Defining folds
2023-10-23 14:48:40,540:INFO:Declaring metric variables
2023-10-23 14:48:40,540:INFO:Importing untrained model
2023-10-23 14:48:40,540:INFO:Declaring custom model
2023-10-23 14:48:40,542:INFO:Bagging Regressor Imported successfully
2023-10-23 14:48:40,542:INFO:Starting cross validation
2023-10-23 14:48:40,544:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 14:49:08,614:INFO:Calculating mean and std
2023-10-23 14:49:08,616:INFO:Creating metrics dataframe
2023-10-23 14:49:08,620:INFO:Finalizing model
2023-10-23 14:49:08,715:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004583 seconds.
2023-10-23 14:49:08,716:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:08,716:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:49:08,717:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:49:08,717:INFO:[LightGBM] [Info] Start training from score 77.044367
2023-10-23 14:49:09,016:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005129 seconds.
2023-10-23 14:49:09,016:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:09,017:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:49:09,017:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:49:09,019:INFO:[LightGBM] [Info] Start training from score 76.520588
2023-10-23 14:49:09,297:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005449 seconds.
2023-10-23 14:49:09,297:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:09,298:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:49:09,298:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:49:09,299:INFO:[LightGBM] [Info] Start training from score 76.462170
2023-10-23 14:49:09,559:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004986 seconds.
2023-10-23 14:49:09,559:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:09,560:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:49:09,560:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:49:09,561:INFO:[LightGBM] [Info] Start training from score 77.386428
2023-10-23 14:49:09,830:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004397 seconds.
2023-10-23 14:49:09,831:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:09,831:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:49:09,832:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:49:09,832:INFO:[LightGBM] [Info] Start training from score 73.916304
2023-10-23 14:49:10,118:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004851 seconds.
2023-10-23 14:49:10,118:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:10,119:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:49:10,119:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:49:10,119:INFO:[LightGBM] [Info] Start training from score 75.879633
2023-10-23 14:49:10,391:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004740 seconds.
2023-10-23 14:49:10,391:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:10,391:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:49:10,391:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:49:10,392:INFO:[LightGBM] [Info] Start training from score 75.615395
2023-10-23 14:49:10,669:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005798 seconds.
2023-10-23 14:49:10,669:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:10,670:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:49:10,670:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:49:10,671:INFO:[LightGBM] [Info] Start training from score 79.544595
2023-10-23 14:49:10,955:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004772 seconds.
2023-10-23 14:49:10,955:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:10,955:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:49:10,956:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:49:10,956:INFO:[LightGBM] [Info] Start training from score 76.012052
2023-10-23 14:49:11,212:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005272 seconds.
2023-10-23 14:49:11,212:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:11,212:INFO:[LightGBM] [Info] Total Bins 6675
2023-10-23 14:49:11,213:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 46
2023-10-23 14:49:11,213:INFO:[LightGBM] [Info] Start training from score 78.124037
2023-10-23 14:49:11,439:INFO:Uploading results into container
2023-10-23 14:49:11,440:INFO:Uploading model into container now
2023-10-23 14:49:11,441:INFO:_master_model_container: 4
2023-10-23 14:49:11,442:INFO:_display_container: 4
2023-10-23 14:49:11,443:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:49:11,444:INFO:create_model() successfully completed......................................
2023-10-23 14:49:11,580:INFO:SubProcess create_model() end ==================================
2023-10-23 14:49:11,581:INFO:Creating Dashboard logs
2023-10-23 14:49:11,581:INFO:Model: Bagging Regressor
2023-10-23 14:49:11,655:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-23 14:49:11,884:INFO:Initializing predict_model()
2023-10-23 14:49:11,884:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E095E7AF70>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096CAF700>)
2023-10-23 14:49:11,884:INFO:Checking exceptions
2023-10-23 14:49:11,884:INFO:Preloading libraries
2023-10-23 14:49:12,495:INFO:_master_model_container: 4
2023-10-23 14:49:12,496:INFO:_display_container: 4
2023-10-23 14:49:12,497:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:49:12,497:INFO:ensemble_model() successfully completed......................................
2023-10-23 14:49:12,611:INFO:Initializing finalize_model()
2023-10-23 14:49:12,611:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E095E7AF70>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-23 14:49:12,611:INFO:Finalizing BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-23 14:49:12,624:INFO:Initializing create_model()
2023-10-23 14:49:12,624:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E095E7AF70>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-23 14:49:12,624:INFO:Checking exceptions
2023-10-23 14:49:12,625:INFO:Importing libraries
2023-10-23 14:49:12,625:INFO:Copying training dataset
2023-10-23 14:49:12,626:INFO:Defining folds
2023-10-23 14:49:12,626:INFO:Declaring metric variables
2023-10-23 14:49:12,626:INFO:Importing untrained model
2023-10-23 14:49:12,626:INFO:Declaring custom model
2023-10-23 14:49:12,627:INFO:Bagging Regressor Imported successfully
2023-10-23 14:49:12,627:INFO:Cross validation set to False
2023-10-23 14:49:12,627:INFO:Fitting Model
2023-10-23 14:49:12,725:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006446 seconds.
2023-10-23 14:49:12,725:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:12,725:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:49:12,725:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:49:12,729:INFO:[LightGBM] [Info] Start training from score 77.360615
2023-10-23 14:49:13,083:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006861 seconds.
2023-10-23 14:49:13,083:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:13,098:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:49:13,098:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:49:13,100:INFO:[LightGBM] [Info] Start training from score 78.162759
2023-10-23 14:49:13,369:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005830 seconds.
2023-10-23 14:49:13,369:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:13,370:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:49:13,370:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:49:13,371:INFO:[LightGBM] [Info] Start training from score 77.185434
2023-10-23 14:49:13,737:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006602 seconds.
2023-10-23 14:49:13,737:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:13,748:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:49:13,749:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:49:13,750:INFO:[LightGBM] [Info] Start training from score 78.293126
2023-10-23 14:49:14,101:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005662 seconds.
2023-10-23 14:49:14,101:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:14,101:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:49:14,101:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:49:14,101:INFO:[LightGBM] [Info] Start training from score 75.493649
2023-10-23 14:49:14,399:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006417 seconds.
2023-10-23 14:49:14,399:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:14,399:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:49:14,399:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:49:14,399:INFO:[LightGBM] [Info] Start training from score 77.467219
2023-10-23 14:49:14,765:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006263 seconds.
2023-10-23 14:49:14,765:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:14,765:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:49:14,765:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:49:14,765:INFO:[LightGBM] [Info] Start training from score 77.083598
2023-10-23 14:49:15,103:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005896 seconds.
2023-10-23 14:49:15,103:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:15,104:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:49:15,104:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:49:15,104:INFO:[LightGBM] [Info] Start training from score 79.854607
2023-10-23 14:49:15,383:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005470 seconds.
2023-10-23 14:49:15,383:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:15,383:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:49:15,383:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:49:15,383:INFO:[LightGBM] [Info] Start training from score 76.153078
2023-10-23 14:49:15,653:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005816 seconds.
2023-10-23 14:49:15,653:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 14:49:15,653:INFO:[LightGBM] [Info] Total Bins 6749
2023-10-23 14:49:15,653:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 46
2023-10-23 14:49:15,653:INFO:[LightGBM] [Info] Start training from score 78.843978
2023-10-23 14:49:15,884:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:49:15,884:INFO:create_model() successfully completed......................................
2023-10-23 14:49:16,015:INFO:Creating Dashboard logs
2023-10-23 14:49:16,015:INFO:Model: Bagging Regressor
2023-10-23 14:49:16,084:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.1, 'estimator__max_depth': -1, 'estimator__min_child_samples': 20, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': -1, 'estimator__num_leaves': 31, 'estimator__objective': None, 'estimator__random_state': 123, 'estimator__reg_alpha': 0.0, 'estimator__reg_lambda': 0.0, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator': LGBMRegressor(n_jobs=-1, random_state=123), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-23 14:49:16,451:INFO:_master_model_container: 4
2023-10-23 14:49:16,451:INFO:_display_container: 4
2023-10-23 14:49:16,451:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:49:16,451:INFO:finalize_model() successfully completed......................................
2023-10-23 14:49:16,577:INFO:Initializing save_model()
2023-10-23 14:49:16,577:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), model_name=final_model_for_location_C, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'pressure_100m:hPa',
                                             'pressure_50m:hPa', 'prob_rime:p',
                                             'rain_water:kgm2',
                                             'relative_humidity_1000hPa:p',
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 14:49:16,577:INFO:Adding model into prep_pipe
2023-10-23 14:49:16,577:WARNING:Only Model saved as it was a pipeline.
2023-10-23 14:49:16,632:INFO:final_model_for_location_C.pkl saved in current working directory
2023-10-23 14:49:16,648:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-23 14:49:16,648:INFO:save_model() successfully completed......................................
2023-10-23 14:49:17,818:INFO:Initializing load_model()
2023-10-23 14:49:17,818:INFO:load_model(model_name=final_model_for_location_A, platform=None, authentication=None, verbose=True)
2023-10-23 14:49:17,858:INFO:Initializing load_model()
2023-10-23 14:49:17,858:INFO:load_model(model_name=final_model_for_location_B, platform=None, authentication=None, verbose=True)
2023-10-23 14:49:17,900:INFO:Initializing load_model()
2023-10-23 14:49:17,900:INFO:load_model(model_name=final_model_for_location_C, platform=None, authentication=None, verbose=True)
2023-10-23 14:49:17,959:INFO:Initializing predict_model()
2023-10-23 14:49:17,959:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E095E7AF70>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096C5B160>)
2023-10-23 14:49:17,959:INFO:Checking exceptions
2023-10-23 14:49:17,960:INFO:Preloading libraries
2023-10-23 14:49:17,960:INFO:Set up data.
2023-10-23 14:49:17,993:INFO:Set up index.
2023-10-23 14:49:18,207:INFO:Initializing predict_model()
2023-10-23 14:49:18,207:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E095E7AF70>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096C5B160>)
2023-10-23 14:49:18,207:INFO:Checking exceptions
2023-10-23 14:49:18,207:INFO:Preloading libraries
2023-10-23 14:49:18,207:INFO:Set up data.
2023-10-23 14:49:18,207:INFO:Set up index.
2023-10-23 14:49:18,394:INFO:Initializing predict_model()
2023-10-23 14:49:18,394:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E095E7AF70>, estimator=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J...
                                             'sfc_pressure:hPa',
                                             'snow_depth:cm', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096C5B160>)
2023-10-23 14:49:18,394:INFO:Checking exceptions
2023-10-23 14:49:18,394:INFO:Preloading libraries
2023-10-23 14:49:18,394:INFO:Set up data.
2023-10-23 14:49:18,409:INFO:Set up index.
2023-10-23 15:34:25,905:INFO:PyCaret RegressionExperiment
2023-10-23 15:34:25,905:INFO:Logging name: exp_A
2023-10-23 15:34:25,906:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 15:34:25,906:INFO:version 3.1.0
2023-10-23 15:34:25,907:INFO:Initializing setup()
2023-10-23 15:34:25,907:INFO:self.USI: 5315
2023-10-23 15:34:25,908:INFO:self._variable_keys: {'gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', '_ml_usecase', 'gpu_param', 'exp_name_log', 'html_param', 'fold_generator', 'y', 'seed', 'y_train', 'transform_target_param', 'n_jobs_param', 'target_param', 'idx', '_available_plots', 'log_plots_param', 'memory', 'data', 'USI', 'X', 'logging_param', 'pipeline', 'exp_id', 'X_train', 'X_test', 'fold_groups_param'}
2023-10-23 15:34:25,908:INFO:Checking environment
2023-10-23 15:34:25,909:INFO:python_version: 3.8.18
2023-10-23 15:34:25,909:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-23 15:34:25,910:INFO:machine: AMD64
2023-10-23 15:34:25,910:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-23 15:34:25,910:INFO:Memory: svmem(total=16505954304, available=4813242368, percent=70.8, used=11692711936, free=4813242368)
2023-10-23 15:34:25,911:INFO:Physical Core: 8
2023-10-23 15:34:25,911:INFO:Logical Core: 16
2023-10-23 15:34:25,912:INFO:Checking libraries
2023-10-23 15:34:25,912:INFO:System:
2023-10-23 15:34:25,912:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-23 15:34:25,912:INFO:executable: c:\Users\thoma\anaconda3\envs\py38\python.exe
2023-10-23 15:34:25,912:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-23 15:34:25,913:INFO:PyCaret required dependencies:
2023-10-23 15:34:25,913:INFO:                 pip: 23.3
2023-10-23 15:34:25,913:INFO:          setuptools: 68.0.0
2023-10-23 15:34:25,914:INFO:             pycaret: 3.1.0
2023-10-23 15:34:25,914:INFO:             IPython: 8.12.0
2023-10-23 15:34:25,914:INFO:          ipywidgets: 8.1.1
2023-10-23 15:34:25,915:INFO:                tqdm: 4.66.1
2023-10-23 15:34:25,915:INFO:               numpy: 1.23.5
2023-10-23 15:34:25,915:INFO:              pandas: 1.5.3
2023-10-23 15:34:25,916:INFO:              jinja2: 3.1.2
2023-10-23 15:34:25,916:INFO:               scipy: 1.10.1
2023-10-23 15:34:25,917:INFO:              joblib: 1.3.2
2023-10-23 15:34:25,917:INFO:             sklearn: 1.2.2
2023-10-23 15:34:25,917:INFO:                pyod: 1.1.0
2023-10-23 15:34:25,918:INFO:            imblearn: 0.11.0
2023-10-23 15:34:25,918:INFO:   category_encoders: 2.6.2
2023-10-23 15:34:25,918:INFO:            lightgbm: 4.1.0
2023-10-23 15:34:25,918:INFO:               numba: 0.58.1
2023-10-23 15:34:25,919:INFO:            requests: 2.31.0
2023-10-23 15:34:25,919:INFO:          matplotlib: 3.7.3
2023-10-23 15:34:25,919:INFO:          scikitplot: 0.3.7
2023-10-23 15:34:25,919:INFO:         yellowbrick: 1.5
2023-10-23 15:34:25,919:INFO:              plotly: 5.17.0
2023-10-23 15:34:25,920:INFO:    plotly-resampler: Not installed
2023-10-23 15:34:25,920:INFO:             kaleido: 0.2.1
2023-10-23 15:34:25,920:INFO:           schemdraw: 0.15
2023-10-23 15:34:25,920:INFO:         statsmodels: 0.14.0
2023-10-23 15:34:25,921:INFO:              sktime: 0.21.1
2023-10-23 15:34:25,921:INFO:               tbats: 1.1.3
2023-10-23 15:34:25,921:INFO:            pmdarima: 2.0.3
2023-10-23 15:34:25,921:INFO:              psutil: 5.9.0
2023-10-23 15:34:25,922:INFO:          markupsafe: 2.1.3
2023-10-23 15:34:25,922:INFO:             pickle5: Not installed
2023-10-23 15:34:25,922:INFO:         cloudpickle: 2.2.1
2023-10-23 15:34:25,922:INFO:         deprecation: 2.1.0
2023-10-23 15:34:25,922:INFO:              xxhash: 3.4.1
2023-10-23 15:34:25,922:INFO:           wurlitzer: Not installed
2023-10-23 15:34:25,923:INFO:PyCaret optional dependencies:
2023-10-23 15:34:25,923:INFO:                shap: Not installed
2023-10-23 15:34:25,923:INFO:           interpret: Not installed
2023-10-23 15:34:25,923:INFO:                umap: Not installed
2023-10-23 15:34:25,923:INFO:     ydata_profiling: Not installed
2023-10-23 15:34:25,923:INFO:  explainerdashboard: Not installed
2023-10-23 15:34:25,923:INFO:             autoviz: Not installed
2023-10-23 15:34:25,924:INFO:           fairlearn: Not installed
2023-10-23 15:34:25,924:INFO:          deepchecks: Not installed
2023-10-23 15:34:25,924:INFO:             xgboost: Not installed
2023-10-23 15:34:25,924:INFO:            catboost: 1.2.2
2023-10-23 15:34:25,924:INFO:              kmodes: Not installed
2023-10-23 15:34:25,924:INFO:             mlxtend: Not installed
2023-10-23 15:34:25,924:INFO:       statsforecast: Not installed
2023-10-23 15:34:25,924:INFO:        tune_sklearn: Not installed
2023-10-23 15:34:25,924:INFO:                 ray: Not installed
2023-10-23 15:34:25,924:INFO:            hyperopt: Not installed
2023-10-23 15:34:25,924:INFO:              optuna: Not installed
2023-10-23 15:34:25,924:INFO:               skopt: Not installed
2023-10-23 15:34:25,925:INFO:              mlflow: 2.7.1
2023-10-23 15:34:25,925:INFO:              gradio: Not installed
2023-10-23 15:34:25,925:INFO:             fastapi: Not installed
2023-10-23 15:34:25,925:INFO:             uvicorn: Not installed
2023-10-23 15:34:25,925:INFO:              m2cgen: Not installed
2023-10-23 15:34:25,925:INFO:           evidently: Not installed
2023-10-23 15:34:25,925:INFO:               fugue: Not installed
2023-10-23 15:34:25,925:INFO:           streamlit: Not installed
2023-10-23 15:34:25,925:INFO:             prophet: Not installed
2023-10-23 15:34:25,925:INFO:None
2023-10-23 15:34:25,925:INFO:Set up data.
2023-10-23 15:34:25,966:INFO:Set up folding strategy.
2023-10-23 15:34:25,966:INFO:Set up train/test split.
2023-10-23 15:34:26,010:INFO:Set up index.
2023-10-23 15:34:26,012:INFO:Assigning column types.
2023-10-23 15:34:26,044:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 15:34:26,045:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,050:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,055:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,140:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,175:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,175:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 15:34:26,175:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 15:34:26,175:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,192:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,198:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,282:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,322:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,322:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 15:34:26,322:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 15:34:26,322:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 15:34:26,338:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,338:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,425:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,457:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,457:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 15:34:26,457:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 15:34:26,474:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,483:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,564:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,611:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,611:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 15:34:26,612:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 15:34:26,612:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 15:34:26,620:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,699:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,746:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,747:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 15:34:26,748:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 15:34:26,758:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,835:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,878:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 15:34:26,878:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 15:34:26,878:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 15:34:26,878:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 15:34:26,979:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 15:34:27,029:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 15:34:27,030:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 15:34:27,030:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 15:34:27,112:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 15:34:27,160:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 15:34:27,160:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 15:34:27,160:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 15:34:27,160:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 15:34:27,246:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 15:34:27,297:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 15:34:27,297:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 15:34:27,378:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 15:34:27,427:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 15:34:27,427:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 15:34:27,427:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 15:34:27,572:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 15:34:27,573:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 15:34:27,709:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 15:34:27,709:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 15:34:27,709:INFO:Preparing preprocessing pipeline...
2023-10-23 15:34:27,709:INFO:Set up date feature engineering.
2023-10-23 15:34:27,709:INFO:Set up simple imputation.
2023-10-23 15:34:27,727:INFO:Set up encoding of ordinal features.
2023-10-23 15:34:27,760:INFO:Set up encoding of categorical features.
2023-10-23 15:34:27,760:INFO:Set up polynomial features.
2023-10-23 15:34:27,760:INFO:Set up removing outliers.
2023-10-23 15:34:27,763:INFO:Set up column name cleaning.
2023-10-23 15:34:29,924:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:34:58,498:INFO:Finished creating preprocessing pipeline.
2023-10-23 15:34:58,597:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_ene...
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 15:34:58,597:INFO:Creating final display dataframe.
2023-10-23 15:34:59,551:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:35:31,806:INFO:Setup _display_container:                     Description          Value
0                    Session id            123
1                        Target         target
2                   Target type     Regression
3           Original data shape    (34061, 52)
4        Transformed data shape  (32868, 1540)
5   Transformed train set shape  (22649, 1540)
6    Transformed test set shape  (10219, 1540)
7              Ordinal features              4
8              Numeric features             44
9                 Date features              3
10         Categorical features              4
11     Rows with missing values          90.5%
12                   Preprocess           True
13              Imputation type         simple
14           Numeric imputation           mean
15       Categorical imputation           mode
16     Maximum one-hot encoding             25
17              Encoding method           None
18          Polynomial features           True
19            Polynomial degree              2
20              Remove outliers           True
21           Outliers threshold           0.05
22               Fold Generator          KFold
23                  Fold Number             10
24                     CPU Jobs             -1
25                      Use GPU          False
26               Log Experiment   MlflowLogger
27              Experiment Name          exp_A
28                          USI           5315
2023-10-23 15:35:31,941:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 15:35:31,941:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 15:35:32,091:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 15:35:32,091:INFO:Soft dependency imported: catboost: 1.2.2
2023-10-23 15:35:32,091:INFO:Logging experiment in loggers
2023-10-23 15:35:32,220:INFO:SubProcess save_model() called ==================================
2023-10-23 15:35:32,455:INFO:Initializing save_model()
2023-10-23 15:35:32,455:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_ene...
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\thoma\AppData\Local\Temp\tmptj34vz9k\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_ene...
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-23 15:35:32,456:INFO:Adding model into prep_pipe
2023-10-23 15:35:32,456:WARNING:Only Model saved as it was a pipeline.
2023-10-23 15:35:32,539:INFO:C:\Users\thoma\AppData\Local\Temp\tmptj34vz9k\Transformation Pipeline.pkl saved in current working directory
2023-10-23 15:35:32,686:INFO:Pipeline(memory=FastMemory(location=C:\Users\thoma\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_ene...
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 15:35:32,686:INFO:save_model() successfully completed......................................
2023-10-23 15:35:32,819:INFO:SubProcess save_model() end ==================================
2023-10-23 15:35:32,908:INFO:setup() successfully completed in 66.19s...............
2023-10-23 15:35:32,908:INFO:Initializing create_model()
2023-10-23 15:35:32,908:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E99F10>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-23 15:35:32,908:INFO:Checking exceptions
2023-10-23 15:35:32,908:INFO:Importing libraries
2023-10-23 15:35:32,908:INFO:Copying training dataset
2023-10-23 15:35:32,937:INFO:Defining folds
2023-10-23 15:35:32,937:INFO:Declaring metric variables
2023-10-23 15:35:32,937:INFO:Importing untrained model
2023-10-23 15:35:32,937:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 15:35:32,938:INFO:Starting cross validation
2023-10-23 15:35:32,955:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 15:35:47,304:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:35:49,487:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:35:52,996:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:35:53,109:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:35:53,351:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:35:53,375:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:35:53,405:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:35:53,561:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:35:54,541:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:35:54,961:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:38:06,176:INFO:Calculating mean and std
2023-10-23 15:38:06,179:INFO:Creating metrics dataframe
2023-10-23 15:38:06,185:INFO:Finalizing model
2023-10-23 15:38:08,048:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:38:38,454:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-10-23 15:38:38,704:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.223384 seconds.
2023-10-23 15:38:38,704:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-23 15:38:38,713:INFO:[LightGBM] [Info] Total Bins 232794
2023-10-23 15:38:38,726:INFO:[LightGBM] [Info] Number of data points in the train set: 22649, number of used features: 1345
2023-10-23 15:38:38,733:INFO:[LightGBM] [Info] Start training from score 606.666216
2023-10-23 15:38:43,078:INFO:Creating Dashboard logs
2023-10-23 15:38:43,079:INFO:Model: Light Gradient Boosting Machine
2023-10-23 15:38:43,172:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-23 15:38:43,362:INFO:Initializing predict_model()
2023-10-23 15:38:43,362:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E99F10>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E096917790>)
2023-10-23 15:38:43,362:INFO:Checking exceptions
2023-10-23 15:38:43,362:INFO:Preloading libraries
2023-10-23 15:38:44,406:INFO:Uploading results into container
2023-10-23 15:38:44,407:INFO:Uploading model into container now
2023-10-23 15:38:44,411:INFO:_master_model_container: 1
2023-10-23 15:38:44,411:INFO:_display_container: 2
2023-10-23 15:38:44,411:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-23 15:38:44,411:INFO:create_model() successfully completed......................................
2023-10-23 15:38:44,519:INFO:Initializing tune_model()
2023-10-23 15:38:44,519:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E096E99F10>)
2023-10-23 15:38:44,519:INFO:Checking exceptions
2023-10-23 15:38:44,531:INFO:Copying training dataset
2023-10-23 15:38:44,547:INFO:Checking base model
2023-10-23 15:38:44,547:INFO:Base model : Light Gradient Boosting Machine
2023-10-23 15:38:44,548:INFO:Declaring metric variables
2023-10-23 15:38:44,548:INFO:Defining Hyperparameters
2023-10-23 15:38:44,680:INFO:Tuning with n_jobs=-1
2023-10-23 15:38:44,680:INFO:Initializing RandomizedSearchCV
2023-10-23 15:38:50,024:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:38:50,235:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:38:50,241:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:38:50,322:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:38:50,380:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:38:51,140:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:38:52,430:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:38:53,602:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:38:56,451:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:38:57,759:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:39:11,085:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:39:15,396:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:39:18,112:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:39:18,362:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:39:18,338:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:39:22,480:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:42:36,169:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:42:36,986:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:42:37,024:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:42:41,282:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:42:42,248:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:42:49,428:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:45:04,986:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:45:07,811:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:45:08,544:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:45:09,201:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:47:04,166:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:47:09,347:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:47:13,807:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:47:19,719:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:47:23,268:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:47:28,714:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:47:39,264:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:47:39,629:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:47:40,942:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:47:44,029:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:50:08,362:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:50:15,309:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:50:23,751:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:50:31,598:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:50:34,042:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:50:39,920:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:51:58,020:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:52:19,390:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:52:48,417:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:52:54,807:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:52:57,721:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:54:05,758:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:54:07,956:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:54:11,427:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:54:21,147:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:54:34,032:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:55:15,782:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:55:27,499:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:55:32,744:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:55:36,344:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:56:04,775:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:56:13,978:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:56:42,689:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-23 15:56:53,540:WARNING:c:\Users\thoma\anaconda3\envs\py38\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-24 11:09:49,239:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-24 11:09:49,239:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-24 11:09:49,239:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-24 11:09:49,239:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-24 11:30:05,852:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-24 11:30:05,853:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-24 11:30:05,853:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-24 11:30:05,853:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-24 11:30:13,529:INFO:PyCaret RegressionExperiment
2023-10-24 11:30:13,530:INFO:Logging name: exp_A
2023-10-24 11:30:13,530:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 11:30:13,530:INFO:version 3.1.0
2023-10-24 11:30:13,530:INFO:Initializing setup()
2023-10-24 11:30:13,530:INFO:self.USI: 43ac
2023-10-24 11:30:13,530:INFO:self._variable_keys: {'exp_id', 'target_param', 'USI', 'data', 'fold_shuffle_param', 'log_plots_param', 'X_test', 'memory', 'idx', 'y', 'X', 'X_train', 'gpu_n_jobs_param', 'n_jobs_param', 'gpu_param', 'logging_param', 'fold_generator', 'pipeline', 'y_test', 'y_train', '_ml_usecase', '_available_plots', 'html_param', 'exp_name_log', 'transform_target_param', 'seed', 'fold_groups_param'}
2023-10-24 11:30:13,530:INFO:Checking environment
2023-10-24 11:30:13,530:INFO:python_version: 3.8.5
2023-10-24 11:30:13,530:INFO:python_build: ('default', 'Sep  4 2020 02:22:02')
2023-10-24 11:30:13,530:INFO:machine: x86_64
2023-10-24 11:30:13,548:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-10-24 11:30:13,548:INFO:Memory: svmem(total=8589934592, available=2136297472, percent=75.1, used=4721729536, free=15331328, active=2122928128, inactive=2085421056, wired=2598801408)
2023-10-24 11:30:13,548:INFO:Physical Core: 4
2023-10-24 11:30:13,548:INFO:Logical Core: 8
2023-10-24 11:30:13,548:INFO:Checking libraries
2023-10-24 11:30:13,548:INFO:System:
2023-10-24 11:30:13,548:INFO:    python: 3.8.5 (default, Sep  4 2020, 02:22:02)  [Clang 10.0.0 ]
2023-10-24 11:30:13,548:INFO:executable: /Users/kaja/opt/anaconda3/bin/python
2023-10-24 11:30:13,549:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-10-24 11:30:13,549:INFO:PyCaret required dependencies:
2023-10-24 11:30:13,817:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:30:13,817:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:30:13,817:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:32:01,620:INFO:PyCaret RegressionExperiment
2023-10-24 11:32:01,620:INFO:Logging name: exp_A
2023-10-24 11:32:01,621:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 11:32:01,621:INFO:version 3.1.0
2023-10-24 11:32:01,621:INFO:Initializing setup()
2023-10-24 11:32:01,621:INFO:self.USI: b125
2023-10-24 11:32:01,621:INFO:self._variable_keys: {'exp_id', 'target_param', 'USI', 'data', 'fold_shuffle_param', 'log_plots_param', 'X_test', 'memory', 'idx', 'y', 'X', 'X_train', 'gpu_n_jobs_param', 'n_jobs_param', 'gpu_param', 'logging_param', 'fold_generator', 'pipeline', 'y_test', 'y_train', '_ml_usecase', '_available_plots', 'html_param', 'exp_name_log', 'transform_target_param', 'seed', 'fold_groups_param'}
2023-10-24 11:32:01,621:INFO:Checking environment
2023-10-24 11:32:01,621:INFO:python_version: 3.8.5
2023-10-24 11:32:01,621:INFO:python_build: ('default', 'Sep  4 2020 02:22:02')
2023-10-24 11:32:01,621:INFO:machine: x86_64
2023-10-24 11:32:01,621:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-10-24 11:32:01,621:INFO:Memory: svmem(total=8589934592, available=1924874240, percent=77.6, used=4613914624, free=24580096, active=1898582016, inactive=1897598976, wired=2715332608)
2023-10-24 11:32:01,621:INFO:Physical Core: 4
2023-10-24 11:32:01,621:INFO:Logical Core: 8
2023-10-24 11:32:01,621:INFO:Checking libraries
2023-10-24 11:32:01,621:INFO:System:
2023-10-24 11:32:01,621:INFO:    python: 3.8.5 (default, Sep  4 2020, 02:22:02)  [Clang 10.0.0 ]
2023-10-24 11:32:01,621:INFO:executable: /Users/kaja/opt/anaconda3/bin/python
2023-10-24 11:32:01,621:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-10-24 11:32:01,622:INFO:PyCaret required dependencies:
2023-10-24 11:32:01,886:INFO:                 pip: 23.3.1
2023-10-24 11:32:01,886:INFO:          setuptools: 68.2.2
2023-10-24 11:32:01,886:INFO:             pycaret: 3.1.0
2023-10-24 11:32:01,886:INFO:             IPython: 7.19.0
2023-10-24 11:32:01,886:INFO:          ipywidgets: 8.1.1
2023-10-24 11:32:01,886:INFO:                tqdm: 4.66.1
2023-10-24 11:32:01,886:INFO:               numpy: 1.23.5
2023-10-24 11:32:01,887:INFO:              pandas: 1.5.3
2023-10-24 11:32:01,887:INFO:              jinja2: 3.1.2
2023-10-24 11:32:01,887:INFO:               scipy: 1.10.1
2023-10-24 11:32:01,887:INFO:              joblib: 1.3.2
2023-10-24 11:32:01,887:INFO:             sklearn: 1.2.2
2023-10-24 11:32:01,887:INFO:                pyod: 1.1.0
2023-10-24 11:32:01,887:INFO:            imblearn: 0.11.0
2023-10-24 11:32:01,887:INFO:   category_encoders: 2.6.2
2023-10-24 11:32:01,887:INFO:            lightgbm: 4.1.0
2023-10-24 11:32:01,887:INFO:               numba: 0.58.1
2023-10-24 11:32:01,887:INFO:            requests: 2.28.2
2023-10-24 11:32:01,887:INFO:          matplotlib: 3.7.3
2023-10-24 11:32:01,887:INFO:          scikitplot: 0.3.7
2023-10-24 11:32:01,887:INFO:         yellowbrick: 1.5
2023-10-24 11:32:01,887:INFO:              plotly: 5.17.0
2023-10-24 11:32:01,887:INFO:    plotly-resampler: Not installed
2023-10-24 11:32:01,887:INFO:             kaleido: 0.2.1
2023-10-24 11:32:01,888:INFO:           schemdraw: 0.15
2023-10-24 11:32:01,888:INFO:         statsmodels: 0.14.0
2023-10-24 11:32:01,888:INFO:              sktime: 0.21.1
2023-10-24 11:32:01,888:INFO:               tbats: 1.1.3
2023-10-24 11:32:01,888:INFO:            pmdarima: 2.0.4
2023-10-24 11:32:01,888:INFO:              psutil: 5.9.6
2023-10-24 11:32:01,888:INFO:          markupsafe: 2.1.2
2023-10-24 11:32:01,888:INFO:             pickle5: Not installed
2023-10-24 11:32:01,888:INFO:         cloudpickle: 1.6.0
2023-10-24 11:32:01,888:INFO:         deprecation: 2.1.0
2023-10-24 11:32:01,888:INFO:              xxhash: 3.4.1
2023-10-24 11:32:01,888:INFO:           wurlitzer: 2.0.1
2023-10-24 11:32:01,888:INFO:PyCaret optional dependencies:
2023-10-24 11:32:01,907:INFO:                shap: Not installed
2023-10-24 11:32:01,907:INFO:           interpret: Not installed
2023-10-24 11:32:01,907:INFO:                umap: Not installed
2023-10-24 11:32:01,907:INFO:     ydata_profiling: Not installed
2023-10-24 11:32:01,907:INFO:  explainerdashboard: Not installed
2023-10-24 11:32:01,908:INFO:             autoviz: Not installed
2023-10-24 11:32:01,908:INFO:           fairlearn: Not installed
2023-10-24 11:32:01,908:INFO:          deepchecks: Not installed
2023-10-24 11:32:01,908:INFO:             xgboost: Not installed
2023-10-24 11:32:01,908:INFO:            catboost: 1.0.4
2023-10-24 11:32:01,908:INFO:              kmodes: Not installed
2023-10-24 11:32:01,908:INFO:             mlxtend: Not installed
2023-10-24 11:32:01,908:INFO:       statsforecast: Not installed
2023-10-24 11:32:01,908:INFO:        tune_sklearn: Not installed
2023-10-24 11:32:01,908:INFO:                 ray: Not installed
2023-10-24 11:32:01,908:INFO:            hyperopt: Not installed
2023-10-24 11:32:01,908:INFO:              optuna: Not installed
2023-10-24 11:32:01,908:INFO:               skopt: Not installed
2023-10-24 11:32:01,908:INFO:              mlflow: 2.7.1
2023-10-24 11:32:01,908:INFO:              gradio: Not installed
2023-10-24 11:32:01,908:INFO:             fastapi: Not installed
2023-10-24 11:32:01,908:INFO:             uvicorn: Not installed
2023-10-24 11:32:01,908:INFO:              m2cgen: Not installed
2023-10-24 11:32:01,908:INFO:           evidently: Not installed
2023-10-24 11:32:01,908:INFO:               fugue: Not installed
2023-10-24 11:32:01,908:INFO:           streamlit: Not installed
2023-10-24 11:32:01,908:INFO:             prophet: Not installed
2023-10-24 11:32:01,908:INFO:None
2023-10-24 11:32:01,908:INFO:Set up data.
2023-10-24 11:32:01,957:INFO:Set up folding strategy.
2023-10-24 11:32:01,957:INFO:Set up train/test split.
2023-10-24 11:32:01,996:INFO:Set up index.
2023-10-24 11:32:01,998:INFO:Assigning column types.
2023-10-24 11:32:02,015:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 11:32:02,015:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 11:32:02,021:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:32:02,025:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:32:02,097:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:32:02,145:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:32:02,146:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:32:02,146:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:32:02,147:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 11:32:02,154:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:32:02,160:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:32:02,251:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:32:02,321:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:32:02,321:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:32:02,322:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:32:02,323:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 11:32:02,330:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:32:02,337:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:32:02,416:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:32:02,458:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:32:02,458:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:32:02,458:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:32:02,463:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:32:02,467:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:32:02,530:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:32:02,575:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:32:02,575:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:32:02,576:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:32:02,576:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 11:32:02,584:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:32:02,666:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:32:02,721:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:32:02,722:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:32:02,722:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:32:02,731:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:32:02,796:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:32:02,850:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:32:02,851:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:32:02,851:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:32:02,852:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 11:32:02,934:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:32:02,978:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:32:02,979:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:32:02,979:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:32:03,054:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:32:03,094:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:32:03,094:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:32:03,095:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:32:03,095:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 11:32:03,165:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:32:03,205:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:32:03,205:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:32:03,280:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:32:03,321:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:32:03,322:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:32:03,328:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 11:32:03,467:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:32:03,468:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:32:03,584:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:32:03,584:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:32:03,587:INFO:Preparing preprocessing pipeline...
2023-10-24 11:32:03,587:INFO:Set up date feature engineering.
2023-10-24 11:32:03,587:INFO:Set up simple imputation.
2023-10-24 11:32:03,602:INFO:Set up encoding of ordinal features.
2023-10-24 11:32:03,631:INFO:Set up encoding of categorical features.
2023-10-24 11:32:03,632:INFO:Set up polynomial features.
2023-10-24 11:32:03,632:INFO:Set up removing outliers.
2023-10-24 11:32:03,635:INFO:Set up column name cleaning.
2023-10-24 11:32:06,498:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-24 11:32:34,955:INFO:Finished creating preprocessing pipeline.
2023-10-24 11:32:35,049:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m'...
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 11:32:35,049:INFO:Creating final display dataframe.
2023-10-24 11:32:36,173:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-10-24 11:33:06,976:INFO:Setup _display_container:                     Description          Value
0                    Session id            123
1                        Target         target
2                   Target type     Regression
3           Original data shape    (34061, 52)
4        Transformed data shape  (32868, 1540)
5   Transformed train set shape  (22649, 1540)
6    Transformed test set shape  (10219, 1540)
7              Ordinal features              4
8              Numeric features             44
9                 Date features              3
10         Categorical features              4
11     Rows with missing values          90.5%
12                   Preprocess           True
13              Imputation type         simple
14           Numeric imputation           mean
15       Categorical imputation           mode
16     Maximum one-hot encoding             25
17              Encoding method           None
18          Polynomial features           True
19            Polynomial degree              2
20              Remove outliers           True
21           Outliers threshold           0.05
22               Fold Generator          KFold
23                  Fold Number             10
24                     CPU Jobs             -1
25                      Use GPU          False
26               Log Experiment   MlflowLogger
27              Experiment Name          exp_A
28                          USI           b125
2023-10-24 11:33:07,114:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:33:07,114:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:33:07,228:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:33:07,229:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:33:07,230:INFO:Logging experiment in loggers
2023-10-24 11:33:07,413:INFO:SubProcess save_model() called ==================================
2023-10-24 11:33:07,654:INFO:Initializing save_model()
2023-10-24 11:33:07,654:INFO:save_model(model=Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m'...
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/tmp_7yqugiw/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m'...
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-24 11:33:07,654:INFO:Adding model into prep_pipe
2023-10-24 11:33:07,654:WARNING:Only Model saved as it was a pipeline.
2023-10-24 11:33:07,733:INFO:/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/tmp_7yqugiw/Transformation Pipeline.pkl saved in current working directory
2023-10-24 11:33:07,833:INFO:Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m'...
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 11:33:07,833:INFO:save_model() successfully completed......................................
2023-10-24 11:33:08,099:INFO:SubProcess save_model() end ==================================
2023-10-24 11:39:30,478:INFO:PyCaret RegressionExperiment
2023-10-24 11:39:30,479:INFO:Logging name: exp_A
2023-10-24 11:39:30,479:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 11:39:30,479:INFO:version 3.1.0
2023-10-24 11:39:30,479:INFO:Initializing setup()
2023-10-24 11:39:30,479:INFO:self.USI: 9620
2023-10-24 11:39:30,479:INFO:self._variable_keys: {'exp_id', 'target_param', 'USI', 'data', 'fold_shuffle_param', 'log_plots_param', 'X_test', 'memory', 'idx', 'y', 'X', 'X_train', 'gpu_n_jobs_param', 'n_jobs_param', 'gpu_param', 'logging_param', 'fold_generator', 'pipeline', 'y_test', 'y_train', '_ml_usecase', '_available_plots', 'html_param', 'exp_name_log', 'transform_target_param', 'seed', 'fold_groups_param'}
2023-10-24 11:39:30,479:INFO:Checking environment
2023-10-24 11:39:30,479:INFO:python_version: 3.8.5
2023-10-24 11:39:30,479:INFO:python_build: ('default', 'Sep  4 2020 02:22:02')
2023-10-24 11:39:30,479:INFO:machine: x86_64
2023-10-24 11:39:30,479:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-10-24 11:39:30,480:INFO:Memory: svmem(total=8589934592, available=2181505024, percent=74.6, used=4884963328, free=64221184, active=2120638464, inactive=2093400064, wired=2764324864)
2023-10-24 11:39:30,480:INFO:Physical Core: 4
2023-10-24 11:39:30,480:INFO:Logical Core: 8
2023-10-24 11:39:30,480:INFO:Checking libraries
2023-10-24 11:39:30,480:INFO:System:
2023-10-24 11:39:30,480:INFO:    python: 3.8.5 (default, Sep  4 2020, 02:22:02)  [Clang 10.0.0 ]
2023-10-24 11:39:30,480:INFO:executable: /Users/kaja/opt/anaconda3/bin/python
2023-10-24 11:39:30,480:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-10-24 11:39:30,480:INFO:PyCaret required dependencies:
2023-10-24 11:39:30,480:INFO:                 pip: 23.3.1
2023-10-24 11:39:30,480:INFO:          setuptools: 68.2.2
2023-10-24 11:39:30,480:INFO:             pycaret: 3.1.0
2023-10-24 11:39:30,480:INFO:             IPython: 7.19.0
2023-10-24 11:39:30,480:INFO:          ipywidgets: 8.1.1
2023-10-24 11:39:30,480:INFO:                tqdm: 4.66.1
2023-10-24 11:39:30,480:INFO:               numpy: 1.23.5
2023-10-24 11:39:30,480:INFO:              pandas: 1.5.3
2023-10-24 11:39:30,481:INFO:              jinja2: 3.1.2
2023-10-24 11:39:30,481:INFO:               scipy: 1.10.1
2023-10-24 11:39:30,481:INFO:              joblib: 1.3.2
2023-10-24 11:39:30,481:INFO:             sklearn: 1.2.2
2023-10-24 11:39:30,481:INFO:                pyod: 1.1.0
2023-10-24 11:39:30,481:INFO:            imblearn: 0.11.0
2023-10-24 11:39:30,481:INFO:   category_encoders: 2.6.2
2023-10-24 11:39:30,481:INFO:            lightgbm: 4.1.0
2023-10-24 11:39:30,481:INFO:               numba: 0.58.1
2023-10-24 11:39:30,481:INFO:            requests: 2.28.2
2023-10-24 11:39:30,481:INFO:          matplotlib: 3.7.3
2023-10-24 11:39:30,481:INFO:          scikitplot: 0.3.7
2023-10-24 11:39:30,481:INFO:         yellowbrick: 1.5
2023-10-24 11:39:30,481:INFO:              plotly: 5.17.0
2023-10-24 11:39:30,481:INFO:    plotly-resampler: Not installed
2023-10-24 11:39:30,481:INFO:             kaleido: 0.2.1
2023-10-24 11:39:30,481:INFO:           schemdraw: 0.15
2023-10-24 11:39:30,481:INFO:         statsmodels: 0.14.0
2023-10-24 11:39:30,481:INFO:              sktime: 0.21.1
2023-10-24 11:39:30,481:INFO:               tbats: 1.1.3
2023-10-24 11:39:30,481:INFO:            pmdarima: 2.0.4
2023-10-24 11:39:30,481:INFO:              psutil: 5.9.6
2023-10-24 11:39:30,481:INFO:          markupsafe: 2.1.2
2023-10-24 11:39:30,481:INFO:             pickle5: Not installed
2023-10-24 11:39:30,482:INFO:         cloudpickle: 1.6.0
2023-10-24 11:39:30,482:INFO:         deprecation: 2.1.0
2023-10-24 11:39:30,482:INFO:              xxhash: 3.4.1
2023-10-24 11:39:30,482:INFO:           wurlitzer: 2.0.1
2023-10-24 11:39:30,482:INFO:PyCaret optional dependencies:
2023-10-24 11:39:30,482:INFO:                shap: Not installed
2023-10-24 11:39:30,482:INFO:           interpret: Not installed
2023-10-24 11:39:30,482:INFO:                umap: Not installed
2023-10-24 11:39:30,482:INFO:     ydata_profiling: Not installed
2023-10-24 11:39:30,482:INFO:  explainerdashboard: Not installed
2023-10-24 11:39:30,482:INFO:             autoviz: Not installed
2023-10-24 11:39:30,482:INFO:           fairlearn: Not installed
2023-10-24 11:39:30,482:INFO:          deepchecks: Not installed
2023-10-24 11:39:30,482:INFO:             xgboost: Not installed
2023-10-24 11:39:30,482:INFO:            catboost: 1.0.4
2023-10-24 11:39:30,482:INFO:              kmodes: Not installed
2023-10-24 11:39:30,482:INFO:             mlxtend: Not installed
2023-10-24 11:39:30,482:INFO:       statsforecast: Not installed
2023-10-24 11:39:30,482:INFO:        tune_sklearn: Not installed
2023-10-24 11:39:30,482:INFO:                 ray: Not installed
2023-10-24 11:39:30,482:INFO:            hyperopt: Not installed
2023-10-24 11:39:30,482:INFO:              optuna: Not installed
2023-10-24 11:39:30,482:INFO:               skopt: Not installed
2023-10-24 11:39:30,482:INFO:              mlflow: 2.7.1
2023-10-24 11:39:30,482:INFO:              gradio: Not installed
2023-10-24 11:39:30,483:INFO:             fastapi: Not installed
2023-10-24 11:39:30,483:INFO:             uvicorn: Not installed
2023-10-24 11:39:30,483:INFO:              m2cgen: Not installed
2023-10-24 11:39:30,483:INFO:           evidently: Not installed
2023-10-24 11:39:30,483:INFO:               fugue: Not installed
2023-10-24 11:39:30,483:INFO:           streamlit: Not installed
2023-10-24 11:39:30,483:INFO:             prophet: Not installed
2023-10-24 11:39:30,483:INFO:None
2023-10-24 11:39:30,483:INFO:Set up data.
2023-10-24 11:39:30,528:INFO:Set up folding strategy.
2023-10-24 11:39:30,529:INFO:Set up train/test split.
2023-10-24 11:39:30,566:INFO:Set up index.
2023-10-24 11:39:30,568:INFO:Assigning column types.
2023-10-24 11:39:30,586:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 11:39:30,586:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 11:39:30,590:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:39:30,594:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:39:30,670:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:39:30,721:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:39:30,722:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:39:30,722:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:39:30,723:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 11:39:30,728:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:39:30,732:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:39:30,835:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:39:30,901:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:39:30,901:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:39:30,901:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:39:30,902:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 11:39:30,909:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:39:30,917:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:39:30,994:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:39:31,045:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:39:31,045:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:39:31,046:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:39:31,051:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:39:31,061:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:39:31,141:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:39:31,183:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:39:31,183:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:39:31,183:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:39:31,184:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 11:39:31,193:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:39:31,259:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:39:31,305:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:39:31,309:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:39:31,309:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:39:31,317:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:39:31,382:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:39:31,424:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:39:31,424:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:39:31,425:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:39:31,425:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 11:39:31,521:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:39:31,593:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:39:31,594:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:39:31,595:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:39:31,706:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:39:31,770:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:39:31,771:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:39:31,771:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:39:31,771:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 11:39:31,858:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:39:31,905:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:39:31,905:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:39:31,980:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:39:32,024:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:39:32,024:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:39:32,025:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 11:39:32,144:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:39:32,144:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:39:32,265:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:39:32,265:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:39:32,267:INFO:Preparing preprocessing pipeline...
2023-10-24 11:39:32,267:INFO:Set up date feature engineering.
2023-10-24 11:39:32,267:INFO:Set up simple imputation.
2023-10-24 11:39:32,278:INFO:Set up encoding of ordinal features.
2023-10-24 11:39:32,297:INFO:Set up encoding of categorical features.
2023-10-24 11:39:32,297:INFO:Set up polynomial features.
2023-10-24 11:39:32,298:INFO:Set up removing outliers.
2023-10-24 11:39:32,299:INFO:Set up column name cleaning.
2023-10-24 11:39:33,699:INFO:Finished creating preprocessing pipeline.
2023-10-24 11:39:33,796:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m'...
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 11:39:33,796:INFO:Creating final display dataframe.
2023-10-24 11:39:37,827:INFO:Setup _display_container:                     Description          Value
0                    Session id            123
1                        Target         target
2                   Target type     Regression
3           Original data shape    (34061, 52)
4        Transformed data shape  (32868, 1540)
5   Transformed train set shape  (22649, 1540)
6    Transformed test set shape  (10219, 1540)
7              Ordinal features              4
8              Numeric features             44
9                 Date features              3
10         Categorical features              4
11     Rows with missing values          90.5%
12                   Preprocess           True
13              Imputation type         simple
14           Numeric imputation           mean
15       Categorical imputation           mode
16     Maximum one-hot encoding             25
17              Encoding method           None
18          Polynomial features           True
19            Polynomial degree              2
20              Remove outliers           True
21           Outliers threshold           0.05
22               Fold Generator          KFold
23                  Fold Number             10
24                     CPU Jobs             -1
25                      Use GPU          False
26               Log Experiment   MlflowLogger
27              Experiment Name          exp_A
28                          USI           9620
2023-10-24 11:39:37,965:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:39:37,965:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:39:38,081:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:39:38,081:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:39:38,083:INFO:Logging experiment in loggers
2023-10-24 11:39:38,135:INFO:SubProcess save_model() called ==================================
2023-10-24 11:39:38,324:INFO:Initializing save_model()
2023-10-24 11:39:38,324:INFO:save_model(model=Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m'...
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/tmpqiutbsdm/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m'...
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-24 11:39:38,324:INFO:Adding model into prep_pipe
2023-10-24 11:39:38,324:WARNING:Only Model saved as it was a pipeline.
2023-10-24 11:39:38,353:INFO:/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/tmpqiutbsdm/Transformation Pipeline.pkl saved in current working directory
2023-10-24 11:39:38,491:INFO:Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m'...
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 11:39:38,491:INFO:save_model() successfully completed......................................
2023-10-24 11:39:38,834:INFO:SubProcess save_model() end ==================================
2023-10-24 11:42:44,568:INFO:PyCaret RegressionExperiment
2023-10-24 11:42:44,568:INFO:Logging name: exp_A
2023-10-24 11:42:44,568:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 11:42:44,568:INFO:version 3.1.0
2023-10-24 11:42:44,568:INFO:Initializing setup()
2023-10-24 11:42:44,568:INFO:self.USI: 115d
2023-10-24 11:42:44,568:INFO:self._variable_keys: {'exp_id', 'target_param', 'USI', 'data', 'fold_shuffle_param', 'log_plots_param', 'X_test', 'memory', 'idx', 'y', 'X', 'X_train', 'gpu_n_jobs_param', 'n_jobs_param', 'gpu_param', 'logging_param', 'fold_generator', 'pipeline', 'y_test', 'y_train', '_ml_usecase', '_available_plots', 'html_param', 'exp_name_log', 'transform_target_param', 'seed', 'fold_groups_param'}
2023-10-24 11:42:44,568:INFO:Checking environment
2023-10-24 11:42:44,569:INFO:python_version: 3.8.5
2023-10-24 11:42:44,569:INFO:python_build: ('default', 'Sep  4 2020 02:22:02')
2023-10-24 11:42:44,569:INFO:machine: x86_64
2023-10-24 11:42:44,569:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-10-24 11:42:44,569:INFO:Memory: svmem(total=8589934592, available=2152009728, percent=74.9, used=4565901312, free=16347136, active=2140278784, inactive=2040029184, wired=2425622528)
2023-10-24 11:42:44,569:INFO:Physical Core: 4
2023-10-24 11:42:44,569:INFO:Logical Core: 8
2023-10-24 11:42:44,569:INFO:Checking libraries
2023-10-24 11:42:44,569:INFO:System:
2023-10-24 11:42:44,569:INFO:    python: 3.8.5 (default, Sep  4 2020, 02:22:02)  [Clang 10.0.0 ]
2023-10-24 11:42:44,569:INFO:executable: /Users/kaja/opt/anaconda3/bin/python
2023-10-24 11:42:44,569:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-10-24 11:42:44,569:INFO:PyCaret required dependencies:
2023-10-24 11:42:44,569:INFO:                 pip: 23.3.1
2023-10-24 11:42:44,569:INFO:          setuptools: 68.2.2
2023-10-24 11:42:44,569:INFO:             pycaret: 3.1.0
2023-10-24 11:42:44,569:INFO:             IPython: 7.19.0
2023-10-24 11:42:44,569:INFO:          ipywidgets: 8.1.1
2023-10-24 11:42:44,569:INFO:                tqdm: 4.66.1
2023-10-24 11:42:44,569:INFO:               numpy: 1.23.5
2023-10-24 11:42:44,569:INFO:              pandas: 1.5.3
2023-10-24 11:42:44,569:INFO:              jinja2: 3.1.2
2023-10-24 11:42:44,569:INFO:               scipy: 1.10.1
2023-10-24 11:42:44,569:INFO:              joblib: 1.3.2
2023-10-24 11:42:44,569:INFO:             sklearn: 1.2.2
2023-10-24 11:42:44,569:INFO:                pyod: 1.1.0
2023-10-24 11:42:44,570:INFO:            imblearn: 0.11.0
2023-10-24 11:42:44,570:INFO:   category_encoders: 2.6.2
2023-10-24 11:42:44,570:INFO:            lightgbm: 4.1.0
2023-10-24 11:42:44,570:INFO:               numba: 0.58.1
2023-10-24 11:42:44,570:INFO:            requests: 2.28.2
2023-10-24 11:42:44,570:INFO:          matplotlib: 3.7.3
2023-10-24 11:42:44,570:INFO:          scikitplot: 0.3.7
2023-10-24 11:42:44,570:INFO:         yellowbrick: 1.5
2023-10-24 11:42:44,570:INFO:              plotly: 5.17.0
2023-10-24 11:42:44,570:INFO:    plotly-resampler: Not installed
2023-10-24 11:42:44,570:INFO:             kaleido: 0.2.1
2023-10-24 11:42:44,570:INFO:           schemdraw: 0.15
2023-10-24 11:42:44,570:INFO:         statsmodels: 0.14.0
2023-10-24 11:42:44,570:INFO:              sktime: 0.21.1
2023-10-24 11:42:44,570:INFO:               tbats: 1.1.3
2023-10-24 11:42:44,570:INFO:            pmdarima: 2.0.4
2023-10-24 11:42:44,570:INFO:              psutil: 5.9.6
2023-10-24 11:42:44,570:INFO:          markupsafe: 2.1.2
2023-10-24 11:42:44,570:INFO:             pickle5: Not installed
2023-10-24 11:42:44,570:INFO:         cloudpickle: 1.6.0
2023-10-24 11:42:44,570:INFO:         deprecation: 2.1.0
2023-10-24 11:42:44,570:INFO:              xxhash: 3.4.1
2023-10-24 11:42:44,570:INFO:           wurlitzer: 2.0.1
2023-10-24 11:42:44,570:INFO:PyCaret optional dependencies:
2023-10-24 11:42:44,570:INFO:                shap: Not installed
2023-10-24 11:42:44,570:INFO:           interpret: Not installed
2023-10-24 11:42:44,570:INFO:                umap: Not installed
2023-10-24 11:42:44,571:INFO:     ydata_profiling: Not installed
2023-10-24 11:42:44,571:INFO:  explainerdashboard: Not installed
2023-10-24 11:42:44,571:INFO:             autoviz: Not installed
2023-10-24 11:42:44,571:INFO:           fairlearn: Not installed
2023-10-24 11:42:44,571:INFO:          deepchecks: Not installed
2023-10-24 11:42:44,571:INFO:             xgboost: Not installed
2023-10-24 11:42:44,571:INFO:            catboost: 1.0.4
2023-10-24 11:42:44,571:INFO:              kmodes: Not installed
2023-10-24 11:42:44,571:INFO:             mlxtend: Not installed
2023-10-24 11:42:44,571:INFO:       statsforecast: Not installed
2023-10-24 11:42:44,571:INFO:        tune_sklearn: Not installed
2023-10-24 11:42:44,571:INFO:                 ray: Not installed
2023-10-24 11:42:44,571:INFO:            hyperopt: Not installed
2023-10-24 11:42:44,571:INFO:              optuna: Not installed
2023-10-24 11:42:44,571:INFO:               skopt: Not installed
2023-10-24 11:42:44,571:INFO:              mlflow: 2.7.1
2023-10-24 11:42:44,571:INFO:              gradio: Not installed
2023-10-24 11:42:44,571:INFO:             fastapi: Not installed
2023-10-24 11:42:44,571:INFO:             uvicorn: Not installed
2023-10-24 11:42:44,571:INFO:              m2cgen: Not installed
2023-10-24 11:42:44,571:INFO:           evidently: Not installed
2023-10-24 11:42:44,571:INFO:               fugue: Not installed
2023-10-24 11:42:44,571:INFO:           streamlit: Not installed
2023-10-24 11:42:44,571:INFO:             prophet: Not installed
2023-10-24 11:42:44,571:INFO:None
2023-10-24 11:42:44,572:INFO:Set up data.
2023-10-24 11:42:44,609:INFO:Set up folding strategy.
2023-10-24 11:42:44,609:INFO:Set up train/test split.
2023-10-24 11:42:44,646:INFO:Set up index.
2023-10-24 11:42:44,648:INFO:Assigning column types.
2023-10-24 11:42:44,664:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 11:42:44,664:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 11:42:44,668:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:42:44,673:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:42:44,735:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:42:44,777:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:42:44,777:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:42:44,778:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:42:44,778:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 11:42:44,783:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:42:44,787:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:42:44,849:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:42:44,891:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:42:44,892:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:42:44,892:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:42:44,893:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 11:42:44,899:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:42:44,904:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:42:44,983:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:42:45,028:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:42:45,029:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:42:45,029:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:42:45,035:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:42:45,039:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:42:45,106:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:42:45,146:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:42:45,147:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:42:45,147:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:42:45,148:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 11:42:45,156:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:42:45,220:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:42:45,260:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:42:45,261:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:42:45,261:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:42:45,270:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:42:45,334:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:42:45,375:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:42:45,376:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:42:45,376:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:42:45,377:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 11:42:45,458:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:42:45,509:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:42:45,510:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:42:45,510:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:42:45,615:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:42:45,711:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:42:45,711:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:42:45,711:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:42:45,713:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 11:42:45,849:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:42:45,915:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:42:45,915:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:42:46,015:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:42:46,062:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:42:46,062:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:42:46,063:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 11:42:46,244:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:42:46,245:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:42:46,405:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:42:46,405:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:42:46,406:INFO:Preparing preprocessing pipeline...
2023-10-24 11:42:46,407:INFO:Set up date feature engineering.
2023-10-24 11:42:46,407:INFO:Set up simple imputation.
2023-10-24 11:42:46,415:INFO:Set up encoding of ordinal features.
2023-10-24 11:42:46,440:INFO:Set up encoding of categorical features.
2023-10-24 11:42:46,443:INFO:Set up column name cleaning.
2023-10-24 11:42:46,811:INFO:Finished creating preprocessing pipeline.
2023-10-24 11:42:46,927:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m'...
NaN   -1
dtype: int64},
                                                                        {'col': 'rime',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 11:42:46,927:INFO:Creating final display dataframe.
2023-10-24 11:42:47,921:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (34061, 52)
4        Transformed data shape   (34061, 55)
5   Transformed train set shape   (23842, 55)
6    Transformed test set shape   (10219, 55)
7              Ordinal features             4
8              Numeric features            44
9                 Date features             3
10         Categorical features             4
11     Rows with missing values         90.5%
12                   Preprocess          True
13              Imputation type        simple
14           Numeric imputation          mean
15       Categorical imputation          mode
16     Maximum one-hot encoding            25
17              Encoding method          None
18               Fold Generator         KFold
19                  Fold Number            10
20                     CPU Jobs            -1
21                      Use GPU         False
22               Log Experiment  MlflowLogger
23              Experiment Name         exp_A
24                          USI          115d
2023-10-24 11:42:48,072:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:42:48,072:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:42:48,208:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:42:48,208:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:42:48,209:INFO:Logging experiment in loggers
2023-10-24 11:42:48,256:INFO:SubProcess save_model() called ==================================
2023-10-24 11:42:48,591:INFO:Initializing save_model()
2023-10-24 11:42:48,592:INFO:save_model(model=Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m'...
NaN   -1
dtype: int64},
                                                                        {'col': 'rime',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/tmp2c59gxxy/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m'...
NaN   -1
dtype: int64},
                                                                        {'col': 'rime',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-24 11:42:48,592:INFO:Adding model into prep_pipe
2023-10-24 11:42:48,592:WARNING:Only Model saved as it was a pipeline.
2023-10-24 11:42:48,597:INFO:/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/tmp2c59gxxy/Transformation Pipeline.pkl saved in current working directory
2023-10-24 11:42:48,685:INFO:Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m'...
NaN   -1
dtype: int64},
                                                                        {'col': 'rime',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 11:42:48,686:INFO:save_model() successfully completed......................................
2023-10-24 11:42:48,775:INFO:SubProcess save_model() end ==================================
2023-10-24 11:46:07,109:INFO:PyCaret RegressionExperiment
2023-10-24 11:46:07,110:INFO:Logging name: exp_A
2023-10-24 11:46:07,110:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 11:46:07,110:INFO:version 3.1.0
2023-10-24 11:46:07,110:INFO:Initializing setup()
2023-10-24 11:46:07,110:INFO:self.USI: b081
2023-10-24 11:46:07,110:INFO:self._variable_keys: {'exp_id', 'target_param', 'USI', 'data', 'fold_shuffle_param', 'log_plots_param', 'X_test', 'memory', 'idx', 'y', 'X', 'X_train', 'gpu_n_jobs_param', 'n_jobs_param', 'gpu_param', 'logging_param', 'fold_generator', 'pipeline', 'y_test', 'y_train', '_ml_usecase', '_available_plots', 'html_param', 'exp_name_log', 'transform_target_param', 'seed', 'fold_groups_param'}
2023-10-24 11:46:07,110:INFO:Checking environment
2023-10-24 11:46:07,110:INFO:python_version: 3.8.5
2023-10-24 11:46:07,110:INFO:python_build: ('default', 'Sep  4 2020 02:22:02')
2023-10-24 11:46:07,110:INFO:machine: x86_64
2023-10-24 11:46:07,110:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-10-24 11:46:07,111:INFO:Memory: svmem(total=8589934592, available=1946890240, percent=77.3, used=4584894464, free=10272768, active=1940492288, inactive=1930711040, wired=2644402176)
2023-10-24 11:46:07,111:INFO:Physical Core: 4
2023-10-24 11:46:07,111:INFO:Logical Core: 8
2023-10-24 11:46:07,111:INFO:Checking libraries
2023-10-24 11:46:07,111:INFO:System:
2023-10-24 11:46:07,111:INFO:    python: 3.8.5 (default, Sep  4 2020, 02:22:02)  [Clang 10.0.0 ]
2023-10-24 11:46:07,111:INFO:executable: /Users/kaja/opt/anaconda3/bin/python
2023-10-24 11:46:07,111:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-10-24 11:46:07,111:INFO:PyCaret required dependencies:
2023-10-24 11:46:07,111:INFO:                 pip: 23.3.1
2023-10-24 11:46:07,111:INFO:          setuptools: 68.2.2
2023-10-24 11:46:07,112:INFO:             pycaret: 3.1.0
2023-10-24 11:46:07,112:INFO:             IPython: 7.19.0
2023-10-24 11:46:07,112:INFO:          ipywidgets: 8.1.1
2023-10-24 11:46:07,112:INFO:                tqdm: 4.66.1
2023-10-24 11:46:07,112:INFO:               numpy: 1.23.5
2023-10-24 11:46:07,112:INFO:              pandas: 1.5.3
2023-10-24 11:46:07,112:INFO:              jinja2: 3.1.2
2023-10-24 11:46:07,112:INFO:               scipy: 1.10.1
2023-10-24 11:46:07,112:INFO:              joblib: 1.3.2
2023-10-24 11:46:07,112:INFO:             sklearn: 1.2.2
2023-10-24 11:46:07,112:INFO:                pyod: 1.1.0
2023-10-24 11:46:07,112:INFO:            imblearn: 0.11.0
2023-10-24 11:46:07,112:INFO:   category_encoders: 2.6.2
2023-10-24 11:46:07,112:INFO:            lightgbm: 4.1.0
2023-10-24 11:46:07,112:INFO:               numba: 0.58.1
2023-10-24 11:46:07,112:INFO:            requests: 2.28.2
2023-10-24 11:46:07,112:INFO:          matplotlib: 3.7.3
2023-10-24 11:46:07,112:INFO:          scikitplot: 0.3.7
2023-10-24 11:46:07,112:INFO:         yellowbrick: 1.5
2023-10-24 11:46:07,112:INFO:              plotly: 5.17.0
2023-10-24 11:46:07,112:INFO:    plotly-resampler: Not installed
2023-10-24 11:46:07,112:INFO:             kaleido: 0.2.1
2023-10-24 11:46:07,112:INFO:           schemdraw: 0.15
2023-10-24 11:46:07,112:INFO:         statsmodels: 0.14.0
2023-10-24 11:46:07,112:INFO:              sktime: 0.21.1
2023-10-24 11:46:07,112:INFO:               tbats: 1.1.3
2023-10-24 11:46:07,112:INFO:            pmdarima: 2.0.4
2023-10-24 11:46:07,112:INFO:              psutil: 5.9.6
2023-10-24 11:46:07,112:INFO:          markupsafe: 2.1.2
2023-10-24 11:46:07,112:INFO:             pickle5: Not installed
2023-10-24 11:46:07,112:INFO:         cloudpickle: 1.6.0
2023-10-24 11:46:07,113:INFO:         deprecation: 2.1.0
2023-10-24 11:46:07,113:INFO:              xxhash: 3.4.1
2023-10-24 11:46:07,113:INFO:           wurlitzer: 2.0.1
2023-10-24 11:46:07,113:INFO:PyCaret optional dependencies:
2023-10-24 11:46:07,113:INFO:                shap: Not installed
2023-10-24 11:46:07,113:INFO:           interpret: Not installed
2023-10-24 11:46:07,113:INFO:                umap: Not installed
2023-10-24 11:46:07,113:INFO:     ydata_profiling: Not installed
2023-10-24 11:46:07,113:INFO:  explainerdashboard: Not installed
2023-10-24 11:46:07,113:INFO:             autoviz: Not installed
2023-10-24 11:46:07,113:INFO:           fairlearn: Not installed
2023-10-24 11:46:07,113:INFO:          deepchecks: Not installed
2023-10-24 11:46:07,113:INFO:             xgboost: Not installed
2023-10-24 11:46:07,113:INFO:            catboost: 1.0.4
2023-10-24 11:46:07,113:INFO:              kmodes: Not installed
2023-10-24 11:46:07,113:INFO:             mlxtend: Not installed
2023-10-24 11:46:07,113:INFO:       statsforecast: Not installed
2023-10-24 11:46:07,113:INFO:        tune_sklearn: Not installed
2023-10-24 11:46:07,113:INFO:                 ray: Not installed
2023-10-24 11:46:07,113:INFO:            hyperopt: Not installed
2023-10-24 11:46:07,113:INFO:              optuna: Not installed
2023-10-24 11:46:07,113:INFO:               skopt: Not installed
2023-10-24 11:46:07,113:INFO:              mlflow: 2.7.1
2023-10-24 11:46:07,113:INFO:              gradio: Not installed
2023-10-24 11:46:07,113:INFO:             fastapi: Not installed
2023-10-24 11:46:07,113:INFO:             uvicorn: Not installed
2023-10-24 11:46:07,113:INFO:              m2cgen: Not installed
2023-10-24 11:46:07,113:INFO:           evidently: Not installed
2023-10-24 11:46:07,113:INFO:               fugue: Not installed
2023-10-24 11:46:07,114:INFO:           streamlit: Not installed
2023-10-24 11:46:07,114:INFO:             prophet: Not installed
2023-10-24 11:46:07,114:INFO:None
2023-10-24 11:46:07,114:INFO:Set up data.
2023-10-24 11:46:07,158:INFO:Set up folding strategy.
2023-10-24 11:46:07,158:INFO:Set up train/test split.
2023-10-24 11:46:07,196:INFO:Set up index.
2023-10-24 11:46:07,198:INFO:Assigning column types.
2023-10-24 11:46:07,215:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 11:46:07,215:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 11:46:07,219:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:46:07,224:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:46:07,285:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:46:07,325:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:46:07,326:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:46:07,326:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:46:07,327:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 11:46:07,331:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:46:07,335:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:46:07,396:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:46:07,434:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:46:07,435:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:46:07,435:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:46:07,435:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 11:46:07,439:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:46:07,443:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:46:07,503:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:46:07,543:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:46:07,544:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:46:07,544:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:46:07,548:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:46:07,553:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:46:07,614:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:46:07,656:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:46:07,656:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:46:07,656:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:46:07,657:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 11:46:07,665:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:46:07,726:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:46:07,767:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:46:07,768:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:46:07,768:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:46:07,776:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:46:07,836:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:46:07,875:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:46:07,878:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:46:07,878:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:46:07,879:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 11:46:07,946:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:46:07,986:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:46:07,986:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:46:07,987:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:46:08,055:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:46:08,095:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:46:08,095:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:46:08,096:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:46:08,096:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 11:46:08,175:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:46:08,218:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:46:08,218:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:46:08,295:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:46:08,336:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:46:08,337:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:46:08,337:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 11:46:08,447:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:46:08,447:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:46:08,599:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:46:08,599:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:46:08,601:INFO:Preparing preprocessing pipeline...
2023-10-24 11:46:08,601:INFO:Set up date feature engineering.
2023-10-24 11:46:08,601:INFO:Set up simple imputation.
2023-10-24 11:46:08,612:INFO:Set up encoding of ordinal features.
2023-10-24 11:46:08,630:INFO:Set up encoding of categorical features.
2023-10-24 11:46:08,633:INFO:Set up column name cleaning.
2023-10-24 11:46:08,899:INFO:Finished creating preprocessing pipeline.
2023-10-24 11:46:09,002:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m'...
NaN   -1
dtype: int64},
                                                                        {'col': 'rime',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 11:46:09,002:INFO:Creating final display dataframe.
2023-10-24 11:46:09,144:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (34061, 52)
4        Transformed data shape   (34061, 55)
5   Transformed train set shape   (23842, 55)
6    Transformed test set shape   (10219, 55)
7              Ordinal features             4
8              Numeric features            44
9                 Date features             3
10         Categorical features             4
11     Rows with missing values         90.5%
12                   Preprocess          True
13              Imputation type        simple
14           Numeric imputation          mean
15       Categorical imputation          mode
16     Maximum one-hot encoding            25
17              Encoding method          None
18               Fold Generator         KFold
19                  Fold Number            10
20                     CPU Jobs            -1
21                      Use GPU         False
22               Log Experiment  MlflowLogger
23              Experiment Name         exp_A
24                          USI          b081
2023-10-24 11:46:09,265:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:46:09,265:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:46:09,382:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:46:09,382:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:46:09,384:INFO:Logging experiment in loggers
2023-10-24 11:46:09,437:INFO:SubProcess save_model() called ==================================
2023-10-24 11:46:09,707:INFO:Initializing save_model()
2023-10-24 11:46:09,707:INFO:save_model(model=Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m'...
NaN   -1
dtype: int64},
                                                                        {'col': 'rime',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/tmpnos_90qu/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m'...
NaN   -1
dtype: int64},
                                                                        {'col': 'rime',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-24 11:46:09,707:INFO:Adding model into prep_pipe
2023-10-24 11:46:09,707:WARNING:Only Model saved as it was a pipeline.
2023-10-24 11:46:09,712:INFO:/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/tmpnos_90qu/Transformation Pipeline.pkl saved in current working directory
2023-10-24 11:46:09,800:INFO:Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m'...
NaN   -1
dtype: int64},
                                                                        {'col': 'rime',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 11:46:09,800:INFO:save_model() successfully completed......................................
2023-10-24 11:46:10,130:INFO:SubProcess save_model() end ==================================
2023-10-24 11:50:29,113:INFO:PyCaret RegressionExperiment
2023-10-24 11:50:29,114:INFO:Logging name: exp_A
2023-10-24 11:50:29,114:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 11:50:29,114:INFO:version 3.1.0
2023-10-24 11:50:29,114:INFO:Initializing setup()
2023-10-24 11:50:29,114:INFO:self.USI: da5a
2023-10-24 11:50:29,114:INFO:self._variable_keys: {'exp_id', 'target_param', 'USI', 'data', 'fold_shuffle_param', 'log_plots_param', 'X_test', 'memory', 'idx', 'y', 'X', 'X_train', 'gpu_n_jobs_param', 'n_jobs_param', 'gpu_param', 'logging_param', 'fold_generator', 'pipeline', 'y_test', 'y_train', '_ml_usecase', '_available_plots', 'html_param', 'exp_name_log', 'transform_target_param', 'seed', 'fold_groups_param'}
2023-10-24 11:50:29,114:INFO:Checking environment
2023-10-24 11:50:29,115:INFO:python_version: 3.8.5
2023-10-24 11:50:29,115:INFO:python_build: ('default', 'Sep  4 2020 02:22:02')
2023-10-24 11:50:29,115:INFO:machine: x86_64
2023-10-24 11:50:29,115:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-10-24 11:50:29,115:INFO:Memory: svmem(total=8589934592, available=2233696256, percent=74.0, used=4926746624, free=15069184, active=2222526464, inactive=2214457344, wired=2704220160)
2023-10-24 11:50:29,115:INFO:Physical Core: 4
2023-10-24 11:50:29,115:INFO:Logical Core: 8
2023-10-24 11:50:29,115:INFO:Checking libraries
2023-10-24 11:50:29,115:INFO:System:
2023-10-24 11:50:29,115:INFO:    python: 3.8.5 (default, Sep  4 2020, 02:22:02)  [Clang 10.0.0 ]
2023-10-24 11:50:29,115:INFO:executable: /Users/kaja/opt/anaconda3/bin/python
2023-10-24 11:50:29,115:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-10-24 11:50:29,115:INFO:PyCaret required dependencies:
2023-10-24 11:50:29,115:INFO:                 pip: 23.3.1
2023-10-24 11:50:29,115:INFO:          setuptools: 68.2.2
2023-10-24 11:50:29,115:INFO:             pycaret: 3.1.0
2023-10-24 11:50:29,115:INFO:             IPython: 7.19.0
2023-10-24 11:50:29,115:INFO:          ipywidgets: 8.1.1
2023-10-24 11:50:29,115:INFO:                tqdm: 4.66.1
2023-10-24 11:50:29,116:INFO:               numpy: 1.23.5
2023-10-24 11:50:29,116:INFO:              pandas: 1.5.3
2023-10-24 11:50:29,116:INFO:              jinja2: 3.1.2
2023-10-24 11:50:29,116:INFO:               scipy: 1.10.1
2023-10-24 11:50:29,116:INFO:              joblib: 1.3.2
2023-10-24 11:50:29,116:INFO:             sklearn: 1.2.2
2023-10-24 11:50:29,116:INFO:                pyod: 1.1.0
2023-10-24 11:50:29,116:INFO:            imblearn: 0.11.0
2023-10-24 11:50:29,116:INFO:   category_encoders: 2.6.2
2023-10-24 11:50:29,116:INFO:            lightgbm: 4.1.0
2023-10-24 11:50:29,116:INFO:               numba: 0.58.1
2023-10-24 11:50:29,116:INFO:            requests: 2.28.2
2023-10-24 11:50:29,116:INFO:          matplotlib: 3.7.3
2023-10-24 11:50:29,116:INFO:          scikitplot: 0.3.7
2023-10-24 11:50:29,116:INFO:         yellowbrick: 1.5
2023-10-24 11:50:29,116:INFO:              plotly: 5.17.0
2023-10-24 11:50:29,116:INFO:    plotly-resampler: Not installed
2023-10-24 11:50:29,116:INFO:             kaleido: 0.2.1
2023-10-24 11:50:29,116:INFO:           schemdraw: 0.15
2023-10-24 11:50:29,116:INFO:         statsmodels: 0.14.0
2023-10-24 11:50:29,116:INFO:              sktime: 0.21.1
2023-10-24 11:50:29,116:INFO:               tbats: 1.1.3
2023-10-24 11:50:29,116:INFO:            pmdarima: 2.0.4
2023-10-24 11:50:29,116:INFO:              psutil: 5.9.6
2023-10-24 11:50:29,116:INFO:          markupsafe: 2.1.2
2023-10-24 11:50:29,116:INFO:             pickle5: Not installed
2023-10-24 11:50:29,116:INFO:         cloudpickle: 1.6.0
2023-10-24 11:50:29,116:INFO:         deprecation: 2.1.0
2023-10-24 11:50:29,116:INFO:              xxhash: 3.4.1
2023-10-24 11:50:29,116:INFO:           wurlitzer: 2.0.1
2023-10-24 11:50:29,116:INFO:PyCaret optional dependencies:
2023-10-24 11:50:29,117:INFO:                shap: Not installed
2023-10-24 11:50:29,117:INFO:           interpret: Not installed
2023-10-24 11:50:29,117:INFO:                umap: Not installed
2023-10-24 11:50:29,117:INFO:     ydata_profiling: Not installed
2023-10-24 11:50:29,117:INFO:  explainerdashboard: Not installed
2023-10-24 11:50:29,117:INFO:             autoviz: Not installed
2023-10-24 11:50:29,117:INFO:           fairlearn: Not installed
2023-10-24 11:50:29,117:INFO:          deepchecks: Not installed
2023-10-24 11:50:29,117:INFO:             xgboost: Not installed
2023-10-24 11:50:29,117:INFO:            catboost: 1.0.4
2023-10-24 11:50:29,117:INFO:              kmodes: Not installed
2023-10-24 11:50:29,117:INFO:             mlxtend: Not installed
2023-10-24 11:50:29,117:INFO:       statsforecast: Not installed
2023-10-24 11:50:29,117:INFO:        tune_sklearn: Not installed
2023-10-24 11:50:29,117:INFO:                 ray: Not installed
2023-10-24 11:50:29,117:INFO:            hyperopt: Not installed
2023-10-24 11:50:29,117:INFO:              optuna: Not installed
2023-10-24 11:50:29,117:INFO:               skopt: Not installed
2023-10-24 11:50:29,117:INFO:              mlflow: 2.7.1
2023-10-24 11:50:29,117:INFO:              gradio: Not installed
2023-10-24 11:50:29,117:INFO:             fastapi: Not installed
2023-10-24 11:50:29,117:INFO:             uvicorn: Not installed
2023-10-24 11:50:29,117:INFO:              m2cgen: Not installed
2023-10-24 11:50:29,117:INFO:           evidently: Not installed
2023-10-24 11:50:29,117:INFO:               fugue: Not installed
2023-10-24 11:50:29,118:INFO:           streamlit: Not installed
2023-10-24 11:50:29,118:INFO:             prophet: Not installed
2023-10-24 11:50:29,118:INFO:None
2023-10-24 11:50:29,118:INFO:Set up data.
2023-10-24 11:50:29,183:INFO:Set up folding strategy.
2023-10-24 11:50:29,183:INFO:Set up train/test split.
2023-10-24 11:50:29,282:INFO:Set up index.
2023-10-24 11:50:29,285:INFO:Assigning column types.
2023-10-24 11:50:29,302:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 11:50:29,303:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 11:50:29,307:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:50:29,311:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:50:29,383:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:50:29,425:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:50:29,426:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:50:29,426:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:50:29,427:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 11:50:29,431:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:50:29,435:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:50:29,512:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:50:29,554:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:50:29,554:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:50:29,554:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:50:29,555:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 11:50:29,559:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:50:29,564:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:50:29,632:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:50:29,674:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:50:29,675:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:50:29,675:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:50:29,680:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:50:29,684:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:50:29,750:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:50:29,792:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:50:29,793:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:50:29,793:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:50:29,794:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 11:50:29,803:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:50:29,865:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:50:29,907:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:50:29,908:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:50:29,908:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:50:29,919:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:50:29,982:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:50:30,022:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:50:30,025:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:50:30,025:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:50:30,025:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 11:50:30,093:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:50:30,165:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:50:30,166:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:50:30,166:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:50:30,260:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:50:30,303:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:50:30,304:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:50:30,304:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:50:30,304:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 11:50:30,375:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:50:30,417:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:50:30,417:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:50:30,492:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:50:30,594:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:50:30,595:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:50:30,596:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 11:50:30,758:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:50:30,759:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:50:30,897:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:50:30,897:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:50:30,899:INFO:Preparing preprocessing pipeline...
2023-10-24 11:50:30,899:INFO:Set up date feature engineering.
2023-10-24 11:50:30,899:INFO:Set up simple imputation.
2023-10-24 11:50:30,908:INFO:Set up encoding of ordinal features.
2023-10-24 11:50:30,927:INFO:Set up encoding of categorical features.
2023-10-24 11:50:30,930:INFO:Set up column name cleaning.
2023-10-24 11:50:31,216:INFO:Finished creating preprocessing pipeline.
2023-10-24 11:50:31,306:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m'...
NaN   -1
dtype: int64},
                                                                        {'col': 'rime',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 11:50:31,306:INFO:Creating final display dataframe.
2023-10-24 11:50:31,437:INFO:Setup _display_container:                     Description         Value
0                    Session id           123
1                        Target        target
2                   Target type    Regression
3           Original data shape   (34061, 52)
4        Transformed data shape   (34061, 55)
5   Transformed train set shape   (23842, 55)
6    Transformed test set shape   (10219, 55)
7              Ordinal features             4
8              Numeric features            44
9                 Date features             3
10         Categorical features             4
11     Rows with missing values         90.5%
12                   Preprocess          True
13              Imputation type        simple
14           Numeric imputation          mean
15       Categorical imputation          mode
16     Maximum one-hot encoding            25
17              Encoding method          None
18               Fold Generator         KFold
19                  Fold Number            10
20                     CPU Jobs            -1
21                      Use GPU         False
22               Log Experiment  MlflowLogger
23              Experiment Name         exp_A
24                          USI          da5a
2023-10-24 11:50:31,555:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:50:31,556:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:50:31,666:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:50:31,666:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:50:31,667:INFO:Logging experiment in loggers
2023-10-24 11:50:31,706:INFO:SubProcess save_model() called ==================================
2023-10-24 11:50:31,952:INFO:Initializing save_model()
2023-10-24 11:50:31,952:INFO:save_model(model=Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m'...
NaN   -1
dtype: int64},
                                                                        {'col': 'rime',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/tmp7wivxt8q/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m'...
NaN   -1
dtype: int64},
                                                                        {'col': 'rime',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-24 11:50:31,952:INFO:Adding model into prep_pipe
2023-10-24 11:50:31,952:WARNING:Only Model saved as it was a pipeline.
2023-10-24 11:50:31,957:INFO:/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/tmp7wivxt8q/Transformation Pipeline.pkl saved in current working directory
2023-10-24 11:50:32,045:INFO:Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m'...
NaN   -1
dtype: int64},
                                                                        {'col': 'rime',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 11:50:32,045:INFO:save_model() successfully completed......................................
2023-10-24 11:50:32,154:INFO:SubProcess save_model() end ==================================
2023-10-24 11:54:02,285:INFO:PyCaret RegressionExperiment
2023-10-24 11:54:02,286:INFO:Logging name: exp_A
2023-10-24 11:54:02,286:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 11:54:02,286:INFO:version 3.1.0
2023-10-24 11:54:02,286:INFO:Initializing setup()
2023-10-24 11:54:02,286:INFO:self.USI: 9454
2023-10-24 11:54:02,286:INFO:self._variable_keys: {'exp_id', 'target_param', 'USI', 'data', 'fold_shuffle_param', 'log_plots_param', 'X_test', 'memory', 'idx', 'y', 'X', 'X_train', 'gpu_n_jobs_param', 'n_jobs_param', 'gpu_param', 'logging_param', 'fold_generator', 'pipeline', 'y_test', 'y_train', '_ml_usecase', '_available_plots', 'html_param', 'exp_name_log', 'transform_target_param', 'seed', 'fold_groups_param'}
2023-10-24 11:54:02,286:INFO:Checking environment
2023-10-24 11:54:02,286:INFO:python_version: 3.8.5
2023-10-24 11:54:02,286:INFO:python_build: ('default', 'Sep  4 2020 02:22:02')
2023-10-24 11:54:02,286:INFO:machine: x86_64
2023-10-24 11:54:02,286:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-10-24 11:54:02,286:INFO:Memory: svmem(total=8589934592, available=2328653824, percent=72.9, used=4525740032, free=214188032, active=2150322176, inactive=2111008768, wired=2375417856)
2023-10-24 11:54:02,286:INFO:Physical Core: 4
2023-10-24 11:54:02,286:INFO:Logical Core: 8
2023-10-24 11:54:02,286:INFO:Checking libraries
2023-10-24 11:54:02,287:INFO:System:
2023-10-24 11:54:02,287:INFO:    python: 3.8.5 (default, Sep  4 2020, 02:22:02)  [Clang 10.0.0 ]
2023-10-24 11:54:02,287:INFO:executable: /Users/kaja/opt/anaconda3/bin/python
2023-10-24 11:54:02,287:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-10-24 11:54:02,287:INFO:PyCaret required dependencies:
2023-10-24 11:54:02,287:INFO:                 pip: 23.3.1
2023-10-24 11:54:02,287:INFO:          setuptools: 68.2.2
2023-10-24 11:54:02,287:INFO:             pycaret: 3.1.0
2023-10-24 11:54:02,287:INFO:             IPython: 7.19.0
2023-10-24 11:54:02,287:INFO:          ipywidgets: 8.1.1
2023-10-24 11:54:02,287:INFO:                tqdm: 4.66.1
2023-10-24 11:54:02,287:INFO:               numpy: 1.23.5
2023-10-24 11:54:02,287:INFO:              pandas: 1.5.3
2023-10-24 11:54:02,287:INFO:              jinja2: 3.1.2
2023-10-24 11:54:02,287:INFO:               scipy: 1.10.1
2023-10-24 11:54:02,287:INFO:              joblib: 1.3.2
2023-10-24 11:54:02,287:INFO:             sklearn: 1.2.2
2023-10-24 11:54:02,287:INFO:                pyod: 1.1.0
2023-10-24 11:54:02,287:INFO:            imblearn: 0.11.0
2023-10-24 11:54:02,287:INFO:   category_encoders: 2.6.2
2023-10-24 11:54:02,287:INFO:            lightgbm: 4.1.0
2023-10-24 11:54:02,287:INFO:               numba: 0.58.1
2023-10-24 11:54:02,287:INFO:            requests: 2.28.2
2023-10-24 11:54:02,287:INFO:          matplotlib: 3.7.3
2023-10-24 11:54:02,288:INFO:          scikitplot: 0.3.7
2023-10-24 11:54:02,288:INFO:         yellowbrick: 1.5
2023-10-24 11:54:02,288:INFO:              plotly: 5.17.0
2023-10-24 11:54:02,288:INFO:    plotly-resampler: Not installed
2023-10-24 11:54:02,288:INFO:             kaleido: 0.2.1
2023-10-24 11:54:02,288:INFO:           schemdraw: 0.15
2023-10-24 11:54:02,288:INFO:         statsmodels: 0.14.0
2023-10-24 11:54:02,288:INFO:              sktime: 0.21.1
2023-10-24 11:54:02,288:INFO:               tbats: 1.1.3
2023-10-24 11:54:02,288:INFO:            pmdarima: 2.0.4
2023-10-24 11:54:02,288:INFO:              psutil: 5.9.6
2023-10-24 11:54:02,288:INFO:          markupsafe: 2.1.2
2023-10-24 11:54:02,288:INFO:             pickle5: Not installed
2023-10-24 11:54:02,288:INFO:         cloudpickle: 1.6.0
2023-10-24 11:54:02,288:INFO:         deprecation: 2.1.0
2023-10-24 11:54:02,288:INFO:              xxhash: 3.4.1
2023-10-24 11:54:02,288:INFO:           wurlitzer: 2.0.1
2023-10-24 11:54:02,288:INFO:PyCaret optional dependencies:
2023-10-24 11:54:02,288:INFO:                shap: Not installed
2023-10-24 11:54:02,288:INFO:           interpret: Not installed
2023-10-24 11:54:02,289:INFO:                umap: Not installed
2023-10-24 11:54:02,289:INFO:     ydata_profiling: Not installed
2023-10-24 11:54:02,289:INFO:  explainerdashboard: Not installed
2023-10-24 11:54:02,289:INFO:             autoviz: Not installed
2023-10-24 11:54:02,289:INFO:           fairlearn: Not installed
2023-10-24 11:54:02,289:INFO:          deepchecks: Not installed
2023-10-24 11:54:02,289:INFO:             xgboost: Not installed
2023-10-24 11:54:02,289:INFO:            catboost: 1.0.4
2023-10-24 11:54:02,289:INFO:              kmodes: Not installed
2023-10-24 11:54:02,289:INFO:             mlxtend: Not installed
2023-10-24 11:54:02,289:INFO:       statsforecast: Not installed
2023-10-24 11:54:02,289:INFO:        tune_sklearn: Not installed
2023-10-24 11:54:02,289:INFO:                 ray: Not installed
2023-10-24 11:54:02,289:INFO:            hyperopt: Not installed
2023-10-24 11:54:02,289:INFO:              optuna: Not installed
2023-10-24 11:54:02,289:INFO:               skopt: Not installed
2023-10-24 11:54:02,289:INFO:              mlflow: 2.7.1
2023-10-24 11:54:02,289:INFO:              gradio: Not installed
2023-10-24 11:54:02,289:INFO:             fastapi: Not installed
2023-10-24 11:54:02,289:INFO:             uvicorn: Not installed
2023-10-24 11:54:02,289:INFO:              m2cgen: Not installed
2023-10-24 11:54:02,289:INFO:           evidently: Not installed
2023-10-24 11:54:02,289:INFO:               fugue: Not installed
2023-10-24 11:54:02,289:INFO:           streamlit: Not installed
2023-10-24 11:54:02,289:INFO:             prophet: Not installed
2023-10-24 11:54:02,289:INFO:None
2023-10-24 11:54:02,289:INFO:Set up data.
2023-10-24 11:54:02,328:INFO:Set up folding strategy.
2023-10-24 11:54:02,328:INFO:Set up train/test split.
2023-10-24 11:54:02,363:INFO:Set up index.
2023-10-24 11:54:02,365:INFO:Assigning column types.
2023-10-24 11:54:02,381:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 11:54:02,381:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 11:54:02,385:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:54:02,389:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:54:02,450:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:54:02,493:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:54:02,494:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:54:02,494:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:54:02,494:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 11:54:02,499:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:54:02,503:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:54:02,569:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:54:02,611:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:54:02,611:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:54:02,612:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:54:02,612:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 11:54:02,616:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:54:02,621:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:54:02,684:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:54:02,724:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:54:02,725:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:54:02,725:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:54:02,729:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:54:02,733:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:54:02,791:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:54:02,832:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:54:02,833:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:54:02,833:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:54:02,833:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 11:54:02,842:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:54:02,902:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:54:02,942:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:54:02,943:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:54:02,943:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:54:02,951:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:54:03,012:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:54:03,054:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:54:03,054:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:54:03,055:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:54:03,055:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 11:54:03,129:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:54:03,176:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:54:03,177:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:54:03,177:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:54:03,256:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:54:03,303:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:54:03,318:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:54:03,318:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:54:03,319:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 11:54:03,392:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:54:03,433:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:54:03,433:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:54:03,555:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:54:03,632:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:54:03,632:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:54:03,632:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 11:54:03,769:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:54:03,770:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:54:03,909:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:54:03,909:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:54:03,911:INFO:Preparing preprocessing pipeline...
2023-10-24 11:54:03,911:INFO:Set up date feature engineering.
2023-10-24 11:54:03,911:INFO:Set up simple imputation.
2023-10-24 11:54:03,922:INFO:Set up encoding of ordinal features.
2023-10-24 11:54:03,951:INFO:Set up encoding of categorical features.
2023-10-24 11:54:03,955:INFO:Set up column name cleaning.
2023-10-24 11:54:04,216:INFO:Finished creating preprocessing pipeline.
2023-10-24 11:54:04,308:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m'...
NaN   -1
dtype: int64},
                                                                        {'col': 'rime',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 11:54:04,308:INFO:Creating final display dataframe.
2023-10-24 11:54:04,432:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (34061, 52)
4        Transformed data shape  (34061, 55)
5   Transformed train set shape  (23842, 55)
6    Transformed test set shape  (10219, 55)
7              Ordinal features            4
8              Numeric features           44
9                 Date features            3
10         Categorical features            4
11     Rows with missing values        90.5%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18               Fold Generator        KFold
19                  Fold Number           10
20                     CPU Jobs           -1
21                      Use GPU        False
22               Log Experiment        False
23              Experiment Name        exp_A
24                          USI         9454
2023-10-24 11:54:04,552:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:54:04,552:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:54:04,668:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:54:04,669:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:54:04,669:INFO:setup() successfully completed in 2.39s...............
2023-10-24 11:54:04,669:INFO:Initializing create_model()
2023-10-24 11:54:04,670:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dcd2bda90>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 11:54:04,670:INFO:Checking exceptions
2023-10-24 11:54:04,686:INFO:Importing libraries
2023-10-24 11:54:04,686:INFO:Copying training dataset
2023-10-24 11:54:04,717:INFO:Defining folds
2023-10-24 11:54:04,717:INFO:Declaring metric variables
2023-10-24 11:54:04,718:INFO:Importing untrained model
2023-10-24 11:54:04,719:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 11:54:04,719:INFO:Starting cross validation
2023-10-24 11:54:04,732:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 11:54:09,627:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:54:09,627:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:54:09,628:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:54:09,627:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:54:09,628:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:54:09,628:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:54:09,628:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:54:09,628:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:54:09,628:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:54:09,628:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:54:09,628:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:54:09,628:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:54:09,628:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:54:09,627:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:54:09,628:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:54:09,628:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:54:09,628:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:54:09,627:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:54:09,628:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:54:09,628:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:54:09,629:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:54:09,629:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:54:09,629:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:54:09,629:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:54:12,336:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044625 seconds.
2023-10-24 11:54:12,338:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:54:12,338:INFO:[LightGBM] [Info] Total Bins 6547
2023-10-24 11:54:12,338:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043240 seconds.
2023-10-24 11:54:12,339:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 11:54:12,339:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 11:54:12,339:INFO:[LightGBM] [Info] Total Bins 6561
2023-10-24 11:54:12,339:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029588 seconds.
2023-10-24 11:54:12,339:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 11:54:12,339:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 11:54:12,339:INFO:[LightGBM] [Info] Total Bins 6562
2023-10-24 11:54:12,339:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037114 seconds.
2023-10-24 11:54:12,339:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 11:54:12,339:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 11:54:12,339:INFO:[LightGBM] [Info] Total Bins 6556
2023-10-24 11:54:12,345:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 51
2023-10-24 11:54:12,346:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 51
2023-10-24 11:54:12,346:INFO:[LightGBM] [Info] Number of data points in the train set: 21457, number of used features: 51
2023-10-24 11:54:12,347:INFO:[LightGBM] [Info] Number of data points in the train set: 21457, number of used features: 51
2023-10-24 11:54:12,350:INFO:[LightGBM] [Info] Start training from score 626.714401
2023-10-24 11:54:12,350:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039208 seconds.
2023-10-24 11:54:12,350:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 11:54:12,350:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 11:54:12,350:INFO:[LightGBM] [Info] Total Bins 6564
2023-10-24 11:54:12,351:INFO:[LightGBM] [Info] Start training from score 624.465909
2023-10-24 11:54:12,352:INFO:[LightGBM] [Info] Start training from score 629.291796[LightGBM] [Info] Start training from score 626.835846
2023-10-24 11:54:12,352:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 51
2023-10-24 11:54:12,352:INFO:
2023-10-24 11:54:12,352:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054308 seconds.
2023-10-24 11:54:12,353:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:54:12,353:INFO:[LightGBM] [Info] Total Bins 6562
2023-10-24 11:54:12,354:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 51
2023-10-24 11:54:12,354:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020386 seconds.
2023-10-24 11:54:12,354:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 11:54:12,354:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 11:54:12,355:INFO:[LightGBM] [Info] Total Bins 6558
2023-10-24 11:54:12,355:INFO:[LightGBM] [Info] Start training from score 627.582936
2023-10-24 11:54:12,356:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 51
2023-10-24 11:54:12,356:INFO:[LightGBM] [Info] Start training from score 631.036433
2023-10-24 11:54:12,357:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026121 seconds.
2023-10-24 11:54:12,357:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 11:54:12,357:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 11:54:12,357:INFO:[LightGBM] [Info] Total Bins 6557
2023-10-24 11:54:12,359:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 51
2023-10-24 11:54:12,360:INFO:[LightGBM] [Info] Start training from score 631.624808
2023-10-24 11:54:12,363:INFO:[LightGBM] [Info] Start training from score 629.037061
2023-10-24 11:54:19,711:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007009 seconds.
2023-10-24 11:54:19,711:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 11:54:19,711:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 11:54:19,711:INFO:[LightGBM] [Info] Total Bins 6551
2023-10-24 11:54:19,712:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 51
2023-10-24 11:54:19,714:INFO:[LightGBM] [Info] Start training from score 620.705419
2023-10-24 11:54:19,802:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007532 seconds.
2023-10-24 11:54:19,802:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 11:54:19,802:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 11:54:19,803:INFO:[LightGBM] [Info] Total Bins 6567
2023-10-24 11:54:19,803:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 51
2023-10-24 11:54:19,804:INFO:[LightGBM] [Info] Start training from score 633.990557
2023-10-24 11:54:21,589:INFO:Calculating mean and std
2023-10-24 11:54:21,593:INFO:Creating metrics dataframe
2023-10-24 11:54:21,599:INFO:Finalizing model
2023-10-24 11:54:21,995:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006490 seconds.
2023-10-24 11:54:21,995:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:54:21,995:INFO:[LightGBM] [Info] Total Bins 6584
2023-10-24 11:54:21,996:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 51
2023-10-24 11:54:21,997:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-24 11:54:22,204:INFO:Uploading results into container
2023-10-24 11:54:22,205:INFO:Uploading model into container now
2023-10-24 11:54:22,212:INFO:_master_model_container: 1
2023-10-24 11:54:22,212:INFO:_display_container: 2
2023-10-24 11:54:22,213:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 11:54:22,214:INFO:create_model() successfully completed......................................
2023-10-24 11:54:22,577:INFO:Initializing tune_model()
2023-10-24 11:54:22,577:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dcd2bda90>)
2023-10-24 11:54:22,577:INFO:Checking exceptions
2023-10-24 11:54:22,599:INFO:Copying training dataset
2023-10-24 11:54:22,613:INFO:Checking base model
2023-10-24 11:54:22,613:INFO:Base model : Light Gradient Boosting Machine
2023-10-24 11:54:22,614:INFO:Declaring metric variables
2023-10-24 11:54:22,614:INFO:Defining Hyperparameters
2023-10-24 11:54:22,703:INFO:Tuning with n_jobs=-1
2023-10-24 11:54:22,703:INFO:Initializing RandomizedSearchCV
2023-10-24 11:57:46,848:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-24 11:57:46,850:INFO:Hyperparameter search completed
2023-10-24 11:57:46,850:INFO:SubProcess create_model() called ==================================
2023-10-24 11:57:46,851:INFO:Initializing create_model()
2023-10-24 11:57:46,851:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dcd2bda90>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9dc2ec1310>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-24 11:57:46,852:INFO:Checking exceptions
2023-10-24 11:57:46,852:INFO:Importing libraries
2023-10-24 11:57:46,852:INFO:Copying training dataset
2023-10-24 11:57:46,883:INFO:Defining folds
2023-10-24 11:57:46,884:INFO:Declaring metric variables
2023-10-24 11:57:46,884:INFO:Importing untrained model
2023-10-24 11:57:46,884:INFO:Declaring custom model
2023-10-24 11:57:46,886:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 11:57:46,886:INFO:Starting cross validation
2023-10-24 11:57:46,889:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 11:59:06,548:INFO:PyCaret RegressionExperiment
2023-10-24 11:59:06,548:INFO:Logging name: exp_A
2023-10-24 11:59:06,548:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 11:59:06,548:INFO:version 3.1.0
2023-10-24 11:59:06,548:INFO:Initializing setup()
2023-10-24 11:59:06,548:INFO:self.USI: 5940
2023-10-24 11:59:06,548:INFO:self._variable_keys: {'exp_id', 'target_param', 'USI', 'data', 'fold_shuffle_param', 'log_plots_param', 'X_test', 'memory', 'idx', 'y', 'X', 'X_train', 'gpu_n_jobs_param', 'n_jobs_param', 'gpu_param', 'logging_param', 'fold_generator', 'pipeline', 'y_test', 'y_train', '_ml_usecase', '_available_plots', 'html_param', 'exp_name_log', 'transform_target_param', 'seed', 'fold_groups_param'}
2023-10-24 11:59:06,548:INFO:Checking environment
2023-10-24 11:59:06,549:INFO:python_version: 3.8.5
2023-10-24 11:59:06,549:INFO:python_build: ('default', 'Sep  4 2020 02:22:02')
2023-10-24 11:59:06,549:INFO:machine: x86_64
2023-10-24 11:59:06,549:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-10-24 11:59:06,549:INFO:Memory: svmem(total=8589934592, available=2404024320, percent=72.0, used=4553072640, free=406323200, active=2001207296, inactive=1945350144, wired=2551865344)
2023-10-24 11:59:06,549:INFO:Physical Core: 4
2023-10-24 11:59:06,549:INFO:Logical Core: 8
2023-10-24 11:59:06,549:INFO:Checking libraries
2023-10-24 11:59:06,549:INFO:System:
2023-10-24 11:59:06,549:INFO:    python: 3.8.5 (default, Sep  4 2020, 02:22:02)  [Clang 10.0.0 ]
2023-10-24 11:59:06,549:INFO:executable: /Users/kaja/opt/anaconda3/bin/python
2023-10-24 11:59:06,549:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-10-24 11:59:06,549:INFO:PyCaret required dependencies:
2023-10-24 11:59:06,549:INFO:                 pip: 23.3.1
2023-10-24 11:59:06,549:INFO:          setuptools: 68.2.2
2023-10-24 11:59:06,549:INFO:             pycaret: 3.1.0
2023-10-24 11:59:06,549:INFO:             IPython: 7.19.0
2023-10-24 11:59:06,549:INFO:          ipywidgets: 8.1.1
2023-10-24 11:59:06,550:INFO:                tqdm: 4.66.1
2023-10-24 11:59:06,550:INFO:               numpy: 1.23.5
2023-10-24 11:59:06,550:INFO:              pandas: 1.5.3
2023-10-24 11:59:06,550:INFO:              jinja2: 3.1.2
2023-10-24 11:59:06,550:INFO:               scipy: 1.10.1
2023-10-24 11:59:06,550:INFO:              joblib: 1.3.2
2023-10-24 11:59:06,550:INFO:             sklearn: 1.2.2
2023-10-24 11:59:06,550:INFO:                pyod: 1.1.0
2023-10-24 11:59:06,550:INFO:            imblearn: 0.11.0
2023-10-24 11:59:06,550:INFO:   category_encoders: 2.6.2
2023-10-24 11:59:06,550:INFO:            lightgbm: 4.1.0
2023-10-24 11:59:06,550:INFO:               numba: 0.58.1
2023-10-24 11:59:06,550:INFO:            requests: 2.28.2
2023-10-24 11:59:06,550:INFO:          matplotlib: 3.7.3
2023-10-24 11:59:06,550:INFO:          scikitplot: 0.3.7
2023-10-24 11:59:06,550:INFO:         yellowbrick: 1.5
2023-10-24 11:59:06,550:INFO:              plotly: 5.17.0
2023-10-24 11:59:06,550:INFO:    plotly-resampler: Not installed
2023-10-24 11:59:06,550:INFO:             kaleido: 0.2.1
2023-10-24 11:59:06,550:INFO:           schemdraw: 0.15
2023-10-24 11:59:06,550:INFO:         statsmodels: 0.14.0
2023-10-24 11:59:06,550:INFO:              sktime: 0.21.1
2023-10-24 11:59:06,550:INFO:               tbats: 1.1.3
2023-10-24 11:59:06,550:INFO:            pmdarima: 2.0.4
2023-10-24 11:59:06,550:INFO:              psutil: 5.9.6
2023-10-24 11:59:06,550:INFO:          markupsafe: 2.1.2
2023-10-24 11:59:06,550:INFO:             pickle5: Not installed
2023-10-24 11:59:06,550:INFO:         cloudpickle: 1.6.0
2023-10-24 11:59:06,550:INFO:         deprecation: 2.1.0
2023-10-24 11:59:06,550:INFO:              xxhash: 3.4.1
2023-10-24 11:59:06,551:INFO:           wurlitzer: 2.0.1
2023-10-24 11:59:06,551:INFO:PyCaret optional dependencies:
2023-10-24 11:59:06,551:INFO:                shap: Not installed
2023-10-24 11:59:06,551:INFO:           interpret: Not installed
2023-10-24 11:59:06,551:INFO:                umap: Not installed
2023-10-24 11:59:06,551:INFO:     ydata_profiling: Not installed
2023-10-24 11:59:06,551:INFO:  explainerdashboard: Not installed
2023-10-24 11:59:06,551:INFO:             autoviz: Not installed
2023-10-24 11:59:06,551:INFO:           fairlearn: Not installed
2023-10-24 11:59:06,551:INFO:          deepchecks: Not installed
2023-10-24 11:59:06,551:INFO:             xgboost: Not installed
2023-10-24 11:59:06,551:INFO:            catboost: 1.0.4
2023-10-24 11:59:06,551:INFO:              kmodes: Not installed
2023-10-24 11:59:06,551:INFO:             mlxtend: Not installed
2023-10-24 11:59:06,551:INFO:       statsforecast: Not installed
2023-10-24 11:59:06,551:INFO:        tune_sklearn: Not installed
2023-10-24 11:59:06,551:INFO:                 ray: Not installed
2023-10-24 11:59:06,551:INFO:            hyperopt: Not installed
2023-10-24 11:59:06,551:INFO:              optuna: Not installed
2023-10-24 11:59:06,551:INFO:               skopt: Not installed
2023-10-24 11:59:06,551:INFO:              mlflow: 2.7.1
2023-10-24 11:59:06,551:INFO:              gradio: Not installed
2023-10-24 11:59:06,551:INFO:             fastapi: Not installed
2023-10-24 11:59:06,551:INFO:             uvicorn: Not installed
2023-10-24 11:59:06,551:INFO:              m2cgen: Not installed
2023-10-24 11:59:06,551:INFO:           evidently: Not installed
2023-10-24 11:59:06,551:INFO:               fugue: Not installed
2023-10-24 11:59:06,551:INFO:           streamlit: Not installed
2023-10-24 11:59:06,551:INFO:             prophet: Not installed
2023-10-24 11:59:06,551:INFO:None
2023-10-24 11:59:06,551:INFO:Set up data.
2023-10-24 11:59:06,603:INFO:Set up folding strategy.
2023-10-24 11:59:06,604:INFO:Set up train/test split.
2023-10-24 11:59:06,638:INFO:Set up index.
2023-10-24 11:59:06,640:INFO:Assigning column types.
2023-10-24 11:59:06,657:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 11:59:06,658:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 11:59:06,661:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:59:06,666:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:59:06,727:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:59:06,769:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:59:06,770:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:59:06,770:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:59:06,771:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 11:59:06,775:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:59:06,779:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:59:06,841:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:59:06,882:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:59:06,882:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:59:06,883:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:59:06,883:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 11:59:06,888:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:59:06,893:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:59:06,956:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:59:06,998:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:59:06,999:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:59:06,999:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:59:07,003:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:59:07,007:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:59:07,073:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:59:07,112:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:59:07,113:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:59:07,113:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:59:07,114:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 11:59:07,122:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:59:07,184:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:59:07,225:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:59:07,228:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:59:07,228:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:59:07,237:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:59:07,299:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:59:07,338:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:59:07,339:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:59:07,339:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:59:07,340:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 11:59:07,409:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:59:07,450:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:59:07,450:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:59:07,450:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:59:07,520:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:59:07,561:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:59:07,562:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:59:07,562:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:59:07,563:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 11:59:07,630:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:59:07,671:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:59:07,672:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:59:07,748:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:59:07,787:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:59:07,788:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:59:07,788:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 11:59:07,949:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:59:07,950:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:59:08,074:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:59:08,075:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:59:08,076:INFO:Preparing preprocessing pipeline...
2023-10-24 11:59:08,076:INFO:Set up date feature engineering.
2023-10-24 11:59:08,076:INFO:Set up simple imputation.
2023-10-24 11:59:08,086:INFO:Set up encoding of ordinal features.
2023-10-24 11:59:08,102:INFO:Set up encoding of categorical features.
2023-10-24 11:59:08,104:INFO:Set up column name cleaning.
2023-10-24 11:59:08,362:INFO:Finished creating preprocessing pipeline.
2023-10-24 11:59:08,475:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m'...
NaN   -1
dtype: int64},
                                                                        {'col': 'rime',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 11:59:08,475:INFO:Creating final display dataframe.
2023-10-24 11:59:08,645:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (34061, 52)
4        Transformed data shape  (34061, 55)
5   Transformed train set shape  (23842, 55)
6    Transformed test set shape  (10219, 55)
7              Ordinal features            4
8              Numeric features           44
9                 Date features            3
10         Categorical features            4
11     Rows with missing values        90.5%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18               Fold Generator        KFold
19                  Fold Number           10
20                     CPU Jobs           -1
21                      Use GPU        False
22               Log Experiment        False
23              Experiment Name        exp_A
24                          USI         5940
2023-10-24 11:59:08,787:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:59:08,788:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:59:08,912:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:59:08,912:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:59:08,913:INFO:setup() successfully completed in 2.37s...............
2023-10-24 11:59:08,913:INFO:Initializing create_model()
2023-10-24 11:59:08,913:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9d49b5ea60>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 11:59:08,913:INFO:Checking exceptions
2023-10-24 11:59:08,917:INFO:Importing libraries
2023-10-24 11:59:08,918:INFO:Copying training dataset
2023-10-24 11:59:08,941:INFO:Defining folds
2023-10-24 11:59:08,941:INFO:Declaring metric variables
2023-10-24 11:59:08,941:INFO:Importing untrained model
2023-10-24 11:59:08,942:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 11:59:08,942:INFO:Starting cross validation
2023-10-24 11:59:08,944:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 11:59:13,373:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:59:13,373:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:59:13,373:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:59:13,373:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:59:13,373:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:59:13,373:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:59:13,373:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:59:13,373:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:59:13,373:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:59:13,373:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:59:13,373:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:59:13,373:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:59:13,373:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:59:13,373:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:59:13,373:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:59:13,373:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:59:13,373:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:59:13,373:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:59:13,373:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:59:13,373:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:59:13,373:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:59:13,373:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:59:13,373:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:59:13,373:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 11:59:15,908:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044604 seconds.
2023-10-24 11:59:15,911:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:59:15,911:INFO:[LightGBM] [Info] Total Bins 6561
2023-10-24 11:59:15,915:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 51
2023-10-24 11:59:15,917:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061333 seconds.
2023-10-24 11:59:15,918:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:59:15,918:INFO:[LightGBM] [Info] Total Bins 6547
2023-10-24 11:59:15,922:INFO:[LightGBM] [Info] Number of data points in the train set: 21457, number of used features: 51
2023-10-24 11:59:15,923:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.105504 seconds.
2023-10-24 11:59:15,923:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 11:59:15,923:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 11:59:15,923:INFO:[LightGBM] [Info] Total Bins 6562
2023-10-24 11:59:15,926:INFO:[LightGBM] [Info] Number of data points in the train set: 21457, number of used features: 51
2023-10-24 11:59:15,926:INFO:[LightGBM] [Info] Start training from score 626.835846
2023-10-24 11:59:15,928:INFO:[LightGBM] [Info] Start training from score 626.714401
2023-10-24 11:59:15,935:INFO:[LightGBM] [Info] Start training from score 624.465909
2023-10-24 11:59:15,938:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070472 seconds.
2023-10-24 11:59:15,938:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:59:15,938:INFO:[LightGBM] [Info] Total Bins 6558
2023-10-24 11:59:15,939:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069858 seconds.
2023-10-24 11:59:15,939:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:59:15,939:INFO:[LightGBM] [Info] Total Bins 6557
2023-10-24 11:59:15,941:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 51
2023-10-24 11:59:15,941:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 51
2023-10-24 11:59:15,950:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043612 seconds.
2023-10-24 11:59:15,951:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 11:59:15,951:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 11:59:15,951:INFO:[LightGBM] [Info] Total Bins 6562
2023-10-24 11:59:15,952:INFO:[LightGBM] [Info] Start training from score 631.624808
2023-10-24 11:59:15,952:INFO:[LightGBM] [Info] Start training from score 629.037061
2023-10-24 11:59:15,952:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 51
2023-10-24 11:59:15,963:INFO:[LightGBM] [Info] Start training from score 631.036433
2023-10-24 11:59:15,974:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.094140 seconds.
2023-10-24 11:59:15,974:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:59:15,975:INFO:[LightGBM] [Info] Total Bins 6564
2023-10-24 11:59:15,977:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 51
2023-10-24 11:59:15,978:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062003 seconds.
2023-10-24 11:59:15,978:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 11:59:15,978:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 11:59:15,978:INFO:[LightGBM] [Info] Total Bins 6556
2023-10-24 11:59:15,983:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 51
2023-10-24 11:59:15,985:INFO:[LightGBM] [Info] Start training from score 627.582936
2023-10-24 11:59:15,988:INFO:[LightGBM] [Info] Start training from score 629.291796
2023-10-24 11:59:23,526:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025175 seconds.
2023-10-24 11:59:23,535:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 11:59:23,535:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 11:59:23,535:INFO:[LightGBM] [Info] Total Bins 6551
2023-10-24 11:59:23,535:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 51
2023-10-24 11:59:23,535:INFO:[LightGBM] [Info] Start training from score 620.705419
2023-10-24 11:59:23,542:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034078 seconds.
2023-10-24 11:59:23,542:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:59:23,542:INFO:[LightGBM] [Info] Total Bins 6567
2023-10-24 11:59:23,543:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 51
2023-10-24 11:59:23,545:INFO:[LightGBM] [Info] Start training from score 633.990557
2023-10-24 11:59:25,214:INFO:Calculating mean and std
2023-10-24 11:59:25,223:INFO:Creating metrics dataframe
2023-10-24 11:59:25,235:INFO:Finalizing model
2023-10-24 11:59:25,569:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006991 seconds.
2023-10-24 11:59:25,569:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:59:25,569:INFO:[LightGBM] [Info] Total Bins 6584
2023-10-24 11:59:25,570:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 51
2023-10-24 11:59:25,570:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-24 11:59:25,763:INFO:Uploading results into container
2023-10-24 11:59:25,764:INFO:Uploading model into container now
2023-10-24 11:59:25,771:INFO:_master_model_container: 1
2023-10-24 11:59:25,771:INFO:_display_container: 2
2023-10-24 11:59:25,772:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 11:59:25,772:INFO:create_model() successfully completed......................................
2023-10-24 11:59:26,119:INFO:Initializing finalize_model()
2023-10-24 11:59:26,119:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9d49b5ea60>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-24 11:59:26,120:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 11:59:26,150:INFO:Initializing create_model()
2023-10-24 11:59:26,150:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9d49b5ea60>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-24 11:59:26,150:INFO:Checking exceptions
2023-10-24 11:59:26,151:INFO:Importing libraries
2023-10-24 11:59:26,151:INFO:Copying training dataset
2023-10-24 11:59:26,152:INFO:Defining folds
2023-10-24 11:59:26,152:INFO:Declaring metric variables
2023-10-24 11:59:26,153:INFO:Importing untrained model
2023-10-24 11:59:26,153:INFO:Declaring custom model
2023-10-24 11:59:26,154:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 11:59:26,156:INFO:Cross validation set to False
2023-10-24 11:59:26,156:INFO:Fitting Model
2023-10-24 11:59:26,572:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009953 seconds.
2023-10-24 11:59:26,572:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:59:26,572:INFO:[LightGBM] [Info] Total Bins 6699
2023-10-24 11:59:26,573:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 51
2023-10-24 11:59:26,574:INFO:[LightGBM] [Info] Start training from score 631.011165
2023-10-24 11:59:26,907:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_...
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 11:59:26,908:INFO:create_model() successfully completed......................................
2023-10-24 11:59:26,997:INFO:_master_model_container: 1
2023-10-24 11:59:26,997:INFO:_display_container: 2
2023-10-24 11:59:27,087:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_...
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 11:59:27,087:INFO:finalize_model() successfully completed......................................
2023-10-24 11:59:27,422:INFO:Initializing save_model()
2023-10-24 11:59:27,422:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_...
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_A, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m'...
NaN   -1
dtype: int64},
                                                                        {'col': 'rime',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-24 11:59:27,422:INFO:Adding model into prep_pipe
2023-10-24 11:59:27,422:WARNING:Only Model saved as it was a pipeline.
2023-10-24 11:59:27,436:INFO:final_model_for_location_A.pkl saved in current working directory
2023-10-24 11:59:27,550:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_...
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 11:59:27,550:INFO:save_model() successfully completed......................................
2023-10-24 11:59:27,668:INFO:PyCaret RegressionExperiment
2023-10-24 11:59:27,668:INFO:Logging name: exp_B
2023-10-24 11:59:27,668:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 11:59:27,668:INFO:version 3.1.0
2023-10-24 11:59:27,668:INFO:Initializing setup()
2023-10-24 11:59:27,668:INFO:self.USI: bd5a
2023-10-24 11:59:27,668:INFO:self._variable_keys: {'exp_id', 'target_param', 'USI', 'data', 'fold_shuffle_param', 'log_plots_param', 'X_test', 'memory', 'idx', 'y', 'X', 'X_train', 'gpu_n_jobs_param', 'n_jobs_param', 'gpu_param', 'logging_param', 'fold_generator', 'pipeline', 'y_test', 'y_train', '_ml_usecase', '_available_plots', 'html_param', 'exp_name_log', 'transform_target_param', 'seed', 'fold_groups_param'}
2023-10-24 11:59:27,668:INFO:Checking environment
2023-10-24 11:59:27,668:INFO:python_version: 3.8.5
2023-10-24 11:59:27,668:INFO:python_build: ('default', 'Sep  4 2020 02:22:02')
2023-10-24 11:59:27,668:INFO:machine: x86_64
2023-10-24 11:59:27,668:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-10-24 11:59:27,668:INFO:Memory: svmem(total=8589934592, available=2828292096, percent=67.1, used=4328071168, free=813170688, active=2018332672, inactive=1991897088, wired=2309738496)
2023-10-24 11:59:27,668:INFO:Physical Core: 4
2023-10-24 11:59:27,668:INFO:Logical Core: 8
2023-10-24 11:59:27,668:INFO:Checking libraries
2023-10-24 11:59:27,669:INFO:System:
2023-10-24 11:59:27,669:INFO:    python: 3.8.5 (default, Sep  4 2020, 02:22:02)  [Clang 10.0.0 ]
2023-10-24 11:59:27,669:INFO:executable: /Users/kaja/opt/anaconda3/bin/python
2023-10-24 11:59:27,669:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-10-24 11:59:27,669:INFO:PyCaret required dependencies:
2023-10-24 11:59:27,669:INFO:                 pip: 23.3.1
2023-10-24 11:59:27,669:INFO:          setuptools: 68.2.2
2023-10-24 11:59:27,669:INFO:             pycaret: 3.1.0
2023-10-24 11:59:27,669:INFO:             IPython: 7.19.0
2023-10-24 11:59:27,669:INFO:          ipywidgets: 8.1.1
2023-10-24 11:59:27,669:INFO:                tqdm: 4.66.1
2023-10-24 11:59:27,669:INFO:               numpy: 1.23.5
2023-10-24 11:59:27,669:INFO:              pandas: 1.5.3
2023-10-24 11:59:27,669:INFO:              jinja2: 3.1.2
2023-10-24 11:59:27,669:INFO:               scipy: 1.10.1
2023-10-24 11:59:27,669:INFO:              joblib: 1.3.2
2023-10-24 11:59:27,669:INFO:             sklearn: 1.2.2
2023-10-24 11:59:27,669:INFO:                pyod: 1.1.0
2023-10-24 11:59:27,669:INFO:            imblearn: 0.11.0
2023-10-24 11:59:27,669:INFO:   category_encoders: 2.6.2
2023-10-24 11:59:27,669:INFO:            lightgbm: 4.1.0
2023-10-24 11:59:27,669:INFO:               numba: 0.58.1
2023-10-24 11:59:27,669:INFO:            requests: 2.28.2
2023-10-24 11:59:27,669:INFO:          matplotlib: 3.7.3
2023-10-24 11:59:27,670:INFO:          scikitplot: 0.3.7
2023-10-24 11:59:27,670:INFO:         yellowbrick: 1.5
2023-10-24 11:59:27,670:INFO:              plotly: 5.17.0
2023-10-24 11:59:27,670:INFO:    plotly-resampler: Not installed
2023-10-24 11:59:27,670:INFO:             kaleido: 0.2.1
2023-10-24 11:59:27,670:INFO:           schemdraw: 0.15
2023-10-24 11:59:27,670:INFO:         statsmodels: 0.14.0
2023-10-24 11:59:27,670:INFO:              sktime: 0.21.1
2023-10-24 11:59:27,670:INFO:               tbats: 1.1.3
2023-10-24 11:59:27,670:INFO:            pmdarima: 2.0.4
2023-10-24 11:59:27,670:INFO:              psutil: 5.9.6
2023-10-24 11:59:27,670:INFO:          markupsafe: 2.1.2
2023-10-24 11:59:27,670:INFO:             pickle5: Not installed
2023-10-24 11:59:27,670:INFO:         cloudpickle: 1.6.0
2023-10-24 11:59:27,670:INFO:         deprecation: 2.1.0
2023-10-24 11:59:27,670:INFO:              xxhash: 3.4.1
2023-10-24 11:59:27,670:INFO:           wurlitzer: 2.0.1
2023-10-24 11:59:27,670:INFO:PyCaret optional dependencies:
2023-10-24 11:59:27,670:INFO:                shap: Not installed
2023-10-24 11:59:27,670:INFO:           interpret: Not installed
2023-10-24 11:59:27,670:INFO:                umap: Not installed
2023-10-24 11:59:27,670:INFO:     ydata_profiling: Not installed
2023-10-24 11:59:27,670:INFO:  explainerdashboard: Not installed
2023-10-24 11:59:27,670:INFO:             autoviz: Not installed
2023-10-24 11:59:27,670:INFO:           fairlearn: Not installed
2023-10-24 11:59:27,670:INFO:          deepchecks: Not installed
2023-10-24 11:59:27,671:INFO:             xgboost: Not installed
2023-10-24 11:59:27,671:INFO:            catboost: 1.0.4
2023-10-24 11:59:27,671:INFO:              kmodes: Not installed
2023-10-24 11:59:27,671:INFO:             mlxtend: Not installed
2023-10-24 11:59:27,671:INFO:       statsforecast: Not installed
2023-10-24 11:59:27,671:INFO:        tune_sklearn: Not installed
2023-10-24 11:59:27,671:INFO:                 ray: Not installed
2023-10-24 11:59:27,671:INFO:            hyperopt: Not installed
2023-10-24 11:59:27,671:INFO:              optuna: Not installed
2023-10-24 11:59:27,671:INFO:               skopt: Not installed
2023-10-24 11:59:27,671:INFO:              mlflow: 2.7.1
2023-10-24 11:59:27,671:INFO:              gradio: Not installed
2023-10-24 11:59:27,671:INFO:             fastapi: Not installed
2023-10-24 11:59:27,671:INFO:             uvicorn: Not installed
2023-10-24 11:59:27,671:INFO:              m2cgen: Not installed
2023-10-24 11:59:27,671:INFO:           evidently: Not installed
2023-10-24 11:59:27,671:INFO:               fugue: Not installed
2023-10-24 11:59:27,671:INFO:           streamlit: Not installed
2023-10-24 11:59:27,671:INFO:             prophet: Not installed
2023-10-24 11:59:27,671:INFO:None
2023-10-24 11:59:27,671:INFO:Set up data.
2023-10-24 11:59:27,712:INFO:Set up folding strategy.
2023-10-24 11:59:27,712:INFO:Set up train/test split.
2023-10-24 11:59:27,742:INFO:Set up index.
2023-10-24 11:59:27,743:INFO:Assigning column types.
2023-10-24 11:59:27,759:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 11:59:27,759:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 11:59:27,763:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:59:27,767:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:59:27,830:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:59:27,871:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:59:27,872:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:59:27,872:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:59:27,873:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 11:59:27,877:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:59:27,882:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:59:27,946:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:59:27,990:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:59:27,991:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:59:27,991:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:59:27,991:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 11:59:27,995:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:59:27,999:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:59:28,061:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:59:28,101:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:59:28,101:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:59:28,101:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:59:28,106:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:59:28,109:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:59:28,171:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:59:28,212:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:59:28,212:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:59:28,212:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:59:28,213:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 11:59:28,223:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:59:28,286:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:59:28,329:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:59:28,330:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:59:28,331:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:59:28,342:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:59:28,407:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:59:28,448:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:59:28,449:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:59:28,449:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:59:28,449:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 11:59:28,519:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:59:28,559:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:59:28,560:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:59:28,560:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:59:28,630:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:59:28,672:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:59:28,672:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:59:28,673:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:59:28,674:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 11:59:28,774:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:59:28,833:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:59:28,834:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:59:28,937:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:59:28,985:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:59:28,986:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:59:28,986:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 11:59:29,100:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:59:29,100:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:59:29,220:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:59:29,220:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:59:29,221:INFO:Preparing preprocessing pipeline...
2023-10-24 11:59:29,221:INFO:Set up date feature engineering.
2023-10-24 11:59:29,221:INFO:Set up simple imputation.
2023-10-24 11:59:29,235:INFO:Set up encoding of ordinal features.
2023-10-24 11:59:29,259:INFO:Set up encoding of categorical features.
2023-10-24 11:59:29,262:INFO:Set up column name cleaning.
2023-10-24 11:59:29,509:INFO:Finished creating preprocessing pipeline.
2023-10-24 11:59:29,599:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m'...
NaN   -1
dtype: int64},
                                                                        {'col': 'rime',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 11:59:29,599:INFO:Creating final display dataframe.
2023-10-24 11:59:30,222:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (32819, 52)
4        Transformed data shape  (32819, 55)
5   Transformed train set shape  (22973, 55)
6    Transformed test set shape   (9846, 55)
7              Ordinal features            4
8              Numeric features           44
9                 Date features            3
10         Categorical features            4
11     Rows with missing values        91.9%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18               Fold Generator        KFold
19                  Fold Number           10
20                     CPU Jobs           -1
21                      Use GPU        False
22               Log Experiment        False
23              Experiment Name        exp_B
24                          USI         bd5a
2023-10-24 11:59:30,337:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:59:30,337:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:59:30,444:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:59:30,444:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:59:30,445:INFO:setup() successfully completed in 2.78s...............
2023-10-24 11:59:30,445:INFO:Initializing create_model()
2023-10-24 11:59:30,445:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9d4aa9ed30>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 11:59:30,445:INFO:Checking exceptions
2023-10-24 11:59:30,450:INFO:Importing libraries
2023-10-24 11:59:30,450:INFO:Copying training dataset
2023-10-24 11:59:30,468:INFO:Defining folds
2023-10-24 11:59:30,468:INFO:Declaring metric variables
2023-10-24 11:59:30,468:INFO:Importing untrained model
2023-10-24 11:59:30,469:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 11:59:30,469:INFO:Starting cross validation
2023-10-24 11:59:30,471:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 11:59:40,230:INFO:Calculating mean and std
2023-10-24 11:59:40,233:INFO:Creating metrics dataframe
2023-10-24 11:59:40,236:INFO:Finalizing model
2023-10-24 11:59:40,548:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006636 seconds.
2023-10-24 11:59:40,548:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:59:40,549:INFO:[LightGBM] [Info] Total Bins 6568
2023-10-24 11:59:40,549:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 51
2023-10-24 11:59:40,550:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-24 11:59:40,748:INFO:Uploading results into container
2023-10-24 11:59:40,749:INFO:Uploading model into container now
2023-10-24 11:59:40,754:INFO:_master_model_container: 1
2023-10-24 11:59:40,755:INFO:_display_container: 2
2023-10-24 11:59:40,755:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 11:59:40,756:INFO:create_model() successfully completed......................................
2023-10-24 11:59:40,856:INFO:Initializing finalize_model()
2023-10-24 11:59:40,856:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9d4aa9ed30>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-24 11:59:40,857:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 11:59:40,877:INFO:Initializing create_model()
2023-10-24 11:59:40,877:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9d4aa9ed30>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-24 11:59:40,878:INFO:Checking exceptions
2023-10-24 11:59:40,879:INFO:Importing libraries
2023-10-24 11:59:40,879:INFO:Copying training dataset
2023-10-24 11:59:40,881:INFO:Defining folds
2023-10-24 11:59:40,881:INFO:Declaring metric variables
2023-10-24 11:59:40,881:INFO:Importing untrained model
2023-10-24 11:59:40,881:INFO:Declaring custom model
2023-10-24 11:59:40,882:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 11:59:40,884:INFO:Cross validation set to False
2023-10-24 11:59:40,884:INFO:Fitting Model
2023-10-24 11:59:41,296:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009258 seconds.
2023-10-24 11:59:41,296:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:59:41,296:INFO:[LightGBM] [Info] Total Bins 6646
2023-10-24 11:59:41,297:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 51
2023-10-24 11:59:41,298:INFO:[LightGBM] [Info] Start training from score 96.893335
2023-10-24 11:59:41,633:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_...
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 11:59:41,633:INFO:create_model() successfully completed......................................
2023-10-24 11:59:41,725:INFO:_master_model_container: 1
2023-10-24 11:59:41,725:INFO:_display_container: 2
2023-10-24 11:59:41,821:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_...
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 11:59:41,821:INFO:finalize_model() successfully completed......................................
2023-10-24 11:59:42,098:INFO:Initializing save_model()
2023-10-24 11:59:42,098:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_...
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_B, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m'...
NaN   -1
dtype: int64},
                                                                        {'col': 'rime',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-24 11:59:42,098:INFO:Adding model into prep_pipe
2023-10-24 11:59:42,098:WARNING:Only Model saved as it was a pipeline.
2023-10-24 11:59:42,108:INFO:final_model_for_location_B.pkl saved in current working directory
2023-10-24 11:59:42,269:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_...
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 11:59:42,269:INFO:save_model() successfully completed......................................
2023-10-24 11:59:42,387:INFO:PyCaret RegressionExperiment
2023-10-24 11:59:42,387:INFO:Logging name: exp_C
2023-10-24 11:59:42,388:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 11:59:42,388:INFO:version 3.1.0
2023-10-24 11:59:42,388:INFO:Initializing setup()
2023-10-24 11:59:42,388:INFO:self.USI: a693
2023-10-24 11:59:42,388:INFO:self._variable_keys: {'exp_id', 'target_param', 'USI', 'data', 'fold_shuffle_param', 'log_plots_param', 'X_test', 'memory', 'idx', 'y', 'X', 'X_train', 'gpu_n_jobs_param', 'n_jobs_param', 'gpu_param', 'logging_param', 'fold_generator', 'pipeline', 'y_test', 'y_train', '_ml_usecase', '_available_plots', 'html_param', 'exp_name_log', 'transform_target_param', 'seed', 'fold_groups_param'}
2023-10-24 11:59:42,389:INFO:Checking environment
2023-10-24 11:59:42,389:INFO:python_version: 3.8.5
2023-10-24 11:59:42,389:INFO:python_build: ('default', 'Sep  4 2020 02:22:02')
2023-10-24 11:59:42,389:INFO:machine: x86_64
2023-10-24 11:59:42,389:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-10-24 11:59:42,389:INFO:Memory: svmem(total=8589934592, available=2776850432, percent=67.7, used=4465528832, free=575016960, active=2204282880, inactive=2192314368, wired=2261245952)
2023-10-24 11:59:42,389:INFO:Physical Core: 4
2023-10-24 11:59:42,389:INFO:Logical Core: 8
2023-10-24 11:59:42,390:INFO:Checking libraries
2023-10-24 11:59:42,390:INFO:System:
2023-10-24 11:59:42,390:INFO:    python: 3.8.5 (default, Sep  4 2020, 02:22:02)  [Clang 10.0.0 ]
2023-10-24 11:59:42,390:INFO:executable: /Users/kaja/opt/anaconda3/bin/python
2023-10-24 11:59:42,390:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-10-24 11:59:42,390:INFO:PyCaret required dependencies:
2023-10-24 11:59:42,390:INFO:                 pip: 23.3.1
2023-10-24 11:59:42,390:INFO:          setuptools: 68.2.2
2023-10-24 11:59:42,390:INFO:             pycaret: 3.1.0
2023-10-24 11:59:42,390:INFO:             IPython: 7.19.0
2023-10-24 11:59:42,390:INFO:          ipywidgets: 8.1.1
2023-10-24 11:59:42,390:INFO:                tqdm: 4.66.1
2023-10-24 11:59:42,390:INFO:               numpy: 1.23.5
2023-10-24 11:59:42,390:INFO:              pandas: 1.5.3
2023-10-24 11:59:42,390:INFO:              jinja2: 3.1.2
2023-10-24 11:59:42,390:INFO:               scipy: 1.10.1
2023-10-24 11:59:42,390:INFO:              joblib: 1.3.2
2023-10-24 11:59:42,390:INFO:             sklearn: 1.2.2
2023-10-24 11:59:42,390:INFO:                pyod: 1.1.0
2023-10-24 11:59:42,391:INFO:            imblearn: 0.11.0
2023-10-24 11:59:42,391:INFO:   category_encoders: 2.6.2
2023-10-24 11:59:42,391:INFO:            lightgbm: 4.1.0
2023-10-24 11:59:42,391:INFO:               numba: 0.58.1
2023-10-24 11:59:42,391:INFO:            requests: 2.28.2
2023-10-24 11:59:42,391:INFO:          matplotlib: 3.7.3
2023-10-24 11:59:42,391:INFO:          scikitplot: 0.3.7
2023-10-24 11:59:42,391:INFO:         yellowbrick: 1.5
2023-10-24 11:59:42,391:INFO:              plotly: 5.17.0
2023-10-24 11:59:42,391:INFO:    plotly-resampler: Not installed
2023-10-24 11:59:42,391:INFO:             kaleido: 0.2.1
2023-10-24 11:59:42,391:INFO:           schemdraw: 0.15
2023-10-24 11:59:42,391:INFO:         statsmodels: 0.14.0
2023-10-24 11:59:42,391:INFO:              sktime: 0.21.1
2023-10-24 11:59:42,391:INFO:               tbats: 1.1.3
2023-10-24 11:59:42,391:INFO:            pmdarima: 2.0.4
2023-10-24 11:59:42,391:INFO:              psutil: 5.9.6
2023-10-24 11:59:42,391:INFO:          markupsafe: 2.1.2
2023-10-24 11:59:42,391:INFO:             pickle5: Not installed
2023-10-24 11:59:42,391:INFO:         cloudpickle: 1.6.0
2023-10-24 11:59:42,391:INFO:         deprecation: 2.1.0
2023-10-24 11:59:42,391:INFO:              xxhash: 3.4.1
2023-10-24 11:59:42,391:INFO:           wurlitzer: 2.0.1
2023-10-24 11:59:42,391:INFO:PyCaret optional dependencies:
2023-10-24 11:59:42,392:INFO:                shap: Not installed
2023-10-24 11:59:42,392:INFO:           interpret: Not installed
2023-10-24 11:59:42,392:INFO:                umap: Not installed
2023-10-24 11:59:42,392:INFO:     ydata_profiling: Not installed
2023-10-24 11:59:42,392:INFO:  explainerdashboard: Not installed
2023-10-24 11:59:42,392:INFO:             autoviz: Not installed
2023-10-24 11:59:42,392:INFO:           fairlearn: Not installed
2023-10-24 11:59:42,392:INFO:          deepchecks: Not installed
2023-10-24 11:59:42,392:INFO:             xgboost: Not installed
2023-10-24 11:59:42,392:INFO:            catboost: 1.0.4
2023-10-24 11:59:42,392:INFO:              kmodes: Not installed
2023-10-24 11:59:42,392:INFO:             mlxtend: Not installed
2023-10-24 11:59:42,392:INFO:       statsforecast: Not installed
2023-10-24 11:59:42,392:INFO:        tune_sklearn: Not installed
2023-10-24 11:59:42,392:INFO:                 ray: Not installed
2023-10-24 11:59:42,392:INFO:            hyperopt: Not installed
2023-10-24 11:59:42,392:INFO:              optuna: Not installed
2023-10-24 11:59:42,392:INFO:               skopt: Not installed
2023-10-24 11:59:42,392:INFO:              mlflow: 2.7.1
2023-10-24 11:59:42,392:INFO:              gradio: Not installed
2023-10-24 11:59:42,393:INFO:             fastapi: Not installed
2023-10-24 11:59:42,393:INFO:             uvicorn: Not installed
2023-10-24 11:59:42,393:INFO:              m2cgen: Not installed
2023-10-24 11:59:42,393:INFO:           evidently: Not installed
2023-10-24 11:59:42,393:INFO:               fugue: Not installed
2023-10-24 11:59:42,393:INFO:           streamlit: Not installed
2023-10-24 11:59:42,393:INFO:             prophet: Not installed
2023-10-24 11:59:42,393:INFO:None
2023-10-24 11:59:42,393:INFO:Set up data.
2023-10-24 11:59:42,426:INFO:Set up folding strategy.
2023-10-24 11:59:42,426:INFO:Set up train/test split.
2023-10-24 11:59:42,448:INFO:Set up index.
2023-10-24 11:59:42,450:INFO:Assigning column types.
2023-10-24 11:59:42,462:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 11:59:42,462:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 11:59:42,466:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:59:42,470:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:59:42,531:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:59:42,573:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:59:42,574:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:59:42,574:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:59:42,574:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 11:59:42,578:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:59:42,583:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:59:42,641:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:59:42,679:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:59:42,680:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:59:42,680:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:59:42,680:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 11:59:42,685:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:59:42,689:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:59:42,746:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:59:42,785:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:59:42,786:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:59:42,786:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:59:42,790:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 11:59:42,794:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:59:42,851:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:59:42,891:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:59:42,892:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:59:42,892:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:59:42,893:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 11:59:42,902:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:59:42,962:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:59:43,008:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:59:43,009:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:59:43,009:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:59:43,019:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 11:59:43,081:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:59:43,125:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:59:43,126:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:59:43,126:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:59:43,126:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 11:59:43,196:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:59:43,237:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:59:43,238:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:59:43,238:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:59:43,311:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:59:43,353:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 11:59:43,354:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:59:43,354:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:59:43,355:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 11:59:43,428:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:59:43,487:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:59:43,487:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:59:43,643:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 11:59:43,693:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:59:43,694:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:59:43,694:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 11:59:43,821:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:59:43,821:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:59:43,955:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:59:43,955:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:59:43,957:INFO:Preparing preprocessing pipeline...
2023-10-24 11:59:43,957:INFO:Set up date feature engineering.
2023-10-24 11:59:43,957:INFO:Set up simple imputation.
2023-10-24 11:59:43,970:INFO:Set up encoding of ordinal features.
2023-10-24 11:59:43,990:INFO:Set up encoding of categorical features.
2023-10-24 11:59:43,992:INFO:Set up column name cleaning.
2023-10-24 11:59:44,205:INFO:Finished creating preprocessing pipeline.
2023-10-24 11:59:44,300:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m'...
NaN   -1
dtype: int64},
                                                                        {'col': 'rime',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 11:59:44,300:INFO:Creating final display dataframe.
2023-10-24 11:59:44,847:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (26071, 52)
4        Transformed data shape  (26071, 55)
5   Transformed train set shape  (18249, 55)
6    Transformed test set shape   (7822, 55)
7              Ordinal features            4
8              Numeric features           44
9                 Date features            3
10         Categorical features            4
11     Rows with missing values        92.4%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18               Fold Generator        KFold
19                  Fold Number           10
20                     CPU Jobs           -1
21                      Use GPU        False
22               Log Experiment        False
23              Experiment Name        exp_C
24                          USI         a693
2023-10-24 11:59:44,964:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:59:44,965:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:59:45,096:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 11:59:45,096:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 11:59:45,097:INFO:setup() successfully completed in 2.71s...............
2023-10-24 11:59:45,097:INFO:Initializing create_model()
2023-10-24 11:59:45,097:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dd6d8a2b0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 11:59:45,097:INFO:Checking exceptions
2023-10-24 11:59:45,103:INFO:Importing libraries
2023-10-24 11:59:45,104:INFO:Copying training dataset
2023-10-24 11:59:45,126:INFO:Defining folds
2023-10-24 11:59:45,126:INFO:Declaring metric variables
2023-10-24 11:59:45,126:INFO:Importing untrained model
2023-10-24 11:59:45,127:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 11:59:45,127:INFO:Starting cross validation
2023-10-24 11:59:45,128:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 11:59:54,866:INFO:Calculating mean and std
2023-10-24 11:59:54,869:INFO:Creating metrics dataframe
2023-10-24 11:59:54,872:INFO:Finalizing model
2023-10-24 11:59:55,183:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007637 seconds.
2023-10-24 11:59:55,183:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:59:55,183:INFO:[LightGBM] [Info] Total Bins 6777
2023-10-24 11:59:55,184:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 52
2023-10-24 11:59:55,185:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-24 11:59:55,529:INFO:Uploading results into container
2023-10-24 11:59:55,531:INFO:Uploading model into container now
2023-10-24 11:59:55,539:INFO:_master_model_container: 1
2023-10-24 11:59:55,539:INFO:_display_container: 2
2023-10-24 11:59:55,540:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 11:59:55,540:INFO:create_model() successfully completed......................................
2023-10-24 11:59:55,646:INFO:Initializing finalize_model()
2023-10-24 11:59:55,646:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dd6d8a2b0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-24 11:59:55,647:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 11:59:55,663:INFO:Initializing create_model()
2023-10-24 11:59:55,663:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dd6d8a2b0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-24 11:59:55,663:INFO:Checking exceptions
2023-10-24 11:59:55,664:INFO:Importing libraries
2023-10-24 11:59:55,665:INFO:Copying training dataset
2023-10-24 11:59:55,666:INFO:Defining folds
2023-10-24 11:59:55,666:INFO:Declaring metric variables
2023-10-24 11:59:55,666:INFO:Importing untrained model
2023-10-24 11:59:55,666:INFO:Declaring custom model
2023-10-24 11:59:55,667:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 11:59:55,669:INFO:Cross validation set to False
2023-10-24 11:59:55,669:INFO:Fitting Model
2023-10-24 11:59:56,019:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008389 seconds.
2023-10-24 11:59:56,019:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 11:59:56,019:INFO:[LightGBM] [Info] Total Bins 6851
2023-10-24 11:59:56,020:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 52
2023-10-24 11:59:56,020:INFO:[LightGBM] [Info] Start training from score 77.700043
2023-10-24 11:59:56,362:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_...
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 11:59:56,362:INFO:create_model() successfully completed......................................
2023-10-24 11:59:56,459:INFO:_master_model_container: 1
2023-10-24 11:59:56,459:INFO:_display_container: 2
2023-10-24 11:59:56,567:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_...
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 11:59:56,567:INFO:finalize_model() successfully completed......................................
2023-10-24 11:59:56,870:INFO:Initializing save_model()
2023-10-24 11:59:56,870:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_...
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_C, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m'...
NaN   -1
dtype: int64},
                                                                        {'col': 'rime',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-24 11:59:56,870:INFO:Adding model into prep_pipe
2023-10-24 11:59:56,870:WARNING:Only Model saved as it was a pipeline.
2023-10-24 11:59:56,882:INFO:final_model_for_location_C.pkl saved in current working directory
2023-10-24 11:59:57,047:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_...
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 11:59:57,047:INFO:save_model() successfully completed......................................
2023-10-24 12:00:31,110:INFO:Initializing load_model()
2023-10-24 12:00:31,111:INFO:load_model(model_name=final_model_for_location_A, platform=None, authentication=None, verbose=True)
2023-10-24 12:00:31,121:INFO:Initializing load_model()
2023-10-24 12:00:31,121:INFO:load_model(model_name=final_model_for_location_B, platform=None, authentication=None, verbose=True)
2023-10-24 12:00:31,129:INFO:Initializing load_model()
2023-10-24 12:00:31,129:INFO:load_model(model_name=final_model_for_location_C, platform=None, authentication=None, verbose=True)
2023-10-24 12:00:31,250:INFO:Initializing predict_model()
2023-10-24 12:00:31,250:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dd6d8a2b0>, estimator=Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc',
                                             'time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m'...
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f9dcd274820>)
2023-10-24 12:00:31,250:INFO:Checking exceptions
2023-10-24 12:00:31,250:INFO:Preloading libraries
2023-10-24 12:00:31,250:INFO:Set up data.
2023-10-24 12:00:31,266:INFO:Set up index.
2023-10-24 12:01:58,210:INFO:PyCaret RegressionExperiment
2023-10-24 12:01:58,210:INFO:Logging name: exp_A
2023-10-24 12:01:58,210:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 12:01:58,211:INFO:version 3.1.0
2023-10-24 12:01:58,211:INFO:Initializing setup()
2023-10-24 12:01:58,211:INFO:self.USI: c76d
2023-10-24 12:01:58,211:INFO:self._variable_keys: {'exp_id', 'target_param', 'USI', 'data', 'fold_shuffle_param', 'log_plots_param', 'X_test', 'memory', 'idx', 'y', 'X', 'X_train', 'gpu_n_jobs_param', 'n_jobs_param', 'gpu_param', 'logging_param', 'fold_generator', 'pipeline', 'y_test', 'y_train', '_ml_usecase', '_available_plots', 'html_param', 'exp_name_log', 'transform_target_param', 'seed', 'fold_groups_param'}
2023-10-24 12:01:58,211:INFO:Checking environment
2023-10-24 12:01:58,211:INFO:python_version: 3.8.5
2023-10-24 12:01:58,211:INFO:python_build: ('default', 'Sep  4 2020 02:22:02')
2023-10-24 12:01:58,211:INFO:machine: x86_64
2023-10-24 12:01:58,211:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-10-24 12:01:58,211:INFO:Memory: svmem(total=8589934592, available=2205917184, percent=74.3, used=4482904064, free=109965312, active=2103595008, inactive=2091651072, wired=2379309056)
2023-10-24 12:01:58,211:INFO:Physical Core: 4
2023-10-24 12:01:58,211:INFO:Logical Core: 8
2023-10-24 12:01:58,211:INFO:Checking libraries
2023-10-24 12:01:58,212:INFO:System:
2023-10-24 12:01:58,212:INFO:    python: 3.8.5 (default, Sep  4 2020, 02:22:02)  [Clang 10.0.0 ]
2023-10-24 12:01:58,212:INFO:executable: /Users/kaja/opt/anaconda3/bin/python
2023-10-24 12:01:58,212:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-10-24 12:01:58,212:INFO:PyCaret required dependencies:
2023-10-24 12:01:58,212:INFO:                 pip: 23.3.1
2023-10-24 12:01:58,212:INFO:          setuptools: 68.2.2
2023-10-24 12:01:58,212:INFO:             pycaret: 3.1.0
2023-10-24 12:01:58,212:INFO:             IPython: 7.19.0
2023-10-24 12:01:58,212:INFO:          ipywidgets: 8.1.1
2023-10-24 12:01:58,212:INFO:                tqdm: 4.66.1
2023-10-24 12:01:58,212:INFO:               numpy: 1.23.5
2023-10-24 12:01:58,212:INFO:              pandas: 1.5.3
2023-10-24 12:01:58,212:INFO:              jinja2: 3.1.2
2023-10-24 12:01:58,213:INFO:               scipy: 1.10.1
2023-10-24 12:01:58,213:INFO:              joblib: 1.3.2
2023-10-24 12:01:58,213:INFO:             sklearn: 1.2.2
2023-10-24 12:01:58,213:INFO:                pyod: 1.1.0
2023-10-24 12:01:58,213:INFO:            imblearn: 0.11.0
2023-10-24 12:01:58,213:INFO:   category_encoders: 2.6.2
2023-10-24 12:01:58,213:INFO:            lightgbm: 4.1.0
2023-10-24 12:01:58,213:INFO:               numba: 0.58.1
2023-10-24 12:01:58,213:INFO:            requests: 2.28.2
2023-10-24 12:01:58,213:INFO:          matplotlib: 3.7.3
2023-10-24 12:01:58,213:INFO:          scikitplot: 0.3.7
2023-10-24 12:01:58,213:INFO:         yellowbrick: 1.5
2023-10-24 12:01:58,213:INFO:              plotly: 5.17.0
2023-10-24 12:01:58,213:INFO:    plotly-resampler: Not installed
2023-10-24 12:01:58,213:INFO:             kaleido: 0.2.1
2023-10-24 12:01:58,213:INFO:           schemdraw: 0.15
2023-10-24 12:01:58,213:INFO:         statsmodels: 0.14.0
2023-10-24 12:01:58,213:INFO:              sktime: 0.21.1
2023-10-24 12:01:58,213:INFO:               tbats: 1.1.3
2023-10-24 12:01:58,213:INFO:            pmdarima: 2.0.4
2023-10-24 12:01:58,213:INFO:              psutil: 5.9.6
2023-10-24 12:01:58,213:INFO:          markupsafe: 2.1.2
2023-10-24 12:01:58,213:INFO:             pickle5: Not installed
2023-10-24 12:01:58,213:INFO:         cloudpickle: 1.6.0
2023-10-24 12:01:58,213:INFO:         deprecation: 2.1.0
2023-10-24 12:01:58,213:INFO:              xxhash: 3.4.1
2023-10-24 12:01:58,213:INFO:           wurlitzer: 2.0.1
2023-10-24 12:01:58,213:INFO:PyCaret optional dependencies:
2023-10-24 12:01:58,214:INFO:                shap: Not installed
2023-10-24 12:01:58,214:INFO:           interpret: Not installed
2023-10-24 12:01:58,214:INFO:                umap: Not installed
2023-10-24 12:01:58,214:INFO:     ydata_profiling: Not installed
2023-10-24 12:01:58,214:INFO:  explainerdashboard: Not installed
2023-10-24 12:01:58,214:INFO:             autoviz: Not installed
2023-10-24 12:01:58,214:INFO:           fairlearn: Not installed
2023-10-24 12:01:58,214:INFO:          deepchecks: Not installed
2023-10-24 12:01:58,214:INFO:             xgboost: Not installed
2023-10-24 12:01:58,214:INFO:            catboost: 1.0.4
2023-10-24 12:01:58,214:INFO:              kmodes: Not installed
2023-10-24 12:01:58,214:INFO:             mlxtend: Not installed
2023-10-24 12:01:58,214:INFO:       statsforecast: Not installed
2023-10-24 12:01:58,214:INFO:        tune_sklearn: Not installed
2023-10-24 12:01:58,214:INFO:                 ray: Not installed
2023-10-24 12:01:58,214:INFO:            hyperopt: Not installed
2023-10-24 12:01:58,214:INFO:              optuna: Not installed
2023-10-24 12:01:58,214:INFO:               skopt: Not installed
2023-10-24 12:01:58,214:INFO:              mlflow: 2.7.1
2023-10-24 12:01:58,214:INFO:              gradio: Not installed
2023-10-24 12:01:58,214:INFO:             fastapi: Not installed
2023-10-24 12:01:58,214:INFO:             uvicorn: Not installed
2023-10-24 12:01:58,214:INFO:              m2cgen: Not installed
2023-10-24 12:01:58,214:INFO:           evidently: Not installed
2023-10-24 12:01:58,214:INFO:               fugue: Not installed
2023-10-24 12:01:58,214:INFO:           streamlit: Not installed
2023-10-24 12:01:58,214:INFO:             prophet: Not installed
2023-10-24 12:01:58,214:INFO:None
2023-10-24 12:01:58,214:INFO:Set up data.
2023-10-24 12:01:58,251:INFO:Set up folding strategy.
2023-10-24 12:01:58,251:INFO:Set up train/test split.
2023-10-24 12:01:58,283:INFO:Set up index.
2023-10-24 12:01:58,284:INFO:Assigning column types.
2023-10-24 12:02:42,191:INFO:PyCaret RegressionExperiment
2023-10-24 12:02:42,192:INFO:Logging name: exp_A
2023-10-24 12:02:42,192:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 12:02:42,192:INFO:version 3.1.0
2023-10-24 12:02:42,192:INFO:Initializing setup()
2023-10-24 12:02:42,192:INFO:self.USI: a91d
2023-10-24 12:02:42,192:INFO:self._variable_keys: {'exp_id', 'target_param', 'USI', 'data', 'fold_shuffle_param', 'log_plots_param', 'X_test', 'memory', 'idx', 'y', 'X', 'X_train', 'gpu_n_jobs_param', 'n_jobs_param', 'gpu_param', 'logging_param', 'fold_generator', 'pipeline', 'y_test', 'y_train', '_ml_usecase', '_available_plots', 'html_param', 'exp_name_log', 'transform_target_param', 'seed', 'fold_groups_param'}
2023-10-24 12:02:42,192:INFO:Checking environment
2023-10-24 12:02:42,192:INFO:python_version: 3.8.5
2023-10-24 12:02:42,192:INFO:python_build: ('default', 'Sep  4 2020 02:22:02')
2023-10-24 12:02:42,192:INFO:machine: x86_64
2023-10-24 12:02:42,192:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-10-24 12:02:42,193:INFO:Memory: svmem(total=8589934592, available=1943224320, percent=77.4, used=4445061120, free=18731008, active=1929134080, inactive=1916768256, wired=2515927040)
2023-10-24 12:02:42,193:INFO:Physical Core: 4
2023-10-24 12:02:42,193:INFO:Logical Core: 8
2023-10-24 12:02:42,195:INFO:Checking libraries
2023-10-24 12:02:42,195:INFO:System:
2023-10-24 12:02:42,195:INFO:    python: 3.8.5 (default, Sep  4 2020, 02:22:02)  [Clang 10.0.0 ]
2023-10-24 12:02:42,195:INFO:executable: /Users/kaja/opt/anaconda3/bin/python
2023-10-24 12:02:42,195:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-10-24 12:02:42,195:INFO:PyCaret required dependencies:
2023-10-24 12:02:42,206:INFO:                 pip: 23.3.1
2023-10-24 12:02:42,206:INFO:          setuptools: 68.2.2
2023-10-24 12:02:42,206:INFO:             pycaret: 3.1.0
2023-10-24 12:02:42,206:INFO:             IPython: 7.19.0
2023-10-24 12:02:42,206:INFO:          ipywidgets: 8.1.1
2023-10-24 12:02:42,206:INFO:                tqdm: 4.66.1
2023-10-24 12:02:42,206:INFO:               numpy: 1.23.5
2023-10-24 12:02:42,206:INFO:              pandas: 1.5.3
2023-10-24 12:02:42,206:INFO:              jinja2: 3.1.2
2023-10-24 12:02:42,206:INFO:               scipy: 1.10.1
2023-10-24 12:02:42,206:INFO:              joblib: 1.3.2
2023-10-24 12:02:42,206:INFO:             sklearn: 1.2.2
2023-10-24 12:02:42,206:INFO:                pyod: 1.1.0
2023-10-24 12:02:42,206:INFO:            imblearn: 0.11.0
2023-10-24 12:02:42,206:INFO:   category_encoders: 2.6.2
2023-10-24 12:02:42,206:INFO:            lightgbm: 4.1.0
2023-10-24 12:02:42,206:INFO:               numba: 0.58.1
2023-10-24 12:02:42,206:INFO:            requests: 2.28.2
2023-10-24 12:02:42,206:INFO:          matplotlib: 3.7.3
2023-10-24 12:02:42,207:INFO:          scikitplot: 0.3.7
2023-10-24 12:02:42,207:INFO:         yellowbrick: 1.5
2023-10-24 12:02:42,207:INFO:              plotly: 5.17.0
2023-10-24 12:02:42,207:INFO:    plotly-resampler: Not installed
2023-10-24 12:02:42,207:INFO:             kaleido: 0.2.1
2023-10-24 12:02:42,207:INFO:           schemdraw: 0.15
2023-10-24 12:02:42,207:INFO:         statsmodels: 0.14.0
2023-10-24 12:02:42,207:INFO:              sktime: 0.21.1
2023-10-24 12:02:42,207:INFO:               tbats: 1.1.3
2023-10-24 12:02:42,207:INFO:            pmdarima: 2.0.4
2023-10-24 12:02:42,207:INFO:              psutil: 5.9.6
2023-10-24 12:02:42,207:INFO:          markupsafe: 2.1.2
2023-10-24 12:02:42,207:INFO:             pickle5: Not installed
2023-10-24 12:02:42,207:INFO:         cloudpickle: 1.6.0
2023-10-24 12:02:42,207:INFO:         deprecation: 2.1.0
2023-10-24 12:02:42,207:INFO:              xxhash: 3.4.1
2023-10-24 12:02:42,207:INFO:           wurlitzer: 2.0.1
2023-10-24 12:02:42,207:INFO:PyCaret optional dependencies:
2023-10-24 12:02:42,207:INFO:                shap: Not installed
2023-10-24 12:02:42,207:INFO:           interpret: Not installed
2023-10-24 12:02:42,207:INFO:                umap: Not installed
2023-10-24 12:02:42,207:INFO:     ydata_profiling: Not installed
2023-10-24 12:02:42,207:INFO:  explainerdashboard: Not installed
2023-10-24 12:02:42,207:INFO:             autoviz: Not installed
2023-10-24 12:02:42,207:INFO:           fairlearn: Not installed
2023-10-24 12:02:42,207:INFO:          deepchecks: Not installed
2023-10-24 12:02:42,207:INFO:             xgboost: Not installed
2023-10-24 12:02:42,207:INFO:            catboost: 1.0.4
2023-10-24 12:02:42,207:INFO:              kmodes: Not installed
2023-10-24 12:02:42,207:INFO:             mlxtend: Not installed
2023-10-24 12:02:42,208:INFO:       statsforecast: Not installed
2023-10-24 12:02:42,208:INFO:        tune_sklearn: Not installed
2023-10-24 12:02:42,208:INFO:                 ray: Not installed
2023-10-24 12:02:42,208:INFO:            hyperopt: Not installed
2023-10-24 12:02:42,208:INFO:              optuna: Not installed
2023-10-24 12:02:42,208:INFO:               skopt: Not installed
2023-10-24 12:02:42,208:INFO:              mlflow: 2.7.1
2023-10-24 12:02:42,208:INFO:              gradio: Not installed
2023-10-24 12:02:42,208:INFO:             fastapi: Not installed
2023-10-24 12:02:42,208:INFO:             uvicorn: Not installed
2023-10-24 12:02:42,208:INFO:              m2cgen: Not installed
2023-10-24 12:02:42,208:INFO:           evidently: Not installed
2023-10-24 12:02:42,208:INFO:               fugue: Not installed
2023-10-24 12:02:42,208:INFO:           streamlit: Not installed
2023-10-24 12:02:42,208:INFO:             prophet: Not installed
2023-10-24 12:02:42,208:INFO:None
2023-10-24 12:02:42,208:INFO:Set up data.
2023-10-24 12:02:42,272:INFO:Set up folding strategy.
2023-10-24 12:02:42,272:INFO:Set up train/test split.
2023-10-24 12:02:42,312:INFO:Set up index.
2023-10-24 12:02:42,314:INFO:Assigning column types.
2023-10-24 12:02:42,329:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 12:02:42,330:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 12:02:42,334:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 12:02:42,339:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:02:42,405:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:02:42,445:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:02:42,446:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:02:42,446:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:02:42,447:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 12:02:42,452:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 12:02:42,456:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:02:42,524:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:02:42,568:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:02:42,569:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:02:42,569:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:02:42,569:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 12:02:42,574:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 12:02:42,578:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:02:42,646:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:02:42,688:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:02:42,689:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:02:42,689:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:02:42,694:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 12:02:42,698:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:02:42,760:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:02:42,801:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:02:42,802:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:02:42,802:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:02:42,803:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 12:02:42,811:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:02:42,875:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:02:42,920:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:02:42,921:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:02:42,921:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:02:42,930:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:02:42,997:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:02:43,042:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:02:43,043:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:02:43,043:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:02:43,044:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 12:02:43,119:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:02:43,164:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:02:43,164:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:02:43,164:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:02:43,274:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:02:43,336:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:02:43,336:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:02:43,337:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:02:43,337:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 12:02:43,425:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:02:43,473:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:02:43,473:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:02:43,543:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:02:43,584:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:02:43,584:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:02:43,584:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 12:02:43,704:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:02:43,705:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:02:43,823:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:02:43,824:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:02:43,825:INFO:Preparing preprocessing pipeline...
2023-10-24 12:02:43,825:INFO:Set up date feature engineering.
2023-10-24 12:02:43,825:INFO:Set up simple imputation.
2023-10-24 12:02:43,834:INFO:Set up encoding of ordinal features.
2023-10-24 12:02:43,861:INFO:Set up encoding of categorical features.
2023-10-24 12:02:43,864:INFO:Set up column name cleaning.
2023-10-24 12:02:44,118:INFO:Finished creating preprocessing pipeline.
2023-10-24 12:02:44,215:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear...
NaN   -1
dtype: int64},
                                                                        {'col': 'rime',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 12:02:44,215:INFO:Creating final display dataframe.
2023-10-24 12:02:44,773:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (34061, 51)
4        Transformed data shape  (34061, 52)
5   Transformed train set shape  (23842, 52)
6    Transformed test set shape  (10219, 52)
7              Ordinal features            4
8              Numeric features           44
9                 Date features            2
10         Categorical features            4
11     Rows with missing values        90.5%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18               Fold Generator        KFold
19                  Fold Number           10
20                     CPU Jobs           -1
21                      Use GPU        False
22               Log Experiment        False
23              Experiment Name        exp_A
24                          USI         a91d
2023-10-24 12:02:44,889:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:02:44,890:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:02:45,000:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:02:45,000:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:02:45,001:INFO:setup() successfully completed in 2.82s...............
2023-10-24 12:02:45,002:INFO:Initializing create_model()
2023-10-24 12:02:45,002:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dc53810a0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 12:02:45,002:INFO:Checking exceptions
2023-10-24 12:02:45,007:INFO:Importing libraries
2023-10-24 12:02:45,007:INFO:Copying training dataset
2023-10-24 12:02:45,026:INFO:Defining folds
2023-10-24 12:02:45,026:INFO:Declaring metric variables
2023-10-24 12:02:45,026:INFO:Importing untrained model
2023-10-24 12:02:45,027:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 12:02:45,027:INFO:Starting cross validation
2023-10-24 12:02:45,029:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 12:02:54,765:INFO:Calculating mean and std
2023-10-24 12:02:54,768:INFO:Creating metrics dataframe
2023-10-24 12:02:54,771:INFO:Finalizing model
2023-10-24 12:02:55,077:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006238 seconds.
2023-10-24 12:02:55,077:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:02:55,077:INFO:[LightGBM] [Info] Total Bins 6533
2023-10-24 12:02:55,078:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 48
2023-10-24 12:02:55,079:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-24 12:02:55,283:INFO:Uploading results into container
2023-10-24 12:02:55,284:INFO:Uploading model into container now
2023-10-24 12:02:55,289:INFO:_master_model_container: 1
2023-10-24 12:02:55,290:INFO:_display_container: 2
2023-10-24 12:02:55,290:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 12:02:55,290:INFO:create_model() successfully completed......................................
2023-10-24 12:02:55,620:INFO:Initializing finalize_model()
2023-10-24 12:02:55,620:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dc53810a0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-24 12:02:55,621:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 12:02:55,642:INFO:Initializing create_model()
2023-10-24 12:02:55,642:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dc53810a0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-24 12:02:55,642:INFO:Checking exceptions
2023-10-24 12:02:55,644:INFO:Importing libraries
2023-10-24 12:02:55,644:INFO:Copying training dataset
2023-10-24 12:02:55,645:INFO:Defining folds
2023-10-24 12:02:55,645:INFO:Declaring metric variables
2023-10-24 12:02:55,646:INFO:Importing untrained model
2023-10-24 12:02:55,646:INFO:Declaring custom model
2023-10-24 12:02:55,647:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 12:02:55,649:INFO:Cross validation set to False
2023-10-24 12:02:55,649:INFO:Fitting Model
2023-10-24 12:02:56,028:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005759 seconds.
2023-10-24 12:02:56,028:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:02:56,028:INFO:[LightGBM] [Info] Total Bins 6648
2023-10-24 12:02:56,029:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 48
2023-10-24 12:02:56,029:INFO:[LightGBM] [Info] Start training from score 631.011165
2023-10-24 12:02:56,340:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',...
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 12:02:56,340:INFO:create_model() successfully completed......................................
2023-10-24 12:02:56,431:INFO:_master_model_container: 1
2023-10-24 12:02:56,432:INFO:_display_container: 2
2023-10-24 12:02:56,521:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',...
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 12:02:56,521:INFO:finalize_model() successfully completed......................................
2023-10-24 12:02:56,791:INFO:Initializing save_model()
2023-10-24 12:02:56,791:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',...
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_A, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear...
NaN   -1
dtype: int64},
                                                                        {'col': 'rime',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-24 12:02:56,791:INFO:Adding model into prep_pipe
2023-10-24 12:02:56,791:WARNING:Only Model saved as it was a pipeline.
2023-10-24 12:02:56,804:INFO:final_model_for_location_A.pkl saved in current working directory
2023-10-24 12:02:56,938:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',...
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 12:02:56,938:INFO:save_model() successfully completed......................................
2023-10-24 12:02:57,093:INFO:PyCaret RegressionExperiment
2023-10-24 12:02:57,093:INFO:Logging name: exp_B
2023-10-24 12:02:57,093:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 12:02:57,094:INFO:version 3.1.0
2023-10-24 12:02:57,094:INFO:Initializing setup()
2023-10-24 12:02:57,094:INFO:self.USI: 8634
2023-10-24 12:02:57,094:INFO:self._variable_keys: {'exp_id', 'target_param', 'USI', 'data', 'fold_shuffle_param', 'log_plots_param', 'X_test', 'memory', 'idx', 'y', 'X', 'X_train', 'gpu_n_jobs_param', 'n_jobs_param', 'gpu_param', 'logging_param', 'fold_generator', 'pipeline', 'y_test', 'y_train', '_ml_usecase', '_available_plots', 'html_param', 'exp_name_log', 'transform_target_param', 'seed', 'fold_groups_param'}
2023-10-24 12:02:57,094:INFO:Checking environment
2023-10-24 12:02:57,094:INFO:python_version: 3.8.5
2023-10-24 12:02:57,094:INFO:python_build: ('default', 'Sep  4 2020 02:22:02')
2023-10-24 12:02:57,094:INFO:machine: x86_64
2023-10-24 12:02:57,094:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-10-24 12:02:57,094:INFO:Memory: svmem(total=8589934592, available=2724917248, percent=68.3, used=4301369344, free=634310656, active=2094182400, inactive=2073313280, wired=2207186944)
2023-10-24 12:02:57,094:INFO:Physical Core: 4
2023-10-24 12:02:57,094:INFO:Logical Core: 8
2023-10-24 12:02:57,094:INFO:Checking libraries
2023-10-24 12:02:57,094:INFO:System:
2023-10-24 12:02:57,094:INFO:    python: 3.8.5 (default, Sep  4 2020, 02:22:02)  [Clang 10.0.0 ]
2023-10-24 12:02:57,094:INFO:executable: /Users/kaja/opt/anaconda3/bin/python
2023-10-24 12:02:57,094:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-10-24 12:02:57,094:INFO:PyCaret required dependencies:
2023-10-24 12:02:57,095:INFO:                 pip: 23.3.1
2023-10-24 12:02:57,095:INFO:          setuptools: 68.2.2
2023-10-24 12:02:57,095:INFO:             pycaret: 3.1.0
2023-10-24 12:02:57,095:INFO:             IPython: 7.19.0
2023-10-24 12:02:57,095:INFO:          ipywidgets: 8.1.1
2023-10-24 12:02:57,095:INFO:                tqdm: 4.66.1
2023-10-24 12:02:57,095:INFO:               numpy: 1.23.5
2023-10-24 12:02:57,095:INFO:              pandas: 1.5.3
2023-10-24 12:02:57,095:INFO:              jinja2: 3.1.2
2023-10-24 12:02:57,095:INFO:               scipy: 1.10.1
2023-10-24 12:02:57,095:INFO:              joblib: 1.3.2
2023-10-24 12:02:57,095:INFO:             sklearn: 1.2.2
2023-10-24 12:02:57,095:INFO:                pyod: 1.1.0
2023-10-24 12:02:57,095:INFO:            imblearn: 0.11.0
2023-10-24 12:02:57,095:INFO:   category_encoders: 2.6.2
2023-10-24 12:02:57,095:INFO:            lightgbm: 4.1.0
2023-10-24 12:02:57,095:INFO:               numba: 0.58.1
2023-10-24 12:02:57,095:INFO:            requests: 2.28.2
2023-10-24 12:02:57,095:INFO:          matplotlib: 3.7.3
2023-10-24 12:02:57,095:INFO:          scikitplot: 0.3.7
2023-10-24 12:02:57,095:INFO:         yellowbrick: 1.5
2023-10-24 12:02:57,095:INFO:              plotly: 5.17.0
2023-10-24 12:02:57,095:INFO:    plotly-resampler: Not installed
2023-10-24 12:02:57,095:INFO:             kaleido: 0.2.1
2023-10-24 12:02:57,095:INFO:           schemdraw: 0.15
2023-10-24 12:02:57,095:INFO:         statsmodels: 0.14.0
2023-10-24 12:02:57,095:INFO:              sktime: 0.21.1
2023-10-24 12:02:57,095:INFO:               tbats: 1.1.3
2023-10-24 12:02:57,096:INFO:            pmdarima: 2.0.4
2023-10-24 12:02:57,096:INFO:              psutil: 5.9.6
2023-10-24 12:02:57,096:INFO:          markupsafe: 2.1.2
2023-10-24 12:02:57,096:INFO:             pickle5: Not installed
2023-10-24 12:02:57,096:INFO:         cloudpickle: 1.6.0
2023-10-24 12:02:57,096:INFO:         deprecation: 2.1.0
2023-10-24 12:02:57,096:INFO:              xxhash: 3.4.1
2023-10-24 12:02:57,096:INFO:           wurlitzer: 2.0.1
2023-10-24 12:02:57,096:INFO:PyCaret optional dependencies:
2023-10-24 12:02:57,096:INFO:                shap: Not installed
2023-10-24 12:02:57,096:INFO:           interpret: Not installed
2023-10-24 12:02:57,096:INFO:                umap: Not installed
2023-10-24 12:02:57,096:INFO:     ydata_profiling: Not installed
2023-10-24 12:02:57,096:INFO:  explainerdashboard: Not installed
2023-10-24 12:02:57,096:INFO:             autoviz: Not installed
2023-10-24 12:02:57,096:INFO:           fairlearn: Not installed
2023-10-24 12:02:57,096:INFO:          deepchecks: Not installed
2023-10-24 12:02:57,096:INFO:             xgboost: Not installed
2023-10-24 12:02:57,096:INFO:            catboost: 1.0.4
2023-10-24 12:02:57,097:INFO:              kmodes: Not installed
2023-10-24 12:02:57,097:INFO:             mlxtend: Not installed
2023-10-24 12:02:57,097:INFO:       statsforecast: Not installed
2023-10-24 12:02:57,097:INFO:        tune_sklearn: Not installed
2023-10-24 12:02:57,097:INFO:                 ray: Not installed
2023-10-24 12:02:57,097:INFO:            hyperopt: Not installed
2023-10-24 12:02:57,097:INFO:              optuna: Not installed
2023-10-24 12:02:57,097:INFO:               skopt: Not installed
2023-10-24 12:02:57,097:INFO:              mlflow: 2.7.1
2023-10-24 12:02:57,097:INFO:              gradio: Not installed
2023-10-24 12:02:57,097:INFO:             fastapi: Not installed
2023-10-24 12:02:57,097:INFO:             uvicorn: Not installed
2023-10-24 12:02:57,097:INFO:              m2cgen: Not installed
2023-10-24 12:02:57,097:INFO:           evidently: Not installed
2023-10-24 12:02:57,098:INFO:               fugue: Not installed
2023-10-24 12:02:57,098:INFO:           streamlit: Not installed
2023-10-24 12:02:57,098:INFO:             prophet: Not installed
2023-10-24 12:02:57,098:INFO:None
2023-10-24 12:02:57,098:INFO:Set up data.
2023-10-24 12:02:57,141:INFO:Set up folding strategy.
2023-10-24 12:02:57,141:INFO:Set up train/test split.
2023-10-24 12:02:57,167:INFO:Set up index.
2023-10-24 12:02:57,169:INFO:Assigning column types.
2023-10-24 12:02:57,183:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 12:02:57,183:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 12:02:57,188:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 12:02:57,191:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:02:57,254:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:02:57,293:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:02:57,293:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:02:57,293:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:02:57,294:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 12:02:57,298:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 12:02:57,302:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:02:57,362:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:02:57,402:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:02:57,402:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:02:57,403:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:02:57,403:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 12:02:57,408:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 12:02:57,412:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:02:57,472:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:02:57,513:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:02:57,514:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:02:57,514:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:02:57,519:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 12:02:57,523:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:02:57,583:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:02:57,624:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:02:57,624:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:02:57,624:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:02:57,625:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 12:02:57,633:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:02:57,692:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:02:57,733:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:02:57,734:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:02:57,734:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:02:57,742:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:02:57,804:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:02:57,843:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:02:57,844:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:02:57,844:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:02:57,845:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 12:02:57,913:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:02:57,953:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:02:57,953:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:02:57,954:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:02:58,022:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:02:58,062:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:02:58,064:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:02:58,064:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:02:58,065:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 12:02:58,137:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:02:58,177:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:02:58,177:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:02:58,248:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:02:58,294:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:02:58,294:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:02:58,295:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 12:02:58,406:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:02:58,406:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:02:58,522:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:02:58,522:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:02:58,523:INFO:Preparing preprocessing pipeline...
2023-10-24 12:02:58,523:INFO:Set up date feature engineering.
2023-10-24 12:02:58,523:INFO:Set up simple imputation.
2023-10-24 12:02:58,538:INFO:Set up encoding of ordinal features.
2023-10-24 12:02:58,561:INFO:Set up encoding of categorical features.
2023-10-24 12:02:58,563:INFO:Set up column name cleaning.
2023-10-24 12:02:58,787:INFO:Finished creating preprocessing pipeline.
2023-10-24 12:02:58,877:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear...
NaN   -1
dtype: int64},
                                                                        {'col': 'rime',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 12:02:58,877:INFO:Creating final display dataframe.
2023-10-24 12:02:59,405:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (32819, 51)
4        Transformed data shape  (32819, 52)
5   Transformed train set shape  (22973, 52)
6    Transformed test set shape   (9846, 52)
7              Ordinal features            4
8              Numeric features           44
9                 Date features            2
10         Categorical features            4
11     Rows with missing values        91.9%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18               Fold Generator        KFold
19                  Fold Number           10
20                     CPU Jobs           -1
21                      Use GPU        False
22               Log Experiment        False
23              Experiment Name        exp_B
24                          USI         8634
2023-10-24 12:02:59,519:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:02:59,520:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:02:59,628:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:02:59,628:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:02:59,629:INFO:setup() successfully completed in 2.59s...............
2023-10-24 12:02:59,630:INFO:Initializing create_model()
2023-10-24 12:02:59,630:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dcd362190>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 12:02:59,630:INFO:Checking exceptions
2023-10-24 12:02:59,633:INFO:Importing libraries
2023-10-24 12:02:59,633:INFO:Copying training dataset
2023-10-24 12:02:59,650:INFO:Defining folds
2023-10-24 12:02:59,650:INFO:Declaring metric variables
2023-10-24 12:02:59,650:INFO:Importing untrained model
2023-10-24 12:02:59,651:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 12:02:59,651:INFO:Starting cross validation
2023-10-24 12:02:59,653:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 12:03:09,864:INFO:Calculating mean and std
2023-10-24 12:03:09,865:INFO:Creating metrics dataframe
2023-10-24 12:03:09,868:INFO:Finalizing model
2023-10-24 12:03:10,162:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006043 seconds.
2023-10-24 12:03:10,162:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:03:10,162:INFO:[LightGBM] [Info] Total Bins 6517
2023-10-24 12:03:10,163:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 48
2023-10-24 12:03:10,164:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-24 12:03:10,360:INFO:Uploading results into container
2023-10-24 12:03:10,361:INFO:Uploading model into container now
2023-10-24 12:03:10,367:INFO:_master_model_container: 1
2023-10-24 12:03:10,368:INFO:_display_container: 2
2023-10-24 12:03:10,368:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 12:03:10,368:INFO:create_model() successfully completed......................................
2023-10-24 12:03:10,475:INFO:Initializing finalize_model()
2023-10-24 12:03:10,475:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dcd362190>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-24 12:03:10,476:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 12:03:10,496:INFO:Initializing create_model()
2023-10-24 12:03:10,496:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dcd362190>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-24 12:03:10,496:INFO:Checking exceptions
2023-10-24 12:03:10,497:INFO:Importing libraries
2023-10-24 12:03:10,497:INFO:Copying training dataset
2023-10-24 12:03:10,498:INFO:Defining folds
2023-10-24 12:03:10,498:INFO:Declaring metric variables
2023-10-24 12:03:10,498:INFO:Importing untrained model
2023-10-24 12:03:10,499:INFO:Declaring custom model
2023-10-24 12:03:10,499:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 12:03:10,501:INFO:Cross validation set to False
2023-10-24 12:03:10,501:INFO:Fitting Model
2023-10-24 12:03:10,888:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012414 seconds.
2023-10-24 12:03:10,888:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:03:10,889:INFO:[LightGBM] [Info] Total Bins 6595
2023-10-24 12:03:10,889:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 48
2023-10-24 12:03:10,890:INFO:[LightGBM] [Info] Start training from score 96.893335
2023-10-24 12:03:11,214:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',...
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 12:03:11,214:INFO:create_model() successfully completed......................................
2023-10-24 12:03:11,306:INFO:_master_model_container: 1
2023-10-24 12:03:11,306:INFO:_display_container: 2
2023-10-24 12:03:11,396:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',...
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 12:03:11,396:INFO:finalize_model() successfully completed......................................
2023-10-24 12:03:11,695:INFO:Initializing save_model()
2023-10-24 12:03:11,696:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',...
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_B, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear...
NaN   -1
dtype: int64},
                                                                        {'col': 'rime',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-24 12:03:11,696:INFO:Adding model into prep_pipe
2023-10-24 12:03:11,696:WARNING:Only Model saved as it was a pipeline.
2023-10-24 12:03:11,708:INFO:final_model_for_location_B.pkl saved in current working directory
2023-10-24 12:03:11,831:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',...
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 12:03:11,831:INFO:save_model() successfully completed......................................
2023-10-24 12:03:12,004:INFO:PyCaret RegressionExperiment
2023-10-24 12:03:12,004:INFO:Logging name: exp_C
2023-10-24 12:03:12,004:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 12:03:12,004:INFO:version 3.1.0
2023-10-24 12:03:12,004:INFO:Initializing setup()
2023-10-24 12:03:12,004:INFO:self.USI: 9c2e
2023-10-24 12:03:12,005:INFO:self._variable_keys: {'exp_id', 'target_param', 'USI', 'data', 'fold_shuffle_param', 'log_plots_param', 'X_test', 'memory', 'idx', 'y', 'X', 'X_train', 'gpu_n_jobs_param', 'n_jobs_param', 'gpu_param', 'logging_param', 'fold_generator', 'pipeline', 'y_test', 'y_train', '_ml_usecase', '_available_plots', 'html_param', 'exp_name_log', 'transform_target_param', 'seed', 'fold_groups_param'}
2023-10-24 12:03:12,005:INFO:Checking environment
2023-10-24 12:03:12,005:INFO:python_version: 3.8.5
2023-10-24 12:03:12,005:INFO:python_build: ('default', 'Sep  4 2020 02:22:02')
2023-10-24 12:03:12,005:INFO:machine: x86_64
2023-10-24 12:03:12,005:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-10-24 12:03:12,005:INFO:Memory: svmem(total=8589934592, available=2565640192, percent=70.1, used=4473577472, free=419885056, active=2148065280, inactive=2135076864, wired=2325512192)
2023-10-24 12:03:12,005:INFO:Physical Core: 4
2023-10-24 12:03:12,005:INFO:Logical Core: 8
2023-10-24 12:03:12,005:INFO:Checking libraries
2023-10-24 12:03:12,005:INFO:System:
2023-10-24 12:03:12,005:INFO:    python: 3.8.5 (default, Sep  4 2020, 02:22:02)  [Clang 10.0.0 ]
2023-10-24 12:03:12,005:INFO:executable: /Users/kaja/opt/anaconda3/bin/python
2023-10-24 12:03:12,005:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-10-24 12:03:12,005:INFO:PyCaret required dependencies:
2023-10-24 12:03:12,005:INFO:                 pip: 23.3.1
2023-10-24 12:03:12,005:INFO:          setuptools: 68.2.2
2023-10-24 12:03:12,006:INFO:             pycaret: 3.1.0
2023-10-24 12:03:12,006:INFO:             IPython: 7.19.0
2023-10-24 12:03:12,006:INFO:          ipywidgets: 8.1.1
2023-10-24 12:03:12,006:INFO:                tqdm: 4.66.1
2023-10-24 12:03:12,006:INFO:               numpy: 1.23.5
2023-10-24 12:03:12,006:INFO:              pandas: 1.5.3
2023-10-24 12:03:12,006:INFO:              jinja2: 3.1.2
2023-10-24 12:03:12,006:INFO:               scipy: 1.10.1
2023-10-24 12:03:12,006:INFO:              joblib: 1.3.2
2023-10-24 12:03:12,006:INFO:             sklearn: 1.2.2
2023-10-24 12:03:12,006:INFO:                pyod: 1.1.0
2023-10-24 12:03:12,006:INFO:            imblearn: 0.11.0
2023-10-24 12:03:12,006:INFO:   category_encoders: 2.6.2
2023-10-24 12:03:12,006:INFO:            lightgbm: 4.1.0
2023-10-24 12:03:12,007:INFO:               numba: 0.58.1
2023-10-24 12:03:12,007:INFO:            requests: 2.28.2
2023-10-24 12:03:12,007:INFO:          matplotlib: 3.7.3
2023-10-24 12:03:12,007:INFO:          scikitplot: 0.3.7
2023-10-24 12:03:12,007:INFO:         yellowbrick: 1.5
2023-10-24 12:03:12,007:INFO:              plotly: 5.17.0
2023-10-24 12:03:12,007:INFO:    plotly-resampler: Not installed
2023-10-24 12:03:12,007:INFO:             kaleido: 0.2.1
2023-10-24 12:03:12,007:INFO:           schemdraw: 0.15
2023-10-24 12:03:12,007:INFO:         statsmodels: 0.14.0
2023-10-24 12:03:12,007:INFO:              sktime: 0.21.1
2023-10-24 12:03:12,007:INFO:               tbats: 1.1.3
2023-10-24 12:03:12,007:INFO:            pmdarima: 2.0.4
2023-10-24 12:03:12,007:INFO:              psutil: 5.9.6
2023-10-24 12:03:12,007:INFO:          markupsafe: 2.1.2
2023-10-24 12:03:12,007:INFO:             pickle5: Not installed
2023-10-24 12:03:12,007:INFO:         cloudpickle: 1.6.0
2023-10-24 12:03:12,007:INFO:         deprecation: 2.1.0
2023-10-24 12:03:12,007:INFO:              xxhash: 3.4.1
2023-10-24 12:03:12,007:INFO:           wurlitzer: 2.0.1
2023-10-24 12:03:12,007:INFO:PyCaret optional dependencies:
2023-10-24 12:03:12,007:INFO:                shap: Not installed
2023-10-24 12:03:12,008:INFO:           interpret: Not installed
2023-10-24 12:03:12,008:INFO:                umap: Not installed
2023-10-24 12:03:12,008:INFO:     ydata_profiling: Not installed
2023-10-24 12:03:12,008:INFO:  explainerdashboard: Not installed
2023-10-24 12:03:12,008:INFO:             autoviz: Not installed
2023-10-24 12:03:12,008:INFO:           fairlearn: Not installed
2023-10-24 12:03:12,008:INFO:          deepchecks: Not installed
2023-10-24 12:03:12,008:INFO:             xgboost: Not installed
2023-10-24 12:03:12,008:INFO:            catboost: 1.0.4
2023-10-24 12:03:12,008:INFO:              kmodes: Not installed
2023-10-24 12:03:12,008:INFO:             mlxtend: Not installed
2023-10-24 12:03:12,008:INFO:       statsforecast: Not installed
2023-10-24 12:03:12,008:INFO:        tune_sklearn: Not installed
2023-10-24 12:03:12,008:INFO:                 ray: Not installed
2023-10-24 12:03:12,008:INFO:            hyperopt: Not installed
2023-10-24 12:03:12,008:INFO:              optuna: Not installed
2023-10-24 12:03:12,008:INFO:               skopt: Not installed
2023-10-24 12:03:12,008:INFO:              mlflow: 2.7.1
2023-10-24 12:03:12,008:INFO:              gradio: Not installed
2023-10-24 12:03:12,008:INFO:             fastapi: Not installed
2023-10-24 12:03:12,008:INFO:             uvicorn: Not installed
2023-10-24 12:03:12,008:INFO:              m2cgen: Not installed
2023-10-24 12:03:12,008:INFO:           evidently: Not installed
2023-10-24 12:03:12,009:INFO:               fugue: Not installed
2023-10-24 12:03:12,009:INFO:           streamlit: Not installed
2023-10-24 12:03:12,009:INFO:             prophet: Not installed
2023-10-24 12:03:12,009:INFO:None
2023-10-24 12:03:12,009:INFO:Set up data.
2023-10-24 12:03:12,043:INFO:Set up folding strategy.
2023-10-24 12:03:12,043:INFO:Set up train/test split.
2023-10-24 12:03:12,063:INFO:Set up index.
2023-10-24 12:03:12,065:INFO:Assigning column types.
2023-10-24 12:03:12,075:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 12:03:12,075:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 12:03:12,079:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 12:03:12,084:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:03:12,143:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:03:12,185:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:03:12,185:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:03:12,186:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:03:12,186:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 12:03:12,190:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 12:03:12,194:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:03:12,256:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:03:12,300:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:03:12,300:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:03:12,301:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:03:12,302:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 12:03:12,306:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 12:03:12,311:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:03:12,375:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:03:12,420:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:03:12,421:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:03:12,421:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:03:12,426:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 12:03:12,431:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:03:12,490:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:03:12,532:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:03:12,532:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:03:12,532:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:03:12,533:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 12:03:12,541:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:03:12,602:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:03:12,644:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:03:12,645:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:03:12,645:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:03:12,656:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:03:12,722:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:03:12,766:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:03:12,766:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:03:12,767:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:03:12,767:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 12:03:12,842:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:03:12,883:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:03:12,884:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:03:12,884:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:03:12,953:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:03:12,996:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:03:12,996:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:03:12,997:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:03:12,998:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 12:03:13,079:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:03:13,125:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:03:13,125:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:03:13,210:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:03:13,256:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:03:13,257:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:03:13,257:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 12:03:13,421:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:03:13,422:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:03:13,574:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:03:13,575:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:03:13,576:INFO:Preparing preprocessing pipeline...
2023-10-24 12:03:13,576:INFO:Set up date feature engineering.
2023-10-24 12:03:13,576:INFO:Set up simple imputation.
2023-10-24 12:03:13,587:INFO:Set up encoding of ordinal features.
2023-10-24 12:03:13,607:INFO:Set up encoding of categorical features.
2023-10-24 12:03:13,609:INFO:Set up column name cleaning.
2023-10-24 12:03:13,813:INFO:Finished creating preprocessing pipeline.
2023-10-24 12:03:13,918:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear...
NaN   -1
dtype: int64},
                                                                        {'col': 'rime',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 12:03:13,918:INFO:Creating final display dataframe.
2023-10-24 12:03:14,421:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (26071, 51)
4        Transformed data shape  (26071, 52)
5   Transformed train set shape  (18249, 52)
6    Transformed test set shape   (7822, 52)
7              Ordinal features            4
8              Numeric features           44
9                 Date features            2
10         Categorical features            4
11     Rows with missing values        92.4%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18               Fold Generator        KFold
19                  Fold Number           10
20                     CPU Jobs           -1
21                      Use GPU        False
22               Log Experiment        False
23              Experiment Name        exp_C
24                          USI         9c2e
2023-10-24 12:03:14,552:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:03:14,553:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:03:14,672:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:03:14,672:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:03:14,673:INFO:setup() successfully completed in 2.67s...............
2023-10-24 12:03:14,674:INFO:Initializing create_model()
2023-10-24 12:03:14,674:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dca0b4a30>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 12:03:14,674:INFO:Checking exceptions
2023-10-24 12:03:14,676:INFO:Importing libraries
2023-10-24 12:03:14,676:INFO:Copying training dataset
2023-10-24 12:03:14,691:INFO:Defining folds
2023-10-24 12:03:14,691:INFO:Declaring metric variables
2023-10-24 12:03:14,692:INFO:Importing untrained model
2023-10-24 12:03:14,692:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 12:03:14,692:INFO:Starting cross validation
2023-10-24 12:03:14,693:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 12:03:25,020:INFO:Calculating mean and std
2023-10-24 12:03:25,021:INFO:Creating metrics dataframe
2023-10-24 12:03:25,023:INFO:Finalizing model
2023-10-24 12:03:25,265:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005240 seconds.
2023-10-24 12:03:25,266:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:03:25,266:INFO:[LightGBM] [Info] Total Bins 6726
2023-10-24 12:03:25,266:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 49
2023-10-24 12:03:25,267:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-24 12:03:25,427:INFO:Uploading results into container
2023-10-24 12:03:25,429:INFO:Uploading model into container now
2023-10-24 12:03:25,434:INFO:_master_model_container: 1
2023-10-24 12:03:25,434:INFO:_display_container: 2
2023-10-24 12:03:25,435:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 12:03:25,435:INFO:create_model() successfully completed......................................
2023-10-24 12:03:25,537:INFO:Initializing finalize_model()
2023-10-24 12:03:25,537:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dca0b4a30>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-24 12:03:25,537:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 12:03:25,552:INFO:Initializing create_model()
2023-10-24 12:03:25,552:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dca0b4a30>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-24 12:03:25,552:INFO:Checking exceptions
2023-10-24 12:03:25,553:INFO:Importing libraries
2023-10-24 12:03:25,553:INFO:Copying training dataset
2023-10-24 12:03:25,554:INFO:Defining folds
2023-10-24 12:03:25,554:INFO:Declaring metric variables
2023-10-24 12:03:25,554:INFO:Importing untrained model
2023-10-24 12:03:25,554:INFO:Declaring custom model
2023-10-24 12:03:25,555:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 12:03:25,557:INFO:Cross validation set to False
2023-10-24 12:03:25,557:INFO:Fitting Model
2023-10-24 12:03:25,874:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008857 seconds.
2023-10-24 12:03:25,874:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:03:25,874:INFO:[LightGBM] [Info] Total Bins 6800
2023-10-24 12:03:25,875:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 49
2023-10-24 12:03:25,875:INFO:[LightGBM] [Info] Start training from score 77.700043
2023-10-24 12:03:26,164:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',...
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 12:03:26,164:INFO:create_model() successfully completed......................................
2023-10-24 12:03:26,256:INFO:_master_model_container: 1
2023-10-24 12:03:26,256:INFO:_display_container: 2
2023-10-24 12:03:26,350:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',...
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 12:03:26,350:INFO:finalize_model() successfully completed......................................
2023-10-24 12:03:26,672:INFO:Initializing save_model()
2023-10-24 12:03:26,673:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',...
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_C, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear...
NaN   -1
dtype: int64},
                                                                        {'col': 'rime',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-24 12:03:26,673:INFO:Adding model into prep_pipe
2023-10-24 12:03:26,673:WARNING:Only Model saved as it was a pipeline.
2023-10-24 12:03:26,743:INFO:final_model_for_location_C.pkl saved in current working directory
2023-10-24 12:03:26,870:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',...
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 12:03:26,870:INFO:save_model() successfully completed......................................
2023-10-24 12:03:28,497:INFO:Initializing load_model()
2023-10-24 12:03:28,497:INFO:load_model(model_name=final_model_for_location_A, platform=None, authentication=None, verbose=True)
2023-10-24 12:03:28,505:INFO:Initializing load_model()
2023-10-24 12:03:28,505:INFO:load_model(model_name=final_model_for_location_B, platform=None, authentication=None, verbose=True)
2023-10-24 12:03:28,513:INFO:Initializing load_model()
2023-10-24 12:03:28,513:INFO:load_model(model_name=final_model_for_location_C, platform=None, authentication=None, verbose=True)
2023-10-24 12:03:28,640:INFO:Initializing predict_model()
2023-10-24 12:03:28,640:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dca0b4a30>, estimator=Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast', 'date_calc'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear...
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f9d498bfc10>)
2023-10-24 12:03:28,640:INFO:Checking exceptions
2023-10-24 12:03:28,640:INFO:Preloading libraries
2023-10-24 12:03:28,641:INFO:Set up data.
2023-10-24 12:03:28,656:INFO:Set up index.
2023-10-24 12:06:06,874:INFO:PyCaret RegressionExperiment
2023-10-24 12:06:06,875:INFO:Logging name: exp_A
2023-10-24 12:06:06,875:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 12:06:06,875:INFO:version 3.1.0
2023-10-24 12:06:06,875:INFO:Initializing setup()
2023-10-24 12:06:06,875:INFO:self.USI: 52fa
2023-10-24 12:06:06,875:INFO:self._variable_keys: {'exp_id', 'target_param', 'USI', 'data', 'fold_shuffle_param', 'log_plots_param', 'X_test', 'memory', 'idx', 'y', 'X', 'X_train', 'gpu_n_jobs_param', 'n_jobs_param', 'gpu_param', 'logging_param', 'fold_generator', 'pipeline', 'y_test', 'y_train', '_ml_usecase', '_available_plots', 'html_param', 'exp_name_log', 'transform_target_param', 'seed', 'fold_groups_param'}
2023-10-24 12:06:06,875:INFO:Checking environment
2023-10-24 12:06:06,875:INFO:python_version: 3.8.5
2023-10-24 12:06:06,875:INFO:python_build: ('default', 'Sep  4 2020 02:22:02')
2023-10-24 12:06:06,875:INFO:machine: x86_64
2023-10-24 12:06:06,875:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-10-24 12:06:06,875:INFO:Memory: svmem(total=8589934592, available=2256154624, percent=73.7, used=4771254272, free=8355840, active=2255036416, inactive=2242457600, wired=2516217856)
2023-10-24 12:06:06,875:INFO:Physical Core: 4
2023-10-24 12:06:06,875:INFO:Logical Core: 8
2023-10-24 12:06:06,875:INFO:Checking libraries
2023-10-24 12:06:06,875:INFO:System:
2023-10-24 12:06:06,875:INFO:    python: 3.8.5 (default, Sep  4 2020, 02:22:02)  [Clang 10.0.0 ]
2023-10-24 12:06:06,875:INFO:executable: /Users/kaja/opt/anaconda3/bin/python
2023-10-24 12:06:06,910:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-10-24 12:06:06,911:INFO:PyCaret required dependencies:
2023-10-24 12:06:06,911:INFO:                 pip: 23.3.1
2023-10-24 12:06:06,911:INFO:          setuptools: 68.2.2
2023-10-24 12:06:06,911:INFO:             pycaret: 3.1.0
2023-10-24 12:06:06,911:INFO:             IPython: 7.19.0
2023-10-24 12:06:06,911:INFO:          ipywidgets: 8.1.1
2023-10-24 12:06:06,911:INFO:                tqdm: 4.66.1
2023-10-24 12:06:06,911:INFO:               numpy: 1.23.5
2023-10-24 12:06:06,911:INFO:              pandas: 1.5.3
2023-10-24 12:06:06,911:INFO:              jinja2: 3.1.2
2023-10-24 12:06:06,911:INFO:               scipy: 1.10.1
2023-10-24 12:06:06,911:INFO:              joblib: 1.3.2
2023-10-24 12:06:06,911:INFO:             sklearn: 1.2.2
2023-10-24 12:06:06,911:INFO:                pyod: 1.1.0
2023-10-24 12:06:06,911:INFO:            imblearn: 0.11.0
2023-10-24 12:06:06,911:INFO:   category_encoders: 2.6.2
2023-10-24 12:06:06,911:INFO:            lightgbm: 4.1.0
2023-10-24 12:06:06,911:INFO:               numba: 0.58.1
2023-10-24 12:06:06,911:INFO:            requests: 2.28.2
2023-10-24 12:06:06,911:INFO:          matplotlib: 3.7.3
2023-10-24 12:06:06,911:INFO:          scikitplot: 0.3.7
2023-10-24 12:06:06,911:INFO:         yellowbrick: 1.5
2023-10-24 12:06:06,911:INFO:              plotly: 5.17.0
2023-10-24 12:06:06,911:INFO:    plotly-resampler: Not installed
2023-10-24 12:06:06,911:INFO:             kaleido: 0.2.1
2023-10-24 12:06:06,911:INFO:           schemdraw: 0.15
2023-10-24 12:06:06,911:INFO:         statsmodels: 0.14.0
2023-10-24 12:06:06,912:INFO:              sktime: 0.21.1
2023-10-24 12:06:06,912:INFO:               tbats: 1.1.3
2023-10-24 12:06:06,912:INFO:            pmdarima: 2.0.4
2023-10-24 12:06:06,912:INFO:              psutil: 5.9.6
2023-10-24 12:06:06,912:INFO:          markupsafe: 2.1.2
2023-10-24 12:06:06,912:INFO:             pickle5: Not installed
2023-10-24 12:06:06,912:INFO:         cloudpickle: 1.6.0
2023-10-24 12:06:06,914:INFO:         deprecation: 2.1.0
2023-10-24 12:06:06,914:INFO:              xxhash: 3.4.1
2023-10-24 12:06:06,914:INFO:           wurlitzer: 2.0.1
2023-10-24 12:06:06,914:INFO:PyCaret optional dependencies:
2023-10-24 12:06:06,915:INFO:                shap: Not installed
2023-10-24 12:06:06,915:INFO:           interpret: Not installed
2023-10-24 12:06:06,915:INFO:                umap: Not installed
2023-10-24 12:06:06,915:INFO:     ydata_profiling: Not installed
2023-10-24 12:06:06,915:INFO:  explainerdashboard: Not installed
2023-10-24 12:06:06,915:INFO:             autoviz: Not installed
2023-10-24 12:06:06,915:INFO:           fairlearn: Not installed
2023-10-24 12:06:06,915:INFO:          deepchecks: Not installed
2023-10-24 12:06:06,915:INFO:             xgboost: Not installed
2023-10-24 12:06:06,915:INFO:            catboost: 1.0.4
2023-10-24 12:06:06,915:INFO:              kmodes: Not installed
2023-10-24 12:06:06,915:INFO:             mlxtend: Not installed
2023-10-24 12:06:06,915:INFO:       statsforecast: Not installed
2023-10-24 12:06:06,915:INFO:        tune_sklearn: Not installed
2023-10-24 12:06:06,916:INFO:                 ray: Not installed
2023-10-24 12:06:06,916:INFO:            hyperopt: Not installed
2023-10-24 12:06:06,916:INFO:              optuna: Not installed
2023-10-24 12:06:06,916:INFO:               skopt: Not installed
2023-10-24 12:06:06,916:INFO:              mlflow: 2.7.1
2023-10-24 12:06:06,916:INFO:              gradio: Not installed
2023-10-24 12:06:06,916:INFO:             fastapi: Not installed
2023-10-24 12:06:06,916:INFO:             uvicorn: Not installed
2023-10-24 12:06:06,916:INFO:              m2cgen: Not installed
2023-10-24 12:06:06,916:INFO:           evidently: Not installed
2023-10-24 12:06:06,916:INFO:               fugue: Not installed
2023-10-24 12:06:06,916:INFO:           streamlit: Not installed
2023-10-24 12:06:06,916:INFO:             prophet: Not installed
2023-10-24 12:06:06,916:INFO:None
2023-10-24 12:06:06,916:INFO:Set up data.
2023-10-24 12:06:06,958:INFO:Set up folding strategy.
2023-10-24 12:06:06,958:INFO:Set up train/test split.
2023-10-24 12:06:06,989:INFO:Set up index.
2023-10-24 12:06:06,991:INFO:Assigning column types.
2023-10-24 12:06:07,007:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 12:06:07,007:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 12:06:07,012:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 12:06:07,016:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:06:07,077:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:06:07,118:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:06:07,120:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:06:07,121:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:06:07,121:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 12:06:07,126:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 12:06:07,130:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:06:07,193:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:06:07,233:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:06:07,233:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:06:07,233:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:06:07,234:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 12:06:07,238:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 12:06:07,242:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:06:07,306:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:06:07,348:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:06:07,348:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:06:07,348:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:06:07,353:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 12:06:07,357:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:06:07,418:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:06:07,458:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:06:07,459:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:06:07,459:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:06:07,460:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 12:06:07,467:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:06:07,528:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:06:07,568:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:06:07,571:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:06:07,571:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:06:07,580:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:06:07,641:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:06:07,680:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:06:07,680:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:06:07,681:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:06:07,681:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 12:06:07,748:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:06:07,788:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:06:07,788:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:06:07,788:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:06:07,858:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:06:07,909:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:06:07,922:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:06:07,923:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:06:07,924:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 12:06:08,000:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:06:08,046:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:06:08,046:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:06:08,120:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:06:08,161:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:06:08,162:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:06:08,162:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 12:06:08,287:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:06:08,287:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:06:08,558:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:06:08,559:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:06:08,560:INFO:Preparing preprocessing pipeline...
2023-10-24 12:06:08,560:INFO:Set up date feature engineering.
2023-10-24 12:06:08,560:INFO:Set up simple imputation.
2023-10-24 12:06:08,570:INFO:Set up encoding of ordinal features.
2023-10-24 12:06:08,590:INFO:Set up encoding of categorical features.
2023-10-24 12:06:08,592:INFO:Set up column name cleaning.
2023-10-24 12:06:08,970:INFO:Finished creating preprocessing pipeline.
2023-10-24 12:06:09,172:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_...
NaN   -1
dtype: int64},
                                                                        {'col': 'rime',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 12:06:09,172:INFO:Creating final display dataframe.
2023-10-24 12:06:09,817:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (34061, 50)
4        Transformed data shape  (34061, 52)
5   Transformed train set shape  (23842, 52)
6    Transformed test set shape  (10219, 52)
7              Ordinal features            4
8              Numeric features           44
9                 Date features            1
10         Categorical features            4
11     Rows with missing values        23.1%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18               Fold Generator        KFold
19                  Fold Number           10
20                     CPU Jobs           -1
21                      Use GPU        False
22               Log Experiment        False
23              Experiment Name        exp_A
24                          USI         52fa
2023-10-24 12:06:09,992:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:06:09,992:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:06:10,131:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:06:10,131:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:06:10,132:INFO:setup() successfully completed in 3.26s...............
2023-10-24 12:06:10,132:INFO:Initializing create_model()
2023-10-24 12:06:10,133:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dd6d59a30>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 12:06:10,133:INFO:Checking exceptions
2023-10-24 12:06:10,135:INFO:Importing libraries
2023-10-24 12:06:10,135:INFO:Copying training dataset
2023-10-24 12:06:10,158:INFO:Defining folds
2023-10-24 12:06:10,158:INFO:Declaring metric variables
2023-10-24 12:06:10,158:INFO:Importing untrained model
2023-10-24 12:06:10,159:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 12:06:10,159:INFO:Starting cross validation
2023-10-24 12:06:10,161:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 12:06:22,310:INFO:Calculating mean and std
2023-10-24 12:06:22,311:INFO:Creating metrics dataframe
2023-10-24 12:06:22,314:INFO:Finalizing model
2023-10-24 12:06:22,625:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006607 seconds.
2023-10-24 12:06:22,625:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:06:22,625:INFO:[LightGBM] [Info] Total Bins 6533
2023-10-24 12:06:22,626:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 48
2023-10-24 12:06:22,627:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-24 12:06:22,846:INFO:Uploading results into container
2023-10-24 12:06:22,847:INFO:Uploading model into container now
2023-10-24 12:06:22,853:INFO:_master_model_container: 1
2023-10-24 12:06:22,854:INFO:_display_container: 2
2023-10-24 12:06:22,854:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 12:06:22,855:INFO:create_model() successfully completed......................................
2023-10-24 12:06:23,001:INFO:Initializing finalize_model()
2023-10-24 12:06:23,002:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dd6d59a30>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-24 12:06:23,002:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 12:06:23,025:INFO:Initializing create_model()
2023-10-24 12:06:23,025:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dd6d59a30>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-24 12:06:23,025:INFO:Checking exceptions
2023-10-24 12:06:23,027:INFO:Importing libraries
2023-10-24 12:06:23,027:INFO:Copying training dataset
2023-10-24 12:06:23,028:INFO:Defining folds
2023-10-24 12:06:23,028:INFO:Declaring metric variables
2023-10-24 12:06:23,028:INFO:Importing untrained model
2023-10-24 12:06:23,028:INFO:Declaring custom model
2023-10-24 12:06:23,029:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 12:06:23,031:INFO:Cross validation set to False
2023-10-24 12:06:23,031:INFO:Fitting Model
2023-10-24 12:06:23,433:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011261 seconds.
2023-10-24 12:06:23,433:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:06:23,433:INFO:[LightGBM] [Info] Total Bins 6648
2023-10-24 12:06:23,434:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 48
2023-10-24 12:06:23,434:INFO:[LightGBM] [Info] Start training from score 631.011165
2023-10-24 12:06:23,753:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 12:06:23,753:INFO:create_model() successfully completed......................................
2023-10-24 12:06:23,849:INFO:_master_model_container: 1
2023-10-24 12:06:23,849:INFO:_display_container: 2
2023-10-24 12:06:23,958:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 12:06:23,958:INFO:finalize_model() successfully completed......................................
2023-10-24 12:06:24,317:INFO:Initializing save_model()
2023-10-24 12:06:24,317:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_A, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_...
NaN   -1
dtype: int64},
                                                                        {'col': 'rime',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-24 12:06:24,317:INFO:Adding model into prep_pipe
2023-10-24 12:06:24,317:WARNING:Only Model saved as it was a pipeline.
2023-10-24 12:06:24,348:INFO:final_model_for_location_A.pkl saved in current working directory
2023-10-24 12:06:24,460:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 12:06:24,460:INFO:save_model() successfully completed......................................
2023-10-24 12:06:24,565:INFO:PyCaret RegressionExperiment
2023-10-24 12:06:24,566:INFO:Logging name: exp_B
2023-10-24 12:06:24,566:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 12:06:24,566:INFO:version 3.1.0
2023-10-24 12:06:24,566:INFO:Initializing setup()
2023-10-24 12:06:24,566:INFO:self.USI: f468
2023-10-24 12:06:24,566:INFO:self._variable_keys: {'exp_id', 'target_param', 'USI', 'data', 'fold_shuffle_param', 'log_plots_param', 'X_test', 'memory', 'idx', 'y', 'X', 'X_train', 'gpu_n_jobs_param', 'n_jobs_param', 'gpu_param', 'logging_param', 'fold_generator', 'pipeline', 'y_test', 'y_train', '_ml_usecase', '_available_plots', 'html_param', 'exp_name_log', 'transform_target_param', 'seed', 'fold_groups_param'}
2023-10-24 12:06:24,566:INFO:Checking environment
2023-10-24 12:06:24,566:INFO:python_version: 3.8.5
2023-10-24 12:06:24,566:INFO:python_build: ('default', 'Sep  4 2020 02:22:02')
2023-10-24 12:06:24,566:INFO:machine: x86_64
2023-10-24 12:06:24,566:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-10-24 12:06:24,566:INFO:Memory: svmem(total=8589934592, available=2527662080, percent=70.6, used=4800970752, free=179654656, active=2348400640, inactive=2334945280, wired=2452570112)
2023-10-24 12:06:24,566:INFO:Physical Core: 4
2023-10-24 12:06:24,566:INFO:Logical Core: 8
2023-10-24 12:06:24,566:INFO:Checking libraries
2023-10-24 12:06:24,566:INFO:System:
2023-10-24 12:06:24,566:INFO:    python: 3.8.5 (default, Sep  4 2020, 02:22:02)  [Clang 10.0.0 ]
2023-10-24 12:06:24,566:INFO:executable: /Users/kaja/opt/anaconda3/bin/python
2023-10-24 12:06:24,566:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-10-24 12:06:24,566:INFO:PyCaret required dependencies:
2023-10-24 12:06:24,567:INFO:                 pip: 23.3.1
2023-10-24 12:06:24,567:INFO:          setuptools: 68.2.2
2023-10-24 12:06:24,567:INFO:             pycaret: 3.1.0
2023-10-24 12:06:24,567:INFO:             IPython: 7.19.0
2023-10-24 12:06:24,567:INFO:          ipywidgets: 8.1.1
2023-10-24 12:06:24,567:INFO:                tqdm: 4.66.1
2023-10-24 12:06:24,567:INFO:               numpy: 1.23.5
2023-10-24 12:06:24,567:INFO:              pandas: 1.5.3
2023-10-24 12:06:24,567:INFO:              jinja2: 3.1.2
2023-10-24 12:06:24,567:INFO:               scipy: 1.10.1
2023-10-24 12:06:24,567:INFO:              joblib: 1.3.2
2023-10-24 12:06:24,567:INFO:             sklearn: 1.2.2
2023-10-24 12:06:24,567:INFO:                pyod: 1.1.0
2023-10-24 12:06:24,567:INFO:            imblearn: 0.11.0
2023-10-24 12:06:24,567:INFO:   category_encoders: 2.6.2
2023-10-24 12:06:24,567:INFO:            lightgbm: 4.1.0
2023-10-24 12:06:24,567:INFO:               numba: 0.58.1
2023-10-24 12:06:24,567:INFO:            requests: 2.28.2
2023-10-24 12:06:24,567:INFO:          matplotlib: 3.7.3
2023-10-24 12:06:24,567:INFO:          scikitplot: 0.3.7
2023-10-24 12:06:24,567:INFO:         yellowbrick: 1.5
2023-10-24 12:06:24,567:INFO:              plotly: 5.17.0
2023-10-24 12:06:24,567:INFO:    plotly-resampler: Not installed
2023-10-24 12:06:24,567:INFO:             kaleido: 0.2.1
2023-10-24 12:06:24,567:INFO:           schemdraw: 0.15
2023-10-24 12:06:24,567:INFO:         statsmodels: 0.14.0
2023-10-24 12:06:24,567:INFO:              sktime: 0.21.1
2023-10-24 12:06:24,567:INFO:               tbats: 1.1.3
2023-10-24 12:06:24,568:INFO:            pmdarima: 2.0.4
2023-10-24 12:06:24,568:INFO:              psutil: 5.9.6
2023-10-24 12:06:24,568:INFO:          markupsafe: 2.1.2
2023-10-24 12:06:24,568:INFO:             pickle5: Not installed
2023-10-24 12:06:24,568:INFO:         cloudpickle: 1.6.0
2023-10-24 12:06:24,568:INFO:         deprecation: 2.1.0
2023-10-24 12:06:24,568:INFO:              xxhash: 3.4.1
2023-10-24 12:06:24,568:INFO:           wurlitzer: 2.0.1
2023-10-24 12:06:24,568:INFO:PyCaret optional dependencies:
2023-10-24 12:06:24,568:INFO:                shap: Not installed
2023-10-24 12:06:24,568:INFO:           interpret: Not installed
2023-10-24 12:06:24,568:INFO:                umap: Not installed
2023-10-24 12:06:24,568:INFO:     ydata_profiling: Not installed
2023-10-24 12:06:24,568:INFO:  explainerdashboard: Not installed
2023-10-24 12:06:24,568:INFO:             autoviz: Not installed
2023-10-24 12:06:24,568:INFO:           fairlearn: Not installed
2023-10-24 12:06:24,568:INFO:          deepchecks: Not installed
2023-10-24 12:06:24,568:INFO:             xgboost: Not installed
2023-10-24 12:06:24,568:INFO:            catboost: 1.0.4
2023-10-24 12:06:24,568:INFO:              kmodes: Not installed
2023-10-24 12:06:24,568:INFO:             mlxtend: Not installed
2023-10-24 12:06:24,568:INFO:       statsforecast: Not installed
2023-10-24 12:06:24,568:INFO:        tune_sklearn: Not installed
2023-10-24 12:06:24,569:INFO:                 ray: Not installed
2023-10-24 12:06:24,569:INFO:            hyperopt: Not installed
2023-10-24 12:06:24,569:INFO:              optuna: Not installed
2023-10-24 12:06:24,569:INFO:               skopt: Not installed
2023-10-24 12:06:24,569:INFO:              mlflow: 2.7.1
2023-10-24 12:06:24,569:INFO:              gradio: Not installed
2023-10-24 12:06:24,569:INFO:             fastapi: Not installed
2023-10-24 12:06:24,569:INFO:             uvicorn: Not installed
2023-10-24 12:06:24,569:INFO:              m2cgen: Not installed
2023-10-24 12:06:24,569:INFO:           evidently: Not installed
2023-10-24 12:06:24,569:INFO:               fugue: Not installed
2023-10-24 12:06:24,569:INFO:           streamlit: Not installed
2023-10-24 12:06:24,569:INFO:             prophet: Not installed
2023-10-24 12:06:24,569:INFO:None
2023-10-24 12:06:24,569:INFO:Set up data.
2023-10-24 12:06:24,599:INFO:Set up folding strategy.
2023-10-24 12:06:24,599:INFO:Set up train/test split.
2023-10-24 12:06:24,624:INFO:Set up index.
2023-10-24 12:06:24,626:INFO:Assigning column types.
2023-10-24 12:06:24,642:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 12:06:24,642:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 12:06:24,646:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 12:06:24,650:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:06:24,710:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:06:24,751:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:06:24,751:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:06:24,751:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:06:24,752:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 12:06:24,756:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 12:06:24,760:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:06:24,819:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:06:24,859:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:06:24,859:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:06:24,860:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:06:24,860:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 12:06:24,864:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 12:06:24,868:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:06:24,927:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:06:24,968:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:06:24,969:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:06:24,969:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:06:24,974:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 12:06:24,978:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:06:25,036:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:06:25,076:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:06:25,076:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:06:25,077:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:06:25,077:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 12:06:25,085:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:06:25,143:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:06:25,182:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:06:25,183:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:06:25,183:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:06:25,192:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:06:25,250:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:06:25,292:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:06:25,293:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:06:25,293:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:06:25,294:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 12:06:25,360:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:06:25,400:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:06:25,400:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:06:25,400:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:06:25,466:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:06:25,506:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:06:25,507:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:06:25,507:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:06:25,508:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 12:06:25,576:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:06:25,618:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:06:25,628:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:06:25,703:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:06:25,749:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:06:25,749:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:06:25,750:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 12:06:25,858:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:06:25,858:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:06:25,971:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:06:25,971:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:06:25,972:INFO:Preparing preprocessing pipeline...
2023-10-24 12:06:25,972:INFO:Set up date feature engineering.
2023-10-24 12:06:25,973:INFO:Set up simple imputation.
2023-10-24 12:06:25,984:INFO:Set up encoding of ordinal features.
2023-10-24 12:06:26,007:INFO:Set up encoding of categorical features.
2023-10-24 12:06:26,010:INFO:Set up column name cleaning.
2023-10-24 12:06:26,266:INFO:Finished creating preprocessing pipeline.
2023-10-24 12:06:26,354:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_...
NaN   -1
dtype: int64},
                                                                        {'col': 'rime',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 12:06:26,355:INFO:Creating final display dataframe.
2023-10-24 12:06:26,867:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (32819, 50)
4        Transformed data shape  (32819, 52)
5   Transformed train set shape  (22973, 52)
6    Transformed test set shape   (9846, 52)
7              Ordinal features            4
8              Numeric features           44
9                 Date features            1
10         Categorical features            4
11     Rows with missing values        19.9%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18               Fold Generator        KFold
19                  Fold Number           10
20                     CPU Jobs           -1
21                      Use GPU        False
22               Log Experiment        False
23              Experiment Name        exp_B
24                          USI         f468
2023-10-24 12:06:26,981:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:06:26,982:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:06:27,090:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:06:27,090:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:06:27,091:INFO:setup() successfully completed in 2.53s...............
2023-10-24 12:06:27,091:INFO:Initializing create_model()
2023-10-24 12:06:27,091:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dd7ed6d30>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 12:06:27,091:INFO:Checking exceptions
2023-10-24 12:06:27,094:INFO:Importing libraries
2023-10-24 12:06:27,094:INFO:Copying training dataset
2023-10-24 12:06:27,112:INFO:Defining folds
2023-10-24 12:06:27,112:INFO:Declaring metric variables
2023-10-24 12:06:27,113:INFO:Importing untrained model
2023-10-24 12:06:27,113:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 12:06:27,113:INFO:Starting cross validation
2023-10-24 12:06:27,115:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 12:06:36,919:INFO:Calculating mean and std
2023-10-24 12:06:36,921:INFO:Creating metrics dataframe
2023-10-24 12:06:36,923:INFO:Finalizing model
2023-10-24 12:06:37,289:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004788 seconds.
2023-10-24 12:06:37,289:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:06:37,289:INFO:[LightGBM] [Info] Total Bins 6517
2023-10-24 12:06:37,290:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 48
2023-10-24 12:06:37,290:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-24 12:06:37,465:INFO:Uploading results into container
2023-10-24 12:06:37,465:INFO:Uploading model into container now
2023-10-24 12:06:37,471:INFO:_master_model_container: 1
2023-10-24 12:06:37,471:INFO:_display_container: 2
2023-10-24 12:06:37,472:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 12:06:37,472:INFO:create_model() successfully completed......................................
2023-10-24 12:06:37,575:INFO:Initializing finalize_model()
2023-10-24 12:06:37,575:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dd7ed6d30>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-24 12:06:37,576:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 12:06:37,595:INFO:Initializing create_model()
2023-10-24 12:06:37,595:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dd7ed6d30>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-24 12:06:37,595:INFO:Checking exceptions
2023-10-24 12:06:37,596:INFO:Importing libraries
2023-10-24 12:06:37,596:INFO:Copying training dataset
2023-10-24 12:06:37,597:INFO:Defining folds
2023-10-24 12:06:37,597:INFO:Declaring metric variables
2023-10-24 12:06:37,598:INFO:Importing untrained model
2023-10-24 12:06:37,598:INFO:Declaring custom model
2023-10-24 12:06:37,598:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 12:06:37,600:INFO:Cross validation set to False
2023-10-24 12:06:37,600:INFO:Fitting Model
2023-10-24 12:06:38,051:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006121 seconds.
2023-10-24 12:06:38,051:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:06:38,052:INFO:[LightGBM] [Info] Total Bins 6595
2023-10-24 12:06:38,052:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 48
2023-10-24 12:06:38,053:INFO:[LightGBM] [Info] Start training from score 96.893335
2023-10-24 12:06:38,377:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 12:06:38,377:INFO:create_model() successfully completed......................................
2023-10-24 12:06:38,471:INFO:_master_model_container: 1
2023-10-24 12:06:38,471:INFO:_display_container: 2
2023-10-24 12:06:38,567:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 12:06:38,567:INFO:finalize_model() successfully completed......................................
2023-10-24 12:06:38,846:INFO:Initializing save_model()
2023-10-24 12:06:38,846:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_B, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_...
NaN   -1
dtype: int64},
                                                                        {'col': 'rime',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-24 12:06:38,846:INFO:Adding model into prep_pipe
2023-10-24 12:06:38,846:WARNING:Only Model saved as it was a pipeline.
2023-10-24 12:06:38,856:INFO:final_model_for_location_B.pkl saved in current working directory
2023-10-24 12:06:38,969:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 12:06:38,969:INFO:save_model() successfully completed......................................
2023-10-24 12:06:39,078:INFO:PyCaret RegressionExperiment
2023-10-24 12:06:39,078:INFO:Logging name: exp_C
2023-10-24 12:06:39,078:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 12:06:39,078:INFO:version 3.1.0
2023-10-24 12:06:39,078:INFO:Initializing setup()
2023-10-24 12:06:39,078:INFO:self.USI: 9763
2023-10-24 12:06:39,078:INFO:self._variable_keys: {'exp_id', 'target_param', 'USI', 'data', 'fold_shuffle_param', 'log_plots_param', 'X_test', 'memory', 'idx', 'y', 'X', 'X_train', 'gpu_n_jobs_param', 'n_jobs_param', 'gpu_param', 'logging_param', 'fold_generator', 'pipeline', 'y_test', 'y_train', '_ml_usecase', '_available_plots', 'html_param', 'exp_name_log', 'transform_target_param', 'seed', 'fold_groups_param'}
2023-10-24 12:06:39,078:INFO:Checking environment
2023-10-24 12:06:39,079:INFO:python_version: 3.8.5
2023-10-24 12:06:39,079:INFO:python_build: ('default', 'Sep  4 2020 02:22:02')
2023-10-24 12:06:39,079:INFO:machine: x86_64
2023-10-24 12:06:39,079:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-10-24 12:06:39,079:INFO:Memory: svmem(total=8589934592, available=2751397888, percent=68.0, used=4540633088, free=385052672, active=2236600320, inactive=2363957248, wired=2304032768)
2023-10-24 12:06:39,079:INFO:Physical Core: 4
2023-10-24 12:06:39,079:INFO:Logical Core: 8
2023-10-24 12:06:39,079:INFO:Checking libraries
2023-10-24 12:06:39,079:INFO:System:
2023-10-24 12:06:39,079:INFO:    python: 3.8.5 (default, Sep  4 2020, 02:22:02)  [Clang 10.0.0 ]
2023-10-24 12:06:39,079:INFO:executable: /Users/kaja/opt/anaconda3/bin/python
2023-10-24 12:06:39,079:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-10-24 12:06:39,079:INFO:PyCaret required dependencies:
2023-10-24 12:06:39,079:INFO:                 pip: 23.3.1
2023-10-24 12:06:39,079:INFO:          setuptools: 68.2.2
2023-10-24 12:06:39,079:INFO:             pycaret: 3.1.0
2023-10-24 12:06:39,079:INFO:             IPython: 7.19.0
2023-10-24 12:06:39,079:INFO:          ipywidgets: 8.1.1
2023-10-24 12:06:39,079:INFO:                tqdm: 4.66.1
2023-10-24 12:06:39,079:INFO:               numpy: 1.23.5
2023-10-24 12:06:39,079:INFO:              pandas: 1.5.3
2023-10-24 12:06:39,079:INFO:              jinja2: 3.1.2
2023-10-24 12:06:39,079:INFO:               scipy: 1.10.1
2023-10-24 12:06:39,079:INFO:              joblib: 1.3.2
2023-10-24 12:06:39,079:INFO:             sklearn: 1.2.2
2023-10-24 12:06:39,079:INFO:                pyod: 1.1.0
2023-10-24 12:06:39,079:INFO:            imblearn: 0.11.0
2023-10-24 12:06:39,080:INFO:   category_encoders: 2.6.2
2023-10-24 12:06:39,080:INFO:            lightgbm: 4.1.0
2023-10-24 12:06:39,080:INFO:               numba: 0.58.1
2023-10-24 12:06:39,080:INFO:            requests: 2.28.2
2023-10-24 12:06:39,080:INFO:          matplotlib: 3.7.3
2023-10-24 12:06:39,080:INFO:          scikitplot: 0.3.7
2023-10-24 12:06:39,080:INFO:         yellowbrick: 1.5
2023-10-24 12:06:39,080:INFO:              plotly: 5.17.0
2023-10-24 12:06:39,080:INFO:    plotly-resampler: Not installed
2023-10-24 12:06:39,080:INFO:             kaleido: 0.2.1
2023-10-24 12:06:39,080:INFO:           schemdraw: 0.15
2023-10-24 12:06:39,080:INFO:         statsmodels: 0.14.0
2023-10-24 12:06:39,080:INFO:              sktime: 0.21.1
2023-10-24 12:06:39,080:INFO:               tbats: 1.1.3
2023-10-24 12:06:39,080:INFO:            pmdarima: 2.0.4
2023-10-24 12:06:39,080:INFO:              psutil: 5.9.6
2023-10-24 12:06:39,080:INFO:          markupsafe: 2.1.2
2023-10-24 12:06:39,080:INFO:             pickle5: Not installed
2023-10-24 12:06:39,080:INFO:         cloudpickle: 1.6.0
2023-10-24 12:06:39,080:INFO:         deprecation: 2.1.0
2023-10-24 12:06:39,080:INFO:              xxhash: 3.4.1
2023-10-24 12:06:39,080:INFO:           wurlitzer: 2.0.1
2023-10-24 12:06:39,080:INFO:PyCaret optional dependencies:
2023-10-24 12:06:39,080:INFO:                shap: Not installed
2023-10-24 12:06:39,080:INFO:           interpret: Not installed
2023-10-24 12:06:39,080:INFO:                umap: Not installed
2023-10-24 12:06:39,080:INFO:     ydata_profiling: Not installed
2023-10-24 12:06:39,080:INFO:  explainerdashboard: Not installed
2023-10-24 12:06:39,080:INFO:             autoviz: Not installed
2023-10-24 12:06:39,080:INFO:           fairlearn: Not installed
2023-10-24 12:06:39,080:INFO:          deepchecks: Not installed
2023-10-24 12:06:39,081:INFO:             xgboost: Not installed
2023-10-24 12:06:39,081:INFO:            catboost: 1.0.4
2023-10-24 12:06:39,081:INFO:              kmodes: Not installed
2023-10-24 12:06:39,081:INFO:             mlxtend: Not installed
2023-10-24 12:06:39,081:INFO:       statsforecast: Not installed
2023-10-24 12:06:39,081:INFO:        tune_sklearn: Not installed
2023-10-24 12:06:39,081:INFO:                 ray: Not installed
2023-10-24 12:06:39,081:INFO:            hyperopt: Not installed
2023-10-24 12:06:39,081:INFO:              optuna: Not installed
2023-10-24 12:06:39,081:INFO:               skopt: Not installed
2023-10-24 12:06:39,081:INFO:              mlflow: 2.7.1
2023-10-24 12:06:39,081:INFO:              gradio: Not installed
2023-10-24 12:06:39,081:INFO:             fastapi: Not installed
2023-10-24 12:06:39,081:INFO:             uvicorn: Not installed
2023-10-24 12:06:39,081:INFO:              m2cgen: Not installed
2023-10-24 12:06:39,081:INFO:           evidently: Not installed
2023-10-24 12:06:39,081:INFO:               fugue: Not installed
2023-10-24 12:06:39,081:INFO:           streamlit: Not installed
2023-10-24 12:06:39,081:INFO:             prophet: Not installed
2023-10-24 12:06:39,081:INFO:None
2023-10-24 12:06:39,081:INFO:Set up data.
2023-10-24 12:06:39,115:INFO:Set up folding strategy.
2023-10-24 12:06:39,115:INFO:Set up train/test split.
2023-10-24 12:06:39,135:INFO:Set up index.
2023-10-24 12:06:39,136:INFO:Assigning column types.
2023-10-24 12:06:39,147:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 12:06:39,147:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 12:06:39,151:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 12:06:39,155:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:06:39,212:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:06:39,253:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:06:39,254:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:06:39,254:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:06:39,255:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 12:06:39,259:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 12:06:39,263:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:06:39,321:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:06:39,362:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:06:39,363:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:06:39,363:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:06:39,363:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 12:06:39,367:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 12:06:39,372:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:06:39,430:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:06:39,471:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:06:39,472:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:06:39,472:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:06:39,476:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 12:06:39,480:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:06:39,538:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:06:39,577:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:06:39,578:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:06:39,578:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:06:39,578:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 12:06:39,586:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:06:39,645:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:06:39,684:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:06:39,685:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:06:39,685:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:06:39,694:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:06:39,752:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:06:39,791:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:06:39,792:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:06:39,792:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:06:39,792:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 12:06:39,857:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:06:39,897:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:06:39,897:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:06:39,898:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:06:39,965:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:06:40,005:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:06:40,005:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:06:40,005:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:06:40,006:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 12:06:40,070:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:06:40,112:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:06:40,112:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:06:40,180:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:06:40,220:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:06:40,221:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:06:40,221:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 12:06:40,334:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:06:40,335:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:06:40,448:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:06:40,449:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:06:40,450:INFO:Preparing preprocessing pipeline...
2023-10-24 12:06:40,450:INFO:Set up date feature engineering.
2023-10-24 12:06:40,450:INFO:Set up simple imputation.
2023-10-24 12:06:40,460:INFO:Set up encoding of ordinal features.
2023-10-24 12:06:40,478:INFO:Set up encoding of categorical features.
2023-10-24 12:06:40,479:INFO:Set up column name cleaning.
2023-10-24 12:06:40,708:INFO:Finished creating preprocessing pipeline.
2023-10-24 12:06:40,797:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_...
NaN   -1
dtype: int64},
                                                                        {'col': 'rime',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 12:06:40,797:INFO:Creating final display dataframe.
2023-10-24 12:06:41,267:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (26071, 50)
4        Transformed data shape  (26071, 52)
5   Transformed train set shape  (18249, 52)
6    Transformed test set shape   (7822, 52)
7              Ordinal features            4
8              Numeric features           44
9                 Date features            1
10         Categorical features            4
11     Rows with missing values        25.0%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18               Fold Generator        KFold
19                  Fold Number           10
20                     CPU Jobs           -1
21                      Use GPU        False
22               Log Experiment        False
23              Experiment Name        exp_C
24                          USI         9763
2023-10-24 12:06:41,381:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:06:41,382:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:06:41,488:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:06:41,489:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:06:41,489:INFO:setup() successfully completed in 2.41s...............
2023-10-24 12:06:41,489:INFO:Initializing create_model()
2023-10-24 12:06:41,489:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dc9c96e20>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 12:06:41,489:INFO:Checking exceptions
2023-10-24 12:06:41,492:INFO:Importing libraries
2023-10-24 12:06:41,492:INFO:Copying training dataset
2023-10-24 12:06:41,507:INFO:Defining folds
2023-10-24 12:06:41,507:INFO:Declaring metric variables
2023-10-24 12:06:41,508:INFO:Importing untrained model
2023-10-24 12:06:41,508:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 12:06:41,508:INFO:Starting cross validation
2023-10-24 12:06:41,510:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 12:06:49,971:INFO:Calculating mean and std
2023-10-24 12:06:49,973:INFO:Creating metrics dataframe
2023-10-24 12:06:49,975:INFO:Finalizing model
2023-10-24 12:06:50,212:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003675 seconds.
2023-10-24 12:06:50,212:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:06:50,212:INFO:[LightGBM] [Info] Total Bins 6726
2023-10-24 12:06:50,213:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 49
2023-10-24 12:06:50,214:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-24 12:06:50,381:INFO:Uploading results into container
2023-10-24 12:06:50,391:INFO:Uploading model into container now
2023-10-24 12:06:50,415:INFO:_master_model_container: 1
2023-10-24 12:06:50,432:INFO:_display_container: 2
2023-10-24 12:06:50,432:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 12:06:50,432:INFO:create_model() successfully completed......................................
2023-10-24 12:06:50,532:INFO:Initializing finalize_model()
2023-10-24 12:06:50,532:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dc9c96e20>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-24 12:06:50,532:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 12:06:50,547:INFO:Initializing create_model()
2023-10-24 12:06:50,547:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dc9c96e20>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-24 12:06:50,547:INFO:Checking exceptions
2023-10-24 12:06:50,548:INFO:Importing libraries
2023-10-24 12:06:50,548:INFO:Copying training dataset
2023-10-24 12:06:50,549:INFO:Defining folds
2023-10-24 12:06:50,549:INFO:Declaring metric variables
2023-10-24 12:06:50,549:INFO:Importing untrained model
2023-10-24 12:06:50,549:INFO:Declaring custom model
2023-10-24 12:06:50,550:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 12:06:50,552:INFO:Cross validation set to False
2023-10-24 12:06:50,552:INFO:Fitting Model
2023-10-24 12:06:50,859:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007655 seconds.
2023-10-24 12:06:50,859:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:06:50,859:INFO:[LightGBM] [Info] Total Bins 6800
2023-10-24 12:06:50,860:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 49
2023-10-24 12:06:50,860:INFO:[LightGBM] [Info] Start training from score 77.700043
2023-10-24 12:06:51,154:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 12:06:51,155:INFO:create_model() successfully completed......................................
2023-10-24 12:06:51,248:INFO:_master_model_container: 1
2023-10-24 12:06:51,248:INFO:_display_container: 2
2023-10-24 12:06:51,342:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 12:06:51,342:INFO:finalize_model() successfully completed......................................
2023-10-24 12:06:51,612:INFO:Initializing save_model()
2023-10-24 12:06:51,612:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=final_model_for_location_C, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_...
NaN   -1
dtype: int64},
                                                                        {'col': 'rime',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-24 12:06:51,612:INFO:Adding model into prep_pipe
2023-10-24 12:06:51,612:WARNING:Only Model saved as it was a pipeline.
2023-10-24 12:06:51,622:INFO:final_model_for_location_C.pkl saved in current working directory
2023-10-24 12:06:51,747:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2023-10-24 12:06:51,747:INFO:save_model() successfully completed......................................
2023-10-24 12:06:53,193:INFO:Initializing load_model()
2023-10-24 12:06:53,193:INFO:load_model(model_name=final_model_for_location_A, platform=None, authentication=None, verbose=True)
2023-10-24 12:06:53,199:INFO:Initializing load_model()
2023-10-24 12:06:53,199:INFO:load_model(model_name=final_model_for_location_B, platform=None, authentication=None, verbose=True)
2023-10-24 12:06:53,207:INFO:Initializing load_model()
2023-10-24 12:06:53,207:INFO:load_model(model_name=final_model_for_location_C, platform=None, authentication=None, verbose=True)
2023-10-24 12:06:53,329:INFO:Initializing predict_model()
2023-10-24 12:06:53,330:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dc9c96e20>, estimator=Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_...
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f9d498a2ee0>)
2023-10-24 12:06:53,330:INFO:Checking exceptions
2023-10-24 12:06:53,330:INFO:Preloading libraries
2023-10-24 12:06:53,330:INFO:Set up data.
2023-10-24 12:06:53,348:INFO:Set up index.
2023-10-24 12:06:53,612:INFO:Initializing predict_model()
2023-10-24 12:06:53,613:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dc9c96e20>, estimator=Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_...
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f9d434c38b0>)
2023-10-24 12:06:53,613:INFO:Checking exceptions
2023-10-24 12:06:53,613:INFO:Preloading libraries
2023-10-24 12:06:53,613:INFO:Set up data.
2023-10-24 12:06:53,627:INFO:Set up index.
2023-10-24 12:06:53,872:INFO:Initializing predict_model()
2023-10-24 12:06:53,872:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dc9c96e20>, estimator=Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_...
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f9d434c38b0>)
2023-10-24 12:06:53,872:INFO:Checking exceptions
2023-10-24 12:06:53,872:INFO:Preloading libraries
2023-10-24 12:06:53,872:INFO:Set up data.
2023-10-24 12:06:53,883:INFO:Set up index.
2023-10-24 12:09:05,904:INFO:PyCaret RegressionExperiment
2023-10-24 12:09:05,904:INFO:Logging name: exp_A
2023-10-24 12:09:05,904:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 12:09:05,904:INFO:version 3.1.0
2023-10-24 12:09:05,905:INFO:Initializing setup()
2023-10-24 12:09:05,905:INFO:self.USI: 6817
2023-10-24 12:09:05,905:INFO:self._variable_keys: {'exp_id', 'target_param', 'USI', 'data', 'fold_shuffle_param', 'log_plots_param', 'X_test', 'memory', 'idx', 'y', 'X', 'X_train', 'gpu_n_jobs_param', 'n_jobs_param', 'gpu_param', 'logging_param', 'fold_generator', 'pipeline', 'y_test', 'y_train', '_ml_usecase', '_available_plots', 'html_param', 'exp_name_log', 'transform_target_param', 'seed', 'fold_groups_param'}
2023-10-24 12:09:05,905:INFO:Checking environment
2023-10-24 12:09:05,905:INFO:python_version: 3.8.5
2023-10-24 12:09:05,905:INFO:python_build: ('default', 'Sep  4 2020 02:22:02')
2023-10-24 12:09:05,905:INFO:machine: x86_64
2023-10-24 12:09:05,905:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-10-24 12:09:05,905:INFO:Memory: svmem(total=8589934592, available=2275598336, percent=73.5, used=4566155264, free=35151872, active=2240954368, inactive=2235977728, wired=2325200896)
2023-10-24 12:09:05,905:INFO:Physical Core: 4
2023-10-24 12:09:05,905:INFO:Logical Core: 8
2023-10-24 12:09:05,905:INFO:Checking libraries
2023-10-24 12:09:05,905:INFO:System:
2023-10-24 12:09:05,905:INFO:    python: 3.8.5 (default, Sep  4 2020, 02:22:02)  [Clang 10.0.0 ]
2023-10-24 12:09:05,905:INFO:executable: /Users/kaja/opt/anaconda3/bin/python
2023-10-24 12:09:05,905:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-10-24 12:09:05,905:INFO:PyCaret required dependencies:
2023-10-24 12:09:05,905:INFO:                 pip: 23.3.1
2023-10-24 12:09:05,906:INFO:          setuptools: 68.2.2
2023-10-24 12:09:05,906:INFO:             pycaret: 3.1.0
2023-10-24 12:09:05,906:INFO:             IPython: 7.19.0
2023-10-24 12:09:05,906:INFO:          ipywidgets: 8.1.1
2023-10-24 12:09:05,906:INFO:                tqdm: 4.66.1
2023-10-24 12:09:05,906:INFO:               numpy: 1.23.5
2023-10-24 12:09:05,906:INFO:              pandas: 1.5.3
2023-10-24 12:09:05,906:INFO:              jinja2: 3.1.2
2023-10-24 12:09:05,906:INFO:               scipy: 1.10.1
2023-10-24 12:09:05,906:INFO:              joblib: 1.3.2
2023-10-24 12:09:05,906:INFO:             sklearn: 1.2.2
2023-10-24 12:09:05,906:INFO:                pyod: 1.1.0
2023-10-24 12:09:05,906:INFO:            imblearn: 0.11.0
2023-10-24 12:09:05,907:INFO:   category_encoders: 2.6.2
2023-10-24 12:09:05,907:INFO:            lightgbm: 4.1.0
2023-10-24 12:09:05,907:INFO:               numba: 0.58.1
2023-10-24 12:09:05,907:INFO:            requests: 2.28.2
2023-10-24 12:09:05,907:INFO:          matplotlib: 3.7.3
2023-10-24 12:09:05,907:INFO:          scikitplot: 0.3.7
2023-10-24 12:09:05,907:INFO:         yellowbrick: 1.5
2023-10-24 12:09:05,907:INFO:              plotly: 5.17.0
2023-10-24 12:09:05,907:INFO:    plotly-resampler: Not installed
2023-10-24 12:09:05,907:INFO:             kaleido: 0.2.1
2023-10-24 12:09:05,907:INFO:           schemdraw: 0.15
2023-10-24 12:09:05,907:INFO:         statsmodels: 0.14.0
2023-10-24 12:09:05,907:INFO:              sktime: 0.21.1
2023-10-24 12:09:05,907:INFO:               tbats: 1.1.3
2023-10-24 12:09:05,907:INFO:            pmdarima: 2.0.4
2023-10-24 12:09:05,907:INFO:              psutil: 5.9.6
2023-10-24 12:09:05,907:INFO:          markupsafe: 2.1.2
2023-10-24 12:09:05,907:INFO:             pickle5: Not installed
2023-10-24 12:09:05,907:INFO:         cloudpickle: 1.6.0
2023-10-24 12:09:05,907:INFO:         deprecation: 2.1.0
2023-10-24 12:09:05,907:INFO:              xxhash: 3.4.1
2023-10-24 12:09:05,907:INFO:           wurlitzer: 2.0.1
2023-10-24 12:09:05,907:INFO:PyCaret optional dependencies:
2023-10-24 12:09:05,907:INFO:                shap: Not installed
2023-10-24 12:09:05,907:INFO:           interpret: Not installed
2023-10-24 12:09:05,907:INFO:                umap: Not installed
2023-10-24 12:09:05,907:INFO:     ydata_profiling: Not installed
2023-10-24 12:09:05,907:INFO:  explainerdashboard: Not installed
2023-10-24 12:09:05,907:INFO:             autoviz: Not installed
2023-10-24 12:09:05,907:INFO:           fairlearn: Not installed
2023-10-24 12:09:05,907:INFO:          deepchecks: Not installed
2023-10-24 12:09:05,907:INFO:             xgboost: Not installed
2023-10-24 12:09:05,908:INFO:            catboost: 1.0.4
2023-10-24 12:09:05,908:INFO:              kmodes: Not installed
2023-10-24 12:09:05,908:INFO:             mlxtend: Not installed
2023-10-24 12:09:05,908:INFO:       statsforecast: Not installed
2023-10-24 12:09:05,908:INFO:        tune_sklearn: Not installed
2023-10-24 12:09:05,908:INFO:                 ray: Not installed
2023-10-24 12:09:05,908:INFO:            hyperopt: Not installed
2023-10-24 12:09:05,908:INFO:              optuna: Not installed
2023-10-24 12:09:05,908:INFO:               skopt: Not installed
2023-10-24 12:09:05,908:INFO:              mlflow: 2.7.1
2023-10-24 12:09:05,908:INFO:              gradio: Not installed
2023-10-24 12:09:05,908:INFO:             fastapi: Not installed
2023-10-24 12:09:05,908:INFO:             uvicorn: Not installed
2023-10-24 12:09:05,908:INFO:              m2cgen: Not installed
2023-10-24 12:09:05,908:INFO:           evidently: Not installed
2023-10-24 12:09:05,908:INFO:               fugue: Not installed
2023-10-24 12:09:05,908:INFO:           streamlit: Not installed
2023-10-24 12:09:05,908:INFO:             prophet: Not installed
2023-10-24 12:09:05,908:INFO:None
2023-10-24 12:09:05,908:INFO:Set up data.
2023-10-24 12:09:05,944:INFO:Set up folding strategy.
2023-10-24 12:09:05,945:INFO:Set up train/test split.
2023-10-24 12:09:05,974:INFO:Set up index.
2023-10-24 12:09:05,975:INFO:Assigning column types.
2023-10-24 12:09:05,991:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 12:09:05,991:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 12:09:05,995:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 12:09:05,999:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:09:06,061:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:09:06,103:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:09:06,104:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:09:06,104:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:09:06,104:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 12:09:06,109:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 12:09:06,113:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:09:06,175:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:09:06,215:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:09:06,216:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:09:06,216:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:09:06,217:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 12:09:06,221:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 12:09:06,225:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:09:06,285:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:09:06,325:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:09:06,325:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:09:06,326:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:09:06,330:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 12:09:06,334:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:09:06,393:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:09:06,435:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:09:06,435:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:09:06,435:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:09:06,436:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 12:09:06,445:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:09:06,506:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:09:06,546:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:09:06,549:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:09:06,549:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:09:06,558:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:09:06,618:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:09:06,657:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:09:06,658:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:09:06,658:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:09:06,659:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 12:09:06,727:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:09:06,767:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:09:06,768:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:09:06,768:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:09:06,836:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:09:06,876:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:09:06,877:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:09:06,877:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:09:06,877:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 12:09:06,956:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:09:06,997:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:09:06,998:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:09:07,124:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:09:07,165:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:09:07,165:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:09:07,166:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 12:09:07,280:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:09:07,280:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:09:07,392:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:09:07,393:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:09:07,394:INFO:Preparing preprocessing pipeline...
2023-10-24 12:09:07,394:INFO:Set up date feature engineering.
2023-10-24 12:09:07,394:INFO:Set up simple imputation.
2023-10-24 12:09:07,404:INFO:Set up encoding of ordinal features.
2023-10-24 12:09:07,422:INFO:Set up encoding of categorical features.
2023-10-24 12:09:07,424:INFO:Set up column name cleaning.
2023-10-24 12:09:07,678:INFO:Finished creating preprocessing pipeline.
2023-10-24 12:09:07,766:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_...
NaN   -1
dtype: int64},
                                                                        {'col': 'rime',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 12:09:07,766:INFO:Creating final display dataframe.
2023-10-24 12:09:08,046:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (34061, 50)
4        Transformed data shape  (34061, 52)
5   Transformed train set shape  (23842, 52)
6    Transformed test set shape  (10219, 52)
7              Ordinal features            4
8              Numeric features           44
9                 Date features            1
10         Categorical features            4
11     Rows with missing values        23.1%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18               Fold Generator        KFold
19                  Fold Number           10
20                     CPU Jobs           -1
21                      Use GPU        False
22               Log Experiment        False
23              Experiment Name        exp_A
24                          USI         6817
2023-10-24 12:09:08,164:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:09:08,164:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:09:08,274:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:09:08,275:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:09:08,275:INFO:setup() successfully completed in 2.38s...............
2023-10-24 12:09:08,276:INFO:Initializing create_model()
2023-10-24 12:09:08,276:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9d427982e0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 12:09:08,276:INFO:Checking exceptions
2023-10-24 12:09:08,278:INFO:Importing libraries
2023-10-24 12:09:08,278:INFO:Copying training dataset
2023-10-24 12:09:08,294:INFO:Defining folds
2023-10-24 12:09:08,295:INFO:Declaring metric variables
2023-10-24 12:09:08,295:INFO:Importing untrained model
2023-10-24 12:09:08,295:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 12:09:08,296:INFO:Starting cross validation
2023-10-24 12:09:08,297:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 12:09:17,473:INFO:Calculating mean and std
2023-10-24 12:09:17,475:INFO:Creating metrics dataframe
2023-10-24 12:09:17,477:INFO:Finalizing model
2023-10-24 12:09:17,787:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008260 seconds.
2023-10-24 12:09:17,787:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:09:17,787:INFO:[LightGBM] [Info] Total Bins 6533
2023-10-24 12:09:17,787:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 48
2023-10-24 12:09:17,788:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-24 12:09:17,985:INFO:Uploading results into container
2023-10-24 12:09:17,987:INFO:Uploading model into container now
2023-10-24 12:09:17,992:INFO:_master_model_container: 1
2023-10-24 12:09:17,992:INFO:_display_container: 2
2023-10-24 12:09:17,993:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 12:09:17,993:INFO:create_model() successfully completed......................................
2023-10-24 12:09:18,310:INFO:Initializing tune_model()
2023-10-24 12:09:18,310:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9d427982e0>)
2023-10-24 12:09:18,311:INFO:Checking exceptions
2023-10-24 12:09:18,323:INFO:Copying training dataset
2023-10-24 12:09:18,339:INFO:Checking base model
2023-10-24 12:09:18,339:INFO:Base model : Light Gradient Boosting Machine
2023-10-24 12:09:18,340:INFO:Declaring metric variables
2023-10-24 12:09:18,340:INFO:Defining Hyperparameters
2023-10-24 12:09:18,432:INFO:Tuning with n_jobs=-1
2023-10-24 12:09:18,432:INFO:Initializing RandomizedSearchCV
2023-10-24 12:12:30,875:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-24 12:12:30,876:INFO:Hyperparameter search completed
2023-10-24 12:12:30,876:INFO:SubProcess create_model() called ==================================
2023-10-24 12:12:30,877:INFO:Initializing create_model()
2023-10-24 12:12:30,877:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9d427982e0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9d447654f0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-24 12:12:30,877:INFO:Checking exceptions
2023-10-24 12:12:30,878:INFO:Importing libraries
2023-10-24 12:12:30,878:INFO:Copying training dataset
2023-10-24 12:12:30,907:INFO:Defining folds
2023-10-24 12:12:30,907:INFO:Declaring metric variables
2023-10-24 12:12:30,907:INFO:Importing untrained model
2023-10-24 12:12:30,907:INFO:Declaring custom model
2023-10-24 12:12:30,909:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 12:12:30,909:INFO:Starting cross validation
2023-10-24 12:12:30,911:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 12:13:12,366:INFO:Calculating mean and std
2023-10-24 12:13:12,368:INFO:Creating metrics dataframe
2023-10-24 12:13:12,370:INFO:Finalizing model
2023-10-24 12:13:12,607:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:13:12,607:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:13:12,607:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:13:12,655:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:13:12,655:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:13:12,655:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:13:12,664:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006965 seconds.
2023-10-24 12:13:12,665:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:13:12,666:INFO:[LightGBM] [Info] Total Bins 6533
2023-10-24 12:13:12,669:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 48
2023-10-24 12:13:12,671:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-24 12:13:13,579:INFO:Uploading results into container
2023-10-24 12:13:13,580:INFO:Uploading model into container now
2023-10-24 12:13:13,580:INFO:_master_model_container: 2
2023-10-24 12:13:13,581:INFO:_display_container: 3
2023-10-24 12:13:13,581:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-24 12:13:13,582:INFO:create_model() successfully completed......................................
2023-10-24 12:13:13,680:INFO:SubProcess create_model() end ==================================
2023-10-24 12:13:13,680:INFO:choose_better activated
2023-10-24 12:13:13,681:INFO:SubProcess create_model() called ==================================
2023-10-24 12:13:13,681:INFO:Initializing create_model()
2023-10-24 12:13:13,682:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9d427982e0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 12:13:13,682:INFO:Checking exceptions
2023-10-24 12:13:13,683:INFO:Importing libraries
2023-10-24 12:13:13,683:INFO:Copying training dataset
2023-10-24 12:13:13,701:INFO:Defining folds
2023-10-24 12:13:13,701:INFO:Declaring metric variables
2023-10-24 12:13:13,702:INFO:Importing untrained model
2023-10-24 12:13:13,702:INFO:Declaring custom model
2023-10-24 12:13:13,703:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 12:13:13,703:INFO:Starting cross validation
2023-10-24 12:13:13,705:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 12:13:22,557:INFO:Calculating mean and std
2023-10-24 12:13:22,558:INFO:Creating metrics dataframe
2023-10-24 12:13:22,560:INFO:Finalizing model
2023-10-24 12:13:22,865:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007642 seconds.
2023-10-24 12:13:22,865:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:13:22,865:INFO:[LightGBM] [Info] Total Bins 6533
2023-10-24 12:13:22,866:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 48
2023-10-24 12:13:22,866:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-24 12:13:23,048:INFO:Uploading results into container
2023-10-24 12:13:23,049:INFO:Uploading model into container now
2023-10-24 12:13:23,049:INFO:_master_model_container: 3
2023-10-24 12:13:23,049:INFO:_display_container: 4
2023-10-24 12:13:23,049:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 12:13:23,050:INFO:create_model() successfully completed......................................
2023-10-24 12:13:23,148:INFO:SubProcess create_model() end ==================================
2023-10-24 12:13:23,148:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8738
2023-10-24 12:13:23,149:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8737
2023-10-24 12:13:23,150:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-24 12:13:23,150:INFO:choose_better completed
2023-10-24 12:13:23,150:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-24 12:13:23,155:INFO:_master_model_container: 3
2023-10-24 12:13:23,155:INFO:_display_container: 3
2023-10-24 12:13:23,156:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 12:13:23,156:INFO:tune_model() successfully completed......................................
2023-10-24 12:13:23,262:INFO:Initializing ensemble_model()
2023-10-24 12:13:23,262:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9d427982e0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-24 12:13:23,262:INFO:Checking exceptions
2023-10-24 12:13:23,272:INFO:Importing libraries
2023-10-24 12:13:23,272:INFO:Copying training dataset
2023-10-24 12:13:23,272:INFO:Checking base model
2023-10-24 12:13:23,273:INFO:Base model : Light Gradient Boosting Machine
2023-10-24 12:13:23,273:INFO:Importing untrained ensembler
2023-10-24 12:13:23,273:INFO:Ensemble method set to Bagging
2023-10-24 12:13:23,274:INFO:SubProcess create_model() called ==================================
2023-10-24 12:13:23,275:INFO:Initializing create_model()
2023-10-24 12:13:23,275:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9d427982e0>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9d447654f0>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 12:13:23,275:INFO:Checking exceptions
2023-10-24 12:13:23,275:INFO:Importing libraries
2023-10-24 12:13:23,275:INFO:Copying training dataset
2023-10-24 12:13:23,294:INFO:Defining folds
2023-10-24 12:13:23,294:INFO:Declaring metric variables
2023-10-24 12:13:23,295:INFO:Importing untrained model
2023-10-24 12:13:23,295:INFO:Declaring custom model
2023-10-24 12:13:23,298:INFO:Bagging Regressor Imported successfully
2023-10-24 12:13:23,299:INFO:Starting cross validation
2023-10-24 12:13:23,300:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 12:14:45,120:INFO:Calculating mean and std
2023-10-24 12:14:45,122:INFO:Creating metrics dataframe
2023-10-24 12:14:45,126:INFO:Finalizing model
2023-10-24 12:14:45,434:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006994 seconds.
2023-10-24 12:14:45,434:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:14:45,435:INFO:[LightGBM] [Info] Total Bins 6533
2023-10-24 12:14:45,435:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 48
2023-10-24 12:14:45,436:INFO:[LightGBM] [Info] Start training from score 626.831517
2023-10-24 12:14:45,739:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005149 seconds.
2023-10-24 12:14:45,739:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:14:45,739:INFO:[LightGBM] [Info] Total Bins 6533
2023-10-24 12:14:45,740:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 48
2023-10-24 12:14:45,740:INFO:[LightGBM] [Info] Start training from score 640.013980
2023-10-24 12:14:45,993:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004559 seconds.
2023-10-24 12:14:45,993:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:14:45,994:INFO:[LightGBM] [Info] Total Bins 6533
2023-10-24 12:14:45,994:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 48
2023-10-24 12:14:45,995:INFO:[LightGBM] [Info] Start training from score 623.946930
2023-10-24 12:14:46,263:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005155 seconds.
2023-10-24 12:14:46,263:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:14:46,263:INFO:[LightGBM] [Info] Total Bins 6533
2023-10-24 12:14:46,264:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 48
2023-10-24 12:14:46,264:INFO:[LightGBM] [Info] Start training from score 632.335152
2023-10-24 12:14:46,528:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008688 seconds.
2023-10-24 12:14:46,528:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:14:46,528:INFO:[LightGBM] [Info] Total Bins 6533
2023-10-24 12:14:46,529:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 48
2023-10-24 12:14:46,529:INFO:[LightGBM] [Info] Start training from score 620.070240
2023-10-24 12:14:46,776:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004716 seconds.
2023-10-24 12:14:46,777:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:14:46,777:INFO:[LightGBM] [Info] Total Bins 6533
2023-10-24 12:14:46,778:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 48
2023-10-24 12:14:46,778:INFO:[LightGBM] [Info] Start training from score 635.137343
2023-10-24 12:14:47,032:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005278 seconds.
2023-10-24 12:14:47,032:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:14:47,032:INFO:[LightGBM] [Info] Total Bins 6533
2023-10-24 12:14:47,033:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 48
2023-10-24 12:14:47,034:INFO:[LightGBM] [Info] Start training from score 620.066941
2023-10-24 12:14:47,289:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006285 seconds.
2023-10-24 12:14:47,289:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:14:47,289:INFO:[LightGBM] [Info] Total Bins 6533
2023-10-24 12:14:47,290:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 48
2023-10-24 12:14:47,290:INFO:[LightGBM] [Info] Start training from score 623.069874
2023-10-24 12:14:47,543:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005114 seconds.
2023-10-24 12:14:47,544:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:14:47,544:INFO:[LightGBM] [Info] Total Bins 6533
2023-10-24 12:14:47,544:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 48
2023-10-24 12:14:47,545:INFO:[LightGBM] [Info] Start training from score 633.817057
2023-10-24 12:14:47,851:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004660 seconds.
2023-10-24 12:14:47,851:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:14:47,851:INFO:[LightGBM] [Info] Total Bins 6533
2023-10-24 12:14:47,852:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 48
2023-10-24 12:14:47,852:INFO:[LightGBM] [Info] Start training from score 641.113408
2023-10-24 12:14:48,054:INFO:Uploading results into container
2023-10-24 12:14:48,056:INFO:Uploading model into container now
2023-10-24 12:14:48,057:INFO:_master_model_container: 4
2023-10-24 12:14:48,057:INFO:_display_container: 4
2023-10-24 12:14:48,058:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-24 12:14:48,058:INFO:create_model() successfully completed......................................
2023-10-24 12:14:48,159:INFO:SubProcess create_model() end ==================================
2023-10-24 12:14:48,163:INFO:_master_model_container: 4
2023-10-24 12:14:48,164:INFO:_display_container: 4
2023-10-24 12:14:48,165:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-24 12:14:48,165:INFO:ensemble_model() successfully completed......................................
2023-10-24 12:14:48,259:INFO:Initializing finalize_model()
2023-10-24 12:14:48,260:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9d427982e0>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-24 12:14:48,260:INFO:Finalizing BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-24 12:14:48,281:INFO:Initializing create_model()
2023-10-24 12:14:48,281:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9d427982e0>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-24 12:14:48,281:INFO:Checking exceptions
2023-10-24 12:14:48,282:INFO:Importing libraries
2023-10-24 12:14:48,282:INFO:Copying training dataset
2023-10-24 12:14:48,283:INFO:Defining folds
2023-10-24 12:14:48,283:INFO:Declaring metric variables
2023-10-24 12:14:48,284:INFO:Importing untrained model
2023-10-24 12:14:48,284:INFO:Declaring custom model
2023-10-24 12:14:48,285:INFO:Bagging Regressor Imported successfully
2023-10-24 12:14:48,286:INFO:Cross validation set to False
2023-10-24 12:14:48,286:INFO:Fitting Model
2023-10-24 12:14:48,688:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006989 seconds.
2023-10-24 12:14:48,689:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:14:48,689:INFO:[LightGBM] [Info] Total Bins 6648
2023-10-24 12:14:48,690:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 48
2023-10-24 12:14:48,690:INFO:[LightGBM] [Info] Start training from score 634.491655
2023-10-24 12:14:48,986:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006672 seconds.
2023-10-24 12:14:48,987:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:14:48,987:INFO:[LightGBM] [Info] Total Bins 6648
2023-10-24 12:14:48,988:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 48
2023-10-24 12:14:48,988:INFO:[LightGBM] [Info] Start training from score 635.470959
2023-10-24 12:14:49,281:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012087 seconds.
2023-10-24 12:14:49,281:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:14:49,281:INFO:[LightGBM] [Info] Total Bins 6648
2023-10-24 12:14:49,282:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 48
2023-10-24 12:14:49,282:INFO:[LightGBM] [Info] Start training from score 634.053589
2023-10-24 12:14:49,687:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007085 seconds.
2023-10-24 12:14:49,687:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:14:49,688:INFO:[LightGBM] [Info] Total Bins 6648
2023-10-24 12:14:49,688:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 48
2023-10-24 12:14:49,689:INFO:[LightGBM] [Info] Start training from score 635.251785
2023-10-24 12:14:50,065:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009453 seconds.
2023-10-24 12:14:50,065:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:14:50,065:INFO:[LightGBM] [Info] Total Bins 6648
2023-10-24 12:14:50,066:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 48
2023-10-24 12:14:50,066:INFO:[LightGBM] [Info] Start training from score 627.555784
2023-10-24 12:14:50,381:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011814 seconds.
2023-10-24 12:14:50,381:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:14:50,381:INFO:[LightGBM] [Info] Total Bins 6648
2023-10-24 12:14:50,382:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 48
2023-10-24 12:14:50,382:INFO:[LightGBM] [Info] Start training from score 638.162596
2023-10-24 12:14:50,692:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007505 seconds.
2023-10-24 12:14:50,692:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:14:50,692:INFO:[LightGBM] [Info] Total Bins 6648
2023-10-24 12:14:50,693:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 48
2023-10-24 12:14:50,694:INFO:[LightGBM] [Info] Start training from score 633.181363
2023-10-24 12:14:51,013:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007205 seconds.
2023-10-24 12:14:51,013:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:14:51,013:INFO:[LightGBM] [Info] Total Bins 6648
2023-10-24 12:14:51,014:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 48
2023-10-24 12:14:51,014:INFO:[LightGBM] [Info] Start training from score 611.992287
2023-10-24 12:14:51,380:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006746 seconds.
2023-10-24 12:14:51,380:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:14:51,380:INFO:[LightGBM] [Info] Total Bins 6648
2023-10-24 12:14:51,381:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 48
2023-10-24 12:14:51,381:INFO:[LightGBM] [Info] Start training from score 638.181417
2023-10-24 12:14:51,686:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007171 seconds.
2023-10-24 12:14:51,686:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:14:51,687:INFO:[LightGBM] [Info] Total Bins 6648
2023-10-24 12:14:51,687:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 48
2023-10-24 12:14:51,688:INFO:[LightGBM] [Info] Start training from score 639.502137
2023-10-24 12:14:52,040:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-24 12:14:52,041:INFO:create_model() successfully completed......................................
2023-10-24 12:14:52,138:INFO:_master_model_container: 4
2023-10-24 12:14:52,138:INFO:_display_container: 4
2023-10-24 12:14:52,245:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-24 12:14:52,245:INFO:finalize_model() successfully completed......................................
2023-10-24 12:14:52,532:INFO:Initializing save_model()
2023-10-24 12:14:52,532:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), model_name=final_model_for_location_A, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_...
NaN   -1
dtype: int64},
                                                                        {'col': 'rime',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-24 12:14:52,532:INFO:Adding model into prep_pipe
2023-10-24 12:14:52,532:WARNING:Only Model saved as it was a pipeline.
2023-10-24 12:14:52,579:INFO:final_model_for_location_A.pkl saved in current working directory
2023-10-24 12:14:52,705:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-24 12:14:52,705:INFO:save_model() successfully completed......................................
2023-10-24 12:14:52,822:INFO:PyCaret RegressionExperiment
2023-10-24 12:14:52,822:INFO:Logging name: exp_B
2023-10-24 12:14:52,822:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 12:14:52,822:INFO:version 3.1.0
2023-10-24 12:14:52,822:INFO:Initializing setup()
2023-10-24 12:14:52,822:INFO:self.USI: 0853
2023-10-24 12:14:52,822:INFO:self._variable_keys: {'exp_id', 'target_param', 'USI', 'data', 'fold_shuffle_param', 'log_plots_param', 'X_test', 'memory', 'idx', 'y', 'X', 'X_train', 'gpu_n_jobs_param', 'n_jobs_param', 'gpu_param', 'logging_param', 'fold_generator', 'pipeline', 'y_test', 'y_train', '_ml_usecase', '_available_plots', 'html_param', 'exp_name_log', 'transform_target_param', 'seed', 'fold_groups_param'}
2023-10-24 12:14:52,822:INFO:Checking environment
2023-10-24 12:14:52,822:INFO:python_version: 3.8.5
2023-10-24 12:14:52,822:INFO:python_build: ('default', 'Sep  4 2020 02:22:02')
2023-10-24 12:14:52,822:INFO:machine: x86_64
2023-10-24 12:14:52,822:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-10-24 12:14:52,822:INFO:Memory: svmem(total=8589934592, available=2627211264, percent=69.4, used=4562317312, free=259805184, active=2370297856, inactive=2353971200, wired=2192019456)
2023-10-24 12:14:52,823:INFO:Physical Core: 4
2023-10-24 12:14:52,823:INFO:Logical Core: 8
2023-10-24 12:14:52,823:INFO:Checking libraries
2023-10-24 12:14:52,823:INFO:System:
2023-10-24 12:14:52,823:INFO:    python: 3.8.5 (default, Sep  4 2020, 02:22:02)  [Clang 10.0.0 ]
2023-10-24 12:14:52,823:INFO:executable: /Users/kaja/opt/anaconda3/bin/python
2023-10-24 12:14:52,823:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-10-24 12:14:52,823:INFO:PyCaret required dependencies:
2023-10-24 12:14:52,823:INFO:                 pip: 23.3.1
2023-10-24 12:14:52,823:INFO:          setuptools: 68.2.2
2023-10-24 12:14:52,823:INFO:             pycaret: 3.1.0
2023-10-24 12:14:52,823:INFO:             IPython: 7.19.0
2023-10-24 12:14:52,823:INFO:          ipywidgets: 8.1.1
2023-10-24 12:14:52,823:INFO:                tqdm: 4.66.1
2023-10-24 12:14:52,823:INFO:               numpy: 1.23.5
2023-10-24 12:14:52,823:INFO:              pandas: 1.5.3
2023-10-24 12:14:52,823:INFO:              jinja2: 3.1.2
2023-10-24 12:14:52,823:INFO:               scipy: 1.10.1
2023-10-24 12:14:52,823:INFO:              joblib: 1.3.2
2023-10-24 12:14:52,823:INFO:             sklearn: 1.2.2
2023-10-24 12:14:52,824:INFO:                pyod: 1.1.0
2023-10-24 12:14:52,824:INFO:            imblearn: 0.11.0
2023-10-24 12:14:52,824:INFO:   category_encoders: 2.6.2
2023-10-24 12:14:52,824:INFO:            lightgbm: 4.1.0
2023-10-24 12:14:52,824:INFO:               numba: 0.58.1
2023-10-24 12:14:52,824:INFO:            requests: 2.28.2
2023-10-24 12:14:52,824:INFO:          matplotlib: 3.7.3
2023-10-24 12:14:52,824:INFO:          scikitplot: 0.3.7
2023-10-24 12:14:52,824:INFO:         yellowbrick: 1.5
2023-10-24 12:14:52,824:INFO:              plotly: 5.17.0
2023-10-24 12:14:52,824:INFO:    plotly-resampler: Not installed
2023-10-24 12:14:52,824:INFO:             kaleido: 0.2.1
2023-10-24 12:14:52,824:INFO:           schemdraw: 0.15
2023-10-24 12:14:52,824:INFO:         statsmodels: 0.14.0
2023-10-24 12:14:52,824:INFO:              sktime: 0.21.1
2023-10-24 12:14:52,824:INFO:               tbats: 1.1.3
2023-10-24 12:14:52,824:INFO:            pmdarima: 2.0.4
2023-10-24 12:14:52,824:INFO:              psutil: 5.9.6
2023-10-24 12:14:52,824:INFO:          markupsafe: 2.1.2
2023-10-24 12:14:52,824:INFO:             pickle5: Not installed
2023-10-24 12:14:52,824:INFO:         cloudpickle: 1.6.0
2023-10-24 12:14:52,824:INFO:         deprecation: 2.1.0
2023-10-24 12:14:52,824:INFO:              xxhash: 3.4.1
2023-10-24 12:14:52,824:INFO:           wurlitzer: 2.0.1
2023-10-24 12:14:52,824:INFO:PyCaret optional dependencies:
2023-10-24 12:14:52,825:INFO:                shap: Not installed
2023-10-24 12:14:52,825:INFO:           interpret: Not installed
2023-10-24 12:14:52,825:INFO:                umap: Not installed
2023-10-24 12:14:52,825:INFO:     ydata_profiling: Not installed
2023-10-24 12:14:52,825:INFO:  explainerdashboard: Not installed
2023-10-24 12:14:52,825:INFO:             autoviz: Not installed
2023-10-24 12:14:52,825:INFO:           fairlearn: Not installed
2023-10-24 12:14:52,825:INFO:          deepchecks: Not installed
2023-10-24 12:14:52,825:INFO:             xgboost: Not installed
2023-10-24 12:14:52,825:INFO:            catboost: 1.0.4
2023-10-24 12:14:52,825:INFO:              kmodes: Not installed
2023-10-24 12:14:52,825:INFO:             mlxtend: Not installed
2023-10-24 12:14:52,825:INFO:       statsforecast: Not installed
2023-10-24 12:14:52,825:INFO:        tune_sklearn: Not installed
2023-10-24 12:14:52,825:INFO:                 ray: Not installed
2023-10-24 12:14:52,825:INFO:            hyperopt: Not installed
2023-10-24 12:14:52,825:INFO:              optuna: Not installed
2023-10-24 12:14:52,825:INFO:               skopt: Not installed
2023-10-24 12:14:52,825:INFO:              mlflow: 2.7.1
2023-10-24 12:14:52,825:INFO:              gradio: Not installed
2023-10-24 12:14:52,825:INFO:             fastapi: Not installed
2023-10-24 12:14:52,825:INFO:             uvicorn: Not installed
2023-10-24 12:14:52,825:INFO:              m2cgen: Not installed
2023-10-24 12:14:52,826:INFO:           evidently: Not installed
2023-10-24 12:14:52,826:INFO:               fugue: Not installed
2023-10-24 12:14:52,826:INFO:           streamlit: Not installed
2023-10-24 12:14:52,826:INFO:             prophet: Not installed
2023-10-24 12:14:52,826:INFO:None
2023-10-24 12:14:52,826:INFO:Set up data.
2023-10-24 12:14:52,860:INFO:Set up folding strategy.
2023-10-24 12:14:52,860:INFO:Set up train/test split.
2023-10-24 12:14:52,884:INFO:Set up index.
2023-10-24 12:14:52,885:INFO:Assigning column types.
2023-10-24 12:14:52,899:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 12:14:52,900:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 12:14:52,904:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 12:14:52,909:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:14:52,970:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:14:53,010:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:14:53,011:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:14:53,011:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:14:53,012:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 12:14:53,015:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 12:14:53,019:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:14:53,078:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:14:53,118:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:14:53,118:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:14:53,118:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:14:53,119:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 12:14:53,123:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 12:14:53,128:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:14:53,187:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:14:53,227:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:14:53,228:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:14:53,228:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:14:53,232:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 12:14:53,236:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:14:53,298:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:14:53,338:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:14:53,339:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:14:53,339:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:14:53,340:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 12:14:53,348:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:14:53,407:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:14:53,446:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:14:53,447:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:14:53,447:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:14:53,456:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:14:53,515:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:14:53,555:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:14:53,556:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:14:53,556:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:14:53,557:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 12:14:53,625:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:14:53,689:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:14:53,709:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:14:53,709:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:14:53,783:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:14:53,825:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:14:53,825:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:14:53,825:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:14:53,826:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 12:14:53,895:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:14:53,935:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:14:53,935:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:14:54,007:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:14:54,052:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:14:54,052:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:14:54,053:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 12:14:54,167:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:14:54,168:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:14:54,290:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:14:54,290:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:14:54,291:INFO:Preparing preprocessing pipeline...
2023-10-24 12:14:54,292:INFO:Set up date feature engineering.
2023-10-24 12:14:54,292:INFO:Set up simple imputation.
2023-10-24 12:14:54,303:INFO:Set up encoding of ordinal features.
2023-10-24 12:14:54,326:INFO:Set up encoding of categorical features.
2023-10-24 12:14:54,328:INFO:Set up column name cleaning.
2023-10-24 12:14:54,554:INFO:Finished creating preprocessing pipeline.
2023-10-24 12:14:54,645:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_...
NaN   -1
dtype: int64},
                                                                        {'col': 'rime',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 12:14:54,645:INFO:Creating final display dataframe.
2023-10-24 12:14:54,927:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (32819, 50)
4        Transformed data shape  (32819, 52)
5   Transformed train set shape  (22973, 52)
6    Transformed test set shape   (9846, 52)
7              Ordinal features            4
8              Numeric features           44
9                 Date features            1
10         Categorical features            4
11     Rows with missing values        19.9%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18               Fold Generator        KFold
19                  Fold Number           10
20                     CPU Jobs           -1
21                      Use GPU        False
22               Log Experiment        False
23              Experiment Name        exp_B
24                          USI         0853
2023-10-24 12:14:55,046:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:14:55,046:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:14:55,156:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:14:55,157:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:14:55,158:INFO:setup() successfully completed in 2.34s...............
2023-10-24 12:14:55,158:INFO:Initializing create_model()
2023-10-24 12:14:55,158:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9d42f28dc0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 12:14:55,158:INFO:Checking exceptions
2023-10-24 12:14:55,161:INFO:Importing libraries
2023-10-24 12:14:55,161:INFO:Copying training dataset
2023-10-24 12:14:55,181:INFO:Defining folds
2023-10-24 12:14:55,181:INFO:Declaring metric variables
2023-10-24 12:14:55,181:INFO:Importing untrained model
2023-10-24 12:14:55,182:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 12:14:55,182:INFO:Starting cross validation
2023-10-24 12:14:55,184:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 12:15:04,143:INFO:Calculating mean and std
2023-10-24 12:15:04,145:INFO:Creating metrics dataframe
2023-10-24 12:15:04,148:INFO:Finalizing model
2023-10-24 12:15:04,444:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005204 seconds.
2023-10-24 12:15:04,445:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:15:04,445:INFO:[LightGBM] [Info] Total Bins 6517
2023-10-24 12:15:04,446:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 48
2023-10-24 12:15:04,446:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-24 12:15:04,635:INFO:Uploading results into container
2023-10-24 12:15:04,636:INFO:Uploading model into container now
2023-10-24 12:15:04,641:INFO:_master_model_container: 1
2023-10-24 12:15:04,642:INFO:_display_container: 2
2023-10-24 12:15:04,642:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 12:15:04,643:INFO:create_model() successfully completed......................................
2023-10-24 12:15:04,746:INFO:Initializing tune_model()
2023-10-24 12:15:04,746:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9d42f28dc0>)
2023-10-24 12:15:04,747:INFO:Checking exceptions
2023-10-24 12:15:04,757:INFO:Copying training dataset
2023-10-24 12:15:04,771:INFO:Checking base model
2023-10-24 12:15:04,771:INFO:Base model : Light Gradient Boosting Machine
2023-10-24 12:15:04,772:INFO:Declaring metric variables
2023-10-24 12:15:04,772:INFO:Defining Hyperparameters
2023-10-24 12:15:04,871:INFO:Tuning with n_jobs=-1
2023-10-24 12:15:04,871:INFO:Initializing RandomizedSearchCV
2023-10-24 12:18:19,733:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-24 12:18:19,740:INFO:Hyperparameter search completed
2023-10-24 12:18:19,740:INFO:SubProcess create_model() called ==================================
2023-10-24 12:18:19,742:INFO:Initializing create_model()
2023-10-24 12:18:19,742:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9d42f28dc0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9dde2c4b20>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-24 12:18:19,742:INFO:Checking exceptions
2023-10-24 12:18:19,742:INFO:Importing libraries
2023-10-24 12:18:19,743:INFO:Copying training dataset
2023-10-24 12:18:19,776:INFO:Defining folds
2023-10-24 12:18:19,776:INFO:Declaring metric variables
2023-10-24 12:18:19,776:INFO:Importing untrained model
2023-10-24 12:18:19,777:INFO:Declaring custom model
2023-10-24 12:18:19,778:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 12:18:19,778:INFO:Starting cross validation
2023-10-24 12:18:19,781:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 12:19:01,862:INFO:Calculating mean and std
2023-10-24 12:19:01,864:INFO:Creating metrics dataframe
2023-10-24 12:19:01,868:INFO:Finalizing model
2023-10-24 12:19:02,103:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:19:02,103:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:19:02,104:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:19:02,147:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:19:02,147:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:19:02,148:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:19:02,154:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003714 seconds.
2023-10-24 12:19:02,154:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:19:02,155:INFO:[LightGBM] [Info] Total Bins 6517
2023-10-24 12:19:02,157:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 48
2023-10-24 12:19:02,158:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-24 12:19:02,946:INFO:Uploading results into container
2023-10-24 12:19:02,947:INFO:Uploading model into container now
2023-10-24 12:19:02,948:INFO:_master_model_container: 2
2023-10-24 12:19:02,949:INFO:_display_container: 3
2023-10-24 12:19:02,950:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-24 12:19:02,950:INFO:create_model() successfully completed......................................
2023-10-24 12:19:03,076:INFO:SubProcess create_model() end ==================================
2023-10-24 12:19:03,077:INFO:choose_better activated
2023-10-24 12:19:03,077:INFO:SubProcess create_model() called ==================================
2023-10-24 12:19:03,078:INFO:Initializing create_model()
2023-10-24 12:19:03,078:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9d42f28dc0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 12:19:03,078:INFO:Checking exceptions
2023-10-24 12:19:03,080:INFO:Importing libraries
2023-10-24 12:19:03,080:INFO:Copying training dataset
2023-10-24 12:19:03,097:INFO:Defining folds
2023-10-24 12:19:03,097:INFO:Declaring metric variables
2023-10-24 12:19:03,098:INFO:Importing untrained model
2023-10-24 12:19:03,098:INFO:Declaring custom model
2023-10-24 12:19:03,099:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 12:19:03,099:INFO:Starting cross validation
2023-10-24 12:19:03,101:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 12:19:12,206:INFO:Calculating mean and std
2023-10-24 12:19:12,206:INFO:Creating metrics dataframe
2023-10-24 12:19:12,208:INFO:Finalizing model
2023-10-24 12:19:12,524:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015188 seconds.
2023-10-24 12:19:12,524:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:19:12,524:INFO:[LightGBM] [Info] Total Bins 6517
2023-10-24 12:19:12,525:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 48
2023-10-24 12:19:12,526:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-24 12:19:12,742:INFO:Uploading results into container
2023-10-24 12:19:12,743:INFO:Uploading model into container now
2023-10-24 12:19:12,743:INFO:_master_model_container: 3
2023-10-24 12:19:12,743:INFO:_display_container: 4
2023-10-24 12:19:12,744:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 12:19:12,744:INFO:create_model() successfully completed......................................
2023-10-24 12:19:12,841:INFO:SubProcess create_model() end ==================================
2023-10-24 12:19:12,841:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8768
2023-10-24 12:19:12,842:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8781
2023-10-24 12:19:12,843:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) is best model
2023-10-24 12:19:12,843:INFO:choose_better completed
2023-10-24 12:19:12,848:INFO:_master_model_container: 3
2023-10-24 12:19:12,848:INFO:_display_container: 3
2023-10-24 12:19:12,849:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-24 12:19:12,849:INFO:tune_model() successfully completed......................................
2023-10-24 12:19:12,945:INFO:Initializing ensemble_model()
2023-10-24 12:19:12,945:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9d42f28dc0>, estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-24 12:19:12,945:INFO:Checking exceptions
2023-10-24 12:19:12,953:INFO:Importing libraries
2023-10-24 12:19:12,954:INFO:Copying training dataset
2023-10-24 12:19:12,954:INFO:Checking base model
2023-10-24 12:19:12,954:INFO:Base model : Light Gradient Boosting Machine
2023-10-24 12:19:12,954:INFO:Importing untrained ensembler
2023-10-24 12:19:12,954:INFO:Ensemble method set to Bagging
2023-10-24 12:19:12,954:INFO:SubProcess create_model() called ==================================
2023-10-24 12:19:12,956:INFO:Initializing create_model()
2023-10-24 12:19:12,956:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9d42f28dc0>, estimator=BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                                         feature_fraction=0.4,
                                         min_child_samples=41,
                                         min_split_gain=0.9, n_estimators=260,
                                         n_jobs=-1, num_leaves=70,
                                         random_state=123, reg_alpha=2,
                                         reg_lambda=3),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9d42798ca0>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 12:19:12,956:INFO:Checking exceptions
2023-10-24 12:19:12,956:INFO:Importing libraries
2023-10-24 12:19:12,957:INFO:Copying training dataset
2023-10-24 12:19:12,976:INFO:Defining folds
2023-10-24 12:19:12,976:INFO:Declaring metric variables
2023-10-24 12:19:12,976:INFO:Importing untrained model
2023-10-24 12:19:12,976:INFO:Declaring custom model
2023-10-24 12:19:12,977:INFO:Bagging Regressor Imported successfully
2023-10-24 12:19:12,977:INFO:Starting cross validation
2023-10-24 12:19:12,979:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 12:26:02,500:INFO:Calculating mean and std
2023-10-24 12:26:02,503:INFO:Creating metrics dataframe
2023-10-24 12:26:02,505:INFO:Finalizing model
2023-10-24 12:26:02,753:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:26:02,753:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:26:02,753:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:26:02,797:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:26:02,797:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:26:02,797:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:26:02,803:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000900 seconds.
2023-10-24 12:26:02,803:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 12:26:02,803:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 12:26:02,803:INFO:[LightGBM] [Info] Total Bins 6517
2023-10-24 12:26:02,805:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 48
2023-10-24 12:26:02,806:INFO:[LightGBM] [Info] Start training from score 99.624795
2023-10-24 12:26:03,748:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:26:03,748:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:26:03,748:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:26:03,794:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:26:03,794:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:26:03,794:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:26:03,801:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004461 seconds.
2023-10-24 12:26:03,802:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:26:03,803:INFO:[LightGBM] [Info] Total Bins 6517
2023-10-24 12:26:03,804:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 48
2023-10-24 12:26:03,805:INFO:[LightGBM] [Info] Start training from score 96.229614
2023-10-24 12:26:04,617:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:26:04,617:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:26:04,617:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:26:04,662:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:26:04,662:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:26:04,662:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:26:04,669:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004185 seconds.
2023-10-24 12:26:04,669:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:26:04,670:INFO:[LightGBM] [Info] Total Bins 6517
2023-10-24 12:26:04,671:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 48
2023-10-24 12:26:04,672:INFO:[LightGBM] [Info] Start training from score 95.360987
2023-10-24 12:26:05,493:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:26:05,493:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:26:05,493:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:26:05,543:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:26:05,543:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:26:05,543:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:26:05,551:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004582 seconds.
2023-10-24 12:26:05,551:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:26:05,552:INFO:[LightGBM] [Info] Total Bins 6517
2023-10-24 12:26:05,554:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 48
2023-10-24 12:26:05,555:INFO:[LightGBM] [Info] Start training from score 94.348528
2023-10-24 12:26:06,554:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:26:06,554:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:26:06,554:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:26:06,600:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:26:06,600:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:26:06,600:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:26:06,607:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003837 seconds.
2023-10-24 12:26:06,607:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:26:06,608:INFO:[LightGBM] [Info] Total Bins 6517
2023-10-24 12:26:06,609:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 48
2023-10-24 12:26:06,610:INFO:[LightGBM] [Info] Start training from score 95.509684
2023-10-24 12:26:07,451:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:26:07,451:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:26:07,452:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:26:07,498:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:26:07,498:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:26:07,499:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:26:07,505:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004167 seconds.
2023-10-24 12:26:07,505:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:26:07,506:INFO:[LightGBM] [Info] Total Bins 6517
2023-10-24 12:26:07,508:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 48
2023-10-24 12:26:07,508:INFO:[LightGBM] [Info] Start training from score 96.036959
2023-10-24 12:26:08,340:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:26:08,340:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:26:08,340:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:26:08,385:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:26:08,385:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:26:08,385:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:26:08,391:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001110 seconds.
2023-10-24 12:26:08,392:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 12:26:08,392:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 12:26:08,392:INFO:[LightGBM] [Info] Total Bins 6517
2023-10-24 12:26:08,393:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 48
2023-10-24 12:26:08,395:INFO:[LightGBM] [Info] Start training from score 97.844637
2023-10-24 12:26:09,370:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:26:09,370:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:26:09,370:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:26:09,415:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:26:09,415:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:26:09,415:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:26:09,423:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005428 seconds.
2023-10-24 12:26:09,423:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:26:09,424:INFO:[LightGBM] [Info] Total Bins 6517
2023-10-24 12:26:09,425:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 48
2023-10-24 12:26:09,426:INFO:[LightGBM] [Info] Start training from score 96.245614
2023-10-24 12:26:10,253:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:26:10,253:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:26:10,253:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:26:10,299:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:26:10,299:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:26:10,299:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:26:10,306:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004252 seconds.
2023-10-24 12:26:10,306:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:26:10,307:INFO:[LightGBM] [Info] Total Bins 6517
2023-10-24 12:26:10,308:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 48
2023-10-24 12:26:10,309:INFO:[LightGBM] [Info] Start training from score 97.594984
2023-10-24 12:26:11,147:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:26:11,147:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:26:11,147:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:26:11,194:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:26:11,194:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:26:11,194:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:26:11,201:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004025 seconds.
2023-10-24 12:26:11,201:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:26:11,202:INFO:[LightGBM] [Info] Total Bins 6517
2023-10-24 12:26:11,204:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 48
2023-10-24 12:26:11,205:INFO:[LightGBM] [Info] Start training from score 96.370407
2023-10-24 12:26:12,120:INFO:Uploading results into container
2023-10-24 12:26:12,121:INFO:Uploading model into container now
2023-10-24 12:26:12,122:INFO:_master_model_container: 4
2023-10-24 12:26:12,122:INFO:_display_container: 4
2023-10-24 12:26:12,125:INFO:BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                                         feature_fraction=0.4,
                                         min_child_samples=41,
                                         min_split_gain=0.9, n_estimators=260,
                                         n_jobs=-1, num_leaves=70,
                                         random_state=123, reg_alpha=2,
                                         reg_lambda=3),
                 random_state=123)
2023-10-24 12:26:12,125:INFO:create_model() successfully completed......................................
2023-10-24 12:26:12,429:INFO:SubProcess create_model() end ==================================
2023-10-24 12:26:12,434:INFO:_master_model_container: 4
2023-10-24 12:26:12,434:INFO:_display_container: 4
2023-10-24 12:26:12,437:INFO:BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                                         feature_fraction=0.4,
                                         min_child_samples=41,
                                         min_split_gain=0.9, n_estimators=260,
                                         n_jobs=-1, num_leaves=70,
                                         random_state=123, reg_alpha=2,
                                         reg_lambda=3),
                 random_state=123)
2023-10-24 12:26:12,437:INFO:ensemble_model() successfully completed......................................
2023-10-24 12:26:12,526:INFO:Initializing finalize_model()
2023-10-24 12:26:12,527:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9d42f28dc0>, estimator=BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                                         feature_fraction=0.4,
                                         min_child_samples=41,
                                         min_split_gain=0.9, n_estimators=260,
                                         n_jobs=-1, num_leaves=70,
                                         random_state=123, reg_alpha=2,
                                         reg_lambda=3),
                 random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-24 12:26:12,529:INFO:Finalizing BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                                         feature_fraction=0.4,
                                         min_child_samples=41,
                                         min_split_gain=0.9, n_estimators=260,
                                         n_jobs=-1, num_leaves=70,
                                         random_state=123, reg_alpha=2,
                                         reg_lambda=3),
                 random_state=123)
2023-10-24 12:26:12,555:INFO:Initializing create_model()
2023-10-24 12:26:12,555:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9d42f28dc0>, estimator=BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                                         feature_fraction=0.4,
                                         min_child_samples=41,
                                         min_split_gain=0.9, n_estimators=260,
                                         n_jobs=-1, num_leaves=70,
                                         random_state=123, reg_alpha=2,
                                         reg_lambda=3),
                 random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-24 12:26:12,555:INFO:Checking exceptions
2023-10-24 12:26:12,556:INFO:Importing libraries
2023-10-24 12:26:12,556:INFO:Copying training dataset
2023-10-24 12:26:12,558:INFO:Defining folds
2023-10-24 12:26:12,558:INFO:Declaring metric variables
2023-10-24 12:26:12,558:INFO:Importing untrained model
2023-10-24 12:26:12,558:INFO:Declaring custom model
2023-10-24 12:26:12,559:INFO:Bagging Regressor Imported successfully
2023-10-24 12:26:12,561:INFO:Cross validation set to False
2023-10-24 12:26:12,561:INFO:Fitting Model
2023-10-24 12:26:12,860:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:26:12,861:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:26:12,861:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:26:12,921:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:26:12,921:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:26:12,921:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:26:12,930:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001261 seconds.
2023-10-24 12:26:12,930:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 12:26:12,930:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 12:26:12,930:INFO:[LightGBM] [Info] Total Bins 6595
2023-10-24 12:26:12,931:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 48
2023-10-24 12:26:12,932:INFO:[LightGBM] [Info] Start training from score 96.465021
2023-10-24 12:26:13,913:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:26:13,913:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:26:13,914:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:26:13,978:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:26:13,978:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:26:13,978:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:26:13,988:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001663 seconds.
2023-10-24 12:26:13,988:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 12:26:13,988:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 12:26:13,989:INFO:[LightGBM] [Info] Total Bins 6595
2023-10-24 12:26:13,990:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 48
2023-10-24 12:26:13,992:INFO:[LightGBM] [Info] Start training from score 97.264361
2023-10-24 12:26:15,084:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:26:15,084:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:26:15,084:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:26:15,153:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:26:15,153:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:26:15,153:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:26:15,164:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001256 seconds.
2023-10-24 12:26:15,164:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 12:26:15,164:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 12:26:15,164:INFO:[LightGBM] [Info] Total Bins 6595
2023-10-24 12:26:15,166:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 48
2023-10-24 12:26:15,167:INFO:[LightGBM] [Info] Start training from score 95.842370
2023-10-24 12:26:16,293:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:26:16,293:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:26:16,294:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:26:16,364:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:26:16,364:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:26:16,364:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:26:16,376:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001706 seconds.
2023-10-24 12:26:16,376:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 12:26:16,376:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 12:26:16,376:INFO:[LightGBM] [Info] Total Bins 6595
2023-10-24 12:26:16,378:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 48
2023-10-24 12:26:16,379:INFO:[LightGBM] [Info] Start training from score 95.431515
2023-10-24 12:26:17,409:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:26:17,409:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:26:17,410:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:26:17,479:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:26:17,479:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:26:17,479:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:26:17,489:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001253 seconds.
2023-10-24 12:26:17,489:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 12:26:17,489:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 12:26:17,489:INFO:[LightGBM] [Info] Total Bins 6595
2023-10-24 12:26:17,491:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 48
2023-10-24 12:26:17,492:INFO:[LightGBM] [Info] Start training from score 97.222213
2023-10-24 12:26:18,511:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:26:18,511:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:26:18,511:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:26:18,579:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:26:18,579:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:26:18,579:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:26:18,590:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001220 seconds.
2023-10-24 12:26:18,590:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 12:26:18,590:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 12:26:18,591:INFO:[LightGBM] [Info] Total Bins 6595
2023-10-24 12:26:18,592:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 48
2023-10-24 12:26:18,593:INFO:[LightGBM] [Info] Start training from score 97.332701
2023-10-24 12:26:19,658:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:26:19,658:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:26:19,658:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:26:19,727:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:26:19,727:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:26:19,727:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:26:19,739:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007837 seconds.
2023-10-24 12:26:19,739:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:26:19,740:INFO:[LightGBM] [Info] Total Bins 6595
2023-10-24 12:26:19,742:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 48
2023-10-24 12:26:19,743:INFO:[LightGBM] [Info] Start training from score 96.452612
2023-10-24 12:26:20,737:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:26:20,737:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:26:20,737:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:26:20,804:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:26:20,804:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:26:20,804:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:26:20,814:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001261 seconds.
2023-10-24 12:26:20,814:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 12:26:20,814:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 12:26:20,815:INFO:[LightGBM] [Info] Total Bins 6595
2023-10-24 12:26:20,816:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 48
2023-10-24 12:26:20,818:INFO:[LightGBM] [Info] Start training from score 97.322509
2023-10-24 12:26:21,981:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:26:21,981:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:26:21,981:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:26:22,050:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:26:22,050:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:26:22,051:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:26:22,059:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001257 seconds.
2023-10-24 12:26:22,060:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 12:26:22,060:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 12:26:22,060:INFO:[LightGBM] [Info] Total Bins 6595
2023-10-24 12:26:22,061:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 48
2023-10-24 12:26:22,062:INFO:[LightGBM] [Info] Start training from score 96.419103
2023-10-24 12:26:23,109:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:26:23,109:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:26:23,109:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:26:23,177:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:26:23,177:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:26:23,177:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:26:23,187:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002211 seconds.
2023-10-24 12:26:23,187:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 12:26:23,187:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 12:26:23,187:INFO:[LightGBM] [Info] Total Bins 6595
2023-10-24 12:26:23,188:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 48
2023-10-24 12:26:23,189:INFO:[LightGBM] [Info] Start training from score 95.095963
2023-10-24 12:26:24,348:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6,
                                                          bagging_freq=2,
                                                          feature_fraction=0.4,
                                                          min_child_samples=41,
                                                          min_split_gain=0.9,
                                                          n_estimators=260,
                                                          n_jobs=-1,
                                                          num_leaves=70,
                                                          random_state=123,
                                                          reg_alpha=2,
                                                          reg_lambda=3),
                                  random_state=123))])
2023-10-24 12:26:24,348:INFO:create_model() successfully completed......................................
2023-10-24 12:26:24,445:INFO:_master_model_container: 4
2023-10-24 12:26:24,445:INFO:_display_container: 4
2023-10-24 12:26:24,551:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6,
                                                          bagging_freq=2,
                                                          feature_fraction=0.4,
                                                          min_child_samples=41,
                                                          min_split_gain=0.9,
                                                          n_estimators=260,
                                                          n_jobs=-1,
                                                          num_leaves=70,
                                                          random_state=123,
                                                          reg_alpha=2,
                                                          reg_lambda=3),
                                  random_state=123))])
2023-10-24 12:26:24,552:INFO:finalize_model() successfully completed......................................
2023-10-24 12:26:24,832:INFO:Initializing save_model()
2023-10-24 12:26:24,832:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6,
                                                          bagging_freq=2,
                                                          feature_fraction=0.4,
                                                          min_child_samples=41,
                                                          min_split_gain=0.9,
                                                          n_estimators=260,
                                                          n_jobs=-1,
                                                          num_leaves=70,
                                                          random_state=123,
                                                          reg_alpha=2,
                                                          reg_lambda=3),
                                  random_state=123))]), model_name=final_model_for_location_B, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_...
NaN   -1
dtype: int64},
                                                                        {'col': 'rime',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-24 12:26:24,832:INFO:Adding model into prep_pipe
2023-10-24 12:26:24,832:WARNING:Only Model saved as it was a pipeline.
2023-10-24 12:26:25,119:INFO:final_model_for_location_B.pkl saved in current working directory
2023-10-24 12:26:25,236:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6,
                                                          bagging_freq=2,
                                                          feature_fraction=0.4,
                                                          min_child_samples=41,
                                                          min_split_gain=0.9,
                                                          n_estimators=260,
                                                          n_jobs=-1,
                                                          num_leaves=70,
                                                          random_state=123,
                                                          reg_alpha=2,
                                                          reg_lambda=3),
                                  random_state=123))])
2023-10-24 12:26:25,236:INFO:save_model() successfully completed......................................
2023-10-24 12:26:25,373:INFO:PyCaret RegressionExperiment
2023-10-24 12:26:25,373:INFO:Logging name: exp_C
2023-10-24 12:26:25,373:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 12:26:25,374:INFO:version 3.1.0
2023-10-24 12:26:25,374:INFO:Initializing setup()
2023-10-24 12:26:25,374:INFO:self.USI: 84df
2023-10-24 12:26:25,374:INFO:self._variable_keys: {'exp_id', 'target_param', 'USI', 'data', 'fold_shuffle_param', 'log_plots_param', 'X_test', 'memory', 'idx', 'y', 'X', 'X_train', 'gpu_n_jobs_param', 'n_jobs_param', 'gpu_param', 'logging_param', 'fold_generator', 'pipeline', 'y_test', 'y_train', '_ml_usecase', '_available_plots', 'html_param', 'exp_name_log', 'transform_target_param', 'seed', 'fold_groups_param'}
2023-10-24 12:26:25,374:INFO:Checking environment
2023-10-24 12:26:25,374:INFO:python_version: 3.8.5
2023-10-24 12:26:25,374:INFO:python_build: ('default', 'Sep  4 2020 02:22:02')
2023-10-24 12:26:25,374:INFO:machine: x86_64
2023-10-24 12:26:25,374:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-10-24 12:26:25,374:INFO:Memory: svmem(total=8589934592, available=2064637952, percent=76.0, used=4141506560, free=82038784, active=1985097728, inactive=1959333888, wired=2156408832)
2023-10-24 12:26:25,374:INFO:Physical Core: 4
2023-10-24 12:26:25,374:INFO:Logical Core: 8
2023-10-24 12:26:25,374:INFO:Checking libraries
2023-10-24 12:26:25,374:INFO:System:
2023-10-24 12:26:25,374:INFO:    python: 3.8.5 (default, Sep  4 2020, 02:22:02)  [Clang 10.0.0 ]
2023-10-24 12:26:25,374:INFO:executable: /Users/kaja/opt/anaconda3/bin/python
2023-10-24 12:26:25,374:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-10-24 12:26:25,374:INFO:PyCaret required dependencies:
2023-10-24 12:26:25,374:INFO:                 pip: 23.3.1
2023-10-24 12:26:25,375:INFO:          setuptools: 68.2.2
2023-10-24 12:26:25,375:INFO:             pycaret: 3.1.0
2023-10-24 12:26:25,375:INFO:             IPython: 7.19.0
2023-10-24 12:26:25,375:INFO:          ipywidgets: 8.1.1
2023-10-24 12:26:25,375:INFO:                tqdm: 4.66.1
2023-10-24 12:26:25,375:INFO:               numpy: 1.23.5
2023-10-24 12:26:25,375:INFO:              pandas: 1.5.3
2023-10-24 12:26:25,375:INFO:              jinja2: 3.1.2
2023-10-24 12:26:25,375:INFO:               scipy: 1.10.1
2023-10-24 12:26:25,375:INFO:              joblib: 1.3.2
2023-10-24 12:26:25,375:INFO:             sklearn: 1.2.2
2023-10-24 12:26:25,375:INFO:                pyod: 1.1.0
2023-10-24 12:26:25,375:INFO:            imblearn: 0.11.0
2023-10-24 12:26:25,375:INFO:   category_encoders: 2.6.2
2023-10-24 12:26:25,375:INFO:            lightgbm: 4.1.0
2023-10-24 12:26:25,375:INFO:               numba: 0.58.1
2023-10-24 12:26:25,375:INFO:            requests: 2.28.2
2023-10-24 12:26:25,375:INFO:          matplotlib: 3.7.3
2023-10-24 12:26:25,375:INFO:          scikitplot: 0.3.7
2023-10-24 12:26:25,375:INFO:         yellowbrick: 1.5
2023-10-24 12:26:25,375:INFO:              plotly: 5.17.0
2023-10-24 12:26:25,375:INFO:    plotly-resampler: Not installed
2023-10-24 12:26:25,375:INFO:             kaleido: 0.2.1
2023-10-24 12:26:25,375:INFO:           schemdraw: 0.15
2023-10-24 12:26:25,375:INFO:         statsmodels: 0.14.0
2023-10-24 12:26:25,375:INFO:              sktime: 0.21.1
2023-10-24 12:26:25,375:INFO:               tbats: 1.1.3
2023-10-24 12:26:25,375:INFO:            pmdarima: 2.0.4
2023-10-24 12:26:25,376:INFO:              psutil: 5.9.6
2023-10-24 12:26:25,376:INFO:          markupsafe: 2.1.2
2023-10-24 12:26:25,376:INFO:             pickle5: Not installed
2023-10-24 12:26:25,376:INFO:         cloudpickle: 1.6.0
2023-10-24 12:26:25,376:INFO:         deprecation: 2.1.0
2023-10-24 12:26:25,376:INFO:              xxhash: 3.4.1
2023-10-24 12:26:25,376:INFO:           wurlitzer: 2.0.1
2023-10-24 12:26:25,376:INFO:PyCaret optional dependencies:
2023-10-24 12:26:25,376:INFO:                shap: Not installed
2023-10-24 12:26:25,376:INFO:           interpret: Not installed
2023-10-24 12:26:25,376:INFO:                umap: Not installed
2023-10-24 12:26:25,376:INFO:     ydata_profiling: Not installed
2023-10-24 12:26:25,376:INFO:  explainerdashboard: Not installed
2023-10-24 12:26:25,376:INFO:             autoviz: Not installed
2023-10-24 12:26:25,376:INFO:           fairlearn: Not installed
2023-10-24 12:26:25,376:INFO:          deepchecks: Not installed
2023-10-24 12:26:25,376:INFO:             xgboost: Not installed
2023-10-24 12:26:25,376:INFO:            catboost: 1.0.4
2023-10-24 12:26:25,376:INFO:              kmodes: Not installed
2023-10-24 12:26:25,376:INFO:             mlxtend: Not installed
2023-10-24 12:26:25,376:INFO:       statsforecast: Not installed
2023-10-24 12:26:25,376:INFO:        tune_sklearn: Not installed
2023-10-24 12:26:25,376:INFO:                 ray: Not installed
2023-10-24 12:26:25,376:INFO:            hyperopt: Not installed
2023-10-24 12:26:25,376:INFO:              optuna: Not installed
2023-10-24 12:26:25,376:INFO:               skopt: Not installed
2023-10-24 12:26:25,376:INFO:              mlflow: 2.7.1
2023-10-24 12:26:25,376:INFO:              gradio: Not installed
2023-10-24 12:26:25,376:INFO:             fastapi: Not installed
2023-10-24 12:26:25,377:INFO:             uvicorn: Not installed
2023-10-24 12:26:25,377:INFO:              m2cgen: Not installed
2023-10-24 12:26:25,377:INFO:           evidently: Not installed
2023-10-24 12:26:25,377:INFO:               fugue: Not installed
2023-10-24 12:26:25,377:INFO:           streamlit: Not installed
2023-10-24 12:26:25,377:INFO:             prophet: Not installed
2023-10-24 12:26:25,377:INFO:None
2023-10-24 12:26:25,377:INFO:Set up data.
2023-10-24 12:26:25,404:INFO:Set up folding strategy.
2023-10-24 12:26:25,405:INFO:Set up train/test split.
2023-10-24 12:26:25,423:INFO:Set up index.
2023-10-24 12:26:25,425:INFO:Assigning column types.
2023-10-24 12:26:25,435:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 12:26:25,436:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 12:26:25,440:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 12:26:25,443:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:26:25,500:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:26:25,539:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:26:25,540:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:26:25,540:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:26:25,540:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 12:26:25,544:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 12:26:25,548:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:26:25,606:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:26:25,646:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:26:25,647:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:26:25,647:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:26:25,647:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 12:26:25,652:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 12:26:25,656:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:26:25,715:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:26:25,756:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:26:25,756:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:26:25,756:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:26:25,761:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 12:26:25,765:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:26:25,824:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:26:25,864:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:26:25,864:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:26:25,864:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:26:25,865:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 12:26:25,873:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:26:25,931:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:26:25,974:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:26:25,974:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:26:25,975:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:26:25,984:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 12:26:26,041:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:26:26,082:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:26:26,082:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:26:26,083:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:26:26,083:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 12:26:26,150:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:26:26,190:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:26:26,191:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:26:26,191:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:26:26,258:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:26:26,303:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 12:26:26,303:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:26:26,303:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:26:26,304:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 12:26:26,370:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:26:26,417:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:26:26,417:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:26:26,490:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 12:26:26,530:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:26:26,531:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:26:26,531:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 12:26:26,650:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:26:26,650:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:26:26,765:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:26:26,765:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:26:26,766:INFO:Preparing preprocessing pipeline...
2023-10-24 12:26:26,767:INFO:Set up date feature engineering.
2023-10-24 12:26:26,767:INFO:Set up simple imputation.
2023-10-24 12:26:26,776:INFO:Set up encoding of ordinal features.
2023-10-24 12:26:26,793:INFO:Set up encoding of categorical features.
2023-10-24 12:26:26,796:INFO:Set up column name cleaning.
2023-10-24 12:26:26,991:INFO:Finished creating preprocessing pipeline.
2023-10-24 12:26:27,082:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_...
NaN   -1
dtype: int64},
                                                                        {'col': 'rime',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 12:26:27,082:INFO:Creating final display dataframe.
2023-10-24 12:26:27,332:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (26071, 50)
4        Transformed data shape  (26071, 52)
5   Transformed train set shape  (18249, 52)
6    Transformed test set shape   (7822, 52)
7              Ordinal features            4
8              Numeric features           44
9                 Date features            1
10         Categorical features            4
11     Rows with missing values        25.0%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18               Fold Generator        KFold
19                  Fold Number           10
20                     CPU Jobs           -1
21                      Use GPU        False
22               Log Experiment        False
23              Experiment Name        exp_C
24                          USI         84df
2023-10-24 12:26:27,444:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:26:27,444:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:26:27,553:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 12:26:27,553:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 12:26:27,554:INFO:setup() successfully completed in 2.18s...............
2023-10-24 12:26:27,554:INFO:Initializing create_model()
2023-10-24 12:26:27,554:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9d42eb2580>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 12:26:27,554:INFO:Checking exceptions
2023-10-24 12:26:27,557:INFO:Importing libraries
2023-10-24 12:26:27,557:INFO:Copying training dataset
2023-10-24 12:26:27,574:INFO:Defining folds
2023-10-24 12:26:27,574:INFO:Declaring metric variables
2023-10-24 12:26:27,574:INFO:Importing untrained model
2023-10-24 12:26:27,574:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 12:26:27,575:INFO:Starting cross validation
2023-10-24 12:26:27,576:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 12:26:37,028:INFO:Calculating mean and std
2023-10-24 12:26:37,029:INFO:Creating metrics dataframe
2023-10-24 12:26:37,032:INFO:Finalizing model
2023-10-24 12:26:37,308:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008780 seconds.
2023-10-24 12:26:37,309:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:26:37,309:INFO:[LightGBM] [Info] Total Bins 6726
2023-10-24 12:26:37,309:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 49
2023-10-24 12:26:37,310:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-24 12:26:37,566:INFO:Uploading results into container
2023-10-24 12:26:37,567:INFO:Uploading model into container now
2023-10-24 12:26:37,572:INFO:_master_model_container: 1
2023-10-24 12:26:37,573:INFO:_display_container: 2
2023-10-24 12:26:37,573:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 12:26:37,573:INFO:create_model() successfully completed......................................
2023-10-24 12:26:37,680:INFO:Initializing tune_model()
2023-10-24 12:26:37,680:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9d42eb2580>)
2023-10-24 12:26:37,680:INFO:Checking exceptions
2023-10-24 12:26:37,689:INFO:Copying training dataset
2023-10-24 12:26:37,704:INFO:Checking base model
2023-10-24 12:26:37,704:INFO:Base model : Light Gradient Boosting Machine
2023-10-24 12:26:37,705:INFO:Declaring metric variables
2023-10-24 12:26:37,705:INFO:Defining Hyperparameters
2023-10-24 12:26:37,804:INFO:Tuning with n_jobs=-1
2023-10-24 12:26:37,805:INFO:Initializing RandomizedSearchCV
2023-10-24 12:35:57,957:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-24 12:35:57,980:INFO:Hyperparameter search completed
2023-10-24 12:35:57,981:INFO:SubProcess create_model() called ==================================
2023-10-24 12:35:57,983:INFO:Initializing create_model()
2023-10-24 12:35:57,983:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9d42eb2580>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9dcd235bb0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-24 12:35:57,983:INFO:Checking exceptions
2023-10-24 12:35:57,984:INFO:Importing libraries
2023-10-24 12:35:57,985:INFO:Copying training dataset
2023-10-24 12:35:58,023:INFO:Defining folds
2023-10-24 12:35:58,023:INFO:Declaring metric variables
2023-10-24 12:35:58,024:INFO:Importing untrained model
2023-10-24 12:35:58,025:INFO:Declaring custom model
2023-10-24 12:35:58,027:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 12:35:58,027:INFO:Starting cross validation
2023-10-24 12:35:58,030:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 12:36:40,721:INFO:Calculating mean and std
2023-10-24 12:36:40,722:INFO:Creating metrics dataframe
2023-10-24 12:36:40,728:INFO:Finalizing model
2023-10-24 12:36:40,940:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:36:40,940:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:36:40,940:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:36:40,980:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 12:36:40,980:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 12:36:40,980:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 12:36:40,989:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001139 seconds.
2023-10-24 12:36:40,989:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 12:36:40,989:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 12:36:40,989:INFO:[LightGBM] [Info] Total Bins 6726
2023-10-24 12:36:40,991:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 49
2023-10-24 12:36:40,992:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-24 12:36:40,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-24 12:36:40,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-24 12:36:40,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-24 12:36:41,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-24 12:36:41,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-24 12:36:41,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-24 12:36:41,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-24 12:36:41,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-24 12:36:41,931:INFO:Uploading results into container
2023-10-24 12:36:41,933:INFO:Uploading model into container now
2023-10-24 12:36:41,934:INFO:_master_model_container: 2
2023-10-24 12:36:41,935:INFO:_display_container: 3
2023-10-24 12:36:41,936:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-24 12:36:41,936:INFO:create_model() successfully completed......................................
2023-10-24 12:36:42,289:INFO:SubProcess create_model() end ==================================
2023-10-24 12:36:42,289:INFO:choose_better activated
2023-10-24 12:36:42,290:INFO:SubProcess create_model() called ==================================
2023-10-24 12:36:42,290:INFO:Initializing create_model()
2023-10-24 12:36:42,290:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9d42eb2580>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 12:36:42,290:INFO:Checking exceptions
2023-10-24 12:36:42,292:INFO:Importing libraries
2023-10-24 12:36:42,292:INFO:Copying training dataset
2023-10-24 12:36:42,308:INFO:Defining folds
2023-10-24 12:36:42,308:INFO:Declaring metric variables
2023-10-24 12:36:42,309:INFO:Importing untrained model
2023-10-24 12:36:42,309:INFO:Declaring custom model
2023-10-24 12:36:42,309:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 12:36:42,310:INFO:Starting cross validation
2023-10-24 12:36:42,312:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 12:36:51,826:INFO:Calculating mean and std
2023-10-24 12:36:51,826:INFO:Creating metrics dataframe
2023-10-24 12:36:51,829:INFO:Finalizing model
2023-10-24 12:36:52,113:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007309 seconds.
2023-10-24 12:36:52,113:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:36:52,113:INFO:[LightGBM] [Info] Total Bins 6726
2023-10-24 12:36:52,114:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 49
2023-10-24 12:36:52,114:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-24 12:36:52,306:INFO:Uploading results into container
2023-10-24 12:36:52,306:INFO:Uploading model into container now
2023-10-24 12:36:52,307:INFO:_master_model_container: 3
2023-10-24 12:36:52,307:INFO:_display_container: 4
2023-10-24 12:36:52,308:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 12:36:52,308:INFO:create_model() successfully completed......................................
2023-10-24 12:36:52,407:INFO:SubProcess create_model() end ==================================
2023-10-24 12:36:52,408:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.9089
2023-10-24 12:36:52,409:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.9017
2023-10-24 12:36:52,409:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-24 12:36:52,409:INFO:choose_better completed
2023-10-24 12:36:52,409:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-24 12:36:52,415:INFO:_master_model_container: 3
2023-10-24 12:36:52,416:INFO:_display_container: 3
2023-10-24 12:36:52,416:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 12:36:52,416:INFO:tune_model() successfully completed......................................
2023-10-24 12:36:52,513:INFO:Initializing ensemble_model()
2023-10-24 12:36:52,513:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9d42eb2580>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-24 12:36:52,513:INFO:Checking exceptions
2023-10-24 12:36:52,528:INFO:Importing libraries
2023-10-24 12:36:52,528:INFO:Copying training dataset
2023-10-24 12:36:52,528:INFO:Checking base model
2023-10-24 12:36:52,528:INFO:Base model : Light Gradient Boosting Machine
2023-10-24 12:36:52,528:INFO:Importing untrained ensembler
2023-10-24 12:36:52,528:INFO:Ensemble method set to Bagging
2023-10-24 12:36:52,529:INFO:SubProcess create_model() called ==================================
2023-10-24 12:36:52,530:INFO:Initializing create_model()
2023-10-24 12:36:52,530:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9d42eb2580>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9dde278c10>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 12:36:52,530:INFO:Checking exceptions
2023-10-24 12:36:52,530:INFO:Importing libraries
2023-10-24 12:36:52,530:INFO:Copying training dataset
2023-10-24 12:36:52,544:INFO:Defining folds
2023-10-24 12:36:52,544:INFO:Declaring metric variables
2023-10-24 12:36:52,544:INFO:Importing untrained model
2023-10-24 12:36:52,544:INFO:Declaring custom model
2023-10-24 12:36:52,545:INFO:Bagging Regressor Imported successfully
2023-10-24 12:36:52,546:INFO:Starting cross validation
2023-10-24 12:36:52,547:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 12:38:14,471:INFO:Calculating mean and std
2023-10-24 12:38:14,474:INFO:Creating metrics dataframe
2023-10-24 12:38:14,479:INFO:Finalizing model
2023-10-24 12:38:14,752:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006132 seconds.
2023-10-24 12:38:14,752:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:38:14,752:INFO:[LightGBM] [Info] Total Bins 6726
2023-10-24 12:38:14,753:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 49
2023-10-24 12:38:14,753:INFO:[LightGBM] [Info] Start training from score 77.044367
2023-10-24 12:38:14,948:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007009 seconds.
2023-10-24 12:38:14,949:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:38:14,949:INFO:[LightGBM] [Info] Total Bins 6726
2023-10-24 12:38:14,950:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 49
2023-10-24 12:38:14,950:INFO:[LightGBM] [Info] Start training from score 76.520588
2023-10-24 12:38:15,225:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005413 seconds.
2023-10-24 12:38:15,225:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:38:15,225:INFO:[LightGBM] [Info] Total Bins 6726
2023-10-24 12:38:15,226:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 49
2023-10-24 12:38:15,226:INFO:[LightGBM] [Info] Start training from score 76.462170
2023-10-24 12:38:15,412:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005370 seconds.
2023-10-24 12:38:15,412:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:38:15,412:INFO:[LightGBM] [Info] Total Bins 6726
2023-10-24 12:38:15,413:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 49
2023-10-24 12:38:15,413:INFO:[LightGBM] [Info] Start training from score 77.386428
2023-10-24 12:38:15,603:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005788 seconds.
2023-10-24 12:38:15,603:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:38:15,603:INFO:[LightGBM] [Info] Total Bins 6726
2023-10-24 12:38:15,604:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 49
2023-10-24 12:38:15,604:INFO:[LightGBM] [Info] Start training from score 73.916304
2023-10-24 12:38:15,786:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004504 seconds.
2023-10-24 12:38:15,786:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:38:15,786:INFO:[LightGBM] [Info] Total Bins 6726
2023-10-24 12:38:15,787:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 49
2023-10-24 12:38:15,787:INFO:[LightGBM] [Info] Start training from score 75.879633
2023-10-24 12:38:16,001:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005039 seconds.
2023-10-24 12:38:16,001:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:38:16,002:INFO:[LightGBM] [Info] Total Bins 6726
2023-10-24 12:38:16,002:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 49
2023-10-24 12:38:16,003:INFO:[LightGBM] [Info] Start training from score 75.615395
2023-10-24 12:38:16,194:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005694 seconds.
2023-10-24 12:38:16,194:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:38:16,194:INFO:[LightGBM] [Info] Total Bins 6726
2023-10-24 12:38:16,195:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 49
2023-10-24 12:38:16,195:INFO:[LightGBM] [Info] Start training from score 79.544595
2023-10-24 12:38:16,382:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004024 seconds.
2023-10-24 12:38:16,383:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:38:16,383:INFO:[LightGBM] [Info] Total Bins 6726
2023-10-24 12:38:16,384:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 49
2023-10-24 12:38:16,384:INFO:[LightGBM] [Info] Start training from score 76.012052
2023-10-24 12:38:16,619:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004785 seconds.
2023-10-24 12:38:16,619:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:38:16,620:INFO:[LightGBM] [Info] Total Bins 6726
2023-10-24 12:38:16,620:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 49
2023-10-24 12:38:16,621:INFO:[LightGBM] [Info] Start training from score 78.124037
2023-10-24 12:38:16,782:INFO:Uploading results into container
2023-10-24 12:38:16,783:INFO:Uploading model into container now
2023-10-24 12:38:16,785:INFO:_master_model_container: 4
2023-10-24 12:38:16,785:INFO:_display_container: 4
2023-10-24 12:38:16,786:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-24 12:38:16,786:INFO:create_model() successfully completed......................................
2023-10-24 12:38:16,885:INFO:SubProcess create_model() end ==================================
2023-10-24 12:38:16,890:INFO:_master_model_container: 4
2023-10-24 12:38:16,890:INFO:_display_container: 4
2023-10-24 12:38:16,891:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-24 12:38:16,891:INFO:ensemble_model() successfully completed......................................
2023-10-24 12:38:16,980:INFO:Initializing finalize_model()
2023-10-24 12:38:16,980:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9d42eb2580>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-24 12:38:16,981:INFO:Finalizing BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-24 12:38:16,997:INFO:Initializing create_model()
2023-10-24 12:38:16,997:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9d42eb2580>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-24 12:38:16,997:INFO:Checking exceptions
2023-10-24 12:38:16,998:INFO:Importing libraries
2023-10-24 12:38:16,999:INFO:Copying training dataset
2023-10-24 12:38:17,000:INFO:Defining folds
2023-10-24 12:38:17,000:INFO:Declaring metric variables
2023-10-24 12:38:17,000:INFO:Importing untrained model
2023-10-24 12:38:17,000:INFO:Declaring custom model
2023-10-24 12:38:17,001:INFO:Bagging Regressor Imported successfully
2023-10-24 12:38:17,003:INFO:Cross validation set to False
2023-10-24 12:38:17,003:INFO:Fitting Model
2023-10-24 12:38:17,308:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005945 seconds.
2023-10-24 12:38:17,308:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:38:17,308:INFO:[LightGBM] [Info] Total Bins 6800
2023-10-24 12:38:17,309:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 49
2023-10-24 12:38:17,309:INFO:[LightGBM] [Info] Start training from score 77.360615
2023-10-24 12:38:17,542:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006637 seconds.
2023-10-24 12:38:17,543:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:38:17,543:INFO:[LightGBM] [Info] Total Bins 6800
2023-10-24 12:38:17,543:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 49
2023-10-24 12:38:17,544:INFO:[LightGBM] [Info] Start training from score 78.162759
2023-10-24 12:38:17,808:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008048 seconds.
2023-10-24 12:38:17,808:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:38:17,808:INFO:[LightGBM] [Info] Total Bins 6800
2023-10-24 12:38:17,808:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 49
2023-10-24 12:38:17,809:INFO:[LightGBM] [Info] Start training from score 77.185434
2023-10-24 12:38:18,039:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006419 seconds.
2023-10-24 12:38:18,040:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:38:18,040:INFO:[LightGBM] [Info] Total Bins 6800
2023-10-24 12:38:18,040:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 49
2023-10-24 12:38:18,041:INFO:[LightGBM] [Info] Start training from score 78.293126
2023-10-24 12:38:18,283:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005446 seconds.
2023-10-24 12:38:18,284:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:38:18,284:INFO:[LightGBM] [Info] Total Bins 6800
2023-10-24 12:38:18,285:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 49
2023-10-24 12:38:18,285:INFO:[LightGBM] [Info] Start training from score 75.493649
2023-10-24 12:38:18,547:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005794 seconds.
2023-10-24 12:38:18,547:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:38:18,547:INFO:[LightGBM] [Info] Total Bins 6800
2023-10-24 12:38:18,548:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 49
2023-10-24 12:38:18,548:INFO:[LightGBM] [Info] Start training from score 77.467219
2023-10-24 12:38:18,835:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005105 seconds.
2023-10-24 12:38:18,835:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:38:18,835:INFO:[LightGBM] [Info] Total Bins 6800
2023-10-24 12:38:18,836:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 49
2023-10-24 12:38:18,836:INFO:[LightGBM] [Info] Start training from score 77.083598
2023-10-24 12:38:19,110:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006172 seconds.
2023-10-24 12:38:19,110:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:38:19,111:INFO:[LightGBM] [Info] Total Bins 6800
2023-10-24 12:38:19,111:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 49
2023-10-24 12:38:19,112:INFO:[LightGBM] [Info] Start training from score 79.854607
2023-10-24 12:38:19,412:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006229 seconds.
2023-10-24 12:38:19,412:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:38:19,412:INFO:[LightGBM] [Info] Total Bins 6800
2023-10-24 12:38:19,413:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 49
2023-10-24 12:38:19,413:INFO:[LightGBM] [Info] Start training from score 76.153078
2023-10-24 12:38:19,681:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005646 seconds.
2023-10-24 12:38:19,681:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 12:38:19,681:INFO:[LightGBM] [Info] Total Bins 6800
2023-10-24 12:38:19,682:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 49
2023-10-24 12:38:19,682:INFO:[LightGBM] [Info] Start training from score 78.843978
2023-10-24 12:38:19,995:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-24 12:38:19,995:INFO:create_model() successfully completed......................................
2023-10-24 12:38:20,091:INFO:_master_model_container: 4
2023-10-24 12:38:20,091:INFO:_display_container: 4
2023-10-24 12:38:20,196:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-24 12:38:20,196:INFO:finalize_model() successfully completed......................................
2023-10-24 12:38:20,488:INFO:Initializing save_model()
2023-10-24 12:38:20,488:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), model_name=final_model_for_location_C, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_...
NaN   -1
dtype: int64},
                                                                        {'col': 'rime',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-24 12:38:20,488:INFO:Adding model into prep_pipe
2023-10-24 12:38:20,488:WARNING:Only Model saved as it was a pipeline.
2023-10-24 12:38:20,535:INFO:final_model_for_location_C.pkl saved in current working directory
2023-10-24 12:38:20,660:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-24 12:38:20,660:INFO:save_model() successfully completed......................................
2023-10-24 12:38:22,166:INFO:Initializing load_model()
2023-10-24 12:38:22,166:INFO:load_model(model_name=final_model_for_location_A, platform=None, authentication=None, verbose=True)
2023-10-24 12:38:22,193:INFO:Initializing load_model()
2023-10-24 12:38:22,194:INFO:load_model(model_name=final_model_for_location_B, platform=None, authentication=None, verbose=True)
2023-10-24 12:38:22,262:INFO:Initializing load_model()
2023-10-24 12:38:22,262:INFO:load_model(model_name=final_model_for_location_C, platform=None, authentication=None, verbose=True)
2023-10-24 12:38:22,411:INFO:Initializing predict_model()
2023-10-24 12:38:22,411:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9d42eb2580>, estimator=Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_...
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f9dcd2aac10>)
2023-10-24 12:38:22,412:INFO:Checking exceptions
2023-10-24 12:38:22,412:INFO:Preloading libraries
2023-10-24 12:38:22,412:INFO:Set up data.
2023-10-24 12:38:22,431:INFO:Set up index.
2023-10-24 12:38:22,740:INFO:Initializing predict_model()
2023-10-24 12:38:22,740:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9d42eb2580>, estimator=Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_...
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6,
                                                          bagging_freq=2,
                                                          feature_fraction=0.4,
                                                          min_child_samples=41,
                                                          min_split_gain=0.9,
                                                          n_estimators=260,
                                                          n_jobs=-1,
                                                          num_leaves=70,
                                                          random_state=123,
                                                          reg_alpha=2,
                                                          reg_lambda=3),
                                  random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f9d4246ee50>)
2023-10-24 12:38:22,740:INFO:Checking exceptions
2023-10-24 12:38:22,740:INFO:Preloading libraries
2023-10-24 12:38:22,740:INFO:Set up data.
2023-10-24 12:38:22,754:INFO:Set up index.
2023-10-24 12:38:23,170:INFO:Initializing predict_model()
2023-10-24 12:38:23,170:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9d42eb2580>, estimator=Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_...
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f9d4246ee50>)
2023-10-24 12:38:23,170:INFO:Checking exceptions
2023-10-24 12:38:23,170:INFO:Preloading libraries
2023-10-24 12:38:23,170:INFO:Set up data.
2023-10-24 12:38:23,183:INFO:Set up index.
2023-10-24 13:26:57,975:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-24 13:26:57,976:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-24 13:26:57,976:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-24 13:26:57,976:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-24 13:26:58,614:WARNING:<ipython-input-3-49df83f3379d>:13: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  estimated_resampled = estimated.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 13:26:58,624:WARNING:<ipython-input-3-49df83f3379d>:14: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  test_resampled = test.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 13:28:16,169:WARNING:<ipython-input-8-49df83f3379d>:13: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  estimated_resampled = estimated.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 13:28:16,177:WARNING:<ipython-input-8-49df83f3379d>:14: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  test_resampled = test.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 13:30:14,057:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-24 13:30:14,058:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-24 13:30:14,058:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-24 13:30:14,058:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-24 13:30:14,593:WARNING:<ipython-input-3-49df83f3379d>:13: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  estimated_resampled = estimated.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 13:30:14,599:WARNING:<ipython-input-3-49df83f3379d>:14: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  test_resampled = test.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 13:31:56,780:WARNING:<ipython-input-8-49df83f3379d>:13: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  estimated_resampled = estimated.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 13:31:56,788:WARNING:<ipython-input-8-49df83f3379d>:14: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  test_resampled = test.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 13:31:56,841:INFO:PyCaret RegressionExperiment
2023-10-24 13:31:56,841:INFO:Logging name: exp_A
2023-10-24 13:31:56,841:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 13:31:56,842:INFO:version 3.1.0
2023-10-24 13:31:56,842:INFO:Initializing setup()
2023-10-24 13:31:56,842:INFO:self.USI: 776e
2023-10-24 13:31:56,842:INFO:self._variable_keys: {'y_test', 'n_jobs_param', 'exp_id', 'gpu_param', 'idx', '_available_plots', 'html_param', 'X_train', 'target_param', 'transform_target_param', 'logging_param', 'seed', 'y_train', 'log_plots_param', 'y', '_ml_usecase', 'X', 'fold_generator', 'X_test', 'exp_name_log', 'pipeline', 'fold_groups_param', 'data', 'USI', 'fold_shuffle_param', 'memory', 'gpu_n_jobs_param'}
2023-10-24 13:31:56,842:INFO:Checking environment
2023-10-24 13:31:56,842:INFO:python_version: 3.8.5
2023-10-24 13:31:56,842:INFO:python_build: ('default', 'Sep  4 2020 02:22:02')
2023-10-24 13:31:56,842:INFO:machine: x86_64
2023-10-24 13:31:56,856:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-10-24 13:31:56,857:INFO:Memory: svmem(total=8589934592, available=2251620352, percent=73.8, used=4654039040, free=126836736, active=2125811712, inactive=2110808064, wired=2528227328)
2023-10-24 13:31:56,857:INFO:Physical Core: 4
2023-10-24 13:31:56,857:INFO:Logical Core: 8
2023-10-24 13:31:56,857:INFO:Checking libraries
2023-10-24 13:31:56,858:INFO:System:
2023-10-24 13:31:56,858:INFO:    python: 3.8.5 (default, Sep  4 2020, 02:22:02)  [Clang 10.0.0 ]
2023-10-24 13:31:56,858:INFO:executable: /Users/kaja/opt/anaconda3/bin/python
2023-10-24 13:31:56,858:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-10-24 13:31:56,858:INFO:PyCaret required dependencies:
2023-10-24 13:31:57,170:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 13:31:57,171:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 13:31:57,171:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 13:31:57,669:INFO:                 pip: 23.3.1
2023-10-24 13:31:57,670:INFO:          setuptools: 68.2.2
2023-10-24 13:31:57,670:INFO:             pycaret: 3.1.0
2023-10-24 13:31:57,670:INFO:             IPython: 7.19.0
2023-10-24 13:31:57,670:INFO:          ipywidgets: 8.1.1
2023-10-24 13:31:57,670:INFO:                tqdm: 4.66.1
2023-10-24 13:31:57,670:INFO:               numpy: 1.23.5
2023-10-24 13:31:57,670:INFO:              pandas: 1.5.3
2023-10-24 13:31:57,670:INFO:              jinja2: 3.1.2
2023-10-24 13:31:57,670:INFO:               scipy: 1.10.1
2023-10-24 13:31:57,670:INFO:              joblib: 1.3.2
2023-10-24 13:31:57,670:INFO:             sklearn: 1.2.2
2023-10-24 13:31:57,670:INFO:                pyod: 1.1.0
2023-10-24 13:31:57,670:INFO:            imblearn: 0.11.0
2023-10-24 13:31:57,670:INFO:   category_encoders: 2.6.2
2023-10-24 13:31:57,670:INFO:            lightgbm: 4.1.0
2023-10-24 13:31:57,670:INFO:               numba: 0.58.1
2023-10-24 13:31:57,671:INFO:            requests: 2.28.2
2023-10-24 13:31:57,671:INFO:          matplotlib: 3.7.3
2023-10-24 13:31:57,671:INFO:          scikitplot: 0.3.7
2023-10-24 13:31:57,671:INFO:         yellowbrick: 1.5
2023-10-24 13:31:57,671:INFO:              plotly: 5.17.0
2023-10-24 13:31:57,672:INFO:    plotly-resampler: Not installed
2023-10-24 13:31:57,672:INFO:             kaleido: 0.2.1
2023-10-24 13:31:57,672:INFO:           schemdraw: 0.15
2023-10-24 13:31:57,672:INFO:         statsmodels: 0.14.0
2023-10-24 13:31:57,672:INFO:              sktime: 0.21.1
2023-10-24 13:31:57,672:INFO:               tbats: 1.1.3
2023-10-24 13:31:57,672:INFO:            pmdarima: 2.0.4
2023-10-24 13:31:57,672:INFO:              psutil: 5.9.6
2023-10-24 13:31:57,672:INFO:          markupsafe: 2.1.2
2023-10-24 13:31:57,672:INFO:             pickle5: Not installed
2023-10-24 13:31:57,672:INFO:         cloudpickle: 1.6.0
2023-10-24 13:31:57,672:INFO:         deprecation: 2.1.0
2023-10-24 13:31:57,672:INFO:              xxhash: 3.4.1
2023-10-24 13:31:57,672:INFO:           wurlitzer: 2.0.1
2023-10-24 13:31:57,672:INFO:PyCaret optional dependencies:
2023-10-24 13:31:57,692:INFO:                shap: Not installed
2023-10-24 13:31:57,692:INFO:           interpret: Not installed
2023-10-24 13:31:57,692:INFO:                umap: Not installed
2023-10-24 13:31:57,693:INFO:     ydata_profiling: Not installed
2023-10-24 13:31:57,693:INFO:  explainerdashboard: Not installed
2023-10-24 13:31:57,693:INFO:             autoviz: Not installed
2023-10-24 13:31:57,693:INFO:           fairlearn: Not installed
2023-10-24 13:31:57,693:INFO:          deepchecks: Not installed
2023-10-24 13:31:57,693:INFO:             xgboost: Not installed
2023-10-24 13:31:57,693:INFO:            catboost: 1.0.4
2023-10-24 13:31:57,693:INFO:              kmodes: Not installed
2023-10-24 13:31:57,693:INFO:             mlxtend: Not installed
2023-10-24 13:31:57,693:INFO:       statsforecast: Not installed
2023-10-24 13:31:57,693:INFO:        tune_sklearn: Not installed
2023-10-24 13:31:57,693:INFO:                 ray: Not installed
2023-10-24 13:31:57,693:INFO:            hyperopt: Not installed
2023-10-24 13:31:57,693:INFO:              optuna: Not installed
2023-10-24 13:31:57,693:INFO:               skopt: Not installed
2023-10-24 13:31:57,693:INFO:              mlflow: 2.7.1
2023-10-24 13:31:57,693:INFO:              gradio: Not installed
2023-10-24 13:31:57,693:INFO:             fastapi: Not installed
2023-10-24 13:31:57,693:INFO:             uvicorn: Not installed
2023-10-24 13:31:57,693:INFO:              m2cgen: Not installed
2023-10-24 13:31:57,693:INFO:           evidently: Not installed
2023-10-24 13:31:57,693:INFO:               fugue: Not installed
2023-10-24 13:31:57,693:INFO:           streamlit: Not installed
2023-10-24 13:31:57,693:INFO:             prophet: Not installed
2023-10-24 13:31:57,693:INFO:None
2023-10-24 13:31:57,693:INFO:Set up data.
2023-10-24 13:31:57,736:INFO:Set up folding strategy.
2023-10-24 13:31:57,736:INFO:Set up train/test split.
2023-10-24 13:31:57,765:INFO:Set up index.
2023-10-24 13:31:57,767:INFO:Assigning column types.
2023-10-24 13:33:00,422:WARNING:<ipython-input-13-49df83f3379d>:13: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  estimated_resampled = estimated.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 13:33:00,429:WARNING:<ipython-input-13-49df83f3379d>:14: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  test_resampled = test.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 13:33:00,459:INFO:PyCaret RegressionExperiment
2023-10-24 13:33:00,459:INFO:Logging name: exp_A
2023-10-24 13:33:00,459:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 13:33:00,459:INFO:version 3.1.0
2023-10-24 13:33:00,459:INFO:Initializing setup()
2023-10-24 13:33:00,459:INFO:self.USI: 6a1d
2023-10-24 13:33:00,459:INFO:self._variable_keys: {'y_test', 'n_jobs_param', 'exp_id', 'gpu_param', 'idx', '_available_plots', 'html_param', 'X_train', 'target_param', 'transform_target_param', 'logging_param', 'seed', 'y_train', 'log_plots_param', 'y', '_ml_usecase', 'X', 'fold_generator', 'X_test', 'exp_name_log', 'pipeline', 'fold_groups_param', 'data', 'USI', 'fold_shuffle_param', 'memory', 'gpu_n_jobs_param'}
2023-10-24 13:33:00,459:INFO:Checking environment
2023-10-24 13:33:00,459:INFO:python_version: 3.8.5
2023-10-24 13:33:00,460:INFO:python_build: ('default', 'Sep  4 2020 02:22:02')
2023-10-24 13:33:00,460:INFO:machine: x86_64
2023-10-24 13:33:00,460:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-10-24 13:33:00,460:INFO:Memory: svmem(total=8589934592, available=2110922752, percent=75.4, used=4626948096, free=43016192, active=2070163456, inactive=2066051072, wired=2556784640)
2023-10-24 13:33:00,460:INFO:Physical Core: 4
2023-10-24 13:33:00,460:INFO:Logical Core: 8
2023-10-24 13:33:00,460:INFO:Checking libraries
2023-10-24 13:33:00,460:INFO:System:
2023-10-24 13:33:00,460:INFO:    python: 3.8.5 (default, Sep  4 2020, 02:22:02)  [Clang 10.0.0 ]
2023-10-24 13:33:00,460:INFO:executable: /Users/kaja/opt/anaconda3/bin/python
2023-10-24 13:33:00,460:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-10-24 13:33:00,460:INFO:PyCaret required dependencies:
2023-10-24 13:33:00,460:INFO:                 pip: 23.3.1
2023-10-24 13:33:00,460:INFO:          setuptools: 68.2.2
2023-10-24 13:33:00,460:INFO:             pycaret: 3.1.0
2023-10-24 13:33:00,460:INFO:             IPython: 7.19.0
2023-10-24 13:33:00,460:INFO:          ipywidgets: 8.1.1
2023-10-24 13:33:00,460:INFO:                tqdm: 4.66.1
2023-10-24 13:33:00,460:INFO:               numpy: 1.23.5
2023-10-24 13:33:00,460:INFO:              pandas: 1.5.3
2023-10-24 13:33:00,460:INFO:              jinja2: 3.1.2
2023-10-24 13:33:00,460:INFO:               scipy: 1.10.1
2023-10-24 13:33:00,460:INFO:              joblib: 1.3.2
2023-10-24 13:33:00,460:INFO:             sklearn: 1.2.2
2023-10-24 13:33:00,460:INFO:                pyod: 1.1.0
2023-10-24 13:33:00,460:INFO:            imblearn: 0.11.0
2023-10-24 13:33:00,460:INFO:   category_encoders: 2.6.2
2023-10-24 13:33:00,461:INFO:            lightgbm: 4.1.0
2023-10-24 13:33:00,461:INFO:               numba: 0.58.1
2023-10-24 13:33:00,461:INFO:            requests: 2.28.2
2023-10-24 13:33:00,461:INFO:          matplotlib: 3.7.3
2023-10-24 13:33:00,461:INFO:          scikitplot: 0.3.7
2023-10-24 13:33:00,461:INFO:         yellowbrick: 1.5
2023-10-24 13:33:00,461:INFO:              plotly: 5.17.0
2023-10-24 13:33:00,461:INFO:    plotly-resampler: Not installed
2023-10-24 13:33:00,461:INFO:             kaleido: 0.2.1
2023-10-24 13:33:00,461:INFO:           schemdraw: 0.15
2023-10-24 13:33:00,461:INFO:         statsmodels: 0.14.0
2023-10-24 13:33:00,461:INFO:              sktime: 0.21.1
2023-10-24 13:33:00,461:INFO:               tbats: 1.1.3
2023-10-24 13:33:00,461:INFO:            pmdarima: 2.0.4
2023-10-24 13:33:00,461:INFO:              psutil: 5.9.6
2023-10-24 13:33:00,461:INFO:          markupsafe: 2.1.2
2023-10-24 13:33:00,461:INFO:             pickle5: Not installed
2023-10-24 13:33:00,461:INFO:         cloudpickle: 1.6.0
2023-10-24 13:33:00,461:INFO:         deprecation: 2.1.0
2023-10-24 13:33:00,461:INFO:              xxhash: 3.4.1
2023-10-24 13:33:00,461:INFO:           wurlitzer: 2.0.1
2023-10-24 13:33:00,461:INFO:PyCaret optional dependencies:
2023-10-24 13:33:00,461:INFO:                shap: Not installed
2023-10-24 13:33:00,461:INFO:           interpret: Not installed
2023-10-24 13:33:00,461:INFO:                umap: Not installed
2023-10-24 13:33:00,461:INFO:     ydata_profiling: Not installed
2023-10-24 13:33:00,461:INFO:  explainerdashboard: Not installed
2023-10-24 13:33:00,461:INFO:             autoviz: Not installed
2023-10-24 13:33:00,461:INFO:           fairlearn: Not installed
2023-10-24 13:33:00,461:INFO:          deepchecks: Not installed
2023-10-24 13:33:00,462:INFO:             xgboost: Not installed
2023-10-24 13:33:00,462:INFO:            catboost: 1.0.4
2023-10-24 13:33:00,462:INFO:              kmodes: Not installed
2023-10-24 13:33:00,462:INFO:             mlxtend: Not installed
2023-10-24 13:33:00,462:INFO:       statsforecast: Not installed
2023-10-24 13:33:00,462:INFO:        tune_sklearn: Not installed
2023-10-24 13:33:00,462:INFO:                 ray: Not installed
2023-10-24 13:33:00,462:INFO:            hyperopt: Not installed
2023-10-24 13:33:00,462:INFO:              optuna: Not installed
2023-10-24 13:33:00,462:INFO:               skopt: Not installed
2023-10-24 13:33:00,462:INFO:              mlflow: 2.7.1
2023-10-24 13:33:00,462:INFO:              gradio: Not installed
2023-10-24 13:33:00,462:INFO:             fastapi: Not installed
2023-10-24 13:33:00,462:INFO:             uvicorn: Not installed
2023-10-24 13:33:00,462:INFO:              m2cgen: Not installed
2023-10-24 13:33:00,462:INFO:           evidently: Not installed
2023-10-24 13:33:00,462:INFO:               fugue: Not installed
2023-10-24 13:33:00,462:INFO:           streamlit: Not installed
2023-10-24 13:33:00,462:INFO:             prophet: Not installed
2023-10-24 13:33:00,462:INFO:None
2023-10-24 13:33:00,462:INFO:Set up data.
2023-10-24 13:33:00,493:INFO:Set up folding strategy.
2023-10-24 13:33:00,493:INFO:Set up train/test split.
2023-10-24 13:33:00,518:INFO:Set up index.
2023-10-24 13:33:00,520:INFO:Assigning column types.
2023-10-24 13:33:00,530:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 13:33:00,530:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 13:33:00,536:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 13:33:00,540:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 13:33:00,605:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 13:33:00,647:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 13:33:00,648:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 13:33:00,648:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 13:33:00,649:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 13:33:00,653:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 13:33:00,657:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 13:33:00,716:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 13:33:00,757:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 13:33:00,758:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 13:33:00,758:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 13:33:00,759:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 13:33:00,763:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 13:33:00,767:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 13:33:00,826:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 13:33:00,869:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 13:33:00,870:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 13:33:00,870:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 13:33:00,875:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 13:33:00,878:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 13:33:00,939:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 13:33:00,979:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 13:33:00,980:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 13:33:00,980:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 13:33:00,980:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 13:33:00,989:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 13:33:01,048:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 13:33:01,089:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 13:33:01,089:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 13:33:01,090:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 13:33:01,098:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 13:33:01,161:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 13:33:01,223:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 13:33:01,223:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 13:33:01,224:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 13:33:01,224:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 13:33:01,295:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 13:33:01,338:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 13:33:01,339:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 13:33:01,339:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 13:33:01,434:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 13:33:01,476:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 13:33:01,480:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 13:33:01,480:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 13:33:01,480:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 13:33:01,550:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 13:33:01,592:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 13:33:01,592:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 13:33:01,660:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 13:33:01,700:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 13:33:01,701:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 13:33:01,701:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 13:33:01,812:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 13:33:01,812:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 13:33:01,924:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 13:33:01,931:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 13:33:01,934:INFO:Preparing preprocessing pipeline...
2023-10-24 13:33:01,934:INFO:Set up simple imputation.
2023-10-24 13:33:01,942:INFO:Set up encoding of categorical features.
2023-10-24 13:33:01,945:INFO:Set up column name cleaning.
2023-10-24 13:33:02,229:INFO:Finished creating preprocessing pipeline.
2023-10-24 13:33:02,238:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             '...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx', 'is_day:idx',
                                             'is_in_shadow:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx',
                                                                    'is_day:idx',
                                                                    'is_in_shadow:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 13:33:02,238:INFO:Creating final display dataframe.
2023-10-24 13:33:02,824:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (34061, 46)
4        Transformed data shape  (34061, 62)
5   Transformed train set shape  (23842, 62)
6    Transformed test set shape  (10219, 62)
7              Numeric features           42
8          Categorical features            3
9      Rows with missing values        97.4%
10                   Preprocess         True
11              Imputation type       simple
12           Numeric imputation         mean
13       Categorical imputation         mode
14     Maximum one-hot encoding           25
15              Encoding method         None
16               Fold Generator        KFold
17                  Fold Number           10
18                     CPU Jobs           -1
19                      Use GPU        False
20               Log Experiment        False
21              Experiment Name        exp_A
22                          USI         6a1d
2023-10-24 13:33:03,036:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 13:33:03,037:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 13:33:03,199:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 13:33:03,202:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 13:33:03,204:INFO:setup() successfully completed in 2.75s...............
2023-10-24 13:33:03,204:INFO:Initializing create_model()
2023-10-24 13:33:03,204:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff604cd3730>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 13:33:03,204:INFO:Checking exceptions
2023-10-24 13:33:03,239:INFO:Importing libraries
2023-10-24 13:33:03,241:INFO:Copying training dataset
2023-10-24 13:33:03,293:INFO:Defining folds
2023-10-24 13:33:03,294:INFO:Declaring metric variables
2023-10-24 13:33:03,294:INFO:Importing untrained model
2023-10-24 13:33:03,295:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 13:33:03,296:INFO:Starting cross validation
2023-10-24 13:33:03,306:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 13:33:08,306:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 13:33:08,306:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 13:33:08,306:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 13:33:08,306:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 13:33:08,306:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 13:33:08,306:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 13:33:08,306:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 13:33:08,306:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 13:33:08,307:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 13:33:08,307:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 13:33:08,307:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 13:33:08,307:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 13:33:08,307:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 13:33:08,307:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 13:33:08,307:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 13:33:08,307:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 13:33:08,307:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 13:33:08,307:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 13:33:08,307:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 13:33:08,307:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 13:33:08,307:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 13:33:08,307:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 13:33:08,307:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 13:33:08,307:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 13:33:10,952:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033855 seconds.
2023-10-24 13:33:10,953:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:33:10,953:INFO:[LightGBM] [Info] Total Bins 7568
2023-10-24 13:33:10,954:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034687 seconds.
2023-10-24 13:33:10,954:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:33:10,954:INFO:[LightGBM] [Info] Total Bins 7574
2023-10-24 13:33:10,954:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 56
2023-10-24 13:33:10,956:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 57
2023-10-24 13:33:10,961:INFO:[LightGBM] [Info] Start training from score 638.315026
2023-10-24 13:33:10,962:INFO:[LightGBM] [Info] Start training from score 637.332613
2023-10-24 13:33:10,966:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029816 seconds.
2023-10-24 13:33:10,966:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 13:33:10,966:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 13:33:10,967:INFO:[LightGBM] [Info] Total Bins 7567
2023-10-24 13:33:10,969:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 57
2023-10-24 13:33:10,972:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043357 seconds.
2023-10-24 13:33:10,972:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:33:10,972:INFO:[LightGBM] [Info] Total Bins 7556
2023-10-24 13:33:10,976:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 56
2023-10-24 13:33:10,976:INFO:[LightGBM] [Info] Start training from score 632.987592
2023-10-24 13:33:10,976:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036607 seconds.
2023-10-24 13:33:10,977:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 13:33:10,977:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 13:33:10,977:INFO:[LightGBM] [Info] Total Bins 7562
2023-10-24 13:33:10,978:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 57
2023-10-24 13:33:10,979:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052677 seconds.
2023-10-24 13:33:10,979:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:33:10,979:INFO:[LightGBM] [Info] Start training from score 632.935130
2023-10-24 13:33:10,979:INFO:[LightGBM] [Info] Total Bins 7556
2023-10-24 13:33:10,981:INFO:[LightGBM] [Info] Number of data points in the train set: 21457, number of used features: 57
2023-10-24 13:33:10,982:INFO:[LightGBM] [Info] Start training from score 635.066755
2023-10-24 13:33:10,985:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054240 seconds.
2023-10-24 13:33:10,985:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:33:10,985:INFO:[LightGBM] [Info] Total Bins 7559
2023-10-24 13:33:10,985:INFO:[LightGBM] [Info] Start training from score 635.025755
2023-10-24 13:33:10,987:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 56
2023-10-24 13:33:10,993:INFO:[LightGBM] [Info] Start training from score 638.498183
2023-10-24 13:33:11,001:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047245 seconds.
2023-10-24 13:33:11,002:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:33:11,002:INFO:[LightGBM] [Info] Total Bins 7552
2023-10-24 13:33:11,003:INFO:[LightGBM] [Info] Number of data points in the train set: 21457, number of used features: 56
2023-10-24 13:33:11,007:INFO:[LightGBM] [Info] Start training from score 638.228207
2023-10-24 13:33:18,956:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019498 seconds.
2023-10-24 13:33:18,956:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 13:33:18,956:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 13:33:18,956:INFO:[LightGBM] [Info] Total Bins 7563
2023-10-24 13:33:18,957:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 55
2023-10-24 13:33:18,959:INFO:[LightGBM] [Info] Start training from score 635.296336
2023-10-24 13:33:19,014:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021919 seconds.
2023-10-24 13:33:19,015:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:33:19,015:INFO:[LightGBM] [Info] Total Bins 7552
2023-10-24 13:33:19,016:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 55
2023-10-24 13:33:19,017:INFO:[LightGBM] [Info] Start training from score 637.380303
2023-10-24 13:33:20,624:INFO:Calculating mean and std
2023-10-24 13:33:20,628:INFO:Creating metrics dataframe
2023-10-24 13:33:20,635:INFO:Finalizing model
2023-10-24 13:33:20,978:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006132 seconds.
2023-10-24 13:33:20,979:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:33:20,979:INFO:[LightGBM] [Info] Total Bins 7689
2023-10-24 13:33:20,980:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 57
2023-10-24 13:33:20,980:INFO:[LightGBM] [Info] Start training from score 636.106585
2023-10-24 13:33:21,201:INFO:Uploading results into container
2023-10-24 13:33:21,203:INFO:Uploading model into container now
2023-10-24 13:33:21,209:INFO:_master_model_container: 1
2023-10-24 13:33:21,210:INFO:_display_container: 2
2023-10-24 13:33:21,210:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 13:33:21,210:INFO:create_model() successfully completed......................................
2023-10-24 13:33:21,516:INFO:Initializing tune_model()
2023-10-24 13:33:21,517:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff604cd3730>)
2023-10-24 13:33:21,517:INFO:Checking exceptions
2023-10-24 13:33:21,532:INFO:Copying training dataset
2023-10-24 13:33:21,547:INFO:Checking base model
2023-10-24 13:33:21,547:INFO:Base model : Light Gradient Boosting Machine
2023-10-24 13:33:21,548:INFO:Declaring metric variables
2023-10-24 13:33:21,548:INFO:Defining Hyperparameters
2023-10-24 13:33:21,633:INFO:Tuning with n_jobs=-1
2023-10-24 13:33:21,634:INFO:Initializing RandomizedSearchCV
2023-10-24 13:37:06,363:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-24 13:37:06,371:INFO:Hyperparameter search completed
2023-10-24 13:37:06,371:INFO:SubProcess create_model() called ==================================
2023-10-24 13:37:06,374:INFO:Initializing create_model()
2023-10-24 13:37:06,374:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff604cd3730>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff5eaf1fbe0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-24 13:37:06,374:INFO:Checking exceptions
2023-10-24 13:37:06,375:INFO:Importing libraries
2023-10-24 13:37:06,375:INFO:Copying training dataset
2023-10-24 13:37:06,416:INFO:Defining folds
2023-10-24 13:37:06,417:INFO:Declaring metric variables
2023-10-24 13:37:06,418:INFO:Importing untrained model
2023-10-24 13:37:06,418:INFO:Declaring custom model
2023-10-24 13:37:06,420:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 13:37:06,421:INFO:Starting cross validation
2023-10-24 13:37:06,424:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 13:37:48,611:INFO:Calculating mean and std
2023-10-24 13:37:48,612:INFO:Creating metrics dataframe
2023-10-24 13:37:48,617:INFO:Finalizing model
2023-10-24 13:37:48,868:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:37:48,868:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:37:48,868:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:37:48,918:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:37:48,919:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:37:48,919:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:37:48,927:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005489 seconds.
2023-10-24 13:37:48,927:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:37:48,929:INFO:[LightGBM] [Info] Total Bins 7683
2023-10-24 13:37:48,930:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 54
2023-10-24 13:37:48,932:INFO:[LightGBM] [Info] Start training from score 636.106585
2023-10-24 13:37:49,771:INFO:Uploading results into container
2023-10-24 13:37:49,772:INFO:Uploading model into container now
2023-10-24 13:37:49,774:INFO:_master_model_container: 2
2023-10-24 13:37:49,774:INFO:_display_container: 3
2023-10-24 13:37:49,775:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-24 13:37:49,775:INFO:create_model() successfully completed......................................
2023-10-24 13:37:50,090:INFO:SubProcess create_model() end ==================================
2023-10-24 13:37:50,090:INFO:choose_better activated
2023-10-24 13:37:50,090:INFO:SubProcess create_model() called ==================================
2023-10-24 13:37:50,091:INFO:Initializing create_model()
2023-10-24 13:37:50,091:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff604cd3730>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 13:37:50,091:INFO:Checking exceptions
2023-10-24 13:37:50,092:INFO:Importing libraries
2023-10-24 13:37:50,092:INFO:Copying training dataset
2023-10-24 13:37:50,112:INFO:Defining folds
2023-10-24 13:37:50,113:INFO:Declaring metric variables
2023-10-24 13:37:50,113:INFO:Importing untrained model
2023-10-24 13:37:50,113:INFO:Declaring custom model
2023-10-24 13:37:50,114:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 13:37:50,114:INFO:Starting cross validation
2023-10-24 13:37:50,116:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 13:37:59,183:INFO:Calculating mean and std
2023-10-24 13:37:59,184:INFO:Creating metrics dataframe
2023-10-24 13:37:59,187:INFO:Finalizing model
2023-10-24 13:37:59,461:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005663 seconds.
2023-10-24 13:37:59,461:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:37:59,461:INFO:[LightGBM] [Info] Total Bins 7689
2023-10-24 13:37:59,462:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 57
2023-10-24 13:37:59,462:INFO:[LightGBM] [Info] Start training from score 636.106585
2023-10-24 13:37:59,654:INFO:Uploading results into container
2023-10-24 13:37:59,654:INFO:Uploading model into container now
2023-10-24 13:37:59,655:INFO:_master_model_container: 3
2023-10-24 13:37:59,655:INFO:_display_container: 4
2023-10-24 13:37:59,655:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 13:37:59,655:INFO:create_model() successfully completed......................................
2023-10-24 13:37:59,740:INFO:SubProcess create_model() end ==================================
2023-10-24 13:37:59,740:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.865
2023-10-24 13:37:59,741:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8657
2023-10-24 13:37:59,742:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) is best model
2023-10-24 13:37:59,742:INFO:choose_better completed
2023-10-24 13:37:59,746:INFO:_master_model_container: 3
2023-10-24 13:37:59,747:INFO:_display_container: 3
2023-10-24 13:37:59,748:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-24 13:37:59,748:INFO:tune_model() successfully completed......................................
2023-10-24 13:37:59,829:INFO:Initializing ensemble_model()
2023-10-24 13:37:59,829:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff604cd3730>, estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-24 13:37:59,829:INFO:Checking exceptions
2023-10-24 13:37:59,844:INFO:Importing libraries
2023-10-24 13:37:59,844:INFO:Copying training dataset
2023-10-24 13:37:59,845:INFO:Checking base model
2023-10-24 13:37:59,845:INFO:Base model : Light Gradient Boosting Machine
2023-10-24 13:37:59,846:INFO:Importing untrained ensembler
2023-10-24 13:37:59,846:INFO:Ensemble method set to Bagging
2023-10-24 13:37:59,846:INFO:SubProcess create_model() called ==================================
2023-10-24 13:37:59,849:INFO:Initializing create_model()
2023-10-24 13:37:59,849:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff604cd3730>, estimator=BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                                         feature_fraction=0.4,
                                         min_child_samples=41,
                                         min_split_gain=0.9, n_estimators=260,
                                         n_jobs=-1, num_leaves=70,
                                         random_state=123, reg_alpha=2,
                                         reg_lambda=3),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff5e957af70>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 13:37:59,849:INFO:Checking exceptions
2023-10-24 13:37:59,849:INFO:Importing libraries
2023-10-24 13:37:59,849:INFO:Copying training dataset
2023-10-24 13:37:59,865:INFO:Defining folds
2023-10-24 13:37:59,865:INFO:Declaring metric variables
2023-10-24 13:37:59,865:INFO:Importing untrained model
2023-10-24 13:37:59,865:INFO:Declaring custom model
2023-10-24 13:37:59,866:INFO:Bagging Regressor Imported successfully
2023-10-24 13:37:59,867:INFO:Starting cross validation
2023-10-24 13:37:59,868:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 13:45:00,352:INFO:Calculating mean and std
2023-10-24 13:45:00,361:INFO:Creating metrics dataframe
2023-10-24 13:45:00,373:INFO:Finalizing model
2023-10-24 13:45:00,661:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:45:00,661:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:45:00,661:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:45:00,708:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:45:00,708:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:45:00,708:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:45:00,717:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005632 seconds.
2023-10-24 13:45:00,717:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:45:00,718:INFO:[LightGBM] [Info] Total Bins 7683
2023-10-24 13:45:00,720:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 54
2023-10-24 13:45:00,722:INFO:[LightGBM] [Info] Start training from score 629.993497
2023-10-24 13:45:01,551:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:45:01,551:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:45:01,551:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:45:01,600:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:45:01,600:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:45:01,600:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:45:01,609:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005745 seconds.
2023-10-24 13:45:01,609:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:45:01,610:INFO:[LightGBM] [Info] Total Bins 7683
2023-10-24 13:45:01,612:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 54
2023-10-24 13:45:01,613:INFO:[LightGBM] [Info] Start training from score 639.698324
2023-10-24 13:45:03,329:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:45:03,329:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:45:03,329:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:45:03,390:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:45:03,391:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:45:03,391:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:45:03,399:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004439 seconds.
2023-10-24 13:45:03,399:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:45:03,401:INFO:[LightGBM] [Info] Total Bins 7683
2023-10-24 13:45:03,403:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 54
2023-10-24 13:45:03,404:INFO:[LightGBM] [Info] Start training from score 639.067381
2023-10-24 13:45:04,331:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:45:04,331:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:45:04,331:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:45:04,382:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:45:04,382:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:45:04,382:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:45:04,392:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007201 seconds.
2023-10-24 13:45:04,392:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:45:04,393:INFO:[LightGBM] [Info] Total Bins 7683
2023-10-24 13:45:04,395:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 54
2023-10-24 13:45:04,395:INFO:[LightGBM] [Info] Start training from score 640.702912
2023-10-24 13:45:05,301:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:45:05,301:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:45:05,301:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:45:05,350:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:45:05,350:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:45:05,350:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:45:05,357:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004295 seconds.
2023-10-24 13:45:05,357:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:45:05,358:INFO:[LightGBM] [Info] Total Bins 7683
2023-10-24 13:45:05,360:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 54
2023-10-24 13:45:05,361:INFO:[LightGBM] [Info] Start training from score 638.373964
2023-10-24 13:45:06,379:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:45:06,379:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:45:06,379:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:45:06,429:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:45:06,430:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:45:06,430:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:45:06,438:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005460 seconds.
2023-10-24 13:45:06,438:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:45:06,439:INFO:[LightGBM] [Info] Total Bins 7683
2023-10-24 13:45:06,441:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 54
2023-10-24 13:45:06,442:INFO:[LightGBM] [Info] Start training from score 631.653878
2023-10-24 13:45:07,356:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:45:07,356:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:45:07,356:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:45:07,402:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:45:07,402:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:45:07,402:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:45:07,413:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007273 seconds.
2023-10-24 13:45:07,413:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:45:07,414:INFO:[LightGBM] [Info] Total Bins 7683
2023-10-24 13:45:07,416:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 54
2023-10-24 13:45:07,417:INFO:[LightGBM] [Info] Start training from score 640.465574
2023-10-24 13:45:08,508:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:45:08,508:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:45:08,508:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:45:08,554:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:45:08,554:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:45:08,554:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:45:08,562:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005700 seconds.
2023-10-24 13:45:08,562:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:45:08,564:INFO:[LightGBM] [Info] Total Bins 7683
2023-10-24 13:45:08,565:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 54
2023-10-24 13:45:08,566:INFO:[LightGBM] [Info] Start training from score 642.146080
2023-10-24 13:45:09,476:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:45:09,476:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:45:09,477:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:45:09,521:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:45:09,521:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:45:09,521:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:45:09,528:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004496 seconds.
2023-10-24 13:45:09,528:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:45:09,530:INFO:[LightGBM] [Info] Total Bins 7683
2023-10-24 13:45:09,531:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 54
2023-10-24 13:45:09,533:INFO:[LightGBM] [Info] Start training from score 646.454539
2023-10-24 13:45:10,365:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:45:10,365:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:45:10,365:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:45:10,410:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:45:10,411:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:45:10,411:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:45:10,418:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005013 seconds.
2023-10-24 13:45:10,418:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:45:10,419:INFO:[LightGBM] [Info] Total Bins 7683
2023-10-24 13:45:10,421:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 54
2023-10-24 13:45:10,422:INFO:[LightGBM] [Info] Start training from score 646.584710
2023-10-24 13:45:11,294:INFO:Uploading results into container
2023-10-24 13:45:11,295:INFO:Uploading model into container now
2023-10-24 13:45:11,296:INFO:_master_model_container: 4
2023-10-24 13:45:11,297:INFO:_display_container: 4
2023-10-24 13:45:11,300:INFO:BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                                         feature_fraction=0.4,
                                         min_child_samples=41,
                                         min_split_gain=0.9, n_estimators=260,
                                         n_jobs=-1, num_leaves=70,
                                         random_state=123, reg_alpha=2,
                                         reg_lambda=3),
                 random_state=123)
2023-10-24 13:45:11,300:INFO:create_model() successfully completed......................................
2023-10-24 13:45:11,621:INFO:SubProcess create_model() end ==================================
2023-10-24 13:45:11,627:INFO:_master_model_container: 4
2023-10-24 13:45:11,627:INFO:_display_container: 4
2023-10-24 13:45:11,629:INFO:BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                                         feature_fraction=0.4,
                                         min_child_samples=41,
                                         min_split_gain=0.9, n_estimators=260,
                                         n_jobs=-1, num_leaves=70,
                                         random_state=123, reg_alpha=2,
                                         reg_lambda=3),
                 random_state=123)
2023-10-24 13:45:11,629:INFO:ensemble_model() successfully completed......................................
2023-10-24 13:45:11,708:INFO:Initializing finalize_model()
2023-10-24 13:45:11,708:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff604cd3730>, estimator=BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                                         feature_fraction=0.4,
                                         min_child_samples=41,
                                         min_split_gain=0.9, n_estimators=260,
                                         n_jobs=-1, num_leaves=70,
                                         random_state=123, reg_alpha=2,
                                         reg_lambda=3),
                 random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-24 13:45:11,710:INFO:Finalizing BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                                         feature_fraction=0.4,
                                         min_child_samples=41,
                                         min_split_gain=0.9, n_estimators=260,
                                         n_jobs=-1, num_leaves=70,
                                         random_state=123, reg_alpha=2,
                                         reg_lambda=3),
                 random_state=123)
2023-10-24 13:45:11,742:INFO:Initializing create_model()
2023-10-24 13:45:11,742:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff604cd3730>, estimator=BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                                         feature_fraction=0.4,
                                         min_child_samples=41,
                                         min_split_gain=0.9, n_estimators=260,
                                         n_jobs=-1, num_leaves=70,
                                         random_state=123, reg_alpha=2,
                                         reg_lambda=3),
                 random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-24 13:45:11,743:INFO:Checking exceptions
2023-10-24 13:45:11,744:INFO:Importing libraries
2023-10-24 13:45:11,744:INFO:Copying training dataset
2023-10-24 13:45:11,745:INFO:Defining folds
2023-10-24 13:45:11,745:INFO:Declaring metric variables
2023-10-24 13:45:11,745:INFO:Importing untrained model
2023-10-24 13:45:11,745:INFO:Declaring custom model
2023-10-24 13:45:11,747:INFO:Bagging Regressor Imported successfully
2023-10-24 13:45:11,748:INFO:Cross validation set to False
2023-10-24 13:45:11,748:INFO:Fitting Model
2023-10-24 13:45:12,069:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:45:12,070:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:45:12,070:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:45:12,141:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:45:12,141:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:45:12,141:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:45:12,150:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002091 seconds.
2023-10-24 13:45:12,150:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 13:45:12,151:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 13:45:12,151:INFO:[LightGBM] [Info] Total Bins 7876
2023-10-24 13:45:12,152:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 55
2023-10-24 13:45:12,153:INFO:[LightGBM] [Info] Start training from score 621.939460
2023-10-24 13:45:13,258:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:45:13,258:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:45:13,258:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:45:13,329:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:45:13,329:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:45:13,330:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:45:13,340:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001699 seconds.
2023-10-24 13:45:13,340:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 13:45:13,340:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 13:45:13,340:INFO:[LightGBM] [Info] Total Bins 7876
2023-10-24 13:45:13,342:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 55
2023-10-24 13:45:13,343:INFO:[LightGBM] [Info] Start training from score 633.276326
2023-10-24 13:45:14,389:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:45:14,389:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:45:14,389:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:45:14,465:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:45:14,466:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:45:14,466:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:45:14,477:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001543 seconds.
2023-10-24 13:45:14,478:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 13:45:14,478:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 13:45:14,478:INFO:[LightGBM] [Info] Total Bins 7876
2023-10-24 13:45:14,479:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 55
2023-10-24 13:45:14,481:INFO:[LightGBM] [Info] Start training from score 622.547611
2023-10-24 13:45:15,551:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:45:15,551:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:45:15,551:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:45:15,628:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:45:15,628:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:45:15,628:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:45:15,641:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001647 seconds.
2023-10-24 13:45:15,661:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 13:45:15,661:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 13:45:15,662:INFO:[LightGBM] [Info] Total Bins 7876
2023-10-24 13:45:15,663:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 55
2023-10-24 13:45:15,664:INFO:[LightGBM] [Info] Start training from score 627.206506
2023-10-24 13:45:16,794:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:45:16,794:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:45:16,794:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:45:16,883:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:45:16,883:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:45:16,883:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:45:16,894:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001890 seconds.
2023-10-24 13:45:16,894:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 13:45:16,894:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 13:45:16,894:INFO:[LightGBM] [Info] Total Bins 7876
2023-10-24 13:45:16,896:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 55
2023-10-24 13:45:16,898:INFO:[LightGBM] [Info] Start training from score 637.955081
2023-10-24 13:45:18,004:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:45:18,004:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:45:18,004:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:45:18,073:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:45:18,073:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:45:18,073:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:45:18,084:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002425 seconds.
2023-10-24 13:45:18,085:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 13:45:18,085:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 13:45:18,085:INFO:[LightGBM] [Info] Total Bins 7876
2023-10-24 13:45:18,087:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 55
2023-10-24 13:45:18,088:INFO:[LightGBM] [Info] Start training from score 632.824687
2023-10-24 13:45:19,106:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:45:19,106:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:45:19,106:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:45:19,175:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:45:19,175:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:45:19,175:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:45:19,186:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007391 seconds.
2023-10-24 13:45:19,186:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:45:19,188:INFO:[LightGBM] [Info] Total Bins 7876
2023-10-24 13:45:19,190:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 55
2023-10-24 13:45:19,192:INFO:[LightGBM] [Info] Start training from score 633.780341
2023-10-24 13:45:20,135:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:45:20,135:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:45:20,135:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:45:20,206:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:45:20,206:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:45:20,206:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:45:20,216:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007109 seconds.
2023-10-24 13:45:20,217:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:45:20,217:INFO:[LightGBM] [Info] Total Bins 7876
2023-10-24 13:45:20,219:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 55
2023-10-24 13:45:20,220:INFO:[LightGBM] [Info] Start training from score 636.770620
2023-10-24 13:45:21,250:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:45:21,250:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:45:21,250:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:45:21,319:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:45:21,319:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:45:21,319:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:45:21,330:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007431 seconds.
2023-10-24 13:45:21,330:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:45:21,332:INFO:[LightGBM] [Info] Total Bins 7876
2023-10-24 13:45:21,333:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 55
2023-10-24 13:45:21,334:INFO:[LightGBM] [Info] Start training from score 638.361113
2023-10-24 13:45:22,338:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:45:22,338:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:45:22,338:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:45:22,407:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:45:22,408:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:45:22,408:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:45:22,419:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002341 seconds.
2023-10-24 13:45:22,419:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 13:45:22,419:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 13:45:22,419:INFO:[LightGBM] [Info] Total Bins 7876
2023-10-24 13:45:22,421:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 55
2023-10-24 13:45:22,422:INFO:[LightGBM] [Info] Start training from score 629.488323
2023-10-24 13:45:23,676:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6,
                                                          bagging_freq=2,
                                                          feature_fraction=0.4,
                                                          min_child_samples=41,
                                                          min_split_gain=0.9,
                                                          n_estimators=260,
                                                          n_jobs=-1,
                                                          num_leaves=70,
                                                          random_state=123,
                                                          reg_alpha=2,
                                                          reg_lambda=3),
                                  random_state=123))])
2023-10-24 13:45:23,676:INFO:create_model() successfully completed......................................
2023-10-24 13:45:23,765:INFO:_master_model_container: 4
2023-10-24 13:45:23,766:INFO:_display_container: 4
2023-10-24 13:45:23,784:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6,
                                                          bagging_freq=2,
                                                          feature_fraction=0.4,
                                                          min_child_samples=41,
                                                          min_split_gain=0.9,
                                                          n_estimators=260,
                                                          n_jobs=-1,
                                                          num_leaves=70,
                                                          random_state=123,
                                                          reg_alpha=2,
                                                          reg_lambda=3),
                                  random_state=123))])
2023-10-24 13:45:23,785:INFO:finalize_model() successfully completed......................................
2023-10-24 13:45:23,892:INFO:Initializing save_model()
2023-10-24 13:45:23,892:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6,
                                                          bagging_freq=2,
                                                          feature_fraction=0.4,
                                                          min_child_samples=41,
                                                          min_split_gain=0.9,
                                                          n_estimators=260,
                                                          n_jobs=-1,
                                                          num_leaves=70,
                                                          random_state=123,
                                                          reg_alpha=2,
                                                          reg_lambda=3),
                                  random_state=123))]), model_name=final_model_for_location_A, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             '...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx', 'is_day:idx',
                                             'is_in_shadow:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx',
                                                                    'is_day:idx',
                                                                    'is_in_shadow:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-24 13:45:23,892:INFO:Adding model into prep_pipe
2023-10-24 13:45:23,893:WARNING:Only Model saved as it was a pipeline.
2023-10-24 13:45:24,361:INFO:final_model_for_location_A.pkl saved in current working directory
2023-10-24 13:45:24,398:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6,
                                                          bagging_freq=2,
                                                          feature_fraction=0.4,
                                                          min_child_samples=41,
                                                          min_split_gain=0.9,
                                                          n_estimators=260,
                                                          n_jobs=-1,
                                                          num_leaves=70,
                                                          random_state=123,
                                                          reg_alpha=2,
                                                          reg_lambda=3),
                                  random_state=123))])
2023-10-24 13:45:24,398:INFO:save_model() successfully completed......................................
2023-10-24 13:45:24,780:WARNING:<ipython-input-13-49df83f3379d>:13: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  estimated_resampled = estimated.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 13:45:24,788:WARNING:<ipython-input-13-49df83f3379d>:14: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  test_resampled = test.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 13:45:24,842:INFO:PyCaret RegressionExperiment
2023-10-24 13:45:24,843:INFO:Logging name: exp_B
2023-10-24 13:45:24,843:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 13:45:24,843:INFO:version 3.1.0
2023-10-24 13:45:24,843:INFO:Initializing setup()
2023-10-24 13:45:24,843:INFO:self.USI: 6f41
2023-10-24 13:45:24,843:INFO:self._variable_keys: {'y_test', 'n_jobs_param', 'exp_id', 'gpu_param', 'idx', '_available_plots', 'html_param', 'X_train', 'target_param', 'transform_target_param', 'logging_param', 'seed', 'y_train', 'log_plots_param', 'y', '_ml_usecase', 'X', 'fold_generator', 'X_test', 'exp_name_log', 'pipeline', 'fold_groups_param', 'data', 'USI', 'fold_shuffle_param', 'memory', 'gpu_n_jobs_param'}
2023-10-24 13:45:24,843:INFO:Checking environment
2023-10-24 13:45:24,843:INFO:python_version: 3.8.5
2023-10-24 13:45:24,843:INFO:python_build: ('default', 'Sep  4 2020 02:22:02')
2023-10-24 13:45:24,843:INFO:machine: x86_64
2023-10-24 13:45:24,843:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-10-24 13:45:24,843:INFO:Memory: svmem(total=8589934592, available=1694547968, percent=80.3, used=4102471680, free=50388992, active=1645879296, inactive=1618055168, wired=2456592384)
2023-10-24 13:45:24,843:INFO:Physical Core: 4
2023-10-24 13:45:24,843:INFO:Logical Core: 8
2023-10-24 13:45:24,843:INFO:Checking libraries
2023-10-24 13:45:24,843:INFO:System:
2023-10-24 13:45:24,843:INFO:    python: 3.8.5 (default, Sep  4 2020, 02:22:02)  [Clang 10.0.0 ]
2023-10-24 13:45:24,843:INFO:executable: /Users/kaja/opt/anaconda3/bin/python
2023-10-24 13:45:24,843:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-10-24 13:45:24,843:INFO:PyCaret required dependencies:
2023-10-24 13:45:24,844:INFO:                 pip: 23.3.1
2023-10-24 13:45:24,844:INFO:          setuptools: 68.2.2
2023-10-24 13:45:24,844:INFO:             pycaret: 3.1.0
2023-10-24 13:45:24,844:INFO:             IPython: 7.19.0
2023-10-24 13:45:24,844:INFO:          ipywidgets: 8.1.1
2023-10-24 13:45:24,844:INFO:                tqdm: 4.66.1
2023-10-24 13:45:24,844:INFO:               numpy: 1.23.5
2023-10-24 13:45:24,844:INFO:              pandas: 1.5.3
2023-10-24 13:45:24,844:INFO:              jinja2: 3.1.2
2023-10-24 13:45:24,844:INFO:               scipy: 1.10.1
2023-10-24 13:45:24,844:INFO:              joblib: 1.3.2
2023-10-24 13:45:24,844:INFO:             sklearn: 1.2.2
2023-10-24 13:45:24,844:INFO:                pyod: 1.1.0
2023-10-24 13:45:24,844:INFO:            imblearn: 0.11.0
2023-10-24 13:45:24,844:INFO:   category_encoders: 2.6.2
2023-10-24 13:45:24,844:INFO:            lightgbm: 4.1.0
2023-10-24 13:45:24,844:INFO:               numba: 0.58.1
2023-10-24 13:45:24,844:INFO:            requests: 2.28.2
2023-10-24 13:45:24,844:INFO:          matplotlib: 3.7.3
2023-10-24 13:45:24,844:INFO:          scikitplot: 0.3.7
2023-10-24 13:45:24,844:INFO:         yellowbrick: 1.5
2023-10-24 13:45:24,844:INFO:              plotly: 5.17.0
2023-10-24 13:45:24,844:INFO:    plotly-resampler: Not installed
2023-10-24 13:45:24,844:INFO:             kaleido: 0.2.1
2023-10-24 13:45:24,845:INFO:           schemdraw: 0.15
2023-10-24 13:45:24,845:INFO:         statsmodels: 0.14.0
2023-10-24 13:45:24,845:INFO:              sktime: 0.21.1
2023-10-24 13:45:24,845:INFO:               tbats: 1.1.3
2023-10-24 13:45:24,845:INFO:            pmdarima: 2.0.4
2023-10-24 13:45:24,845:INFO:              psutil: 5.9.6
2023-10-24 13:45:24,845:INFO:          markupsafe: 2.1.2
2023-10-24 13:45:24,845:INFO:             pickle5: Not installed
2023-10-24 13:45:24,845:INFO:         cloudpickle: 1.6.0
2023-10-24 13:45:24,845:INFO:         deprecation: 2.1.0
2023-10-24 13:45:24,845:INFO:              xxhash: 3.4.1
2023-10-24 13:45:24,845:INFO:           wurlitzer: 2.0.1
2023-10-24 13:45:24,845:INFO:PyCaret optional dependencies:
2023-10-24 13:45:24,845:INFO:                shap: Not installed
2023-10-24 13:45:24,845:INFO:           interpret: Not installed
2023-10-24 13:45:24,845:INFO:                umap: Not installed
2023-10-24 13:45:24,845:INFO:     ydata_profiling: Not installed
2023-10-24 13:45:24,845:INFO:  explainerdashboard: Not installed
2023-10-24 13:45:24,845:INFO:             autoviz: Not installed
2023-10-24 13:45:24,845:INFO:           fairlearn: Not installed
2023-10-24 13:45:24,845:INFO:          deepchecks: Not installed
2023-10-24 13:45:24,845:INFO:             xgboost: Not installed
2023-10-24 13:45:24,845:INFO:            catboost: 1.0.4
2023-10-24 13:45:24,845:INFO:              kmodes: Not installed
2023-10-24 13:45:24,845:INFO:             mlxtend: Not installed
2023-10-24 13:45:24,845:INFO:       statsforecast: Not installed
2023-10-24 13:45:24,845:INFO:        tune_sklearn: Not installed
2023-10-24 13:45:24,845:INFO:                 ray: Not installed
2023-10-24 13:45:24,846:INFO:            hyperopt: Not installed
2023-10-24 13:45:24,846:INFO:              optuna: Not installed
2023-10-24 13:45:24,846:INFO:               skopt: Not installed
2023-10-24 13:45:24,846:INFO:              mlflow: 2.7.1
2023-10-24 13:45:24,846:INFO:              gradio: Not installed
2023-10-24 13:45:24,846:INFO:             fastapi: Not installed
2023-10-24 13:45:24,846:INFO:             uvicorn: Not installed
2023-10-24 13:45:24,846:INFO:              m2cgen: Not installed
2023-10-24 13:45:24,846:INFO:           evidently: Not installed
2023-10-24 13:45:24,846:INFO:               fugue: Not installed
2023-10-24 13:45:24,846:INFO:           streamlit: Not installed
2023-10-24 13:45:24,846:INFO:             prophet: Not installed
2023-10-24 13:45:24,846:INFO:None
2023-10-24 13:45:24,846:INFO:Set up data.
2023-10-24 13:45:24,881:INFO:Set up folding strategy.
2023-10-24 13:45:24,881:INFO:Set up train/test split.
2023-10-24 13:45:24,902:INFO:Set up index.
2023-10-24 13:45:24,903:INFO:Assigning column types.
2023-10-24 13:45:24,915:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 13:45:24,915:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 13:45:24,920:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 13:45:24,925:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 13:45:24,997:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 13:45:25,108:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 13:45:25,109:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 13:45:25,110:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 13:45:25,111:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 13:45:25,141:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 13:45:25,146:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 13:45:25,214:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 13:45:25,265:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 13:45:25,266:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 13:45:25,266:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 13:45:25,266:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 13:45:25,272:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 13:45:25,277:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 13:45:25,350:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 13:45:25,406:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 13:45:25,406:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 13:45:25,407:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 13:45:25,412:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 13:45:25,417:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 13:45:25,484:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 13:45:25,544:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 13:45:25,545:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 13:45:25,545:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 13:45:25,546:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 13:45:25,558:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 13:45:25,647:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 13:45:25,711:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 13:45:25,712:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 13:45:25,712:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 13:45:25,722:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 13:45:25,788:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 13:45:25,834:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 13:45:25,834:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 13:45:25,835:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 13:45:25,836:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 13:45:25,910:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 13:45:25,958:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 13:45:25,958:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 13:45:25,959:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 13:45:26,033:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 13:45:26,076:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 13:45:26,077:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 13:45:26,077:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 13:45:26,077:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 13:45:26,152:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 13:45:26,204:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 13:45:26,204:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 13:45:26,290:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 13:45:26,339:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 13:45:26,339:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 13:45:26,340:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 13:45:26,471:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 13:45:26,472:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 13:45:26,602:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 13:45:26,602:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 13:45:26,604:INFO:Preparing preprocessing pipeline...
2023-10-24 13:45:26,604:INFO:Set up simple imputation.
2023-10-24 13:45:26,610:INFO:Set up encoding of categorical features.
2023-10-24 13:45:26,614:INFO:Set up column name cleaning.
2023-10-24 13:45:26,908:INFO:Finished creating preprocessing pipeline.
2023-10-24 13:45:26,919:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             '...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx', 'is_day:idx',
                                             'is_in_shadow:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx',
                                                                    'is_day:idx',
                                                                    'is_in_shadow:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 13:45:26,919:INFO:Creating final display dataframe.
2023-10-24 13:45:27,383:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (32823, 46)
4        Transformed data shape  (32823, 62)
5   Transformed train set shape  (22976, 62)
6    Transformed test set shape   (9847, 62)
7              Numeric features           42
8          Categorical features            3
9      Rows with missing values        95.7%
10                   Preprocess         True
11              Imputation type       simple
12           Numeric imputation         mean
13       Categorical imputation         mode
14     Maximum one-hot encoding           25
15              Encoding method         None
16               Fold Generator        KFold
17                  Fold Number           10
18                     CPU Jobs           -1
19                      Use GPU        False
20               Log Experiment        False
21              Experiment Name        exp_B
22                          USI         6f41
2023-10-24 13:45:27,504:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 13:45:27,505:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 13:45:27,617:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 13:45:27,618:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 13:45:27,620:INFO:setup() successfully completed in 2.78s...............
2023-10-24 13:45:27,620:INFO:Initializing create_model()
2023-10-24 13:45:27,620:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff60423e880>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 13:45:27,620:INFO:Checking exceptions
2023-10-24 13:45:27,622:INFO:Importing libraries
2023-10-24 13:45:27,623:INFO:Copying training dataset
2023-10-24 13:45:27,641:INFO:Defining folds
2023-10-24 13:45:27,641:INFO:Declaring metric variables
2023-10-24 13:45:27,641:INFO:Importing untrained model
2023-10-24 13:45:27,642:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 13:45:27,642:INFO:Starting cross validation
2023-10-24 13:45:27,644:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 13:45:38,035:INFO:Calculating mean and std
2023-10-24 13:45:38,037:INFO:Creating metrics dataframe
2023-10-24 13:45:38,039:INFO:Finalizing model
2023-10-24 13:45:38,312:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004811 seconds.
2023-10-24 13:45:38,312:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:45:38,312:INFO:[LightGBM] [Info] Total Bins 7785
2023-10-24 13:45:38,313:INFO:[LightGBM] [Info] Number of data points in the train set: 22976, number of used features: 54
2023-10-24 13:45:38,313:INFO:[LightGBM] [Info] Start training from score 97.726333
2023-10-24 13:45:38,523:INFO:Uploading results into container
2023-10-24 13:45:38,524:INFO:Uploading model into container now
2023-10-24 13:45:38,529:INFO:_master_model_container: 1
2023-10-24 13:45:38,530:INFO:_display_container: 2
2023-10-24 13:45:38,530:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 13:45:38,530:INFO:create_model() successfully completed......................................
2023-10-24 13:45:38,623:INFO:Initializing tune_model()
2023-10-24 13:45:38,624:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff60423e880>)
2023-10-24 13:45:38,624:INFO:Checking exceptions
2023-10-24 13:45:38,634:INFO:Copying training dataset
2023-10-24 13:45:38,648:INFO:Checking base model
2023-10-24 13:45:38,648:INFO:Base model : Light Gradient Boosting Machine
2023-10-24 13:45:38,648:INFO:Declaring metric variables
2023-10-24 13:45:38,649:INFO:Defining Hyperparameters
2023-10-24 13:45:38,738:INFO:Tuning with n_jobs=-1
2023-10-24 13:45:38,738:INFO:Initializing RandomizedSearchCV
2023-10-24 13:48:58,276:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-24 13:48:58,278:INFO:Hyperparameter search completed
2023-10-24 13:48:58,278:INFO:SubProcess create_model() called ==================================
2023-10-24 13:48:58,279:INFO:Initializing create_model()
2023-10-24 13:48:58,279:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff60423e880>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff5eb296e20>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-24 13:48:58,280:INFO:Checking exceptions
2023-10-24 13:48:58,280:INFO:Importing libraries
2023-10-24 13:48:58,280:INFO:Copying training dataset
2023-10-24 13:48:58,306:INFO:Defining folds
2023-10-24 13:48:58,306:INFO:Declaring metric variables
2023-10-24 13:48:58,306:INFO:Importing untrained model
2023-10-24 13:48:58,306:INFO:Declaring custom model
2023-10-24 13:48:58,308:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 13:48:58,308:INFO:Starting cross validation
2023-10-24 13:48:58,310:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 13:49:40,171:INFO:Calculating mean and std
2023-10-24 13:49:40,172:INFO:Creating metrics dataframe
2023-10-24 13:49:40,175:INFO:Finalizing model
2023-10-24 13:49:40,400:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:49:40,401:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:49:40,401:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:49:40,442:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:49:40,443:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:49:40,443:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:49:40,450:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005132 seconds.
2023-10-24 13:49:40,450:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:49:40,452:INFO:[LightGBM] [Info] Total Bins 7783
2023-10-24 13:49:40,453:INFO:[LightGBM] [Info] Number of data points in the train set: 22976, number of used features: 53
2023-10-24 13:49:40,454:INFO:[LightGBM] [Info] Start training from score 97.726333
2023-10-24 13:49:41,294:INFO:Uploading results into container
2023-10-24 13:49:41,295:INFO:Uploading model into container now
2023-10-24 13:49:41,296:INFO:_master_model_container: 2
2023-10-24 13:49:41,297:INFO:_display_container: 3
2023-10-24 13:49:41,298:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-24 13:49:41,298:INFO:create_model() successfully completed......................................
2023-10-24 13:49:41,389:INFO:SubProcess create_model() end ==================================
2023-10-24 13:49:41,390:INFO:choose_better activated
2023-10-24 13:49:41,390:INFO:SubProcess create_model() called ==================================
2023-10-24 13:49:41,391:INFO:Initializing create_model()
2023-10-24 13:49:41,391:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff60423e880>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 13:49:41,391:INFO:Checking exceptions
2023-10-24 13:49:41,392:INFO:Importing libraries
2023-10-24 13:49:41,392:INFO:Copying training dataset
2023-10-24 13:49:41,409:INFO:Defining folds
2023-10-24 13:49:41,409:INFO:Declaring metric variables
2023-10-24 13:49:41,410:INFO:Importing untrained model
2023-10-24 13:49:41,410:INFO:Declaring custom model
2023-10-24 13:49:41,410:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 13:49:41,411:INFO:Starting cross validation
2023-10-24 13:49:41,412:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 13:49:50,498:INFO:Calculating mean and std
2023-10-24 13:49:50,499:INFO:Creating metrics dataframe
2023-10-24 13:49:50,501:INFO:Finalizing model
2023-10-24 13:49:50,775:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004176 seconds.
2023-10-24 13:49:50,775:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:49:50,775:INFO:[LightGBM] [Info] Total Bins 7785
2023-10-24 13:49:50,776:INFO:[LightGBM] [Info] Number of data points in the train set: 22976, number of used features: 54
2023-10-24 13:49:50,777:INFO:[LightGBM] [Info] Start training from score 97.726333
2023-10-24 13:49:50,970:INFO:Uploading results into container
2023-10-24 13:49:50,970:INFO:Uploading model into container now
2023-10-24 13:49:50,971:INFO:_master_model_container: 3
2023-10-24 13:49:50,971:INFO:_display_container: 4
2023-10-24 13:49:50,971:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 13:49:50,971:INFO:create_model() successfully completed......................................
2023-10-24 13:49:51,059:INFO:SubProcess create_model() end ==================================
2023-10-24 13:49:51,059:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8448
2023-10-24 13:49:51,060:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8493
2023-10-24 13:49:51,061:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) is best model
2023-10-24 13:49:51,061:INFO:choose_better completed
2023-10-24 13:49:51,065:INFO:_master_model_container: 3
2023-10-24 13:49:51,065:INFO:_display_container: 3
2023-10-24 13:49:51,066:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-24 13:49:51,066:INFO:tune_model() successfully completed......................................
2023-10-24 13:49:51,148:INFO:Initializing ensemble_model()
2023-10-24 13:49:51,148:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff60423e880>, estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-24 13:49:51,148:INFO:Checking exceptions
2023-10-24 13:49:51,158:INFO:Importing libraries
2023-10-24 13:49:51,158:INFO:Copying training dataset
2023-10-24 13:49:51,159:INFO:Checking base model
2023-10-24 13:49:51,159:INFO:Base model : Light Gradient Boosting Machine
2023-10-24 13:49:51,160:INFO:Importing untrained ensembler
2023-10-24 13:49:51,160:INFO:Ensemble method set to Bagging
2023-10-24 13:49:51,160:INFO:SubProcess create_model() called ==================================
2023-10-24 13:49:51,163:INFO:Initializing create_model()
2023-10-24 13:49:51,163:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff60423e880>, estimator=BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                                         feature_fraction=0.4,
                                         min_child_samples=41,
                                         min_split_gain=0.9, n_estimators=260,
                                         n_jobs=-1, num_leaves=70,
                                         random_state=123, reg_alpha=2,
                                         reg_lambda=3),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6037c1070>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 13:49:51,163:INFO:Checking exceptions
2023-10-24 13:49:51,163:INFO:Importing libraries
2023-10-24 13:49:51,163:INFO:Copying training dataset
2023-10-24 13:49:51,179:INFO:Defining folds
2023-10-24 13:49:51,179:INFO:Declaring metric variables
2023-10-24 13:49:51,179:INFO:Importing untrained model
2023-10-24 13:49:51,179:INFO:Declaring custom model
2023-10-24 13:49:51,181:INFO:Bagging Regressor Imported successfully
2023-10-24 13:49:51,181:INFO:Starting cross validation
2023-10-24 13:49:51,182:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 13:57:22,113:INFO:Calculating mean and std
2023-10-24 13:57:22,121:INFO:Creating metrics dataframe
2023-10-24 13:57:22,134:INFO:Finalizing model
2023-10-24 13:57:22,393:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:57:22,393:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:57:22,393:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:57:22,439:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:57:22,439:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:57:22,439:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:57:22,450:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006676 seconds.
2023-10-24 13:57:22,450:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:57:22,451:INFO:[LightGBM] [Info] Total Bins 7783
2023-10-24 13:57:22,454:INFO:[LightGBM] [Info] Number of data points in the train set: 22976, number of used features: 53
2023-10-24 13:57:22,457:INFO:[LightGBM] [Info] Start training from score 96.916183
2023-10-24 13:57:24,047:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:57:24,047:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:57:24,047:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:57:24,102:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:57:24,102:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:57:24,102:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:57:24,112:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006786 seconds.
2023-10-24 13:57:24,112:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:57:24,114:INFO:[LightGBM] [Info] Total Bins 7783
2023-10-24 13:57:24,116:INFO:[LightGBM] [Info] Number of data points in the train set: 22976, number of used features: 53
2023-10-24 13:57:24,117:INFO:[LightGBM] [Info] Start training from score 98.362982
2023-10-24 13:57:25,239:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:57:25,239:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:57:25,239:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:57:25,285:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:57:25,286:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:57:25,286:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:57:25,296:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006123 seconds.
2023-10-24 13:57:25,296:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:57:25,297:INFO:[LightGBM] [Info] Total Bins 7783
2023-10-24 13:57:25,299:INFO:[LightGBM] [Info] Number of data points in the train set: 22976, number of used features: 53
2023-10-24 13:57:25,300:INFO:[LightGBM] [Info] Start training from score 99.135759
2023-10-24 13:57:26,173:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:57:26,173:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:57:26,173:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:57:26,220:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:57:26,220:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:57:26,220:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:57:26,228:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005749 seconds.
2023-10-24 13:57:26,228:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:57:26,229:INFO:[LightGBM] [Info] Total Bins 7783
2023-10-24 13:57:26,231:INFO:[LightGBM] [Info] Number of data points in the train set: 22976, number of used features: 53
2023-10-24 13:57:26,232:INFO:[LightGBM] [Info] Start training from score 96.116652
2023-10-24 13:57:27,191:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:57:27,191:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:57:27,191:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:57:27,235:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:57:27,235:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:57:27,235:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:57:27,242:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004001 seconds.
2023-10-24 13:57:27,242:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:57:27,243:INFO:[LightGBM] [Info] Total Bins 7783
2023-10-24 13:57:27,244:INFO:[LightGBM] [Info] Number of data points in the train set: 22976, number of used features: 53
2023-10-24 13:57:27,245:INFO:[LightGBM] [Info] Start training from score 96.087856
2023-10-24 13:57:28,475:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:57:28,475:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:57:28,475:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:57:28,525:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:57:28,525:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:57:28,525:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:57:28,531:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003586 seconds.
2023-10-24 13:57:28,531:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:57:28,533:INFO:[LightGBM] [Info] Total Bins 7783
2023-10-24 13:57:28,534:INFO:[LightGBM] [Info] Number of data points in the train set: 22976, number of used features: 53
2023-10-24 13:57:28,535:INFO:[LightGBM] [Info] Start training from score 97.124739
2023-10-24 13:57:29,495:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:57:29,495:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:57:29,495:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:57:29,539:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:57:29,539:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:57:29,539:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:57:29,546:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004002 seconds.
2023-10-24 13:57:29,546:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:57:29,547:INFO:[LightGBM] [Info] Total Bins 7783
2023-10-24 13:57:29,549:INFO:[LightGBM] [Info] Number of data points in the train set: 22976, number of used features: 53
2023-10-24 13:57:29,550:INFO:[LightGBM] [Info] Start training from score 98.263794
2023-10-24 13:57:30,488:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:57:30,488:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:57:30,488:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:57:30,539:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:57:30,540:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:57:30,540:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:57:30,551:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007058 seconds.
2023-10-24 13:57:30,551:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:57:30,553:INFO:[LightGBM] [Info] Total Bins 7783
2023-10-24 13:57:30,555:INFO:[LightGBM] [Info] Number of data points in the train set: 22976, number of used features: 53
2023-10-24 13:57:30,557:INFO:[LightGBM] [Info] Start training from score 98.588858
2023-10-24 13:57:32,692:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:57:32,692:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:57:32,693:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:57:32,759:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:57:32,759:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:57:32,759:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:57:32,769:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006583 seconds.
2023-10-24 13:57:32,769:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:57:32,771:INFO:[LightGBM] [Info] Total Bins 7783
2023-10-24 13:57:32,774:INFO:[LightGBM] [Info] Number of data points in the train set: 22976, number of used features: 53
2023-10-24 13:57:32,775:INFO:[LightGBM] [Info] Start training from score 99.280716
2023-10-24 13:57:34,021:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:57:34,022:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:57:34,022:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:57:34,088:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:57:34,088:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:57:34,088:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:57:34,105:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010697 seconds.
2023-10-24 13:57:34,105:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:57:34,107:INFO:[LightGBM] [Info] Total Bins 7783
2023-10-24 13:57:34,109:INFO:[LightGBM] [Info] Number of data points in the train set: 22976, number of used features: 53
2023-10-24 13:57:34,111:INFO:[LightGBM] [Info] Start training from score 96.256244
2023-10-24 13:57:35,481:INFO:Uploading results into container
2023-10-24 13:57:35,483:INFO:Uploading model into container now
2023-10-24 13:57:35,486:INFO:_master_model_container: 4
2023-10-24 13:57:35,486:INFO:_display_container: 4
2023-10-24 13:57:35,489:INFO:BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                                         feature_fraction=0.4,
                                         min_child_samples=41,
                                         min_split_gain=0.9, n_estimators=260,
                                         n_jobs=-1, num_leaves=70,
                                         random_state=123, reg_alpha=2,
                                         reg_lambda=3),
                 random_state=123)
2023-10-24 13:57:35,489:INFO:create_model() successfully completed......................................
2023-10-24 13:57:35,936:INFO:SubProcess create_model() end ==================================
2023-10-24 13:57:35,944:INFO:_master_model_container: 4
2023-10-24 13:57:35,945:INFO:_display_container: 4
2023-10-24 13:57:35,951:INFO:BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                                         feature_fraction=0.4,
                                         min_child_samples=41,
                                         min_split_gain=0.9, n_estimators=260,
                                         n_jobs=-1, num_leaves=70,
                                         random_state=123, reg_alpha=2,
                                         reg_lambda=3),
                 random_state=123)
2023-10-24 13:57:35,952:INFO:ensemble_model() successfully completed......................................
2023-10-24 13:57:36,074:INFO:Initializing finalize_model()
2023-10-24 13:57:36,074:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff60423e880>, estimator=BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                                         feature_fraction=0.4,
                                         min_child_samples=41,
                                         min_split_gain=0.9, n_estimators=260,
                                         n_jobs=-1, num_leaves=70,
                                         random_state=123, reg_alpha=2,
                                         reg_lambda=3),
                 random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-24 13:57:36,076:INFO:Finalizing BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                                         feature_fraction=0.4,
                                         min_child_samples=41,
                                         min_split_gain=0.9, n_estimators=260,
                                         n_jobs=-1, num_leaves=70,
                                         random_state=123, reg_alpha=2,
                                         reg_lambda=3),
                 random_state=123)
2023-10-24 13:57:36,107:INFO:Initializing create_model()
2023-10-24 13:57:36,107:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff60423e880>, estimator=BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                                         feature_fraction=0.4,
                                         min_child_samples=41,
                                         min_split_gain=0.9, n_estimators=260,
                                         n_jobs=-1, num_leaves=70,
                                         random_state=123, reg_alpha=2,
                                         reg_lambda=3),
                 random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-24 13:57:36,107:INFO:Checking exceptions
2023-10-24 13:57:36,108:INFO:Importing libraries
2023-10-24 13:57:36,108:INFO:Copying training dataset
2023-10-24 13:57:36,109:INFO:Defining folds
2023-10-24 13:57:36,110:INFO:Declaring metric variables
2023-10-24 13:57:36,110:INFO:Importing untrained model
2023-10-24 13:57:36,110:INFO:Declaring custom model
2023-10-24 13:57:36,111:INFO:Bagging Regressor Imported successfully
2023-10-24 13:57:36,112:INFO:Cross validation set to False
2023-10-24 13:57:36,113:INFO:Fitting Model
2023-10-24 13:57:36,431:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:57:36,431:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:57:36,431:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:57:36,495:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:57:36,495:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:57:36,495:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:57:36,504:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005979 seconds.
2023-10-24 13:57:36,504:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:57:36,505:INFO:[LightGBM] [Info] Total Bins 7880
2023-10-24 13:57:36,507:INFO:[LightGBM] [Info] Number of data points in the train set: 32823, number of used features: 54
2023-10-24 13:57:36,509:INFO:[LightGBM] [Info] Start training from score 93.825920
2023-10-24 13:57:37,398:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:57:37,398:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:57:37,398:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:57:37,461:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:57:37,461:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:57:37,461:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:57:37,471:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006200 seconds.
2023-10-24 13:57:37,471:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:57:37,471:INFO:[LightGBM] [Info] Total Bins 7880
2023-10-24 13:57:37,473:INFO:[LightGBM] [Info] Number of data points in the train set: 32823, number of used features: 54
2023-10-24 13:57:37,474:INFO:[LightGBM] [Info] Start training from score 96.688231
2023-10-24 13:57:38,465:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:57:38,465:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:57:38,465:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:57:38,529:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:57:38,530:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:57:38,530:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:57:38,539:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001872 seconds.
2023-10-24 13:57:38,540:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 13:57:38,540:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 13:57:38,540:INFO:[LightGBM] [Info] Total Bins 7880
2023-10-24 13:57:38,542:INFO:[LightGBM] [Info] Number of data points in the train set: 32823, number of used features: 54
2023-10-24 13:57:38,543:INFO:[LightGBM] [Info] Start training from score 96.871196
2023-10-24 13:57:39,733:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:57:39,733:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:57:39,733:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:57:39,799:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:57:39,799:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:57:39,799:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:57:39,808:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001747 seconds.
2023-10-24 13:57:39,808:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 13:57:39,809:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 13:57:39,809:INFO:[LightGBM] [Info] Total Bins 7880
2023-10-24 13:57:39,810:INFO:[LightGBM] [Info] Number of data points in the train set: 32823, number of used features: 54
2023-10-24 13:57:39,811:INFO:[LightGBM] [Info] Start training from score 96.707576
2023-10-24 13:57:41,080:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:57:41,080:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:57:41,080:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:57:41,147:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:57:41,147:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:57:41,147:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:57:41,155:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001506 seconds.
2023-10-24 13:57:41,155:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 13:57:41,156:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 13:57:41,156:INFO:[LightGBM] [Info] Total Bins 7880
2023-10-24 13:57:41,157:INFO:[LightGBM] [Info] Number of data points in the train set: 32823, number of used features: 54
2023-10-24 13:57:41,159:INFO:[LightGBM] [Info] Start training from score 95.812279
2023-10-24 13:57:42,228:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:57:42,229:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:57:42,229:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:57:42,293:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:57:42,294:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:57:42,294:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:57:42,305:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001800 seconds.
2023-10-24 13:57:42,305:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 13:57:42,305:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 13:57:42,306:INFO:[LightGBM] [Info] Total Bins 7880
2023-10-24 13:57:42,308:INFO:[LightGBM] [Info] Number of data points in the train set: 32823, number of used features: 54
2023-10-24 13:57:42,310:INFO:[LightGBM] [Info] Start training from score 97.305582
2023-10-24 13:57:43,551:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:57:43,552:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:57:43,552:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:57:43,616:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:57:43,616:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:57:43,616:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:57:43,627:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007021 seconds.
2023-10-24 13:57:43,627:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:57:43,628:INFO:[LightGBM] [Info] Total Bins 7880
2023-10-24 13:57:43,630:INFO:[LightGBM] [Info] Number of data points in the train set: 32823, number of used features: 54
2023-10-24 13:57:43,632:INFO:[LightGBM] [Info] Start training from score 97.788672
2023-10-24 13:57:44,597:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:57:44,597:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:57:44,597:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:57:44,663:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:57:44,663:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:57:44,663:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:57:44,673:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006436 seconds.
2023-10-24 13:57:44,673:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:57:44,674:INFO:[LightGBM] [Info] Total Bins 7880
2023-10-24 13:57:44,676:INFO:[LightGBM] [Info] Number of data points in the train set: 32823, number of used features: 54
2023-10-24 13:57:44,677:INFO:[LightGBM] [Info] Start training from score 97.461131
2023-10-24 13:57:45,601:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:57:45,601:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:57:45,602:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:57:45,667:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:57:45,668:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:57:45,668:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:57:45,678:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001513 seconds.
2023-10-24 13:57:45,678:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 13:57:45,678:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 13:57:45,678:INFO:[LightGBM] [Info] Total Bins 7880
2023-10-24 13:57:45,680:INFO:[LightGBM] [Info] Number of data points in the train set: 32823, number of used features: 54
2023-10-24 13:57:45,681:INFO:[LightGBM] [Info] Start training from score 98.387361
2023-10-24 13:57:46,885:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:57:46,886:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:57:46,886:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:57:46,950:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 13:57:46,951:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 13:57:46,951:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 13:57:46,961:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006452 seconds.
2023-10-24 13:57:46,961:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:57:46,962:INFO:[LightGBM] [Info] Total Bins 7880
2023-10-24 13:57:46,964:INFO:[LightGBM] [Info] Number of data points in the train set: 32823, number of used features: 54
2023-10-24 13:57:46,965:INFO:[LightGBM] [Info] Start training from score 94.002376
2023-10-24 13:57:48,281:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6,
                                                          bagging_freq=2,
                                                          feature_fraction=0.4,
                                                          min_child_samples=41,
                                                          min_split_gain=0.9,
                                                          n_estimators=260,
                                                          n_jobs=-1,
                                                          num_leaves=70,
                                                          random_state=123,
                                                          reg_alpha=2,
                                                          reg_lambda=3),
                                  random_state=123))])
2023-10-24 13:57:48,282:INFO:create_model() successfully completed......................................
2023-10-24 13:57:48,416:INFO:_master_model_container: 4
2023-10-24 13:57:48,417:INFO:_display_container: 4
2023-10-24 13:57:48,437:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6,
                                                          bagging_freq=2,
                                                          feature_fraction=0.4,
                                                          min_child_samples=41,
                                                          min_split_gain=0.9,
                                                          n_estimators=260,
                                                          n_jobs=-1,
                                                          num_leaves=70,
                                                          random_state=123,
                                                          reg_alpha=2,
                                                          reg_lambda=3),
                                  random_state=123))])
2023-10-24 13:57:48,437:INFO:finalize_model() successfully completed......................................
2023-10-24 13:57:48,543:INFO:Initializing save_model()
2023-10-24 13:57:48,543:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6,
                                                          bagging_freq=2,
                                                          feature_fraction=0.4,
                                                          min_child_samples=41,
                                                          min_split_gain=0.9,
                                                          n_estimators=260,
                                                          n_jobs=-1,
                                                          num_leaves=70,
                                                          random_state=123,
                                                          reg_alpha=2,
                                                          reg_lambda=3),
                                  random_state=123))]), model_name=final_model_for_location_B, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             '...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx', 'is_day:idx',
                                             'is_in_shadow:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx',
                                                                    'is_day:idx',
                                                                    'is_in_shadow:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-24 13:57:48,543:INFO:Adding model into prep_pipe
2023-10-24 13:57:48,543:WARNING:Only Model saved as it was a pipeline.
2023-10-24 13:57:48,892:INFO:final_model_for_location_B.pkl saved in current working directory
2023-10-24 13:57:48,917:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6,
                                                          bagging_freq=2,
                                                          feature_fraction=0.4,
                                                          min_child_samples=41,
                                                          min_split_gain=0.9,
                                                          n_estimators=260,
                                                          n_jobs=-1,
                                                          num_leaves=70,
                                                          random_state=123,
                                                          reg_alpha=2,
                                                          reg_lambda=3),
                                  random_state=123))])
2023-10-24 13:57:48,917:INFO:save_model() successfully completed......................................
2023-10-24 13:57:49,230:WARNING:<ipython-input-13-49df83f3379d>:13: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  estimated_resampled = estimated.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 13:57:49,236:WARNING:<ipython-input-13-49df83f3379d>:14: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  test_resampled = test.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 13:57:49,300:INFO:PyCaret RegressionExperiment
2023-10-24 13:57:49,300:INFO:Logging name: exp_C
2023-10-24 13:57:49,300:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 13:57:49,300:INFO:version 3.1.0
2023-10-24 13:57:49,300:INFO:Initializing setup()
2023-10-24 13:57:49,300:INFO:self.USI: 6d3a
2023-10-24 13:57:49,300:INFO:self._variable_keys: {'y_test', 'n_jobs_param', 'exp_id', 'gpu_param', 'idx', '_available_plots', 'html_param', 'X_train', 'target_param', 'transform_target_param', 'logging_param', 'seed', 'y_train', 'log_plots_param', 'y', '_ml_usecase', 'X', 'fold_generator', 'X_test', 'exp_name_log', 'pipeline', 'fold_groups_param', 'data', 'USI', 'fold_shuffle_param', 'memory', 'gpu_n_jobs_param'}
2023-10-24 13:57:49,300:INFO:Checking environment
2023-10-24 13:57:49,300:INFO:python_version: 3.8.5
2023-10-24 13:57:49,300:INFO:python_build: ('default', 'Sep  4 2020 02:22:02')
2023-10-24 13:57:49,300:INFO:machine: x86_64
2023-10-24 13:57:49,300:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-10-24 13:57:49,300:INFO:Memory: svmem(total=8589934592, available=2511687680, percent=70.8, used=4825829376, free=461455360, active=2053107712, inactive=2031144960, wired=2772721664)
2023-10-24 13:57:49,301:INFO:Physical Core: 4
2023-10-24 13:57:49,301:INFO:Logical Core: 8
2023-10-24 13:57:49,301:INFO:Checking libraries
2023-10-24 13:57:49,301:INFO:System:
2023-10-24 13:57:49,301:INFO:    python: 3.8.5 (default, Sep  4 2020, 02:22:02)  [Clang 10.0.0 ]
2023-10-24 13:57:49,301:INFO:executable: /Users/kaja/opt/anaconda3/bin/python
2023-10-24 13:57:49,301:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-10-24 13:57:49,301:INFO:PyCaret required dependencies:
2023-10-24 13:57:49,301:INFO:                 pip: 23.3.1
2023-10-24 13:57:49,302:INFO:          setuptools: 68.2.2
2023-10-24 13:57:49,302:INFO:             pycaret: 3.1.0
2023-10-24 13:57:49,302:INFO:             IPython: 7.19.0
2023-10-24 13:57:49,302:INFO:          ipywidgets: 8.1.1
2023-10-24 13:57:49,302:INFO:                tqdm: 4.66.1
2023-10-24 13:57:49,302:INFO:               numpy: 1.23.5
2023-10-24 13:57:49,302:INFO:              pandas: 1.5.3
2023-10-24 13:57:49,302:INFO:              jinja2: 3.1.2
2023-10-24 13:57:49,302:INFO:               scipy: 1.10.1
2023-10-24 13:57:49,302:INFO:              joblib: 1.3.2
2023-10-24 13:57:49,302:INFO:             sklearn: 1.2.2
2023-10-24 13:57:49,302:INFO:                pyod: 1.1.0
2023-10-24 13:57:49,302:INFO:            imblearn: 0.11.0
2023-10-24 13:57:49,302:INFO:   category_encoders: 2.6.2
2023-10-24 13:57:49,302:INFO:            lightgbm: 4.1.0
2023-10-24 13:57:49,302:INFO:               numba: 0.58.1
2023-10-24 13:57:49,302:INFO:            requests: 2.28.2
2023-10-24 13:57:49,302:INFO:          matplotlib: 3.7.3
2023-10-24 13:57:49,303:INFO:          scikitplot: 0.3.7
2023-10-24 13:57:49,303:INFO:         yellowbrick: 1.5
2023-10-24 13:57:49,303:INFO:              plotly: 5.17.0
2023-10-24 13:57:49,303:INFO:    plotly-resampler: Not installed
2023-10-24 13:57:49,303:INFO:             kaleido: 0.2.1
2023-10-24 13:57:49,303:INFO:           schemdraw: 0.15
2023-10-24 13:57:49,303:INFO:         statsmodels: 0.14.0
2023-10-24 13:57:49,303:INFO:              sktime: 0.21.1
2023-10-24 13:57:49,303:INFO:               tbats: 1.1.3
2023-10-24 13:57:49,303:INFO:            pmdarima: 2.0.4
2023-10-24 13:57:49,303:INFO:              psutil: 5.9.6
2023-10-24 13:57:49,303:INFO:          markupsafe: 2.1.2
2023-10-24 13:57:49,303:INFO:             pickle5: Not installed
2023-10-24 13:57:49,303:INFO:         cloudpickle: 1.6.0
2023-10-24 13:57:49,303:INFO:         deprecation: 2.1.0
2023-10-24 13:57:49,303:INFO:              xxhash: 3.4.1
2023-10-24 13:57:49,303:INFO:           wurlitzer: 2.0.1
2023-10-24 13:57:49,303:INFO:PyCaret optional dependencies:
2023-10-24 13:57:49,303:INFO:                shap: Not installed
2023-10-24 13:57:49,303:INFO:           interpret: Not installed
2023-10-24 13:57:49,303:INFO:                umap: Not installed
2023-10-24 13:57:49,303:INFO:     ydata_profiling: Not installed
2023-10-24 13:57:49,303:INFO:  explainerdashboard: Not installed
2023-10-24 13:57:49,303:INFO:             autoviz: Not installed
2023-10-24 13:57:49,303:INFO:           fairlearn: Not installed
2023-10-24 13:57:49,303:INFO:          deepchecks: Not installed
2023-10-24 13:57:49,303:INFO:             xgboost: Not installed
2023-10-24 13:57:49,304:INFO:            catboost: 1.0.4
2023-10-24 13:57:49,304:INFO:              kmodes: Not installed
2023-10-24 13:57:49,304:INFO:             mlxtend: Not installed
2023-10-24 13:57:49,304:INFO:       statsforecast: Not installed
2023-10-24 13:57:49,304:INFO:        tune_sklearn: Not installed
2023-10-24 13:57:49,304:INFO:                 ray: Not installed
2023-10-24 13:57:49,304:INFO:            hyperopt: Not installed
2023-10-24 13:57:49,304:INFO:              optuna: Not installed
2023-10-24 13:57:49,304:INFO:               skopt: Not installed
2023-10-24 13:57:49,304:INFO:              mlflow: 2.7.1
2023-10-24 13:57:49,304:INFO:              gradio: Not installed
2023-10-24 13:57:49,304:INFO:             fastapi: Not installed
2023-10-24 13:57:49,304:INFO:             uvicorn: Not installed
2023-10-24 13:57:49,304:INFO:              m2cgen: Not installed
2023-10-24 13:57:49,304:INFO:           evidently: Not installed
2023-10-24 13:57:49,304:INFO:               fugue: Not installed
2023-10-24 13:57:49,304:INFO:           streamlit: Not installed
2023-10-24 13:57:49,304:INFO:             prophet: Not installed
2023-10-24 13:57:49,304:INFO:None
2023-10-24 13:57:49,304:INFO:Set up data.
2023-10-24 13:57:49,351:INFO:Set up folding strategy.
2023-10-24 13:57:49,351:INFO:Set up train/test split.
2023-10-24 13:57:49,378:INFO:Set up index.
2023-10-24 13:57:49,380:INFO:Assigning column types.
2023-10-24 13:57:49,391:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 13:57:49,391:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 13:57:49,396:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 13:57:49,401:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 13:57:49,471:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 13:57:49,518:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 13:57:49,519:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 13:57:49,519:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 13:57:49,520:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 13:57:49,524:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 13:57:49,530:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 13:57:49,595:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 13:57:49,643:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 13:57:49,643:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 13:57:49,644:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 13:57:49,644:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 13:57:49,649:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 13:57:49,654:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 13:57:49,719:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 13:57:49,767:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 13:57:49,768:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 13:57:49,768:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 13:57:49,773:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 13:57:49,777:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 13:57:49,840:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 13:57:49,884:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 13:57:49,885:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 13:57:49,885:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 13:57:49,886:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 13:57:49,895:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 13:57:49,958:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 13:57:50,002:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 13:57:50,003:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 13:57:50,003:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 13:57:50,013:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 13:57:50,083:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 13:57:50,136:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 13:57:50,152:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 13:57:50,152:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 13:57:50,153:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 13:57:50,234:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 13:57:50,279:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 13:57:50,280:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 13:57:50,280:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 13:57:50,349:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 13:57:50,391:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 13:57:50,392:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 13:57:50,392:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 13:57:50,393:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 13:57:50,465:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 13:57:50,514:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 13:57:50,514:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 13:57:50,586:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 13:57:50,629:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 13:57:50,629:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 13:57:50,630:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 13:57:50,743:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 13:57:50,744:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 13:57:50,862:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 13:57:50,862:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 13:57:50,863:INFO:Preparing preprocessing pipeline...
2023-10-24 13:57:50,863:INFO:Set up simple imputation.
2023-10-24 13:57:50,870:INFO:Set up encoding of categorical features.
2023-10-24 13:57:50,872:INFO:Set up column name cleaning.
2023-10-24 13:57:51,148:INFO:Finished creating preprocessing pipeline.
2023-10-24 13:57:51,158:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             '...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx', 'is_day:idx',
                                             'is_in_shadow:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx',
                                                                    'is_day:idx',
                                                                    'is_in_shadow:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 13:57:51,158:INFO:Creating final display dataframe.
2023-10-24 13:57:51,660:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (32130, 46)
4        Transformed data shape  (32130, 62)
5   Transformed train set shape  (22491, 62)
6    Transformed test set shape   (9639, 62)
7              Numeric features           42
8          Categorical features            3
9      Rows with missing values        93.5%
10                   Preprocess         True
11              Imputation type       simple
12           Numeric imputation         mean
13       Categorical imputation         mode
14     Maximum one-hot encoding           25
15              Encoding method         None
16               Fold Generator        KFold
17                  Fold Number           10
18                     CPU Jobs           -1
19                      Use GPU        False
20               Log Experiment        False
21              Experiment Name        exp_C
22                          USI         6d3a
2023-10-24 13:57:51,785:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 13:57:51,786:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 13:57:51,900:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 13:57:51,901:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 13:57:51,901:INFO:setup() successfully completed in 2.61s...............
2023-10-24 13:57:51,902:INFO:Initializing create_model()
2023-10-24 13:57:51,902:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff5ebca3670>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 13:57:51,902:INFO:Checking exceptions
2023-10-24 13:57:51,904:INFO:Importing libraries
2023-10-24 13:57:51,904:INFO:Copying training dataset
2023-10-24 13:57:51,922:INFO:Defining folds
2023-10-24 13:57:51,922:INFO:Declaring metric variables
2023-10-24 13:57:51,923:INFO:Importing untrained model
2023-10-24 13:57:51,923:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 13:57:51,923:INFO:Starting cross validation
2023-10-24 13:57:51,925:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 13:58:01,600:INFO:Calculating mean and std
2023-10-24 13:58:01,601:INFO:Creating metrics dataframe
2023-10-24 13:58:01,604:INFO:Finalizing model
2023-10-24 13:58:01,882:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006271 seconds.
2023-10-24 13:58:01,882:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 13:58:01,882:INFO:[LightGBM] [Info] Total Bins 8210
2023-10-24 13:58:01,883:INFO:[LightGBM] [Info] Number of data points in the train set: 22491, number of used features: 58
2023-10-24 13:58:01,883:INFO:[LightGBM] [Info] Start training from score 62.727538
2023-10-24 13:58:02,095:INFO:Uploading results into container
2023-10-24 13:58:02,096:INFO:Uploading model into container now
2023-10-24 13:58:02,102:INFO:_master_model_container: 1
2023-10-24 13:58:02,102:INFO:_display_container: 2
2023-10-24 13:58:02,102:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 13:58:02,103:INFO:create_model() successfully completed......................................
2023-10-24 13:58:02,196:INFO:Initializing tune_model()
2023-10-24 13:58:02,196:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff5ebca3670>)
2023-10-24 13:58:02,197:INFO:Checking exceptions
2023-10-24 13:58:02,207:INFO:Copying training dataset
2023-10-24 13:58:02,221:INFO:Checking base model
2023-10-24 13:58:02,221:INFO:Base model : Light Gradient Boosting Machine
2023-10-24 13:58:02,222:INFO:Declaring metric variables
2023-10-24 13:58:02,222:INFO:Defining Hyperparameters
2023-10-24 13:58:02,321:INFO:Tuning with n_jobs=-1
2023-10-24 13:58:02,321:INFO:Initializing RandomizedSearchCV
2023-10-24 14:01:27,186:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-24 14:01:27,188:INFO:Hyperparameter search completed
2023-10-24 14:01:27,188:INFO:SubProcess create_model() called ==================================
2023-10-24 14:01:27,189:INFO:Initializing create_model()
2023-10-24 14:01:27,189:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff5ebca3670>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff5e9a67b80>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-24 14:01:27,189:INFO:Checking exceptions
2023-10-24 14:01:27,190:INFO:Importing libraries
2023-10-24 14:01:27,190:INFO:Copying training dataset
2023-10-24 14:01:27,215:INFO:Defining folds
2023-10-24 14:01:27,215:INFO:Declaring metric variables
2023-10-24 14:01:27,215:INFO:Importing untrained model
2023-10-24 14:01:27,215:INFO:Declaring custom model
2023-10-24 14:01:27,217:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 14:01:27,217:INFO:Starting cross validation
2023-10-24 14:01:27,219:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 14:02:16,552:INFO:Calculating mean and std
2023-10-24 14:02:16,555:INFO:Creating metrics dataframe
2023-10-24 14:02:16,561:INFO:Finalizing model
2023-10-24 14:02:16,792:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:02:16,792:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:02:16,792:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:02:16,842:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:02:16,842:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:02:16,842:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:02:16,849:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003895 seconds.
2023-10-24 14:02:16,849:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:02:16,851:INFO:[LightGBM] [Info] Total Bins 8210
2023-10-24 14:02:16,853:INFO:[LightGBM] [Info] Number of data points in the train set: 22491, number of used features: 58
2023-10-24 14:02:16,854:INFO:[LightGBM] [Info] Start training from score 62.727538
2023-10-24 14:02:17,830:INFO:Uploading results into container
2023-10-24 14:02:17,831:INFO:Uploading model into container now
2023-10-24 14:02:17,833:INFO:_master_model_container: 2
2023-10-24 14:02:17,833:INFO:_display_container: 3
2023-10-24 14:02:17,834:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-24 14:02:17,834:INFO:create_model() successfully completed......................................
2023-10-24 14:02:18,143:INFO:SubProcess create_model() end ==================================
2023-10-24 14:02:18,143:INFO:choose_better activated
2023-10-24 14:02:18,144:INFO:SubProcess create_model() called ==================================
2023-10-24 14:02:18,145:INFO:Initializing create_model()
2023-10-24 14:02:18,145:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff5ebca3670>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 14:02:18,145:INFO:Checking exceptions
2023-10-24 14:02:18,148:INFO:Importing libraries
2023-10-24 14:02:18,148:INFO:Copying training dataset
2023-10-24 14:02:18,174:INFO:Defining folds
2023-10-24 14:02:18,175:INFO:Declaring metric variables
2023-10-24 14:02:18,175:INFO:Importing untrained model
2023-10-24 14:02:18,175:INFO:Declaring custom model
2023-10-24 14:02:18,176:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 14:02:18,176:INFO:Starting cross validation
2023-10-24 14:02:18,177:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 14:02:28,872:INFO:Calculating mean and std
2023-10-24 14:02:28,873:INFO:Creating metrics dataframe
2023-10-24 14:02:28,876:INFO:Finalizing model
2023-10-24 14:02:29,154:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004737 seconds.
2023-10-24 14:02:29,154:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:02:29,154:INFO:[LightGBM] [Info] Total Bins 8210
2023-10-24 14:02:29,155:INFO:[LightGBM] [Info] Number of data points in the train set: 22491, number of used features: 58
2023-10-24 14:02:29,156:INFO:[LightGBM] [Info] Start training from score 62.727538
2023-10-24 14:02:29,372:INFO:Uploading results into container
2023-10-24 14:02:29,373:INFO:Uploading model into container now
2023-10-24 14:02:29,373:INFO:_master_model_container: 3
2023-10-24 14:02:29,373:INFO:_display_container: 4
2023-10-24 14:02:29,374:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 14:02:29,374:INFO:create_model() successfully completed......................................
2023-10-24 14:02:29,458:INFO:SubProcess create_model() end ==================================
2023-10-24 14:02:29,459:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8255
2023-10-24 14:02:29,460:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8197
2023-10-24 14:02:29,460:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-24 14:02:29,460:INFO:choose_better completed
2023-10-24 14:02:29,460:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-24 14:02:29,465:INFO:_master_model_container: 3
2023-10-24 14:02:29,466:INFO:_display_container: 3
2023-10-24 14:02:29,466:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 14:02:29,466:INFO:tune_model() successfully completed......................................
2023-10-24 14:02:29,549:INFO:Initializing ensemble_model()
2023-10-24 14:02:29,549:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff5ebca3670>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-24 14:02:29,549:INFO:Checking exceptions
2023-10-24 14:02:29,565:INFO:Importing libraries
2023-10-24 14:02:29,565:INFO:Copying training dataset
2023-10-24 14:02:29,565:INFO:Checking base model
2023-10-24 14:02:29,565:INFO:Base model : Light Gradient Boosting Machine
2023-10-24 14:02:29,566:INFO:Importing untrained ensembler
2023-10-24 14:02:29,566:INFO:Ensemble method set to Bagging
2023-10-24 14:02:29,566:INFO:SubProcess create_model() called ==================================
2023-10-24 14:02:29,567:INFO:Initializing create_model()
2023-10-24 14:02:29,568:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff5ebca3670>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff5fc7e8b80>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 14:02:29,568:INFO:Checking exceptions
2023-10-24 14:02:29,568:INFO:Importing libraries
2023-10-24 14:02:29,568:INFO:Copying training dataset
2023-10-24 14:02:29,583:INFO:Defining folds
2023-10-24 14:02:29,583:INFO:Declaring metric variables
2023-10-24 14:02:29,583:INFO:Importing untrained model
2023-10-24 14:02:29,583:INFO:Declaring custom model
2023-10-24 14:02:29,585:INFO:Bagging Regressor Imported successfully
2023-10-24 14:02:29,585:INFO:Starting cross validation
2023-10-24 14:02:29,586:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 14:04:08,333:INFO:Calculating mean and std
2023-10-24 14:04:08,342:INFO:Creating metrics dataframe
2023-10-24 14:04:08,352:INFO:Finalizing model
2023-10-24 14:04:08,645:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004198 seconds.
2023-10-24 14:04:08,646:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:04:08,646:INFO:[LightGBM] [Info] Total Bins 8210
2023-10-24 14:04:08,646:INFO:[LightGBM] [Info] Number of data points in the train set: 22491, number of used features: 58
2023-10-24 14:04:08,647:INFO:[LightGBM] [Info] Start training from score 61.741961
2023-10-24 14:04:08,914:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004949 seconds.
2023-10-24 14:04:08,915:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:04:08,915:INFO:[LightGBM] [Info] Total Bins 8210
2023-10-24 14:04:08,916:INFO:[LightGBM] [Info] Number of data points in the train set: 22491, number of used features: 58
2023-10-24 14:04:08,916:INFO:[LightGBM] [Info] Start training from score 63.170501
2023-10-24 14:04:09,196:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004325 seconds.
2023-10-24 14:04:09,196:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:04:09,197:INFO:[LightGBM] [Info] Total Bins 8210
2023-10-24 14:04:09,198:INFO:[LightGBM] [Info] Number of data points in the train set: 22491, number of used features: 58
2023-10-24 14:04:09,198:INFO:[LightGBM] [Info] Start training from score 61.042905
2023-10-24 14:04:09,507:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004941 seconds.
2023-10-24 14:04:09,507:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:04:09,507:INFO:[LightGBM] [Info] Total Bins 8210
2023-10-24 14:04:09,508:INFO:[LightGBM] [Info] Number of data points in the train set: 22491, number of used features: 58
2023-10-24 14:04:09,508:INFO:[LightGBM] [Info] Start training from score 62.329201
2023-10-24 14:04:09,779:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006490 seconds.
2023-10-24 14:04:09,780:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:04:09,780:INFO:[LightGBM] [Info] Total Bins 8210
2023-10-24 14:04:09,781:INFO:[LightGBM] [Info] Number of data points in the train set: 22491, number of used features: 58
2023-10-24 14:04:09,781:INFO:[LightGBM] [Info] Start training from score 62.383617
2023-10-24 14:04:10,074:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004636 seconds.
2023-10-24 14:04:10,074:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:04:10,074:INFO:[LightGBM] [Info] Total Bins 8210
2023-10-24 14:04:10,075:INFO:[LightGBM] [Info] Number of data points in the train set: 22491, number of used features: 58
2023-10-24 14:04:10,075:INFO:[LightGBM] [Info] Start training from score 62.497792
2023-10-24 14:04:10,361:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004881 seconds.
2023-10-24 14:04:10,361:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:04:10,361:INFO:[LightGBM] [Info] Total Bins 8210
2023-10-24 14:04:10,362:INFO:[LightGBM] [Info] Number of data points in the train set: 22491, number of used features: 58
2023-10-24 14:04:10,362:INFO:[LightGBM] [Info] Start training from score 63.218627
2023-10-24 14:04:10,664:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005422 seconds.
2023-10-24 14:04:10,664:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:04:10,664:INFO:[LightGBM] [Info] Total Bins 8210
2023-10-24 14:04:10,665:INFO:[LightGBM] [Info] Number of data points in the train set: 22491, number of used features: 58
2023-10-24 14:04:10,666:INFO:[LightGBM] [Info] Start training from score 65.127161
2023-10-24 14:04:10,945:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004559 seconds.
2023-10-24 14:04:10,945:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:04:10,945:INFO:[LightGBM] [Info] Total Bins 8210
2023-10-24 14:04:10,946:INFO:[LightGBM] [Info] Number of data points in the train set: 22491, number of used features: 58
2023-10-24 14:04:10,947:INFO:[LightGBM] [Info] Start training from score 63.463028
2023-10-24 14:04:11,204:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006198 seconds.
2023-10-24 14:04:11,204:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:04:11,204:INFO:[LightGBM] [Info] Total Bins 8210
2023-10-24 14:04:11,205:INFO:[LightGBM] [Info] Number of data points in the train set: 22491, number of used features: 58
2023-10-24 14:04:11,206:INFO:[LightGBM] [Info] Start training from score 61.089317
2023-10-24 14:04:11,410:INFO:Uploading results into container
2023-10-24 14:04:11,411:INFO:Uploading model into container now
2023-10-24 14:04:11,412:INFO:_master_model_container: 4
2023-10-24 14:04:11,413:INFO:_display_container: 4
2023-10-24 14:04:11,414:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-24 14:04:11,415:INFO:create_model() successfully completed......................................
2023-10-24 14:04:11,514:INFO:SubProcess create_model() end ==================================
2023-10-24 14:04:11,518:INFO:_master_model_container: 4
2023-10-24 14:04:11,519:INFO:_display_container: 4
2023-10-24 14:04:11,520:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-24 14:04:11,520:INFO:ensemble_model() successfully completed......................................
2023-10-24 14:04:11,604:INFO:Initializing finalize_model()
2023-10-24 14:04:11,604:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff5ebca3670>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-24 14:04:11,605:INFO:Finalizing BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-24 14:04:11,622:INFO:Initializing create_model()
2023-10-24 14:04:11,622:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff5ebca3670>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-24 14:04:11,622:INFO:Checking exceptions
2023-10-24 14:04:11,623:INFO:Importing libraries
2023-10-24 14:04:11,623:INFO:Copying training dataset
2023-10-24 14:04:11,624:INFO:Defining folds
2023-10-24 14:04:11,624:INFO:Declaring metric variables
2023-10-24 14:04:11,624:INFO:Importing untrained model
2023-10-24 14:04:11,624:INFO:Declaring custom model
2023-10-24 14:04:11,625:INFO:Bagging Regressor Imported successfully
2023-10-24 14:04:11,627:INFO:Cross validation set to False
2023-10-24 14:04:11,627:INFO:Fitting Model
2023-10-24 14:04:11,995:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008178 seconds.
2023-10-24 14:04:11,995:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:04:11,996:INFO:[LightGBM] [Info] Total Bins 8286
2023-10-24 14:04:11,996:INFO:[LightGBM] [Info] Number of data points in the train set: 32130, number of used features: 58
2023-10-24 14:04:11,997:INFO:[LightGBM] [Info] Start training from score 62.422218
2023-10-24 14:04:12,320:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006254 seconds.
2023-10-24 14:04:12,320:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:04:12,320:INFO:[LightGBM] [Info] Total Bins 8286
2023-10-24 14:04:12,321:INFO:[LightGBM] [Info] Number of data points in the train set: 32130, number of used features: 58
2023-10-24 14:04:12,321:INFO:[LightGBM] [Info] Start training from score 63.730349
2023-10-24 14:04:12,645:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003085 seconds.
2023-10-24 14:04:12,645:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:04:12,645:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:04:12,646:INFO:[LightGBM] [Info] Total Bins 8286
2023-10-24 14:04:12,646:INFO:[LightGBM] [Info] Number of data points in the train set: 32130, number of used features: 58
2023-10-24 14:04:12,647:INFO:[LightGBM] [Info] Start training from score 62.003611
2023-10-24 14:04:13,004:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006925 seconds.
2023-10-24 14:04:13,004:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:04:13,004:INFO:[LightGBM] [Info] Total Bins 8286
2023-10-24 14:04:13,005:INFO:[LightGBM] [Info] Number of data points in the train set: 32130, number of used features: 58
2023-10-24 14:04:13,005:INFO:[LightGBM] [Info] Start training from score 62.821574
2023-10-24 14:04:13,323:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010211 seconds.
2023-10-24 14:04:13,324:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:04:13,324:INFO:[LightGBM] [Info] Total Bins 8286
2023-10-24 14:04:13,324:INFO:[LightGBM] [Info] Number of data points in the train set: 32130, number of used features: 58
2023-10-24 14:04:13,325:INFO:[LightGBM] [Info] Start training from score 63.584828
2023-10-24 14:04:13,644:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006426 seconds.
2023-10-24 14:04:13,644:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:04:13,645:INFO:[LightGBM] [Info] Total Bins 8286
2023-10-24 14:04:13,645:INFO:[LightGBM] [Info] Number of data points in the train set: 32130, number of used features: 58
2023-10-24 14:04:13,646:INFO:[LightGBM] [Info] Start training from score 63.053357
2023-10-24 14:04:13,959:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006432 seconds.
2023-10-24 14:04:13,960:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:04:13,960:INFO:[LightGBM] [Info] Total Bins 8286
2023-10-24 14:04:13,960:INFO:[LightGBM] [Info] Number of data points in the train set: 32130, number of used features: 58
2023-10-24 14:04:13,961:INFO:[LightGBM] [Info] Start training from score 63.169876
2023-10-24 14:04:14,278:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006387 seconds.
2023-10-24 14:04:14,278:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:04:14,278:INFO:[LightGBM] [Info] Total Bins 8286
2023-10-24 14:04:14,279:INFO:[LightGBM] [Info] Number of data points in the train set: 32130, number of used features: 58
2023-10-24 14:04:14,279:INFO:[LightGBM] [Info] Start training from score 64.765657
2023-10-24 14:04:14,606:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006096 seconds.
2023-10-24 14:04:14,607:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:04:14,607:INFO:[LightGBM] [Info] Total Bins 8286
2023-10-24 14:04:14,607:INFO:[LightGBM] [Info] Number of data points in the train set: 32130, number of used features: 58
2023-10-24 14:04:14,608:INFO:[LightGBM] [Info] Start training from score 64.039492
2023-10-24 14:04:14,927:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006032 seconds.
2023-10-24 14:04:14,928:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:04:14,928:INFO:[LightGBM] [Info] Total Bins 8286
2023-10-24 14:04:14,928:INFO:[LightGBM] [Info] Number of data points in the train set: 32130, number of used features: 58
2023-10-24 14:04:14,929:INFO:[LightGBM] [Info] Start training from score 62.156091
2023-10-24 14:04:15,174:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                 TransformerWrapper(include=['dew_or_rime:idx', 'is_day:idx',
                                             'is_in_shadow:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx',
                                                                    'is_day:idx',
                                                                    'is_in_shadow:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-24 14:04:15,174:INFO:create_model() successfully completed......................................
2023-10-24 14:04:15,261:INFO:_master_model_container: 4
2023-10-24 14:04:15,262:INFO:_display_container: 4
2023-10-24 14:04:15,277:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                 TransformerWrapper(include=['dew_or_rime:idx', 'is_day:idx',
                                             'is_in_shadow:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx',
                                                                    'is_day:idx',
                                                                    'is_in_shadow:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-24 14:04:15,277:INFO:finalize_model() successfully completed......................................
2023-10-24 14:04:15,380:INFO:Initializing save_model()
2023-10-24 14:04:15,380:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                 TransformerWrapper(include=['dew_or_rime:idx', 'is_day:idx',
                                             'is_in_shadow:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx',
                                                                    'is_day:idx',
                                                                    'is_in_shadow:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), model_name=final_model_for_location_C, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             '...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx', 'is_day:idx',
                                             'is_in_shadow:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx',
                                                                    'is_day:idx',
                                                                    'is_in_shadow:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-24 14:04:15,380:INFO:Adding model into prep_pipe
2023-10-24 14:04:15,380:WARNING:Only Model saved as it was a pipeline.
2023-10-24 14:04:15,437:INFO:final_model_for_location_C.pkl saved in current working directory
2023-10-24 14:04:15,453:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                 TransformerWrapper(include=['dew_or_rime:idx', 'is_day:idx',
                                             'is_in_shadow:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx',
                                                                    'is_day:idx',
                                                                    'is_in_shadow:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-24 14:04:15,453:INFO:save_model() successfully completed......................................
2023-10-24 14:16:49,342:WARNING:<ipython-input-13-49df83f3379d>:13: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  estimated_resampled = estimated.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 14:16:49,351:WARNING:<ipython-input-13-49df83f3379d>:14: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  test_resampled = test.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 14:16:49,426:INFO:PyCaret RegressionExperiment
2023-10-24 14:16:49,426:INFO:Logging name: exp_A
2023-10-24 14:16:49,426:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 14:16:49,426:INFO:version 3.1.0
2023-10-24 14:16:49,426:INFO:Initializing setup()
2023-10-24 14:16:49,427:INFO:self.USI: 2a04
2023-10-24 14:16:49,427:INFO:self._variable_keys: {'y_test', 'n_jobs_param', 'exp_id', 'gpu_param', 'idx', '_available_plots', 'html_param', 'X_train', 'target_param', 'transform_target_param', 'logging_param', 'seed', 'y_train', 'log_plots_param', 'y', '_ml_usecase', 'X', 'fold_generator', 'X_test', 'exp_name_log', 'pipeline', 'fold_groups_param', 'data', 'USI', 'fold_shuffle_param', 'memory', 'gpu_n_jobs_param'}
2023-10-24 14:16:49,427:INFO:Checking environment
2023-10-24 14:16:49,427:INFO:python_version: 3.8.5
2023-10-24 14:16:49,427:INFO:python_build: ('default', 'Sep  4 2020 02:22:02')
2023-10-24 14:16:49,427:INFO:machine: x86_64
2023-10-24 14:16:49,427:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-10-24 14:16:49,428:INFO:Memory: svmem(total=8589934592, available=2353930240, percent=72.6, used=4918341632, free=45498368, active=2309214208, inactive=2306719744, wired=2609127424)
2023-10-24 14:16:49,428:INFO:Physical Core: 4
2023-10-24 14:16:49,428:INFO:Logical Core: 8
2023-10-24 14:16:49,428:INFO:Checking libraries
2023-10-24 14:16:49,428:INFO:System:
2023-10-24 14:16:49,428:INFO:    python: 3.8.5 (default, Sep  4 2020, 02:22:02)  [Clang 10.0.0 ]
2023-10-24 14:16:49,428:INFO:executable: /Users/kaja/opt/anaconda3/bin/python
2023-10-24 14:16:49,428:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-10-24 14:16:49,428:INFO:PyCaret required dependencies:
2023-10-24 14:16:49,429:INFO:                 pip: 23.3.1
2023-10-24 14:16:49,429:INFO:          setuptools: 68.2.2
2023-10-24 14:16:49,429:INFO:             pycaret: 3.1.0
2023-10-24 14:16:49,429:INFO:             IPython: 7.19.0
2023-10-24 14:16:49,429:INFO:          ipywidgets: 8.1.1
2023-10-24 14:16:49,429:INFO:                tqdm: 4.66.1
2023-10-24 14:16:49,429:INFO:               numpy: 1.23.5
2023-10-24 14:16:49,429:INFO:              pandas: 1.5.3
2023-10-24 14:16:49,429:INFO:              jinja2: 3.1.2
2023-10-24 14:16:49,429:INFO:               scipy: 1.10.1
2023-10-24 14:16:49,429:INFO:              joblib: 1.3.2
2023-10-24 14:16:49,429:INFO:             sklearn: 1.2.2
2023-10-24 14:16:49,429:INFO:                pyod: 1.1.0
2023-10-24 14:16:49,429:INFO:            imblearn: 0.11.0
2023-10-24 14:16:49,429:INFO:   category_encoders: 2.6.2
2023-10-24 14:16:49,429:INFO:            lightgbm: 4.1.0
2023-10-24 14:16:49,429:INFO:               numba: 0.58.1
2023-10-24 14:16:49,429:INFO:            requests: 2.28.2
2023-10-24 14:16:49,429:INFO:          matplotlib: 3.7.3
2023-10-24 14:16:49,429:INFO:          scikitplot: 0.3.7
2023-10-24 14:16:49,429:INFO:         yellowbrick: 1.5
2023-10-24 14:16:49,429:INFO:              plotly: 5.17.0
2023-10-24 14:16:49,429:INFO:    plotly-resampler: Not installed
2023-10-24 14:16:49,429:INFO:             kaleido: 0.2.1
2023-10-24 14:16:49,429:INFO:           schemdraw: 0.15
2023-10-24 14:16:49,429:INFO:         statsmodels: 0.14.0
2023-10-24 14:16:49,429:INFO:              sktime: 0.21.1
2023-10-24 14:16:49,429:INFO:               tbats: 1.1.3
2023-10-24 14:16:49,430:INFO:            pmdarima: 2.0.4
2023-10-24 14:16:49,430:INFO:              psutil: 5.9.6
2023-10-24 14:16:49,430:INFO:          markupsafe: 2.1.2
2023-10-24 14:16:49,430:INFO:             pickle5: Not installed
2023-10-24 14:16:49,430:INFO:         cloudpickle: 1.6.0
2023-10-24 14:16:49,430:INFO:         deprecation: 2.1.0
2023-10-24 14:16:49,430:INFO:              xxhash: 3.4.1
2023-10-24 14:16:49,430:INFO:           wurlitzer: 2.0.1
2023-10-24 14:16:49,430:INFO:PyCaret optional dependencies:
2023-10-24 14:16:49,430:INFO:                shap: Not installed
2023-10-24 14:16:49,430:INFO:           interpret: Not installed
2023-10-24 14:16:49,430:INFO:                umap: Not installed
2023-10-24 14:16:49,430:INFO:     ydata_profiling: Not installed
2023-10-24 14:16:49,430:INFO:  explainerdashboard: Not installed
2023-10-24 14:16:49,430:INFO:             autoviz: Not installed
2023-10-24 14:16:49,430:INFO:           fairlearn: Not installed
2023-10-24 14:16:49,430:INFO:          deepchecks: Not installed
2023-10-24 14:16:49,430:INFO:             xgboost: Not installed
2023-10-24 14:16:49,430:INFO:            catboost: 1.0.4
2023-10-24 14:16:49,430:INFO:              kmodes: Not installed
2023-10-24 14:16:49,430:INFO:             mlxtend: Not installed
2023-10-24 14:16:49,430:INFO:       statsforecast: Not installed
2023-10-24 14:16:49,430:INFO:        tune_sklearn: Not installed
2023-10-24 14:16:49,430:INFO:                 ray: Not installed
2023-10-24 14:16:49,430:INFO:            hyperopt: Not installed
2023-10-24 14:16:49,430:INFO:              optuna: Not installed
2023-10-24 14:16:49,430:INFO:               skopt: Not installed
2023-10-24 14:16:49,430:INFO:              mlflow: 2.7.1
2023-10-24 14:16:49,430:INFO:              gradio: Not installed
2023-10-24 14:16:49,430:INFO:             fastapi: Not installed
2023-10-24 14:16:49,430:INFO:             uvicorn: Not installed
2023-10-24 14:16:49,431:INFO:              m2cgen: Not installed
2023-10-24 14:16:49,431:INFO:           evidently: Not installed
2023-10-24 14:16:49,431:INFO:               fugue: Not installed
2023-10-24 14:16:49,431:INFO:           streamlit: Not installed
2023-10-24 14:16:49,431:INFO:             prophet: Not installed
2023-10-24 14:16:49,431:INFO:None
2023-10-24 14:16:49,431:INFO:Set up data.
2023-10-24 14:16:49,468:INFO:Set up folding strategy.
2023-10-24 14:16:49,469:INFO:Set up train/test split.
2023-10-24 14:16:49,497:INFO:Set up index.
2023-10-24 14:16:49,499:INFO:Assigning column types.
2023-10-24 14:16:49,510:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 14:16:49,511:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 14:16:49,515:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 14:16:49,520:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 14:16:49,587:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:16:49,631:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:16:49,632:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:16:49,632:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:16:49,633:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 14:16:49,638:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 14:16:49,642:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 14:16:49,705:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:16:49,746:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:16:49,747:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:16:49,747:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:16:49,747:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 14:16:49,753:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 14:16:49,757:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 14:16:49,820:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:16:49,866:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:16:49,867:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:16:49,867:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:16:49,873:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 14:16:49,877:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 14:16:49,948:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:16:50,000:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:16:50,001:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:16:50,001:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:16:50,002:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 14:16:50,012:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 14:16:50,080:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:16:50,126:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:16:50,127:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:16:50,128:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:16:50,137:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 14:16:50,204:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:16:50,250:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:16:50,251:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:16:50,251:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:16:50,252:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 14:16:50,330:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:16:50,373:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:16:50,374:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:16:50,375:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:16:50,446:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:16:50,490:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:16:50,490:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:16:50,491:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:16:50,491:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 14:16:50,566:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:16:50,613:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:16:50,613:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:16:50,705:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:16:50,773:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:16:50,774:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:16:50,774:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 14:16:50,939:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:16:50,940:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:16:51,079:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:16:51,080:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:16:51,082:INFO:Preparing preprocessing pipeline...
2023-10-24 14:16:51,082:INFO:Set up simple imputation.
2023-10-24 14:16:51,096:INFO:Set up encoding of categorical features.
2023-10-24 14:16:51,101:INFO:Set up column name cleaning.
2023-10-24 14:16:51,494:INFO:Finished creating preprocessing pipeline.
2023-10-24 14:16:51,502:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             '...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx', 'is_day:idx',
                                             'is_in_shadow:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx',
                                                                    'is_day:idx',
                                                                    'is_in_shadow:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 14:16:51,502:INFO:Creating final display dataframe.
2023-10-24 14:16:51,636:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (34061, 46)
4        Transformed data shape  (34061, 62)
5   Transformed train set shape  (23842, 62)
6    Transformed test set shape  (10219, 62)
7              Numeric features           42
8          Categorical features            3
9      Rows with missing values        97.4%
10                   Preprocess         True
11              Imputation type       simple
12           Numeric imputation         mean
13       Categorical imputation         mode
14     Maximum one-hot encoding           25
15              Encoding method         None
16               Fold Generator        KFold
17                  Fold Number           10
18                     CPU Jobs           -1
19                      Use GPU        False
20               Log Experiment        False
21              Experiment Name        exp_A
22                          USI         2a04
2023-10-24 14:16:51,764:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:16:51,764:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:16:51,907:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:16:51,908:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:16:51,910:INFO:setup() successfully completed in 2.49s...............
2023-10-24 14:16:51,910:INFO:Initializing create_model()
2023-10-24 14:16:51,910:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff5e9591130>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 14:16:51,910:INFO:Checking exceptions
2023-10-24 14:16:51,915:INFO:Importing libraries
2023-10-24 14:16:51,915:INFO:Copying training dataset
2023-10-24 14:16:51,938:INFO:Defining folds
2023-10-24 14:16:51,938:INFO:Declaring metric variables
2023-10-24 14:16:51,939:INFO:Importing untrained model
2023-10-24 14:16:51,939:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 14:16:51,939:INFO:Starting cross validation
2023-10-24 14:16:51,941:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 14:16:57,572:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:16:57,572:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:16:57,572:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:16:57,572:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:16:57,572:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:16:57,572:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:16:57,573:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:16:57,573:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:16:57,573:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:16:57,573:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:16:57,573:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:16:57,573:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:16:57,573:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:16:57,573:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:16:57,573:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:16:57,573:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:16:57,573:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:16:57,573:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:16:57,573:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:16:57,573:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:16:57,573:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:16:57,573:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:16:57,573:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:16:57,573:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:17:00,245:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054150 seconds.
2023-10-24 14:17:00,246:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:17:00,246:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:17:00,246:INFO:[LightGBM] [Info] Total Bins 7552
2023-10-24 14:17:00,246:INFO:[LightGBM] [Info] Number of data points in the train set: 21457, number of used features: 56
2023-10-24 14:17:00,254:INFO:[LightGBM] [Info] Start training from score 638.228207
2023-10-24 14:17:00,262:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045281 seconds.
2023-10-24 14:17:00,262:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:17:00,262:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:17:00,262:INFO:[LightGBM] [Info] Total Bins 7568
2023-10-24 14:17:00,263:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042584 seconds.
2023-10-24 14:17:00,263:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:17:00,263:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:17:00,263:INFO:[LightGBM] [Info] Total Bins 7559
2023-10-24 14:17:00,263:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 56
2023-10-24 14:17:00,266:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046527 seconds.
2023-10-24 14:17:00,266:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:17:00,267:INFO:[LightGBM] [Info] Total Bins 7556
2023-10-24 14:17:00,267:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 56
2023-10-24 14:17:00,268:INFO:[LightGBM] [Info] Number of data points in the train set: 21457, number of used features: 57
2023-10-24 14:17:00,273:INFO:[LightGBM] [Info] Start training from score 638.315026
2023-10-24 14:17:00,274:INFO:[LightGBM] [Info] Start training from score 635.025755
2023-10-24 14:17:00,275:INFO:[LightGBM] [Info] Start training from score 638.498183
2023-10-24 14:17:00,276:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054478 seconds.
2023-10-24 14:17:00,276:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:17:00,276:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:17:00,276:INFO:[LightGBM] [Info] Total Bins 7562
2023-10-24 14:17:00,277:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 57
2023-10-24 14:17:00,280:INFO:[LightGBM] [Info] Start training from score 635.066755
2023-10-24 14:17:00,281:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049549 seconds.
2023-10-24 14:17:00,281:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:17:00,281:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:17:00,281:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051335 seconds.
2023-10-24 14:17:00,281:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:17:00,281:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:17:00,281:INFO:[LightGBM] [Info] Total Bins 7556
2023-10-24 14:17:00,281:INFO:[LightGBM] [Info] Total Bins 7574
2023-10-24 14:17:00,283:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 57
2023-10-24 14:17:00,283:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 56
2023-10-24 14:17:00,287:INFO:[LightGBM] [Info] Start training from score 632.935130
2023-10-24 14:17:00,288:INFO:[LightGBM] [Info] Start training from score 637.332613
2023-10-24 14:17:00,294:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039329 seconds.
2023-10-24 14:17:00,295:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:17:00,295:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:17:00,295:INFO:[LightGBM] [Info] Total Bins 7567
2023-10-24 14:17:00,296:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 57
2023-10-24 14:17:00,298:INFO:[LightGBM] [Info] Start training from score 632.987592
2023-10-24 14:17:07,674:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015147 seconds.
2023-10-24 14:17:07,674:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:17:07,674:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:17:07,674:INFO:[LightGBM] [Info] Total Bins 7563
2023-10-24 14:17:07,676:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 55
2023-10-24 14:17:07,678:INFO:[LightGBM] [Info] Start training from score 635.296336
2023-10-24 14:17:07,994:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038923 seconds.
2023-10-24 14:17:07,994:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:17:07,994:INFO:[LightGBM] [Info] Total Bins 7552
2023-10-24 14:17:07,997:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 55
2023-10-24 14:17:08,007:INFO:[LightGBM] [Info] Start training from score 637.380303
2023-10-24 14:17:09,696:INFO:Calculating mean and std
2023-10-24 14:17:09,700:INFO:Creating metrics dataframe
2023-10-24 14:17:09,704:INFO:Finalizing model
2023-10-24 14:17:10,054:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005792 seconds.
2023-10-24 14:17:10,055:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:17:10,055:INFO:[LightGBM] [Info] Total Bins 7689
2023-10-24 14:17:10,056:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 57
2023-10-24 14:17:10,057:INFO:[LightGBM] [Info] Start training from score 636.106585
2023-10-24 14:17:10,304:INFO:Uploading results into container
2023-10-24 14:17:10,305:INFO:Uploading model into container now
2023-10-24 14:17:10,311:INFO:_master_model_container: 1
2023-10-24 14:17:10,312:INFO:_display_container: 2
2023-10-24 14:17:10,312:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 14:17:10,312:INFO:create_model() successfully completed......................................
2023-10-24 14:17:10,788:INFO:Initializing tune_model()
2023-10-24 14:17:10,789:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff5e9591130>)
2023-10-24 14:17:10,789:INFO:Checking exceptions
2023-10-24 14:17:10,803:INFO:Copying training dataset
2023-10-24 14:17:10,817:INFO:Checking base model
2023-10-24 14:17:10,817:INFO:Base model : Light Gradient Boosting Machine
2023-10-24 14:17:10,817:INFO:Declaring metric variables
2023-10-24 14:17:10,817:INFO:Defining Hyperparameters
2023-10-24 14:17:10,896:INFO:Tuning with n_jobs=-1
2023-10-24 14:17:10,897:INFO:Initializing RandomizedSearchCV
2023-10-24 14:22:23,554:WARNING:<ipython-input-13-49df83f3379d>:13: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  estimated_resampled = estimated.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 14:22:23,561:WARNING:<ipython-input-13-49df83f3379d>:14: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  test_resampled = test.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 14:22:23,612:INFO:PyCaret RegressionExperiment
2023-10-24 14:22:23,612:INFO:Logging name: exp_A
2023-10-24 14:22:23,612:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 14:22:23,612:INFO:version 3.1.0
2023-10-24 14:22:23,612:INFO:Initializing setup()
2023-10-24 14:22:23,612:INFO:self.USI: fb70
2023-10-24 14:22:23,612:INFO:self._variable_keys: {'y_test', 'n_jobs_param', 'exp_id', 'gpu_param', 'idx', '_available_plots', 'html_param', 'X_train', 'target_param', 'transform_target_param', 'logging_param', 'seed', 'y_train', 'log_plots_param', 'y', '_ml_usecase', 'X', 'fold_generator', 'X_test', 'exp_name_log', 'pipeline', 'fold_groups_param', 'data', 'USI', 'fold_shuffle_param', 'memory', 'gpu_n_jobs_param'}
2023-10-24 14:22:23,612:INFO:Checking environment
2023-10-24 14:22:23,612:INFO:python_version: 3.8.5
2023-10-24 14:22:23,612:INFO:python_build: ('default', 'Sep  4 2020 02:22:02')
2023-10-24 14:22:23,613:INFO:machine: x86_64
2023-10-24 14:22:23,613:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-10-24 14:22:23,613:INFO:Memory: svmem(total=8589934592, available=2721021952, percent=68.3, used=4854132736, free=478593024, active=2245881856, inactive=2204434432, wired=2608250880)
2023-10-24 14:22:23,613:INFO:Physical Core: 4
2023-10-24 14:22:23,613:INFO:Logical Core: 8
2023-10-24 14:22:23,613:INFO:Checking libraries
2023-10-24 14:22:23,613:INFO:System:
2023-10-24 14:22:23,613:INFO:    python: 3.8.5 (default, Sep  4 2020, 02:22:02)  [Clang 10.0.0 ]
2023-10-24 14:22:23,613:INFO:executable: /Users/kaja/opt/anaconda3/bin/python
2023-10-24 14:22:23,613:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-10-24 14:22:23,613:INFO:PyCaret required dependencies:
2023-10-24 14:22:23,613:INFO:                 pip: 23.3.1
2023-10-24 14:22:23,613:INFO:          setuptools: 68.2.2
2023-10-24 14:22:23,613:INFO:             pycaret: 3.1.0
2023-10-24 14:22:23,613:INFO:             IPython: 7.19.0
2023-10-24 14:22:23,613:INFO:          ipywidgets: 8.1.1
2023-10-24 14:22:23,613:INFO:                tqdm: 4.66.1
2023-10-24 14:22:23,613:INFO:               numpy: 1.23.5
2023-10-24 14:22:23,613:INFO:              pandas: 1.5.3
2023-10-24 14:22:23,613:INFO:              jinja2: 3.1.2
2023-10-24 14:22:23,614:INFO:               scipy: 1.10.1
2023-10-24 14:22:23,614:INFO:              joblib: 1.3.2
2023-10-24 14:22:23,614:INFO:             sklearn: 1.2.2
2023-10-24 14:22:23,614:INFO:                pyod: 1.1.0
2023-10-24 14:22:23,614:INFO:            imblearn: 0.11.0
2023-10-24 14:22:23,614:INFO:   category_encoders: 2.6.2
2023-10-24 14:22:23,614:INFO:            lightgbm: 4.1.0
2023-10-24 14:22:23,614:INFO:               numba: 0.58.1
2023-10-24 14:22:23,614:INFO:            requests: 2.28.2
2023-10-24 14:22:23,614:INFO:          matplotlib: 3.7.3
2023-10-24 14:22:23,614:INFO:          scikitplot: 0.3.7
2023-10-24 14:22:23,614:INFO:         yellowbrick: 1.5
2023-10-24 14:22:23,614:INFO:              plotly: 5.17.0
2023-10-24 14:22:23,614:INFO:    plotly-resampler: Not installed
2023-10-24 14:22:23,614:INFO:             kaleido: 0.2.1
2023-10-24 14:22:23,614:INFO:           schemdraw: 0.15
2023-10-24 14:22:23,614:INFO:         statsmodels: 0.14.0
2023-10-24 14:22:23,614:INFO:              sktime: 0.21.1
2023-10-24 14:22:23,614:INFO:               tbats: 1.1.3
2023-10-24 14:22:23,614:INFO:            pmdarima: 2.0.4
2023-10-24 14:22:23,614:INFO:              psutil: 5.9.6
2023-10-24 14:22:23,614:INFO:          markupsafe: 2.1.2
2023-10-24 14:22:23,614:INFO:             pickle5: Not installed
2023-10-24 14:22:23,614:INFO:         cloudpickle: 1.6.0
2023-10-24 14:22:23,614:INFO:         deprecation: 2.1.0
2023-10-24 14:22:23,614:INFO:              xxhash: 3.4.1
2023-10-24 14:22:23,614:INFO:           wurlitzer: 2.0.1
2023-10-24 14:22:23,615:INFO:PyCaret optional dependencies:
2023-10-24 14:22:23,615:INFO:                shap: Not installed
2023-10-24 14:22:23,615:INFO:           interpret: Not installed
2023-10-24 14:22:23,615:INFO:                umap: Not installed
2023-10-24 14:22:23,615:INFO:     ydata_profiling: Not installed
2023-10-24 14:22:23,615:INFO:  explainerdashboard: Not installed
2023-10-24 14:22:23,615:INFO:             autoviz: Not installed
2023-10-24 14:22:23,615:INFO:           fairlearn: Not installed
2023-10-24 14:22:23,615:INFO:          deepchecks: Not installed
2023-10-24 14:22:23,615:INFO:             xgboost: Not installed
2023-10-24 14:22:23,615:INFO:            catboost: 1.0.4
2023-10-24 14:22:23,615:INFO:              kmodes: Not installed
2023-10-24 14:22:23,615:INFO:             mlxtend: Not installed
2023-10-24 14:22:23,615:INFO:       statsforecast: Not installed
2023-10-24 14:22:23,615:INFO:        tune_sklearn: Not installed
2023-10-24 14:22:23,615:INFO:                 ray: Not installed
2023-10-24 14:22:23,615:INFO:            hyperopt: Not installed
2023-10-24 14:22:23,615:INFO:              optuna: Not installed
2023-10-24 14:22:23,615:INFO:               skopt: Not installed
2023-10-24 14:22:23,615:INFO:              mlflow: 2.7.1
2023-10-24 14:22:23,615:INFO:              gradio: Not installed
2023-10-24 14:22:23,615:INFO:             fastapi: Not installed
2023-10-24 14:22:23,615:INFO:             uvicorn: Not installed
2023-10-24 14:22:23,615:INFO:              m2cgen: Not installed
2023-10-24 14:22:23,615:INFO:           evidently: Not installed
2023-10-24 14:22:23,615:INFO:               fugue: Not installed
2023-10-24 14:22:23,616:INFO:           streamlit: Not installed
2023-10-24 14:22:23,616:INFO:             prophet: Not installed
2023-10-24 14:22:23,616:INFO:None
2023-10-24 14:22:23,616:INFO:Set up data.
2023-10-24 14:22:23,650:INFO:Set up folding strategy.
2023-10-24 14:22:23,650:INFO:Set up train/test split.
2023-10-24 14:22:23,679:INFO:Set up index.
2023-10-24 14:22:23,682:INFO:Assigning column types.
2023-10-24 14:22:23,692:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 14:22:23,692:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 14:22:23,697:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 14:22:23,701:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 14:22:23,767:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:22:23,832:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:22:23,835:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:22:23,836:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:22:23,839:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 14:22:23,849:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 14:22:23,960:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 14:22:24,055:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:22:24,105:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:22:24,105:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:22:24,106:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:22:24,106:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 14:22:24,111:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 14:22:24,117:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 14:22:24,188:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:22:24,233:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:22:24,234:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:22:24,234:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:22:24,239:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 14:22:24,244:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 14:22:24,308:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:22:24,352:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:22:24,353:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:22:24,353:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:22:24,353:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 14:22:24,362:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 14:22:24,429:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:22:24,473:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:22:24,474:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:22:24,474:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:22:24,483:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 14:22:24,547:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:22:24,595:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:22:24,596:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:22:24,596:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:22:24,596:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 14:22:24,682:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:22:24,731:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:22:24,732:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:22:24,732:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:22:24,806:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:22:24,850:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:22:24,851:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:22:24,851:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:22:24,851:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 14:22:24,931:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:22:24,978:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:22:24,978:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:22:25,052:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:22:25,095:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:22:25,095:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:22:25,096:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 14:22:25,207:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:22:25,207:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:22:25,326:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:22:25,327:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:22:25,329:INFO:Preparing preprocessing pipeline...
2023-10-24 14:22:25,329:INFO:Set up simple imputation.
2023-10-24 14:22:25,335:INFO:Set up encoding of categorical features.
2023-10-24 14:22:25,338:INFO:Set up column name cleaning.
2023-10-24 14:22:25,537:INFO:Finished creating preprocessing pipeline.
2023-10-24 14:22:25,548:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             '...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx', 'is_day:idx',
                                             'is_in_shadow:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx',
                                                                    'is_day:idx',
                                                                    'is_in_shadow:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 14:22:25,548:INFO:Creating final display dataframe.
2023-10-24 14:22:26,005:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (34061, 46)
4        Transformed data shape  (34061, 62)
5   Transformed train set shape  (23842, 62)
6    Transformed test set shape  (10219, 62)
7              Numeric features           42
8          Categorical features            3
9      Rows with missing values        97.4%
10                   Preprocess         True
11              Imputation type       simple
12           Numeric imputation         mean
13       Categorical imputation         mode
14     Maximum one-hot encoding           25
15              Encoding method         None
16               Fold Generator        KFold
17                  Fold Number           10
18                     CPU Jobs           -1
19                      Use GPU        False
20               Log Experiment        False
21              Experiment Name        exp_A
22                          USI         fb70
2023-10-24 14:22:26,126:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:22:26,127:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:22:26,256:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:22:26,256:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:22:26,257:INFO:setup() successfully completed in 2.66s...............
2023-10-24 14:22:26,258:INFO:Initializing create_model()
2023-10-24 14:22:26,258:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff5eaf78ee0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 14:22:26,258:INFO:Checking exceptions
2023-10-24 14:22:26,263:INFO:Importing libraries
2023-10-24 14:22:26,264:INFO:Copying training dataset
2023-10-24 14:22:26,288:INFO:Defining folds
2023-10-24 14:22:26,288:INFO:Declaring metric variables
2023-10-24 14:22:26,288:INFO:Importing untrained model
2023-10-24 14:22:26,289:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 14:22:26,289:INFO:Starting cross validation
2023-10-24 14:22:26,291:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 14:22:31,177:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:22:31,177:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:22:31,177:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:22:31,177:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:22:31,177:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:22:31,178:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:22:31,178:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:22:31,178:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:22:31,178:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:22:31,178:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:22:31,178:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:22:31,178:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:22:31,178:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:22:31,178:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:22:31,178:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:22:31,178:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:22:31,178:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:22:31,178:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:22:31,187:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:22:31,202:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:22:31,204:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:22:31,204:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:22:31,204:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:22:31,211:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:22:34,187:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041841 seconds.
2023-10-24 14:22:34,189:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:22:34,190:INFO:[LightGBM] [Info] Total Bins 7562
2023-10-24 14:22:34,192:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 57
2023-10-24 14:22:34,201:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044797 seconds.
2023-10-24 14:22:34,201:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:22:34,201:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:22:34,201:INFO:[LightGBM] [Info] Start training from score 635.066755
2023-10-24 14:22:34,201:INFO:[LightGBM] [Info] Total Bins 7568
2023-10-24 14:22:34,205:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 56
2023-10-24 14:22:34,208:INFO:[LightGBM] [Info] Start training from score 638.315026
2023-10-24 14:22:34,210:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040657 seconds.
2023-10-24 14:22:34,210:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:22:34,210:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:22:34,210:INFO:[LightGBM] [Info] Total Bins 7556
2023-10-24 14:22:34,213:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 56
2023-10-24 14:22:34,213:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037255 seconds.
2023-10-24 14:22:34,213:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:22:34,213:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:22:34,213:INFO:[LightGBM] [Info] Total Bins 7559
2023-10-24 14:22:34,214:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058807 seconds.
2023-10-24 14:22:34,214:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:22:34,214:INFO:[LightGBM] [Info] Total Bins 7567
2023-10-24 14:22:34,215:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 56
2023-10-24 14:22:34,217:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 57
2023-10-24 14:22:34,217:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029933 seconds.
2023-10-24 14:22:34,217:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:22:34,217:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:22:34,218:INFO:[LightGBM] [Info] Total Bins 7552
2023-10-24 14:22:34,219:INFO:[LightGBM] [Info] Number of data points in the train set: 21457, number of used features: 56
2023-10-24 14:22:34,220:INFO:[LightGBM] [Info] Start training from score 632.935130
2023-10-24 14:22:34,225:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069300 seconds.
2023-10-24 14:22:34,225:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:22:34,225:INFO:[LightGBM] [Info] Total Bins 7556
2023-10-24 14:22:34,225:INFO:[LightGBM] [Info] Start training from score 638.498183
2023-10-24 14:22:34,227:INFO:[LightGBM] [Info] Start training from score 632.987592
2023-10-24 14:22:34,227:INFO:[LightGBM] [Info] Number of data points in the train set: 21457, number of used features: 57
2023-10-24 14:22:34,229:INFO:[LightGBM] [Info] Start training from score 638.228207
2023-10-24 14:22:34,230:INFO:[LightGBM] [Info] Start training from score 635.025755
2023-10-24 14:22:34,238:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043544 seconds.
2023-10-24 14:22:34,239:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:22:34,239:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:22:34,239:INFO:[LightGBM] [Info] Total Bins 7574
2023-10-24 14:22:34,240:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 57
2023-10-24 14:22:34,243:INFO:[LightGBM] [Info] Start training from score 637.332613
2023-10-24 14:22:44,763:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014676 seconds.
2023-10-24 14:22:44,764:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:22:44,764:INFO:[LightGBM] [Info] Total Bins 7552
2023-10-24 14:22:44,765:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 55
2023-10-24 14:22:44,766:INFO:[LightGBM] [Info] Start training from score 637.380303
2023-10-24 14:22:44,776:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016777 seconds.
2023-10-24 14:22:44,777:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:22:44,777:INFO:[LightGBM] [Info] Total Bins 7563
2023-10-24 14:22:44,778:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 55
2023-10-24 14:22:44,779:INFO:[LightGBM] [Info] Start training from score 635.296336
2023-10-24 14:22:47,233:INFO:Calculating mean and std
2023-10-24 14:22:47,239:INFO:Creating metrics dataframe
2023-10-24 14:22:47,247:INFO:Finalizing model
2023-10-24 14:22:47,608:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007017 seconds.
2023-10-24 14:22:47,608:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:22:47,608:INFO:[LightGBM] [Info] Total Bins 7689
2023-10-24 14:22:47,610:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 57
2023-10-24 14:22:47,610:INFO:[LightGBM] [Info] Start training from score 636.106585
2023-10-24 14:22:48,061:INFO:Uploading results into container
2023-10-24 14:22:48,062:INFO:Uploading model into container now
2023-10-24 14:22:48,070:INFO:_master_model_container: 1
2023-10-24 14:22:48,070:INFO:_display_container: 2
2023-10-24 14:22:48,071:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 14:22:48,071:INFO:create_model() successfully completed......................................
2023-10-24 14:22:48,503:INFO:Initializing tune_model()
2023-10-24 14:22:48,503:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff5eaf78ee0>)
2023-10-24 14:22:48,503:INFO:Checking exceptions
2023-10-24 14:22:48,518:INFO:Copying training dataset
2023-10-24 14:22:48,531:INFO:Checking base model
2023-10-24 14:22:48,532:INFO:Base model : Light Gradient Boosting Machine
2023-10-24 14:22:48,532:INFO:Declaring metric variables
2023-10-24 14:22:48,532:INFO:Defining Hyperparameters
2023-10-24 14:22:48,634:INFO:Tuning with n_jobs=-1
2023-10-24 14:22:48,634:INFO:Initializing RandomizedSearchCV
2023-10-24 14:23:13,282:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-24 14:23:13,282:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-24 14:23:13,282:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-24 14:23:13,283:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-24 14:23:13,869:WARNING:<ipython-input-3-49df83f3379d>:13: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  estimated_resampled = estimated.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 14:23:13,874:WARNING:<ipython-input-3-49df83f3379d>:14: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  test_resampled = test.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 14:23:13,908:INFO:PyCaret RegressionExperiment
2023-10-24 14:23:13,908:INFO:Logging name: exp_A
2023-10-24 14:23:13,908:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 14:23:13,908:INFO:version 3.1.0
2023-10-24 14:23:13,909:INFO:Initializing setup()
2023-10-24 14:23:13,909:INFO:self.USI: 44c2
2023-10-24 14:23:13,909:INFO:self._variable_keys: {'pipeline', 'fold_shuffle_param', 'idx', '_ml_usecase', 'transform_target_param', 'seed', 'X_test', 'gpu_n_jobs_param', 'exp_name_log', 'log_plots_param', 'X_train', 'memory', 'target_param', 'USI', 'fold_generator', 'logging_param', 'html_param', '_available_plots', 'data', 'y_train', 'y_test', 'fold_groups_param', 'gpu_param', 'X', 'n_jobs_param', 'y', 'exp_id'}
2023-10-24 14:23:13,909:INFO:Checking environment
2023-10-24 14:23:13,909:INFO:python_version: 3.8.5
2023-10-24 14:23:13,909:INFO:python_build: ('default', 'Sep  4 2020 02:22:02')
2023-10-24 14:23:13,909:INFO:machine: x86_64
2023-10-24 14:23:13,923:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-10-24 14:23:13,923:INFO:Memory: svmem(total=8589934592, available=3192152064, percent=62.8, used=4512235520, free=1261588480, active=1785020416, inactive=1883045888, wired=2727215104)
2023-10-24 14:23:13,924:INFO:Physical Core: 4
2023-10-24 14:23:13,924:INFO:Logical Core: 8
2023-10-24 14:23:13,924:INFO:Checking libraries
2023-10-24 14:23:13,924:INFO:System:
2023-10-24 14:23:13,924:INFO:    python: 3.8.5 (default, Sep  4 2020, 02:22:02)  [Clang 10.0.0 ]
2023-10-24 14:23:13,924:INFO:executable: /Users/kaja/opt/anaconda3/bin/python
2023-10-24 14:23:13,924:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-10-24 14:23:13,924:INFO:PyCaret required dependencies:
2023-10-24 14:23:14,186:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:23:14,186:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:23:14,186:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:23:14,491:INFO:                 pip: 23.3.1
2023-10-24 14:23:14,491:INFO:          setuptools: 68.2.2
2023-10-24 14:23:14,491:INFO:             pycaret: 3.1.0
2023-10-24 14:23:14,491:INFO:             IPython: 7.19.0
2023-10-24 14:23:14,491:INFO:          ipywidgets: 8.1.1
2023-10-24 14:23:14,491:INFO:                tqdm: 4.66.1
2023-10-24 14:23:14,491:INFO:               numpy: 1.23.5
2023-10-24 14:23:14,491:INFO:              pandas: 1.5.3
2023-10-24 14:23:14,491:INFO:              jinja2: 3.1.2
2023-10-24 14:23:14,491:INFO:               scipy: 1.10.1
2023-10-24 14:23:14,491:INFO:              joblib: 1.3.2
2023-10-24 14:23:14,491:INFO:             sklearn: 1.2.2
2023-10-24 14:23:14,492:INFO:                pyod: 1.1.0
2023-10-24 14:23:14,492:INFO:            imblearn: 0.11.0
2023-10-24 14:23:14,492:INFO:   category_encoders: 2.6.2
2023-10-24 14:23:14,492:INFO:            lightgbm: 4.1.0
2023-10-24 14:23:14,492:INFO:               numba: 0.58.1
2023-10-24 14:23:14,492:INFO:            requests: 2.28.2
2023-10-24 14:23:14,492:INFO:          matplotlib: 3.7.3
2023-10-24 14:23:14,492:INFO:          scikitplot: 0.3.7
2023-10-24 14:23:14,492:INFO:         yellowbrick: 1.5
2023-10-24 14:23:14,492:INFO:              plotly: 5.17.0
2023-10-24 14:23:14,492:INFO:    plotly-resampler: Not installed
2023-10-24 14:23:14,492:INFO:             kaleido: 0.2.1
2023-10-24 14:23:14,492:INFO:           schemdraw: 0.15
2023-10-24 14:23:14,492:INFO:         statsmodels: 0.14.0
2023-10-24 14:23:14,492:INFO:              sktime: 0.21.1
2023-10-24 14:23:14,492:INFO:               tbats: 1.1.3
2023-10-24 14:23:14,492:INFO:            pmdarima: 2.0.4
2023-10-24 14:23:14,492:INFO:              psutil: 5.9.6
2023-10-24 14:23:14,492:INFO:          markupsafe: 2.1.2
2023-10-24 14:23:14,492:INFO:             pickle5: Not installed
2023-10-24 14:23:14,492:INFO:         cloudpickle: 1.6.0
2023-10-24 14:23:14,492:INFO:         deprecation: 2.1.0
2023-10-24 14:23:14,492:INFO:              xxhash: 3.4.1
2023-10-24 14:23:14,492:INFO:           wurlitzer: 2.0.1
2023-10-24 14:23:14,492:INFO:PyCaret optional dependencies:
2023-10-24 14:23:14,511:INFO:                shap: Not installed
2023-10-24 14:23:14,511:INFO:           interpret: Not installed
2023-10-24 14:23:14,511:INFO:                umap: Not installed
2023-10-24 14:23:14,511:INFO:     ydata_profiling: Not installed
2023-10-24 14:23:14,511:INFO:  explainerdashboard: Not installed
2023-10-24 14:23:14,511:INFO:             autoviz: Not installed
2023-10-24 14:23:14,511:INFO:           fairlearn: Not installed
2023-10-24 14:23:14,511:INFO:          deepchecks: Not installed
2023-10-24 14:23:14,511:INFO:             xgboost: Not installed
2023-10-24 14:23:14,511:INFO:            catboost: 1.0.4
2023-10-24 14:23:14,511:INFO:              kmodes: Not installed
2023-10-24 14:23:14,511:INFO:             mlxtend: Not installed
2023-10-24 14:23:14,511:INFO:       statsforecast: Not installed
2023-10-24 14:23:14,511:INFO:        tune_sklearn: Not installed
2023-10-24 14:23:14,511:INFO:                 ray: Not installed
2023-10-24 14:23:14,511:INFO:            hyperopt: Not installed
2023-10-24 14:23:14,511:INFO:              optuna: Not installed
2023-10-24 14:23:14,511:INFO:               skopt: Not installed
2023-10-24 14:23:14,511:INFO:              mlflow: 2.7.1
2023-10-24 14:23:14,512:INFO:              gradio: Not installed
2023-10-24 14:23:14,512:INFO:             fastapi: Not installed
2023-10-24 14:23:14,512:INFO:             uvicorn: Not installed
2023-10-24 14:23:14,512:INFO:              m2cgen: Not installed
2023-10-24 14:23:14,512:INFO:           evidently: Not installed
2023-10-24 14:23:14,512:INFO:               fugue: Not installed
2023-10-24 14:23:14,512:INFO:           streamlit: Not installed
2023-10-24 14:23:14,512:INFO:             prophet: Not installed
2023-10-24 14:23:14,512:INFO:None
2023-10-24 14:23:14,512:INFO:Set up data.
2023-10-24 14:23:14,552:INFO:Set up folding strategy.
2023-10-24 14:23:14,552:INFO:Set up train/test split.
2023-10-24 14:23:14,583:INFO:Set up index.
2023-10-24 14:23:14,585:INFO:Assigning column types.
2023-10-24 14:23:14,597:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 14:23:14,597:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 14:23:14,604:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 14:23:14,610:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 14:23:14,691:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:23:14,745:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:23:14,746:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:23:14,747:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:23:14,748:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 14:23:14,754:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 14:23:14,759:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 14:23:14,846:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:23:14,897:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:23:14,897:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:23:14,898:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:23:14,898:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 14:23:14,903:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 14:23:14,908:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 14:23:14,975:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:23:15,020:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:23:15,021:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:23:15,021:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:23:15,027:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 14:23:15,032:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 14:23:15,100:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:23:15,145:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:23:15,146:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:23:15,146:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:23:15,146:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 14:23:15,156:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 14:23:15,223:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:23:15,270:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:23:15,271:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:23:15,271:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:23:15,281:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 14:23:15,354:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:23:15,409:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:23:15,410:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:23:15,410:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:23:15,410:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 14:23:15,501:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:23:15,561:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:23:15,561:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:23:15,562:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:23:15,666:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:23:15,726:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:23:15,728:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:23:15,728:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:23:15,729:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 14:23:15,827:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:23:15,877:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:23:15,878:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:23:15,956:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:23:16,002:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:23:16,003:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:23:16,004:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 14:23:16,140:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:23:16,140:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:23:16,347:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:23:16,348:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:23:16,351:INFO:Preparing preprocessing pipeline...
2023-10-24 14:23:16,351:INFO:Set up simple imputation.
2023-10-24 14:23:16,361:INFO:Set up encoding of categorical features.
2023-10-24 14:23:16,364:INFO:Set up column name cleaning.
2023-10-24 14:23:16,530:INFO:Finished creating preprocessing pipeline.
2023-10-24 14:23:16,542:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             '...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx', 'is_day:idx',
                                             'is_in_shadow:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx',
                                                                    'is_day:idx',
                                                                    'is_in_shadow:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 14:23:16,542:INFO:Creating final display dataframe.
2023-10-24 14:23:16,850:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (34061, 46)
4        Transformed data shape  (34061, 62)
5   Transformed train set shape  (23842, 62)
6    Transformed test set shape  (10219, 62)
7              Numeric features           42
8          Categorical features            3
9      Rows with missing values        97.4%
10                   Preprocess         True
11              Imputation type       simple
12           Numeric imputation         mean
13       Categorical imputation         mode
14     Maximum one-hot encoding           25
15              Encoding method         None
16               Fold Generator        KFold
17                  Fold Number           10
18                     CPU Jobs           -1
19                      Use GPU        False
20               Log Experiment        False
21              Experiment Name        exp_A
22                          USI         44c2
2023-10-24 14:23:16,990:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:23:16,991:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:23:17,119:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:23:17,119:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:23:17,125:INFO:setup() successfully completed in 3.22s...............
2023-10-24 14:23:17,125:INFO:Initializing create_model()
2023-10-24 14:23:17,125:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa4cfad3eb0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 14:23:17,125:INFO:Checking exceptions
2023-10-24 14:23:17,134:INFO:Importing libraries
2023-10-24 14:23:17,135:INFO:Copying training dataset
2023-10-24 14:23:17,156:INFO:Defining folds
2023-10-24 14:23:17,157:INFO:Declaring metric variables
2023-10-24 14:23:17,157:INFO:Importing untrained model
2023-10-24 14:23:17,158:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 14:23:17,158:INFO:Starting cross validation
2023-10-24 14:23:17,165:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 14:23:22,060:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:23:22,061:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:23:22,061:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:23:22,062:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:23:22,062:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:23:22,062:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:23:22,062:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:23:22,063:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:23:22,063:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:23:22,138:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:23:22,138:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:23:22,139:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:23:22,163:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:23:22,163:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:23:22,163:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:23:22,168:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:23:22,168:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:23:22,169:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:23:22,214:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:23:22,215:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:23:22,215:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:23:22,223:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:23:22,223:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:23:22,224:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:23:24,540:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063802 seconds.
2023-10-24 14:23:24,540:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:23:24,541:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:23:24,541:INFO:[LightGBM] [Info] Total Bins 7552
2023-10-24 14:23:24,542:INFO:[LightGBM] [Info] Number of data points in the train set: 21457, number of used features: 56
2023-10-24 14:23:24,548:INFO:[LightGBM] [Info] Start training from score 638.228207
2023-10-24 14:23:24,549:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.091740 seconds.
2023-10-24 14:23:24,549:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:23:24,549:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:23:24,549:INFO:[LightGBM] [Info] Total Bins 7556
2023-10-24 14:23:24,552:INFO:[LightGBM] [Info] Number of data points in the train set: 21457, number of used features: 57
2023-10-24 14:23:24,552:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076134 seconds.
2023-10-24 14:23:24,552:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:23:24,552:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:23:24,552:INFO:[LightGBM] [Info] Total Bins 7568
2023-10-24 14:23:24,558:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 56
2023-10-24 14:23:24,561:INFO:[LightGBM] [Info] Start training from score 635.025755
2023-10-24 14:23:24,563:INFO:[LightGBM] [Info] Start training from score 638.315026
2023-10-24 14:23:24,564:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.089593 seconds.
2023-10-24 14:23:24,564:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:23:24,564:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:23:24,564:INFO:[LightGBM] [Info] Total Bins 7556
2023-10-24 14:23:24,566:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 56
2023-10-24 14:23:24,569:INFO:[LightGBM] [Info] Start training from score 632.935130
2023-10-24 14:23:24,570:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061770 seconds.
2023-10-24 14:23:24,570:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:23:24,571:INFO:[LightGBM] [Info] Total Bins 7562
2023-10-24 14:23:24,573:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 57
2023-10-24 14:23:24,576:INFO:[LightGBM] [Info] Start training from score 635.066755
2023-10-24 14:23:24,597:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071889 seconds.
2023-10-24 14:23:24,597:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:23:24,597:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:23:24,597:INFO:[LightGBM] [Info] Total Bins 7559
2023-10-24 14:23:24,601:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 56
2023-10-24 14:23:24,606:INFO:[LightGBM] [Info] Start training from score 638.498183
2023-10-24 14:23:24,607:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062164 seconds.
2023-10-24 14:23:24,607:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:23:24,607:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:23:24,607:INFO:[LightGBM] [Info] Total Bins 7574
2023-10-24 14:23:24,609:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 57
2023-10-24 14:23:24,613:INFO:[LightGBM] [Info] Start training from score 637.332613
2023-10-24 14:23:24,615:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.059691 seconds.
2023-10-24 14:23:24,615:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:23:24,615:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:23:24,615:INFO:[LightGBM] [Info] Total Bins 7567
2023-10-24 14:23:24,616:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 57
2023-10-24 14:23:24,619:INFO:[LightGBM] [Info] Start training from score 632.987592
2023-10-24 14:23:33,068:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009864 seconds.
2023-10-24 14:23:33,068:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:23:33,068:INFO:[LightGBM] [Info] Total Bins 7563
2023-10-24 14:23:33,069:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 55
2023-10-24 14:23:33,070:INFO:[LightGBM] [Info] Start training from score 635.296336
2023-10-24 14:23:33,181:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010882 seconds.
2023-10-24 14:23:33,181:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:23:33,182:INFO:[LightGBM] [Info] Total Bins 7552
2023-10-24 14:23:33,182:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 55
2023-10-24 14:23:33,183:INFO:[LightGBM] [Info] Start training from score 637.380303
2023-10-24 14:23:34,883:INFO:Calculating mean and std
2023-10-24 14:23:34,887:INFO:Creating metrics dataframe
2023-10-24 14:23:34,891:INFO:Finalizing model
2023-10-24 14:23:35,281:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008600 seconds.
2023-10-24 14:23:35,282:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:23:35,282:INFO:[LightGBM] [Info] Total Bins 7689
2023-10-24 14:23:35,283:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 57
2023-10-24 14:23:35,284:INFO:[LightGBM] [Info] Start training from score 636.106585
2023-10-24 14:23:35,653:INFO:Uploading results into container
2023-10-24 14:23:35,655:INFO:Uploading model into container now
2023-10-24 14:23:35,662:INFO:_master_model_container: 1
2023-10-24 14:23:35,662:INFO:_display_container: 2
2023-10-24 14:23:35,663:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 14:23:35,663:INFO:create_model() successfully completed......................................
2023-10-24 14:23:35,781:INFO:Initializing tune_model()
2023-10-24 14:23:35,781:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa4cfad3eb0>)
2023-10-24 14:23:35,781:INFO:Checking exceptions
2023-10-24 14:23:35,797:INFO:Copying training dataset
2023-10-24 14:23:35,814:INFO:Checking base model
2023-10-24 14:23:35,814:INFO:Base model : Light Gradient Boosting Machine
2023-10-24 14:23:35,814:INFO:Declaring metric variables
2023-10-24 14:23:35,815:INFO:Defining Hyperparameters
2023-10-24 14:23:35,896:INFO:Tuning with n_jobs=-1
2023-10-24 14:23:35,897:INFO:Initializing RandomizedSearchCV
2023-10-24 14:27:22,310:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-24 14:27:22,319:INFO:Hyperparameter search completed
2023-10-24 14:27:22,320:INFO:SubProcess create_model() called ==================================
2023-10-24 14:27:22,323:INFO:Initializing create_model()
2023-10-24 14:27:22,323:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa4cfad3eb0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa4ca5bc880>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-24 14:27:22,323:INFO:Checking exceptions
2023-10-24 14:27:22,324:INFO:Importing libraries
2023-10-24 14:27:22,324:INFO:Copying training dataset
2023-10-24 14:27:22,379:INFO:Defining folds
2023-10-24 14:27:22,379:INFO:Declaring metric variables
2023-10-24 14:27:22,380:INFO:Importing untrained model
2023-10-24 14:27:22,380:INFO:Declaring custom model
2023-10-24 14:27:22,382:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 14:27:22,383:INFO:Starting cross validation
2023-10-24 14:27:22,386:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 14:28:06,677:INFO:Calculating mean and std
2023-10-24 14:28:06,678:INFO:Creating metrics dataframe
2023-10-24 14:28:06,683:INFO:Finalizing model
2023-10-24 14:28:06,928:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:28:06,928:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:28:06,928:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:28:06,974:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:28:06,974:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:28:06,974:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:28:06,980:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003772 seconds.
2023-10-24 14:28:06,980:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:28:06,982:INFO:[LightGBM] [Info] Total Bins 7683
2023-10-24 14:28:06,983:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 54
2023-10-24 14:28:06,985:INFO:[LightGBM] [Info] Start training from score 636.106585
2023-10-24 14:28:07,817:INFO:Uploading results into container
2023-10-24 14:28:07,818:INFO:Uploading model into container now
2023-10-24 14:28:07,820:INFO:_master_model_container: 2
2023-10-24 14:28:07,820:INFO:_display_container: 3
2023-10-24 14:28:07,821:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-24 14:28:07,821:INFO:create_model() successfully completed......................................
2023-10-24 14:28:08,131:INFO:SubProcess create_model() end ==================================
2023-10-24 14:28:08,131:INFO:choose_better activated
2023-10-24 14:28:08,131:INFO:SubProcess create_model() called ==================================
2023-10-24 14:28:08,132:INFO:Initializing create_model()
2023-10-24 14:28:08,132:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa4cfad3eb0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 14:28:08,132:INFO:Checking exceptions
2023-10-24 14:28:08,133:INFO:Importing libraries
2023-10-24 14:28:08,133:INFO:Copying training dataset
2023-10-24 14:28:08,156:INFO:Defining folds
2023-10-24 14:28:08,156:INFO:Declaring metric variables
2023-10-24 14:28:08,156:INFO:Importing untrained model
2023-10-24 14:28:08,156:INFO:Declaring custom model
2023-10-24 14:28:08,157:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 14:28:08,157:INFO:Starting cross validation
2023-10-24 14:28:08,159:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 14:28:17,436:INFO:Calculating mean and std
2023-10-24 14:28:17,437:INFO:Creating metrics dataframe
2023-10-24 14:28:17,439:INFO:Finalizing model
2023-10-24 14:28:17,728:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006592 seconds.
2023-10-24 14:28:17,728:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:28:17,729:INFO:[LightGBM] [Info] Total Bins 7689
2023-10-24 14:28:17,729:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 57
2023-10-24 14:28:17,730:INFO:[LightGBM] [Info] Start training from score 636.106585
2023-10-24 14:28:17,932:INFO:Uploading results into container
2023-10-24 14:28:17,933:INFO:Uploading model into container now
2023-10-24 14:28:17,933:INFO:_master_model_container: 3
2023-10-24 14:28:17,933:INFO:_display_container: 4
2023-10-24 14:28:17,933:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 14:28:17,934:INFO:create_model() successfully completed......................................
2023-10-24 14:28:18,019:INFO:SubProcess create_model() end ==================================
2023-10-24 14:28:18,020:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.865
2023-10-24 14:28:18,021:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8657
2023-10-24 14:28:18,021:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) is best model
2023-10-24 14:28:18,021:INFO:choose_better completed
2023-10-24 14:28:18,026:INFO:_master_model_container: 3
2023-10-24 14:28:18,026:INFO:_display_container: 3
2023-10-24 14:28:18,027:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-24 14:28:18,028:INFO:tune_model() successfully completed......................................
2023-10-24 14:28:18,111:INFO:Initializing ensemble_model()
2023-10-24 14:28:18,111:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa4cfad3eb0>, estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-24 14:28:18,111:INFO:Checking exceptions
2023-10-24 14:28:18,126:INFO:Importing libraries
2023-10-24 14:28:18,126:INFO:Copying training dataset
2023-10-24 14:28:18,126:INFO:Checking base model
2023-10-24 14:28:18,127:INFO:Base model : Light Gradient Boosting Machine
2023-10-24 14:28:18,127:INFO:Importing untrained ensembler
2023-10-24 14:28:18,128:INFO:Ensemble method set to Bagging
2023-10-24 14:28:18,128:INFO:SubProcess create_model() called ==================================
2023-10-24 14:28:18,130:INFO:Initializing create_model()
2023-10-24 14:28:18,130:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa4cfad3eb0>, estimator=BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                                         feature_fraction=0.4,
                                         min_child_samples=41,
                                         min_split_gain=0.9, n_estimators=260,
                                         n_jobs=-1, num_leaves=70,
                                         random_state=123, reg_alpha=2,
                                         reg_lambda=3),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa4b2624ca0>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 14:28:18,130:INFO:Checking exceptions
2023-10-24 14:28:18,130:INFO:Importing libraries
2023-10-24 14:28:18,130:INFO:Copying training dataset
2023-10-24 14:28:18,145:INFO:Defining folds
2023-10-24 14:28:18,145:INFO:Declaring metric variables
2023-10-24 14:28:18,145:INFO:Importing untrained model
2023-10-24 14:28:18,145:INFO:Declaring custom model
2023-10-24 14:28:18,146:INFO:Bagging Regressor Imported successfully
2023-10-24 14:28:18,146:INFO:Starting cross validation
2023-10-24 14:28:18,148:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 14:35:21,416:INFO:Calculating mean and std
2023-10-24 14:35:21,425:INFO:Creating metrics dataframe
2023-10-24 14:35:21,434:INFO:Finalizing model
2023-10-24 14:35:21,701:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:35:21,701:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:35:21,701:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:35:21,750:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:35:21,751:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:35:21,751:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:35:21,760:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005903 seconds.
2023-10-24 14:35:21,760:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:35:21,761:INFO:[LightGBM] [Info] Total Bins 7683
2023-10-24 14:35:21,763:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 54
2023-10-24 14:35:21,765:INFO:[LightGBM] [Info] Start training from score 629.993497
2023-10-24 14:35:22,613:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:35:22,613:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:35:22,613:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:35:22,661:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:35:22,661:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:35:22,661:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:35:22,670:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006683 seconds.
2023-10-24 14:35:22,670:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:35:22,672:INFO:[LightGBM] [Info] Total Bins 7683
2023-10-24 14:35:22,673:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 54
2023-10-24 14:35:22,674:INFO:[LightGBM] [Info] Start training from score 639.698324
2023-10-24 14:35:23,530:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:35:23,530:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:35:23,530:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:35:23,574:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:35:23,574:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:35:23,574:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:35:23,581:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004268 seconds.
2023-10-24 14:35:23,581:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:35:23,582:INFO:[LightGBM] [Info] Total Bins 7683
2023-10-24 14:35:23,584:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 54
2023-10-24 14:35:23,584:INFO:[LightGBM] [Info] Start training from score 639.067381
2023-10-24 14:35:24,474:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:35:24,475:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:35:24,475:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:35:24,522:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:35:24,523:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:35:24,523:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:35:24,531:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005634 seconds.
2023-10-24 14:35:24,531:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:35:24,533:INFO:[LightGBM] [Info] Total Bins 7683
2023-10-24 14:35:24,534:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 54
2023-10-24 14:35:24,535:INFO:[LightGBM] [Info] Start training from score 640.702912
2023-10-24 14:35:25,491:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:35:25,491:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:35:25,491:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:35:25,538:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:35:25,538:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:35:25,538:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:35:25,548:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008079 seconds.
2023-10-24 14:35:25,549:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:35:25,550:INFO:[LightGBM] [Info] Total Bins 7683
2023-10-24 14:35:25,552:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 54
2023-10-24 14:35:25,552:INFO:[LightGBM] [Info] Start training from score 638.373964
2023-10-24 14:35:26,410:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:35:26,410:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:35:26,410:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:35:26,459:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:35:26,459:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:35:26,460:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:35:26,470:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007407 seconds.
2023-10-24 14:35:26,470:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:35:26,471:INFO:[LightGBM] [Info] Total Bins 7683
2023-10-24 14:35:26,473:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 54
2023-10-24 14:35:26,474:INFO:[LightGBM] [Info] Start training from score 631.653878
2023-10-24 14:35:27,322:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:35:27,322:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:35:27,322:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:35:27,373:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:35:27,374:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:35:27,374:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:35:27,384:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007021 seconds.
2023-10-24 14:35:27,384:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:35:27,385:INFO:[LightGBM] [Info] Total Bins 7683
2023-10-24 14:35:27,387:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 54
2023-10-24 14:35:27,388:INFO:[LightGBM] [Info] Start training from score 640.465574
2023-10-24 14:35:28,322:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:35:28,322:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:35:28,322:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:35:28,371:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:35:28,371:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:35:28,371:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:35:28,382:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008138 seconds.
2023-10-24 14:35:28,382:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:35:28,383:INFO:[LightGBM] [Info] Total Bins 7683
2023-10-24 14:35:28,385:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 54
2023-10-24 14:35:28,386:INFO:[LightGBM] [Info] Start training from score 642.146080
2023-10-24 14:35:29,235:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:35:29,235:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:35:29,235:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:35:29,280:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:35:29,281:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:35:29,281:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:35:29,291:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006959 seconds.
2023-10-24 14:35:29,291:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:35:29,293:INFO:[LightGBM] [Info] Total Bins 7683
2023-10-24 14:35:29,294:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 54
2023-10-24 14:35:29,295:INFO:[LightGBM] [Info] Start training from score 646.454539
2023-10-24 14:35:30,155:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:35:30,155:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:35:30,155:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:35:30,204:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:35:30,204:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:35:30,204:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:35:30,213:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006218 seconds.
2023-10-24 14:35:30,213:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:35:30,214:INFO:[LightGBM] [Info] Total Bins 7683
2023-10-24 14:35:30,216:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 54
2023-10-24 14:35:30,216:INFO:[LightGBM] [Info] Start training from score 646.584710
2023-10-24 14:35:31,110:INFO:Uploading results into container
2023-10-24 14:35:31,112:INFO:Uploading model into container now
2023-10-24 14:35:31,114:INFO:_master_model_container: 4
2023-10-24 14:35:31,114:INFO:_display_container: 4
2023-10-24 14:35:31,117:INFO:BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                                         feature_fraction=0.4,
                                         min_child_samples=41,
                                         min_split_gain=0.9, n_estimators=260,
                                         n_jobs=-1, num_leaves=70,
                                         random_state=123, reg_alpha=2,
                                         reg_lambda=3),
                 random_state=123)
2023-10-24 14:35:31,117:INFO:create_model() successfully completed......................................
2023-10-24 14:35:31,464:INFO:SubProcess create_model() end ==================================
2023-10-24 14:35:31,469:INFO:_master_model_container: 4
2023-10-24 14:35:31,469:INFO:_display_container: 4
2023-10-24 14:35:31,472:INFO:BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                                         feature_fraction=0.4,
                                         min_child_samples=41,
                                         min_split_gain=0.9, n_estimators=260,
                                         n_jobs=-1, num_leaves=70,
                                         random_state=123, reg_alpha=2,
                                         reg_lambda=3),
                 random_state=123)
2023-10-24 14:35:31,472:INFO:ensemble_model() successfully completed......................................
2023-10-24 14:35:31,553:INFO:Initializing finalize_model()
2023-10-24 14:35:31,554:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa4cfad3eb0>, estimator=BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                                         feature_fraction=0.4,
                                         min_child_samples=41,
                                         min_split_gain=0.9, n_estimators=260,
                                         n_jobs=-1, num_leaves=70,
                                         random_state=123, reg_alpha=2,
                                         reg_lambda=3),
                 random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-24 14:35:31,556:INFO:Finalizing BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                                         feature_fraction=0.4,
                                         min_child_samples=41,
                                         min_split_gain=0.9, n_estimators=260,
                                         n_jobs=-1, num_leaves=70,
                                         random_state=123, reg_alpha=2,
                                         reg_lambda=3),
                 random_state=123)
2023-10-24 14:35:31,591:INFO:Initializing create_model()
2023-10-24 14:35:31,591:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa4cfad3eb0>, estimator=BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                                         feature_fraction=0.4,
                                         min_child_samples=41,
                                         min_split_gain=0.9, n_estimators=260,
                                         n_jobs=-1, num_leaves=70,
                                         random_state=123, reg_alpha=2,
                                         reg_lambda=3),
                 random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-24 14:35:31,591:INFO:Checking exceptions
2023-10-24 14:35:31,592:INFO:Importing libraries
2023-10-24 14:35:31,592:INFO:Copying training dataset
2023-10-24 14:35:31,594:INFO:Defining folds
2023-10-24 14:35:31,595:INFO:Declaring metric variables
2023-10-24 14:35:31,595:INFO:Importing untrained model
2023-10-24 14:35:31,595:INFO:Declaring custom model
2023-10-24 14:35:31,597:INFO:Bagging Regressor Imported successfully
2023-10-24 14:35:31,600:INFO:Cross validation set to False
2023-10-24 14:35:31,600:INFO:Fitting Model
2023-10-24 14:35:31,932:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:35:31,932:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:35:31,932:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:35:31,994:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:35:31,994:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:35:31,994:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:35:32,003:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001752 seconds.
2023-10-24 14:35:32,003:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:35:32,004:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:35:32,004:INFO:[LightGBM] [Info] Total Bins 7876
2023-10-24 14:35:32,005:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 55
2023-10-24 14:35:32,006:INFO:[LightGBM] [Info] Start training from score 621.939460
2023-10-24 14:35:32,972:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:35:32,972:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:35:32,972:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:35:33,040:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:35:33,040:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:35:33,040:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:35:33,052:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001609 seconds.
2023-10-24 14:35:33,052:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:35:33,052:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:35:33,052:INFO:[LightGBM] [Info] Total Bins 7876
2023-10-24 14:35:33,054:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 55
2023-10-24 14:35:33,055:INFO:[LightGBM] [Info] Start training from score 633.276326
2023-10-24 14:35:34,063:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:35:34,064:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:35:34,064:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:35:34,131:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:35:34,131:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:35:34,131:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:35:34,142:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001610 seconds.
2023-10-24 14:35:34,142:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:35:34,142:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:35:34,143:INFO:[LightGBM] [Info] Total Bins 7876
2023-10-24 14:35:34,145:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 55
2023-10-24 14:35:34,146:INFO:[LightGBM] [Info] Start training from score 622.547611
2023-10-24 14:35:35,324:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:35:35,324:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:35:35,325:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:35:35,394:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:35:35,394:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:35:35,394:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:35:35,404:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001611 seconds.
2023-10-24 14:35:35,405:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:35:35,405:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:35:35,405:INFO:[LightGBM] [Info] Total Bins 7876
2023-10-24 14:35:35,406:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 55
2023-10-24 14:35:35,407:INFO:[LightGBM] [Info] Start training from score 627.206506
2023-10-24 14:35:36,454:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:35:36,455:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:35:36,455:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:35:36,523:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:35:36,523:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:35:36,523:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:35:36,533:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001724 seconds.
2023-10-24 14:35:36,534:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:35:36,534:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:35:36,534:INFO:[LightGBM] [Info] Total Bins 7876
2023-10-24 14:35:36,536:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 55
2023-10-24 14:35:36,537:INFO:[LightGBM] [Info] Start training from score 637.955081
2023-10-24 14:35:37,612:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:35:37,612:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:35:37,612:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:35:37,685:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:35:37,685:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:35:37,686:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:35:37,702:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012225 seconds.
2023-10-24 14:35:37,702:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:35:37,704:INFO:[LightGBM] [Info] Total Bins 7876
2023-10-24 14:35:37,706:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 55
2023-10-24 14:35:37,707:INFO:[LightGBM] [Info] Start training from score 632.824687
2023-10-24 14:35:38,669:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:35:38,669:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:35:38,669:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:35:38,740:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:35:38,740:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:35:38,740:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:35:38,752:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002059 seconds.
2023-10-24 14:35:38,752:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:35:38,752:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:35:38,752:INFO:[LightGBM] [Info] Total Bins 7876
2023-10-24 14:35:38,754:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 55
2023-10-24 14:35:38,755:INFO:[LightGBM] [Info] Start training from score 633.780341
2023-10-24 14:35:39,822:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:35:39,823:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:35:39,823:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:35:39,891:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:35:39,891:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:35:39,891:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:35:39,904:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002121 seconds.
2023-10-24 14:35:39,904:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:35:39,904:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:35:39,905:INFO:[LightGBM] [Info] Total Bins 7876
2023-10-24 14:35:39,906:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 55
2023-10-24 14:35:39,907:INFO:[LightGBM] [Info] Start training from score 636.770620
2023-10-24 14:35:41,060:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:35:41,061:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:35:41,061:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:35:41,132:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:35:41,132:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:35:41,132:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:35:41,144:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002287 seconds.
2023-10-24 14:35:41,144:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:35:41,144:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:35:41,144:INFO:[LightGBM] [Info] Total Bins 7876
2023-10-24 14:35:41,146:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 55
2023-10-24 14:35:41,147:INFO:[LightGBM] [Info] Start training from score 638.361113
2023-10-24 14:35:42,212:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:35:42,212:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:35:42,212:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:35:42,279:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:35:42,279:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:35:42,279:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:35:42,289:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001590 seconds.
2023-10-24 14:35:42,289:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:35:42,289:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:35:42,289:INFO:[LightGBM] [Info] Total Bins 7876
2023-10-24 14:35:42,291:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 55
2023-10-24 14:35:42,292:INFO:[LightGBM] [Info] Start training from score 629.488323
2023-10-24 14:35:43,333:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6,
                                                          bagging_freq=2,
                                                          feature_fraction=0.4,
                                                          min_child_samples=41,
                                                          min_split_gain=0.9,
                                                          n_estimators=260,
                                                          n_jobs=-1,
                                                          num_leaves=70,
                                                          random_state=123,
                                                          reg_alpha=2,
                                                          reg_lambda=3),
                                  random_state=123))])
2023-10-24 14:35:43,333:INFO:create_model() successfully completed......................................
2023-10-24 14:35:43,421:INFO:_master_model_container: 4
2023-10-24 14:35:43,422:INFO:_display_container: 4
2023-10-24 14:35:43,440:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6,
                                                          bagging_freq=2,
                                                          feature_fraction=0.4,
                                                          min_child_samples=41,
                                                          min_split_gain=0.9,
                                                          n_estimators=260,
                                                          n_jobs=-1,
                                                          num_leaves=70,
                                                          random_state=123,
                                                          reg_alpha=2,
                                                          reg_lambda=3),
                                  random_state=123))])
2023-10-24 14:35:43,440:INFO:finalize_model() successfully completed......................................
2023-10-24 14:35:43,550:INFO:Initializing save_model()
2023-10-24 14:35:43,550:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6,
                                                          bagging_freq=2,
                                                          feature_fraction=0.4,
                                                          min_child_samples=41,
                                                          min_split_gain=0.9,
                                                          n_estimators=260,
                                                          n_jobs=-1,
                                                          num_leaves=70,
                                                          random_state=123,
                                                          reg_alpha=2,
                                                          reg_lambda=3),
                                  random_state=123))]), model_name=final_model_for_location_A, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             '...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx', 'is_day:idx',
                                             'is_in_shadow:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx',
                                                                    'is_day:idx',
                                                                    'is_in_shadow:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-24 14:35:43,550:INFO:Adding model into prep_pipe
2023-10-24 14:35:43,550:WARNING:Only Model saved as it was a pipeline.
2023-10-24 14:35:43,920:INFO:final_model_for_location_A.pkl saved in current working directory
2023-10-24 14:35:43,938:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6,
                                                          bagging_freq=2,
                                                          feature_fraction=0.4,
                                                          min_child_samples=41,
                                                          min_split_gain=0.9,
                                                          n_estimators=260,
                                                          n_jobs=-1,
                                                          num_leaves=70,
                                                          random_state=123,
                                                          reg_alpha=2,
                                                          reg_lambda=3),
                                  random_state=123))])
2023-10-24 14:35:43,938:INFO:save_model() successfully completed......................................
2023-10-24 14:35:44,042:INFO:Initializing predict_model()
2023-10-24 14:35:44,042:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa4cfad3eb0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6,
                                                          bagging_freq=2,
                                                          feature_fraction=0.4,
                                                          min_child_samples=41,
                                                          min_split_gain=0.9,
                                                          n_estimators=260,
                                                          n_jobs=-1,
                                                          num_leaves=70,
                                                          random_state=123,
                                                          reg_alpha=2,
                                                          reg_lambda=3),
                                  random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa4cfae7550>)
2023-10-24 14:35:44,042:INFO:Checking exceptions
2023-10-24 14:35:44,042:INFO:Preloading libraries
2023-10-24 14:35:44,042:INFO:Set up data.
2023-10-24 14:35:44,057:INFO:Set up index.
2023-10-24 14:39:45,571:WARNING:<ipython-input-9-49df83f3379d>:13: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  estimated_resampled = estimated.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 14:39:45,577:WARNING:<ipython-input-9-49df83f3379d>:14: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  test_resampled = test.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 14:39:45,671:INFO:PyCaret RegressionExperiment
2023-10-24 14:39:45,671:INFO:Logging name: exp_A
2023-10-24 14:39:45,671:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 14:39:45,671:INFO:version 3.1.0
2023-10-24 14:39:45,672:INFO:Initializing setup()
2023-10-24 14:39:45,672:INFO:self.USI: 929d
2023-10-24 14:39:45,672:INFO:self._variable_keys: {'pipeline', 'fold_shuffle_param', 'idx', '_ml_usecase', 'transform_target_param', 'seed', 'X_test', 'gpu_n_jobs_param', 'exp_name_log', 'log_plots_param', 'X_train', 'memory', 'target_param', 'USI', 'fold_generator', 'logging_param', 'html_param', '_available_plots', 'data', 'y_train', 'y_test', 'fold_groups_param', 'gpu_param', 'X', 'n_jobs_param', 'y', 'exp_id'}
2023-10-24 14:39:45,672:INFO:Checking environment
2023-10-24 14:39:45,672:INFO:python_version: 3.8.5
2023-10-24 14:39:45,672:INFO:python_build: ('default', 'Sep  4 2020 02:22:02')
2023-10-24 14:39:45,672:INFO:machine: x86_64
2023-10-24 14:39:45,672:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-10-24 14:39:45,672:INFO:Memory: svmem(total=8589934592, available=2222841856, percent=74.1, used=4645703680, free=183627776, active=2042802176, inactive=2004373504, wired=2602901504)
2023-10-24 14:39:45,672:INFO:Physical Core: 4
2023-10-24 14:39:45,673:INFO:Logical Core: 8
2023-10-24 14:39:45,673:INFO:Checking libraries
2023-10-24 14:39:45,673:INFO:System:
2023-10-24 14:39:45,673:INFO:    python: 3.8.5 (default, Sep  4 2020, 02:22:02)  [Clang 10.0.0 ]
2023-10-24 14:39:45,673:INFO:executable: /Users/kaja/opt/anaconda3/bin/python
2023-10-24 14:39:45,673:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-10-24 14:39:45,673:INFO:PyCaret required dependencies:
2023-10-24 14:39:45,673:INFO:                 pip: 23.3.1
2023-10-24 14:39:45,673:INFO:          setuptools: 68.2.2
2023-10-24 14:39:45,673:INFO:             pycaret: 3.1.0
2023-10-24 14:39:45,673:INFO:             IPython: 7.19.0
2023-10-24 14:39:45,673:INFO:          ipywidgets: 8.1.1
2023-10-24 14:39:45,673:INFO:                tqdm: 4.66.1
2023-10-24 14:39:45,674:INFO:               numpy: 1.23.5
2023-10-24 14:39:45,674:INFO:              pandas: 1.5.3
2023-10-24 14:39:45,674:INFO:              jinja2: 3.1.2
2023-10-24 14:39:45,674:INFO:               scipy: 1.10.1
2023-10-24 14:39:45,674:INFO:              joblib: 1.3.2
2023-10-24 14:39:45,674:INFO:             sklearn: 1.2.2
2023-10-24 14:39:45,674:INFO:                pyod: 1.1.0
2023-10-24 14:39:45,674:INFO:            imblearn: 0.11.0
2023-10-24 14:39:45,674:INFO:   category_encoders: 2.6.2
2023-10-24 14:39:45,674:INFO:            lightgbm: 4.1.0
2023-10-24 14:39:45,674:INFO:               numba: 0.58.1
2023-10-24 14:39:45,674:INFO:            requests: 2.28.2
2023-10-24 14:39:45,674:INFO:          matplotlib: 3.7.3
2023-10-24 14:39:45,674:INFO:          scikitplot: 0.3.7
2023-10-24 14:39:45,674:INFO:         yellowbrick: 1.5
2023-10-24 14:39:45,674:INFO:              plotly: 5.17.0
2023-10-24 14:39:45,674:INFO:    plotly-resampler: Not installed
2023-10-24 14:39:45,674:INFO:             kaleido: 0.2.1
2023-10-24 14:39:45,674:INFO:           schemdraw: 0.15
2023-10-24 14:39:45,674:INFO:         statsmodels: 0.14.0
2023-10-24 14:39:45,674:INFO:              sktime: 0.21.1
2023-10-24 14:39:45,674:INFO:               tbats: 1.1.3
2023-10-24 14:39:45,674:INFO:            pmdarima: 2.0.4
2023-10-24 14:39:45,674:INFO:              psutil: 5.9.6
2023-10-24 14:39:45,674:INFO:          markupsafe: 2.1.2
2023-10-24 14:39:45,674:INFO:             pickle5: Not installed
2023-10-24 14:39:45,674:INFO:         cloudpickle: 1.6.0
2023-10-24 14:39:45,674:INFO:         deprecation: 2.1.0
2023-10-24 14:39:45,674:INFO:              xxhash: 3.4.1
2023-10-24 14:39:45,674:INFO:           wurlitzer: 2.0.1
2023-10-24 14:39:45,674:INFO:PyCaret optional dependencies:
2023-10-24 14:39:45,675:INFO:                shap: Not installed
2023-10-24 14:39:45,675:INFO:           interpret: Not installed
2023-10-24 14:39:45,675:INFO:                umap: Not installed
2023-10-24 14:39:45,675:INFO:     ydata_profiling: Not installed
2023-10-24 14:39:45,675:INFO:  explainerdashboard: Not installed
2023-10-24 14:39:45,675:INFO:             autoviz: Not installed
2023-10-24 14:39:45,675:INFO:           fairlearn: Not installed
2023-10-24 14:39:45,675:INFO:          deepchecks: Not installed
2023-10-24 14:39:45,675:INFO:             xgboost: Not installed
2023-10-24 14:39:45,675:INFO:            catboost: 1.0.4
2023-10-24 14:39:45,675:INFO:              kmodes: Not installed
2023-10-24 14:39:45,675:INFO:             mlxtend: Not installed
2023-10-24 14:39:45,675:INFO:       statsforecast: Not installed
2023-10-24 14:39:45,675:INFO:        tune_sklearn: Not installed
2023-10-24 14:39:45,675:INFO:                 ray: Not installed
2023-10-24 14:39:45,675:INFO:            hyperopt: Not installed
2023-10-24 14:39:45,675:INFO:              optuna: Not installed
2023-10-24 14:39:45,675:INFO:               skopt: Not installed
2023-10-24 14:39:45,675:INFO:              mlflow: 2.7.1
2023-10-24 14:39:45,675:INFO:              gradio: Not installed
2023-10-24 14:39:45,675:INFO:             fastapi: Not installed
2023-10-24 14:39:45,675:INFO:             uvicorn: Not installed
2023-10-24 14:39:45,675:INFO:              m2cgen: Not installed
2023-10-24 14:39:45,675:INFO:           evidently: Not installed
2023-10-24 14:39:45,675:INFO:               fugue: Not installed
2023-10-24 14:39:45,676:INFO:           streamlit: Not installed
2023-10-24 14:39:45,676:INFO:             prophet: Not installed
2023-10-24 14:39:45,676:INFO:None
2023-10-24 14:39:45,676:INFO:Set up data.
2023-10-24 14:39:45,718:INFO:Set up folding strategy.
2023-10-24 14:39:45,718:INFO:Set up train/test split.
2023-10-24 14:39:45,749:INFO:Set up index.
2023-10-24 14:39:45,750:INFO:Assigning column types.
2023-10-24 14:39:45,760:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 14:39:45,761:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 14:39:45,768:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 14:39:45,773:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 14:39:45,852:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:39:45,906:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:39:45,907:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:39:45,907:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:39:45,909:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 14:39:45,916:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 14:39:45,921:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 14:39:45,998:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:39:46,053:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:39:46,053:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:39:46,054:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:39:46,054:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 14:39:46,061:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 14:39:46,065:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 14:39:46,133:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:39:46,181:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:39:46,181:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:39:46,182:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:39:46,186:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 14:39:46,191:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 14:39:46,258:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:39:46,304:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:39:46,304:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:39:46,304:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:39:46,305:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 14:39:46,314:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 14:39:46,381:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:39:46,451:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:39:46,452:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:39:46,452:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:39:46,462:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 14:39:46,528:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:39:46,578:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:39:46,578:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:39:46,578:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:39:46,579:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 14:39:46,654:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:39:46,700:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:39:46,701:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:39:46,701:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:39:46,778:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:39:46,831:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:39:46,831:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:39:46,831:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:39:46,832:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 14:39:46,908:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:39:46,955:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:39:46,955:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:39:47,030:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:39:47,080:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:39:47,081:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:39:47,081:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 14:39:47,221:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:39:47,221:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:39:47,362:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:39:47,362:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:39:47,364:INFO:Preparing preprocessing pipeline...
2023-10-24 14:39:47,364:INFO:Set up simple imputation.
2023-10-24 14:39:47,370:INFO:Set up encoding of categorical features.
2023-10-24 14:39:47,372:INFO:Set up column name cleaning.
2023-10-24 14:39:47,544:INFO:Finished creating preprocessing pipeline.
2023-10-24 14:39:47,552:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             '...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx', 'is_day:idx',
                                             'is_in_shadow:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx',
                                                                    'is_day:idx',
                                                                    'is_in_shadow:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 14:39:47,552:INFO:Creating final display dataframe.
2023-10-24 14:39:47,817:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (34061, 46)
4        Transformed data shape  (34061, 62)
5   Transformed train set shape  (23842, 62)
6    Transformed test set shape  (10219, 62)
7              Numeric features           42
8          Categorical features            3
9      Rows with missing values        97.4%
10                   Preprocess         True
11              Imputation type       simple
12           Numeric imputation         mean
13       Categorical imputation         mode
14     Maximum one-hot encoding           25
15              Encoding method         None
16               Fold Generator        KFold
17                  Fold Number           10
18                     CPU Jobs           -1
19                      Use GPU        False
20               Log Experiment        False
21              Experiment Name        exp_A
22                          USI         929d
2023-10-24 14:39:47,949:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:39:47,949:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:39:48,074:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:39:48,074:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:39:48,075:INFO:setup() successfully completed in 2.41s...............
2023-10-24 14:39:48,075:INFO:Initializing create_model()
2023-10-24 14:39:48,075:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa4ca5711c0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 14:39:48,075:INFO:Checking exceptions
2023-10-24 14:39:48,079:INFO:Importing libraries
2023-10-24 14:39:48,079:INFO:Copying training dataset
2023-10-24 14:39:48,097:INFO:Defining folds
2023-10-24 14:39:48,098:INFO:Declaring metric variables
2023-10-24 14:39:48,098:INFO:Importing untrained model
2023-10-24 14:39:48,099:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 14:39:48,099:INFO:Starting cross validation
2023-10-24 14:39:48,101:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 14:39:52,449:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:39:52,449:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:39:52,449:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:39:52,449:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:39:52,449:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:39:52,450:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:39:52,450:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:39:52,450:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:39:52,450:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:39:52,450:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:39:52,450:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:39:52,450:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:39:52,450:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:39:52,450:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:39:52,450:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:39:52,450:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:39:52,450:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:39:52,450:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:39:55,067:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031958 seconds.
2023-10-24 14:39:55,069:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:39:55,069:INFO:[LightGBM] [Info] Total Bins 7568
2023-10-24 14:39:55,071:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 56
2023-10-24 14:39:55,076:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050173 seconds.
2023-10-24 14:39:55,076:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:39:55,076:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:39:55,076:INFO:[LightGBM] [Info] Total Bins 7559
2023-10-24 14:39:55,079:INFO:[LightGBM] [Info] Start training from score 638.315026
2023-10-24 14:39:55,079:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 56
2023-10-24 14:39:55,090:INFO:[LightGBM] [Info] Start training from score 638.498183
2023-10-24 14:39:55,093:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053182 seconds.
2023-10-24 14:39:55,093:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:39:55,093:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:39:55,093:INFO:[LightGBM] [Info] Total Bins 7556
2023-10-24 14:39:55,095:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 56
2023-10-24 14:39:55,097:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051062 seconds.
2023-10-24 14:39:55,097:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:39:55,097:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:39:55,097:INFO:[LightGBM] [Info] Total Bins 7562
2023-10-24 14:39:55,098:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 57
2023-10-24 14:39:55,100:INFO:[LightGBM] [Info] Start training from score 632.935130
2023-10-24 14:39:55,101:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055821 seconds.
2023-10-24 14:39:55,101:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:39:55,101:INFO:[LightGBM] [Info] Total Bins 7567
2023-10-24 14:39:55,101:INFO:[LightGBM] [Info] Start training from score 635.066755
2023-10-24 14:39:55,104:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 57
2023-10-24 14:39:55,110:INFO:[LightGBM] [Info] Start training from score 632.987592
2023-10-24 14:39:55,117:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055176 seconds.
2023-10-24 14:39:55,118:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:39:55,118:INFO:[LightGBM] [Info] Total Bins 7574
2023-10-24 14:39:55,119:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 57
2023-10-24 14:39:55,123:INFO:[LightGBM] [Info] Start training from score 637.332613
2023-10-24 14:40:04,208:INFO:Calculating mean and std
2023-10-24 14:40:04,211:INFO:Creating metrics dataframe
2023-10-24 14:40:04,217:INFO:Finalizing model
2023-10-24 14:40:04,537:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005419 seconds.
2023-10-24 14:40:04,537:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:40:04,538:INFO:[LightGBM] [Info] Total Bins 7689
2023-10-24 14:40:04,538:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 57
2023-10-24 14:40:04,539:INFO:[LightGBM] [Info] Start training from score 636.106585
2023-10-24 14:40:04,756:INFO:Uploading results into container
2023-10-24 14:40:04,757:INFO:Uploading model into container now
2023-10-24 14:40:04,764:INFO:_master_model_container: 1
2023-10-24 14:40:04,764:INFO:_display_container: 2
2023-10-24 14:40:04,765:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 14:40:04,765:INFO:create_model() successfully completed......................................
2023-10-24 14:40:05,069:INFO:Initializing tune_model()
2023-10-24 14:40:05,070:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa4ca5711c0>)
2023-10-24 14:40:05,070:INFO:Checking exceptions
2023-10-24 14:40:05,091:INFO:Copying training dataset
2023-10-24 14:40:05,105:INFO:Checking base model
2023-10-24 14:40:05,105:INFO:Base model : Light Gradient Boosting Machine
2023-10-24 14:40:05,106:INFO:Declaring metric variables
2023-10-24 14:40:05,106:INFO:Defining Hyperparameters
2023-10-24 14:40:05,191:INFO:Tuning with n_jobs=-1
2023-10-24 14:40:05,191:INFO:Initializing RandomizedSearchCV
2023-10-24 14:43:22,051:INFO:PyCaret RegressionExperiment
2023-10-24 14:43:22,051:INFO:Logging name: exp_A
2023-10-24 14:43:22,051:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 14:43:22,052:INFO:version 3.1.0
2023-10-24 14:43:22,052:INFO:Initializing setup()
2023-10-24 14:43:22,052:INFO:self.USI: 87f0
2023-10-24 14:43:22,052:INFO:self._variable_keys: {'exp_id', 'target_param', 'USI', 'data', 'fold_shuffle_param', 'log_plots_param', 'X_test', 'memory', 'idx', 'y', 'X', 'X_train', 'gpu_n_jobs_param', 'n_jobs_param', 'gpu_param', 'logging_param', 'fold_generator', 'pipeline', 'y_test', 'y_train', '_ml_usecase', '_available_plots', 'html_param', 'exp_name_log', 'transform_target_param', 'seed', 'fold_groups_param'}
2023-10-24 14:43:22,052:INFO:Checking environment
2023-10-24 14:43:22,052:INFO:python_version: 3.8.5
2023-10-24 14:43:22,052:INFO:python_build: ('default', 'Sep  4 2020 02:22:02')
2023-10-24 14:43:22,052:INFO:machine: x86_64
2023-10-24 14:43:22,052:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-10-24 14:43:22,053:INFO:Memory: svmem(total=8589934592, available=2247450624, percent=73.8, used=4632702976, free=228503552, active=2021257216, inactive=2005430272, wired=2611445760)
2023-10-24 14:43:22,053:INFO:Physical Core: 4
2023-10-24 14:43:22,053:INFO:Logical Core: 8
2023-10-24 14:43:22,053:INFO:Checking libraries
2023-10-24 14:43:22,054:INFO:System:
2023-10-24 14:43:22,054:INFO:    python: 3.8.5 (default, Sep  4 2020, 02:22:02)  [Clang 10.0.0 ]
2023-10-24 14:43:22,054:INFO:executable: /Users/kaja/opt/anaconda3/bin/python
2023-10-24 14:43:22,054:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-10-24 14:43:22,054:INFO:PyCaret required dependencies:
2023-10-24 14:43:22,054:INFO:                 pip: 23.3.1
2023-10-24 14:43:22,054:INFO:          setuptools: 68.2.2
2023-10-24 14:43:22,054:INFO:             pycaret: 3.1.0
2023-10-24 14:43:22,054:INFO:             IPython: 7.19.0
2023-10-24 14:43:22,054:INFO:          ipywidgets: 8.1.1
2023-10-24 14:43:22,054:INFO:                tqdm: 4.66.1
2023-10-24 14:43:22,054:INFO:               numpy: 1.23.5
2023-10-24 14:43:22,054:INFO:              pandas: 1.5.3
2023-10-24 14:43:22,054:INFO:              jinja2: 3.1.2
2023-10-24 14:43:22,054:INFO:               scipy: 1.10.1
2023-10-24 14:43:22,054:INFO:              joblib: 1.3.2
2023-10-24 14:43:22,054:INFO:             sklearn: 1.2.2
2023-10-24 14:43:22,054:INFO:                pyod: 1.1.0
2023-10-24 14:43:22,055:INFO:            imblearn: 0.11.0
2023-10-24 14:43:22,055:INFO:   category_encoders: 2.6.2
2023-10-24 14:43:22,055:INFO:            lightgbm: 4.1.0
2023-10-24 14:43:22,055:INFO:               numba: 0.58.1
2023-10-24 14:43:22,055:INFO:            requests: 2.28.2
2023-10-24 14:43:22,055:INFO:          matplotlib: 3.7.3
2023-10-24 14:43:22,055:INFO:          scikitplot: 0.3.7
2023-10-24 14:43:22,055:INFO:         yellowbrick: 1.5
2023-10-24 14:43:22,055:INFO:              plotly: 5.17.0
2023-10-24 14:43:22,055:INFO:    plotly-resampler: Not installed
2023-10-24 14:43:22,055:INFO:             kaleido: 0.2.1
2023-10-24 14:43:22,055:INFO:           schemdraw: 0.15
2023-10-24 14:43:22,055:INFO:         statsmodels: 0.14.0
2023-10-24 14:43:22,055:INFO:              sktime: 0.21.1
2023-10-24 14:43:22,055:INFO:               tbats: 1.1.3
2023-10-24 14:43:22,055:INFO:            pmdarima: 2.0.4
2023-10-24 14:43:22,055:INFO:              psutil: 5.9.6
2023-10-24 14:43:22,055:INFO:          markupsafe: 2.1.2
2023-10-24 14:43:22,055:INFO:             pickle5: Not installed
2023-10-24 14:43:22,055:INFO:         cloudpickle: 1.6.0
2023-10-24 14:43:22,055:INFO:         deprecation: 2.1.0
2023-10-24 14:43:22,055:INFO:              xxhash: 3.4.1
2023-10-24 14:43:22,055:INFO:           wurlitzer: 2.0.1
2023-10-24 14:43:22,055:INFO:PyCaret optional dependencies:
2023-10-24 14:43:22,055:INFO:                shap: Not installed
2023-10-24 14:43:22,055:INFO:           interpret: Not installed
2023-10-24 14:43:22,055:INFO:                umap: Not installed
2023-10-24 14:43:22,055:INFO:     ydata_profiling: Not installed
2023-10-24 14:43:22,055:INFO:  explainerdashboard: Not installed
2023-10-24 14:43:22,055:INFO:             autoviz: Not installed
2023-10-24 14:43:22,055:INFO:           fairlearn: Not installed
2023-10-24 14:43:22,055:INFO:          deepchecks: Not installed
2023-10-24 14:43:22,056:INFO:             xgboost: Not installed
2023-10-24 14:43:22,056:INFO:            catboost: 1.0.4
2023-10-24 14:43:22,056:INFO:              kmodes: Not installed
2023-10-24 14:43:22,056:INFO:             mlxtend: Not installed
2023-10-24 14:43:22,056:INFO:       statsforecast: Not installed
2023-10-24 14:43:22,056:INFO:        tune_sklearn: Not installed
2023-10-24 14:43:22,056:INFO:                 ray: Not installed
2023-10-24 14:43:22,056:INFO:            hyperopt: Not installed
2023-10-24 14:43:22,056:INFO:              optuna: Not installed
2023-10-24 14:43:22,056:INFO:               skopt: Not installed
2023-10-24 14:43:22,056:INFO:              mlflow: 2.7.1
2023-10-24 14:43:22,056:INFO:              gradio: Not installed
2023-10-24 14:43:22,056:INFO:             fastapi: Not installed
2023-10-24 14:43:22,056:INFO:             uvicorn: Not installed
2023-10-24 14:43:22,056:INFO:              m2cgen: Not installed
2023-10-24 14:43:22,056:INFO:           evidently: Not installed
2023-10-24 14:43:22,056:INFO:               fugue: Not installed
2023-10-24 14:43:22,056:INFO:           streamlit: Not installed
2023-10-24 14:43:22,056:INFO:             prophet: Not installed
2023-10-24 14:43:22,056:INFO:None
2023-10-24 14:43:22,056:INFO:Set up data.
2023-10-24 14:43:22,104:INFO:Set up folding strategy.
2023-10-24 14:43:22,105:INFO:Set up train/test split.
2023-10-24 14:43:22,139:INFO:Set up index.
2023-10-24 14:43:22,141:INFO:Assigning column types.
2023-10-24 14:43:22,158:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 14:43:22,159:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 14:43:22,165:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 14:43:22,170:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 14:43:22,244:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:43:22,290:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:43:22,292:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:43:22,292:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:43:22,293:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 14:43:22,297:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 14:43:22,302:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 14:43:22,371:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:43:22,464:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:43:22,465:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:43:22,465:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:43:22,465:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 14:43:22,483:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 14:43:22,492:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 14:43:22,567:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:43:22,615:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:43:22,616:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:43:22,616:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:43:22,621:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 14:43:22,626:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 14:43:22,699:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:43:22,745:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:43:22,745:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:43:22,745:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:43:22,746:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 14:43:22,756:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 14:43:22,824:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:43:22,866:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:43:22,867:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:43:22,867:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:43:22,876:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 14:43:22,938:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:43:22,981:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:43:22,988:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:43:22,988:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:43:22,989:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 14:43:23,066:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:43:23,109:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:43:23,110:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:43:23,110:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:43:23,185:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:43:23,229:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:43:23,230:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:43:23,231:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:43:23,231:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 14:43:23,308:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:43:23,358:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:43:23,359:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:43:23,459:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:43:23,504:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:43:23,504:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:43:23,504:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 14:43:23,632:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:43:23,633:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:43:23,751:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:43:23,751:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:43:23,755:INFO:Preparing preprocessing pipeline...
2023-10-24 14:43:23,755:INFO:Set up date feature engineering.
2023-10-24 14:43:23,755:INFO:Set up simple imputation.
2023-10-24 14:43:23,766:INFO:Set up encoding of ordinal features.
2023-10-24 14:43:23,786:INFO:Set up encoding of categorical features.
2023-10-24 14:43:23,788:INFO:Set up column name cleaning.
2023-10-24 14:43:24,032:INFO:Finished creating preprocessing pipeline.
2023-10-24 14:43:24,123:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_...
NaN   -1
dtype: int64},
                                                                        {'col': 'rime',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 14:43:24,123:INFO:Creating final display dataframe.
2023-10-24 14:43:24,619:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (34061, 50)
4        Transformed data shape  (34061, 52)
5   Transformed train set shape  (23842, 52)
6    Transformed test set shape  (10219, 52)
7              Ordinal features            4
8              Numeric features           44
9                 Date features            1
10         Categorical features            4
11     Rows with missing values        23.1%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18               Fold Generator        KFold
19                  Fold Number           10
20                     CPU Jobs           -1
21                      Use GPU        False
22               Log Experiment        False
23              Experiment Name        exp_A
24                          USI         87f0
2023-10-24 14:43:24,741:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:43:24,741:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:43:24,865:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:43:24,865:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:43:24,866:INFO:setup() successfully completed in 2.84s...............
2023-10-24 14:43:24,867:INFO:Initializing create_model()
2023-10-24 14:43:24,867:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dde26abb0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 14:43:24,867:INFO:Checking exceptions
2023-10-24 14:43:24,872:INFO:Importing libraries
2023-10-24 14:43:24,873:INFO:Copying training dataset
2023-10-24 14:43:24,895:INFO:Defining folds
2023-10-24 14:43:24,895:INFO:Declaring metric variables
2023-10-24 14:43:24,895:INFO:Importing untrained model
2023-10-24 14:43:24,896:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 14:43:24,896:INFO:Starting cross validation
2023-10-24 14:43:24,898:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 14:43:29,816:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:43:29,816:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:43:29,816:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:43:29,816:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:43:29,816:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:43:29,816:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:43:29,816:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:43:29,816:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:43:29,816:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:43:29,816:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:43:29,816:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:43:29,816:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:43:29,816:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:43:29,817:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:43:29,816:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:43:29,817:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:43:29,816:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:43:29,817:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:43:29,817:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:43:29,817:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:43:29,817:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:43:29,817:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:43:29,817:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:43:29,817:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:43:32,566:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038884 seconds.
2023-10-24 14:43:32,569:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:43:32,570:INFO:[LightGBM] [Info] Total Bins 6507
2023-10-24 14:43:32,570:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 48
2023-10-24 14:43:32,575:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.060677 seconds.
2023-10-24 14:43:32,575:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:43:32,575:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:43:32,575:INFO:[LightGBM] [Info] Total Bins 6511
2023-10-24 14:43:32,577:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 48
2023-10-24 14:43:32,578:INFO:[LightGBM] [Info] Start training from score 631.624808
2023-10-24 14:43:32,579:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039308 seconds.
2023-10-24 14:43:32,579:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:43:32,579:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:43:32,579:INFO:[LightGBM] [Info] Total Bins 6510
2023-10-24 14:43:32,580:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 48
2023-10-24 14:43:32,584:INFO:[LightGBM] [Info] Start training from score 631.036433
2023-10-24 14:43:32,584:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051423 seconds.
2023-10-24 14:43:32,584:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:43:32,584:INFO:[LightGBM] [Info] Total Bins 6505
2023-10-24 14:43:32,586:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 48
2023-10-24 14:43:32,587:INFO:[LightGBM] [Info] Start training from score 626.835846
2023-10-24 14:43:32,589:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041888 seconds.
2023-10-24 14:43:32,589:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:43:32,589:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:43:32,589:INFO:[LightGBM] [Info] Total Bins 6511
2023-10-24 14:43:32,590:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036077 seconds.
2023-10-24 14:43:32,590:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:43:32,590:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:43:32,590:INFO:[LightGBM] [Info] Total Bins 6496
2023-10-24 14:43:32,592:INFO:[LightGBM] [Info] Number of data points in the train set: 21457, number of used features: 48
2023-10-24 14:43:32,592:INFO:[LightGBM] [Info] Start training from score 629.291796[LightGBM] [Info] Number of data points in the train set: 21457, number of used features: 48
2023-10-24 14:43:32,592:INFO:
2023-10-24 14:43:32,595:INFO:[LightGBM] [Info] Start training from score 626.714401
2023-10-24 14:43:32,596:INFO:[LightGBM] [Info] Start training from score 624.465909
2023-10-24 14:43:32,597:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025890 seconds.
2023-10-24 14:43:32,597:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:43:32,597:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:43:32,598:INFO:[LightGBM] [Info] Total Bins 6513
2023-10-24 14:43:32,599:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 48
2023-10-24 14:43:32,605:INFO:[LightGBM] [Info] Start training from score 627.582936
2023-10-24 14:43:32,611:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039477 seconds.
2023-10-24 14:43:32,611:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:43:32,611:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:43:32,611:INFO:[LightGBM] [Info] Total Bins 6506
2023-10-24 14:43:32,612:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 48
2023-10-24 14:43:32,616:INFO:[LightGBM] [Info] Start training from score 629.037061
2023-10-24 14:43:39,580:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011888 seconds.
2023-10-24 14:43:39,580:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:43:39,580:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:43:39,581:INFO:[LightGBM] [Info] Total Bins 6500
2023-10-24 14:43:39,582:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 48
2023-10-24 14:43:39,583:INFO:[LightGBM] [Info] Start training from score 620.705419
2023-10-24 14:43:39,722:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012319 seconds.
2023-10-24 14:43:39,722:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:43:39,722:INFO:[LightGBM] [Info] Total Bins 6516
2023-10-24 14:43:39,723:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 48
2023-10-24 14:43:39,724:INFO:[LightGBM] [Info] Start training from score 633.990557
2023-10-24 14:43:41,167:INFO:Calculating mean and std
2023-10-24 14:43:41,171:INFO:Creating metrics dataframe
2023-10-24 14:43:41,177:INFO:Finalizing model
2023-10-24 14:43:41,536:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008414 seconds.
2023-10-24 14:43:41,536:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:43:41,536:INFO:[LightGBM] [Info] Total Bins 6533
2023-10-24 14:43:41,538:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 48
2023-10-24 14:43:41,539:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-24 14:43:41,992:INFO:Uploading results into container
2023-10-24 14:43:41,993:INFO:Uploading model into container now
2023-10-24 14:43:42,000:INFO:_master_model_container: 1
2023-10-24 14:43:42,000:INFO:_display_container: 2
2023-10-24 14:43:42,001:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 14:43:42,001:INFO:create_model() successfully completed......................................
2023-10-24 14:43:42,645:INFO:Initializing tune_model()
2023-10-24 14:43:42,646:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dde26abb0>)
2023-10-24 14:43:42,646:INFO:Checking exceptions
2023-10-24 14:43:42,666:INFO:Copying training dataset
2023-10-24 14:43:42,678:INFO:Checking base model
2023-10-24 14:43:42,678:INFO:Base model : Light Gradient Boosting Machine
2023-10-24 14:43:42,678:INFO:Declaring metric variables
2023-10-24 14:43:42,678:INFO:Defining Hyperparameters
2023-10-24 14:43:42,769:INFO:Tuning with n_jobs=-1
2023-10-24 14:43:42,769:INFO:Initializing RandomizedSearchCV
2023-10-24 14:44:03,498:WARNING:<ipython-input-15-49df83f3379d>:13: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  estimated_resampled = estimated.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 14:44:03,509:WARNING:<ipython-input-15-49df83f3379d>:14: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  test_resampled = test.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 14:44:03,572:INFO:PyCaret RegressionExperiment
2023-10-24 14:44:03,572:INFO:Logging name: exp_A
2023-10-24 14:44:03,572:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 14:44:03,572:INFO:version 3.1.0
2023-10-24 14:44:03,572:INFO:Initializing setup()
2023-10-24 14:44:03,572:INFO:self.USI: 8b71
2023-10-24 14:44:03,573:INFO:self._variable_keys: {'pipeline', 'fold_shuffle_param', 'idx', '_ml_usecase', 'transform_target_param', 'seed', 'X_test', 'gpu_n_jobs_param', 'exp_name_log', 'log_plots_param', 'X_train', 'memory', 'target_param', 'USI', 'fold_generator', 'logging_param', 'html_param', '_available_plots', 'data', 'y_train', 'y_test', 'fold_groups_param', 'gpu_param', 'X', 'n_jobs_param', 'y', 'exp_id'}
2023-10-24 14:44:03,573:INFO:Checking environment
2023-10-24 14:44:03,573:INFO:python_version: 3.8.5
2023-10-24 14:44:03,573:INFO:python_build: ('default', 'Sep  4 2020 02:22:02')
2023-10-24 14:44:03,573:INFO:machine: x86_64
2023-10-24 14:44:03,574:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-10-24 14:44:03,574:INFO:Memory: svmem(total=8589934592, available=2373419008, percent=72.4, used=4938539008, free=37859328, active=2338189312, inactive=2333229056, wired=2600349696)
2023-10-24 14:44:03,574:INFO:Physical Core: 4
2023-10-24 14:44:03,574:INFO:Logical Core: 8
2023-10-24 14:44:03,574:INFO:Checking libraries
2023-10-24 14:44:03,574:INFO:System:
2023-10-24 14:44:03,575:INFO:    python: 3.8.5 (default, Sep  4 2020, 02:22:02)  [Clang 10.0.0 ]
2023-10-24 14:44:03,575:INFO:executable: /Users/kaja/opt/anaconda3/bin/python
2023-10-24 14:44:03,575:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-10-24 14:44:03,575:INFO:PyCaret required dependencies:
2023-10-24 14:44:03,576:INFO:                 pip: 23.3.1
2023-10-24 14:44:03,576:INFO:          setuptools: 68.2.2
2023-10-24 14:44:03,576:INFO:             pycaret: 3.1.0
2023-10-24 14:44:03,576:INFO:             IPython: 7.19.0
2023-10-24 14:44:03,576:INFO:          ipywidgets: 8.1.1
2023-10-24 14:44:03,576:INFO:                tqdm: 4.66.1
2023-10-24 14:44:03,576:INFO:               numpy: 1.23.5
2023-10-24 14:44:03,576:INFO:              pandas: 1.5.3
2023-10-24 14:44:03,576:INFO:              jinja2: 3.1.2
2023-10-24 14:44:03,576:INFO:               scipy: 1.10.1
2023-10-24 14:44:03,576:INFO:              joblib: 1.3.2
2023-10-24 14:44:03,576:INFO:             sklearn: 1.2.2
2023-10-24 14:44:03,576:INFO:                pyod: 1.1.0
2023-10-24 14:44:03,576:INFO:            imblearn: 0.11.0
2023-10-24 14:44:03,576:INFO:   category_encoders: 2.6.2
2023-10-24 14:44:03,576:INFO:            lightgbm: 4.1.0
2023-10-24 14:44:03,576:INFO:               numba: 0.58.1
2023-10-24 14:44:03,576:INFO:            requests: 2.28.2
2023-10-24 14:44:03,577:INFO:          matplotlib: 3.7.3
2023-10-24 14:44:03,577:INFO:          scikitplot: 0.3.7
2023-10-24 14:44:03,577:INFO:         yellowbrick: 1.5
2023-10-24 14:44:03,577:INFO:              plotly: 5.17.0
2023-10-24 14:44:03,577:INFO:    plotly-resampler: Not installed
2023-10-24 14:44:03,577:INFO:             kaleido: 0.2.1
2023-10-24 14:44:03,577:INFO:           schemdraw: 0.15
2023-10-24 14:44:03,577:INFO:         statsmodels: 0.14.0
2023-10-24 14:44:03,577:INFO:              sktime: 0.21.1
2023-10-24 14:44:03,577:INFO:               tbats: 1.1.3
2023-10-24 14:44:03,577:INFO:            pmdarima: 2.0.4
2023-10-24 14:44:03,577:INFO:              psutil: 5.9.6
2023-10-24 14:44:03,577:INFO:          markupsafe: 2.1.2
2023-10-24 14:44:03,577:INFO:             pickle5: Not installed
2023-10-24 14:44:03,577:INFO:         cloudpickle: 1.6.0
2023-10-24 14:44:03,577:INFO:         deprecation: 2.1.0
2023-10-24 14:44:03,577:INFO:              xxhash: 3.4.1
2023-10-24 14:44:03,577:INFO:           wurlitzer: 2.0.1
2023-10-24 14:44:03,577:INFO:PyCaret optional dependencies:
2023-10-24 14:44:03,578:INFO:                shap: Not installed
2023-10-24 14:44:03,578:INFO:           interpret: Not installed
2023-10-24 14:44:03,578:INFO:                umap: Not installed
2023-10-24 14:44:03,578:INFO:     ydata_profiling: Not installed
2023-10-24 14:44:03,578:INFO:  explainerdashboard: Not installed
2023-10-24 14:44:03,578:INFO:             autoviz: Not installed
2023-10-24 14:44:03,578:INFO:           fairlearn: Not installed
2023-10-24 14:44:03,578:INFO:          deepchecks: Not installed
2023-10-24 14:44:03,578:INFO:             xgboost: Not installed
2023-10-24 14:44:03,578:INFO:            catboost: 1.0.4
2023-10-24 14:44:03,578:INFO:              kmodes: Not installed
2023-10-24 14:44:03,578:INFO:             mlxtend: Not installed
2023-10-24 14:44:03,578:INFO:       statsforecast: Not installed
2023-10-24 14:44:03,578:INFO:        tune_sklearn: Not installed
2023-10-24 14:44:03,578:INFO:                 ray: Not installed
2023-10-24 14:44:03,578:INFO:            hyperopt: Not installed
2023-10-24 14:44:03,578:INFO:              optuna: Not installed
2023-10-24 14:44:03,578:INFO:               skopt: Not installed
2023-10-24 14:44:03,579:INFO:              mlflow: 2.7.1
2023-10-24 14:44:03,579:INFO:              gradio: Not installed
2023-10-24 14:44:03,579:INFO:             fastapi: Not installed
2023-10-24 14:44:03,579:INFO:             uvicorn: Not installed
2023-10-24 14:44:03,579:INFO:              m2cgen: Not installed
2023-10-24 14:44:03,579:INFO:           evidently: Not installed
2023-10-24 14:44:03,579:INFO:               fugue: Not installed
2023-10-24 14:44:03,579:INFO:           streamlit: Not installed
2023-10-24 14:44:03,579:INFO:             prophet: Not installed
2023-10-24 14:44:03,579:INFO:None
2023-10-24 14:44:03,579:INFO:Set up data.
2023-10-24 14:44:03,626:INFO:Set up folding strategy.
2023-10-24 14:44:03,626:INFO:Set up train/test split.
2023-10-24 14:44:03,661:INFO:Set up index.
2023-10-24 14:44:03,664:INFO:Assigning column types.
2023-10-24 14:44:03,678:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 14:44:03,679:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 14:44:03,687:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 14:44:03,696:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 14:44:03,810:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:44:03,891:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:44:03,892:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:44:03,893:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:44:03,895:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 14:44:03,903:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 14:44:03,911:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 14:44:04,023:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:44:04,105:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:44:04,106:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:44:04,106:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:44:04,107:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 14:44:04,115:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 14:44:04,123:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 14:44:04,260:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:44:04,345:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:44:04,346:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:44:04,347:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:44:04,356:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 14:44:04,364:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 14:44:04,478:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:44:04,560:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:44:04,561:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:44:04,561:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:44:04,562:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 14:44:04,579:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 14:44:04,703:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:44:04,789:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:44:04,791:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:44:04,791:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:44:04,809:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 14:44:04,940:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:44:05,024:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:44:05,025:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:44:05,026:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:44:05,026:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 14:44:05,159:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:44:05,243:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:44:05,244:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:44:05,244:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:44:05,383:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:44:05,466:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:44:05,467:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:44:05,468:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:44:05,468:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 14:44:05,612:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:44:05,700:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:44:05,701:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:44:05,836:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:44:05,922:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:44:05,923:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:44:05,923:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 14:44:06,158:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:44:06,158:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:44:06,389:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:44:06,389:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:44:06,392:INFO:Preparing preprocessing pipeline...
2023-10-24 14:44:06,392:INFO:Set up simple imputation.
2023-10-24 14:44:06,402:INFO:Set up encoding of categorical features.
2023-10-24 14:44:06,405:INFO:Set up column name cleaning.
2023-10-24 14:44:06,837:INFO:Finished creating preprocessing pipeline.
2023-10-24 14:44:06,854:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             '...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx', 'is_day:idx',
                                             'is_in_shadow:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx',
                                                                    'is_day:idx',
                                                                    'is_in_shadow:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 14:44:06,854:INFO:Creating final display dataframe.
2023-10-24 14:44:07,320:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (34061, 46)
4        Transformed data shape  (34061, 62)
5   Transformed train set shape  (23842, 62)
6    Transformed test set shape  (10219, 62)
7              Numeric features           42
8          Categorical features            3
9      Rows with missing values        97.4%
10                   Preprocess         True
11              Imputation type       simple
12           Numeric imputation         mean
13       Categorical imputation         mode
14     Maximum one-hot encoding           25
15              Encoding method         None
16               Fold Generator        KFold
17                  Fold Number           10
18                     CPU Jobs           -1
19                      Use GPU        False
20               Log Experiment        False
21              Experiment Name        exp_A
22                          USI         8b71
2023-10-24 14:44:07,581:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:44:07,581:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:44:07,812:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:44:07,812:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:44:07,815:INFO:setup() successfully completed in 4.27s...............
2023-10-24 14:44:07,815:INFO:Initializing create_model()
2023-10-24 14:44:07,815:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa4ca557b20>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 14:44:07,815:INFO:Checking exceptions
2023-10-24 14:44:07,825:INFO:Importing libraries
2023-10-24 14:44:07,825:INFO:Copying training dataset
2023-10-24 14:44:07,854:INFO:Defining folds
2023-10-24 14:44:07,855:INFO:Declaring metric variables
2023-10-24 14:44:07,855:INFO:Importing untrained model
2023-10-24 14:44:07,856:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 14:44:07,856:INFO:Starting cross validation
2023-10-24 14:44:07,859:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 14:44:13,611:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:44:13,612:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:44:13,612:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:44:13,612:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:44:13,612:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:44:13,612:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:44:13,612:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:44:13,612:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:44:13,612:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:44:13,612:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:44:13,612:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:44:13,612:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:44:13,612:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:44:13,613:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:44:13,613:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:44:13,613:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:44:13,613:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:44:13,613:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:44:13,613:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:44:13,613:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:44:13,613:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:44:13,613:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:44:13,614:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:44:13,615:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 14:44:16,302:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.124690 seconds.
2023-10-24 14:44:16,302:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:44:16,302:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:44:16,302:INFO:[LightGBM] [Info] Total Bins 7567
2023-10-24 14:44:16,305:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 57
2023-10-24 14:44:16,313:INFO:[LightGBM] [Info] Start training from score 632.987592
2023-10-24 14:44:16,409:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.083632 seconds.
2023-10-24 14:44:16,410:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:44:16,410:INFO:[LightGBM] [Info] Total Bins 7552
2023-10-24 14:44:16,415:INFO:[LightGBM] [Info] Number of data points in the train set: 21457, number of used features: 56
2023-10-24 14:44:16,418:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.126636 seconds.
2023-10-24 14:44:16,418:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:44:16,418:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:44:16,418:INFO:[LightGBM] [Info] Total Bins 7574
2023-10-24 14:44:16,421:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 57
2023-10-24 14:44:16,424:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.100382 seconds.
2023-10-24 14:44:16,424:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:44:16,424:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:44:16,424:INFO:[LightGBM] [Info] Total Bins 7556
2023-10-24 14:44:16,426:INFO:[LightGBM] [Info] Start training from score 638.228207
2023-10-24 14:44:16,427:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 56
2023-10-24 14:44:16,428:INFO:[LightGBM] [Info] Start training from score 637.332613
2023-10-24 14:44:16,433:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.090541 seconds.
2023-10-24 14:44:16,433:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:44:16,434:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:44:16,434:INFO:[LightGBM] [Info] Total Bins 7568
2023-10-24 14:44:16,434:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.092121 seconds.
2023-10-24 14:44:16,434:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:44:16,434:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:44:16,434:INFO:[LightGBM] [Info] Total Bins 7562
2023-10-24 14:44:16,437:INFO:[LightGBM] [Info] Start training from score 632.935130
2023-10-24 14:44:16,438:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.084348 seconds.
2023-10-24 14:44:16,438:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:44:16,438:INFO:[LightGBM] [Info] Total Bins 7559
2023-10-24 14:44:16,439:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 56
2023-10-24 14:44:16,440:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 57
2023-10-24 14:44:16,443:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 56
2023-10-24 14:44:16,447:INFO:[LightGBM] [Info] Start training from score 638.315026
2023-10-24 14:44:16,447:INFO:[LightGBM] [Info] Start training from score 635.066755
2023-10-24 14:44:16,451:INFO:[LightGBM] [Info] Start training from score 638.498183
2023-10-24 14:44:16,458:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076071 seconds.
2023-10-24 14:44:16,458:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:44:16,458:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:44:16,458:INFO:[LightGBM] [Info] Total Bins 7556
2023-10-24 14:44:16,460:INFO:[LightGBM] [Info] Number of data points in the train set: 21457, number of used features: 57
2023-10-24 14:44:16,466:INFO:[LightGBM] [Info] Start training from score 635.025755
2023-10-24 14:44:31,865:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061610 seconds.
2023-10-24 14:44:31,866:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:44:31,866:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:44:31,866:INFO:[LightGBM] [Info] Total Bins 7563
2023-10-24 14:44:31,869:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 55
2023-10-24 14:44:31,877:INFO:[LightGBM] [Info] Start training from score 635.296336
2023-10-24 14:44:32,031:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040435 seconds.
2023-10-24 14:44:32,031:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:44:32,031:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:44:32,031:INFO:[LightGBM] [Info] Total Bins 7552
2023-10-24 14:44:32,033:INFO:[LightGBM] [Info] Number of data points in the train set: 21458, number of used features: 55
2023-10-24 14:44:32,036:INFO:[LightGBM] [Info] Start training from score 637.380303
2023-10-24 14:44:41,940:INFO:Calculating mean and std
2023-10-24 14:44:41,951:INFO:Creating metrics dataframe
2023-10-24 14:44:41,966:INFO:Finalizing model
2023-10-24 14:44:42,553:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023312 seconds.
2023-10-24 14:44:42,554:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:44:42,554:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:44:42,554:INFO:[LightGBM] [Info] Total Bins 7689
2023-10-24 14:44:42,555:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 57
2023-10-24 14:44:42,559:INFO:[LightGBM] [Info] Start training from score 636.106585
2023-10-24 14:44:51,445:INFO:Uploading results into container
2023-10-24 14:44:51,446:INFO:Uploading model into container now
2023-10-24 14:44:51,459:INFO:_master_model_container: 1
2023-10-24 14:44:51,459:INFO:_display_container: 2
2023-10-24 14:44:51,460:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 14:44:51,460:INFO:create_model() successfully completed......................................
2023-10-24 14:44:52,046:INFO:Initializing tune_model()
2023-10-24 14:44:52,046:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa4ca557b20>)
2023-10-24 14:44:52,046:INFO:Checking exceptions
2023-10-24 14:44:52,086:INFO:Copying training dataset
2023-10-24 14:44:52,101:INFO:Checking base model
2023-10-24 14:44:52,102:INFO:Base model : Light Gradient Boosting Machine
2023-10-24 14:44:52,103:INFO:Declaring metric variables
2023-10-24 14:44:52,103:INFO:Defining Hyperparameters
2023-10-24 14:44:52,202:INFO:Tuning with n_jobs=-1
2023-10-24 14:44:52,202:INFO:Initializing RandomizedSearchCV
2023-10-24 14:50:12,139:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-24 14:50:12,154:INFO:Hyperparameter search completed
2023-10-24 14:50:12,155:INFO:SubProcess create_model() called ==================================
2023-10-24 14:50:12,159:INFO:Initializing create_model()
2023-10-24 14:50:12,159:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dde26abb0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9d43f51e20>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-24 14:50:12,159:INFO:Checking exceptions
2023-10-24 14:50:12,160:INFO:Importing libraries
2023-10-24 14:50:12,161:INFO:Copying training dataset
2023-10-24 14:50:12,222:INFO:Defining folds
2023-10-24 14:50:12,222:INFO:Declaring metric variables
2023-10-24 14:50:12,225:INFO:Importing untrained model
2023-10-24 14:50:12,225:INFO:Declaring custom model
2023-10-24 14:50:12,234:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 14:50:12,234:INFO:Starting cross validation
2023-10-24 14:50:12,241:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 14:51:31,627:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-24 14:51:31,638:INFO:Hyperparameter search completed
2023-10-24 14:51:31,638:INFO:SubProcess create_model() called ==================================
2023-10-24 14:51:31,641:INFO:Initializing create_model()
2023-10-24 14:51:31,641:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa4ca557b20>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa4b4b67a90>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-24 14:51:31,642:INFO:Checking exceptions
2023-10-24 14:51:31,642:INFO:Importing libraries
2023-10-24 14:51:31,643:INFO:Copying training dataset
2023-10-24 14:51:31,685:INFO:Defining folds
2023-10-24 14:51:31,686:INFO:Declaring metric variables
2023-10-24 14:51:31,687:INFO:Importing untrained model
2023-10-24 14:51:31,687:INFO:Declaring custom model
2023-10-24 14:51:31,691:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 14:51:31,691:INFO:Starting cross validation
2023-10-24 14:51:31,694:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 14:52:12,723:INFO:Calculating mean and std
2023-10-24 14:52:12,726:INFO:Creating metrics dataframe
2023-10-24 14:52:12,735:INFO:Finalizing model
2023-10-24 14:52:13,087:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:52:13,088:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:52:13,088:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:52:13,170:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:52:13,170:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:52:13,170:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:52:13,211:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021003 seconds.
2023-10-24 14:52:13,211:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:52:13,213:INFO:[LightGBM] [Info] Total Bins 6533
2023-10-24 14:52:13,215:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 48
2023-10-24 14:52:13,222:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-24 14:52:28,716:INFO:Uploading results into container
2023-10-24 14:52:28,718:INFO:Uploading model into container now
2023-10-24 14:52:28,719:INFO:_master_model_container: 2
2023-10-24 14:52:28,719:INFO:_display_container: 3
2023-10-24 14:52:28,721:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-24 14:52:28,721:INFO:create_model() successfully completed......................................
2023-10-24 14:52:29,119:INFO:SubProcess create_model() end ==================================
2023-10-24 14:52:29,119:INFO:choose_better activated
2023-10-24 14:52:29,120:INFO:SubProcess create_model() called ==================================
2023-10-24 14:52:29,121:INFO:Initializing create_model()
2023-10-24 14:52:29,121:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dde26abb0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 14:52:29,121:INFO:Checking exceptions
2023-10-24 14:52:29,123:INFO:Importing libraries
2023-10-24 14:52:29,123:INFO:Copying training dataset
2023-10-24 14:52:29,146:INFO:Defining folds
2023-10-24 14:52:29,146:INFO:Declaring metric variables
2023-10-24 14:52:29,146:INFO:Importing untrained model
2023-10-24 14:52:29,146:INFO:Declaring custom model
2023-10-24 14:52:29,147:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 14:52:29,148:INFO:Starting cross validation
2023-10-24 14:52:29,149:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 14:52:35,273:INFO:Calculating mean and std
2023-10-24 14:52:35,277:INFO:Creating metrics dataframe
2023-10-24 14:52:35,283:INFO:Finalizing model
2023-10-24 14:52:35,591:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:52:35,591:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:52:35,591:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:52:35,675:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 14:52:35,675:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 14:52:35,675:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 14:52:35,717:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018432 seconds.
2023-10-24 14:52:35,717:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:52:35,719:INFO:[LightGBM] [Info] Total Bins 7683
2023-10-24 14:52:35,722:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 54
2023-10-24 14:52:35,736:INFO:[LightGBM] [Info] Start training from score 636.106585
2023-10-24 14:52:41,437:INFO:Calculating mean and std
2023-10-24 14:52:41,438:INFO:Creating metrics dataframe
2023-10-24 14:52:41,440:INFO:Finalizing model
2023-10-24 14:52:41,800:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008367 seconds.
2023-10-24 14:52:41,801:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:52:41,801:INFO:[LightGBM] [Info] Total Bins 6533
2023-10-24 14:52:41,801:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 48
2023-10-24 14:52:41,802:INFO:[LightGBM] [Info] Start training from score 628.128540
2023-10-24 14:52:42,707:INFO:Uploading results into container
2023-10-24 14:52:42,708:INFO:Uploading model into container now
2023-10-24 14:52:42,708:INFO:_master_model_container: 3
2023-10-24 14:52:42,708:INFO:_display_container: 4
2023-10-24 14:52:42,709:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 14:52:42,709:INFO:create_model() successfully completed......................................
2023-10-24 14:52:42,811:INFO:SubProcess create_model() end ==================================
2023-10-24 14:52:42,813:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8738
2023-10-24 14:52:42,814:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8737
2023-10-24 14:52:42,814:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-24 14:52:42,815:INFO:choose_better completed
2023-10-24 14:52:42,815:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-24 14:52:42,821:INFO:_master_model_container: 3
2023-10-24 14:52:42,822:INFO:_display_container: 3
2023-10-24 14:52:42,822:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 14:52:42,822:INFO:tune_model() successfully completed......................................
2023-10-24 14:52:42,925:INFO:Initializing ensemble_model()
2023-10-24 14:52:42,925:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dde26abb0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-24 14:52:42,925:INFO:Checking exceptions
2023-10-24 14:52:42,955:INFO:Importing libraries
2023-10-24 14:52:42,955:INFO:Copying training dataset
2023-10-24 14:52:42,955:INFO:Checking base model
2023-10-24 14:52:42,955:INFO:Base model : Light Gradient Boosting Machine
2023-10-24 14:52:42,956:INFO:Importing untrained ensembler
2023-10-24 14:52:42,956:INFO:Ensemble method set to Bagging
2023-10-24 14:52:42,957:INFO:SubProcess create_model() called ==================================
2023-10-24 14:52:42,958:INFO:Initializing create_model()
2023-10-24 14:52:42,958:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dde26abb0>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9dd7ed4bb0>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 14:52:42,958:INFO:Checking exceptions
2023-10-24 14:52:42,958:INFO:Importing libraries
2023-10-24 14:52:42,959:INFO:Copying training dataset
2023-10-24 14:52:42,978:INFO:Defining folds
2023-10-24 14:52:42,978:INFO:Declaring metric variables
2023-10-24 14:52:42,978:INFO:Importing untrained model
2023-10-24 14:52:42,978:INFO:Declaring custom model
2023-10-24 14:52:42,979:INFO:Bagging Regressor Imported successfully
2023-10-24 14:52:42,980:INFO:Starting cross validation
2023-10-24 14:52:42,981:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 14:52:54,722:INFO:Uploading results into container
2023-10-24 14:52:54,723:INFO:Uploading model into container now
2023-10-24 14:52:54,724:INFO:_master_model_container: 2
2023-10-24 14:52:54,724:INFO:_display_container: 3
2023-10-24 14:52:54,725:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-24 14:52:54,725:INFO:create_model() successfully completed......................................
2023-10-24 14:52:55,087:INFO:SubProcess create_model() end ==================================
2023-10-24 14:52:55,087:INFO:choose_better activated
2023-10-24 14:52:55,087:INFO:SubProcess create_model() called ==================================
2023-10-24 14:52:55,088:INFO:Initializing create_model()
2023-10-24 14:52:55,088:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa4ca557b20>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 14:52:55,088:INFO:Checking exceptions
2023-10-24 14:52:55,090:INFO:Importing libraries
2023-10-24 14:52:55,090:INFO:Copying training dataset
2023-10-24 14:52:55,113:INFO:Defining folds
2023-10-24 14:52:55,114:INFO:Declaring metric variables
2023-10-24 14:52:55,114:INFO:Importing untrained model
2023-10-24 14:52:55,114:INFO:Declaring custom model
2023-10-24 14:52:55,115:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 14:52:55,115:INFO:Starting cross validation
2023-10-24 14:52:55,117:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 14:53:20,628:INFO:Calculating mean and std
2023-10-24 14:53:20,631:INFO:Creating metrics dataframe
2023-10-24 14:53:20,633:INFO:Finalizing model
2023-10-24 14:53:21,056:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023034 seconds.
2023-10-24 14:53:21,056:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:53:21,056:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:53:21,056:INFO:[LightGBM] [Info] Total Bins 7689
2023-10-24 14:53:21,057:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 57
2023-10-24 14:53:21,060:INFO:[LightGBM] [Info] Start training from score 636.106585
2023-10-24 14:53:28,636:INFO:Uploading results into container
2023-10-24 14:53:28,637:INFO:Uploading model into container now
2023-10-24 14:53:28,637:INFO:_master_model_container: 3
2023-10-24 14:53:28,637:INFO:_display_container: 4
2023-10-24 14:53:28,638:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 14:53:28,638:INFO:create_model() successfully completed......................................
2023-10-24 14:53:28,735:INFO:SubProcess create_model() end ==================================
2023-10-24 14:53:28,736:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.865
2023-10-24 14:53:28,737:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8657
2023-10-24 14:53:28,738:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) is best model
2023-10-24 14:53:28,738:INFO:choose_better completed
2023-10-24 14:53:28,744:INFO:_master_model_container: 3
2023-10-24 14:53:28,744:INFO:_display_container: 3
2023-10-24 14:53:28,746:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-24 14:53:28,746:INFO:tune_model() successfully completed......................................
2023-10-24 14:53:28,843:INFO:Initializing ensemble_model()
2023-10-24 14:53:28,843:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa4ca557b20>, estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-24 14:53:28,843:INFO:Checking exceptions
2023-10-24 14:53:28,870:INFO:Importing libraries
2023-10-24 14:53:28,871:INFO:Copying training dataset
2023-10-24 14:53:28,871:INFO:Checking base model
2023-10-24 14:53:28,871:INFO:Base model : Light Gradient Boosting Machine
2023-10-24 14:53:28,871:INFO:Importing untrained ensembler
2023-10-24 14:53:28,871:INFO:Ensemble method set to Bagging
2023-10-24 14:53:28,872:INFO:SubProcess create_model() called ==================================
2023-10-24 14:53:28,874:INFO:Initializing create_model()
2023-10-24 14:53:28,875:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa4ca557b20>, estimator=BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                                         feature_fraction=0.4,
                                         min_child_samples=41,
                                         min_split_gain=0.9, n_estimators=260,
                                         n_jobs=-1, num_leaves=70,
                                         random_state=123, reg_alpha=2,
                                         reg_lambda=3),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa4ca557610>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 14:53:28,875:INFO:Checking exceptions
2023-10-24 14:53:28,875:INFO:Importing libraries
2023-10-24 14:53:28,875:INFO:Copying training dataset
2023-10-24 14:53:28,896:INFO:Defining folds
2023-10-24 14:53:28,896:INFO:Declaring metric variables
2023-10-24 14:53:28,897:INFO:Importing untrained model
2023-10-24 14:53:28,897:INFO:Declaring custom model
2023-10-24 14:53:28,898:INFO:Bagging Regressor Imported successfully
2023-10-24 14:53:28,898:INFO:Starting cross validation
2023-10-24 14:53:28,900:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 14:56:12,382:INFO:Calculating mean and std
2023-10-24 14:56:12,393:INFO:Creating metrics dataframe
2023-10-24 14:56:12,406:INFO:Finalizing model
2023-10-24 14:56:12,888:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017871 seconds.
2023-10-24 14:56:12,889:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:56:12,889:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:56:12,889:INFO:[LightGBM] [Info] Total Bins 6533
2023-10-24 14:56:12,890:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 48
2023-10-24 14:56:12,893:INFO:[LightGBM] [Info] Start training from score 626.831517
2023-10-24 14:56:20,453:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016579 seconds.
2023-10-24 14:56:20,453:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:56:20,453:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:56:20,454:INFO:[LightGBM] [Info] Total Bins 6533
2023-10-24 14:56:20,455:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 48
2023-10-24 14:56:20,457:INFO:[LightGBM] [Info] Start training from score 640.013980
2023-10-24 14:56:27,902:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014343 seconds.
2023-10-24 14:56:27,902:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:56:27,902:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:56:27,903:INFO:[LightGBM] [Info] Total Bins 6533
2023-10-24 14:56:27,904:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 48
2023-10-24 14:56:27,907:INFO:[LightGBM] [Info] Start training from score 623.946930
2023-10-24 14:56:35,168:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017885 seconds.
2023-10-24 14:56:35,168:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:56:35,168:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:56:35,168:INFO:[LightGBM] [Info] Total Bins 6533
2023-10-24 14:56:35,169:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 48
2023-10-24 14:56:35,171:INFO:[LightGBM] [Info] Start training from score 632.335152
2023-10-24 14:56:42,531:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018134 seconds.
2023-10-24 14:56:42,531:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:56:42,532:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:56:42,532:INFO:[LightGBM] [Info] Total Bins 6533
2023-10-24 14:56:42,533:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 48
2023-10-24 14:56:42,535:INFO:[LightGBM] [Info] Start training from score 620.070240
2023-10-24 14:56:50,006:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020565 seconds.
2023-10-24 14:56:50,006:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:56:50,006:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:56:50,006:INFO:[LightGBM] [Info] Total Bins 6533
2023-10-24 14:56:50,007:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 48
2023-10-24 14:56:50,010:INFO:[LightGBM] [Info] Start training from score 635.137343
2023-10-24 14:56:57,542:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014371 seconds.
2023-10-24 14:56:57,543:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:56:57,543:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:56:57,544:INFO:[LightGBM] [Info] Total Bins 6533
2023-10-24 14:56:57,545:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 48
2023-10-24 14:56:57,547:INFO:[LightGBM] [Info] Start training from score 620.066941
2023-10-24 14:57:05,537:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020266 seconds.
2023-10-24 14:57:05,537:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:57:05,537:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:57:05,537:INFO:[LightGBM] [Info] Total Bins 6533
2023-10-24 14:57:05,538:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 48
2023-10-24 14:57:05,540:INFO:[LightGBM] [Info] Start training from score 623.069874
2023-10-24 14:57:13,000:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019346 seconds.
2023-10-24 14:57:13,000:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:57:13,000:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:57:13,001:INFO:[LightGBM] [Info] Total Bins 6533
2023-10-24 14:57:13,002:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 48
2023-10-24 14:57:13,004:INFO:[LightGBM] [Info] Start training from score 633.817057
2023-10-24 14:57:20,099:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025190 seconds.
2023-10-24 14:57:20,100:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:57:20,100:INFO:[LightGBM] [Info] Total Bins 6533
2023-10-24 14:57:20,104:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 48
2023-10-24 14:57:20,108:INFO:[LightGBM] [Info] Start training from score 641.113408
2023-10-24 14:57:28,101:INFO:Uploading results into container
2023-10-24 14:57:28,103:INFO:Uploading model into container now
2023-10-24 14:57:28,105:INFO:_master_model_container: 4
2023-10-24 14:57:28,105:INFO:_display_container: 4
2023-10-24 14:57:28,107:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-24 14:57:28,107:INFO:create_model() successfully completed......................................
2023-10-24 14:57:28,541:INFO:SubProcess create_model() end ==================================
2023-10-24 14:57:28,548:INFO:_master_model_container: 4
2023-10-24 14:57:28,548:INFO:_display_container: 4
2023-10-24 14:57:28,550:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-24 14:57:28,550:INFO:ensemble_model() successfully completed......................................
2023-10-24 14:57:28,655:INFO:Initializing finalize_model()
2023-10-24 14:57:28,655:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dde26abb0>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-24 14:57:28,656:INFO:Finalizing BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-24 14:57:28,696:INFO:Initializing create_model()
2023-10-24 14:57:28,697:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dde26abb0>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-24 14:57:28,697:INFO:Checking exceptions
2023-10-24 14:57:28,699:INFO:Importing libraries
2023-10-24 14:57:28,700:INFO:Copying training dataset
2023-10-24 14:57:28,701:INFO:Defining folds
2023-10-24 14:57:28,701:INFO:Declaring metric variables
2023-10-24 14:57:28,702:INFO:Importing untrained model
2023-10-24 14:57:28,702:INFO:Declaring custom model
2023-10-24 14:57:28,703:INFO:Bagging Regressor Imported successfully
2023-10-24 14:57:28,706:INFO:Cross validation set to False
2023-10-24 14:57:28,706:INFO:Fitting Model
2023-10-24 14:57:29,296:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020358 seconds.
2023-10-24 14:57:29,297:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:57:29,297:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:57:29,297:INFO:[LightGBM] [Info] Total Bins 6648
2023-10-24 14:57:29,299:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 48
2023-10-24 14:57:29,302:INFO:[LightGBM] [Info] Start training from score 634.491655
2023-10-24 14:57:36,812:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020424 seconds.
2023-10-24 14:57:36,813:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:57:36,813:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:57:36,813:INFO:[LightGBM] [Info] Total Bins 6648
2023-10-24 14:57:36,815:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 48
2023-10-24 14:57:36,817:INFO:[LightGBM] [Info] Start training from score 635.470959
2023-10-24 14:57:44,235:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016120 seconds.
2023-10-24 14:57:44,236:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:57:44,236:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:57:44,236:INFO:[LightGBM] [Info] Total Bins 6648
2023-10-24 14:57:44,237:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 48
2023-10-24 14:57:44,240:INFO:[LightGBM] [Info] Start training from score 634.053589
2023-10-24 14:57:51,923:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018848 seconds.
2023-10-24 14:57:51,923:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:57:51,923:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:57:51,923:INFO:[LightGBM] [Info] Total Bins 6648
2023-10-24 14:57:51,924:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 48
2023-10-24 14:57:51,927:INFO:[LightGBM] [Info] Start training from score 635.251785
2023-10-24 14:57:59,256:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015380 seconds.
2023-10-24 14:57:59,256:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:57:59,257:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:57:59,257:INFO:[LightGBM] [Info] Total Bins 6648
2023-10-24 14:57:59,258:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 48
2023-10-24 14:57:59,261:INFO:[LightGBM] [Info] Start training from score 627.555784
2023-10-24 14:58:06,834:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021435 seconds.
2023-10-24 14:58:06,834:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:58:06,834:INFO:[LightGBM] [Info] Total Bins 6648
2023-10-24 14:58:06,835:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 48
2023-10-24 14:58:06,838:INFO:[LightGBM] [Info] Start training from score 638.162596
2023-10-24 14:58:15,080:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015029 seconds.
2023-10-24 14:58:15,080:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:58:15,080:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:58:15,081:INFO:[LightGBM] [Info] Total Bins 6648
2023-10-24 14:58:15,082:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 48
2023-10-24 14:58:15,085:INFO:[LightGBM] [Info] Start training from score 633.181363
2023-10-24 14:58:22,537:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015126 seconds.
2023-10-24 14:58:22,538:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:58:22,538:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:58:22,538:INFO:[LightGBM] [Info] Total Bins 6648
2023-10-24 14:58:22,539:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 48
2023-10-24 14:58:22,542:INFO:[LightGBM] [Info] Start training from score 611.992287
2023-10-24 14:58:30,240:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025049 seconds.
2023-10-24 14:58:30,241:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:58:30,241:INFO:[LightGBM] [Info] Total Bins 6648
2023-10-24 14:58:30,243:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 48
2023-10-24 14:58:30,246:INFO:[LightGBM] [Info] Start training from score 638.181417
2023-10-24 14:58:38,691:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019922 seconds.
2023-10-24 14:58:38,691:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 14:58:38,691:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 14:58:38,691:INFO:[LightGBM] [Info] Total Bins 6648
2023-10-24 14:58:38,692:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 48
2023-10-24 14:58:38,695:INFO:[LightGBM] [Info] Start training from score 639.502137
2023-10-24 14:58:46,083:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-24 14:58:46,084:INFO:create_model() successfully completed......................................
2023-10-24 14:58:46,198:INFO:_master_model_container: 4
2023-10-24 14:58:46,198:INFO:_display_container: 4
2023-10-24 14:58:46,340:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-24 14:58:46,340:INFO:finalize_model() successfully completed......................................
2023-10-24 14:58:46,724:INFO:Initializing save_model()
2023-10-24 14:58:46,724:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), model_name=final_model_for_location_A, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_...
NaN   -1
dtype: int64},
                                                                        {'col': 'rime',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-24 14:58:46,724:INFO:Adding model into prep_pipe
2023-10-24 14:58:46,724:WARNING:Only Model saved as it was a pipeline.
2023-10-24 14:58:46,806:INFO:final_model_for_location_A.pkl saved in current working directory
2023-10-24 14:58:46,951:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-24 14:58:46,951:INFO:save_model() successfully completed......................................
2023-10-24 14:58:47,245:INFO:PyCaret RegressionExperiment
2023-10-24 14:58:47,246:INFO:Logging name: exp_B
2023-10-24 14:58:47,246:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 14:58:47,246:INFO:version 3.1.0
2023-10-24 14:58:47,246:INFO:Initializing setup()
2023-10-24 14:58:47,246:INFO:self.USI: f3ca
2023-10-24 14:58:47,246:INFO:self._variable_keys: {'exp_id', 'target_param', 'USI', 'data', 'fold_shuffle_param', 'log_plots_param', 'X_test', 'memory', 'idx', 'y', 'X', 'X_train', 'gpu_n_jobs_param', 'n_jobs_param', 'gpu_param', 'logging_param', 'fold_generator', 'pipeline', 'y_test', 'y_train', '_ml_usecase', '_available_plots', 'html_param', 'exp_name_log', 'transform_target_param', 'seed', 'fold_groups_param'}
2023-10-24 14:58:47,246:INFO:Checking environment
2023-10-24 14:58:47,246:INFO:python_version: 3.8.5
2023-10-24 14:58:47,246:INFO:python_build: ('default', 'Sep  4 2020 02:22:02')
2023-10-24 14:58:47,246:INFO:machine: x86_64
2023-10-24 14:58:47,246:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-10-24 14:58:47,246:INFO:Memory: svmem(total=8589934592, available=2488258560, percent=71.0, used=4155047936, free=578322432, active=1910460416, inactive=1904545792, wired=2244587520)
2023-10-24 14:58:47,246:INFO:Physical Core: 4
2023-10-24 14:58:47,246:INFO:Logical Core: 8
2023-10-24 14:58:47,246:INFO:Checking libraries
2023-10-24 14:58:47,246:INFO:System:
2023-10-24 14:58:47,247:INFO:    python: 3.8.5 (default, Sep  4 2020, 02:22:02)  [Clang 10.0.0 ]
2023-10-24 14:58:47,247:INFO:executable: /Users/kaja/opt/anaconda3/bin/python
2023-10-24 14:58:47,247:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-10-24 14:58:47,247:INFO:PyCaret required dependencies:
2023-10-24 14:58:47,247:INFO:                 pip: 23.3.1
2023-10-24 14:58:47,247:INFO:          setuptools: 68.2.2
2023-10-24 14:58:47,247:INFO:             pycaret: 3.1.0
2023-10-24 14:58:47,247:INFO:             IPython: 7.19.0
2023-10-24 14:58:47,247:INFO:          ipywidgets: 8.1.1
2023-10-24 14:58:47,247:INFO:                tqdm: 4.66.1
2023-10-24 14:58:47,247:INFO:               numpy: 1.23.5
2023-10-24 14:58:47,247:INFO:              pandas: 1.5.3
2023-10-24 14:58:47,247:INFO:              jinja2: 3.1.2
2023-10-24 14:58:47,247:INFO:               scipy: 1.10.1
2023-10-24 14:58:47,247:INFO:              joblib: 1.3.2
2023-10-24 14:58:47,247:INFO:             sklearn: 1.2.2
2023-10-24 14:58:47,247:INFO:                pyod: 1.1.0
2023-10-24 14:58:47,247:INFO:            imblearn: 0.11.0
2023-10-24 14:58:47,247:INFO:   category_encoders: 2.6.2
2023-10-24 14:58:47,248:INFO:            lightgbm: 4.1.0
2023-10-24 14:58:47,248:INFO:               numba: 0.58.1
2023-10-24 14:58:47,248:INFO:            requests: 2.28.2
2023-10-24 14:58:47,248:INFO:          matplotlib: 3.7.3
2023-10-24 14:58:47,248:INFO:          scikitplot: 0.3.7
2023-10-24 14:58:47,248:INFO:         yellowbrick: 1.5
2023-10-24 14:58:47,248:INFO:              plotly: 5.17.0
2023-10-24 14:58:47,248:INFO:    plotly-resampler: Not installed
2023-10-24 14:58:47,248:INFO:             kaleido: 0.2.1
2023-10-24 14:58:47,248:INFO:           schemdraw: 0.15
2023-10-24 14:58:47,248:INFO:         statsmodels: 0.14.0
2023-10-24 14:58:47,248:INFO:              sktime: 0.21.1
2023-10-24 14:58:47,248:INFO:               tbats: 1.1.3
2023-10-24 14:58:47,248:INFO:            pmdarima: 2.0.4
2023-10-24 14:58:47,248:INFO:              psutil: 5.9.6
2023-10-24 14:58:47,248:INFO:          markupsafe: 2.1.2
2023-10-24 14:58:47,248:INFO:             pickle5: Not installed
2023-10-24 14:58:47,248:INFO:         cloudpickle: 1.6.0
2023-10-24 14:58:47,248:INFO:         deprecation: 2.1.0
2023-10-24 14:58:47,248:INFO:              xxhash: 3.4.1
2023-10-24 14:58:47,248:INFO:           wurlitzer: 2.0.1
2023-10-24 14:58:47,249:INFO:PyCaret optional dependencies:
2023-10-24 14:58:47,249:INFO:                shap: Not installed
2023-10-24 14:58:47,249:INFO:           interpret: Not installed
2023-10-24 14:58:47,249:INFO:                umap: Not installed
2023-10-24 14:58:47,249:INFO:     ydata_profiling: Not installed
2023-10-24 14:58:47,249:INFO:  explainerdashboard: Not installed
2023-10-24 14:58:47,249:INFO:             autoviz: Not installed
2023-10-24 14:58:47,249:INFO:           fairlearn: Not installed
2023-10-24 14:58:47,249:INFO:          deepchecks: Not installed
2023-10-24 14:58:47,249:INFO:             xgboost: Not installed
2023-10-24 14:58:47,249:INFO:            catboost: 1.0.4
2023-10-24 14:58:47,249:INFO:              kmodes: Not installed
2023-10-24 14:58:47,249:INFO:             mlxtend: Not installed
2023-10-24 14:58:47,249:INFO:       statsforecast: Not installed
2023-10-24 14:58:47,249:INFO:        tune_sklearn: Not installed
2023-10-24 14:58:47,249:INFO:                 ray: Not installed
2023-10-24 14:58:47,249:INFO:            hyperopt: Not installed
2023-10-24 14:58:47,249:INFO:              optuna: Not installed
2023-10-24 14:58:47,249:INFO:               skopt: Not installed
2023-10-24 14:58:47,250:INFO:              mlflow: 2.7.1
2023-10-24 14:58:47,250:INFO:              gradio: Not installed
2023-10-24 14:58:47,250:INFO:             fastapi: Not installed
2023-10-24 14:58:47,250:INFO:             uvicorn: Not installed
2023-10-24 14:58:47,250:INFO:              m2cgen: Not installed
2023-10-24 14:58:47,250:INFO:           evidently: Not installed
2023-10-24 14:58:47,250:INFO:               fugue: Not installed
2023-10-24 14:58:47,250:INFO:           streamlit: Not installed
2023-10-24 14:58:47,250:INFO:             prophet: Not installed
2023-10-24 14:58:47,250:INFO:None
2023-10-24 14:58:47,250:INFO:Set up data.
2023-10-24 14:58:47,303:INFO:Set up folding strategy.
2023-10-24 14:58:47,303:INFO:Set up train/test split.
2023-10-24 14:58:47,339:INFO:Set up index.
2023-10-24 14:58:47,341:INFO:Assigning column types.
2023-10-24 14:58:47,361:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 14:58:47,361:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 14:58:47,368:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 14:58:47,376:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 14:58:47,485:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:58:47,557:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:58:47,558:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:58:47,558:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:58:47,559:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 14:58:47,567:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 14:58:47,574:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 14:58:47,685:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:58:47,763:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:58:47,764:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:58:47,764:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:58:47,765:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 14:58:47,773:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 14:58:47,780:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 14:58:47,891:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:58:47,969:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:58:47,970:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:58:47,970:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:58:47,979:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 14:58:47,986:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 14:58:48,096:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:58:48,179:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:58:48,180:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:58:48,180:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:58:48,181:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 14:58:48,197:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 14:58:48,316:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:58:48,393:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:58:48,395:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:58:48,395:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:58:48,411:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 14:58:48,518:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:58:48,593:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:58:48,594:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:58:48,595:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:58:48,595:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 14:58:48,717:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:58:48,792:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:58:48,793:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:58:48,793:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:58:48,917:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:58:48,990:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 14:58:48,991:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:58:48,991:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:58:48,992:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 14:58:49,114:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:58:49,190:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:58:49,191:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:58:49,316:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 14:58:49,390:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:58:49,391:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:58:49,392:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 14:58:49,591:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:58:49,592:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:58:49,804:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:58:49,805:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:58:49,807:INFO:Preparing preprocessing pipeline...
2023-10-24 14:58:49,807:INFO:Set up date feature engineering.
2023-10-24 14:58:49,808:INFO:Set up simple imputation.
2023-10-24 14:58:49,825:INFO:Set up encoding of ordinal features.
2023-10-24 14:58:49,855:INFO:Set up encoding of categorical features.
2023-10-24 14:58:49,858:INFO:Set up column name cleaning.
2023-10-24 14:58:50,198:INFO:Finished creating preprocessing pipeline.
2023-10-24 14:58:50,339:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_...
NaN   -1
dtype: int64},
                                                                        {'col': 'rime',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 14:58:50,339:INFO:Creating final display dataframe.
2023-10-24 14:58:50,825:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (32819, 50)
4        Transformed data shape  (32819, 52)
5   Transformed train set shape  (22973, 52)
6    Transformed test set shape   (9846, 52)
7              Ordinal features            4
8              Numeric features           44
9                 Date features            1
10         Categorical features            4
11     Rows with missing values        19.9%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18               Fold Generator        KFold
19                  Fold Number           10
20                     CPU Jobs           -1
21                      Use GPU        False
22               Log Experiment        False
23              Experiment Name        exp_B
24                          USI         f3ca
2023-10-24 14:58:51,029:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:58:51,030:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:58:51,235:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 14:58:51,236:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 14:58:51,238:INFO:setup() successfully completed in 4.0s...............
2023-10-24 14:58:51,238:INFO:Initializing create_model()
2023-10-24 14:58:51,238:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dcd2332b0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 14:58:51,238:INFO:Checking exceptions
2023-10-24 14:58:51,244:INFO:Importing libraries
2023-10-24 14:58:51,244:INFO:Copying training dataset
2023-10-24 14:58:51,267:INFO:Defining folds
2023-10-24 14:58:51,267:INFO:Declaring metric variables
2023-10-24 14:58:51,267:INFO:Importing untrained model
2023-10-24 14:58:51,268:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 14:58:51,268:INFO:Starting cross validation
2023-10-24 14:58:51,271:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 14:59:16,150:INFO:Calculating mean and std
2023-10-24 14:59:16,152:INFO:Creating metrics dataframe
2023-10-24 14:59:16,155:INFO:Finalizing model
2023-10-24 14:59:16,554:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018700 seconds.
2023-10-24 14:59:16,554:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 14:59:16,554:INFO:[LightGBM] [Info] Total Bins 6517
2023-10-24 14:59:16,555:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 48
2023-10-24 14:59:16,558:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-24 14:59:25,367:INFO:Uploading results into container
2023-10-24 14:59:25,368:INFO:Uploading model into container now
2023-10-24 14:59:25,374:INFO:_master_model_container: 1
2023-10-24 14:59:25,375:INFO:_display_container: 2
2023-10-24 14:59:25,375:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 14:59:25,375:INFO:create_model() successfully completed......................................
2023-10-24 14:59:25,490:INFO:Initializing tune_model()
2023-10-24 14:59:25,490:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dcd2332b0>)
2023-10-24 14:59:25,490:INFO:Checking exceptions
2023-10-24 14:59:25,505:INFO:Copying training dataset
2023-10-24 14:59:25,523:INFO:Checking base model
2023-10-24 14:59:25,523:INFO:Base model : Light Gradient Boosting Machine
2023-10-24 14:59:25,524:INFO:Declaring metric variables
2023-10-24 14:59:25,524:INFO:Defining Hyperparameters
2023-10-24 14:59:25,633:INFO:Tuning with n_jobs=-1
2023-10-24 14:59:25,633:INFO:Initializing RandomizedSearchCV
2023-10-24 15:05:05,186:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-24 15:05:05,195:INFO:Hyperparameter search completed
2023-10-24 15:05:05,196:INFO:SubProcess create_model() called ==================================
2023-10-24 15:05:05,198:INFO:Initializing create_model()
2023-10-24 15:05:05,199:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dcd2332b0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9dca0c6bb0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-24 15:05:05,199:INFO:Checking exceptions
2023-10-24 15:05:05,199:INFO:Importing libraries
2023-10-24 15:05:05,200:INFO:Copying training dataset
2023-10-24 15:05:05,245:INFO:Defining folds
2023-10-24 15:05:05,245:INFO:Declaring metric variables
2023-10-24 15:05:05,246:INFO:Importing untrained model
2023-10-24 15:05:05,246:INFO:Declaring custom model
2023-10-24 15:05:05,249:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 15:05:05,249:INFO:Starting cross validation
2023-10-24 15:05:05,252:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 15:06:10,735:INFO:Calculating mean and std
2023-10-24 15:06:10,737:INFO:Creating metrics dataframe
2023-10-24 15:06:10,742:INFO:Finalizing model
2023-10-24 15:06:11,045:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:06:11,045:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:06:11,045:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:06:11,105:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:06:11,105:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:06:11,105:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:06:11,125:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007137 seconds.
2023-10-24 15:06:11,126:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 15:06:11,126:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 15:06:11,126:INFO:[LightGBM] [Info] Total Bins 6517
2023-10-24 15:06:11,128:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 48
2023-10-24 15:06:11,132:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-24 15:06:23,184:INFO:Uploading results into container
2023-10-24 15:06:23,185:INFO:Uploading model into container now
2023-10-24 15:06:23,187:INFO:_master_model_container: 2
2023-10-24 15:06:23,187:INFO:_display_container: 3
2023-10-24 15:06:23,188:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-24 15:06:23,188:INFO:create_model() successfully completed......................................
2023-10-24 15:06:23,570:INFO:SubProcess create_model() end ==================================
2023-10-24 15:06:23,570:INFO:choose_better activated
2023-10-24 15:06:23,571:INFO:SubProcess create_model() called ==================================
2023-10-24 15:06:23,572:INFO:Initializing create_model()
2023-10-24 15:06:23,572:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dcd2332b0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 15:06:23,573:INFO:Checking exceptions
2023-10-24 15:06:23,575:INFO:Importing libraries
2023-10-24 15:06:23,575:INFO:Copying training dataset
2023-10-24 15:06:23,596:INFO:Defining folds
2023-10-24 15:06:23,597:INFO:Declaring metric variables
2023-10-24 15:06:23,597:INFO:Importing untrained model
2023-10-24 15:06:23,597:INFO:Declaring custom model
2023-10-24 15:06:23,598:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 15:06:23,598:INFO:Starting cross validation
2023-10-24 15:06:23,600:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 15:06:37,119:INFO:Calculating mean and std
2023-10-24 15:06:37,120:INFO:Creating metrics dataframe
2023-10-24 15:06:37,122:INFO:Finalizing model
2023-10-24 15:06:37,475:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009033 seconds.
2023-10-24 15:06:37,475:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 15:06:37,475:INFO:[LightGBM] [Info] Total Bins 6517
2023-10-24 15:06:37,476:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 48
2023-10-24 15:06:37,477:INFO:[LightGBM] [Info] Start training from score 96.947042
2023-10-24 15:06:39,785:INFO:Uploading results into container
2023-10-24 15:06:39,786:INFO:Uploading model into container now
2023-10-24 15:06:39,786:INFO:_master_model_container: 3
2023-10-24 15:06:39,786:INFO:_display_container: 4
2023-10-24 15:06:39,787:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 15:06:39,787:INFO:create_model() successfully completed......................................
2023-10-24 15:06:39,890:INFO:SubProcess create_model() end ==================================
2023-10-24 15:06:39,891:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8768
2023-10-24 15:06:39,892:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8781
2023-10-24 15:06:39,892:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) is best model
2023-10-24 15:06:39,893:INFO:choose_better completed
2023-10-24 15:06:39,898:INFO:_master_model_container: 3
2023-10-24 15:06:39,898:INFO:_display_container: 3
2023-10-24 15:06:39,899:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-24 15:06:39,899:INFO:tune_model() successfully completed......................................
2023-10-24 15:06:40,001:INFO:Initializing ensemble_model()
2023-10-24 15:06:40,001:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dcd2332b0>, estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-24 15:06:40,001:INFO:Checking exceptions
2023-10-24 15:06:40,022:INFO:Importing libraries
2023-10-24 15:06:40,022:INFO:Copying training dataset
2023-10-24 15:06:40,022:INFO:Checking base model
2023-10-24 15:06:40,022:INFO:Base model : Light Gradient Boosting Machine
2023-10-24 15:06:40,024:INFO:Importing untrained ensembler
2023-10-24 15:06:40,024:INFO:Ensemble method set to Bagging
2023-10-24 15:06:40,024:INFO:SubProcess create_model() called ==================================
2023-10-24 15:06:40,028:INFO:Initializing create_model()
2023-10-24 15:06:40,028:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dcd2332b0>, estimator=BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                                         feature_fraction=0.4,
                                         min_child_samples=41,
                                         min_split_gain=0.9, n_estimators=260,
                                         n_jobs=-1, num_leaves=70,
                                         random_state=123, reg_alpha=2,
                                         reg_lambda=3),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9d40c02910>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 15:06:40,028:INFO:Checking exceptions
2023-10-24 15:06:40,028:INFO:Importing libraries
2023-10-24 15:06:40,028:INFO:Copying training dataset
2023-10-24 15:06:40,047:INFO:Defining folds
2023-10-24 15:06:40,047:INFO:Declaring metric variables
2023-10-24 15:06:40,047:INFO:Importing untrained model
2023-10-24 15:06:40,047:INFO:Declaring custom model
2023-10-24 15:06:40,048:INFO:Bagging Regressor Imported successfully
2023-10-24 15:06:40,049:INFO:Starting cross validation
2023-10-24 15:06:40,051:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 15:09:36,905:INFO:Calculating mean and std
2023-10-24 15:09:36,918:INFO:Creating metrics dataframe
2023-10-24 15:09:36,955:INFO:Finalizing model
2023-10-24 15:09:37,342:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:09:37,343:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:09:37,343:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:09:37,424:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:09:37,424:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:09:37,424:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:09:37,472:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024714 seconds.
2023-10-24 15:09:37,472:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 15:09:37,474:INFO:[LightGBM] [Info] Total Bins 7683
2023-10-24 15:09:37,478:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 54
2023-10-24 15:09:37,492:INFO:[LightGBM] [Info] Start training from score 629.993497
2023-10-24 15:10:17,425:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:10:17,425:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:10:17,425:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:10:17,495:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:10:17,495:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:10:17,495:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:10:17,543:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021768 seconds.
2023-10-24 15:10:17,544:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 15:10:17,544:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 15:10:17,544:INFO:[LightGBM] [Info] Total Bins 7683
2023-10-24 15:10:17,547:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 54
2023-10-24 15:10:17,557:INFO:[LightGBM] [Info] Start training from score 639.698324
2023-10-24 15:10:59,279:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:10:59,280:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:10:59,280:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:10:59,352:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:10:59,352:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:10:59,352:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:10:59,406:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029290 seconds.
2023-10-24 15:10:59,406:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 15:10:59,408:INFO:[LightGBM] [Info] Total Bins 7683
2023-10-24 15:10:59,410:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 54
2023-10-24 15:10:59,429:INFO:[LightGBM] [Info] Start training from score 639.067381
2023-10-24 15:11:39,802:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:11:39,802:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:11:39,802:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:11:39,870:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:11:39,870:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:11:39,870:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:11:39,909:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023731 seconds.
2023-10-24 15:11:39,909:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 15:11:39,910:INFO:[LightGBM] [Info] Total Bins 7683
2023-10-24 15:11:39,913:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 54
2023-10-24 15:11:39,926:INFO:[LightGBM] [Info] Start training from score 640.702912
2023-10-24 15:12:19,800:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:12:19,800:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:12:19,800:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:12:19,863:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:12:19,864:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:12:19,864:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:12:19,903:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017582 seconds.
2023-10-24 15:12:19,903:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 15:12:19,905:INFO:[LightGBM] [Info] Total Bins 7683
2023-10-24 15:12:19,908:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 54
2023-10-24 15:12:19,921:INFO:[LightGBM] [Info] Start training from score 638.373964
2023-10-24 15:12:59,835:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:12:59,835:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:12:59,836:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:12:59,897:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:12:59,897:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:12:59,897:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:12:59,939:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016273 seconds.
2023-10-24 15:12:59,939:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 15:12:59,939:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 15:12:59,939:INFO:[LightGBM] [Info] Total Bins 7683
2023-10-24 15:12:59,943:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 54
2023-10-24 15:12:59,955:INFO:[LightGBM] [Info] Start training from score 631.653878
2023-10-24 15:13:41,820:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:13:41,821:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:13:41,821:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:13:41,884:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:13:41,884:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:13:41,884:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:13:41,924:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020179 seconds.
2023-10-24 15:13:41,925:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 15:13:41,925:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 15:13:41,925:INFO:[LightGBM] [Info] Total Bins 7683
2023-10-24 15:13:41,928:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 54
2023-10-24 15:13:41,941:INFO:[LightGBM] [Info] Start training from score 640.465574
2023-10-24 15:14:16,349:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:14:16,351:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:14:16,351:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:14:16,403:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:14:16,403:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:14:16,403:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:14:16,420:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009001 seconds.
2023-10-24 15:14:16,420:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 15:14:16,421:INFO:[LightGBM] [Info] Total Bins 7683
2023-10-24 15:14:16,423:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 54
2023-10-24 15:14:16,427:INFO:[LightGBM] [Info] Start training from score 642.146080
2023-10-24 15:14:28,749:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:14:28,750:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:14:28,750:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:14:28,803:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:14:28,803:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:14:28,803:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:14:28,819:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009446 seconds.
2023-10-24 15:14:28,819:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 15:14:28,820:INFO:[LightGBM] [Info] Total Bins 7683
2023-10-24 15:14:28,822:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 54
2023-10-24 15:14:28,823:INFO:[LightGBM] [Info] Start training from score 646.454539
2023-10-24 15:14:41,385:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:14:41,385:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:14:41,386:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:14:41,435:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:14:41,435:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:14:41,435:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:14:41,452:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006079 seconds.
2023-10-24 15:14:41,453:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 15:14:41,453:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 15:14:41,453:INFO:[LightGBM] [Info] Total Bins 7683
2023-10-24 15:14:41,454:INFO:[LightGBM] [Info] Number of data points in the train set: 23842, number of used features: 54
2023-10-24 15:14:41,458:INFO:[LightGBM] [Info] Start training from score 646.584710
2023-10-24 15:14:53,483:INFO:Uploading results into container
2023-10-24 15:14:53,484:INFO:Uploading model into container now
2023-10-24 15:14:53,486:INFO:_master_model_container: 4
2023-10-24 15:14:53,487:INFO:_display_container: 4
2023-10-24 15:14:53,490:INFO:BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                                         feature_fraction=0.4,
                                         min_child_samples=41,
                                         min_split_gain=0.9, n_estimators=260,
                                         n_jobs=-1, num_leaves=70,
                                         random_state=123, reg_alpha=2,
                                         reg_lambda=3),
                 random_state=123)
2023-10-24 15:14:53,490:INFO:create_model() successfully completed......................................
2023-10-24 15:14:53,856:INFO:SubProcess create_model() end ==================================
2023-10-24 15:14:53,861:INFO:_master_model_container: 4
2023-10-24 15:14:53,862:INFO:_display_container: 4
2023-10-24 15:14:53,864:INFO:BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                                         feature_fraction=0.4,
                                         min_child_samples=41,
                                         min_split_gain=0.9, n_estimators=260,
                                         n_jobs=-1, num_leaves=70,
                                         random_state=123, reg_alpha=2,
                                         reg_lambda=3),
                 random_state=123)
2023-10-24 15:14:53,864:INFO:ensemble_model() successfully completed......................................
2023-10-24 15:14:53,954:INFO:Initializing finalize_model()
2023-10-24 15:14:53,954:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa4ca557b20>, estimator=BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                                         feature_fraction=0.4,
                                         min_child_samples=41,
                                         min_split_gain=0.9, n_estimators=260,
                                         n_jobs=-1, num_leaves=70,
                                         random_state=123, reg_alpha=2,
                                         reg_lambda=3),
                 random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-24 15:14:53,956:INFO:Finalizing BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                                         feature_fraction=0.4,
                                         min_child_samples=41,
                                         min_split_gain=0.9, n_estimators=260,
                                         n_jobs=-1, num_leaves=70,
                                         random_state=123, reg_alpha=2,
                                         reg_lambda=3),
                 random_state=123)
2023-10-24 15:14:53,987:INFO:Initializing create_model()
2023-10-24 15:14:53,987:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa4ca557b20>, estimator=BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                                         feature_fraction=0.4,
                                         min_child_samples=41,
                                         min_split_gain=0.9, n_estimators=260,
                                         n_jobs=-1, num_leaves=70,
                                         random_state=123, reg_alpha=2,
                                         reg_lambda=3),
                 random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-24 15:14:53,987:INFO:Checking exceptions
2023-10-24 15:14:53,988:INFO:Importing libraries
2023-10-24 15:14:53,988:INFO:Copying training dataset
2023-10-24 15:14:53,990:INFO:Defining folds
2023-10-24 15:14:53,990:INFO:Declaring metric variables
2023-10-24 15:14:53,990:INFO:Importing untrained model
2023-10-24 15:14:53,990:INFO:Declaring custom model
2023-10-24 15:14:53,991:INFO:Bagging Regressor Imported successfully
2023-10-24 15:14:53,994:INFO:Cross validation set to False
2023-10-24 15:14:53,994:INFO:Fitting Model
2023-10-24 15:14:54,404:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:14:54,404:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:14:54,404:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:14:54,480:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:14:54,480:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:14:54,480:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:14:54,502:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007100 seconds.
2023-10-24 15:14:54,502:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 15:14:54,502:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 15:14:54,503:INFO:[LightGBM] [Info] Total Bins 7876
2023-10-24 15:14:54,505:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 55
2023-10-24 15:14:54,509:INFO:[LightGBM] [Info] Start training from score 621.939460
2023-10-24 15:15:07,203:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:15:07,203:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:15:07,203:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:15:07,273:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:15:07,273:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:15:07,273:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:15:07,295:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008809 seconds.
2023-10-24 15:15:07,295:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 15:15:07,295:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 15:15:07,295:INFO:[LightGBM] [Info] Total Bins 7876
2023-10-24 15:15:07,297:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 55
2023-10-24 15:15:07,301:INFO:[LightGBM] [Info] Start training from score 633.276326
2023-10-24 15:15:20,092:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:15:20,092:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:15:20,092:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:15:20,166:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:15:20,166:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:15:20,166:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:15:20,185:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010338 seconds.
2023-10-24 15:15:20,185:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 15:15:20,187:INFO:[LightGBM] [Info] Total Bins 7876
2023-10-24 15:15:20,188:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 55
2023-10-24 15:15:20,191:INFO:[LightGBM] [Info] Start training from score 622.547611
2023-10-24 15:15:32,522:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:15:32,522:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:15:32,522:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:15:32,592:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:15:32,592:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:15:32,592:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:15:32,614:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007383 seconds.
2023-10-24 15:15:32,614:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 15:15:32,614:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 15:15:32,615:INFO:[LightGBM] [Info] Total Bins 7876
2023-10-24 15:15:32,616:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 55
2023-10-24 15:15:32,620:INFO:[LightGBM] [Info] Start training from score 627.206506
2023-10-24 15:15:45,522:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:15:45,523:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:15:45,523:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:15:45,593:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:15:45,593:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:15:45,593:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:15:45,615:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009083 seconds.
2023-10-24 15:15:45,615:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 15:15:45,615:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 15:15:45,615:INFO:[LightGBM] [Info] Total Bins 7876
2023-10-24 15:15:45,618:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 55
2023-10-24 15:15:45,623:INFO:[LightGBM] [Info] Start training from score 637.955081
2023-10-24 15:15:58,235:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:15:58,235:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:15:58,235:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:15:58,308:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:15:58,308:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:15:58,308:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:15:58,329:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007077 seconds.
2023-10-24 15:15:58,329:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 15:15:58,329:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 15:15:58,330:INFO:[LightGBM] [Info] Total Bins 7876
2023-10-24 15:15:58,331:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 55
2023-10-24 15:15:58,335:INFO:[LightGBM] [Info] Start training from score 632.824687
2023-10-24 15:16:11,104:INFO:Calculating mean and std
2023-10-24 15:16:11,116:INFO:Creating metrics dataframe
2023-10-24 15:16:11,133:INFO:Finalizing model
2023-10-24 15:16:11,337:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:16:11,338:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:16:11,338:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:16:11,422:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:16:11,422:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:16:11,422:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:16:11,440:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011403 seconds.
2023-10-24 15:16:11,440:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 15:16:11,442:INFO:[LightGBM] [Info] Total Bins 7876
2023-10-24 15:16:11,444:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 55
2023-10-24 15:16:11,446:INFO:[LightGBM] [Info] Start training from score 633.780341
2023-10-24 15:16:11,563:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:16:11,563:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:16:11,563:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:16:11,625:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:16:11,625:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:16:11,625:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:16:11,642:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004199 seconds.
2023-10-24 15:16:11,642:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 15:16:11,642:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 15:16:11,642:INFO:[LightGBM] [Info] Total Bins 6517
2023-10-24 15:16:11,644:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 48
2023-10-24 15:16:11,649:INFO:[LightGBM] [Info] Start training from score 99.624795
2023-10-24 15:16:16,967:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:16:16,967:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:16:16,967:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:16:17,018:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:16:17,018:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:16:17,018:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:16:17,032:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008423 seconds.
2023-10-24 15:16:17,032:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 15:16:17,033:INFO:[LightGBM] [Info] Total Bins 6517
2023-10-24 15:16:17,035:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 48
2023-10-24 15:16:17,038:INFO:[LightGBM] [Info] Start training from score 96.229614
2023-10-24 15:16:17,471:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:16:17,471:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:16:17,471:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:16:17,543:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:16:17,543:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:16:17,543:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:16:17,560:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009488 seconds.
2023-10-24 15:16:17,560:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 15:16:17,560:INFO:[LightGBM] [Info] Total Bins 7876
2023-10-24 15:16:17,563:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 55
2023-10-24 15:16:17,566:INFO:[LightGBM] [Info] Start training from score 636.770620
2023-10-24 15:16:21,140:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:16:21,140:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:16:21,141:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:16:21,194:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:16:21,194:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:16:21,194:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:16:21,209:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009851 seconds.
2023-10-24 15:16:21,210:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 15:16:21,211:INFO:[LightGBM] [Info] Total Bins 6517
2023-10-24 15:16:21,213:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 48
2023-10-24 15:16:21,214:INFO:[LightGBM] [Info] Start training from score 95.360987
2023-10-24 15:16:22,519:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:16:22,519:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:16:22,519:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:16:22,592:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:16:22,593:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:16:22,593:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:16:22,612:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006605 seconds.
2023-10-24 15:16:22,612:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 15:16:22,612:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 15:16:22,612:INFO:[LightGBM] [Info] Total Bins 7876
2023-10-24 15:16:22,614:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 55
2023-10-24 15:16:22,615:INFO:[LightGBM] [Info] Start training from score 638.361113
2023-10-24 15:16:25,230:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:16:25,231:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:16:25,231:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:16:25,281:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:16:25,281:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:16:25,282:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:16:25,292:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005885 seconds.
2023-10-24 15:16:25,292:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 15:16:25,293:INFO:[LightGBM] [Info] Total Bins 6517
2023-10-24 15:16:25,295:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 48
2023-10-24 15:16:25,299:INFO:[LightGBM] [Info] Start training from score 94.348528
2023-10-24 15:16:27,421:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:16:27,421:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:16:27,421:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:16:27,492:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:16:27,492:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:16:27,492:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:16:27,508:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005911 seconds.
2023-10-24 15:16:27,509:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 15:16:27,509:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 15:16:27,509:INFO:[LightGBM] [Info] Total Bins 7876
2023-10-24 15:16:27,511:INFO:[LightGBM] [Info] Number of data points in the train set: 34061, number of used features: 55
2023-10-24 15:16:27,515:INFO:[LightGBM] [Info] Start training from score 629.488323
2023-10-24 15:16:29,147:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:16:29,147:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:16:29,147:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:16:29,197:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:16:29,197:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:16:29,197:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:16:29,209:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007864 seconds.
2023-10-24 15:16:29,210:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 15:16:29,211:INFO:[LightGBM] [Info] Total Bins 6517
2023-10-24 15:16:29,213:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 48
2023-10-24 15:16:29,215:INFO:[LightGBM] [Info] Start training from score 95.509684
2023-10-24 15:16:32,192:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6,
                                                          bagging_freq=2,
                                                          feature_fraction=0.4,
                                                          min_child_samples=41,
                                                          min_split_gain=0.9,
                                                          n_estimators=260,
                                                          n_jobs=-1,
                                                          num_leaves=70,
                                                          random_state=123,
                                                          reg_alpha=2,
                                                          reg_lambda=3),
                                  random_state=123))])
2023-10-24 15:16:32,192:INFO:create_model() successfully completed......................................
2023-10-24 15:16:32,285:INFO:_master_model_container: 4
2023-10-24 15:16:32,285:INFO:_display_container: 4
2023-10-24 15:16:32,303:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6,
                                                          bagging_freq=2,
                                                          feature_fraction=0.4,
                                                          min_child_samples=41,
                                                          min_split_gain=0.9,
                                                          n_estimators=260,
                                                          n_jobs=-1,
                                                          num_leaves=70,
                                                          random_state=123,
                                                          reg_alpha=2,
                                                          reg_lambda=3),
                                  random_state=123))])
2023-10-24 15:16:32,304:INFO:finalize_model() successfully completed......................................
2023-10-24 15:16:32,419:INFO:Initializing save_model()
2023-10-24 15:16:32,420:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6,
                                                          bagging_freq=2,
                                                          feature_fraction=0.4,
                                                          min_child_samples=41,
                                                          min_split_gain=0.9,
                                                          n_estimators=260,
                                                          n_jobs=-1,
                                                          num_leaves=70,
                                                          random_state=123,
                                                          reg_alpha=2,
                                                          reg_lambda=3),
                                  random_state=123))]), model_name=final_model_for_location_A, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             '...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx', 'is_day:idx',
                                             'is_in_shadow:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx',
                                                                    'is_day:idx',
                                                                    'is_in_shadow:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-24 15:16:32,420:INFO:Adding model into prep_pipe
2023-10-24 15:16:32,420:WARNING:Only Model saved as it was a pipeline.
2023-10-24 15:16:32,754:INFO:final_model_for_location_A.pkl saved in current working directory
2023-10-24 15:16:32,772:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6,
                                                          bagging_freq=2,
                                                          feature_fraction=0.4,
                                                          min_child_samples=41,
                                                          min_split_gain=0.9,
                                                          n_estimators=260,
                                                          n_jobs=-1,
                                                          num_leaves=70,
                                                          random_state=123,
                                                          reg_alpha=2,
                                                          reg_lambda=3),
                                  random_state=123))])
2023-10-24 15:16:32,773:INFO:save_model() successfully completed......................................
2023-10-24 15:16:32,919:INFO:Initializing predict_model()
2023-10-24 15:16:32,919:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa4ca557b20>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6,
                                                          bagging_freq=2,
                                                          feature_fraction=0.4,
                                                          min_child_samples=41,
                                                          min_split_gain=0.9,
                                                          n_estimators=260,
                                                          n_jobs=-1,
                                                          num_leaves=70,
                                                          random_state=123,
                                                          reg_alpha=2,
                                                          reg_lambda=3),
                                  random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa4b56b2280>)
2023-10-24 15:16:32,920:INFO:Checking exceptions
2023-10-24 15:16:32,920:INFO:Preloading libraries
2023-10-24 15:16:32,920:INFO:Set up data.
2023-10-24 15:16:32,936:INFO:Set up index.
2023-10-24 15:16:33,363:WARNING:<ipython-input-15-49df83f3379d>:13: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  estimated_resampled = estimated.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 15:16:33,370:WARNING:<ipython-input-15-49df83f3379d>:14: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  test_resampled = test.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 15:16:33,384:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:16:33,384:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:16:33,384:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:16:33,437:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:16:33,438:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:16:33,438:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:16:33,446:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004921 seconds.
2023-10-24 15:16:33,446:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 15:16:33,447:INFO:[LightGBM] [Info] Total Bins 6517
2023-10-24 15:16:33,449:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 48
2023-10-24 15:16:33,451:INFO:[LightGBM] [Info] Start training from score 96.036959
2023-10-24 15:16:33,463:INFO:PyCaret RegressionExperiment
2023-10-24 15:16:33,463:INFO:Logging name: exp_B
2023-10-24 15:16:33,463:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 15:16:33,463:INFO:version 3.1.0
2023-10-24 15:16:33,463:INFO:Initializing setup()
2023-10-24 15:16:33,463:INFO:self.USI: 6b92
2023-10-24 15:16:33,463:INFO:self._variable_keys: {'pipeline', 'fold_shuffle_param', 'idx', '_ml_usecase', 'transform_target_param', 'seed', 'X_test', 'gpu_n_jobs_param', 'exp_name_log', 'log_plots_param', 'X_train', 'memory', 'target_param', 'USI', 'fold_generator', 'logging_param', 'html_param', '_available_plots', 'data', 'y_train', 'y_test', 'fold_groups_param', 'gpu_param', 'X', 'n_jobs_param', 'y', 'exp_id'}
2023-10-24 15:16:33,463:INFO:Checking environment
2023-10-24 15:16:33,463:INFO:python_version: 3.8.5
2023-10-24 15:16:33,463:INFO:python_build: ('default', 'Sep  4 2020 02:22:02')
2023-10-24 15:16:33,463:INFO:machine: x86_64
2023-10-24 15:16:33,463:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-10-24 15:16:33,463:INFO:Memory: svmem(total=8589934592, available=2565980160, percent=70.1, used=4339810304, free=508387328, active=2062069760, inactive=2037006336, wired=2277740544)
2023-10-24 15:16:33,464:INFO:Physical Core: 4
2023-10-24 15:16:33,464:INFO:Logical Core: 8
2023-10-24 15:16:33,464:INFO:Checking libraries
2023-10-24 15:16:33,464:INFO:System:
2023-10-24 15:16:33,464:INFO:    python: 3.8.5 (default, Sep  4 2020, 02:22:02)  [Clang 10.0.0 ]
2023-10-24 15:16:33,464:INFO:executable: /Users/kaja/opt/anaconda3/bin/python
2023-10-24 15:16:33,464:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-10-24 15:16:33,464:INFO:PyCaret required dependencies:
2023-10-24 15:16:33,464:INFO:                 pip: 23.3.1
2023-10-24 15:16:33,464:INFO:          setuptools: 68.2.2
2023-10-24 15:16:33,464:INFO:             pycaret: 3.1.0
2023-10-24 15:16:33,464:INFO:             IPython: 7.19.0
2023-10-24 15:16:33,464:INFO:          ipywidgets: 8.1.1
2023-10-24 15:16:33,464:INFO:                tqdm: 4.66.1
2023-10-24 15:16:33,464:INFO:               numpy: 1.23.5
2023-10-24 15:16:33,464:INFO:              pandas: 1.5.3
2023-10-24 15:16:33,464:INFO:              jinja2: 3.1.2
2023-10-24 15:16:33,465:INFO:               scipy: 1.10.1
2023-10-24 15:16:33,465:INFO:              joblib: 1.3.2
2023-10-24 15:16:33,465:INFO:             sklearn: 1.2.2
2023-10-24 15:16:33,465:INFO:                pyod: 1.1.0
2023-10-24 15:16:33,465:INFO:            imblearn: 0.11.0
2023-10-24 15:16:33,465:INFO:   category_encoders: 2.6.2
2023-10-24 15:16:33,465:INFO:            lightgbm: 4.1.0
2023-10-24 15:16:33,465:INFO:               numba: 0.58.1
2023-10-24 15:16:33,465:INFO:            requests: 2.28.2
2023-10-24 15:16:33,465:INFO:          matplotlib: 3.7.3
2023-10-24 15:16:33,465:INFO:          scikitplot: 0.3.7
2023-10-24 15:16:33,465:INFO:         yellowbrick: 1.5
2023-10-24 15:16:33,465:INFO:              plotly: 5.17.0
2023-10-24 15:16:33,465:INFO:    plotly-resampler: Not installed
2023-10-24 15:16:33,465:INFO:             kaleido: 0.2.1
2023-10-24 15:16:33,465:INFO:           schemdraw: 0.15
2023-10-24 15:16:33,465:INFO:         statsmodels: 0.14.0
2023-10-24 15:16:33,465:INFO:              sktime: 0.21.1
2023-10-24 15:16:33,465:INFO:               tbats: 1.1.3
2023-10-24 15:16:33,465:INFO:            pmdarima: 2.0.4
2023-10-24 15:16:33,466:INFO:              psutil: 5.9.6
2023-10-24 15:16:33,466:INFO:          markupsafe: 2.1.2
2023-10-24 15:16:33,466:INFO:             pickle5: Not installed
2023-10-24 15:16:33,466:INFO:         cloudpickle: 1.6.0
2023-10-24 15:16:33,466:INFO:         deprecation: 2.1.0
2023-10-24 15:16:33,466:INFO:              xxhash: 3.4.1
2023-10-24 15:16:33,466:INFO:           wurlitzer: 2.0.1
2023-10-24 15:16:33,466:INFO:PyCaret optional dependencies:
2023-10-24 15:16:33,466:INFO:                shap: Not installed
2023-10-24 15:16:33,466:INFO:           interpret: Not installed
2023-10-24 15:16:33,466:INFO:                umap: Not installed
2023-10-24 15:16:33,466:INFO:     ydata_profiling: Not installed
2023-10-24 15:16:33,466:INFO:  explainerdashboard: Not installed
2023-10-24 15:16:33,466:INFO:             autoviz: Not installed
2023-10-24 15:16:33,466:INFO:           fairlearn: Not installed
2023-10-24 15:16:33,466:INFO:          deepchecks: Not installed
2023-10-24 15:16:33,466:INFO:             xgboost: Not installed
2023-10-24 15:16:33,466:INFO:            catboost: 1.0.4
2023-10-24 15:16:33,467:INFO:              kmodes: Not installed
2023-10-24 15:16:33,467:INFO:             mlxtend: Not installed
2023-10-24 15:16:33,467:INFO:       statsforecast: Not installed
2023-10-24 15:16:33,467:INFO:        tune_sklearn: Not installed
2023-10-24 15:16:33,467:INFO:                 ray: Not installed
2023-10-24 15:16:33,467:INFO:            hyperopt: Not installed
2023-10-24 15:16:33,467:INFO:              optuna: Not installed
2023-10-24 15:16:33,467:INFO:               skopt: Not installed
2023-10-24 15:16:33,467:INFO:              mlflow: 2.7.1
2023-10-24 15:16:33,467:INFO:              gradio: Not installed
2023-10-24 15:16:33,467:INFO:             fastapi: Not installed
2023-10-24 15:16:33,467:INFO:             uvicorn: Not installed
2023-10-24 15:16:33,467:INFO:              m2cgen: Not installed
2023-10-24 15:16:33,467:INFO:           evidently: Not installed
2023-10-24 15:16:33,467:INFO:               fugue: Not installed
2023-10-24 15:16:33,468:INFO:           streamlit: Not installed
2023-10-24 15:16:33,468:INFO:             prophet: Not installed
2023-10-24 15:16:33,468:INFO:None
2023-10-24 15:16:33,468:INFO:Set up data.
2023-10-24 15:16:33,512:INFO:Set up folding strategy.
2023-10-24 15:16:33,512:INFO:Set up train/test split.
2023-10-24 15:16:33,536:INFO:Set up index.
2023-10-24 15:16:33,538:INFO:Assigning column types.
2023-10-24 15:16:33,550:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 15:16:33,551:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 15:16:33,560:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 15:16:33,567:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 15:16:33,668:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 15:16:33,741:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 15:16:33,742:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 15:16:33,742:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 15:16:33,743:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 15:16:33,750:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 15:16:33,758:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 15:16:33,858:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 15:16:33,930:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 15:16:33,931:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 15:16:33,932:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 15:16:33,932:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 15:16:33,940:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 15:16:33,947:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 15:16:34,049:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 15:16:34,123:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 15:16:34,124:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 15:16:34,124:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 15:16:34,132:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 15:16:34,140:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 15:16:34,246:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 15:16:34,324:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 15:16:34,325:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 15:16:34,325:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 15:16:34,326:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 15:16:34,341:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 15:16:34,448:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 15:16:34,524:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 15:16:34,525:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 15:16:34,526:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 15:16:34,541:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 15:16:34,649:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 15:16:34,725:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 15:16:34,726:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 15:16:34,726:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 15:16:34,727:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 15:16:34,847:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 15:16:34,922:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 15:16:34,923:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 15:16:34,923:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 15:16:35,045:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 15:16:35,122:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 15:16:35,123:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 15:16:35,123:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 15:16:35,124:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 15:16:35,245:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 15:16:35,325:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 15:16:35,326:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 15:16:35,447:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 15:16:35,524:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 15:16:35,524:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 15:16:35,525:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 15:16:35,728:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 15:16:35,728:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 15:16:35,931:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 15:16:35,932:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 15:16:35,933:INFO:Preparing preprocessing pipeline...
2023-10-24 15:16:35,933:INFO:Set up simple imputation.
2023-10-24 15:16:35,941:INFO:Set up encoding of categorical features.
2023-10-24 15:16:35,945:INFO:Set up column name cleaning.
2023-10-24 15:16:36,299:INFO:Finished creating preprocessing pipeline.
2023-10-24 15:16:36,310:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             '...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx', 'is_day:idx',
                                             'is_in_shadow:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx',
                                                                    'is_day:idx',
                                                                    'is_in_shadow:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 15:16:36,311:INFO:Creating final display dataframe.
2023-10-24 15:16:36,635:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (32823, 46)
4        Transformed data shape  (32823, 62)
5   Transformed train set shape  (22976, 62)
6    Transformed test set shape   (9847, 62)
7              Numeric features           42
8          Categorical features            3
9      Rows with missing values        95.7%
10                   Preprocess         True
11              Imputation type       simple
12           Numeric imputation         mean
13       Categorical imputation         mode
14     Maximum one-hot encoding           25
15              Encoding method         None
16               Fold Generator        KFold
17                  Fold Number           10
18                     CPU Jobs           -1
19                      Use GPU        False
20               Log Experiment        False
21              Experiment Name        exp_B
22                          USI         6b92
2023-10-24 15:16:36,848:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 15:16:36,849:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 15:16:37,049:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 15:16:37,050:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 15:16:37,051:INFO:setup() successfully completed in 3.59s...............
2023-10-24 15:16:37,051:INFO:Initializing create_model()
2023-10-24 15:16:37,051:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa4b4b588e0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 15:16:37,051:INFO:Checking exceptions
2023-10-24 15:16:37,056:INFO:Importing libraries
2023-10-24 15:16:37,057:INFO:Copying training dataset
2023-10-24 15:16:37,081:INFO:Defining folds
2023-10-24 15:16:37,081:INFO:Declaring metric variables
2023-10-24 15:16:37,081:INFO:Importing untrained model
2023-10-24 15:16:37,081:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 15:16:37,082:INFO:Starting cross validation
2023-10-24 15:16:37,083:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 15:16:38,915:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:16:38,915:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:16:38,915:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:16:39,021:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:16:39,021:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:16:39,022:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:16:39,070:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034374 seconds.
2023-10-24 15:16:39,070:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 15:16:39,072:INFO:[LightGBM] [Info] Total Bins 6517
2023-10-24 15:16:39,075:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 48
2023-10-24 15:16:39,081:INFO:[LightGBM] [Info] Start training from score 97.844637
2023-10-24 15:16:42,070:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:16:42,070:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:16:42,070:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:16:42,070:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:16:42,070:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:16:42,070:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:16:42,070:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:16:42,070:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:16:42,070:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:16:42,070:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:16:42,070:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:16:42,070:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:16:42,070:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:16:42,070:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:16:42,070:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:16:42,070:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:16:42,070:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:16:42,071:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:16:42,071:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:16:42,071:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:16:42,071:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:16:42,071:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:16:42,071:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:16:42,071:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:16:44,746:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.126014 seconds.
2023-10-24 15:16:44,748:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 15:16:44,748:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 15:16:44,748:INFO:[LightGBM] [Info] Total Bins 7658
2023-10-24 15:16:44,748:INFO:[LightGBM] [Info] Number of data points in the train set: 20679, number of used features: 54
2023-10-24 15:16:44,753:INFO:[LightGBM] [Info] Start training from score 97.291397
2023-10-24 15:16:44,755:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040763 seconds.
2023-10-24 15:16:44,755:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 15:16:44,755:INFO:[LightGBM] [Info] Total Bins 7660
2023-10-24 15:16:44,757:INFO:[LightGBM] [Info] Number of data points in the train set: 20678, number of used features: 54
2023-10-24 15:16:44,771:INFO:[LightGBM] [Info] Start training from score 97.853669
2023-10-24 15:16:44,773:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.095927 seconds.
2023-10-24 15:16:44,773:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 15:16:44,773:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 15:16:44,773:INFO:[LightGBM] [Info] Total Bins 7661
2023-10-24 15:16:44,775:INFO:[LightGBM] [Info] Number of data points in the train set: 20678, number of used features: 54
2023-10-24 15:16:44,782:INFO:[LightGBM] [Info] Start training from score 97.925240
2023-10-24 15:16:44,783:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055909 seconds.
2023-10-24 15:16:44,783:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 15:16:44,783:INFO:[LightGBM] [Info] Total Bins 7733
2023-10-24 15:16:44,784:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036400 seconds.
2023-10-24 15:16:44,784:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 15:16:44,784:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 15:16:44,785:INFO:[LightGBM] [Info] Total Bins 7638
2023-10-24 15:16:44,786:INFO:[LightGBM] [Info] Number of data points in the train set: 20678, number of used features: 54
2023-10-24 15:16:44,787:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041108 seconds.
2023-10-24 15:16:44,787:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 15:16:44,787:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 15:16:44,787:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041290 seconds.
2023-10-24 15:16:44,787:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 15:16:44,787:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 15:16:44,787:INFO:[LightGBM] [Info] Total Bins 7742
2023-10-24 15:16:44,787:INFO:[LightGBM] [Info] Total Bins 7656
2023-10-24 15:16:44,788:INFO:[LightGBM] [Info] Number of data points in the train set: 20678, number of used features: 54
2023-10-24 15:16:44,789:INFO:[LightGBM] [Info] Number of data points in the train set: 20679, number of used features: 54
2023-10-24 15:16:44,790:INFO:[LightGBM] [Info] Number of data points in the train set: 20678, number of used features: 54
2023-10-24 15:16:44,791:INFO:[LightGBM] [Info] Start training from score 98.229053
2023-10-24 15:16:44,792:INFO:[LightGBM] [Info] Start training from score 97.528584
2023-10-24 15:16:44,793:INFO:[LightGBM] [Info] Start training from score 98.177091
2023-10-24 15:16:44,794:INFO:[LightGBM] [Info] Start training from score 97.266851
2023-10-24 15:16:44,795:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051926 seconds.
2023-10-24 15:16:44,795:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 15:16:44,795:INFO:[LightGBM] [Info] Total Bins 7654
2023-10-24 15:16:44,796:INFO:[LightGBM] [Info] Number of data points in the train set: 20678, number of used features: 54
2023-10-24 15:16:44,801:INFO:[LightGBM] [Info] Start training from score 97.405741
2023-10-24 15:16:52,480:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024479 seconds.
2023-10-24 15:16:52,480:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 15:16:52,480:INFO:[LightGBM] [Info] Total Bins 7655
2023-10-24 15:16:52,481:INFO:[LightGBM] [Info] Number of data points in the train set: 20679, number of used features: 54
2023-10-24 15:16:52,484:INFO:[LightGBM] [Info] Start training from score 97.825341
2023-10-24 15:16:52,613:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015411 seconds.
2023-10-24 15:16:52,613:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 15:16:52,613:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 15:16:52,613:INFO:[LightGBM] [Info] Total Bins 7658
2023-10-24 15:16:52,614:INFO:[LightGBM] [Info] Number of data points in the train set: 20679, number of used features: 54
2023-10-24 15:16:52,616:INFO:[LightGBM] [Info] Start training from score 97.760351
2023-10-24 15:16:55,455:INFO:Calculating mean and std
2023-10-24 15:16:55,464:INFO:Creating metrics dataframe
2023-10-24 15:16:55,477:INFO:Finalizing model
2023-10-24 15:16:55,823:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:16:55,823:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:16:55,823:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:16:55,868:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015480 seconds.
2023-10-24 15:16:55,868:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 15:16:55,868:INFO:[LightGBM] [Info] Total Bins 7785
2023-10-24 15:16:55,869:INFO:[LightGBM] [Info] Number of data points in the train set: 22976, number of used features: 54
2023-10-24 15:16:55,870:INFO:[LightGBM] [Info] Start training from score 97.726333
2023-10-24 15:16:55,889:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:16:55,889:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:16:55,889:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:16:55,901:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006540 seconds.
2023-10-24 15:16:55,901:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 15:16:55,902:INFO:[LightGBM] [Info] Total Bins 6517
2023-10-24 15:16:55,903:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 48
2023-10-24 15:16:55,906:INFO:[LightGBM] [Info] Start training from score 96.245614
2023-10-24 15:16:56,996:INFO:Uploading results into container
2023-10-24 15:16:56,997:INFO:Uploading model into container now
2023-10-24 15:16:57,004:INFO:_master_model_container: 1
2023-10-24 15:16:57,004:INFO:_display_container: 2
2023-10-24 15:16:57,005:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 15:16:57,005:INFO:create_model() successfully completed......................................
2023-10-24 15:16:57,138:INFO:Initializing tune_model()
2023-10-24 15:16:57,138:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa4b4b588e0>)
2023-10-24 15:16:57,138:INFO:Checking exceptions
2023-10-24 15:16:57,168:INFO:Copying training dataset
2023-10-24 15:16:57,182:INFO:Checking base model
2023-10-24 15:16:57,182:INFO:Base model : Light Gradient Boosting Machine
2023-10-24 15:16:57,183:INFO:Declaring metric variables
2023-10-24 15:16:57,183:INFO:Defining Hyperparameters
2023-10-24 15:16:57,274:INFO:Tuning with n_jobs=-1
2023-10-24 15:16:57,274:INFO:Initializing RandomizedSearchCV
2023-10-24 15:17:25,888:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:17:25,889:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:17:25,890:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:17:25,965:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:17:25,965:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:17:25,965:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:17:26,009:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019781 seconds.
2023-10-24 15:17:26,009:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 15:17:26,009:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 15:17:26,009:INFO:[LightGBM] [Info] Total Bins 6517
2023-10-24 15:17:26,012:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 48
2023-10-24 15:17:26,025:INFO:[LightGBM] [Info] Start training from score 97.594984
2023-10-24 15:18:11,367:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:18:11,369:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:18:11,370:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:18:11,434:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:18:11,434:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:18:11,434:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:18:11,479:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020383 seconds.
2023-10-24 15:18:11,479:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 15:18:11,479:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 15:18:11,479:INFO:[LightGBM] [Info] Total Bins 6517
2023-10-24 15:18:11,483:INFO:[LightGBM] [Info] Number of data points in the train set: 22973, number of used features: 48
2023-10-24 15:18:11,495:INFO:[LightGBM] [Info] Start training from score 96.370407
2023-10-24 15:18:57,161:INFO:Uploading results into container
2023-10-24 15:18:57,165:INFO:Uploading model into container now
2023-10-24 15:18:57,169:INFO:_master_model_container: 4
2023-10-24 15:18:57,169:INFO:_display_container: 4
2023-10-24 15:18:57,173:INFO:BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                                         feature_fraction=0.4,
                                         min_child_samples=41,
                                         min_split_gain=0.9, n_estimators=260,
                                         n_jobs=-1, num_leaves=70,
                                         random_state=123, reg_alpha=2,
                                         reg_lambda=3),
                 random_state=123)
2023-10-24 15:18:57,173:INFO:create_model() successfully completed......................................
2023-10-24 15:18:57,785:INFO:SubProcess create_model() end ==================================
2023-10-24 15:18:57,794:INFO:_master_model_container: 4
2023-10-24 15:18:57,794:INFO:_display_container: 4
2023-10-24 15:18:57,797:INFO:BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                                         feature_fraction=0.4,
                                         min_child_samples=41,
                                         min_split_gain=0.9, n_estimators=260,
                                         n_jobs=-1, num_leaves=70,
                                         random_state=123, reg_alpha=2,
                                         reg_lambda=3),
                 random_state=123)
2023-10-24 15:18:57,799:INFO:ensemble_model() successfully completed......................................
2023-10-24 15:18:57,949:INFO:Initializing finalize_model()
2023-10-24 15:18:57,949:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dcd2332b0>, estimator=BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                                         feature_fraction=0.4,
                                         min_child_samples=41,
                                         min_split_gain=0.9, n_estimators=260,
                                         n_jobs=-1, num_leaves=70,
                                         random_state=123, reg_alpha=2,
                                         reg_lambda=3),
                 random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-24 15:18:57,952:INFO:Finalizing BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                                         feature_fraction=0.4,
                                         min_child_samples=41,
                                         min_split_gain=0.9, n_estimators=260,
                                         n_jobs=-1, num_leaves=70,
                                         random_state=123, reg_alpha=2,
                                         reg_lambda=3),
                 random_state=123)
2023-10-24 15:18:57,997:INFO:Initializing create_model()
2023-10-24 15:18:57,997:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dcd2332b0>, estimator=BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                                         feature_fraction=0.4,
                                         min_child_samples=41,
                                         min_split_gain=0.9, n_estimators=260,
                                         n_jobs=-1, num_leaves=70,
                                         random_state=123, reg_alpha=2,
                                         reg_lambda=3),
                 random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-24 15:18:57,997:INFO:Checking exceptions
2023-10-24 15:18:58,000:INFO:Importing libraries
2023-10-24 15:18:58,000:INFO:Copying training dataset
2023-10-24 15:18:58,011:INFO:Defining folds
2023-10-24 15:18:58,011:INFO:Declaring metric variables
2023-10-24 15:18:58,012:INFO:Importing untrained model
2023-10-24 15:18:58,012:INFO:Declaring custom model
2023-10-24 15:18:58,014:INFO:Bagging Regressor Imported successfully
2023-10-24 15:18:58,016:INFO:Cross validation set to False
2023-10-24 15:18:58,016:INFO:Fitting Model
2023-10-24 15:18:58,497:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:18:58,497:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:18:58,497:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:18:58,595:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:18:58,596:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:18:58,596:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:18:58,645:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017721 seconds.
2023-10-24 15:18:58,645:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 15:18:58,645:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 15:18:58,645:INFO:[LightGBM] [Info] Total Bins 6595
2023-10-24 15:18:58,648:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 48
2023-10-24 15:18:58,662:INFO:[LightGBM] [Info] Start training from score 96.465021
2023-10-24 15:19:46,638:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:19:46,639:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:19:46,639:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:19:46,734:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:19:46,734:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:19:46,734:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:19:46,779:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019996 seconds.
2023-10-24 15:19:46,779:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 15:19:46,779:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 15:19:46,779:INFO:[LightGBM] [Info] Total Bins 6595
2023-10-24 15:19:46,782:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 48
2023-10-24 15:19:46,791:INFO:[LightGBM] [Info] Start training from score 97.264361
2023-10-24 15:20:32,349:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:20:32,350:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:20:32,350:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:20:32,434:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:20:32,434:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:20:32,434:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:20:32,468:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011853 seconds.
2023-10-24 15:20:32,469:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 15:20:32,469:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 15:20:32,469:INFO:[LightGBM] [Info] Total Bins 6595
2023-10-24 15:20:32,471:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 48
2023-10-24 15:20:32,480:INFO:[LightGBM] [Info] Start training from score 95.842370
2023-10-24 15:20:37,009:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-24 15:20:37,018:INFO:Hyperparameter search completed
2023-10-24 15:20:37,018:INFO:SubProcess create_model() called ==================================
2023-10-24 15:20:37,020:INFO:Initializing create_model()
2023-10-24 15:20:37,021:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa4b4b588e0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa4b578b2b0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-24 15:20:37,021:INFO:Checking exceptions
2023-10-24 15:20:37,022:INFO:Importing libraries
2023-10-24 15:20:37,022:INFO:Copying training dataset
2023-10-24 15:20:37,066:INFO:Defining folds
2023-10-24 15:20:37,066:INFO:Declaring metric variables
2023-10-24 15:20:37,067:INFO:Importing untrained model
2023-10-24 15:20:37,067:INFO:Declaring custom model
2023-10-24 15:20:37,069:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 15:20:37,070:INFO:Starting cross validation
2023-10-24 15:20:37,073:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 15:21:07,673:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:21:07,674:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:21:07,674:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:21:07,757:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:21:07,757:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:21:07,757:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:21:07,800:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019390 seconds.
2023-10-24 15:21:07,800:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 15:21:07,800:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 15:21:07,801:INFO:[LightGBM] [Info] Total Bins 6595
2023-10-24 15:21:07,804:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 48
2023-10-24 15:21:07,818:INFO:[LightGBM] [Info] Start training from score 95.431515
2023-10-24 15:21:30,515:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:21:30,517:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:21:30,517:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:21:30,590:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:21:30,590:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:21:30,590:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:21:30,610:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005553 seconds.
2023-10-24 15:21:30,610:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 15:21:30,610:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 15:21:30,610:INFO:[LightGBM] [Info] Total Bins 6595
2023-10-24 15:21:30,612:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 48
2023-10-24 15:21:30,616:INFO:[LightGBM] [Info] Start training from score 97.222213
2023-10-24 15:21:34,234:INFO:Calculating mean and std
2023-10-24 15:21:34,237:INFO:Creating metrics dataframe
2023-10-24 15:21:34,242:INFO:Finalizing model
2023-10-24 15:21:34,532:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:21:34,532:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:21:34,532:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:21:34,587:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:21:34,587:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:21:34,588:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:21:34,601:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005479 seconds.
2023-10-24 15:21:34,601:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 15:21:34,601:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 15:21:34,601:INFO:[LightGBM] [Info] Total Bins 7783
2023-10-24 15:21:34,603:INFO:[LightGBM] [Info] Number of data points in the train set: 22976, number of used features: 53
2023-10-24 15:21:34,607:INFO:[LightGBM] [Info] Start training from score 97.726333
2023-10-24 15:21:36,951:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:21:36,952:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:21:36,952:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:21:37,029:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:21:37,029:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:21:37,029:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:21:37,045:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004624 seconds.
2023-10-24 15:21:37,046:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 15:21:37,046:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 15:21:37,046:INFO:[LightGBM] [Info] Total Bins 6595
2023-10-24 15:21:37,048:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 48
2023-10-24 15:21:37,051:INFO:[LightGBM] [Info] Start training from score 97.332701
2023-10-24 15:21:39,479:INFO:Uploading results into container
2023-10-24 15:21:39,480:INFO:Uploading model into container now
2023-10-24 15:21:39,481:INFO:_master_model_container: 2
2023-10-24 15:21:39,481:INFO:_display_container: 3
2023-10-24 15:21:39,482:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-24 15:21:39,482:INFO:create_model() successfully completed......................................
2023-10-24 15:21:39,713:INFO:SubProcess create_model() end ==================================
2023-10-24 15:21:39,713:INFO:choose_better activated
2023-10-24 15:21:39,713:INFO:SubProcess create_model() called ==================================
2023-10-24 15:21:39,714:INFO:Initializing create_model()
2023-10-24 15:21:39,714:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa4b4b588e0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 15:21:39,714:INFO:Checking exceptions
2023-10-24 15:21:39,716:INFO:Importing libraries
2023-10-24 15:21:39,716:INFO:Copying training dataset
2023-10-24 15:21:39,735:INFO:Defining folds
2023-10-24 15:21:39,735:INFO:Declaring metric variables
2023-10-24 15:21:39,736:INFO:Importing untrained model
2023-10-24 15:21:39,736:INFO:Declaring custom model
2023-10-24 15:21:39,737:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 15:21:39,737:INFO:Starting cross validation
2023-10-24 15:21:39,739:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 15:21:50,752:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:21:50,753:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:21:50,753:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:21:50,823:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:21:50,824:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:21:50,824:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:21:50,841:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010573 seconds.
2023-10-24 15:21:50,841:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 15:21:50,843:INFO:[LightGBM] [Info] Total Bins 6595
2023-10-24 15:21:50,845:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 48
2023-10-24 15:21:50,849:INFO:[LightGBM] [Info] Start training from score 96.452612
2023-10-24 15:21:51,103:INFO:Calculating mean and std
2023-10-24 15:21:51,103:INFO:Creating metrics dataframe
2023-10-24 15:21:51,106:INFO:Finalizing model
2023-10-24 15:21:51,444:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006657 seconds.
2023-10-24 15:21:51,444:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 15:21:51,444:INFO:[LightGBM] [Info] Total Bins 7785
2023-10-24 15:21:51,445:INFO:[LightGBM] [Info] Number of data points in the train set: 22976, number of used features: 54
2023-10-24 15:21:51,446:INFO:[LightGBM] [Info] Start training from score 97.726333
2023-10-24 15:21:52,539:INFO:Uploading results into container
2023-10-24 15:21:52,540:INFO:Uploading model into container now
2023-10-24 15:21:52,540:INFO:_master_model_container: 3
2023-10-24 15:21:52,540:INFO:_display_container: 4
2023-10-24 15:21:52,541:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 15:21:52,541:INFO:create_model() successfully completed......................................
2023-10-24 15:21:52,635:INFO:SubProcess create_model() end ==================================
2023-10-24 15:21:52,636:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8448
2023-10-24 15:21:52,637:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8493
2023-10-24 15:21:52,637:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) is best model
2023-10-24 15:21:52,638:INFO:choose_better completed
2023-10-24 15:21:52,643:INFO:_master_model_container: 3
2023-10-24 15:21:52,643:INFO:_display_container: 3
2023-10-24 15:21:52,644:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-24 15:21:52,644:INFO:tune_model() successfully completed......................................
2023-10-24 15:21:52,738:INFO:Initializing ensemble_model()
2023-10-24 15:21:52,738:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa4b4b588e0>, estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-24 15:21:52,738:INFO:Checking exceptions
2023-10-24 15:21:52,760:INFO:Importing libraries
2023-10-24 15:21:52,761:INFO:Copying training dataset
2023-10-24 15:21:52,761:INFO:Checking base model
2023-10-24 15:21:52,761:INFO:Base model : Light Gradient Boosting Machine
2023-10-24 15:21:52,761:INFO:Importing untrained ensembler
2023-10-24 15:21:52,761:INFO:Ensemble method set to Bagging
2023-10-24 15:21:52,762:INFO:SubProcess create_model() called ==================================
2023-10-24 15:21:52,764:INFO:Initializing create_model()
2023-10-24 15:21:52,764:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa4b4b588e0>, estimator=BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                                         feature_fraction=0.4,
                                         min_child_samples=41,
                                         min_split_gain=0.9, n_estimators=260,
                                         n_jobs=-1, num_leaves=70,
                                         random_state=123, reg_alpha=2,
                                         reg_lambda=3),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa4b578b2b0>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 15:21:52,764:INFO:Checking exceptions
2023-10-24 15:21:52,764:INFO:Importing libraries
2023-10-24 15:21:52,764:INFO:Copying training dataset
2023-10-24 15:21:52,784:INFO:Defining folds
2023-10-24 15:21:52,784:INFO:Declaring metric variables
2023-10-24 15:21:52,784:INFO:Importing untrained model
2023-10-24 15:21:52,784:INFO:Declaring custom model
2023-10-24 15:21:52,786:INFO:Bagging Regressor Imported successfully
2023-10-24 15:21:52,786:INFO:Starting cross validation
2023-10-24 15:21:52,788:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 15:22:16,720:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:22:16,720:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:22:16,720:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:22:16,810:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:22:16,810:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:22:16,811:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:22:16,868:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023316 seconds.
2023-10-24 15:22:16,868:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 15:22:16,868:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 15:22:16,869:INFO:[LightGBM] [Info] Total Bins 6595
2023-10-24 15:22:16,872:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 48
2023-10-24 15:22:16,887:INFO:[LightGBM] [Info] Start training from score 97.322509
2023-10-24 15:23:00,361:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:23:00,361:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:23:00,361:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:23:00,438:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:23:00,438:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:23:00,438:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:23:00,484:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018624 seconds.
2023-10-24 15:23:00,484:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 15:23:00,484:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 15:23:00,484:INFO:[LightGBM] [Info] Total Bins 6595
2023-10-24 15:23:00,487:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 48
2023-10-24 15:23:00,495:INFO:[LightGBM] [Info] Start training from score 96.419103
2023-10-24 15:23:43,707:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:23:43,709:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:23:43,709:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:23:43,790:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:23:43,791:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:23:43,791:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:23:43,830:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013911 seconds.
2023-10-24 15:23:43,830:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 15:23:43,830:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 15:23:43,831:INFO:[LightGBM] [Info] Total Bins 6595
2023-10-24 15:23:43,833:INFO:[LightGBM] [Info] Number of data points in the train set: 32819, number of used features: 48
2023-10-24 15:23:43,845:INFO:[LightGBM] [Info] Start training from score 95.095963
2023-10-24 15:24:27,721:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6,
                                                          bagging_freq=2,
                                                          feature_fraction=0.4,
                                                          min_child_samples=41,
                                                          min_split_gain=0.9,
                                                          n_estimators=260,
                                                          n_jobs=-1,
                                                          num_leaves=70,
                                                          random_state=123,
                                                          reg_alpha=2,
                                                          reg_lambda=3),
                                  random_state=123))])
2023-10-24 15:24:27,722:INFO:create_model() successfully completed......................................
2023-10-24 15:24:28,185:INFO:_master_model_container: 4
2023-10-24 15:24:28,185:INFO:_display_container: 4
2023-10-24 15:24:28,341:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6,
                                                          bagging_freq=2,
                                                          feature_fraction=0.4,
                                                          min_child_samples=41,
                                                          min_split_gain=0.9,
                                                          n_estimators=260,
                                                          n_jobs=-1,
                                                          num_leaves=70,
                                                          random_state=123,
                                                          reg_alpha=2,
                                                          reg_lambda=3),
                                  random_state=123))])
2023-10-24 15:24:28,341:INFO:finalize_model() successfully completed......................................
2023-10-24 15:24:28,731:INFO:Initializing save_model()
2023-10-24 15:24:28,731:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6,
                                                          bagging_freq=2,
                                                          feature_fraction=0.4,
                                                          min_child_samples=41,
                                                          min_split_gain=0.9,
                                                          n_estimators=260,
                                                          n_jobs=-1,
                                                          num_leaves=70,
                                                          random_state=123,
                                                          reg_alpha=2,
                                                          reg_lambda=3),
                                  random_state=123))]), model_name=final_model_for_location_B, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_...
NaN   -1
dtype: int64},
                                                                        {'col': 'rime',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-24 15:24:28,731:INFO:Adding model into prep_pipe
2023-10-24 15:24:28,731:WARNING:Only Model saved as it was a pipeline.
2023-10-24 15:24:29,167:INFO:final_model_for_location_B.pkl saved in current working directory
2023-10-24 15:24:29,324:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6,
                                                          bagging_freq=2,
                                                          feature_fraction=0.4,
                                                          min_child_samples=41,
                                                          min_split_gain=0.9,
                                                          n_estimators=260,
                                                          n_jobs=-1,
                                                          num_leaves=70,
                                                          random_state=123,
                                                          reg_alpha=2,
                                                          reg_lambda=3),
                                  random_state=123))])
2023-10-24 15:24:29,324:INFO:save_model() successfully completed......................................
2023-10-24 15:24:29,698:INFO:PyCaret RegressionExperiment
2023-10-24 15:24:29,698:INFO:Logging name: exp_C
2023-10-24 15:24:29,698:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 15:24:29,699:INFO:version 3.1.0
2023-10-24 15:24:29,699:INFO:Initializing setup()
2023-10-24 15:24:29,699:INFO:self.USI: a54f
2023-10-24 15:24:29,699:INFO:self._variable_keys: {'exp_id', 'target_param', 'USI', 'data', 'fold_shuffle_param', 'log_plots_param', 'X_test', 'memory', 'idx', 'y', 'X', 'X_train', 'gpu_n_jobs_param', 'n_jobs_param', 'gpu_param', 'logging_param', 'fold_generator', 'pipeline', 'y_test', 'y_train', '_ml_usecase', '_available_plots', 'html_param', 'exp_name_log', 'transform_target_param', 'seed', 'fold_groups_param'}
2023-10-24 15:24:29,699:INFO:Checking environment
2023-10-24 15:24:29,699:INFO:python_version: 3.8.5
2023-10-24 15:24:29,699:INFO:python_build: ('default', 'Sep  4 2020 02:22:02')
2023-10-24 15:24:29,699:INFO:machine: x86_64
2023-10-24 15:24:29,699:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-10-24 15:24:29,699:INFO:Memory: svmem(total=8589934592, available=2118017024, percent=75.3, used=4337291264, free=34193408, active=2088116224, inactive=2067992576, wired=2249175040)
2023-10-24 15:24:29,699:INFO:Physical Core: 4
2023-10-24 15:24:29,699:INFO:Logical Core: 8
2023-10-24 15:24:29,699:INFO:Checking libraries
2023-10-24 15:24:29,699:INFO:System:
2023-10-24 15:24:29,699:INFO:    python: 3.8.5 (default, Sep  4 2020, 02:22:02)  [Clang 10.0.0 ]
2023-10-24 15:24:29,699:INFO:executable: /Users/kaja/opt/anaconda3/bin/python
2023-10-24 15:24:29,700:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-10-24 15:24:29,700:INFO:PyCaret required dependencies:
2023-10-24 15:24:29,700:INFO:                 pip: 23.3.1
2023-10-24 15:24:29,700:INFO:          setuptools: 68.2.2
2023-10-24 15:24:29,700:INFO:             pycaret: 3.1.0
2023-10-24 15:24:29,700:INFO:             IPython: 7.19.0
2023-10-24 15:24:29,700:INFO:          ipywidgets: 8.1.1
2023-10-24 15:24:29,700:INFO:                tqdm: 4.66.1
2023-10-24 15:24:29,700:INFO:               numpy: 1.23.5
2023-10-24 15:24:29,700:INFO:              pandas: 1.5.3
2023-10-24 15:24:29,700:INFO:              jinja2: 3.1.2
2023-10-24 15:24:29,700:INFO:               scipy: 1.10.1
2023-10-24 15:24:29,700:INFO:              joblib: 1.3.2
2023-10-24 15:24:29,700:INFO:             sklearn: 1.2.2
2023-10-24 15:24:29,700:INFO:                pyod: 1.1.0
2023-10-24 15:24:29,700:INFO:            imblearn: 0.11.0
2023-10-24 15:24:29,700:INFO:   category_encoders: 2.6.2
2023-10-24 15:24:29,700:INFO:            lightgbm: 4.1.0
2023-10-24 15:24:29,700:INFO:               numba: 0.58.1
2023-10-24 15:24:29,701:INFO:            requests: 2.28.2
2023-10-24 15:24:29,701:INFO:          matplotlib: 3.7.3
2023-10-24 15:24:29,701:INFO:          scikitplot: 0.3.7
2023-10-24 15:24:29,701:INFO:         yellowbrick: 1.5
2023-10-24 15:24:29,701:INFO:              plotly: 5.17.0
2023-10-24 15:24:29,701:INFO:    plotly-resampler: Not installed
2023-10-24 15:24:29,701:INFO:             kaleido: 0.2.1
2023-10-24 15:24:29,701:INFO:           schemdraw: 0.15
2023-10-24 15:24:29,701:INFO:         statsmodels: 0.14.0
2023-10-24 15:24:29,701:INFO:              sktime: 0.21.1
2023-10-24 15:24:29,701:INFO:               tbats: 1.1.3
2023-10-24 15:24:29,701:INFO:            pmdarima: 2.0.4
2023-10-24 15:24:29,701:INFO:              psutil: 5.9.6
2023-10-24 15:24:29,701:INFO:          markupsafe: 2.1.2
2023-10-24 15:24:29,701:INFO:             pickle5: Not installed
2023-10-24 15:24:29,701:INFO:         cloudpickle: 1.6.0
2023-10-24 15:24:29,701:INFO:         deprecation: 2.1.0
2023-10-24 15:24:29,701:INFO:              xxhash: 3.4.1
2023-10-24 15:24:29,701:INFO:           wurlitzer: 2.0.1
2023-10-24 15:24:29,701:INFO:PyCaret optional dependencies:
2023-10-24 15:24:29,702:INFO:                shap: Not installed
2023-10-24 15:24:29,702:INFO:           interpret: Not installed
2023-10-24 15:24:29,702:INFO:                umap: Not installed
2023-10-24 15:24:29,702:INFO:     ydata_profiling: Not installed
2023-10-24 15:24:29,702:INFO:  explainerdashboard: Not installed
2023-10-24 15:24:29,702:INFO:             autoviz: Not installed
2023-10-24 15:24:29,702:INFO:           fairlearn: Not installed
2023-10-24 15:24:29,702:INFO:          deepchecks: Not installed
2023-10-24 15:24:29,702:INFO:             xgboost: Not installed
2023-10-24 15:24:29,702:INFO:            catboost: 1.0.4
2023-10-24 15:24:29,702:INFO:              kmodes: Not installed
2023-10-24 15:24:29,702:INFO:             mlxtend: Not installed
2023-10-24 15:24:29,702:INFO:       statsforecast: Not installed
2023-10-24 15:24:29,703:INFO:        tune_sklearn: Not installed
2023-10-24 15:24:29,703:INFO:                 ray: Not installed
2023-10-24 15:24:29,703:INFO:            hyperopt: Not installed
2023-10-24 15:24:29,703:INFO:              optuna: Not installed
2023-10-24 15:24:29,703:INFO:               skopt: Not installed
2023-10-24 15:24:29,703:INFO:              mlflow: 2.7.1
2023-10-24 15:24:29,703:INFO:              gradio: Not installed
2023-10-24 15:24:29,703:INFO:             fastapi: Not installed
2023-10-24 15:24:29,703:INFO:             uvicorn: Not installed
2023-10-24 15:24:29,703:INFO:              m2cgen: Not installed
2023-10-24 15:24:29,703:INFO:           evidently: Not installed
2023-10-24 15:24:29,703:INFO:               fugue: Not installed
2023-10-24 15:24:29,704:INFO:           streamlit: Not installed
2023-10-24 15:24:29,704:INFO:             prophet: Not installed
2023-10-24 15:24:29,704:INFO:None
2023-10-24 15:24:29,704:INFO:Set up data.
2023-10-24 15:24:29,750:INFO:Set up folding strategy.
2023-10-24 15:24:29,750:INFO:Set up train/test split.
2023-10-24 15:24:29,778:INFO:Set up index.
2023-10-24 15:24:29,781:INFO:Assigning column types.
2023-10-24 15:24:29,796:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 15:24:29,796:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 15:24:29,804:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 15:24:29,812:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 15:24:29,917:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 15:24:29,992:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 15:24:29,992:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 15:24:29,993:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 15:24:29,994:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 15:24:30,002:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 15:24:30,011:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 15:24:30,141:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 15:24:30,216:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 15:24:30,217:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 15:24:30,217:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 15:24:30,218:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 15:24:30,226:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 15:24:30,233:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 15:24:30,339:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 15:24:30,413:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 15:24:30,414:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 15:24:30,414:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 15:24:30,422:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 15:24:30,430:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 15:24:30,545:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 15:24:30,622:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 15:24:30,623:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 15:24:30,623:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 15:24:30,624:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 15:24:30,639:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 15:24:30,744:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 15:24:30,819:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 15:24:30,821:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 15:24:30,821:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 15:24:30,838:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 15:24:30,944:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 15:24:31,019:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 15:24:31,020:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 15:24:31,020:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 15:24:31,021:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 15:24:31,142:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 15:24:31,215:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 15:24:31,216:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 15:24:31,216:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 15:24:31,336:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 15:24:31,410:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 15:24:31,411:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 15:24:31,411:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 15:24:31,412:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 15:24:31,604:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 15:24:31,678:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 15:24:31,679:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 15:24:31,798:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 15:24:31,872:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 15:24:31,872:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 15:24:31,873:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 15:24:32,068:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 15:24:32,068:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 15:24:32,271:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 15:24:32,272:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 15:24:32,273:INFO:Preparing preprocessing pipeline...
2023-10-24 15:24:32,273:INFO:Set up date feature engineering.
2023-10-24 15:24:32,273:INFO:Set up simple imputation.
2023-10-24 15:24:32,288:INFO:Set up encoding of ordinal features.
2023-10-24 15:24:32,314:INFO:Set up encoding of categorical features.
2023-10-24 15:24:32,316:INFO:Set up column name cleaning.
2023-10-24 15:24:32,620:INFO:Finished creating preprocessing pipeline.
2023-10-24 15:24:32,761:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_...
NaN   -1
dtype: int64},
                                                                        {'col': 'rime',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 15:24:32,761:INFO:Creating final display dataframe.
2023-10-24 15:24:33,210:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (26071, 50)
4        Transformed data shape  (26071, 52)
5   Transformed train set shape  (18249, 52)
6    Transformed test set shape   (7822, 52)
7              Ordinal features            4
8              Numeric features           44
9                 Date features            1
10         Categorical features            4
11     Rows with missing values        25.0%
12                   Preprocess         True
13              Imputation type       simple
14           Numeric imputation         mean
15       Categorical imputation         mode
16     Maximum one-hot encoding           25
17              Encoding method         None
18               Fold Generator        KFold
19                  Fold Number           10
20                     CPU Jobs           -1
21                      Use GPU        False
22               Log Experiment        False
23              Experiment Name        exp_C
24                          USI         a54f
2023-10-24 15:24:33,411:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 15:24:33,411:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 15:24:33,609:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 15:24:33,609:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 15:24:33,611:INFO:setup() successfully completed in 3.92s...............
2023-10-24 15:24:33,611:INFO:Initializing create_model()
2023-10-24 15:24:33,611:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dc2954b80>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 15:24:33,611:INFO:Checking exceptions
2023-10-24 15:24:33,616:INFO:Importing libraries
2023-10-24 15:24:33,616:INFO:Copying training dataset
2023-10-24 15:24:33,639:INFO:Defining folds
2023-10-24 15:24:33,640:INFO:Declaring metric variables
2023-10-24 15:24:33,640:INFO:Importing untrained model
2023-10-24 15:24:33,640:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 15:24:33,641:INFO:Starting cross validation
2023-10-24 15:24:33,643:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 15:24:39,174:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:24:39,174:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:24:39,174:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:24:39,174:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:24:39,174:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:24:39,174:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:24:39,174:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:24:39,174:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:24:39,174:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:24:39,174:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:24:39,174:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:24:39,174:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:24:39,174:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:24:39,174:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:24:39,174:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:24:39,174:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:24:39,175:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:24:39,175:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:24:39,175:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:24:39,175:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:24:39,175:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:24:39,175:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:24:39,176:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:24:39,176:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 15:24:41,528:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075302 seconds.
2023-10-24 15:24:41,529:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 15:24:41,642:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 15:24:41,663:INFO:[LightGBM] [Info] Total Bins 6714
2023-10-24 15:24:41,663:INFO:[LightGBM] [Info] Number of data points in the train set: 16424, number of used features: 49
2023-10-24 15:24:41,663:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052550 seconds.
2023-10-24 15:24:41,663:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 15:24:41,663:INFO:[LightGBM] [Info] Total Bins 6709
2023-10-24 15:24:41,663:INFO:[LightGBM] [Info] Number of data points in the train set: 16424, number of used features: 49
2023-10-24 15:24:41,663:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053272 seconds.
2023-10-24 15:24:41,663:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 15:24:41,663:INFO:[LightGBM] [Info] Total Bins 6711
2023-10-24 15:24:41,663:INFO:[LightGBM] [Info] Start training from score 77.463200
2023-10-24 15:24:41,663:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042225 seconds.
2023-10-24 15:24:41,663:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 15:24:41,663:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 15:24:41,664:INFO:[LightGBM] [Info] Total Bins 6715
2023-10-24 15:24:41,664:INFO:[LightGBM] [Info] Number of data points in the train set: 16424, number of used features: 49
2023-10-24 15:24:41,664:INFO:[LightGBM] [Info] Number of data points in the train set: 16424, number of used features: 49
2023-10-24 15:24:41,664:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073456 seconds.
2023-10-24 15:24:41,664:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 15:24:41,664:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 15:24:41,664:INFO:[LightGBM] [Info] Total Bins 6713
2023-10-24 15:24:41,664:INFO:[LightGBM] [Info] Start training from score 77.258357
2023-10-24 15:24:41,664:INFO:[LightGBM] [Info] Number of data points in the train set: 16424, number of used features: 49
2023-10-24 15:24:41,664:INFO:[LightGBM] [Info] Start training from score 77.705286
2023-10-24 15:24:41,664:INFO:[LightGBM] [Info] Start training from score 77.203223
2023-10-24 15:24:41,664:INFO:[LightGBM] [Info] Start training from score 76.868720
2023-10-24 15:24:41,664:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040457 seconds.
2023-10-24 15:24:41,664:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 15:24:41,664:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 15:24:41,665:INFO:[LightGBM] [Info] Total Bins 6706
2023-10-24 15:24:41,665:INFO:[LightGBM] [Info] Number of data points in the train set: 16424, number of used features: 49
2023-10-24 15:24:41,665:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036938 seconds.
2023-10-24 15:24:41,665:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 15:24:41,665:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 15:24:41,665:INFO:[LightGBM] [Info] Total Bins 6712
2023-10-24 15:24:41,665:INFO:[LightGBM] [Info] Number of data points in the train set: 16424, number of used features: 49
2023-10-24 15:24:41,665:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036059 seconds.
2023-10-24 15:24:41,665:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 15:24:41,665:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 15:24:41,665:INFO:[LightGBM] [Info] Total Bins 6710
2023-10-24 15:24:41,665:INFO:[LightGBM] [Info] Start training from score 77.527225
2023-10-24 15:24:41,665:INFO:[LightGBM] [Info] Start training from score 76.706501
2023-10-24 15:24:41,665:INFO:[LightGBM] [Info] Number of data points in the train set: 16424, number of used features: 49
2023-10-24 15:24:41,665:INFO:[LightGBM] [Info] Start training from score 77.065269
2023-10-24 15:24:55,831:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025148 seconds.
2023-10-24 15:24:55,831:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 15:24:55,832:INFO:[LightGBM] [Info] Total Bins 6703
2023-10-24 15:24:55,833:INFO:[LightGBM] [Info] Number of data points in the train set: 16425, number of used features: 49
2023-10-24 15:24:55,837:INFO:[LightGBM] [Info] Start training from score 77.033459
2023-10-24 15:24:55,841:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023017 seconds.
2023-10-24 15:24:55,841:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 15:24:55,841:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 15:24:55,842:INFO:[LightGBM] [Info] Total Bins 6705
2023-10-24 15:24:55,843:INFO:[LightGBM] [Info] Number of data points in the train set: 16424, number of used features: 49
2023-10-24 15:24:55,846:INFO:[LightGBM] [Info] Start training from score 76.770684
2023-10-24 15:25:04,887:INFO:Calculating mean and std
2023-10-24 15:25:04,891:INFO:Creating metrics dataframe
2023-10-24 15:25:04,896:INFO:Finalizing model
2023-10-24 15:25:05,275:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019016 seconds.
2023-10-24 15:25:05,275:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 15:25:05,275:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 15:25:05,275:INFO:[LightGBM] [Info] Total Bins 6726
2023-10-24 15:25:05,277:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 49
2023-10-24 15:25:05,279:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-24 15:25:12,552:INFO:Uploading results into container
2023-10-24 15:25:12,554:INFO:Uploading model into container now
2023-10-24 15:25:12,560:INFO:_master_model_container: 1
2023-10-24 15:25:12,560:INFO:_display_container: 2
2023-10-24 15:25:12,561:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 15:25:12,561:INFO:create_model() successfully completed......................................
2023-10-24 15:25:12,705:INFO:Initializing tune_model()
2023-10-24 15:25:12,705:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dc2954b80>)
2023-10-24 15:25:12,705:INFO:Checking exceptions
2023-10-24 15:25:12,723:INFO:Copying training dataset
2023-10-24 15:25:12,737:INFO:Checking base model
2023-10-24 15:25:12,737:INFO:Base model : Light Gradient Boosting Machine
2023-10-24 15:25:12,738:INFO:Declaring metric variables
2023-10-24 15:25:12,738:INFO:Defining Hyperparameters
2023-10-24 15:25:12,847:INFO:Tuning with n_jobs=-1
2023-10-24 15:25:12,847:INFO:Initializing RandomizedSearchCV
2023-10-24 15:54:00,301:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-24 15:54:00,311:INFO:Hyperparameter search completed
2023-10-24 15:54:00,312:INFO:SubProcess create_model() called ==================================
2023-10-24 15:54:00,314:INFO:Initializing create_model()
2023-10-24 15:54:00,314:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dc2954b80>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9d423b2fd0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-24 15:54:00,314:INFO:Checking exceptions
2023-10-24 15:54:00,315:INFO:Importing libraries
2023-10-24 15:54:00,315:INFO:Copying training dataset
2023-10-24 15:54:00,354:INFO:Defining folds
2023-10-24 15:54:00,355:INFO:Declaring metric variables
2023-10-24 15:54:00,356:INFO:Importing untrained model
2023-10-24 15:54:00,356:INFO:Declaring custom model
2023-10-24 15:54:00,358:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 15:54:00,359:INFO:Starting cross validation
2023-10-24 15:54:00,362:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 15:55:50,923:INFO:Calculating mean and std
2023-10-24 15:55:50,939:INFO:Creating metrics dataframe
2023-10-24 15:55:50,993:INFO:Finalizing model
2023-10-24 15:55:51,346:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:55:51,347:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:55:51,347:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:55:51,398:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 15:55:51,402:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2

2023-10-24 15:55:51,415:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 15:55:51,415:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 15:55:51,456:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005328 seconds.
2023-10-24 15:55:51,460:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 15:55:51,460:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 15:55:51,460:INFO:[LightGBM] [Info] Total Bins 6726
2023-10-24 15:55:51,462:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 49
2023-10-24 15:55:51,466:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-24 15:55:51,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-24 15:55:51,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-24 15:55:51,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-24 15:55:51,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-24 15:55:51,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-24 15:55:51,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-24 15:55:51,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-24 15:55:51,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-24 15:56:03,453:INFO:Uploading results into container
2023-10-24 15:56:03,455:INFO:Uploading model into container now
2023-10-24 15:56:03,461:INFO:_master_model_container: 2
2023-10-24 15:56:03,461:INFO:_display_container: 3
2023-10-24 15:56:03,463:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-24 15:56:03,463:INFO:create_model() successfully completed......................................
2023-10-24 15:56:04,054:INFO:SubProcess create_model() end ==================================
2023-10-24 15:56:04,054:INFO:choose_better activated
2023-10-24 15:56:04,055:INFO:SubProcess create_model() called ==================================
2023-10-24 15:56:04,056:INFO:Initializing create_model()
2023-10-24 15:56:04,056:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dc2954b80>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 15:56:04,056:INFO:Checking exceptions
2023-10-24 15:56:04,060:INFO:Importing libraries
2023-10-24 15:56:04,060:INFO:Copying training dataset
2023-10-24 15:56:04,087:INFO:Defining folds
2023-10-24 15:56:04,087:INFO:Declaring metric variables
2023-10-24 15:56:04,088:INFO:Importing untrained model
2023-10-24 15:56:04,088:INFO:Declaring custom model
2023-10-24 15:56:04,089:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 15:56:04,089:INFO:Starting cross validation
2023-10-24 15:56:04,091:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 15:56:17,202:INFO:Calculating mean and std
2023-10-24 15:56:17,202:INFO:Creating metrics dataframe
2023-10-24 15:56:17,205:INFO:Finalizing model
2023-10-24 15:56:17,506:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008343 seconds.
2023-10-24 15:56:17,506:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 15:56:17,506:INFO:[LightGBM] [Info] Total Bins 6726
2023-10-24 15:56:17,507:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 49
2023-10-24 15:56:17,508:INFO:[LightGBM] [Info] Start training from score 77.160192
2023-10-24 15:56:19,819:INFO:Uploading results into container
2023-10-24 15:56:19,820:INFO:Uploading model into container now
2023-10-24 15:56:19,821:INFO:_master_model_container: 3
2023-10-24 15:56:19,821:INFO:_display_container: 4
2023-10-24 15:56:19,821:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 15:56:19,821:INFO:create_model() successfully completed......................................
2023-10-24 15:56:19,923:INFO:SubProcess create_model() end ==================================
2023-10-24 15:56:19,924:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.9089
2023-10-24 15:56:19,925:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.9017
2023-10-24 15:56:19,926:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-24 15:56:19,926:INFO:choose_better completed
2023-10-24 15:56:19,926:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-24 15:56:19,933:INFO:_master_model_container: 3
2023-10-24 15:56:19,933:INFO:_display_container: 3
2023-10-24 15:56:19,934:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 15:56:19,934:INFO:tune_model() successfully completed......................................
2023-10-24 15:56:20,035:INFO:Initializing ensemble_model()
2023-10-24 15:56:20,035:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dc2954b80>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-24 15:56:20,035:INFO:Checking exceptions
2023-10-24 15:56:20,055:INFO:Importing libraries
2023-10-24 15:56:20,056:INFO:Copying training dataset
2023-10-24 15:56:20,056:INFO:Checking base model
2023-10-24 15:56:20,056:INFO:Base model : Light Gradient Boosting Machine
2023-10-24 15:56:20,056:INFO:Importing untrained ensembler
2023-10-24 15:56:20,056:INFO:Ensemble method set to Bagging
2023-10-24 15:56:20,057:INFO:SubProcess create_model() called ==================================
2023-10-24 15:56:20,058:INFO:Initializing create_model()
2023-10-24 15:56:20,058:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dc2954b80>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9dca0c62e0>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 15:56:20,058:INFO:Checking exceptions
2023-10-24 15:56:20,058:INFO:Importing libraries
2023-10-24 15:56:20,058:INFO:Copying training dataset
2023-10-24 15:56:20,074:INFO:Defining folds
2023-10-24 15:56:20,074:INFO:Declaring metric variables
2023-10-24 15:56:20,074:INFO:Importing untrained model
2023-10-24 15:56:20,074:INFO:Declaring custom model
2023-10-24 15:56:20,076:INFO:Bagging Regressor Imported successfully
2023-10-24 15:56:20,076:INFO:Starting cross validation
2023-10-24 15:56:20,078:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 15:59:17,296:INFO:Calculating mean and std
2023-10-24 15:59:17,307:INFO:Creating metrics dataframe
2023-10-24 15:59:17,325:INFO:Finalizing model
2023-10-24 15:59:17,684:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008389 seconds.
2023-10-24 15:59:17,684:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 15:59:17,684:INFO:[LightGBM] [Info] Total Bins 6726
2023-10-24 15:59:17,685:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 49
2023-10-24 15:59:17,687:INFO:[LightGBM] [Info] Start training from score 77.044367
2023-10-24 15:59:20,083:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006006 seconds.
2023-10-24 15:59:20,084:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 15:59:20,084:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 15:59:20,084:INFO:[LightGBM] [Info] Total Bins 6726
2023-10-24 15:59:20,085:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 49
2023-10-24 15:59:20,086:INFO:[LightGBM] [Info] Start training from score 76.520588
2023-10-24 15:59:22,160:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006793 seconds.
2023-10-24 15:59:22,160:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 15:59:22,160:INFO:[LightGBM] [Info] Total Bins 6726
2023-10-24 15:59:22,161:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 49
2023-10-24 15:59:22,162:INFO:[LightGBM] [Info] Start training from score 76.462170
2023-10-24 15:59:25,853:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022220 seconds.
2023-10-24 15:59:25,853:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 15:59:25,853:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 15:59:25,853:INFO:[LightGBM] [Info] Total Bins 6726
2023-10-24 15:59:25,854:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 49
2023-10-24 15:59:25,856:INFO:[LightGBM] [Info] Start training from score 77.386428
2023-10-24 15:59:28,403:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008226 seconds.
2023-10-24 15:59:28,404:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 15:59:28,404:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 15:59:28,405:INFO:[LightGBM] [Info] Total Bins 6726
2023-10-24 15:59:28,405:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 49
2023-10-24 15:59:28,406:INFO:[LightGBM] [Info] Start training from score 73.916304
2023-10-24 15:59:30,456:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007413 seconds.
2023-10-24 15:59:30,456:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 15:59:30,456:INFO:[LightGBM] [Info] Total Bins 6726
2023-10-24 15:59:30,457:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 49
2023-10-24 15:59:30,458:INFO:[LightGBM] [Info] Start training from score 75.879633
2023-10-24 15:59:32,640:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007928 seconds.
2023-10-24 15:59:32,640:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 15:59:32,641:INFO:[LightGBM] [Info] Total Bins 6726
2023-10-24 15:59:32,642:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 49
2023-10-24 15:59:32,642:INFO:[LightGBM] [Info] Start training from score 75.615395
2023-10-24 15:59:35,081:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009988 seconds.
2023-10-24 15:59:35,081:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 15:59:35,081:INFO:[LightGBM] [Info] Total Bins 6726
2023-10-24 15:59:35,082:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 49
2023-10-24 15:59:35,083:INFO:[LightGBM] [Info] Start training from score 79.544595
2023-10-24 15:59:37,539:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007480 seconds.
2023-10-24 15:59:37,542:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 15:59:37,542:INFO:[LightGBM] [Info] Total Bins 6726
2023-10-24 15:59:37,543:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 49
2023-10-24 15:59:37,543:INFO:[LightGBM] [Info] Start training from score 76.012052
2023-10-24 15:59:39,882:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007765 seconds.
2023-10-24 15:59:39,882:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 15:59:39,882:INFO:[LightGBM] [Info] Total Bins 6726
2023-10-24 15:59:39,883:INFO:[LightGBM] [Info] Number of data points in the train set: 18249, number of used features: 49
2023-10-24 15:59:39,884:INFO:[LightGBM] [Info] Start training from score 78.124037
2023-10-24 15:59:42,178:INFO:Uploading results into container
2023-10-24 15:59:42,180:INFO:Uploading model into container now
2023-10-24 15:59:42,181:INFO:_master_model_container: 4
2023-10-24 15:59:42,182:INFO:_display_container: 4
2023-10-24 15:59:42,183:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-24 15:59:42,184:INFO:create_model() successfully completed......................................
2023-10-24 15:59:42,436:INFO:SubProcess create_model() end ==================================
2023-10-24 15:59:42,442:INFO:_master_model_container: 4
2023-10-24 15:59:42,442:INFO:_display_container: 4
2023-10-24 15:59:42,443:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-24 15:59:42,443:INFO:ensemble_model() successfully completed......................................
2023-10-24 15:59:42,539:INFO:Initializing finalize_model()
2023-10-24 15:59:42,539:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dc2954b80>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-24 15:59:42,540:INFO:Finalizing BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-24 15:59:42,559:INFO:Initializing create_model()
2023-10-24 15:59:42,559:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dc2954b80>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-24 15:59:42,559:INFO:Checking exceptions
2023-10-24 15:59:42,560:INFO:Importing libraries
2023-10-24 15:59:42,560:INFO:Copying training dataset
2023-10-24 15:59:42,561:INFO:Defining folds
2023-10-24 15:59:42,561:INFO:Declaring metric variables
2023-10-24 15:59:42,562:INFO:Importing untrained model
2023-10-24 15:59:42,562:INFO:Declaring custom model
2023-10-24 15:59:42,563:INFO:Bagging Regressor Imported successfully
2023-10-24 15:59:42,565:INFO:Cross validation set to False
2023-10-24 15:59:42,565:INFO:Fitting Model
2023-10-24 15:59:42,986:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009292 seconds.
2023-10-24 15:59:42,986:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 15:59:42,986:INFO:[LightGBM] [Info] Total Bins 6800
2023-10-24 15:59:42,987:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 49
2023-10-24 15:59:42,988:INFO:[LightGBM] [Info] Start training from score 77.360615
2023-10-24 15:59:45,620:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009005 seconds.
2023-10-24 15:59:45,621:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 15:59:45,621:INFO:[LightGBM] [Info] Total Bins 6800
2023-10-24 15:59:45,622:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 49
2023-10-24 15:59:45,623:INFO:[LightGBM] [Info] Start training from score 78.162759
2023-10-24 15:59:48,029:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009040 seconds.
2023-10-24 15:59:48,029:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 15:59:48,030:INFO:[LightGBM] [Info] Total Bins 6800
2023-10-24 15:59:48,030:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 49
2023-10-24 15:59:48,032:INFO:[LightGBM] [Info] Start training from score 77.185434
2023-10-24 15:59:50,418:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008787 seconds.
2023-10-24 15:59:50,418:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 15:59:50,418:INFO:[LightGBM] [Info] Total Bins 6800
2023-10-24 15:59:50,419:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 49
2023-10-24 15:59:50,420:INFO:[LightGBM] [Info] Start training from score 78.293126
2023-10-24 15:59:52,702:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009756 seconds.
2023-10-24 15:59:52,703:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 15:59:52,703:INFO:[LightGBM] [Info] Total Bins 6800
2023-10-24 15:59:52,704:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 49
2023-10-24 15:59:52,705:INFO:[LightGBM] [Info] Start training from score 75.493649
2023-10-24 15:59:56,049:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013875 seconds.
2023-10-24 15:59:56,049:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 15:59:56,049:INFO:[LightGBM] [Info] Total Bins 6800
2023-10-24 15:59:56,050:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 49
2023-10-24 15:59:56,052:INFO:[LightGBM] [Info] Start training from score 77.467219
2023-10-24 15:59:58,593:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008061 seconds.
2023-10-24 15:59:58,593:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 15:59:58,593:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 15:59:58,594:INFO:[LightGBM] [Info] Total Bins 6800
2023-10-24 15:59:58,595:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 49
2023-10-24 15:59:58,596:INFO:[LightGBM] [Info] Start training from score 77.083598
2023-10-24 16:00:00,975:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009502 seconds.
2023-10-24 16:00:00,975:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 16:00:00,975:INFO:[LightGBM] [Info] Total Bins 6800
2023-10-24 16:00:00,976:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 49
2023-10-24 16:00:00,977:INFO:[LightGBM] [Info] Start training from score 79.854607
2023-10-24 16:00:03,304:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009665 seconds.
2023-10-24 16:00:03,304:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 16:00:03,304:INFO:[LightGBM] [Info] Total Bins 6800
2023-10-24 16:00:03,305:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 49
2023-10-24 16:00:03,306:INFO:[LightGBM] [Info] Start training from score 76.153078
2023-10-24 16:00:05,556:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009136 seconds.
2023-10-24 16:00:05,556:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 16:00:05,556:INFO:[LightGBM] [Info] Total Bins 6800
2023-10-24 16:00:05,557:INFO:[LightGBM] [Info] Number of data points in the train set: 26071, number of used features: 49
2023-10-24 16:00:05,558:INFO:[LightGBM] [Info] Start training from score 78.843978
2023-10-24 16:00:06,766:INFO:Calculating mean and std
2023-10-24 16:00:06,789:INFO:Creating metrics dataframe
2023-10-24 16:00:06,815:INFO:Finalizing model
2023-10-24 16:00:06,874:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-24 16:00:06,874:INFO:create_model() successfully completed......................................
2023-10-24 16:00:06,973:INFO:_master_model_container: 4
2023-10-24 16:00:06,974:INFO:_display_container: 4
2023-10-24 16:00:07,072:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-24 16:00:07,072:INFO:finalize_model() successfully completed......................................
2023-10-24 16:00:07,140:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 16:00:07,140:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 16:00:07,140:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 16:00:07,204:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 16:00:07,204:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 16:00:07,204:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 16:00:07,216:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006687 seconds.
2023-10-24 16:00:07,216:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 16:00:07,217:INFO:[LightGBM] [Info] Total Bins 7783
2023-10-24 16:00:07,219:INFO:[LightGBM] [Info] Number of data points in the train set: 22976, number of used features: 53
2023-10-24 16:00:07,221:INFO:[LightGBM] [Info] Start training from score 96.916183
2023-10-24 16:00:07,418:INFO:Initializing save_model()
2023-10-24 16:00:07,419:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), model_name=final_model_for_location_C, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_...
NaN   -1
dtype: int64},
                                                                        {'col': 'rime',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-24 16:00:07,419:INFO:Adding model into prep_pipe
2023-10-24 16:00:07,419:WARNING:Only Model saved as it was a pipeline.
2023-10-24 16:00:07,474:INFO:final_model_for_location_C.pkl saved in current working directory
2023-10-24 16:00:07,606:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date_forecast'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2...
                                                                        {'col': 'is_day:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64},
                                                                        {'col': 'is_in_shadow:idx',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-24 16:00:07,606:INFO:save_model() successfully completed......................................
2023-10-24 16:00:09,524:INFO:Initializing load_model()
2023-10-24 16:00:09,525:INFO:load_model(model_name=final_model_for_location_A, platform=None, authentication=None, verbose=True)
2023-10-24 16:00:09,640:INFO:Initializing load_model()
2023-10-24 16:00:09,640:INFO:load_model(model_name=final_model_for_location_B, platform=None, authentication=None, verbose=True)
2023-10-24 16:00:09,796:INFO:Initializing load_model()
2023-10-24 16:00:09,796:INFO:load_model(model_name=final_model_for_location_C, platform=None, authentication=None, verbose=True)
2023-10-24 16:00:09,870:INFO:Initializing predict_model()
2023-10-24 16:00:09,870:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9dc2954b80>, estimator=Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             '...
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6,
                                                          bagging_freq=2,
                                                          feature_fraction=0.4,
                                                          min_child_samples=41,
                                                          min_split_gain=0.9,
                                                          n_estimators=260,
                                                          n_jobs=-1,
                                                          num_leaves=70,
                                                          random_state=123,
                                                          reg_alpha=2,
                                                          reg_lambda=3),
                                  random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f9d4933d040>)
2023-10-24 16:00:09,870:INFO:Checking exceptions
2023-10-24 16:00:09,870:INFO:Preloading libraries
2023-10-24 16:00:09,871:INFO:Set up data.
2023-10-24 16:00:09,898:INFO:Set up index.
2023-10-24 16:00:10,302:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 16:00:10,302:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 16:00:10,302:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 16:00:10,346:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 16:00:10,346:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 16:00:10,347:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 16:00:10,355:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005373 seconds.
2023-10-24 16:00:10,355:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 16:00:10,356:INFO:[LightGBM] [Info] Total Bins 7783
2023-10-24 16:00:10,358:INFO:[LightGBM] [Info] Number of data points in the train set: 22976, number of used features: 53
2023-10-24 16:00:10,359:INFO:[LightGBM] [Info] Start training from score 98.362982
2023-10-24 16:00:11,157:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 16:00:11,157:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 16:00:11,157:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 16:00:11,202:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 16:00:11,202:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 16:00:11,202:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 16:00:11,211:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006314 seconds.
2023-10-24 16:00:11,211:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 16:00:11,212:INFO:[LightGBM] [Info] Total Bins 7783
2023-10-24 16:00:11,214:INFO:[LightGBM] [Info] Number of data points in the train set: 22976, number of used features: 53
2023-10-24 16:00:11,215:INFO:[LightGBM] [Info] Start training from score 99.135759
2023-10-24 16:00:12,020:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 16:00:12,020:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 16:00:12,021:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 16:00:12,070:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 16:00:12,070:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 16:00:12,070:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 16:00:12,078:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005110 seconds.
2023-10-24 16:00:12,078:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 16:00:12,079:INFO:[LightGBM] [Info] Total Bins 7783
2023-10-24 16:00:12,081:INFO:[LightGBM] [Info] Number of data points in the train set: 22976, number of used features: 53
2023-10-24 16:00:12,082:INFO:[LightGBM] [Info] Start training from score 96.116652
2023-10-24 16:00:12,876:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 16:00:12,876:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 16:00:12,876:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 16:00:12,922:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 16:00:12,923:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 16:00:12,923:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 16:00:12,934:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006551 seconds.
2023-10-24 16:00:12,934:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 16:00:12,935:INFO:[LightGBM] [Info] Total Bins 7783
2023-10-24 16:00:12,937:INFO:[LightGBM] [Info] Number of data points in the train set: 22976, number of used features: 53
2023-10-24 16:00:12,938:INFO:[LightGBM] [Info] Start training from score 96.087856
2023-10-24 16:00:13,805:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 16:00:13,805:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 16:00:13,805:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 16:00:13,850:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 16:00:13,850:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 16:00:13,850:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 16:00:13,858:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005189 seconds.
2023-10-24 16:00:13,858:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 16:00:13,859:INFO:[LightGBM] [Info] Total Bins 7783
2023-10-24 16:00:13,861:INFO:[LightGBM] [Info] Number of data points in the train set: 22976, number of used features: 53
2023-10-24 16:00:13,863:INFO:[LightGBM] [Info] Start training from score 97.124739
2023-10-24 16:00:17,137:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 16:00:17,137:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 16:00:17,137:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 16:00:17,192:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 16:00:17,192:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 16:00:17,192:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 16:00:17,201:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006170 seconds.
2023-10-24 16:00:17,201:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 16:00:17,203:INFO:[LightGBM] [Info] Total Bins 7783
2023-10-24 16:00:17,205:INFO:[LightGBM] [Info] Number of data points in the train set: 22976, number of used features: 53
2023-10-24 16:00:17,205:INFO:[LightGBM] [Info] Start training from score 98.263794
2023-10-24 16:00:18,002:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 16:00:18,002:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 16:00:18,002:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 16:00:18,048:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 16:00:18,048:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 16:00:18,048:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 16:00:18,058:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005851 seconds.
2023-10-24 16:00:18,058:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 16:00:18,059:INFO:[LightGBM] [Info] Total Bins 7783
2023-10-24 16:00:18,061:INFO:[LightGBM] [Info] Number of data points in the train set: 22976, number of used features: 53
2023-10-24 16:00:18,062:INFO:[LightGBM] [Info] Start training from score 98.588858
2023-10-24 16:00:18,974:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 16:00:18,974:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 16:00:18,974:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 16:00:19,059:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 16:00:19,059:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 16:00:19,059:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 16:00:19,068:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006279 seconds.
2023-10-24 16:00:19,068:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 16:00:19,070:INFO:[LightGBM] [Info] Total Bins 7783
2023-10-24 16:00:19,071:INFO:[LightGBM] [Info] Number of data points in the train set: 22976, number of used features: 53
2023-10-24 16:00:19,072:INFO:[LightGBM] [Info] Start training from score 99.280716
2023-10-24 16:00:20,199:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 16:00:20,199:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 16:00:20,199:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 16:00:20,243:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 16:00:20,243:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 16:00:20,243:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 16:00:20,250:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003914 seconds.
2023-10-24 16:00:20,250:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 16:00:20,251:INFO:[LightGBM] [Info] Total Bins 7783
2023-10-24 16:00:20,253:INFO:[LightGBM] [Info] Number of data points in the train set: 22976, number of used features: 53
2023-10-24 16:00:20,253:INFO:[LightGBM] [Info] Start training from score 96.256244
2023-10-24 16:00:21,016:INFO:Uploading results into container
2023-10-24 16:00:21,017:INFO:Uploading model into container now
2023-10-24 16:00:21,019:INFO:_master_model_container: 4
2023-10-24 16:00:21,019:INFO:_display_container: 4
2023-10-24 16:00:21,022:INFO:BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                                         feature_fraction=0.4,
                                         min_child_samples=41,
                                         min_split_gain=0.9, n_estimators=260,
                                         n_jobs=-1, num_leaves=70,
                                         random_state=123, reg_alpha=2,
                                         reg_lambda=3),
                 random_state=123)
2023-10-24 16:00:21,022:INFO:create_model() successfully completed......................................
2023-10-24 16:00:21,745:INFO:SubProcess create_model() end ==================================
2023-10-24 16:00:21,750:INFO:_master_model_container: 4
2023-10-24 16:00:21,750:INFO:_display_container: 4
2023-10-24 16:00:21,753:INFO:BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                                         feature_fraction=0.4,
                                         min_child_samples=41,
                                         min_split_gain=0.9, n_estimators=260,
                                         n_jobs=-1, num_leaves=70,
                                         random_state=123, reg_alpha=2,
                                         reg_lambda=3),
                 random_state=123)
2023-10-24 16:00:21,753:INFO:ensemble_model() successfully completed......................................
2023-10-24 16:00:21,841:INFO:Initializing finalize_model()
2023-10-24 16:00:21,841:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa4b4b588e0>, estimator=BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                                         feature_fraction=0.4,
                                         min_child_samples=41,
                                         min_split_gain=0.9, n_estimators=260,
                                         n_jobs=-1, num_leaves=70,
                                         random_state=123, reg_alpha=2,
                                         reg_lambda=3),
                 random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-24 16:00:21,843:INFO:Finalizing BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                                         feature_fraction=0.4,
                                         min_child_samples=41,
                                         min_split_gain=0.9, n_estimators=260,
                                         n_jobs=-1, num_leaves=70,
                                         random_state=123, reg_alpha=2,
                                         reg_lambda=3),
                 random_state=123)
2023-10-24 16:00:21,885:INFO:Initializing create_model()
2023-10-24 16:00:21,886:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa4b4b588e0>, estimator=BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                                         feature_fraction=0.4,
                                         min_child_samples=41,
                                         min_split_gain=0.9, n_estimators=260,
                                         n_jobs=-1, num_leaves=70,
                                         random_state=123, reg_alpha=2,
                                         reg_lambda=3),
                 random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-24 16:00:21,886:INFO:Checking exceptions
2023-10-24 16:00:21,887:INFO:Importing libraries
2023-10-24 16:00:21,887:INFO:Copying training dataset
2023-10-24 16:00:21,889:INFO:Defining folds
2023-10-24 16:00:21,889:INFO:Declaring metric variables
2023-10-24 16:00:21,889:INFO:Importing untrained model
2023-10-24 16:00:21,889:INFO:Declaring custom model
2023-10-24 16:00:21,890:INFO:Bagging Regressor Imported successfully
2023-10-24 16:00:21,892:INFO:Cross validation set to False
2023-10-24 16:00:21,892:INFO:Fitting Model
2023-10-24 16:00:22,204:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 16:00:22,204:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 16:00:22,204:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 16:00:22,263:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 16:00:22,264:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 16:00:22,264:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 16:00:22,275:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001327 seconds.
2023-10-24 16:00:22,275:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 16:00:22,275:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 16:00:22,275:INFO:[LightGBM] [Info] Total Bins 7880
2023-10-24 16:00:22,277:INFO:[LightGBM] [Info] Number of data points in the train set: 32823, number of used features: 54
2023-10-24 16:00:22,278:INFO:[LightGBM] [Info] Start training from score 93.825920
2023-10-24 16:00:23,195:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 16:00:23,195:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 16:00:23,195:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 16:00:23,256:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 16:00:23,256:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 16:00:23,256:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 16:00:23,265:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006015 seconds.
2023-10-24 16:00:23,265:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 16:00:23,265:INFO:[LightGBM] [Info] Total Bins 7880
2023-10-24 16:00:23,267:INFO:[LightGBM] [Info] Number of data points in the train set: 32823, number of used features: 54
2023-10-24 16:00:23,268:INFO:[LightGBM] [Info] Start training from score 96.688231
2023-10-24 16:00:24,102:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 16:00:24,103:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 16:00:24,103:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 16:00:24,165:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 16:00:24,165:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 16:00:24,165:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 16:00:24,174:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001501 seconds.
2023-10-24 16:00:24,174:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 16:00:24,174:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 16:00:24,174:INFO:[LightGBM] [Info] Total Bins 7880
2023-10-24 16:00:24,176:INFO:[LightGBM] [Info] Number of data points in the train set: 32823, number of used features: 54
2023-10-24 16:00:24,177:INFO:[LightGBM] [Info] Start training from score 96.871196
2023-10-24 16:00:25,162:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 16:00:25,162:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 16:00:25,162:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 16:00:25,235:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 16:00:25,236:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 16:00:25,236:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 16:00:25,251:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009761 seconds.
2023-10-24 16:00:25,251:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 16:00:25,252:INFO:[LightGBM] [Info] Total Bins 7880
2023-10-24 16:00:25,254:INFO:[LightGBM] [Info] Number of data points in the train set: 32823, number of used features: 54
2023-10-24 16:00:25,255:INFO:[LightGBM] [Info] Start training from score 96.707576
2023-10-24 16:00:26,377:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 16:00:26,377:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 16:00:26,377:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 16:00:26,444:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 16:00:26,444:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 16:00:26,444:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 16:00:26,454:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001958 seconds.
2023-10-24 16:00:26,454:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 16:00:26,454:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 16:00:26,454:INFO:[LightGBM] [Info] Total Bins 7880
2023-10-24 16:00:26,456:INFO:[LightGBM] [Info] Number of data points in the train set: 32823, number of used features: 54
2023-10-24 16:00:26,457:INFO:[LightGBM] [Info] Start training from score 95.812279
2023-10-24 16:00:27,428:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 16:00:27,428:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 16:00:27,428:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 16:00:27,496:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 16:00:27,496:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 16:00:27,496:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 16:00:27,506:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006424 seconds.
2023-10-24 16:00:27,506:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 16:00:27,507:INFO:[LightGBM] [Info] Total Bins 7880
2023-10-24 16:00:27,509:INFO:[LightGBM] [Info] Number of data points in the train set: 32823, number of used features: 54
2023-10-24 16:00:27,510:INFO:[LightGBM] [Info] Start training from score 97.305582
2023-10-24 16:00:28,363:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 16:00:28,363:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 16:00:28,363:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 16:00:28,435:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 16:00:28,435:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 16:00:28,435:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 16:00:28,444:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006282 seconds.
2023-10-24 16:00:28,444:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 16:00:28,446:INFO:[LightGBM] [Info] Total Bins 7880
2023-10-24 16:00:28,448:INFO:[LightGBM] [Info] Number of data points in the train set: 32823, number of used features: 54
2023-10-24 16:00:28,449:INFO:[LightGBM] [Info] Start training from score 97.788672
2023-10-24 16:00:29,432:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 16:00:29,432:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 16:00:29,433:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 16:00:29,499:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 16:00:29,499:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 16:00:29,499:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 16:00:29,509:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006501 seconds.
2023-10-24 16:00:29,509:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 16:00:29,511:INFO:[LightGBM] [Info] Total Bins 7880
2023-10-24 16:00:29,512:INFO:[LightGBM] [Info] Number of data points in the train set: 32823, number of used features: 54
2023-10-24 16:00:29,513:INFO:[LightGBM] [Info] Start training from score 97.461131
2023-10-24 16:00:30,364:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 16:00:30,364:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 16:00:30,364:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 16:00:30,430:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 16:00:30,430:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 16:00:30,431:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 16:00:30,442:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008077 seconds.
2023-10-24 16:00:30,442:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 16:00:30,443:INFO:[LightGBM] [Info] Total Bins 7880
2023-10-24 16:00:30,445:INFO:[LightGBM] [Info] Number of data points in the train set: 32823, number of used features: 54
2023-10-24 16:00:30,446:INFO:[LightGBM] [Info] Start training from score 98.387361
2023-10-24 16:00:31,274:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 16:00:31,275:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 16:00:31,275:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 16:00:31,341:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 16:00:31,341:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 16:00:31,341:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 16:00:31,351:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001686 seconds.
2023-10-24 16:00:31,351:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 16:00:31,351:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 16:00:31,351:INFO:[LightGBM] [Info] Total Bins 7880
2023-10-24 16:00:31,353:INFO:[LightGBM] [Info] Number of data points in the train set: 32823, number of used features: 54
2023-10-24 16:00:31,354:INFO:[LightGBM] [Info] Start training from score 94.002376
2023-10-24 16:00:32,273:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6,
                                                          bagging_freq=2,
                                                          feature_fraction=0.4,
                                                          min_child_samples=41,
                                                          min_split_gain=0.9,
                                                          n_estimators=260,
                                                          n_jobs=-1,
                                                          num_leaves=70,
                                                          random_state=123,
                                                          reg_alpha=2,
                                                          reg_lambda=3),
                                  random_state=123))])
2023-10-24 16:00:32,273:INFO:create_model() successfully completed......................................
2023-10-24 16:00:32,360:INFO:_master_model_container: 4
2023-10-24 16:00:32,360:INFO:_display_container: 4
2023-10-24 16:00:32,377:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6,
                                                          bagging_freq=2,
                                                          feature_fraction=0.4,
                                                          min_child_samples=41,
                                                          min_split_gain=0.9,
                                                          n_estimators=260,
                                                          n_jobs=-1,
                                                          num_leaves=70,
                                                          random_state=123,
                                                          reg_alpha=2,
                                                          reg_lambda=3),
                                  random_state=123))])
2023-10-24 16:00:32,377:INFO:finalize_model() successfully completed......................................
2023-10-24 16:00:32,479:INFO:Initializing save_model()
2023-10-24 16:00:32,479:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6,
                                                          bagging_freq=2,
                                                          feature_fraction=0.4,
                                                          min_child_samples=41,
                                                          min_split_gain=0.9,
                                                          n_estimators=260,
                                                          n_jobs=-1,
                                                          num_leaves=70,
                                                          random_state=123,
                                                          reg_alpha=2,
                                                          reg_lambda=3),
                                  random_state=123))]), model_name=final_model_for_location_B, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             '...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx', 'is_day:idx',
                                             'is_in_shadow:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx',
                                                                    'is_day:idx',
                                                                    'is_in_shadow:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-24 16:00:32,479:INFO:Adding model into prep_pipe
2023-10-24 16:00:32,479:WARNING:Only Model saved as it was a pipeline.
2023-10-24 16:00:32,860:INFO:final_model_for_location_B.pkl saved in current working directory
2023-10-24 16:00:32,879:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6,
                                                          bagging_freq=2,
                                                          feature_fraction=0.4,
                                                          min_child_samples=41,
                                                          min_split_gain=0.9,
                                                          n_estimators=260,
                                                          n_jobs=-1,
                                                          num_leaves=70,
                                                          random_state=123,
                                                          reg_alpha=2,
                                                          reg_lambda=3),
                                  random_state=123))])
2023-10-24 16:00:32,879:INFO:save_model() successfully completed......................................
2023-10-24 16:00:33,022:INFO:Initializing predict_model()
2023-10-24 16:00:33,022:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa4b4b588e0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(bagging_fraction=0.6,
                                                          bagging_freq=2,
                                                          feature_fraction=0.4,
                                                          min_child_samples=41,
                                                          min_split_gain=0.9,
                                                          n_estimators=260,
                                                          n_jobs=-1,
                                                          num_leaves=70,
                                                          random_state=123,
                                                          reg_alpha=2,
                                                          reg_lambda=3),
                                  random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa4ca50c550>)
2023-10-24 16:00:33,023:INFO:Checking exceptions
2023-10-24 16:00:33,023:INFO:Preloading libraries
2023-10-24 16:00:33,023:INFO:Set up data.
2023-10-24 16:00:33,038:INFO:Set up index.
2023-10-24 16:00:33,572:WARNING:<ipython-input-15-49df83f3379d>:13: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  estimated_resampled = estimated.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 16:00:33,578:WARNING:<ipython-input-15-49df83f3379d>:14: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  test_resampled = test.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()

2023-10-24 16:00:33,650:INFO:PyCaret RegressionExperiment
2023-10-24 16:00:33,650:INFO:Logging name: exp_C
2023-10-24 16:00:33,650:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-24 16:00:33,650:INFO:version 3.1.0
2023-10-24 16:00:33,650:INFO:Initializing setup()
2023-10-24 16:00:33,650:INFO:self.USI: 213f
2023-10-24 16:00:33,650:INFO:self._variable_keys: {'pipeline', 'fold_shuffle_param', 'idx', '_ml_usecase', 'transform_target_param', 'seed', 'X_test', 'gpu_n_jobs_param', 'exp_name_log', 'log_plots_param', 'X_train', 'memory', 'target_param', 'USI', 'fold_generator', 'logging_param', 'html_param', '_available_plots', 'data', 'y_train', 'y_test', 'fold_groups_param', 'gpu_param', 'X', 'n_jobs_param', 'y', 'exp_id'}
2023-10-24 16:00:33,651:INFO:Checking environment
2023-10-24 16:00:33,651:INFO:python_version: 3.8.5
2023-10-24 16:00:33,651:INFO:python_build: ('default', 'Sep  4 2020 02:22:02')
2023-10-24 16:00:33,651:INFO:machine: x86_64
2023-10-24 16:00:33,651:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-10-24 16:00:33,651:INFO:Memory: svmem(total=8589934592, available=2222751744, percent=74.1, used=4205428736, free=111702016, active=2112942080, inactive=2082557952, wired=2092486656)
2023-10-24 16:00:33,651:INFO:Physical Core: 4
2023-10-24 16:00:33,651:INFO:Logical Core: 8
2023-10-24 16:00:33,651:INFO:Checking libraries
2023-10-24 16:00:33,651:INFO:System:
2023-10-24 16:00:33,651:INFO:    python: 3.8.5 (default, Sep  4 2020, 02:22:02)  [Clang 10.0.0 ]
2023-10-24 16:00:33,651:INFO:executable: /Users/kaja/opt/anaconda3/bin/python
2023-10-24 16:00:33,651:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-10-24 16:00:33,652:INFO:PyCaret required dependencies:
2023-10-24 16:00:33,652:INFO:                 pip: 23.3.1
2023-10-24 16:00:33,652:INFO:          setuptools: 68.2.2
2023-10-24 16:00:33,652:INFO:             pycaret: 3.1.0
2023-10-24 16:00:33,652:INFO:             IPython: 7.19.0
2023-10-24 16:00:33,652:INFO:          ipywidgets: 8.1.1
2023-10-24 16:00:33,652:INFO:                tqdm: 4.66.1
2023-10-24 16:00:33,652:INFO:               numpy: 1.23.5
2023-10-24 16:00:33,652:INFO:              pandas: 1.5.3
2023-10-24 16:00:33,652:INFO:              jinja2: 3.1.2
2023-10-24 16:00:33,652:INFO:               scipy: 1.10.1
2023-10-24 16:00:33,652:INFO:              joblib: 1.3.2
2023-10-24 16:00:33,652:INFO:             sklearn: 1.2.2
2023-10-24 16:00:33,652:INFO:                pyod: 1.1.0
2023-10-24 16:00:33,652:INFO:            imblearn: 0.11.0
2023-10-24 16:00:33,652:INFO:   category_encoders: 2.6.2
2023-10-24 16:00:33,652:INFO:            lightgbm: 4.1.0
2023-10-24 16:00:33,652:INFO:               numba: 0.58.1
2023-10-24 16:00:33,652:INFO:            requests: 2.28.2
2023-10-24 16:00:33,652:INFO:          matplotlib: 3.7.3
2023-10-24 16:00:33,652:INFO:          scikitplot: 0.3.7
2023-10-24 16:00:33,652:INFO:         yellowbrick: 1.5
2023-10-24 16:00:33,652:INFO:              plotly: 5.17.0
2023-10-24 16:00:33,652:INFO:    plotly-resampler: Not installed
2023-10-24 16:00:33,652:INFO:             kaleido: 0.2.1
2023-10-24 16:00:33,653:INFO:           schemdraw: 0.15
2023-10-24 16:00:33,653:INFO:         statsmodels: 0.14.0
2023-10-24 16:00:33,653:INFO:              sktime: 0.21.1
2023-10-24 16:00:33,653:INFO:               tbats: 1.1.3
2023-10-24 16:00:33,653:INFO:            pmdarima: 2.0.4
2023-10-24 16:00:33,653:INFO:              psutil: 5.9.6
2023-10-24 16:00:33,653:INFO:          markupsafe: 2.1.2
2023-10-24 16:00:33,653:INFO:             pickle5: Not installed
2023-10-24 16:00:33,653:INFO:         cloudpickle: 1.6.0
2023-10-24 16:00:33,653:INFO:         deprecation: 2.1.0
2023-10-24 16:00:33,653:INFO:              xxhash: 3.4.1
2023-10-24 16:00:33,653:INFO:           wurlitzer: 2.0.1
2023-10-24 16:00:33,653:INFO:PyCaret optional dependencies:
2023-10-24 16:00:33,653:INFO:                shap: Not installed
2023-10-24 16:00:33,653:INFO:           interpret: Not installed
2023-10-24 16:00:33,653:INFO:                umap: Not installed
2023-10-24 16:00:33,653:INFO:     ydata_profiling: Not installed
2023-10-24 16:00:33,653:INFO:  explainerdashboard: Not installed
2023-10-24 16:00:33,653:INFO:             autoviz: Not installed
2023-10-24 16:00:33,653:INFO:           fairlearn: Not installed
2023-10-24 16:00:33,653:INFO:          deepchecks: Not installed
2023-10-24 16:00:33,653:INFO:             xgboost: Not installed
2023-10-24 16:00:33,653:INFO:            catboost: 1.0.4
2023-10-24 16:00:33,653:INFO:              kmodes: Not installed
2023-10-24 16:00:33,653:INFO:             mlxtend: Not installed
2023-10-24 16:00:33,653:INFO:       statsforecast: Not installed
2023-10-24 16:00:33,654:INFO:        tune_sklearn: Not installed
2023-10-24 16:00:33,654:INFO:                 ray: Not installed
2023-10-24 16:00:33,654:INFO:            hyperopt: Not installed
2023-10-24 16:00:33,654:INFO:              optuna: Not installed
2023-10-24 16:00:33,654:INFO:               skopt: Not installed
2023-10-24 16:00:33,654:INFO:              mlflow: 2.7.1
2023-10-24 16:00:33,654:INFO:              gradio: Not installed
2023-10-24 16:00:33,654:INFO:             fastapi: Not installed
2023-10-24 16:00:33,654:INFO:             uvicorn: Not installed
2023-10-24 16:00:33,654:INFO:              m2cgen: Not installed
2023-10-24 16:00:33,654:INFO:           evidently: Not installed
2023-10-24 16:00:33,654:INFO:               fugue: Not installed
2023-10-24 16:00:33,654:INFO:           streamlit: Not installed
2023-10-24 16:00:33,654:INFO:             prophet: Not installed
2023-10-24 16:00:33,654:INFO:None
2023-10-24 16:00:33,654:INFO:Set up data.
2023-10-24 16:00:33,694:INFO:Set up folding strategy.
2023-10-24 16:00:33,694:INFO:Set up train/test split.
2023-10-24 16:00:33,718:INFO:Set up index.
2023-10-24 16:00:33,719:INFO:Assigning column types.
2023-10-24 16:00:33,729:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-24 16:00:33,729:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 16:00:33,734:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 16:00:33,739:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 16:00:33,805:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 16:00:33,852:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 16:00:33,853:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 16:00:33,853:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 16:00:33,853:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-24 16:00:33,858:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 16:00:33,863:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 16:00:33,929:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 16:00:33,976:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 16:00:33,976:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 16:00:33,977:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 16:00:33,977:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-24 16:00:33,982:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 16:00:33,987:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 16:00:34,055:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 16:00:34,100:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 16:00:34,101:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 16:00:34,101:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 16:00:34,106:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-24 16:00:34,111:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 16:00:34,175:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 16:00:34,220:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 16:00:34,221:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 16:00:34,221:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 16:00:34,222:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-24 16:00:34,231:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 16:00:34,294:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 16:00:34,338:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 16:00:34,339:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 16:00:34,339:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 16:00:34,349:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-24 16:00:34,415:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 16:00:34,460:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 16:00:34,460:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 16:00:34,461:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 16:00:34,461:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-24 16:00:34,536:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 16:00:34,579:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 16:00:34,580:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 16:00:34,580:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 16:00:34,654:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 16:00:34,701:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-24 16:00:34,701:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 16:00:34,725:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 16:00:34,726:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-24 16:00:34,802:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 16:00:34,848:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 16:00:34,849:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 16:00:34,923:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-24 16:00:34,969:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 16:00:34,969:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 16:00:34,970:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-24 16:00:35,088:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 16:00:35,088:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 16:00:35,204:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 16:00:35,204:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 16:00:35,205:INFO:Preparing preprocessing pipeline...
2023-10-24 16:00:35,205:INFO:Set up simple imputation.
2023-10-24 16:00:35,211:INFO:Set up encoding of categorical features.
2023-10-24 16:00:35,213:INFO:Set up column name cleaning.
2023-10-24 16:00:35,427:INFO:Finished creating preprocessing pipeline.
2023-10-24 16:00:35,490:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             '...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx', 'is_day:idx',
                                             'is_in_shadow:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx',
                                                                    'is_day:idx',
                                                                    'is_in_shadow:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-24 16:00:35,490:INFO:Creating final display dataframe.
2023-10-24 16:00:35,727:INFO:Setup _display_container:                     Description        Value
0                    Session id          123
1                        Target       target
2                   Target type   Regression
3           Original data shape  (32130, 46)
4        Transformed data shape  (32130, 62)
5   Transformed train set shape  (22491, 62)
6    Transformed test set shape   (9639, 62)
7              Numeric features           42
8          Categorical features            3
9      Rows with missing values        93.5%
10                   Preprocess         True
11              Imputation type       simple
12           Numeric imputation         mean
13       Categorical imputation         mode
14     Maximum one-hot encoding           25
15              Encoding method         None
16               Fold Generator        KFold
17                  Fold Number           10
18                     CPU Jobs           -1
19                      Use GPU        False
20               Log Experiment        False
21              Experiment Name        exp_C
22                          USI         213f
2023-10-24 16:00:35,868:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 16:00:35,869:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 16:00:35,987:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-24 16:00:35,987:INFO:Soft dependency imported: catboost: 1.0.4
2023-10-24 16:00:35,988:INFO:setup() successfully completed in 2.34s...............
2023-10-24 16:00:35,988:INFO:Initializing create_model()
2023-10-24 16:00:35,988:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa4b4b58820>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 16:00:35,988:INFO:Checking exceptions
2023-10-24 16:00:35,992:INFO:Importing libraries
2023-10-24 16:00:35,993:INFO:Copying training dataset
2023-10-24 16:00:36,009:INFO:Defining folds
2023-10-24 16:00:36,009:INFO:Declaring metric variables
2023-10-24 16:00:36,009:INFO:Importing untrained model
2023-10-24 16:00:36,009:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 16:00:36,009:INFO:Starting cross validation
2023-10-24 16:00:36,011:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 16:00:46,666:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 16:00:46,666:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 16:00:46,667:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 16:00:46,667:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 16:00:46,666:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 16:00:46,667:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 16:00:46,667:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 16:00:46,668:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 16:00:46,668:WARNING:/Users/kaja/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)

2023-10-24 16:00:48,530:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010197 seconds.
2023-10-24 16:00:48,531:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 16:00:48,531:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 16:00:48,531:INFO:[LightGBM] [Info] Total Bins 8179
2023-10-24 16:00:48,532:INFO:[LightGBM] [Info] Number of data points in the train set: 20242, number of used features: 58
2023-10-24 16:00:48,533:INFO:[LightGBM] [Info] Start training from score 62.257451
2023-10-24 16:00:48,533:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007826 seconds.
2023-10-24 16:00:48,533:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 16:00:48,533:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 16:00:48,533:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007672 seconds.
2023-10-24 16:00:48,533:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-24 16:00:48,533:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-24 16:00:48,533:INFO:[LightGBM] [Info] Total Bins 8176
2023-10-24 16:00:48,533:INFO:[LightGBM] [Info] Total Bins 8177
2023-10-24 16:00:48,534:INFO:[LightGBM] [Info] Number of data points in the train set: 20242, number of used features: 58
2023-10-24 16:00:48,534:INFO:[LightGBM] [Info] Number of data points in the train set: 20242, number of used features: 58
2023-10-24 16:00:48,535:INFO:[LightGBM] [Info] Start training from score 62.394221
2023-10-24 16:00:48,535:INFO:[LightGBM] [Info] Start training from score 62.457627
2023-10-24 16:00:51,698:INFO:Calculating mean and std
2023-10-24 16:00:51,702:INFO:Creating metrics dataframe
2023-10-24 16:00:51,706:INFO:Finalizing model
2023-10-24 16:00:52,013:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008152 seconds.
2023-10-24 16:00:52,013:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 16:00:52,013:INFO:[LightGBM] [Info] Total Bins 8210
2023-10-24 16:00:52,014:INFO:[LightGBM] [Info] Number of data points in the train set: 22491, number of used features: 58
2023-10-24 16:00:52,015:INFO:[LightGBM] [Info] Start training from score 62.727538
2023-10-24 16:00:52,480:INFO:Uploading results into container
2023-10-24 16:00:52,482:INFO:Uploading model into container now
2023-10-24 16:00:52,489:INFO:_master_model_container: 1
2023-10-24 16:00:52,489:INFO:_display_container: 2
2023-10-24 16:00:52,490:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 16:00:52,490:INFO:create_model() successfully completed......................................
2023-10-24 16:00:52,598:INFO:Initializing tune_model()
2023-10-24 16:00:52,598:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa4b4b58820>)
2023-10-24 16:00:52,598:INFO:Checking exceptions
2023-10-24 16:00:52,614:INFO:Copying training dataset
2023-10-24 16:00:52,628:INFO:Checking base model
2023-10-24 16:00:52,628:INFO:Base model : Light Gradient Boosting Machine
2023-10-24 16:00:52,629:INFO:Declaring metric variables
2023-10-24 16:00:52,629:INFO:Defining Hyperparameters
2023-10-24 16:00:52,709:INFO:Tuning with n_jobs=-1
2023-10-24 16:00:52,709:INFO:Initializing RandomizedSearchCV
2023-10-24 16:22:00,213:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-24 16:22:00,230:INFO:Hyperparameter search completed
2023-10-24 16:22:00,232:INFO:SubProcess create_model() called ==================================
2023-10-24 16:22:00,244:INFO:Initializing create_model()
2023-10-24 16:22:00,244:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa4b4b58820>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa4ca557d30>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-24 16:22:00,246:INFO:Checking exceptions
2023-10-24 16:22:00,250:INFO:Importing libraries
2023-10-24 16:22:00,250:INFO:Copying training dataset
2023-10-24 16:22:00,292:INFO:Defining folds
2023-10-24 16:22:00,293:INFO:Declaring metric variables
2023-10-24 16:22:00,295:INFO:Importing untrained model
2023-10-24 16:22:00,295:INFO:Declaring custom model
2023-10-24 16:22:00,302:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 16:22:00,303:INFO:Starting cross validation
2023-10-24 16:22:00,308:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 16:22:50,382:INFO:Calculating mean and std
2023-10-24 16:22:50,386:INFO:Creating metrics dataframe
2023-10-24 16:22:50,392:INFO:Finalizing model
2023-10-24 16:22:50,639:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 16:22:50,639:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 16:22:50,639:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 16:22:50,684:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-24 16:22:50,684:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-10-24 16:22:50,684:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-24 16:22:50,692:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005299 seconds.
2023-10-24 16:22:50,692:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 16:22:50,695:INFO:[LightGBM] [Info] Total Bins 8210
2023-10-24 16:22:50,697:INFO:[LightGBM] [Info] Number of data points in the train set: 22491, number of used features: 58
2023-10-24 16:22:50,698:INFO:[LightGBM] [Info] Start training from score 62.727538
2023-10-24 16:22:51,470:INFO:Uploading results into container
2023-10-24 16:22:51,471:INFO:Uploading model into container now
2023-10-24 16:22:51,472:INFO:_master_model_container: 2
2023-10-24 16:22:51,472:INFO:_display_container: 3
2023-10-24 16:22:51,473:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2023-10-24 16:22:51,474:INFO:create_model() successfully completed......................................
2023-10-24 16:22:51,823:INFO:SubProcess create_model() end ==================================
2023-10-24 16:22:51,823:INFO:choose_better activated
2023-10-24 16:22:51,824:INFO:SubProcess create_model() called ==================================
2023-10-24 16:22:51,825:INFO:Initializing create_model()
2023-10-24 16:22:51,825:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa4b4b58820>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-24 16:22:51,825:INFO:Checking exceptions
2023-10-24 16:22:51,828:INFO:Importing libraries
2023-10-24 16:22:51,828:INFO:Copying training dataset
2023-10-24 16:22:51,849:INFO:Defining folds
2023-10-24 16:22:51,850:INFO:Declaring metric variables
2023-10-24 16:22:51,850:INFO:Importing untrained model
2023-10-24 16:22:51,850:INFO:Declaring custom model
2023-10-24 16:22:51,851:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-24 16:22:51,851:INFO:Starting cross validation
2023-10-24 16:22:51,852:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 16:23:00,604:INFO:Calculating mean and std
2023-10-24 16:23:00,606:INFO:Creating metrics dataframe
2023-10-24 16:23:00,608:INFO:Finalizing model
2023-10-24 16:23:00,877:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005679 seconds.
2023-10-24 16:23:00,878:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 16:23:00,878:INFO:[LightGBM] [Info] Total Bins 8210
2023-10-24 16:23:00,878:INFO:[LightGBM] [Info] Number of data points in the train set: 22491, number of used features: 58
2023-10-24 16:23:00,879:INFO:[LightGBM] [Info] Start training from score 62.727538
2023-10-24 16:23:01,046:INFO:Uploading results into container
2023-10-24 16:23:01,046:INFO:Uploading model into container now
2023-10-24 16:23:01,047:INFO:_master_model_container: 3
2023-10-24 16:23:01,047:INFO:_display_container: 4
2023-10-24 16:23:01,047:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 16:23:01,047:INFO:create_model() successfully completed......................................
2023-10-24 16:23:01,132:INFO:SubProcess create_model() end ==================================
2023-10-24 16:23:01,132:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8255
2023-10-24 16:23:01,133:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.8197
2023-10-24 16:23:01,134:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2023-10-24 16:23:01,134:INFO:choose_better completed
2023-10-24 16:23:01,134:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-24 16:23:01,139:INFO:_master_model_container: 3
2023-10-24 16:23:01,139:INFO:_display_container: 3
2023-10-24 16:23:01,140:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-24 16:23:01,140:INFO:tune_model() successfully completed......................................
2023-10-24 16:23:01,220:INFO:Initializing ensemble_model()
2023-10-24 16:23:01,220:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa4b4b58820>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-24 16:23:01,220:INFO:Checking exceptions
2023-10-24 16:23:01,231:INFO:Importing libraries
2023-10-24 16:23:01,232:INFO:Copying training dataset
2023-10-24 16:23:01,232:INFO:Checking base model
2023-10-24 16:23:01,232:INFO:Base model : Light Gradient Boosting Machine
2023-10-24 16:23:01,233:INFO:Importing untrained ensembler
2023-10-24 16:23:01,233:INFO:Ensemble method set to Bagging
2023-10-24 16:23:01,234:INFO:SubProcess create_model() called ==================================
2023-10-24 16:23:01,235:INFO:Initializing create_model()
2023-10-24 16:23:01,235:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa4b4b58820>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa4b4bcaa60>, model_only=True, return_train_score=False, kwargs={})
2023-10-24 16:23:01,235:INFO:Checking exceptions
2023-10-24 16:23:01,236:INFO:Importing libraries
2023-10-24 16:23:01,236:INFO:Copying training dataset
2023-10-24 16:23:01,253:INFO:Defining folds
2023-10-24 16:23:01,253:INFO:Declaring metric variables
2023-10-24 16:23:01,253:INFO:Importing untrained model
2023-10-24 16:23:01,254:INFO:Declaring custom model
2023-10-24 16:23:01,254:INFO:Bagging Regressor Imported successfully
2023-10-24 16:23:01,255:INFO:Starting cross validation
2023-10-24 16:23:01,256:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-24 16:26:24,793:INFO:Calculating mean and std
2023-10-24 16:26:24,797:INFO:Creating metrics dataframe
2023-10-24 16:26:24,800:INFO:Finalizing model
2023-10-24 16:26:25,084:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006131 seconds.
2023-10-24 16:26:25,084:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 16:26:25,085:INFO:[LightGBM] [Info] Total Bins 8210
2023-10-24 16:26:25,085:INFO:[LightGBM] [Info] Number of data points in the train set: 22491, number of used features: 58
2023-10-24 16:26:25,086:INFO:[LightGBM] [Info] Start training from score 61.741961
2023-10-24 16:26:25,309:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004676 seconds.
2023-10-24 16:26:25,309:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 16:26:25,309:INFO:[LightGBM] [Info] Total Bins 8210
2023-10-24 16:26:25,310:INFO:[LightGBM] [Info] Number of data points in the train set: 22491, number of used features: 58
2023-10-24 16:26:25,311:INFO:[LightGBM] [Info] Start training from score 63.170501
2023-10-24 16:26:25,529:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004491 seconds.
2023-10-24 16:26:25,529:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 16:26:25,529:INFO:[LightGBM] [Info] Total Bins 8210
2023-10-24 16:26:25,530:INFO:[LightGBM] [Info] Number of data points in the train set: 22491, number of used features: 58
2023-10-24 16:26:25,530:INFO:[LightGBM] [Info] Start training from score 61.042905
2023-10-24 16:26:25,755:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005186 seconds.
2023-10-24 16:26:25,755:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 16:26:25,755:INFO:[LightGBM] [Info] Total Bins 8210
2023-10-24 16:26:25,756:INFO:[LightGBM] [Info] Number of data points in the train set: 22491, number of used features: 58
2023-10-24 16:26:25,756:INFO:[LightGBM] [Info] Start training from score 62.329201
2023-10-24 16:26:25,984:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006305 seconds.
2023-10-24 16:26:25,984:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 16:26:25,984:INFO:[LightGBM] [Info] Total Bins 8210
2023-10-24 16:26:25,985:INFO:[LightGBM] [Info] Number of data points in the train set: 22491, number of used features: 58
2023-10-24 16:26:25,985:INFO:[LightGBM] [Info] Start training from score 62.383617
2023-10-24 16:26:26,212:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006710 seconds.
2023-10-24 16:26:26,213:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 16:26:26,213:INFO:[LightGBM] [Info] Total Bins 8210
2023-10-24 16:26:26,214:INFO:[LightGBM] [Info] Number of data points in the train set: 22491, number of used features: 58
2023-10-24 16:26:26,214:INFO:[LightGBM] [Info] Start training from score 62.497792
2023-10-24 16:26:26,434:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006265 seconds.
2023-10-24 16:26:26,434:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 16:26:26,434:INFO:[LightGBM] [Info] Total Bins 8210
2023-10-24 16:26:26,435:INFO:[LightGBM] [Info] Number of data points in the train set: 22491, number of used features: 58
2023-10-24 16:26:26,436:INFO:[LightGBM] [Info] Start training from score 63.218627
2023-10-24 16:26:26,652:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004454 seconds.
2023-10-24 16:26:26,652:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 16:26:26,652:INFO:[LightGBM] [Info] Total Bins 8210
2023-10-24 16:26:26,653:INFO:[LightGBM] [Info] Number of data points in the train set: 22491, number of used features: 58
2023-10-24 16:26:26,653:INFO:[LightGBM] [Info] Start training from score 65.127161
2023-10-24 16:26:26,879:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005423 seconds.
2023-10-24 16:26:26,879:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 16:26:26,879:INFO:[LightGBM] [Info] Total Bins 8210
2023-10-24 16:26:26,880:INFO:[LightGBM] [Info] Number of data points in the train set: 22491, number of used features: 58
2023-10-24 16:26:26,880:INFO:[LightGBM] [Info] Start training from score 63.463028
2023-10-24 16:26:27,101:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005868 seconds.
2023-10-24 16:26:27,101:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 16:26:27,101:INFO:[LightGBM] [Info] Total Bins 8210
2023-10-24 16:26:27,102:INFO:[LightGBM] [Info] Number of data points in the train set: 22491, number of used features: 58
2023-10-24 16:26:27,102:INFO:[LightGBM] [Info] Start training from score 61.089317
2023-10-24 16:26:27,278:INFO:Uploading results into container
2023-10-24 16:26:27,280:INFO:Uploading model into container now
2023-10-24 16:26:27,281:INFO:_master_model_container: 4
2023-10-24 16:26:27,281:INFO:_display_container: 4
2023-10-24 16:26:27,282:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-24 16:26:27,282:INFO:create_model() successfully completed......................................
2023-10-24 16:26:27,369:INFO:SubProcess create_model() end ==================================
2023-10-24 16:26:27,375:INFO:_master_model_container: 4
2023-10-24 16:26:27,375:INFO:_display_container: 4
2023-10-24 16:26:27,376:INFO:BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-24 16:26:27,377:INFO:ensemble_model() successfully completed......................................
2023-10-24 16:26:27,459:INFO:Initializing finalize_model()
2023-10-24 16:26:27,459:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa4b4b58820>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-24 16:26:27,460:INFO:Finalizing BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-10-24 16:26:27,479:INFO:Initializing create_model()
2023-10-24 16:26:27,479:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa4b4b58820>, estimator=BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-24 16:26:27,479:INFO:Checking exceptions
2023-10-24 16:26:27,480:INFO:Importing libraries
2023-10-24 16:26:27,480:INFO:Copying training dataset
2023-10-24 16:26:27,481:INFO:Defining folds
2023-10-24 16:26:27,482:INFO:Declaring metric variables
2023-10-24 16:26:27,482:INFO:Importing untrained model
2023-10-24 16:26:27,482:INFO:Declaring custom model
2023-10-24 16:26:27,483:INFO:Bagging Regressor Imported successfully
2023-10-24 16:26:27,484:INFO:Cross validation set to False
2023-10-24 16:26:27,484:INFO:Fitting Model
2023-10-24 16:26:27,852:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006352 seconds.
2023-10-24 16:26:27,852:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 16:26:27,852:INFO:[LightGBM] [Info] Total Bins 8286
2023-10-24 16:26:27,853:INFO:[LightGBM] [Info] Number of data points in the train set: 32130, number of used features: 58
2023-10-24 16:26:27,853:INFO:[LightGBM] [Info] Start training from score 62.422218
2023-10-24 16:26:28,121:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006125 seconds.
2023-10-24 16:26:28,121:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 16:26:28,122:INFO:[LightGBM] [Info] Total Bins 8286
2023-10-24 16:26:28,122:INFO:[LightGBM] [Info] Number of data points in the train set: 32130, number of used features: 58
2023-10-24 16:26:28,123:INFO:[LightGBM] [Info] Start training from score 63.730349
2023-10-24 16:26:28,392:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005929 seconds.
2023-10-24 16:26:28,393:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 16:26:28,393:INFO:[LightGBM] [Info] Total Bins 8286
2023-10-24 16:26:28,393:INFO:[LightGBM] [Info] Number of data points in the train set: 32130, number of used features: 58
2023-10-24 16:26:28,394:INFO:[LightGBM] [Info] Start training from score 62.003611
2023-10-24 16:26:28,667:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006168 seconds.
2023-10-24 16:26:28,667:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 16:26:28,667:INFO:[LightGBM] [Info] Total Bins 8286
2023-10-24 16:26:28,668:INFO:[LightGBM] [Info] Number of data points in the train set: 32130, number of used features: 58
2023-10-24 16:26:28,668:INFO:[LightGBM] [Info] Start training from score 62.821574
2023-10-24 16:26:29,015:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005750 seconds.
2023-10-24 16:26:29,015:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 16:26:29,015:INFO:[LightGBM] [Info] Total Bins 8286
2023-10-24 16:26:29,016:INFO:[LightGBM] [Info] Number of data points in the train set: 32130, number of used features: 58
2023-10-24 16:26:29,016:INFO:[LightGBM] [Info] Start training from score 63.584828
2023-10-24 16:26:29,395:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009603 seconds.
2023-10-24 16:26:29,395:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 16:26:29,395:INFO:[LightGBM] [Info] Total Bins 8286
2023-10-24 16:26:29,396:INFO:[LightGBM] [Info] Number of data points in the train set: 32130, number of used features: 58
2023-10-24 16:26:29,396:INFO:[LightGBM] [Info] Start training from score 63.053357
2023-10-24 16:26:29,778:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011055 seconds.
2023-10-24 16:26:29,779:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 16:26:29,779:INFO:[LightGBM] [Info] Total Bins 8286
2023-10-24 16:26:29,780:INFO:[LightGBM] [Info] Number of data points in the train set: 32130, number of used features: 58
2023-10-24 16:26:29,780:INFO:[LightGBM] [Info] Start training from score 63.169876
2023-10-24 16:26:30,086:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007821 seconds.
2023-10-24 16:26:30,086:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 16:26:30,086:INFO:[LightGBM] [Info] Total Bins 8286
2023-10-24 16:26:30,087:INFO:[LightGBM] [Info] Number of data points in the train set: 32130, number of used features: 58
2023-10-24 16:26:30,087:INFO:[LightGBM] [Info] Start training from score 64.765657
2023-10-24 16:26:30,366:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006120 seconds.
2023-10-24 16:26:30,367:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 16:26:30,367:INFO:[LightGBM] [Info] Total Bins 8286
2023-10-24 16:26:30,367:INFO:[LightGBM] [Info] Number of data points in the train set: 32130, number of used features: 58
2023-10-24 16:26:30,368:INFO:[LightGBM] [Info] Start training from score 64.039492
2023-10-24 16:26:30,652:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007985 seconds.
2023-10-24 16:26:30,652:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-24 16:26:30,652:INFO:[LightGBM] [Info] Total Bins 8286
2023-10-24 16:26:30,653:INFO:[LightGBM] [Info] Number of data points in the train set: 32130, number of used features: 58
2023-10-24 16:26:30,653:INFO:[LightGBM] [Info] Start training from score 62.156091
2023-10-24 16:26:30,939:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                 TransformerWrapper(include=['dew_or_rime:idx', 'is_day:idx',
                                             'is_in_shadow:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx',
                                                                    'is_day:idx',
                                                                    'is_in_shadow:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-24 16:26:30,940:INFO:create_model() successfully completed......................................
2023-10-24 16:26:31,027:INFO:_master_model_container: 4
2023-10-24 16:26:31,027:INFO:_display_container: 4
2023-10-24 16:26:31,043:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                 TransformerWrapper(include=['dew_or_rime:idx', 'is_day:idx',
                                             'is_in_shadow:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx',
                                                                    'is_day:idx',
                                                                    'is_in_shadow:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-24 16:26:31,043:INFO:finalize_model() successfully completed......................................
2023-10-24 16:26:31,143:INFO:Initializing save_model()
2023-10-24 16:26:31,143:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                 TransformerWrapper(include=['dew_or_rime:idx', 'is_day:idx',
                                             'is_in_shadow:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx',
                                                                    'is_day:idx',
                                                                    'is_in_shadow:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), model_name=final_model_for_location_C, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/bs/7c8kgd8d68dbtq25fp22krqh0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             '...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['dew_or_rime:idx', 'is_day:idx',
                                             'is_in_shadow:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx',
                                                                    'is_day:idx',
                                                                    'is_in_shadow:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-24 16:26:31,143:INFO:Adding model into prep_pipe
2023-10-24 16:26:31,143:WARNING:Only Model saved as it was a pipeline.
2023-10-24 16:26:31,217:INFO:final_model_for_location_C.pkl saved in current working directory
2023-10-24 16:26:31,233:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                 TransformerWrapper(include=['dew_or_rime:idx', 'is_day:idx',
                                             'is_in_shadow:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx',
                                                                    'is_day:idx',
                                                                    'is_in_shadow:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))])
2023-10-24 16:26:31,233:INFO:save_model() successfully completed......................................
2023-10-24 16:26:31,387:INFO:Initializing predict_model()
2023-10-24 16:26:31,387:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa4b4b58820>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['absolute_humidity_2m:gm3',
                                             'air_density_2m:kgm3',
                                             'ceiling_height_agl:m',
                                             'clear_sky_energy_1h:J',
                                             'clear_sky_rad:W',
                                             'cloud_base_agl:m',
                                             'dew_point_2m:K', 'diffuse_rad:W',
                                             'diffuse_rad_1h:J', 'direct_rad:W',
                                             'direct_rad_1h:J',
                                             'effective_cloud_cover:p',
                                             'elevation:m...
                 TransformerWrapper(include=['dew_or_rime:idx', 'is_day:idx',
                                             'is_in_shadow:idx'],
                                    transformer=OneHotEncoder(cols=['dew_or_rime:idx',
                                                                    'is_day:idx',
                                                                    'is_in_shadow:idx'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 BaggingRegressor(estimator=LGBMRegressor(n_jobs=-1,
                                                          random_state=123),
                                  random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa4c856b4c0>)
2023-10-24 16:26:31,387:INFO:Checking exceptions
2023-10-24 16:26:31,387:INFO:Preloading libraries
2023-10-24 16:26:31,388:INFO:Set up data.
2023-10-24 16:26:31,401:INFO:Set up index.
